GitDiffStart: 8da43c4bb86e24029c2be7cad4a87eea04827399 | Sat Oct 3 14:24:45 2009 +0000
diff --git a/contrib/CHANGES.txt b/contrib/CHANGES.txt
index 4f045b7..b128c5a 100644
--- a/contrib/CHANGES.txt
+++ b/contrib/CHANGES.txt
@@ -27,6 +27,9 @@ Optimizations
 
 Documentation
 
+ * LUCENE-1916: Translated documentation in the smartcn hhmm package.
+   (Patricia Peng via Robert Muir)
+
 Build
 
 Test Cases
diff --git a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/AbstractDictionary.java b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/AbstractDictionary.java
index 9b37ae9..729829f 100644
--- a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/AbstractDictionary.java
+++ b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/AbstractDictionary.java
@@ -117,8 +117,9 @@ abstract class AbstractDictionary {
         // Should be a two-byte character
         return -1;
       }
-      int b0 = (int) (buffer[0] & 0x0FF) - 161; // ç¼??ä»?1å¼?å§????????0xA1=161
-      int b1 = (int) (buffer[1] & 0x0FF) - 161; // ç¬??ä¸??ç¬???????ä¸??ç¬?²¡???å­?????æ¯?¸ª?ºå???16*6-2=94ä¸??å­?
+      int b0 = (int) (buffer[0] & 0x0FF) - 161; // Code starts from A1, therefore subtract 0xA1=161
+      int b1 = (int) (buffer[1] & 0x0FF) - 161; // There is no Chinese char for the first and last symbol. 
+      											// Therefore, each code page only has 16*6-2=94 characters.
       return (short) (b0 * 94 + b1);
     } catch (UnsupportedEncodingException e) {
       e.printStackTrace();
diff --git a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/BiSegGraph.java b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/BiSegGraph.java
index 1552e4b..dc4ea99 100644
--- a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/BiSegGraph.java
+++ b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/BiSegGraph.java
@@ -63,7 +63,7 @@ class BiSegGraph {
     char[] idBuffer;
     // get the list of tokens ordered and indexed
     segTokenList = segGraph.makeIndex();
-    // ??¸ºstartTokenï¼?"å§?##å§?"ï¼??èµ·å?ä½?½®??-1???keyä¸?-1?¶å?ä»¥å???tartToken
+    // Because the beginning position of startToken is -1, therefore startToken can be obtained when key = -1
     int key = -1;
     List nextTokens = null;
     while (key < maxStart) {
@@ -71,16 +71,17 @@ class BiSegGraph {
 
         List tokenList = segGraph.getStartList(key);
 
-        // ä¸ºæ?ä¸?ä¸?eyå¯¹å??????oken?½è?ç®??æ¬?
+        // Calculate all tokens for a given key.
         for (Iterator iter = tokenList.iterator(); iter.hasNext();) {
           SegToken t1 = (SegToken) iter.next();
           oneWordFreq = t1.weight;
           next = t1.endOffset;
           nextTokens = null;
-          // ?¾å?ä¸??ä¸??åº??Tokenï¼??å¦??????µ·å²¸â???å½??Token?????????? ä¸??ä¸?oken??»¥????µ·???????µ·å²¸â??
-          // å¦???¾ä??°ä?ä¸?ä¸?okenï¼??è¯´æ??°ä???°¾ï¼???°å¾ª????
+          // Find the next corresponding Token.
+          // For example: "Sunny seashore", the present Token is "sunny", next one should be "sea" or "seashore".
+          // If we cannot find the next Token, then go to the end and repeat the same cycle.
           while (next <= maxStart) {
-            // ??¸ºendToken??µ·å§??ç½??sentenceLenï¼??æ­¤ç?äº?entenceLen???ä»¥æ???ndToken
+            // Because the beginning position of endToken is sentenceLen, so equal to sentenceLen can find endToken.
             if (segGraph.isStartExist(next)) {
               nextTokens = segGraph.getStartList(next);
               break;
diff --git a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/BigramDictionary.java b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/BigramDictionary.java
index 127a2ff..5a1ea00 100644
--- a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/BigramDictionary.java
+++ b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/BigramDictionary.java
@@ -156,7 +156,8 @@ class BigramDictionary extends AbstractDictionary {
       IOException, UnsupportedEncodingException {
 
     int i, cnt, length, total = 0;
-    // ??»¶ä¸??ç»??äº?6763ä¸??å­??5ä¸?©ºæ±??ç¬?3756~3760ï¼??ä¸??3756ä¸???¥å??¨ç??·ä¿¡????
+    // The file only counted 6763 Chinese characters plus 5 reserved slots 3756~3760.  
+    // The 3756th is used (as a header) to store information.
     int[] buffer = new int[3];
     byte[] intBuffer = new byte[4];
     String tmpword;
diff --git a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/HHMMSegmenter.java b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/HHMMSegmenter.java
index 50a0987..a0556ea 100644
--- a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/HHMMSegmenter.java
+++ b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/HHMMSegmenter.java
@@ -49,7 +49,7 @@ public class HHMMSegmenter {
     int[] charTypeArray = getCharTypes(sentence);
     StringBuilder wordBuf = new StringBuilder();
     SegToken token;
-    int frequency = 0; // word????°æ???
+    int frequency = 0; // the number of times word appears.
     boolean hasFullWidth;
     int wordType;
     char[] charArray;
@@ -64,7 +64,9 @@ public class HHMMSegmenter {
         case CharType.HANZI:
           j = i + 1;
           wordBuf.delete(0, wordBuf.length());
-          // ä¸????¸ªæ±???½ä??½æ????ï¼??å°??ä¸??å­????egGraphä¸??ï¼????????????¾æ?å­?
+          // It doesn't matter if a single Chinese character (Hanzi) can form a phrase or not, 
+          // it will store that single Chinese character (Hanzi) in the SegGraph.  Otherwise, it will 
+          // cause word division.
           wordBuf.append(sentence.charAt(i));
           charArray = new char[] { sentence.charAt(i) };
           frequency = wordDict.getFrequency(charArray);
@@ -75,7 +77,8 @@ public class HHMMSegmenter {
           foundIndex = wordDict.getPrefixMatch(charArray);
           while (j <= length && foundIndex != -1) {
             if (wordDict.isEqual(charArray, foundIndex) && charArray.length > 1) {
-              // å°±æ???»¬è¦?????ï¼? ä¹?°±????¾å?äº??i?????ä¸??è¯?egTokenï¼?¹¶ä¸?????å­??
+              // It is the phrase we are looking for; In other words, we have found a phrase SegToken
+              // from i to j.  It is not a monosyllabic word (single word).
               frequency = wordDict.getFrequency(charArray);
               token = new SegToken(charArray, i, j, WordType.CHINESE_WORD,
                   frequency);
@@ -89,9 +92,9 @@ public class HHMMSegmenter {
               wordBuf.append(sentence.charAt(j));
               charArray = new char[wordBuf.length()];
               wordBuf.getChars(0, charArray.length, charArray, 0);
-              // idArrayä½?¸º???å·²ç??¾å?è¿?(foundWordIndex!=-1),
-              // ??????è¿????dArray????½å??°å?foundWordIndexä»¥å?,
-              // ???foundWordIndexä¹??å¼?å§????
+              // idArray has been found (foundWordIndex!=-1) as a prefix before.  
+              // Therefore, idArray after it has been lengthened can only appear after foundWordIndex.  
+              // So start searching after foundWordIndex.
               foundIndex = wordDict.getPrefixMatch(charArray, foundIndex);
               j++;
             } else {
@@ -110,7 +113,7 @@ public class HHMMSegmenter {
               hasFullWidth = true;
             j++;
           }
-          // ?¾å?äº??i?????ä¸?okenï¼?±»??¸ºLETTER???ç¬?¸²
+          // Found a Token from i to j. Type is LETTER char string.
           charArray = Utility.STRING_CHAR_ARRAY;
           frequency = wordDict.getFrequency(charArray);
           wordType = hasFullWidth ? WordType.FULLWIDTH_STRING : WordType.STRING;
@@ -128,7 +131,7 @@ public class HHMMSegmenter {
               hasFullWidth = true;
             j++;
           }
-          // ?¾å?äº??i?????ä¸?okenï¼?±»??¸ºNUMBER???ç¬?¸²
+          // Found a Token from i to j. Type is NUMBER char string.
           charArray = Utility.NUMBER_CHAR_ARRAY;
           frequency = wordDict.getFrequency(charArray);
           wordType = hasFullWidth ? WordType.FULLWIDTH_NUMBER : WordType.NUMBER;
@@ -138,7 +141,7 @@ public class HHMMSegmenter {
           break;
         case CharType.DELIMITER:
           j = i + 1;
-          // ???ç¬????eightä¸???¥ä?ï¼???¸ª??å¤§ç?é¢???³å?
+          // No need to search the weight for the punctuation.  Picking the highest frequency will work.
           frequency = Utility.MAX_FREQUENCE;
           charArray = new char[] { sentence.charAt(i) };
           token = new SegToken(charArray, i, j, WordType.DELIMITER, frequency);
@@ -147,7 +150,8 @@ public class HHMMSegmenter {
           break;
         default:
           j = i + 1;
-          // ???è®¤è????ç¬??ä½???¥ä¸²???ï¼??å¦?B2312ç¼??ä¹?????ç¬??æ¯?¸ªå­??å½??ä¸?ä¸?
+          // Treat the unrecognized char symbol as unknown string.
+          // For example, any symbol not in GB2312 is treated as one of these.
           charArray = Utility.STRING_CHAR_ARRAY;
           frequency = wordDict.getFrequency(charArray);
           token = new SegToken(charArray, i, j, WordType.STRING, frequency);
@@ -157,13 +161,13 @@ public class HHMMSegmenter {
       }
     }
 
-    // ä¸?egGraphå¢??ä¸¤ä¸ª??okenï¼? "å§?##å§?","??##??"
+    // Add two more Tokens: "beginning xx beginning"
     charArray = Utility.START_CHAR_ARRAY;
     frequency = wordDict.getFrequency(charArray);
     token = new SegToken(charArray, -1, 0, WordType.SENTENCE_BEGIN, frequency);
     segGraph.addToken(token);
 
-    // "??##??"
+    // "end xx end"
     charArray = Utility.END_CHAR_ARRAY;
     frequency = wordDict.getFrequency(charArray);
     token = new SegToken(charArray, length, length + 1, WordType.SENTENCE_END,
diff --git a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/WordDictionary.java b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/WordDictionary.java
index cdc8871..dc3f558 100644
--- a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/WordDictionary.java
+++ b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/WordDictionary.java
@@ -55,19 +55,24 @@ class WordDictionary extends AbstractDictionary {
   public static final int PRIME_INDEX_LENGTH = 12071;
 
   /**
-   * wordIndexTableä¿??å°?nicodeä¸???????å­????ash??RIME_INDEX_LENGTH?¿åº¦???ç»?¸­ï¼?
-   * å½??ä¼???²ç?ï¼??å®??ä¸??ç¨???????B2312å­???¨å?ï¼?6768ä¸??ç¬??ä¸??äº?SCIIå­??ï¼?
-   * ???å¯¹è?äº??ç¬????????ä¸ºä?ä¿??æ¯?????ç¡??§ï?ä¿????????ç¬??charIndexTableä¸?»¥ç¡???¥æ????ç¡???
+   * wordIndexTable guarantees to hash all Chinese characters in Unicode into 
+   * PRIME_INDEX_LENGTH array. There will be conflict, but in reality this 
+   * program only handles the 6768 characters found in GB2312 plus some 
+   * ASCII characters. Therefore in order to guarantee better precision, it is
+   * necessary to retain the original symbol in the charIndexTable.
    */
   private short[] wordIndexTable;
 
   private char[] charIndexTable;
 
   /**
-   * å­???????åº??????°æ?ç»??ï¼?¸ºäº??????¨ç©º?´å¤ªå¤???¨ä?ä¸¤ä¸ª??????ç»´æ?ç»??å­??è¯?????????
-   * æ¯?¸ªè¯???¨ä?ä¸?har[]ä¸??æ¯?¸ªcharå¯¹å?ä¸?ä¸??å­???¶ä?å­??ï¼??ä¸??????¨ä?ä¸?ntä¸??
-   * è¿?¸¤ä¸??ç»????¸¤ä¸??è¡¨æ?ä¸?ä¸?å¯¹å??????æ­¤å?ä»¥å???ordItem_charArrayTable[i][j]?¥æ?è¯??
-   * ??ordItem_frequencyTable[i][j]?¥æ?è¯¢å?åº??é¢??
+   * To avoid taking too much space, the data structure needed to store the 
+   * lexicon requires two multidimensional arrays to store word and frequency.
+   * Each word is placed in a char[]. Each char represents a Chinese char or 
+   * other symbol.  Each frequency is put into an int. These two arrays 
+   * correspond to each other one-to-one. Therefore, one can use 
+   * wordItem_charArrayTable[i][j] to look up word from lexicon, and 
+   * wordItem_frequencyTable[i][j] to look up the corresponding frequency. 
    */
   private char[][][] wordItem_charArrayTable;
 
@@ -193,7 +198,8 @@ class WordDictionary extends AbstractDictionary {
   private int loadMainDataFromFile(String dctFilePath)
       throws FileNotFoundException, IOException, UnsupportedEncodingException {
     int i, cnt, length, total = 0;
-    // ??»¶ä¸??ç»??äº?6763ä¸??å­??5ä¸?©ºæ±??ç¬?3756~3760ï¼??ä¸??3756ä¸???¥å??¨ç??·ä¿¡????
+    // The file only counted 6763 Chinese characters plus 5 reserved slots 3756~3760.
+    // The 3756th is used (as a header) to store information.
     int[] buffer = new int[3];
     byte[] intBuffer = new byte[4];
     String tmpword;
@@ -255,33 +261,37 @@ class WordDictionary extends AbstractDictionary {
   }
 
   /**
-   * ???åº????????¹ç??·ç?ä¿¡æ???¹¶?°ä?ä¸??è¡¨é?(ä»?1å¼?å§??3755å¤?)???????¶å?å¼?ï¼??????°å?ä¸???·å?åº????¡¨ä¸?
+   * The original lexicon puts all information with punctuation into a 
+   * chart (from 1 to 3755). Here it then gets expanded, separately being
+   * placed into the chart that has the corresponding symbol.
    */
   private void expandDelimiterData() {
     int i;
     int cnt;
-    // ???ç¬???¨ä?1å¼?å§??3755å¤??å°??å§?????ç¬??å¯¹å?????¸å????å¯¹å?????¹ç??·ä¸­
+    // Punctuation then treating index 3755 as 1, 
+    // distribute the original punctuation corresponding dictionary into 
     int delimiterIndex = 3755 + GB2312_FIRST_CHAR;
     i = 0;
     while (i < wordItem_charArrayTable[delimiterIndex].length) {
       char c = wordItem_charArrayTable[delimiterIndex][i][0];
-      int j = getGB2312Id(c);// è¯¥æ??¹ç??·å?è¯¥æ??¨ç?index??
+      int j = getGB2312Id(c);// the id value of the punctuation
       if (wordItem_charArrayTable[j] == null) {
 
         int k = i;
-        // ä»?å¼?å§???°å???»¥jå¼?å¤´ç?ç¬????orditem??¸ª??
+        // Starting from i, count the number of the following worditem symbol from j
         while (k < wordItem_charArrayTable[delimiterIndex].length
             && wordItem_charArrayTable[delimiterIndex][k][0] == c) {
           k++;
         }
-        // æ­¤æ?k-iä¸?dä¸?????¹ç??·å?åº??wordItem??¸ª??
+        // c is the punctuation character, j is the id value of c
+        // k-1 represents the index of the last punctuation character
         cnt = k - i;
         if (cnt != 0) {
           wordItem_charArrayTable[j] = new char[cnt][];
           wordItem_frequencyTable[j] = new int[cnt];
         }
 
-        // ä¸ºæ?ä¸?ä¸?ordItemèµ???
+        // Assign value for each wordItem.
         for (k = 0; k < cnt; k++, i++) {
           // wordItemTable[j][k] = new WordItem();
           wordItem_frequencyTable[j][k] = wordItem_frequencyTable[delimiterIndex][i];
@@ -293,7 +303,7 @@ class WordDictionary extends AbstractDictionary {
         setTableIndex(c, j);
       }
     }
-    // å°??ç¬??å¯¹å????ç»????
+    // Delete the original corresponding symbol array.
     wordItem_charArrayTable[delimiterIndex] = null;
     wordItem_frequencyTable[delimiterIndex] = null;
   }
@@ -362,8 +372,8 @@ class WordDictionary extends AbstractDictionary {
   }
 
   /*
-   * è®¡ç?å­??c?¨å?å¸?¡¨ä¸??è¯¥å????ç½???¶å?å°??????¡¨ä¸??ä½?½®???¼å?å§??
-   * 
+   * Calculate character c's position in hash table, 
+   * then initialize the value of that position in the address table.
    */
   private boolean setTableIndex(char c, int j) {
     int index = getAvaliableTableIndex(c);
@@ -420,12 +430,14 @@ class WordDictionary extends AbstractDictionary {
   }
 
   /**
-   * ?¨å??¸å?ä¸???¾å?è¯??åº??char?°ç?ä¸?harArray???ç¬?¸²??????????¨å?è¯????¸­???ç½?
+   * Look up the text string corresponding with the word char array, 
+   * and return the position of the word list.
    * 
-   * @param knownHashIndex å·²ç????ç¬??ä¸??ç¬?harArray[0]??ashè¡¨ä¸­???ç½??å¦?????ç®????»¥?¨å???nt
-   *        findInTable(char[] charArray) ä»£æ?
-   * @param charArray ?¥æ????å¯¹å???har?°ç?
-   * @return ????¨å?è¯??ç»?¸­???ç½??å¦??æ²¡æ??°å?è¿??-1
+   * @param knownHashIndex already figure out position of the first word 
+   *   symbol charArray[0] in hash table. If not calculated yet, can be 
+   *   replaced with function int findInTable(char[] charArray).
+   * @param charArray look up the char array corresponding with the word.
+   * @return word location in word array.  If not found, then return -1.
    */
   private int findInTable(short knownHashIndex, char[] charArray) {
     if (charArray == null || charArray.length == 0)
@@ -488,7 +500,7 @@ class WordDictionary extends AbstractDictionary {
             && Utility.compareArrayByPrefix(charArray, 1, items[mid], 0) == 0)
           mid--;
         mid++;
-        return mid;// ?¾å?ç¬??ä¸?»¥charArrayä¸ºå?ç¼????è¯?
+        return mid;// Find the first word that uses charArray as prefix.
       } else if (cmpResult < 0)
         end = mid - 1;
       else

