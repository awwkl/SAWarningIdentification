GitDiffStart: 08a2eb4665848d196c446f2b5235b1cfdab076cb | Fri May 23 18:57:55 2008 +0000
diff --git a/CHANGES.txt b/CHANGES.txt
index a59f58c..cd8b23a 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -66,6 +66,10 @@ API Changes
 
  8. LUCENE-852: Let the SpellChecker caller specify IndexWriter mergeFactor
     and RAM buffer size.  (Otis Gospodnetic)
+	
+ 9. LUCENE-1290: Deprecate org.apache.lucene.search.Hits, Hit and HitIterator
+    and remove all references to these classes from the core. Also update demos
+    and tutorials. (Michael Busch)
 
 Bug fixes
     
diff --git a/docs/demo2.html b/docs/demo2.html
index 2181b0a..f41a330 100644
--- a/docs/demo2.html
+++ b/docs/demo2.html
@@ -339,14 +339,23 @@ documents are interpreted: finding the end of words and removing useless words l
 the results from the <span class="codefrag">QueryParser</span> which is passed to
 the searcher.  Note that it's also possible to programmatically construct a rich <span class="codefrag">Query</span> object without using the query
 parser.  The query parser just enables decoding the <a href="queryparsersyntax.html">Lucene query
-syntax</a> into the corresponding <span class="codefrag">Query</span> object.  The searcher results are
-returned in a collection of Documents called <span class="codefrag">Hits</span> which is then iterated through and
-displayed to the user.
+syntax</a> into the corresponding <span class="codefrag">Query</span> object. Search can be executed in 
+two different ways: 
+<ul>
+
+<li>Streaming: A <span class="codefrag">HitCollector</span> subclass
+simply prints out the document ID and score for each matching document.</li>
+
+<li>Paging: Using a <span class="codefrag">TopDocCollector</span> 
+the search results are printed in pages, sorted by score (i. e. relevance).</li>
+
+</ul>  
+
 </p>
 </div>
 
 
-<a name="N100ED"></a><a name="The Web example..."></a>
+<a name="N100FB"></a><a name="The Web example..."></a>
 <h2 class="boxed">The Web example...</h2>
 <div class="section">
 <p>
diff --git a/docs/demo2.pdf b/docs/demo2.pdf
index cb0b8cb..3bc6e03 100644
--- a/docs/demo2.pdf
+++ b/docs/demo2.pdf
@@ -84,8 +84,13 @@ words and removing useless words like 'a', 'an' and 'the'. The Query object cont
 results from the QueryParser which is passed to the searcher. Note that it's also possible
 to programmatically construct a rich Query object without using the query parser. The query
 parser just enables decoding the Lucene query syntax into the corresponding Query object.
-The searcher results are returned in a collection of Documents called Hits which is then
-iterated through and displayed to the user.
+Search can be executed in two different ways:
+?? Streaming: A HitCollector subclass simply prints out the document ID and score for
+
+    each matching document.
+?? Paging: Using a TopDocCollector the search results are printed in pages, sorted by
+
+    score (i. e. relevance).
 
 5. The Web example...
 
diff --git a/docs/scoring.html b/docs/scoring.html
index f9ed5c2..0795ed7 100644
--- a/docs/scoring.html
+++ b/docs/scoring.html
@@ -494,9 +494,9 @@ document.write("Last Published: " + document.lastModified);
                     , beginning the scoring process.
                 </p>
 <p>Once inside the Searcher, a
-                    <a href="api/org/apache/lucene/search/Hits.html">Hits</a>
-                    object is constructed, which handles the scoring and caching of the search results.
-                    The Hits constructor stores references to three or four important objects:
+                    <a href="api/org/apache/lucene/search/HitCollector.html">HitCollector</a>
+                    is used for the scoring and sorting of the search results.
+                    These important objects are involved in a search:
                     <ol>
                         
 <li>The
@@ -521,12 +521,11 @@ document.write("Last Published: " + document.lastModified);
 </ol>
                 
 </p>
-<p>Now that the Hits object has been initialized, it begins the process of identifying documents that
-                    match the query by calling getMoreDocs method. Assuming we are not sorting (since sorting doesn't
+<p> Assuming we are not sorting (since sorting doesn't
                     effect the raw Lucene score),
-                    we call on the "expert" search method of the Searcher, passing in our
+                    we call one of the search method of the Searcher, passing in the
                     <a href="api/org/apache/lucene/search/Weight.html">Weight</a>
-                    object,
+                    object created by Searcher.createWeight(Query),
                     <a href="api/org/apache/lucene/search/Filter.html">Filter</a>
                     and the number of results we want. This method
                     returns a
diff --git a/docs/scoring.pdf b/docs/scoring.pdf
index 36d5f91..4c202a5 100644
--- a/docs/scoring.pdf
+++ b/docs/scoring.pdf
@@ -185,8 +185,8 @@ for the earlier sections.
 In the typical search application, a Query is passed to the Searcher , beginning the scoring
 process.
 
-Once inside the Searcher, a Hits object is constructed, which handles the scoring and caching
-of the search results. The Hits constructor stores references to three or four important objects:
+Once inside the Searcher, a HitCollector is used for the scoring and sorting of the search
+results. These important objects are involved in a search:
 1. The Weight object of the Query. The Weight object is an internal representation of the
 
     Query that allows the Query to be reused by the Searcher.
@@ -196,14 +196,13 @@ of the search results. The Hits constructor stores references to three or four i
 
     method is not desired.
 
-Now that the Hits object has been initialized, it begins the process of identifying documents
-that match the query by calling getMoreDocs method. Assuming we are not sorting (since
-sorting doesn't effect the raw Lucene score), we call on the "expert" search method of the
-Searcher, passing in our Weight object, Filter and the number of results we want. This
-method returns a TopDocs object, which is an internal collection of search results. The
-Searcher creates a TopDocCollector and passes it along with the Weight, Filter to another
-expert search method (for more on the HitCollector mechanism, see Searcher .) The
-TopDocCollector uses a PriorityQueue to collect the top results for the search.
+Assuming we are not sorting (since sorting doesn't effect the raw Lucene score), we call one
+of the search method of the Searcher, passing in the Weight object created by
+Searcher.createWeight(Query), Filter and the number of results we want. This method returns
+a TopDocs object, which is an internal collection of search results. The Searcher creates a
+TopDocCollector and passes it along with the Weight, Filter to another expert search method
+(for more on the HitCollector mechanism, see Searcher .) The TopDocCollector uses a
+PriorityQueue to collect the top results for the search.
 
 If a Filter is being used, some initial setup is done to determine which docs to include.
 Otherwise, we ask the Weight for a Scorer for the IndexReader of the current searcher and
diff --git a/src/demo/org/apache/lucene/demo/SearchFiles.java b/src/demo/org/apache/lucene/demo/SearchFiles.java
index 7308908..dae2e5c 100644
--- a/src/demo/org/apache/lucene/demo/SearchFiles.java
+++ b/src/demo/org/apache/lucene/demo/SearchFiles.java
@@ -17,22 +17,24 @@ package org.apache.lucene.demo;
  * limitations under the License.
  */
 
+import java.io.BufferedReader;
+import java.io.FileReader;
+import java.io.IOException;
+import java.io.InputStreamReader;
+import java.util.Date;
+
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.standard.StandardAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.index.FilterIndexReader;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.queryParser.QueryParser;
-import org.apache.lucene.search.Hits;
+import org.apache.lucene.search.HitCollector;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
+import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.Searcher;
-
-import java.io.BufferedReader;
-import java.io.FileReader;
-import java.io.IOException;
-import java.io.InputStreamReader;
-import java.util.Date;
+import org.apache.lucene.search.TopDocCollector;
 
 /** Simple command-line based search demo. */
 public class SearchFiles {
@@ -60,7 +62,8 @@ public class SearchFiles {
   /** Simple command-line based search demo. */
   public static void main(String[] args) throws Exception {
     String usage =
-      "Usage: java org.apache.lucene.demo.SearchFiles [-index dir] [-field f] [-repeat n] [-queries file] [-raw] [-norms field]";
+      "Usage:\tjava org.apache.lucene.demo.SearchFiles [-index dir] [-field f] [-repeat n] [-queries file] [-raw] [-norms field] [-paging hitsPerPage]";
+    usage += "\n\tSpecify 'false' for hitsPerPage to use streaming instead of paging search.";
     if (args.length > 0 && ("-h".equals(args[0]) || "-help".equals(args[0]))) {
       System.out.println(usage);
       System.exit(0);
@@ -72,6 +75,8 @@ public class SearchFiles {
     int repeat = 0;
     boolean raw = false;
     String normsField = null;
+    boolean paging = true;
+    int hitsPerPage = 10;
     
     for (int i = 0; i < args.length; i++) {
       if ("-index".equals(args[i])) {
@@ -91,6 +96,16 @@ public class SearchFiles {
       } else if ("-norms".equals(args[i])) {
         normsField = args[i+1];
         i++;
+      } else if ("-paging".equals(args[i])) {
+        if (args[i+1].equals("false")) {
+          paging = false;
+        } else {
+          hitsPerPage = Integer.parseInt(args[i+1]);
+          if (hitsPerPage == 0) {
+            paging = false;
+          }
+        }
+        i++;
       }
     }
     
@@ -125,53 +140,149 @@ public class SearchFiles {
       Query query = parser.parse(line);
       System.out.println("Searching for: " + query.toString(field));
 
-      Hits hits = searcher.search(query);
-      
+            
       if (repeat > 0) {                           // repeat & time as benchmark
         Date start = new Date();
         for (int i = 0; i < repeat; i++) {
-          hits = searcher.search(query);
+          searcher.search(query, null, 100);
         }
         Date end = new Date();
         System.out.println("Time: "+(end.getTime()-start.getTime())+"ms");
       }
 
-      System.out.println(hits.length() + " total matching documents");
+      if (paging) {
+        doPagingSearch(in, searcher, query, hitsPerPage, raw, queries == null);
+      } else {
+        doStreamingSearch(searcher, query);
+      }
+    }
+    reader.close();
+  }
+  
+  /**
+   * This method uses a custom HitCollector implementation which simply prints out
+   * the docId and score of every matching document. 
+   * 
+   *  This simulates the streaming search use case, where all hits are supposed to
+   *  be processed, regardless of their relevance.
+   */
+  public static void doStreamingSearch(final Searcher searcher, Query query) throws IOException {
+    HitCollector streamingHitCollector = new HitCollector() {
+      
+      // simply print docId and score of every matching document
+      public void collect(int doc, float score) {
+        System.out.println("doc="+doc+" score="+score);
+      }
+      
+    };
+    
+    searcher.search(query, streamingHitCollector);
+  }
 
-      final int HITS_PER_PAGE = 10;
-      for (int start = 0; start < hits.length(); start += HITS_PER_PAGE) {
-        int end = Math.min(hits.length(), start + HITS_PER_PAGE);
-        for (int i = start; i < end; i++) {
+  /**
+   * This demonstrates a typical paging search scenario, where the search engine presents 
+   * pages of size n to the user. The user can then go to the next page if interested in
+   * the next hits.
+   * 
+   * When the query is executed for the first time, then only enough results are collected
+   * to fill 5 result pages. If the user wants to page beyond this limit, then the query
+   * is executed another time and all hits are collected.
+   * 
+   */
+  public static void doPagingSearch(BufferedReader in, Searcher searcher, Query query, 
+                                     int hitsPerPage, boolean raw, boolean interactive) throws IOException {
+ 
+    // Collect enough docs to show 5 pages
+    TopDocCollector collector = new TopDocCollector(5 * hitsPerPage);
+    searcher.search(query, collector);
+    ScoreDoc[] hits = collector.topDocs().scoreDocs;
+    
+    int numTotalHits = collector.getTotalHits();
+    System.out.println(numTotalHits + " total matching documents");
 
-          if (raw) {                              // output raw format
-            System.out.println("doc="+hits.id(i)+" score="+hits.score(i));
-            continue;
-          }
+    int start = 0;
+    int end = Math.min(numTotalHits, hitsPerPage);
+        
+    while (true) {
+      if (end > hits.length) {
+        System.out.println("Only results 1 - " + hits.length +" of " + numTotalHits + " total matching documents collected.");
+        System.out.println("Collect more (y/n) ?");
+        String line = in.readLine();
+        if (line.length() == 0 || line.charAt(0) == 'n') {
+          break;
+        }
 
-          Document doc = hits.doc(i);
-          String path = doc.get("path");
-          if (path != null) {
-            System.out.println((i+1) + ". " + path);
-            String title = doc.get("title");
-            if (title != null) {
-              System.out.println("   Title: " + doc.get("title"));
-            }
-          } else {
-            System.out.println((i+1) + ". " + "No path for this document");
+        collector = new TopDocCollector(numTotalHits);
+        searcher.search(query, collector);
+        hits = collector.topDocs().scoreDocs;
+      }
+      
+      end = Math.min(hits.length, start + hitsPerPage);
+      
+      for (int i = start; i < end; i++) {
+        if (raw) {                              // output raw format
+          System.out.println("doc="+hits[i].doc+" score="+hits[i].score);
+          continue;
+        }
+
+        Document doc = searcher.doc(hits[i].doc);
+        String path = doc.get("path");
+        if (path != null) {
+          System.out.println((i+1) + ". " + path);
+          String title = doc.get("title");
+          if (title != null) {
+            System.out.println("   Title: " + doc.get("title"));
           }
+        } else {
+          System.out.println((i+1) + ". " + "No path for this document");
         }
+                  
+      }
 
-        if (queries != null)                      // non-interactive
-          break;
-        
-        if (hits.length() > end) {
-          System.out.println("more (y/n) ? ");
-          line = in.readLine();
-          if (line.length() == 0 || line.charAt(0) == 'n')
+      if (!interactive) {
+        break;
+      }
+
+      if (numTotalHits >= end) {
+        boolean quit = false;
+        while (true) {
+          System.out.print("Press ");
+          if (start - hitsPerPage >= 0) {
+            System.out.print("(p)revious page, ");  
+          }
+          if (start + hitsPerPage < numTotalHits) {
+            System.out.print("(n)ext page, ");
+          }
+          System.out.println("(q)uit or enter number to jump to a page.");
+          
+          String line = in.readLine();
+          if (line.length() == 0 || line.charAt(0)=='q') {
+            quit = true;
+            break;
+          }
+          if (line.charAt(0) == 'p') {
+            start = Math.max(0, start - hitsPerPage);
+            break;
+          } else if (line.charAt(0) == 'n') {
+            if (start + hitsPerPage < numTotalHits) {
+              start+=hitsPerPage;
+            }
             break;
+          } else {
+            int page = Integer.parseInt(line);
+            if ((page - 1) * hitsPerPage < numTotalHits) {
+              start = (page - 1) * hitsPerPage;
+              break;
+            } else {
+              System.out.println("No such page");
+            }
+          }
         }
+        if (quit) break;
+        end = Math.min(numTotalHits, start + hitsPerPage);
       }
+      
     }
-    reader.close();
+
   }
 }
diff --git a/src/java/org/apache/lucene/document/Document.java b/src/java/org/apache/lucene/document/Document.java
index 7291cc2..d3b9fb8 100644
--- a/src/java/org/apache/lucene/document/Document.java
+++ b/src/java/org/apache/lucene/document/Document.java
@@ -18,7 +18,7 @@ package org.apache.lucene.document;
  */
 
 import java.util.*;             // for javadoc
-import org.apache.lucene.search.Hits;  // for javadoc
+import org.apache.lucene.search.ScoreDoc; // for javadoc
 import org.apache.lucene.search.Searcher;  // for javadoc
 import org.apache.lucene.index.IndexReader;  // for javadoc
 
@@ -32,7 +32,7 @@ import org.apache.lucene.index.IndexReader;  // for javadoc
  *
  * <p>Note that fields which are <i>not</i> {@link Fieldable#isStored() stored} are
  * <i>not</i> available in documents retrieved from the index, e.g. with {@link
- * Hits#doc(int)}, {@link Searcher#doc(int)} or {@link
+ * ScoreDoc#doc}, {@link Searcher#doc(int)} or {@link
  * IndexReader#document(int)}.
  */
 
diff --git a/src/java/org/apache/lucene/search/Hit.java b/src/java/org/apache/lucene/search/Hit.java
index 8406b0a..c9cf277 100644
--- a/src/java/org/apache/lucene/search/Hit.java
+++ b/src/java/org/apache/lucene/search/Hit.java
@@ -26,6 +26,7 @@ import org.apache.lucene.index.CorruptIndexException;
  * Wrapper used by {@link HitIterator} to provide a lazily loaded hit
  * from {@link Hits}.
  *
+ * @deprecated Hits will be removed in Lucene 3.0. Use {@link TopDocCollector} and {@link TopDocs} instead. 
  * @author Jeremy Rayner
  */
 public class Hit implements java.io.Serializable {
diff --git a/src/java/org/apache/lucene/search/HitIterator.java b/src/java/org/apache/lucene/search/HitIterator.java
index b6f8bd3..f0667cc 100644
--- a/src/java/org/apache/lucene/search/HitIterator.java
+++ b/src/java/org/apache/lucene/search/HitIterator.java
@@ -25,6 +25,7 @@ import java.util.NoSuchElementException;
  * {@link Hits#iterator()} returns an instance of this class.  Calls to {@link #next()}
  * return a {@link Hit} instance.
  *
+ * @deprecated Hits will be removed in Lucene 3.0. Use {@link TopDocCollector} and {@link TopDocs} instead.
  * @author Jeremy Rayner
  */
 public class HitIterator implements Iterator {
@@ -76,3 +77,4 @@ public class HitIterator implements Iterator {
   }
 }
 
+
diff --git a/src/java/org/apache/lucene/search/Hits.java b/src/java/org/apache/lucene/search/Hits.java
index d1e5fd6..6703083 100644
--- a/src/java/org/apache/lucene/search/Hits.java
+++ b/src/java/org/apache/lucene/search/Hits.java
@@ -38,6 +38,19 @@ import org.apache.lucene.index.CorruptIndexException;
  * {@link java.util.ConcurrentModificationException ConcurrentModificationException}
  * is thrown when accessing hit <code>n</code> &ge; current_{@link #length()} 
  * (but <code>n</code> &lt; {@link #length()}_at_start). 
+ * 
+ * @deprecated Hits will be removed in Lucene 3.0. <p>
+ * Instead e. g. {@link TopDocCollector} and {@link TopDocs} can be used:<br>
+ * <pre>
+ *   TopDocCollector collector = new TopDocCollector(hitsPerPage);
+ *   searcher.search(query, collector);
+ *   ScoreDoc[] hits = collector.topDocs().scoreDocs;
+ *   for (int i = 0; i < hits.length; i++) {
+ *     int docId = hits[i].doc;
+ *     Document d = searcher.doc(docId);
+ *     // do something with current hit
+ *     ...
+ * </pre>
  */
 public final class Hits {
   private Weight weight;
diff --git a/src/java/org/apache/lucene/search/Searcher.java b/src/java/org/apache/lucene/search/Searcher.java
index 77e4a9a..875f351 100644
--- a/src/java/org/apache/lucene/search/Searcher.java
+++ b/src/java/org/apache/lucene/search/Searcher.java
@@ -33,6 +33,8 @@ public abstract class Searcher implements Searchable {
 
   /** Returns the documents matching <code>query</code>. 
    * @throws BooleanQuery.TooManyClauses
+   * @deprecated Hits will be removed in Lucene 3.0. Use
+   * {@link #search(Query, Filter, int))} instead.
    */
   public final Hits search(Query query) throws IOException {
     return search(query, (Filter)null);
@@ -41,6 +43,8 @@ public abstract class Searcher implements Searchable {
   /** Returns the documents matching <code>query</code> and
    * <code>filter</code>.
    * @throws BooleanQuery.TooManyClauses
+   * @deprecated Hits will be removed in Lucene 3.0. Use
+   * {@link #search(Query, Filter, int))} instead.
    */
   public Hits search(Query query, Filter filter) throws IOException {
     return new Hits(this, query, filter);
@@ -49,6 +53,8 @@ public abstract class Searcher implements Searchable {
   /** Returns documents matching <code>query</code> sorted by
    * <code>sort</code>.
    * @throws BooleanQuery.TooManyClauses
+   * @deprecated Hits will be removed in Lucene 3.0. Use 
+   * {@link #search(Query, Filter, int, Sort))} instead.
    */
   public Hits search(Query query, Sort sort)
     throws IOException {
@@ -58,13 +64,15 @@ public abstract class Searcher implements Searchable {
   /** Returns documents matching <code>query</code> and <code>filter</code>,
    * sorted by <code>sort</code>.
    * @throws BooleanQuery.TooManyClauses
+   * @deprecated Hits will be removed in Lucene 3.0. Use 
+   * {@link #search(Query, Filter, int, Sort))} instead.
    */
   public Hits search(Query query, Filter filter, Sort sort)
     throws IOException {
     return new Hits(this, query, filter, sort);
   }
 
-  /** Expert: Low-level search implementation with arbitrary sorting.  Finds
+  /** Search implementation with arbitrary sorting.  Finds
    * the top <code>n</code> hits for <code>query</code>, applying
    * <code>filter</code> if non-null, and sorting the hits by the criteria in
    * <code>sort</code>.
@@ -105,7 +113,7 @@ public abstract class Searcher implements Searchable {
    *
    * <p>Applications should only use this if they need <i>all</i> of the
    * matching documents.  The high-level search API ({@link
-   * Searcher#search(Query)}) is usually more efficient, as it skips
+   * Searcher#search(Query, Filter, int))}) is usually more efficient, as it skips
    * non-high-scoring hits.
    *
    * @param query to match documents
@@ -118,13 +126,9 @@ public abstract class Searcher implements Searchable {
     search(createWeight(query), filter, results);
   }
 
-  /** Expert: Low-level search implementation.  Finds the top <code>n</code>
+  /** Finds the top <code>n</code>
    * hits for <code>query</code>, applying <code>filter</code> if non-null.
    *
-   * <p>Called by {@link Hits}.
-   *
-   * <p>Applications should usually call {@link Searcher#search(Query)} or
-   * {@link Searcher#search(Query,Filter)} instead.
    * @throws BooleanQuery.TooManyClauses
    */
   public TopDocs search(Query query, Filter filter, int n)
diff --git a/src/site/src/documentation/content/xdocs/demo2.xml b/src/site/src/documentation/content/xdocs/demo2.xml
index a48817a..d74a151 100644
--- a/src/site/src/documentation/content/xdocs/demo2.xml
+++ b/src/site/src/documentation/content/xdocs/demo2.xml
@@ -118,10 +118,14 @@ the searcher.  Note that it's also possible to programmatically construct a rich
 href="api/org/apache/lucene/search/Query.html">Query</a></code> object without using the query
 parser.  The query parser just enables decoding the <a href="queryparsersyntax.html">Lucene query
 syntax</a> into the corresponding <code><a
-href="api/org/apache/lucene/search/Query.html">Query</a></code> object.  The searcher results are
-returned in a collection of Documents called <code><a
-href="api/org/apache/lucene/search/Hits.html">Hits</a></code> which is then iterated through and
-displayed to the user.
+href="api/org/apache/lucene/search/Query.html">Query</a></code> object. Search can be executed in 
+two different ways: 
+<ul>
+<li>Streaming: A <code><a href="api/org/apache/lucene/search/HitCollector.html">HitCollector</a></code> subclass
+simply prints out the document ID and score for each matching document.</li>
+<li>Paging: Using a <code><a href="api/org/apache/lucene/search/TopDocCollector.html">TopDocCollector</a></code> 
+the search results are printed in pages, sorted by score (i. e. relevance).</li>
+</ul>  
 </p>
 
 </section>
@@ -137,3 +141,4 @@ displayed to the user.
 </body>
 </document>
 
+
diff --git a/src/site/src/documentation/content/xdocs/scoring.xml b/src/site/src/documentation/content/xdocs/scoring.xml
index e1bf6ae..dac9a01 100644
--- a/src/site/src/documentation/content/xdocs/scoring.xml
+++ b/src/site/src/documentation/content/xdocs/scoring.xml
@@ -207,9 +207,9 @@
                     , beginning the scoring process.
                 </p>
                 <p>Once inside the Searcher, a
-                    <a href="api/org/apache/lucene/search/Hits.html">Hits</a>
-                    object is constructed, which handles the scoring and caching of the search results.
-                    The Hits constructor stores references to three or four important objects:
+                    <a href="api/org/apache/lucene/search/HitCollector.html">HitCollector</a>
+                    is used for the scoring and sorting of the search results.
+                    These important objects are involved in a search:
                     <ol>
                         <li>The
                             <a href="api/org/apache/lucene/search/Weight.html">Weight</a>
@@ -228,12 +228,11 @@
                         </li>
                     </ol>
                 </p>
-                <p>Now that the Hits object has been initialized, it begins the process of identifying documents that
-                    match the query by calling getMoreDocs method. Assuming we are not sorting (since sorting doesn't
+                <p> Assuming we are not sorting (since sorting doesn't
                     effect the raw Lucene score),
-                    we call on the "expert" search method of the Searcher, passing in our
+                    we call one of the search method of the Searcher, passing in the
                     <a href="api/org/apache/lucene/search/Weight.html">Weight</a>
-                    object,
+                    object created by Searcher.createWeight(Query),
                     <a href="api/org/apache/lucene/search/Filter.html">Filter</a>
                     and the number of results we want. This method
                     returns a
@@ -288,4 +287,4 @@
             </section>
         </section>
     </body>
-</document>
\ No newline at end of file
+</document>
diff --git a/src/test/org/apache/lucene/SearchTest.java b/src/test/org/apache/lucene/SearchTest.java
index f1b2db0..464121a 100644
--- a/src/test/org/apache/lucene/SearchTest.java
+++ b/src/test/org/apache/lucene/SearchTest.java
@@ -59,7 +59,6 @@ class SearchTest {
 // 	"\"a c\"",
 	    "\"a c e\"",
       };
-      Hits hits = null;
 
       QueryParser parser = new QueryParser("contents", analyzer);
       parser.setPhraseSlop(4);
@@ -72,12 +71,12 @@ class SearchTest {
       //DateFilter filter = DateFilter.Before("modified", Time(1997,00,01));
       //System.out.println(filter);
 
-        hits = searcher.search(query);
+        ScoreDoc[] hits = searcher.search(query, null, docs.length).scoreDocs;
 
-        System.out.println(hits.length() + " total results");
-        for (int i = 0 ; i < hits.length() && i < 10; i++) {
-          Document d = hits.doc(i);
-          System.out.println(i + " " + hits.score(i)
+        System.out.println(hits.length + " total results");
+        for (int i = 0 ; i < hits.length && i < 10; i++) {
+          Document d = searcher.doc(hits[i].doc);
+          System.out.println(i + " " + hits[i].score
 // 			   + " " + DateField.stringToDate(d.get("modified"))
             + " " + d.get("contents"));
         }
diff --git a/src/test/org/apache/lucene/SearchTestForDuplicates.java b/src/test/org/apache/lucene/SearchTestForDuplicates.java
index 557ebb5..09672b8 100644
--- a/src/test/org/apache/lucene/SearchTestForDuplicates.java
+++ b/src/test/org/apache/lucene/SearchTestForDuplicates.java
@@ -19,12 +19,18 @@ package org.apache.lucene;
 
 import java.io.IOException;
 
-import org.apache.lucene.store.*;
-import org.apache.lucene.document.*;
-import org.apache.lucene.analysis.*;
-import org.apache.lucene.index.*;
-import org.apache.lucene.search.*;
-import org.apache.lucene.queryParser.*;
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.SimpleAnalyzer;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.index.IndexWriter;
+import org.apache.lucene.queryParser.QueryParser;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.ScoreDoc;
+import org.apache.lucene.search.Searcher;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.store.RAMDirectory;
 
 class SearchTestForDuplicates {
 
@@ -52,15 +58,15 @@ class SearchTestForDuplicates {
 
       // try a search without OR
       Searcher searcher = new IndexSearcher(directory);
-      Hits hits = null;
+      ScoreDoc[] hits = null;
 
       QueryParser parser = new QueryParser(PRIORITY_FIELD, analyzer);
 
       Query query = parser.parse(HIGH_PRIORITY);
       System.out.println("Query: " + query.toString(PRIORITY_FIELD));
 
-      hits = searcher.search(query);
-      printHits(hits);
+      hits = searcher.search(query, null, 1000).scoreDocs;
+      printHits(hits, searcher);
 
       searcher.close();
 
@@ -73,8 +79,8 @@ class SearchTestForDuplicates {
       query = parser.parse(HIGH_PRIORITY + " OR " + MED_PRIORITY);
       System.out.println("Query: " + query.toString(PRIORITY_FIELD));
 
-      hits = searcher.search(query);
-      printHits(hits);
+      hits = searcher.search(query, null, 1000).scoreDocs;
+      printHits(hits, searcher);
 
       searcher.close();
 
@@ -84,11 +90,11 @@ class SearchTestForDuplicates {
     }
   }
 
-  private static void printHits( Hits hits ) throws IOException {
-    System.out.println(hits.length() + " total results\n");
-    for (int i = 0 ; i < hits.length(); i++) {
+  private static void printHits( ScoreDoc[] hits, Searcher searcher) throws IOException {
+    System.out.println(hits.length + " total results\n");
+    for (int i = 0 ; i < hits.length; i++) {
       if ( i < 10 || (i > 94 && i < 105) ) {
-        Document d = hits.doc(i);
+        Document d = searcher.doc(hits[i].doc);
         System.out.println(i + " " + d.get(ID_FIELD));
       }
     }
diff --git a/src/test/org/apache/lucene/TestDemo.java b/src/test/org/apache/lucene/TestDemo.java
index 60de0f2..d50a11d 100644
--- a/src/test/org/apache/lucene/TestDemo.java
+++ b/src/test/org/apache/lucene/TestDemo.java
@@ -17,7 +17,8 @@ package org.apache.lucene;
  * limitations under the License.
  */
 
-import org.apache.lucene.util.LuceneTestCase;
+import java.io.IOException;
+
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.standard.StandardAnalyzer;
 import org.apache.lucene.document.Document;
@@ -25,13 +26,12 @@ import org.apache.lucene.document.Field;
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.queryParser.ParseException;
 import org.apache.lucene.queryParser.QueryParser;
-import org.apache.lucene.search.Hits;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
+import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.RAMDirectory;
-
-import java.io.IOException;
+import org.apache.lucene.util.LuceneTestCase;
 
 /**
  * A very simple demo used in the API documentation (src/java/overview.html).
@@ -64,11 +64,11 @@ public class TestDemo extends LuceneTestCase {
     // Parse a simple query that searches for "text":
     QueryParser parser = new QueryParser("fieldname", analyzer);
     Query query = parser.parse("text");
-    Hits hits = isearcher.search(query);
-    assertEquals(1, hits.length());
+    ScoreDoc[] hits = isearcher.search(query, null, 1000).scoreDocs;
+    assertEquals(1, hits.length);
     // Iterate through the results:
-    for (int i = 0; i < hits.length(); i++) {
-      Document hitDoc = hits.doc(i);
+    for (int i = 0; i < hits.length; i++) {
+      Document hitDoc = isearcher.doc(hits[i].doc);
       assertEquals("This is the text to be indexed.", hitDoc.get("fieldname"));
     }
     isearcher.close();
diff --git a/src/test/org/apache/lucene/TestHitIterator.java b/src/test/org/apache/lucene/TestHitIterator.java
index d0b14dc..59fd120 100644
--- a/src/test/org/apache/lucene/TestHitIterator.java
+++ b/src/test/org/apache/lucene/TestHitIterator.java
@@ -35,6 +35,8 @@ import java.util.NoSuchElementException;
 /**
  * This test intentionally not put in the search package in order
  * to test HitIterator and Hit package protection.
+ * 
+ * @deprecated Hits will be removed in Lucene 3.0 
  */
 public class TestHitIterator extends LuceneTestCase {
   public void testIterator() throws Exception {
diff --git a/src/test/org/apache/lucene/TestSearch.java b/src/test/org/apache/lucene/TestSearch.java
index 7bcc584..4bbd281 100644
--- a/src/test/org/apache/lucene/TestSearch.java
+++ b/src/test/org/apache/lucene/TestSearch.java
@@ -108,7 +108,7 @@ public class TestSearch extends LuceneTestCase {
         "\"a c\"",
         "\"a c e\"",
       };
-      Hits hits = null;
+      ScoreDoc[] hits = null;
 
       QueryParser parser = new QueryParser("contents", analyzer);
       parser.setPhraseSlop(4);
@@ -121,12 +121,12 @@ public class TestSearch extends LuceneTestCase {
       //DateFilter filter = DateFilter.Before("modified", Time(1997,00,01));
       //System.out.println(filter);
 
-        hits = searcher.search(query);
+        hits = searcher.search(query, null, 1000).scoreDocs;
 
-        out.println(hits.length() + " total results");
-        for (int i = 0 ; i < hits.length() && i < 10; i++) {
-          Document d = hits.doc(i);
-          out.println(i + " " + hits.score(i)
+        out.println(hits.length + " total results");
+        for (int i = 0 ; i < hits.length && i < 10; i++) {
+          Document d = searcher.doc(hits[i].doc);
+          out.println(i + " " + hits[i].score
 // 			   + " " + DateField.stringToDate(d.get("modified"))
                              + " " + d.get("contents"));
         }
diff --git a/src/test/org/apache/lucene/TestSearchForDuplicates.java b/src/test/org/apache/lucene/TestSearchForDuplicates.java
index 2c54c97..57f6174 100644
--- a/src/test/org/apache/lucene/TestSearchForDuplicates.java
+++ b/src/test/org/apache/lucene/TestSearchForDuplicates.java
@@ -101,16 +101,15 @@ public class TestSearchForDuplicates extends LuceneTestCase {
 
       // try a search without OR
       Searcher searcher = new IndexSearcher(directory);
-      Hits hits = null;
 
       QueryParser parser = new QueryParser(PRIORITY_FIELD, analyzer);
 
       Query query = parser.parse(HIGH_PRIORITY);
       out.println("Query: " + query.toString(PRIORITY_FIELD));
 
-      hits = searcher.search(query);
-      printHits(out, hits);
-      checkHits(hits, MAX_DOCS);
+      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS).scoreDocs;
+      printHits(out, hits, searcher);
+      checkHits(hits, MAX_DOCS, searcher);
 
       searcher.close();
 
@@ -123,29 +122,29 @@ public class TestSearchForDuplicates extends LuceneTestCase {
       query = parser.parse(HIGH_PRIORITY + " OR " + MED_PRIORITY);
       out.println("Query: " + query.toString(PRIORITY_FIELD));
 
-      hits = searcher.search(query);
-      printHits(out, hits);
-      checkHits(hits, MAX_DOCS);
+      hits = searcher.search(query, null, MAX_DOCS).scoreDocs;
+      printHits(out, hits, searcher);
+      checkHits(hits, MAX_DOCS, searcher);
 
       searcher.close();
   }
 
 
-  private void printHits(PrintWriter out, Hits hits ) throws IOException {
-    out.println(hits.length() + " total results\n");
-    for (int i = 0 ; i < hits.length(); i++) {
+  private void printHits(PrintWriter out, ScoreDoc[] hits, Searcher searcher ) throws IOException {
+    out.println(hits.length + " total results\n");
+    for (int i = 0 ; i < hits.length; i++) {
       if ( i < 10 || (i > 94 && i < 105) ) {
-        Document d = hits.doc(i);
+        Document d = searcher.doc(hits[i].doc);
         out.println(i + " " + d.get(ID_FIELD));
       }
     }
   }
 
-  private void checkHits(Hits hits, int expectedCount) throws IOException {
-    assertEquals("total results", expectedCount, hits.length());
-    for (int i = 0 ; i < hits.length(); i++) {
+  private void checkHits(ScoreDoc[] hits, int expectedCount, Searcher searcher) throws IOException {
+    assertEquals("total results", expectedCount, hits.length);
+    for (int i = 0 ; i < hits.length; i++) {
       if ( i < 10 || (i > 94 && i < 105) ) {
-        Document d = hits.doc(i);
+      Document d = searcher.doc(hits[i].doc);
         assertEquals("check " + i, String.valueOf(i), d.get(ID_FIELD));
       }
     }
diff --git a/src/test/org/apache/lucene/ThreadSafetyTest.java b/src/test/org/apache/lucene/ThreadSafetyTest.java
index 0fa304a..3b15d1f 100644
--- a/src/test/org/apache/lucene/ThreadSafetyTest.java
+++ b/src/test/org/apache/lucene/ThreadSafetyTest.java
@@ -115,11 +115,11 @@ class ThreadSafetyTest {
       throws Exception {
       System.out.println("Searching for " + n);
         QueryParser parser = new QueryParser("contents", ANALYZER);
-      Hits hits =
-        searcher.search(parser.parse(English.intToEnglish(n)));
-      System.out.println("Search for " + n + ": total=" + hits.length());
-      for (int j = 0; j < Math.min(3, hits.length()); j++) {
-        System.out.println("Hit for " + n + ": " + hits.doc(j).get("id"));
+      ScoreDoc[] hits =
+        searcher.search(parser.parse(English.intToEnglish(n)), null, 1000).scoreDocs;
+      System.out.println("Search for " + n + ": total=" + hits.length);
+      for (int j = 0; j < Math.min(3, hits.length); j++) {
+        System.out.println("Hit for " + n + ": " + searcher.doc(hits[j].doc).get("id"));
       }
     }
   }
diff --git a/src/test/org/apache/lucene/analysis/TestKeywordAnalyzer.java b/src/test/org/apache/lucene/analysis/TestKeywordAnalyzer.java
index e225d87..224ecb3 100644
--- a/src/test/org/apache/lucene/analysis/TestKeywordAnalyzer.java
+++ b/src/test/org/apache/lucene/analysis/TestKeywordAnalyzer.java
@@ -17,18 +17,18 @@ package org.apache.lucene.analysis;
  * limitations under the License.
  */
 
-import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.index.TermDocs;
-import org.apache.lucene.store.RAMDirectory;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
+import org.apache.lucene.queryParser.QueryParser;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
-import org.apache.lucene.search.Hits;
-import org.apache.lucene.queryParser.QueryParser;
+import org.apache.lucene.search.ScoreDoc;
+import org.apache.lucene.store.RAMDirectory;
+import org.apache.lucene.util.LuceneTestCase;
 
 public class TestKeywordAnalyzer extends LuceneTestCase {
   
@@ -59,10 +59,10 @@ public class TestKeywordAnalyzer extends LuceneTestCase {
     QueryParser queryParser = new QueryParser("description", analyzer);
     Query query = queryParser.parse("partnum:Q36 AND SPACE");
 
-    Hits hits = searcher.search(query);
+    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
     assertEquals("Q36 kept as-is",
               "+partnum:Q36 +space", query.toString("description"));
-    assertEquals("doc found!", 1, hits.length());
+    assertEquals("doc found!", 1, hits.length);
   }
 
   public void testMutipleDocument() throws Exception {
diff --git a/src/test/org/apache/lucene/document/TestDocument.java b/src/test/org/apache/lucene/document/TestDocument.java
index 95073cc..349efab 100644
--- a/src/test/org/apache/lucene/document/TestDocument.java
+++ b/src/test/org/apache/lucene/document/TestDocument.java
@@ -1,18 +1,15 @@
 package org.apache.lucene.document;
 
-import org.apache.lucene.util.LuceneTestCase;
-
-import org.apache.lucene.store.RAMDirectory;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
 import org.apache.lucene.analysis.standard.StandardAnalyzer;
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.Term;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.Searcher;
-import org.apache.lucene.search.Hits;
+import org.apache.lucene.search.TermQuery;
+import org.apache.lucene.store.RAMDirectory;
+import org.apache.lucene.util.LuceneTestCase;
 
 /**
  * Licensed to the Apache Software Foundation (ASF) under one or more
@@ -170,10 +167,10 @@ public class TestDocument extends LuceneTestCase
 	Query query = new TermQuery(new Term("keyword", "test1"));
 
 	// ensure that queries return expected results without DateFilter first
-        Hits hits = searcher.search(query);
-	assertEquals(1, hits.length());
+        ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+  assertEquals(1, hits.length);
 
-         doAssert(hits.doc(0), true);
+         doAssert(searcher.doc(hits[0].doc), true);
          searcher.close();
     }
 
@@ -244,11 +241,11 @@ public class TestDocument extends LuceneTestCase
       Query query = new TermQuery(new Term("keyword", "test"));
 
       // ensure that queries return expected results without DateFilter first
-      Hits hits = searcher.search(query);
-      assertEquals(3, hits.length());
+      ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+      assertEquals(3, hits.length);
       int result = 0;
       for(int i=0;i<3;i++) {
-        Document doc2 = hits.doc(i);
+        Document doc2 = searcher.doc(hits[i].doc);
         Field f = doc2.getField("id");
         if (f.stringValue().equals("id1"))
           result |= 1;
diff --git a/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java b/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java
index fdae88a..969f4ec 100644
--- a/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java
+++ b/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java
@@ -17,29 +17,27 @@ package org.apache.lucene.index;
  * limitations under the License.
  */
 
-import org.apache.lucene.util.LuceneTestCase;
-
+import java.io.BufferedOutputStream;
+import java.io.File;
+import java.io.FileOutputStream;
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.OutputStream;
 import java.util.Arrays;
-import java.util.List;
 import java.util.Enumeration;
-import java.util.zip.ZipFile;
+import java.util.List;
 import java.util.zip.ZipEntry;
-
-import java.io.OutputStream;
-import java.io.InputStream;
-import java.io.FileOutputStream;
-import java.io.BufferedOutputStream;
-import java.io.IOException;
-import java.io.File;
+import java.util.zip.ZipFile;
 
 import org.apache.lucene.analysis.WhitespaceAnalyzer;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
 import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.TermQuery;
-import org.apache.lucene.search.Hits;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.FSDirectory;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
+import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util._TestUtil;
 
 /*
@@ -180,12 +178,12 @@ public class TestBackwardsCompatibility extends LuceneTestCase
     }
   }
 
-  private void testHits(Hits hits, int expectedCount, IndexReader reader) throws IOException {
-    final int hitCount = hits.length();
+  private void testHits(ScoreDoc[] hits, int expectedCount, IndexReader reader) throws IOException {
+    final int hitCount = hits.length;
     assertEquals("wrong number of hits", expectedCount, hitCount);
     for(int i=0;i<hitCount;i++) {
-      hits.doc(i);
-      reader.getTermFreqVectors(hits.id(i));
+      reader.document(hits[i].doc);
+      reader.getTermFreqVectors(hits[i].doc);
     }
   }
 
@@ -224,11 +222,11 @@ public class TestBackwardsCompatibility extends LuceneTestCase
         assertEquals(7, i);
     }
     
-    Hits hits = searcher.search(new TermQuery(new Term("content", "aaa")));
+    ScoreDoc[] hits = searcher.search(new TermQuery(new Term("content", "aaa")), null, 1000).scoreDocs;
 
     // First document should be #21 since it's norm was
     // increased:
-    Document d = hits.doc(0);
+    Document d = searcher.doc(hits[0].doc);
     assertEquals("didn't get the right document first", "21", d.get("id"));
 
     testHits(hits, 34, searcher.getIndexReader());
@@ -238,12 +236,12 @@ public class TestBackwardsCompatibility extends LuceneTestCase
         !oldName.startsWith("21.") &&
         !oldName.startsWith("22.")) {
       // Test on indices >= 2.3
-      hits = searcher.search(new TermQuery(new Term("utf8", "\u0000")));
-      assertEquals(34, hits.length());
-      hits = searcher.search(new TermQuery(new Term("utf8", "Lu\uD834\uDD1Ece\uD834\uDD60ne")));
-      assertEquals(34, hits.length());
-      hits = searcher.search(new TermQuery(new Term("utf8", "ab\ud917\udc17cd")));
-      assertEquals(34, hits.length());
+      hits = searcher.search(new TermQuery(new Term("utf8", "\u0000")), null, 1000).scoreDocs;
+      assertEquals(34, hits.length);
+      hits = searcher.search(new TermQuery(new Term("utf8", "Lu\uD834\uDD1Ece\uD834\uDD60ne")), null, 1000).scoreDocs;
+      assertEquals(34, hits.length);
+      hits = searcher.search(new TermQuery(new Term("utf8", "ab\ud917\udc17cd")), null, 1000).scoreDocs;
+      assertEquals(34, hits.length);
     }
 
     searcher.close();
@@ -272,8 +270,8 @@ public class TestBackwardsCompatibility extends LuceneTestCase
 
     // make sure searching sees right # hits
     IndexSearcher searcher = new IndexSearcher(dir);
-    Hits hits = searcher.search(new TermQuery(new Term("content", "aaa")));
-    Document d = hits.doc(0);
+    ScoreDoc[] hits = searcher.search(new TermQuery(new Term("content", "aaa")), null, 1000).scoreDocs;
+    Document d = searcher.doc(hits[0].doc);
     assertEquals("wrong first document", "21", d.get("id"));
     testHits(hits, 44, searcher.getIndexReader());
     searcher.close();
@@ -289,9 +287,9 @@ public class TestBackwardsCompatibility extends LuceneTestCase
 
     // make sure they "took":
     searcher = new IndexSearcher(dir);
-    hits = searcher.search(new TermQuery(new Term("content", "aaa")));
-    assertEquals("wrong number of hits", 43, hits.length());
-    d = hits.doc(0);
+    hits = searcher.search(new TermQuery(new Term("content", "aaa")), null, 1000).scoreDocs;
+    assertEquals("wrong number of hits", 43, hits.length);
+    d = searcher.doc(hits[0].doc);
     assertEquals("wrong first document", "22", d.get("id"));
     testHits(hits, 43, searcher.getIndexReader());
     searcher.close();
@@ -302,9 +300,9 @@ public class TestBackwardsCompatibility extends LuceneTestCase
     writer.close();
 
     searcher = new IndexSearcher(dir);
-    hits = searcher.search(new TermQuery(new Term("content", "aaa")));
-    assertEquals("wrong number of hits", 43, hits.length());
-    d = hits.doc(0);
+    hits = searcher.search(new TermQuery(new Term("content", "aaa")), null, 1000).scoreDocs;
+    assertEquals("wrong number of hits", 43, hits.length);
+    d = searcher.doc(hits[0].doc);
     testHits(hits, 43, searcher.getIndexReader());
     assertEquals("wrong first document", "22", d.get("id"));
     searcher.close();
@@ -322,9 +320,9 @@ public class TestBackwardsCompatibility extends LuceneTestCase
 
     // make sure searching sees right # hits
     IndexSearcher searcher = new IndexSearcher(dir);
-    Hits hits = searcher.search(new TermQuery(new Term("content", "aaa")));
-    assertEquals("wrong number of hits", 34, hits.length());
-    Document d = hits.doc(0);
+    ScoreDoc[] hits = searcher.search(new TermQuery(new Term("content", "aaa")), null, 1000).scoreDocs;
+    assertEquals("wrong number of hits", 34, hits.length);
+    Document d = searcher.doc(hits[0].doc);
     assertEquals("wrong first document", "21", d.get("id"));
     searcher.close();
 
@@ -339,9 +337,9 @@ public class TestBackwardsCompatibility extends LuceneTestCase
 
     // make sure they "took":
     searcher = new IndexSearcher(dir);
-    hits = searcher.search(new TermQuery(new Term("content", "aaa")));
-    assertEquals("wrong number of hits", 33, hits.length());
-    d = hits.doc(0);
+    hits = searcher.search(new TermQuery(new Term("content", "aaa")), null, 1000).scoreDocs;
+    assertEquals("wrong number of hits", 33, hits.length);
+    d = searcher.doc(hits[0].doc);
     assertEquals("wrong first document", "22", d.get("id"));
     testHits(hits, 33, searcher.getIndexReader());
     searcher.close();
@@ -352,9 +350,9 @@ public class TestBackwardsCompatibility extends LuceneTestCase
     writer.close();
 
     searcher = new IndexSearcher(dir);
-    hits = searcher.search(new TermQuery(new Term("content", "aaa")));
-    assertEquals("wrong number of hits", 33, hits.length());
-    d = hits.doc(0);
+    hits = searcher.search(new TermQuery(new Term("content", "aaa")), null, 1000).scoreDocs;
+    assertEquals("wrong number of hits", 33, hits.length);
+    d = searcher.doc(hits[0].doc);
     assertEquals("wrong first document", "22", d.get("id"));
     testHits(hits, 33, searcher.getIndexReader());
     searcher.close();
diff --git a/src/test/org/apache/lucene/index/TestDeletionPolicy.java b/src/test/org/apache/lucene/index/TestDeletionPolicy.java
index 0b3dd95..c2473dd 100644
--- a/src/test/org/apache/lucene/index/TestDeletionPolicy.java
+++ b/src/test/org/apache/lucene/index/TestDeletionPolicy.java
@@ -17,23 +17,22 @@ package org.apache.lucene.index;
  * limitations under the License.
  */
 
-import org.apache.lucene.util.LuceneTestCase;
-
 import java.io.IOException;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Set;
 
 import org.apache.lucene.analysis.WhitespaceAnalyzer;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.store.RAMDirectory;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.TermQuery;
-import org.apache.lucene.search.Hits;
-import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
-import java.util.List;
-import java.util.Iterator;
-import java.util.Set;
-import java.util.HashSet;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.ScoreDoc;
+import org.apache.lucene.search.TermQuery;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.store.RAMDirectory;
+import org.apache.lucene.util.LuceneTestCase;
 
 /*
   Verify we can read the pre-2.1 file format, do searches
@@ -440,8 +439,8 @@ public class TestDeletionPolicy extends LuceneTestCase
         reader.deleteDocument(3*i+1);
         reader.setNorm(4*i+1, "content", 2.0F);
         IndexSearcher searcher = new IndexSearcher(reader);
-        Hits hits = searcher.search(query);
-        assertEquals(16*(1+i), hits.length());
+        ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+        assertEquals(16*(1+i), hits.length);
         // this is a commit when autoCommit=false:
         reader.close();
         searcher.close();
@@ -457,8 +456,8 @@ public class TestDeletionPolicy extends LuceneTestCase
         assertEquals(2*(N+2)-1, policy.numOnCommit);
 
       IndexSearcher searcher = new IndexSearcher(dir);
-      Hits hits = searcher.search(query);
-      assertEquals(176, hits.length());
+      ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+      assertEquals(176, hits.length);
 
       // Simplistic check: just verify only the past N segments_N's still
       // exist, and, I can open a reader on each:
@@ -476,7 +475,7 @@ public class TestDeletionPolicy extends LuceneTestCase
           // autoCommit false case:
           if (!autoCommit) {
             searcher = new IndexSearcher(reader);
-            hits = searcher.search(query);
+            hits = searcher.search(query, null, 1000).scoreDocs;
             if (i > 1) {
               if (i % 2 == 0) {
                 expectedCount += 1;
@@ -484,7 +483,7 @@ public class TestDeletionPolicy extends LuceneTestCase
                 expectedCount -= 17;
               }
             }
-            assertEquals(expectedCount, hits.length());
+            assertEquals(expectedCount, hits.length);
             searcher.close();
           }
           reader.close();
@@ -543,8 +542,8 @@ public class TestDeletionPolicy extends LuceneTestCase
         reader.deleteDocument(3);
         reader.setNorm(5, "content", 2.0F);
         IndexSearcher searcher = new IndexSearcher(reader);
-        Hits hits = searcher.search(query);
-        assertEquals(16, hits.length());
+        ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+        assertEquals(16, hits.length);
         // this is a commit when autoCommit=false:
         reader.close();
         searcher.close();
@@ -560,8 +559,8 @@ public class TestDeletionPolicy extends LuceneTestCase
         assertEquals(2*(N+1), policy.numOnCommit);
 
       IndexSearcher searcher = new IndexSearcher(dir);
-      Hits hits = searcher.search(query);
-      assertEquals(0, hits.length());
+      ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+      assertEquals(0, hits.length);
 
       // Simplistic check: just verify only the past N segments_N's still
       // exist, and, I can open a reader on each:
@@ -579,8 +578,8 @@ public class TestDeletionPolicy extends LuceneTestCase
           // autoCommit false case:
           if (!autoCommit) {
             searcher = new IndexSearcher(reader);
-            hits = searcher.search(query);
-            assertEquals(expectedCount, hits.length());
+            hits = searcher.search(query, null, 1000).scoreDocs;
+            assertEquals(expectedCount, hits.length);
             searcher.close();
             if (expectedCount == 0) {
               expectedCount = 16;
diff --git a/src/test/org/apache/lucene/index/TestIndexReader.java b/src/test/org/apache/lucene/index/TestIndexReader.java
index c0f09a9..6b188f1 100644
--- a/src/test/org/apache/lucene/index/TestIndexReader.java
+++ b/src/test/org/apache/lucene/index/TestIndexReader.java
@@ -18,25 +18,35 @@ package org.apache.lucene.index;
  */
 
 
-import org.apache.lucene.util.LuceneTestCase;
+import java.io.File;
+import java.io.FileNotFoundException;
+import java.io.IOException;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.Iterator;
+import java.util.Map;
+import java.util.Set;
+
 import junit.framework.TestSuite;
 import junit.textui.TestRunner;
+
 import org.apache.lucene.analysis.WhitespaceAnalyzer;
 import org.apache.lucene.analysis.standard.StandardAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.index.IndexReader.FieldOption;
-import org.apache.lucene.search.Hits;
 import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.TermQuery;
-import org.apache.lucene.store.*;
+import org.apache.lucene.store.AlreadyClosedException;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.store.FSDirectory;
+import org.apache.lucene.store.LockObtainFailedException;
+import org.apache.lucene.store.MockRAMDirectory;
+import org.apache.lucene.store.RAMDirectory;
+import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util._TestUtil;
 
-import java.io.File;
-import java.io.FileNotFoundException;
-import java.io.IOException;
-import java.util.*;
-
 public class TestIndexReader extends LuceneTestCase
 {
     /** Main for running test case by itself. */
@@ -910,14 +920,14 @@ public class TestIndexReader extends LuceneTestCase
           */
 
           IndexSearcher searcher = new IndexSearcher(newReader);
-          Hits hits = null;
+          ScoreDoc[] hits = null;
           try {
-            hits = searcher.search(new TermQuery(searchTerm));
+            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
           } catch (IOException e) {
             e.printStackTrace();
             fail(testName + ": exception when searching: " + e);
           }
-          int result2 = hits.length();
+          int result2 = hits.length;
           if (success) {
             if (result2 != END_COUNT) {
               fail(testName + ": method did not throw exception but hits.length for search on term 'aaa' is " + result2 + " instead of expected " + END_COUNT);
diff --git a/src/test/org/apache/lucene/index/TestIndexReaderReopen.java b/src/test/org/apache/lucene/index/TestIndexReaderReopen.java
index 62aaed1..6146f76 100644
--- a/src/test/org/apache/lucene/index/TestIndexReaderReopen.java
+++ b/src/test/org/apache/lucene/index/TestIndexReaderReopen.java
@@ -27,6 +27,8 @@ import java.util.List;
 import java.util.Random;
 import java.util.Set;
 
+import junit.framework.TestCase;
+
 import org.apache.lucene.analysis.KeywordAnalyzer;
 import org.apache.lucene.analysis.WhitespaceAnalyzer;
 import org.apache.lucene.analysis.standard.StandardAnalyzer;
@@ -35,16 +37,14 @@ import org.apache.lucene.document.Field;
 import org.apache.lucene.document.Field.Index;
 import org.apache.lucene.document.Field.Store;
 import org.apache.lucene.index.IndexWriter.MaxFieldLength;
-import org.apache.lucene.search.Hits;
 import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.FSDirectory;
 import org.apache.lucene.store.RAMDirectory;
 import org.apache.lucene.util.LuceneTestCase;
 
-import junit.framework.TestCase;
-
 public class TestIndexReaderReopen extends LuceneTestCase {
     
   private File indexDir;
@@ -687,9 +687,11 @@ public class TestIndexReaderReopen extends LuceneTestCase {
                 
                 
                 IndexSearcher searcher = new IndexSearcher(refreshed);
-                Hits hits = searcher.search(new TermQuery(new Term("field1", "a" + rnd.nextInt(refreshed.maxDoc()))));
-                if (hits.length() > 0) {
-                  hits.doc(0);
+                ScoreDoc[] hits = searcher.search(
+                    new TermQuery(new Term("field1", "a" + rnd.nextInt(refreshed.maxDoc()))),
+                    null, 1000).scoreDocs;
+                if (hits.length > 0) {
+                  searcher.doc(hits[0].doc);
                 }
                 
                 // r might have changed because this is not a 
diff --git a/src/test/org/apache/lucene/index/TestIndexWriter.java b/src/test/org/apache/lucene/index/TestIndexWriter.java
index 242fd7e..3a3ceca 100644
--- a/src/test/org/apache/lucene/index/TestIndexWriter.java
+++ b/src/test/org/apache/lucene/index/TestIndexWriter.java
@@ -39,7 +39,7 @@ import org.apache.lucene.analysis.Token;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.Hits;
+import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.spans.SpanTermQuery;
@@ -188,8 +188,8 @@ public class TestIndexWriter extends LuceneTestCase
       assertEquals("first docFreq", 57, reader.docFreq(searchTerm));
 
       IndexSearcher searcher = new IndexSearcher(reader);
-      Hits hits = searcher.search(new TermQuery(searchTerm));
-      assertEquals("first number of hits", 57, hits.length());
+      ScoreDoc[] hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
+      assertEquals("first number of hits", 57, hits.length);
       searcher.close();
       reader.close();
 
@@ -392,12 +392,12 @@ public class TestIndexWriter extends LuceneTestCase
 
             searcher = new IndexSearcher(reader);
             try {
-              hits = searcher.search(new TermQuery(searchTerm));
+              hits = searcher.search(new TermQuery(searchTerm), null, END_COUNT).scoreDocs;
             } catch (IOException e) {
               e.printStackTrace(System.out);
               fail(testName + ": exception when searching: " + e);
             }
-            int result2 = hits.length();
+            int result2 = hits.length;
             if (success) {
               if (result2 != result) {
                 fail(testName + ": method did not throw exception but hits.length for search on term 'aaa' is " + result2 + " instead of expected " + result);
@@ -1016,8 +1016,8 @@ public class TestIndexWriter extends LuceneTestCase
 
         Term searchTerm = new Term("content", "aaa");        
         IndexSearcher searcher = new IndexSearcher(dir);
-        Hits hits = searcher.search(new TermQuery(searchTerm));
-        assertEquals("first number of hits", 14, hits.length());
+        ScoreDoc[] hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
+        assertEquals("first number of hits", 14, hits.length);
         searcher.close();
 
         IndexReader reader = IndexReader.open(dir);
@@ -1028,8 +1028,8 @@ public class TestIndexWriter extends LuceneTestCase
             addDoc(writer);
           }
           searcher = new IndexSearcher(dir);
-          hits = searcher.search(new TermQuery(searchTerm));
-          assertEquals("reader incorrectly sees changes from writer with autoCommit disabled", 14, hits.length());
+          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
+          assertEquals("reader incorrectly sees changes from writer with autoCommit disabled", 14, hits.length);
           searcher.close();
           assertTrue("reader should have still been current", reader.isCurrent());
         }
@@ -1039,8 +1039,8 @@ public class TestIndexWriter extends LuceneTestCase
         assertFalse("reader should not be current now", reader.isCurrent());
 
         searcher = new IndexSearcher(dir);
-        hits = searcher.search(new TermQuery(searchTerm));
-        assertEquals("reader did not see changes after writer was closed", 47, hits.length());
+        hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
+        assertEquals("reader did not see changes after writer was closed", 47, hits.length);
         searcher.close();
     }
 
@@ -1064,8 +1064,8 @@ public class TestIndexWriter extends LuceneTestCase
 
       Term searchTerm = new Term("content", "aaa");        
       IndexSearcher searcher = new IndexSearcher(dir);
-      Hits hits = searcher.search(new TermQuery(searchTerm));
-      assertEquals("first number of hits", 14, hits.length());
+      ScoreDoc[] hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
+      assertEquals("first number of hits", 14, hits.length);
       searcher.close();
 
       writer = new IndexWriter(dir, false, new WhitespaceAnalyzer(), false, IndexWriter.MaxFieldLength.LIMITED);
@@ -1077,8 +1077,8 @@ public class TestIndexWriter extends LuceneTestCase
       writer.deleteDocuments(searchTerm);
 
       searcher = new IndexSearcher(dir);
-      hits = searcher.search(new TermQuery(searchTerm));
-      assertEquals("reader incorrectly sees changes from writer with autoCommit disabled", 14, hits.length());
+      hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
+      assertEquals("reader incorrectly sees changes from writer with autoCommit disabled", 14, hits.length);
       searcher.close();
 
       // Now, close the writer:
@@ -1087,8 +1087,8 @@ public class TestIndexWriter extends LuceneTestCase
       assertNoUnreferencedFiles(dir, "unreferenced files remain after abort()");
 
       searcher = new IndexSearcher(dir);
-      hits = searcher.search(new TermQuery(searchTerm));
-      assertEquals("saw changes after writer.abort", 14, hits.length());
+      hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
+      assertEquals("saw changes after writer.abort", 14, hits.length);
       searcher.close();
           
       // Now make sure we can re-open the index, add docs,
@@ -1105,15 +1105,15 @@ public class TestIndexWriter extends LuceneTestCase
           addDoc(writer);
         }
         searcher = new IndexSearcher(dir);
-        hits = searcher.search(new TermQuery(searchTerm));
-        assertEquals("reader incorrectly sees changes from writer with autoCommit disabled", 14, hits.length());
+        hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
+        assertEquals("reader incorrectly sees changes from writer with autoCommit disabled", 14, hits.length);
         searcher.close();
       }
 
       writer.close();
       searcher = new IndexSearcher(dir);
-      hits = searcher.search(new TermQuery(searchTerm));
-      assertEquals("didn't see changes after close", 218, hits.length());
+      hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
+      assertEquals("didn't see changes after close", 218, hits.length);
       searcher.close();
 
       dir.close();
@@ -1437,8 +1437,8 @@ public class TestIndexWriter extends LuceneTestCase
       writer.close();
 
       IndexSearcher searcher = new IndexSearcher(dir);
-      Hits hits = searcher.search(new TermQuery(new Term("field", "aaa")));
-      assertEquals(300, hits.length());
+      ScoreDoc[] hits = searcher.search(new TermQuery(new Term("field", "aaa")), null, 1000).scoreDocs;
+      assertEquals(300, hits.length);
       searcher.close();
 
       dir.close();
@@ -1463,8 +1463,8 @@ public class TestIndexWriter extends LuceneTestCase
       Term searchTerm = new Term("field", "aaa");
 
       IndexSearcher searcher = new IndexSearcher(dir);
-      Hits hits = searcher.search(new TermQuery(searchTerm));
-      assertEquals(10, hits.length());
+      ScoreDoc[] hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
+      assertEquals(10, hits.length);
       searcher.close();
 
       writer  = new IndexWriter(dir, new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
@@ -1481,8 +1481,8 @@ public class TestIndexWriter extends LuceneTestCase
       }
       writer.close();
       searcher = new IndexSearcher(dir);
-      hits = searcher.search(new TermQuery(searchTerm));
-      assertEquals(27, hits.length());
+      hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
+      assertEquals(27, hits.length);
       searcher.close();
 
       IndexReader reader = IndexReader.open(dir);
@@ -1546,8 +1546,8 @@ public class TestIndexWriter extends LuceneTestCase
       writer.close();
       Term searchTerm = new Term("content", "aaa");        
       IndexSearcher searcher = new IndexSearcher(dir);
-      Hits hits = searcher.search(new TermQuery(searchTerm));
-      assertEquals("did not get right number of hits", 100, hits.length());
+      ScoreDoc[] hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
+      assertEquals("did not get right number of hits", 100, hits.length);
       writer.close();
 
       writer  = new IndexWriter(dir, new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
@@ -3587,12 +3587,12 @@ public class TestIndexWriter extends LuceneTestCase
     pq.add(new Term("field", "a"));
     pq.add(new Term("field", "b"));
     pq.add(new Term("field", "c"));
-    Hits hits = s.search(pq);
-    assertEquals(1, hits.length());
+    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;
+    assertEquals(1, hits.length);
 
     Query q = new SpanTermQuery(new Term("field", "a"));
-    hits = s.search(q);
-    assertEquals(1, hits.length());
+    hits = s.search(q, null, 1000).scoreDocs;
+    assertEquals(1, hits.length);
     TermPositions tps = s.getIndexReader().termPositions(new Term("field", "a"));
     assertTrue(tps.next());
     assertEquals(1, tps.freq());
diff --git a/src/test/org/apache/lucene/index/TestIndexWriterDelete.java b/src/test/org/apache/lucene/index/TestIndexWriterDelete.java
index 85b7dd2..15b3470 100644
--- a/src/test/org/apache/lucene/index/TestIndexWriterDelete.java
+++ b/src/test/org/apache/lucene/index/TestIndexWriterDelete.java
@@ -20,16 +20,15 @@ package org.apache.lucene.index;
 import java.io.IOException;
 import java.util.Arrays;
 
-import org.apache.lucene.util.LuceneTestCase;
-
 import org.apache.lucene.analysis.WhitespaceAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
-import org.apache.lucene.search.Hits;
 import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.MockRAMDirectory;
+import org.apache.lucene.util.LuceneTestCase;
 
 public class TestIndexWriterDelete extends LuceneTestCase {
 
@@ -278,7 +277,7 @@ public class TestIndexWriterDelete extends LuceneTestCase {
 
   private int getHitCount(Directory dir, Term term) throws IOException {
     IndexSearcher searcher = new IndexSearcher(dir);
-    int hitCount = searcher.search(new TermQuery(term)).length();
+    int hitCount = searcher.search(new TermQuery(term), null, 1000).totalHits;
     searcher.close();
     return hitCount;
   }
@@ -434,15 +433,15 @@ public class TestIndexWriterDelete extends LuceneTestCase {
           }
 
           IndexSearcher searcher = new IndexSearcher(newReader);
-          Hits hits = null;
+          ScoreDoc[] hits = null;
           try {
-            hits = searcher.search(new TermQuery(searchTerm));
+            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
           }
           catch (IOException e) {
             e.printStackTrace();
             fail(testName + ": exception when searching: " + e);
           }
-          int result2 = hits.length();
+          int result2 = hits.length;
           if (success) {
             if (x == 0 && result2 != END_COUNT) {
               fail(testName
diff --git a/src/test/org/apache/lucene/index/TestLazyProxSkipping.java b/src/test/org/apache/lucene/index/TestLazyProxSkipping.java
index 0b46b9c..53e37d2 100755
--- a/src/test/org/apache/lucene/index/TestLazyProxSkipping.java
+++ b/src/test/org/apache/lucene/index/TestLazyProxSkipping.java
@@ -22,14 +22,13 @@ import java.io.IOException;
 import org.apache.lucene.analysis.WhitespaceAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
-import org.apache.lucene.search.Hits;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.PhraseQuery;
+import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.Searcher;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.store.RAMDirectory;
-
 import org.apache.lucene.util.LuceneTestCase;
 
 /**
@@ -82,20 +81,20 @@ public class TestLazyProxSkipping extends LuceneTestCase {
         this.searcher = new IndexSearcher(reader);        
     }
     
-    private Hits search() throws IOException {
+    private ScoreDoc[] search() throws IOException {
         // create PhraseQuery "term1 term2" and search
         PhraseQuery pq = new PhraseQuery();
         pq.add(new Term(this.field, this.term1));
         pq.add(new Term(this.field, this.term2));
-        return this.searcher.search(pq);        
+        return this.searcher.search(pq, null, 1000).scoreDocs;        
     }
     
     private void performTest(int numHits) throws IOException {
         createIndex(numHits);
         this.seeksCounter = 0;
-        Hits hits = search();
+        ScoreDoc[] hits = search();
         // verify that the right number of docs was found
-        assertEquals(numHits, hits.length());
+        assertEquals(numHits, hits.length);
         
         // check if the number of calls of seek() does not exceed the number of hits
         assertTrue(this.seeksCounter <= numHits + 1);
diff --git a/src/test/org/apache/lucene/index/TestParallelReader.java b/src/test/org/apache/lucene/index/TestParallelReader.java
index 6034bbb..31637e5 100644
--- a/src/test/org/apache/lucene/index/TestParallelReader.java
+++ b/src/test/org/apache/lucene/index/TestParallelReader.java
@@ -21,22 +21,21 @@ import java.io.IOException;
 import java.util.Arrays;
 import java.util.Collection;
 
-import org.apache.lucene.util.LuceneTestCase;
-
 import org.apache.lucene.analysis.standard.StandardAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.MapFieldSelector;
 import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Hits;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
+import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.Searcher;
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.store.Directory;
-import org.apache.lucene.store.RAMDirectory;
 import org.apache.lucene.store.MockRAMDirectory;
+import org.apache.lucene.store.RAMDirectory;
+import org.apache.lucene.util.LuceneTestCase;
 
 public class TestParallelReader extends LuceneTestCase {
 
@@ -197,13 +196,13 @@ public class TestParallelReader extends LuceneTestCase {
 
   
   private void queryTest(Query query) throws IOException {
-    Hits parallelHits = parallel.search(query);
-    Hits singleHits = single.search(query);
-    assertEquals(parallelHits.length(), singleHits.length());
-    for(int i = 0; i < parallelHits.length(); i++) {
-      assertEquals(parallelHits.score(i), singleHits.score(i), 0.001f);
-      Document docParallel = parallelHits.doc(i);
-      Document docSingle = singleHits.doc(i);
+    ScoreDoc[] parallelHits = parallel.search(query, null, 1000).scoreDocs;
+    ScoreDoc[] singleHits = single.search(query, null, 1000).scoreDocs;
+    assertEquals(parallelHits.length, singleHits.length);
+    for(int i = 0; i < parallelHits.length; i++) {
+      assertEquals(parallelHits[i].score, singleHits[i].score, 0.001f);
+      Document docParallel = parallel.doc(parallelHits[i].doc);
+      Document docSingle = single.doc(singleHits[i].doc);
       assertEquals(docParallel.get("f1"), docSingle.get("f1"));
       assertEquals(docParallel.get("f2"), docSingle.get("f2"));
       assertEquals(docParallel.get("f3"), docSingle.get("f3"));
diff --git a/src/test/org/apache/lucene/queryParser/TestMultiFieldQueryParser.java b/src/test/org/apache/lucene/queryParser/TestMultiFieldQueryParser.java
index f887592..bd09b2c 100644
--- a/src/test/org/apache/lucene/queryParser/TestMultiFieldQueryParser.java
+++ b/src/test/org/apache/lucene/queryParser/TestMultiFieldQueryParser.java
@@ -17,7 +17,10 @@ package org.apache.lucene.queryParser;
  * limitations under the License.
  */
 
-import org.apache.lucene.util.LuceneTestCase;
+import java.io.Reader;
+import java.util.HashMap;
+import java.util.Map;
+
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.Token;
 import org.apache.lucene.analysis.TokenStream;
@@ -26,17 +29,13 @@ import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Hits;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
+import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.RAMDirectory;
-
-import java.io.Reader;
-import java.util.HashMap;
-import java.util.Map;
+import org.apache.lucene.util.LuceneTestCase;
 
 /**
  * Tests QueryParser.
@@ -297,8 +296,8 @@ public class TestMultiFieldQueryParser extends LuceneTestCase {
     mfqp.setDefaultOperator(QueryParser.Operator.AND);
     Query q = mfqp.parse("the footest");
     IndexSearcher is = new IndexSearcher(ramDir);
-    Hits hits = is.search(q);
-    assertEquals(1, hits.length());
+    ScoreDoc[] hits = is.search(q, null, 1000).scoreDocs;
+    assertEquals(1, hits.length);
     is.close();
   }
   
diff --git a/src/test/org/apache/lucene/queryParser/TestQueryParser.java b/src/test/org/apache/lucene/queryParser/TestQueryParser.java
index 4d65fd2..9d04309 100644
--- a/src/test/org/apache/lucene/queryParser/TestQueryParser.java
+++ b/src/test/org/apache/lucene/queryParser/TestQueryParser.java
@@ -17,9 +17,23 @@ package org.apache.lucene.queryParser;
  * limitations under the License.
  */
 
-import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.analysis.*;
+import java.io.IOException;
+import java.io.Reader;
+import java.text.DateFormat;
+import java.util.Calendar;
+import java.util.Date;
+import java.util.Locale;
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.KeywordAnalyzer;
+import org.apache.lucene.analysis.LowerCaseTokenizer;
+import org.apache.lucene.analysis.SimpleAnalyzer;
+import org.apache.lucene.analysis.StopAnalyzer;
+import org.apache.lucene.analysis.StopFilter;
 import org.apache.lucene.analysis.Token;
+import org.apache.lucene.analysis.TokenFilter;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.WhitespaceAnalyzer;
 import org.apache.lucene.analysis.standard.StandardAnalyzer;
 import org.apache.lucene.document.DateField;
 import org.apache.lucene.document.DateTools;
@@ -27,15 +41,20 @@ import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.Term;
-import org.apache.lucene.search.*;
+import org.apache.lucene.search.BooleanQuery;
+import org.apache.lucene.search.ConstantScoreRangeQuery;
+import org.apache.lucene.search.FuzzyQuery;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.MatchAllDocsQuery;
+import org.apache.lucene.search.PhraseQuery;
+import org.apache.lucene.search.PrefixQuery;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.RangeQuery;
+import org.apache.lucene.search.ScoreDoc;
+import org.apache.lucene.search.TermQuery;
+import org.apache.lucene.search.WildcardQuery;
 import org.apache.lucene.store.RAMDirectory;
-
-import java.io.IOException;
-import java.io.Reader;
-import java.text.DateFormat;
-import java.util.Calendar;
-import java.util.Date;
-import java.util.Locale;
+import org.apache.lucene.util.LuceneTestCase;
 
 /**
  * Tests QueryParser.
@@ -887,8 +906,8 @@ public class TestQueryParser extends LuceneTestCase {
     QueryParser qp = new QueryParser("date", new WhitespaceAnalyzer());
     qp.setLocale(Locale.ENGLISH);
     Query q = qp.parse(query);
-    Hits hits = is.search(q);
-    assertEquals(expected, hits.length());
+    ScoreDoc[] hits = is.search(q, null, 1000).scoreDocs;
+    assertEquals(expected, hits.length);
   }
 
   private static void addDateDoc(String content, int year, int month,
diff --git a/src/test/org/apache/lucene/search/CheckHits.java b/src/test/org/apache/lucene/search/CheckHits.java
index 2349d6a..e47bfb9 100644
--- a/src/test/org/apache/lucene/search/CheckHits.java
+++ b/src/test/org/apache/lucene/search/CheckHits.java
@@ -123,7 +123,7 @@ public class CheckHits {
       QueryUtils.check(query,(IndexSearcher)searcher);
     }
 
-    Hits hits = searcher.search(query);
+    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
 
     Set correct = new TreeSet();
     for (int i = 0; i < results.length; i++) {
@@ -131,8 +131,8 @@ public class CheckHits {
     }
 
     Set actual = new TreeSet();
-    for (int i = 0; i < hits.length(); i++) {
-      actual.add(new Integer(hits.id(i)));
+    for (int i = 0; i < hits.length; i++) {
+      actual.add(new Integer(hits[i].doc));
     }
 
     TestCase.assertEquals(query.toString(defaultFieldName), correct, actual);
@@ -141,11 +141,11 @@ public class CheckHits {
   }
 
   /** Tests that a Hits has an expected order of documents */
-  public static void checkDocIds(String mes, int[] results, Hits hits)
+  public static void checkDocIds(String mes, int[] results, ScoreDoc[] hits)
   throws IOException {
-    TestCase.assertEquals(mes + " nr of hits", results.length, hits.length());
+    TestCase.assertEquals(mes + " nr of hits", results.length, hits.length);
     for (int i = 0; i < results.length; i++) {
-      TestCase.assertEquals(mes + " doc nrs for hit " + i, results[i], hits.id(i));
+      TestCase.assertEquals(mes + " doc nrs for hit " + i, results[i], hits[i].doc);
     }
   }
 
@@ -154,8 +154,8 @@ public class CheckHits {
    */
   public static void checkHitsQuery(
         Query query,
-        Hits hits1,
-        Hits hits2,
+        ScoreDoc[] hits1,
+        ScoreDoc[] hits2,
         int[] results)
           throws IOException {
 
@@ -164,33 +164,33 @@ public class CheckHits {
     checkEqual(query, hits1, hits2);
   }
 
-  public static void checkEqual(Query query, Hits hits1, Hits hits2) throws IOException {
+  public static void checkEqual(Query query, ScoreDoc[] hits1, ScoreDoc[] hits2) throws IOException {
      final float scoreTolerance = 1.0e-6f;
-     if (hits1.length() != hits2.length()) {
-       TestCase.fail("Unequal lengths: hits1="+hits1.length()+",hits2="+hits2.length());
+     if (hits1.length != hits2.length) {
+       TestCase.fail("Unequal lengths: hits1="+hits1.length+",hits2="+hits2.length);
      }
-    for (int i = 0; i < hits1.length(); i++) {
-      if (hits1.id(i) != hits2.id(i)) {
+    for (int i = 0; i < hits1.length; i++) {
+      if (hits1[i].doc != hits2[i].doc) {
         TestCase.fail("Hit " + i + " docnumbers don't match\n"
                 + hits2str(hits1, hits2,0,0)
                 + "for query:" + query.toString());
       }
 
-      if ((hits1.id(i) != hits2.id(i))
-          || Math.abs(hits1.score(i) -  hits2.score(i)) > scoreTolerance)
+      if ((hits1[i].doc != hits2[i].doc)
+          || Math.abs(hits1[i].score -  hits2[i].score) > scoreTolerance)
       {
-        TestCase.fail("Hit " + i + ", doc nrs " + hits1.id(i) + " and " + hits2.id(i)
-                      + "\nunequal       : " + hits1.score(i)
-                      + "\n           and: " + hits2.score(i)
+        TestCase.fail("Hit " + i + ", doc nrs " + hits1[i].doc + " and " + hits2[i].doc
+                      + "\nunequal       : " + hits1[i].score
+                      + "\n           and: " + hits2[i].score
                       + "\nfor query:" + query.toString());
       }
     }
   }
 
-  public static String hits2str(Hits hits1, Hits hits2, int start, int end) throws IOException {
+  public static String hits2str(ScoreDoc[] hits1, ScoreDoc[] hits2, int start, int end) throws IOException {
     StringBuffer sb = new StringBuffer();
-    int len1=hits1==null ? 0 : hits1.length();
-    int len2=hits2==null ? 0 : hits2.length();
+    int len1=hits1==null ? 0 : hits1.length;
+    int len2=hits2==null ? 0 : hits2.length;
     if (end<=0) {
       end = Math.max(len1,len2);
     }
@@ -201,13 +201,13 @@ public class CheckHits {
     for (int i=start; i<end; i++) {
         sb.append("hit=").append(i).append(':');
       if (i<len1) {
-          sb.append(" doc").append(hits1.id(i)).append('=').append(hits1.score(i));
+          sb.append(" doc").append(hits1[i].doc).append('=').append(hits1[i].score);
       } else {
         sb.append("               ");
       }
       sb.append(",\t");
       if (i<len2) {
-        sb.append(" doc").append(hits2.id(i)).append('=').append(hits2.score(i));
+        sb.append(" doc").append(hits2[i].doc).append('=').append(hits2[i].score);
       }
       sb.append('\n');
     }
@@ -377,19 +377,6 @@ public class CheckHits {
                    new ExplanationAsserter
                    (q, null, this));
     }
-    public Hits search(Query query, Filter filter) throws IOException {
-      checkExplanations(query);
-      return super.search(query,filter);
-    }
-    public Hits search(Query query, Sort sort) throws IOException {
-      checkExplanations(query);
-      return super.search(query,sort);
-    }
-    public Hits search(Query query, Filter filter,
-                       Sort sort) throws IOException {
-      checkExplanations(query);
-      return super.search(query,filter,sort);
-    }
     public TopFieldDocs search(Query query,
                                Filter filter,
                                int n,
@@ -467,3 +454,4 @@ public class CheckHits {
 
 }
 
+
diff --git a/src/test/org/apache/lucene/search/TestBoolean2.java b/src/test/org/apache/lucene/search/TestBoolean2.java
index 8ed71e7..862c2e1 100644
--- a/src/test/org/apache/lucene/search/TestBoolean2.java
+++ b/src/test/org/apache/lucene/search/TestBoolean2.java
@@ -74,11 +74,11 @@ public class TestBoolean2 extends LuceneTestCase {
     try {
       Query query1 = makeQuery(queryText);
       BooleanQuery.setAllowDocsOutOfOrder(true);
-      Hits hits1 = searcher.search(query1);
+      ScoreDoc[] hits1 = searcher.search(query1, null, 1000).scoreDocs;
 
       Query query2 = makeQuery(queryText); // there should be no need to parse again...
       BooleanQuery.setAllowDocsOutOfOrder(false);
-      Hits hits2 = searcher.search(query2);
+      ScoreDoc[] hits2 = searcher.search(query2, null, 1000).scoreDocs;
 
       CheckHits.checkHitsQuery(query2, hits1, hits2, expDocNrs);
     } finally { // even when a test fails.
@@ -173,13 +173,11 @@ public class TestBoolean2 extends LuceneTestCase {
 
         QueryUtils.check(q1,searcher);
 
-        Hits hits1 = searcher.search(q1,sort);
-        if (hits1.length()>0) hits1.id(hits1.length()-1);
+        ScoreDoc[] hits1 = searcher.search(q1,null, 1000, sort).scoreDocs;
 
         BooleanQuery.setAllowDocsOutOfOrder(true);
-        Hits hits2 = searcher.search(q1,sort);
-        if (hits2.length()>0) hits2.id(hits1.length()-1);
-        tot+=hits2.length();
+        ScoreDoc[] hits2 = searcher.search(q1,null, 1000, sort).scoreDocs;
+        tot+=hits2.length;
         CheckHits.checkEqual(q1, hits1, hits2);
       }
 
diff --git a/src/test/org/apache/lucene/search/TestBooleanMinShouldMatch.java b/src/test/org/apache/lucene/search/TestBooleanMinShouldMatch.java
index fd887a2..6c8f9b2 100644
--- a/src/test/org/apache/lucene/search/TestBooleanMinShouldMatch.java
+++ b/src/test/org/apache/lucene/search/TestBooleanMinShouldMatch.java
@@ -83,11 +83,11 @@ public class TestBooleanMinShouldMatch extends LuceneTestCase {
     }
 
     public void verifyNrHits(Query q, int expected) throws Exception {
-        Hits h = s.search(q);
-        if (expected != h.length()) {
-            printHits(getName(), h);
+        ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
+        if (expected != h.length) {
+            printHits(getName(), h, s);
         }
-        assertEquals("result count", expected, h.length());
+        assertEquals("result count", expected, h.length);
         QueryUtils.check(q,s);
     }
 
@@ -375,15 +375,15 @@ public class TestBooleanMinShouldMatch extends LuceneTestCase {
 
 
 
-    protected void printHits(String test, Hits h) throws Exception {
+    protected void printHits(String test, ScoreDoc[] h, Searcher searcher) throws Exception {
 
         System.err.println("------- " + test + " -------");
 
         DecimalFormat f = new DecimalFormat("0.000000");
 
-        for (int i = 0; i < h.length(); i++) {
-            Document d = h.doc(i);
-            float score = h.score(i);
+        for (int i = 0; i < h.length; i++) {
+            Document d = searcher.doc(h[i].doc);
+            float score = h[i].score;
             System.err.println("#" + i + ": " + f.format(score) + " - " +
                                d.get("id") + " - " + d.get("data"));
         }
diff --git a/src/test/org/apache/lucene/search/TestBooleanOr.java b/src/test/org/apache/lucene/search/TestBooleanOr.java
index 1895aea..3f2e162 100644
--- a/src/test/org/apache/lucene/search/TestBooleanOr.java
+++ b/src/test/org/apache/lucene/search/TestBooleanOr.java
@@ -50,7 +50,7 @@ public class TestBooleanOr extends LuceneTestCase {
 
 	private int search(Query q) throws IOException {
     QueryUtils.check(q,searcher);
-    return searcher.search(q).length();
+    return searcher.search(q, null, 1000).totalHits;
 	}
 
 	public void testElements() throws IOException {
diff --git a/src/test/org/apache/lucene/search/TestBooleanScorer.java b/src/test/org/apache/lucene/search/TestBooleanScorer.java
index 6b1246a..5ae9026 100644
--- a/src/test/org/apache/lucene/search/TestBooleanScorer.java
+++ b/src/test/org/apache/lucene/search/TestBooleanScorer.java
@@ -64,8 +64,8 @@ public class TestBooleanScorer extends LuceneTestCase
       query.add(new TermQuery(new Term(FIELD, "9")), BooleanClause.Occur.MUST_NOT);
 
       IndexSearcher indexSearcher = new IndexSearcher(directory);
-      Hits hits = indexSearcher.search(query);
-      assertEquals("Number of matched documents", 2, hits.length());
+      ScoreDoc[] hits = indexSearcher.search(query, null, 1000).scoreDocs;
+      assertEquals("Number of matched documents", 2, hits.length);
 
     }
     catch (IOException e) {
diff --git a/src/test/org/apache/lucene/search/TestConstantScoreRangeQuery.java b/src/test/org/apache/lucene/search/TestConstantScoreRangeQuery.java
index 5860ce9..0ba6400 100644
--- a/src/test/org/apache/lucene/search/TestConstantScoreRangeQuery.java
+++ b/src/test/org/apache/lucene/search/TestConstantScoreRangeQuery.java
@@ -104,17 +104,17 @@ public class TestConstantScoreRangeQuery extends BaseTestRangeFilter {
         IndexReader reader = IndexReader.open(small);
 	IndexSearcher search = new IndexSearcher(reader);
 
-	Hits result;
+  ScoreDoc[] result;
 
         // some hits match more terms then others, score should be the same
         
-        result = search.search(csrq("data","1","6",T,T));
-        int numHits = result.length();
+        result = search.search(csrq("data","1","6",T,T), null, 1000).scoreDocs;
+        int numHits = result.length;
         assertEquals("wrong number of results", 6, numHits);
-        float score = result.score(0);
+        float score = result[0].score;
         for (int i = 1; i < numHits; i++) {
             assertEquals("score for " + i +" was not the same",
-                         score, result.score(i));
+                         score, result[i].score);
         }
 
     }
@@ -148,10 +148,10 @@ public class TestConstantScoreRangeQuery extends BaseTestRangeFilter {
       bq.add(q1, BooleanClause.Occur.SHOULD);
       bq.add(q2, BooleanClause.Occur.SHOULD);
 
-      Hits hits = search.search(bq);
-      assertEquals(1, hits.id(0));
-      assertEquals(0, hits.id(1));
-      assertTrue(hits.score(0) > hits.score(1));
+      ScoreDoc[] hits = search.search(bq, null, 1000).scoreDocs;
+      assertEquals(1, hits[0].doc);
+      assertEquals(0, hits[1].doc);
+      assertTrue(hits[0].score > hits[1].score);
 
       q1 = csrq("data","A","A",T,T);  // matches document #0
       q1.setBoost(10f);
@@ -160,10 +160,10 @@ public class TestConstantScoreRangeQuery extends BaseTestRangeFilter {
       bq.add(q1, BooleanClause.Occur.SHOULD);
       bq.add(q2, BooleanClause.Occur.SHOULD);
 
-      hits = search.search(bq);
-      assertEquals(0, hits.id(0));
-      assertEquals(1, hits.id(1));
-      assertTrue(hits.score(0) > hits.score(1));
+      hits = search.search(bq, null, 1000).scoreDocs;
+      assertEquals(0, hits[0].doc);
+      assertEquals(1, hits[1].doc);
+      assertTrue(hits[0].score > hits[1].score);
     }
 
     
@@ -178,8 +178,8 @@ public class TestConstantScoreRangeQuery extends BaseTestRangeFilter {
         
         Query rq = new RangeQuery(new Term("data","1"),new Term("data","4"),T);
 
-        Hits expected = search.search(rq);
-        int numHits = expected.length();
+        ScoreDoc[] expected = search.search(rq, null, 1000).scoreDocs;
+        int numHits = expected.length;
 
         // now do a boolean where which also contains a
         // ConstantScoreRangeQuery and make sure hte order is the same
@@ -188,12 +188,12 @@ public class TestConstantScoreRangeQuery extends BaseTestRangeFilter {
         q.add(rq, BooleanClause.Occur.MUST);//T, F);
         q.add(csrq("data","1","6", T, T), BooleanClause.Occur.MUST);//T, F);
 
-        Hits actual = search.search(q);
+        ScoreDoc[] actual = search.search(q, null, 1000).scoreDocs;
 
-        assertEquals("wrong numebr of hits", numHits, actual.length());
+        assertEquals("wrong numebr of hits", numHits, actual.length);
         for (int i = 0; i < numHits; i++) {
             assertEquals("mismatch in docid for hit#"+i,
-                         expected.id(i), actual.id(i));
+                         expected[i].doc, actual[i].doc);
         }
 
     }
@@ -218,69 +218,69 @@ public class TestConstantScoreRangeQuery extends BaseTestRangeFilter {
         
         assertEquals("num of docs", numDocs, 1+ maxId - minId);
         
-	Hits result;
+  ScoreDoc[] result;
 
         // test id, bounded on both ends
         
-	result = search.search(csrq("id",minIP,maxIP,T,T));
-	assertEquals("find all", numDocs, result.length());
+  result = search.search(csrq("id",minIP,maxIP,T,T), null, numDocs).scoreDocs;
+  assertEquals("find all", numDocs, result.length);
 
-	result = search.search(csrq("id",minIP,maxIP,T,F));
-	assertEquals("all but last", numDocs-1, result.length());
+  result = search.search(csrq("id",minIP,maxIP,T,F), null, numDocs).scoreDocs;
+  assertEquals("all but last", numDocs-1, result.length);
 
-	result = search.search(csrq("id",minIP,maxIP,F,T));
-	assertEquals("all but first", numDocs-1, result.length());
+  result = search.search(csrq("id",minIP,maxIP,F,T), null, numDocs).scoreDocs;
+  assertEquals("all but first", numDocs-1, result.length);
         
-	result = search.search(csrq("id",minIP,maxIP,F,F));
-        assertEquals("all but ends", numDocs-2, result.length());
+  result = search.search(csrq("id",minIP,maxIP,F,F), null, numDocs).scoreDocs;
+        assertEquals("all but ends", numDocs-2, result.length);
     
-        result = search.search(csrq("id",medIP,maxIP,T,T));
-        assertEquals("med and up", 1+ maxId-medId, result.length());
+        result = search.search(csrq("id",medIP,maxIP,T,T), null, numDocs).scoreDocs;
+        assertEquals("med and up", 1+ maxId-medId, result.length);
         
-        result = search.search(csrq("id",minIP,medIP,T,T));
-        assertEquals("up to med", 1+ medId-minId, result.length());
+        result = search.search(csrq("id",minIP,medIP,T,T), null, numDocs).scoreDocs;
+        assertEquals("up to med", 1+ medId-minId, result.length);
 
         // unbounded id
 
-	result = search.search(csrq("id",minIP,null,T,F));
-	assertEquals("min and up", numDocs, result.length());
+  result = search.search(csrq("id",minIP,null,T,F), null, numDocs).scoreDocs;
+  assertEquals("min and up", numDocs, result.length);
 
-	result = search.search(csrq("id",null,maxIP,F,T));
-	assertEquals("max and down", numDocs, result.length());
+  result = search.search(csrq("id",null,maxIP,F,T), null, numDocs).scoreDocs;
+  assertEquals("max and down", numDocs, result.length);
 
-	result = search.search(csrq("id",minIP,null,F,F));
-	assertEquals("not min, but up", numDocs-1, result.length());
+  result = search.search(csrq("id",minIP,null,F,F), null, numDocs).scoreDocs;
+  assertEquals("not min, but up", numDocs-1, result.length);
         
-	result = search.search(csrq("id",null,maxIP,F,F));
-	assertEquals("not max, but down", numDocs-1, result.length());
+  result = search.search(csrq("id",null,maxIP,F,F), null, numDocs).scoreDocs;
+  assertEquals("not max, but down", numDocs-1, result.length);
         
-        result = search.search(csrq("id",medIP,maxIP,T,F));
-        assertEquals("med and up, not max", maxId-medId, result.length());
+        result = search.search(csrq("id",medIP,maxIP,T,F), null, numDocs).scoreDocs;
+        assertEquals("med and up, not max", maxId-medId, result.length);
         
-        result = search.search(csrq("id",minIP,medIP,F,T));
-        assertEquals("not min, up to med", medId-minId, result.length());
+        result = search.search(csrq("id",minIP,medIP,F,T), null, numDocs).scoreDocs;
+        assertEquals("not min, up to med", medId-minId, result.length);
 
         // very small sets
 
-	result = search.search(csrq("id",minIP,minIP,F,F));
-	assertEquals("min,min,F,F", 0, result.length());
-	result = search.search(csrq("id",medIP,medIP,F,F));
-	assertEquals("med,med,F,F", 0, result.length());
-	result = search.search(csrq("id",maxIP,maxIP,F,F));
-	assertEquals("max,max,F,F", 0, result.length());
+  result = search.search(csrq("id",minIP,minIP,F,F), null, numDocs).scoreDocs;
+  assertEquals("min,min,F,F", 0, result.length);
+  result = search.search(csrq("id",medIP,medIP,F,F), null, numDocs).scoreDocs;
+  assertEquals("med,med,F,F", 0, result.length);
+  result = search.search(csrq("id",maxIP,maxIP,F,F), null, numDocs).scoreDocs;
+  assertEquals("max,max,F,F", 0, result.length);
                      
-	result = search.search(csrq("id",minIP,minIP,T,T));
-	assertEquals("min,min,T,T", 1, result.length());
-	result = search.search(csrq("id",null,minIP,F,T));
-	assertEquals("nul,min,F,T", 1, result.length());
-
-	result = search.search(csrq("id",maxIP,maxIP,T,T));
-	assertEquals("max,max,T,T", 1, result.length());
-	result = search.search(csrq("id",maxIP,null,T,F));
-	assertEquals("max,nul,T,T", 1, result.length());
-
-	result = search.search(csrq("id",medIP,medIP,T,T));
-	assertEquals("med,med,T,T", 1, result.length());
+  result = search.search(csrq("id",minIP,minIP,T,T), null, numDocs).scoreDocs;
+  assertEquals("min,min,T,T", 1, result.length);
+  result = search.search(csrq("id",null,minIP,F,T), null, numDocs).scoreDocs;
+  assertEquals("nul,min,F,T", 1, result.length);
+
+  result = search.search(csrq("id",maxIP,maxIP,T,T), null, numDocs).scoreDocs;
+  assertEquals("max,max,T,T", 1, result.length);
+  result = search.search(csrq("id",maxIP,null,T,F), null, numDocs).scoreDocs;
+  assertEquals("max,nul,T,T", 1, result.length);
+
+  result = search.search(csrq("id",medIP,medIP,T,T), null, numDocs).scoreDocs;
+  assertEquals("med,med,T,T", 1, result.length);
         
     }
 
@@ -297,53 +297,53 @@ public class TestConstantScoreRangeQuery extends BaseTestRangeFilter {
         
         assertEquals("num of docs", numDocs, 1+ maxId - minId);
         
-	Hits result;
+  ScoreDoc[] result;
         Query q = new TermQuery(new Term("body","body"));
 
         // test extremes, bounded on both ends
         
-	result = search.search(csrq("rand",minRP,maxRP,T,T));
-	assertEquals("find all", numDocs, result.length());
+  result = search.search(csrq("rand",minRP,maxRP,T,T), null, numDocs).scoreDocs;
+  assertEquals("find all", numDocs, result.length);
 
-	result = search.search(csrq("rand",minRP,maxRP,T,F));
-	assertEquals("all but biggest", numDocs-1, result.length());
+  result = search.search(csrq("rand",minRP,maxRP,T,F), null, numDocs).scoreDocs;
+  assertEquals("all but biggest", numDocs-1, result.length);
 
-	result = search.search(csrq("rand",minRP,maxRP,F,T));
-	assertEquals("all but smallest", numDocs-1, result.length());
+  result = search.search(csrq("rand",minRP,maxRP,F,T), null, numDocs).scoreDocs;
+  assertEquals("all but smallest", numDocs-1, result.length);
         
-	result = search.search(csrq("rand",minRP,maxRP,F,F));
-        assertEquals("all but extremes", numDocs-2, result.length());
+  result = search.search(csrq("rand",minRP,maxRP,F,F), null, numDocs).scoreDocs;
+        assertEquals("all but extremes", numDocs-2, result.length);
     
         // unbounded
 
-	result = search.search(csrq("rand",minRP,null,T,F));
-	assertEquals("smallest and up", numDocs, result.length());
+  result = search.search(csrq("rand",minRP,null,T,F), null, numDocs).scoreDocs;
+  assertEquals("smallest and up", numDocs, result.length);
 
-	result = search.search(csrq("rand",null,maxRP,F,T));
-	assertEquals("biggest and down", numDocs, result.length());
+  result = search.search(csrq("rand",null,maxRP,F,T), null, numDocs).scoreDocs;
+  assertEquals("biggest and down", numDocs, result.length);
 
-	result = search.search(csrq("rand",minRP,null,F,F));
-	assertEquals("not smallest, but up", numDocs-1, result.length());
+  result = search.search(csrq("rand",minRP,null,F,F), null, numDocs).scoreDocs;
+  assertEquals("not smallest, but up", numDocs-1, result.length);
         
-	result = search.search(csrq("rand",null,maxRP,F,F));
-	assertEquals("not biggest, but down", numDocs-1, result.length());
+  result = search.search(csrq("rand",null,maxRP,F,F), null, numDocs).scoreDocs;
+  assertEquals("not biggest, but down", numDocs-1, result.length);
         
         // very small sets
 
-	result = search.search(csrq("rand",minRP,minRP,F,F));
-	assertEquals("min,min,F,F", 0, result.length());
-	result = search.search(csrq("rand",maxRP,maxRP,F,F));
-	assertEquals("max,max,F,F", 0, result.length());
+  result = search.search(csrq("rand",minRP,minRP,F,F), null, numDocs).scoreDocs;
+  assertEquals("min,min,F,F", 0, result.length);
+  result = search.search(csrq("rand",maxRP,maxRP,F,F), null, numDocs).scoreDocs;
+  assertEquals("max,max,F,F", 0, result.length);
                      
-	result = search.search(csrq("rand",minRP,minRP,T,T));
-	assertEquals("min,min,T,T", 1, result.length());
-	result = search.search(csrq("rand",null,minRP,F,T));
-	assertEquals("nul,min,F,T", 1, result.length());
-
-	result = search.search(csrq("rand",maxRP,maxRP,T,T));
-	assertEquals("max,max,T,T", 1, result.length());
-	result = search.search(csrq("rand",maxRP,null,T,F));
-	assertEquals("max,nul,T,T", 1, result.length());
+  result = search.search(csrq("rand",minRP,minRP,T,T), null, numDocs).scoreDocs;
+  assertEquals("min,min,T,T", 1, result.length);
+  result = search.search(csrq("rand",null,minRP,F,T), null, numDocs).scoreDocs;
+  assertEquals("nul,min,F,T", 1, result.length);
+
+  result = search.search(csrq("rand",maxRP,maxRP,T,T), null, numDocs).scoreDocs;
+  assertEquals("max,max,T,T", 1, result.length);
+  result = search.search(csrq("rand",maxRP,null,T,F), null, numDocs).scoreDocs;
+  assertEquals("max,nul,T,T", 1, result.length);
         
     }
 
diff --git a/src/test/org/apache/lucene/search/TestCustomSearcherSort.java b/src/test/org/apache/lucene/search/TestCustomSearcherSort.java
index 275dfa7..e2472b3 100644
--- a/src/test/org/apache/lucene/search/TestCustomSearcherSort.java
+++ b/src/test/org/apache/lucene/search/TestCustomSearcherSort.java
@@ -151,24 +151,24 @@ implements Serializable {
 	private void matchHits (Searcher searcher, Sort sort)
 	throws IOException {
 	    // make a query without sorting first
-		Hits hitsByRank = searcher.search(query);
+    ScoreDoc[] hitsByRank = searcher.search(query, null, 1000).scoreDocs;
 		checkHits(hitsByRank, "Sort by rank: "); // check for duplicates
         Map resultMap = new TreeMap();
         // store hits in TreeMap - TreeMap does not allow duplicates; existing entries are silently overwritten
-        for(int hitid=0;hitid<hitsByRank.length(); ++hitid) {
+        for(int hitid=0;hitid<hitsByRank.length; ++hitid) {
             resultMap.put(
-                    new Integer(hitsByRank.id(hitid)),  // Key:   Lucene Document ID
+                    new Integer(hitsByRank[hitid].doc),  // Key:   Lucene Document ID
                     new Integer(hitid));				// Value: Hits-Objekt Index
         }
         
         // now make a query using the sort criteria
-		Hits resultSort = searcher.search (query, sort);
+    ScoreDoc[] resultSort = searcher.search (query, null, 1000, sort).scoreDocs;
 		checkHits(resultSort, "Sort by custom criteria: "); // check for duplicates
 		
         String lf = System.getProperty("line.separator", "\n");
         // besides the sorting both sets of hits must be identical
-        for(int hitid=0;hitid<resultSort.length(); ++hitid) {
-            Integer idHitDate = new Integer(resultSort.id(hitid)); // document ID from sorted search
+        for(int hitid=0;hitid<resultSort.length; ++hitid) {
+            Integer idHitDate = new Integer(resultSort[hitid].doc); // document ID from sorted search
             if(!resultMap.containsKey(idHitDate)) {
                 log("ID "+idHitDate+" not found. Possibliy a duplicate.");
             }
@@ -189,33 +189,24 @@ implements Serializable {
 	 * Check the hits for duplicates.
 	 * @param hits
 	 */
-    private void checkHits(Hits hits, String prefix) {
+    private void checkHits(ScoreDoc[] hits, String prefix) {
         if(hits!=null) {
             Map idMap = new TreeMap();
-            for(int docnum=0;docnum<hits.length();++docnum) {
+            for(int docnum=0;docnum<hits.length;++docnum) {
                 Integer luceneId = null;
-                try {
-                    luceneId = new Integer(hits.id(docnum));
-                    if(idMap.containsKey(luceneId)) {
-                        StringBuffer message = new StringBuffer(prefix);
-                        message.append("Duplicate key for hit index = ");
-                        message.append(docnum);
-                        message.append(", previous index = ");
-                        message.append(((Integer)idMap.get(luceneId)).toString());
-                        message.append(", Lucene ID = ");
-                        message.append(luceneId);
-                        log(message.toString());
-                    } else { 
-                        idMap.put(luceneId, new Integer(docnum));
-                    }
-                } catch(IOException ioe) {
+
+                luceneId = new Integer(hits[docnum].doc);
+                if(idMap.containsKey(luceneId)) {
                     StringBuffer message = new StringBuffer(prefix);
-                    message.append("Error occurred for hit index = ");
+                    message.append("Duplicate key for hit index = ");
                     message.append(docnum);
-                    message.append(" (");
-                    message.append(ioe.getMessage());
-                    message.append(")");
+                    message.append(", previous index = ");
+                    message.append(((Integer)idMap.get(luceneId)).toString());
+                    message.append(", Lucene ID = ");
+                    message.append(luceneId);
                     log(message.toString());
+                } else { 
+                    idMap.put(luceneId, new Integer(docnum));
                 }
             }
         }
diff --git a/src/test/org/apache/lucene/search/TestDateFilter.java b/src/test/org/apache/lucene/search/TestDateFilter.java
index 9fdf0a3..35b807b 100644
--- a/src/test/org/apache/lucene/search/TestDateFilter.java
+++ b/src/test/org/apache/lucene/search/TestDateFilter.java
@@ -79,28 +79,28 @@ public class TestDateFilter
 	// search for something that does exists
 	Query query2 = new TermQuery(new Term("body", "sunny"));
 
-	Hits result;
+  ScoreDoc[] result;
 
 	// ensure that queries return expected results without DateFilter first
-	result = searcher.search(query1);
-	assertEquals(0, result.length());
+  result = searcher.search(query1, null, 1000).scoreDocs;
+  assertEquals(0, result.length);
 
-	result = searcher.search(query2);
-	assertEquals(1, result.length());
+  result = searcher.search(query2, null, 1000).scoreDocs;
+  assertEquals(1, result.length);
 
 
 	// run queries with DateFilter
-	result = searcher.search(query1, df1);
-	assertEquals(0, result.length());
+  result = searcher.search(query1, df1, 1000).scoreDocs;
+  assertEquals(0, result.length);
 
-	result = searcher.search(query1, df2);
-	assertEquals(0, result.length());
+  result = searcher.search(query1, df2, 1000).scoreDocs;
+  assertEquals(0, result.length);
 
- 	result = searcher.search(query2, df1);
- 	assertEquals(1, result.length());
+   result = searcher.search(query2, df1, 1000).scoreDocs;
+   assertEquals(1, result.length);
 
-	result = searcher.search(query2, df2);
-	assertEquals(0, result.length());
+  result = searcher.search(query2, df2, 1000).scoreDocs;
+  assertEquals(0, result.length);
     }
 
     /**
@@ -140,27 +140,27 @@ public class TestDateFilter
 	// search for something that does exists
 	Query query2 = new TermQuery(new Term("body", "sunny"));
 
-	Hits result;
+  ScoreDoc[] result;
 
 	// ensure that queries return expected results without DateFilter first
-	result = searcher.search(query1);
-	assertEquals(0, result.length());
+  result = searcher.search(query1, null, 1000).scoreDocs;
+  assertEquals(0, result.length);
 
-	result = searcher.search(query2);
-	assertEquals(1, result.length());
+  result = searcher.search(query2, null, 1000).scoreDocs;
+  assertEquals(1, result.length);
 
 
 	// run queries with DateFilter
-	result = searcher.search(query1, df1);
-	assertEquals(0, result.length());
+  result = searcher.search(query1, df1, 1000).scoreDocs;
+  assertEquals(0, result.length);
 
-	result = searcher.search(query1, df2);
-	assertEquals(0, result.length());
+  result = searcher.search(query1, df2, 1000).scoreDocs;
+  assertEquals(0, result.length);
 
- 	result = searcher.search(query2, df1);
- 	assertEquals(1, result.length());
+   result = searcher.search(query2, df1, 1000).scoreDocs;
+   assertEquals(1, result.length);
 
-	result = searcher.search(query2, df2);
-	assertEquals(0, result.length());
+  result = searcher.search(query2, df2, 1000).scoreDocs;
+  assertEquals(0, result.length);
     }
 }
diff --git a/src/test/org/apache/lucene/search/TestDateSort.java b/src/test/org/apache/lucene/search/TestDateSort.java
index 4879541..cfe15a2 100644
--- a/src/test/org/apache/lucene/search/TestDateSort.java
+++ b/src/test/org/apache/lucene/search/TestDateSort.java
@@ -27,7 +27,6 @@ import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.queryParser.QueryParser;
-import org.apache.lucene.search.Hits;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.Sort;
@@ -81,9 +80,9 @@ public class TestDateSort extends TestCase {
 
     // Execute the search and process the search results.
     String[] actualOrder = new String[5];
-    Hits hits = searcher.search(query, sort);
-    for (int i = 0; i < hits.length(); i++) {
-      Document document = hits.doc(i);
+    ScoreDoc[] hits = searcher.search(query, null, 1000, sort).scoreDocs;
+    for (int i = 0; i < hits.length; i++) {
+      Document document = searcher.doc(hits[i].doc);
       String text = document.get(TEXT_FIELD);
       actualOrder[i] = text;
     }
diff --git a/src/test/org/apache/lucene/search/TestDisjunctionMaxQuery.java b/src/test/org/apache/lucene/search/TestDisjunctionMaxQuery.java
index 0138485..a89e9aa 100644
--- a/src/test/org/apache/lucene/search/TestDisjunctionMaxQuery.java
+++ b/src/test/org/apache/lucene/search/TestDisjunctionMaxQuery.java
@@ -166,19 +166,19 @@ public class TestDisjunctionMaxQuery extends LuceneTestCase{
         q.add(tq("hed","elephant"));
         QueryUtils.check(q,s);
 
-        Hits h = s.search(q);
+        ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
 
         try {
             assertEquals("all docs should match " + q.toString(),
-                         4, h.length());
+                         4, h.length);
 
-            float score = h.score(0);
-            for (int i = 1; i < h.length(); i++) {
+            float score = h[0].score;
+            for (int i = 1; i < h.length; i++) {
                 assertEquals("score #" + i + " is not the same",
-                             score, h.score(i), SCORE_COMP_THRESH);
+                             score, h[i].score, SCORE_COMP_THRESH);
             }
         } catch (Error e) {
-            printHits("testSimpleEqualScores1",h);
+            printHits("testSimpleEqualScores1",h,s);
             throw e;
         }
 
@@ -193,18 +193,18 @@ public class TestDisjunctionMaxQuery extends LuceneTestCase{
         QueryUtils.check(q,s);
 
 
-        Hits h = s.search(q);
+        ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
 
         try {
             assertEquals("3 docs should match " + q.toString(),
-                         3, h.length());
-            float score = h.score(0);
-            for (int i = 1; i < h.length(); i++) {
+                         3, h.length);
+            float score = h[0].score;
+            for (int i = 1; i < h.length; i++) {
                 assertEquals("score #" + i + " is not the same",
-                             score, h.score(i), SCORE_COMP_THRESH);
+                             score, h[i].score, SCORE_COMP_THRESH);
             }
         } catch (Error e) {
-            printHits("testSimpleEqualScores2",h);
+            printHits("testSimpleEqualScores2",h, s);
             throw e;
         }
 
@@ -220,18 +220,18 @@ public class TestDisjunctionMaxQuery extends LuceneTestCase{
         QueryUtils.check(q,s);
 
 
-        Hits h = s.search(q);
+        ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
 
         try {
             assertEquals("all docs should match " + q.toString(),
-                         4, h.length());
-            float score = h.score(0);
-            for (int i = 1; i < h.length(); i++) {
+                         4, h.length);
+            float score = h[0].score;
+            for (int i = 1; i < h.length; i++) {
                 assertEquals("score #" + i + " is not the same",
-                             score, h.score(i), SCORE_COMP_THRESH);
+                             score, h[i].score, SCORE_COMP_THRESH);
             }
         } catch (Error e) {
-            printHits("testSimpleEqualScores3",h);
+            printHits("testSimpleEqualScores3",h, s);
             throw e;
         }
 
@@ -245,22 +245,22 @@ public class TestDisjunctionMaxQuery extends LuceneTestCase{
         QueryUtils.check(q,s);
 
 
-        Hits h = s.search(q);
+        ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
 
         try {
             assertEquals("3 docs should match " + q.toString(),
-                         3, h.length());
-            assertEquals("wrong first",  "d2", h.doc(0).get("id"));
-            float score0 = h.score(0);
-            float score1 = h.score(1);
-            float score2 = h.score(2);
+                         3, h.length);
+            assertEquals("wrong first",  "d2", s.doc(h[0].doc).get("id"));
+            float score0 = h[0].score;
+            float score1 = h[1].score;
+            float score2 = h[2].score;
             assertTrue("d2 does not have better score then others: " +
                        score0 + " >? " + score1,
                        score0 > score1);
             assertEquals("d4 and d1 don't have equal scores",
                          score1, score2, SCORE_COMP_THRESH);
         } catch (Error e) {
-            printHits("testSimpleTiebreaker",h);
+            printHits("testSimpleTiebreaker",h, s);
             throw e;
         }
     }
@@ -286,18 +286,18 @@ public class TestDisjunctionMaxQuery extends LuceneTestCase{
 
         QueryUtils.check(q,s);
 
-        Hits h = s.search(q);
+        ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
 
         try {
             assertEquals("3 docs should match " + q.toString(),
-                         3, h.length());
-            float score = h.score(0);
-            for (int i = 1; i < h.length(); i++) {
+                         3, h.length);
+            float score = h[0].score;
+            for (int i = 1; i < h.length; i++) {
                 assertEquals("score #" + i + " is not the same",
-                             score, h.score(i), SCORE_COMP_THRESH);
+                             score, h[i].score, SCORE_COMP_THRESH);
             }
         } catch (Error e) {
-            printHits("testBooleanRequiredEqualScores1",h);
+            printHits("testBooleanRequiredEqualScores1",h, s);
             throw e;
         }
     }
@@ -321,23 +321,23 @@ public class TestDisjunctionMaxQuery extends LuceneTestCase{
         QueryUtils.check(q,s);
 
 
-        Hits h = s.search(q);
+        ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
 
         try {
             assertEquals("4 docs should match " + q.toString(),
-                         4, h.length());
-            float score = h.score(0);
-            for (int i = 1; i < h.length()-1; i++) { /* note: -1 */
+                         4, h.length);
+            float score = h[0].score;
+            for (int i = 1; i < h.length-1; i++) { /* note: -1 */
                 assertEquals("score #" + i + " is not the same",
-                             score, h.score(i), SCORE_COMP_THRESH);
+                             score, h[i].score, SCORE_COMP_THRESH);
             }
-            assertEquals("wrong last", "d1", h.doc(h.length()-1).get("id"));
-            float score1 = h.score(h.length()-1);
+            assertEquals("wrong last", "d1", s.doc(h[h.length-1].doc).get("id"));
+            float score1 = h[h.length-1].score;
             assertTrue("d1 does not have worse score then others: " +
                        score + " >? " + score1,
                        score > score1);
         } catch (Error e) {
-            printHits("testBooleanOptionalNoTiebreaker",h);
+            printHits("testBooleanOptionalNoTiebreaker",h, s);
             throw e;
         }
     }
@@ -361,22 +361,22 @@ public class TestDisjunctionMaxQuery extends LuceneTestCase{
         QueryUtils.check(q,s);
 
 
-        Hits h = s.search(q);
+        ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
 
         try {
 
             assertEquals("4 docs should match " + q.toString(),
-                         4, h.length());
+                         4, h.length);
 
-            float score0 = h.score(0);
-            float score1 = h.score(1);
-            float score2 = h.score(2);
-            float score3 = h.score(3);
+            float score0 = h[0].score;
+            float score1 = h[1].score;
+            float score2 = h[2].score;
+            float score3 = h[3].score;
 
-            String doc0 = h.doc(0).get("id");
-            String doc1 = h.doc(1).get("id");
-            String doc2 = h.doc(2).get("id");
-            String doc3 = h.doc(3).get("id");
+            String doc0 = s.doc(h[0].doc).get("id");
+            String doc1 = s.doc(h[1].doc).get("id");
+            String doc2 = s.doc(h[2].doc).get("id");
+            String doc3 = s.doc(h[3].doc).get("id");            
 
             assertTrue("doc0 should be d2 or d4: " + doc0,
                        doc0.equals("d2") || doc0.equals("d4"));
@@ -395,7 +395,7 @@ public class TestDisjunctionMaxQuery extends LuceneTestCase{
                        score2 > score3);
 
         } catch (Error e) {
-            printHits("testBooleanOptionalWithTiebreaker",h);
+            printHits("testBooleanOptionalWithTiebreaker",h, s);
             throw e;
         }
 
@@ -420,22 +420,22 @@ public class TestDisjunctionMaxQuery extends LuceneTestCase{
         QueryUtils.check(q,s);
 
 
-        Hits h = s.search(q);
+        ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
 
         try {
 
             assertEquals("4 docs should match " + q.toString(),
-                         4, h.length());
+                         4, h.length);
 
-            float score0 = h.score(0);
-            float score1 = h.score(1);
-            float score2 = h.score(2);
-            float score3 = h.score(3);
+            float score0 = h[0].score;
+            float score1 = h[1].score;
+            float score2 = h[2].score;
+            float score3 = h[3].score;
 
-            String doc0 = h.doc(0).get("id");
-            String doc1 = h.doc(1).get("id");
-            String doc2 = h.doc(2).get("id");
-            String doc3 = h.doc(3).get("id");
+            String doc0 = s.doc(h[0].doc).get("id");
+            String doc1 = s.doc(h[1].doc).get("id");
+            String doc2 = s.doc(h[2].doc).get("id");
+            String doc3 = s.doc(h[3].doc).get("id");            
 
             assertEquals("doc0 should be d4: ", "d4", doc0);
             assertEquals("doc1 should be d3: ", "d3", doc1);
@@ -453,7 +453,7 @@ public class TestDisjunctionMaxQuery extends LuceneTestCase{
                        score2 > score3);
 
         } catch (Error e) {
-            printHits("testBooleanOptionalWithTiebreakerAndBoost",h);
+            printHits("testBooleanOptionalWithTiebreakerAndBoost",h, s);
             throw e;
         }
     }
@@ -476,15 +476,15 @@ public class TestDisjunctionMaxQuery extends LuceneTestCase{
     }
 
 
-    protected void printHits(String test, Hits h) throws Exception {
+    protected void printHits(String test, ScoreDoc[] h, Searcher searcher) throws Exception {
 
         System.err.println("------- " + test + " -------");
 
         DecimalFormat f = new DecimalFormat("0.000000000");
 
-        for (int i = 0; i < h.length(); i++) {
-            Document d = h.doc(i);
-            float score = h.score(i);
+        for (int i = 0; i < h.length; i++) {
+            Document d = searcher.doc(h[i].doc);
+            float score = h[i].score;
             System.err.println("#" + i + ": " + f.format(score) + " - " +
                                d.get("id"));
         }
diff --git a/src/test/org/apache/lucene/search/TestFilteredQuery.java b/src/test/org/apache/lucene/search/TestFilteredQuery.java
index 669f56d..bdcdd57 100644
--- a/src/test/org/apache/lucene/search/TestFilteredQuery.java
+++ b/src/test/org/apache/lucene/search/TestFilteredQuery.java
@@ -101,29 +101,29 @@ extends LuceneTestCase {
   public void testFilteredQuery()
   throws Exception {
     Query filteredquery = new FilteredQuery (query, filter);
-    Hits hits = searcher.search (filteredquery);
-    assertEquals (1, hits.length());
-    assertEquals (1, hits.id(0));
+    ScoreDoc[] hits = searcher.search (filteredquery, null, 1000).scoreDocs;
+    assertEquals (1, hits.length);
+    assertEquals (1, hits[0].doc);
     QueryUtils.check(filteredquery,searcher);
 
-    hits = searcher.search (filteredquery, new Sort("sorter"));
-    assertEquals (1, hits.length());
-    assertEquals (1, hits.id(0));
+    hits = searcher.search (filteredquery, null, 1000, new Sort("sorter")).scoreDocs;
+    assertEquals (1, hits.length);
+    assertEquals (1, hits[0].doc);
 
     filteredquery = new FilteredQuery (new TermQuery (new Term ("field", "one")), filter);
-    hits = searcher.search (filteredquery);
-    assertEquals (2, hits.length());
+    hits = searcher.search (filteredquery, null, 1000).scoreDocs;
+    assertEquals (2, hits.length);
     QueryUtils.check(filteredquery,searcher);
 
     filteredquery = new FilteredQuery (new TermQuery (new Term ("field", "x")), filter);
-    hits = searcher.search (filteredquery);
-    assertEquals (1, hits.length());
-    assertEquals (3, hits.id(0));
+    hits = searcher.search (filteredquery, null, 1000).scoreDocs;
+    assertEquals (1, hits.length);
+    assertEquals (3, hits[0].doc);
     QueryUtils.check(filteredquery,searcher);
 
     filteredquery = new FilteredQuery (new TermQuery (new Term ("field", "y")), filter);
-    hits = searcher.search (filteredquery);
-    assertEquals (0, hits.length());
+    hits = searcher.search (filteredquery, null, 1000).scoreDocs;
+    assertEquals (0, hits.length);
     QueryUtils.check(filteredquery,searcher);
     
     // test boost
@@ -163,13 +163,13 @@ extends LuceneTestCase {
    * Tests whether the scores of the two queries are the same.
    */
   public void assertScoreEquals(Query q1, Query q2) throws Exception {
-    Hits hits1 = searcher.search (q1);
-    Hits hits2 = searcher.search (q2);
+    ScoreDoc[] hits1 = searcher.search (q1, null, 1000).scoreDocs;
+    ScoreDoc[] hits2 = searcher.search (q2, null, 1000).scoreDocs;
       
-    assertEquals(hits1.length(), hits2.length());
+    assertEquals(hits1.length, hits2.length);
     
-    for (int i = 0; i < hits1.length(); i++) {
-      assertEquals(hits1.score(i), hits2.score(i), 0.0000001f);
+    for (int i = 0; i < hits1.length; i++) {
+      assertEquals(hits1[i].score, hits2[i].score, 0.0000001f);
     }
   }
 
@@ -181,8 +181,8 @@ extends LuceneTestCase {
         new Term("sorter", "b"), new Term("sorter", "d"), true);
 
     Query filteredquery = new FilteredQuery(rq, filter);
-    Hits hits = searcher.search(filteredquery);
-    assertEquals(2, hits.length());
+    ScoreDoc[] hits = searcher.search(filteredquery, null, 1000).scoreDocs;
+    assertEquals(2, hits.length);
     QueryUtils.check(filteredquery,searcher);
   }
 
@@ -194,11 +194,12 @@ extends LuceneTestCase {
     query = new FilteredQuery(new MatchAllDocsQuery(),
         new SingleDocTestFilter(1));
     bq.add(query, BooleanClause.Occur.MUST);
-    Hits hits = searcher.search(bq);
-    assertEquals(0, hits.length());
+    ScoreDoc[] hits = searcher.search(bq, null, 1000).scoreDocs;
+    assertEquals(0, hits.length);
     QueryUtils.check(query,searcher);    
   }
 }
 
 
 
+
diff --git a/src/test/org/apache/lucene/search/TestFilteredSearch.java b/src/test/org/apache/lucene/search/TestFilteredSearch.java
index 534a9d3..99ec220 100644
--- a/src/test/org/apache/lucene/search/TestFilteredSearch.java
+++ b/src/test/org/apache/lucene/search/TestFilteredSearch.java
@@ -63,8 +63,8 @@ public class TestFilteredSearch extends TestCase
      
      
       IndexSearcher indexSearcher = new IndexSearcher(directory);
-      org.apache.lucene.search.Hits hits = indexSearcher.search(booleanQuery, filter);
-      assertEquals("Number of matched documents", 1, hits.length());
+      ScoreDoc[] hits = indexSearcher.search(booleanQuery, filter, 1000).scoreDocs;
+      assertEquals("Number of matched documents", 1, hits.length);
 
     }
     catch (IOException e) {
diff --git a/src/test/org/apache/lucene/search/TestFuzzyQuery.java b/src/test/org/apache/lucene/search/TestFuzzyQuery.java
index e443818..e85a502 100644
--- a/src/test/org/apache/lucene/search/TestFuzzyQuery.java
+++ b/src/test/org/apache/lucene/search/TestFuzzyQuery.java
@@ -49,114 +49,114 @@ public class TestFuzzyQuery extends LuceneTestCase {
     IndexSearcher searcher = new IndexSearcher(directory);
 
     FuzzyQuery query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMinSimilarity, 0);   
-    Hits hits = searcher.search(query);
-    assertEquals(3, hits.length());
+    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(3, hits.length);
     
     // same with prefix
     query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMinSimilarity, 1);   
-    hits = searcher.search(query);
-    assertEquals(3, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(3, hits.length);
     query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMinSimilarity, 2);   
-    hits = searcher.search(query);
-    assertEquals(3, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(3, hits.length);
     query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMinSimilarity, 3);   
-    hits = searcher.search(query);
-    assertEquals(3, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(3, hits.length);
     query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMinSimilarity, 4);   
-    hits = searcher.search(query);
-    assertEquals(2, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(2, hits.length);
     query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMinSimilarity, 5);   
-    hits = searcher.search(query);
-    assertEquals(1, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(1, hits.length);
     query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMinSimilarity, 6);   
-    hits = searcher.search(query);
-    assertEquals(1, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(1, hits.length);
 
     // not similar enough:
     query = new FuzzyQuery(new Term("field", "xxxxx"), FuzzyQuery.defaultMinSimilarity, 0);  	
-    hits = searcher.search(query);
-    assertEquals(0, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(0, hits.length);
     query = new FuzzyQuery(new Term("field", "aaccc"), FuzzyQuery.defaultMinSimilarity, 0);   // edit distance to "aaaaa" = 3
-    hits = searcher.search(query);
-    assertEquals(0, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(0, hits.length);
 
     // query identical to a word in the index:
     query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMinSimilarity, 0);   
-    hits = searcher.search(query);
-    assertEquals(3, hits.length());
-    assertEquals(hits.doc(0).get("field"), ("aaaaa"));
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(3, hits.length);
+    assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaa"));
     // default allows for up to two edits:
-    assertEquals(hits.doc(1).get("field"), ("aaaab"));
-    assertEquals(hits.doc(2).get("field"), ("aaabb"));
+    assertEquals(searcher.doc(hits[1].doc).get("field"), ("aaaab"));
+    assertEquals(searcher.doc(hits[2].doc).get("field"), ("aaabb"));
 
     // query similar to a word in the index:
     query = new FuzzyQuery(new Term("field", "aaaac"), FuzzyQuery.defaultMinSimilarity, 0);   
-    hits = searcher.search(query);
-    assertEquals(3, hits.length());
-    assertEquals(hits.doc(0).get("field"), ("aaaaa"));
-    assertEquals(hits.doc(1).get("field"), ("aaaab"));
-    assertEquals(hits.doc(2).get("field"), ("aaabb"));
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(3, hits.length);
+    assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaa"));
+    assertEquals(searcher.doc(hits[1].doc).get("field"), ("aaaab"));
+    assertEquals(searcher.doc(hits[2].doc).get("field"), ("aaabb"));
     
     // now with prefix
     query = new FuzzyQuery(new Term("field", "aaaac"), FuzzyQuery.defaultMinSimilarity, 1);   
-    hits = searcher.search(query);
-    assertEquals(3, hits.length());
-    assertEquals(hits.doc(0).get("field"), ("aaaaa"));
-    assertEquals(hits.doc(1).get("field"), ("aaaab"));
-    assertEquals(hits.doc(2).get("field"), ("aaabb"));
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(3, hits.length);
+    assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaa"));
+    assertEquals(searcher.doc(hits[1].doc).get("field"), ("aaaab"));
+    assertEquals(searcher.doc(hits[2].doc).get("field"), ("aaabb"));
     query = new FuzzyQuery(new Term("field", "aaaac"), FuzzyQuery.defaultMinSimilarity, 2);   
-    hits = searcher.search(query);
-    assertEquals(3, hits.length());
-    assertEquals(hits.doc(0).get("field"), ("aaaaa"));
-    assertEquals(hits.doc(1).get("field"), ("aaaab"));
-    assertEquals(hits.doc(2).get("field"), ("aaabb"));
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(3, hits.length);
+    assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaa"));
+    assertEquals(searcher.doc(hits[1].doc).get("field"), ("aaaab"));
+    assertEquals(searcher.doc(hits[2].doc).get("field"), ("aaabb"));
     query = new FuzzyQuery(new Term("field", "aaaac"), FuzzyQuery.defaultMinSimilarity, 3);   
-    hits = searcher.search(query);
-    assertEquals(3, hits.length());
-    assertEquals(hits.doc(0).get("field"), ("aaaaa"));
-    assertEquals(hits.doc(1).get("field"), ("aaaab"));
-    assertEquals(hits.doc(2).get("field"), ("aaabb"));
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(3, hits.length);
+    assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaa"));
+    assertEquals(searcher.doc(hits[1].doc).get("field"), ("aaaab"));
+    assertEquals(searcher.doc(hits[2].doc).get("field"), ("aaabb"));
     query = new FuzzyQuery(new Term("field", "aaaac"), FuzzyQuery.defaultMinSimilarity, 4);   
-    hits = searcher.search(query);
-    assertEquals(2, hits.length());
-    assertEquals(hits.doc(0).get("field"), ("aaaaa"));
-    assertEquals(hits.doc(1).get("field"), ("aaaab"));
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(2, hits.length);
+    assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaa"));
+    assertEquals(searcher.doc(hits[1].doc).get("field"), ("aaaab"));
     query = new FuzzyQuery(new Term("field", "aaaac"), FuzzyQuery.defaultMinSimilarity, 5);   
-    hits = searcher.search(query);
-    assertEquals(0, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(0, hits.length);
     
 
     query = new FuzzyQuery(new Term("field", "ddddX"), FuzzyQuery.defaultMinSimilarity, 0);   
-    hits = searcher.search(query);
-    assertEquals(1, hits.length());
-    assertEquals(hits.doc(0).get("field"), ("ddddd"));
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(1, hits.length);
+    assertEquals(searcher.doc(hits[0].doc).get("field"), ("ddddd"));
     
     // now with prefix
     query = new FuzzyQuery(new Term("field", "ddddX"), FuzzyQuery.defaultMinSimilarity, 1);   
-    hits = searcher.search(query);
-    assertEquals(1, hits.length());
-    assertEquals(hits.doc(0).get("field"), ("ddddd"));
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(1, hits.length);
+    assertEquals(searcher.doc(hits[0].doc).get("field"), ("ddddd"));
     query = new FuzzyQuery(new Term("field", "ddddX"), FuzzyQuery.defaultMinSimilarity, 2);   
-    hits = searcher.search(query);
-    assertEquals(1, hits.length());
-    assertEquals(hits.doc(0).get("field"), ("ddddd"));
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(1, hits.length);
+    assertEquals(searcher.doc(hits[0].doc).get("field"), ("ddddd"));
     query = new FuzzyQuery(new Term("field", "ddddX"), FuzzyQuery.defaultMinSimilarity, 3);   
-    hits = searcher.search(query);
-    assertEquals(1, hits.length());
-    assertEquals(hits.doc(0).get("field"), ("ddddd"));
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(1, hits.length);
+    assertEquals(searcher.doc(hits[0].doc).get("field"), ("ddddd"));
     query = new FuzzyQuery(new Term("field", "ddddX"), FuzzyQuery.defaultMinSimilarity, 4);   
-    hits = searcher.search(query);
-    assertEquals(1, hits.length());
-    assertEquals(hits.doc(0).get("field"), ("ddddd"));
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(1, hits.length);
+    assertEquals(searcher.doc(hits[0].doc).get("field"), ("ddddd"));
     query = new FuzzyQuery(new Term("field", "ddddX"), FuzzyQuery.defaultMinSimilarity, 5);   
-    hits = searcher.search(query);
-    assertEquals(0, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(0, hits.length);
     
 
     // different field = no match:
     query = new FuzzyQuery(new Term("anotherfield", "ddddX"), FuzzyQuery.defaultMinSimilarity, 0);   
-    hits = searcher.search(query);
-    assertEquals(0, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(0, hits.length);
 
     searcher.close();
     directory.close();
@@ -174,64 +174,64 @@ public class TestFuzzyQuery extends LuceneTestCase {
     FuzzyQuery query;
     // not similar enough:
     query = new FuzzyQuery(new Term("field", "xxxxx"), FuzzyQuery.defaultMinSimilarity, 0);   
-    Hits hits = searcher.search(query);
-    assertEquals(0, hits.length());
+    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(0, hits.length);
     // edit distance to "aaaaaaa" = 3, this matches because the string is longer than
     // in testDefaultFuzziness so a bigger difference is allowed:
     query = new FuzzyQuery(new Term("field", "aaaaccc"), FuzzyQuery.defaultMinSimilarity, 0);   
-    hits = searcher.search(query);
-    assertEquals(1, hits.length());
-    assertEquals(hits.doc(0).get("field"), ("aaaaaaa"));
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(1, hits.length);
+    assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaaaa"));
     
     // now with prefix
     query = new FuzzyQuery(new Term("field", "aaaaccc"), FuzzyQuery.defaultMinSimilarity, 1);   
-    hits = searcher.search(query);
-    assertEquals(1, hits.length());
-    assertEquals(hits.doc(0).get("field"), ("aaaaaaa"));
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(1, hits.length);
+    assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaaaa"));
     query = new FuzzyQuery(new Term("field", "aaaaccc"), FuzzyQuery.defaultMinSimilarity, 4);   
-    hits = searcher.search(query);
-    assertEquals(1, hits.length());
-    assertEquals(hits.doc(0).get("field"), ("aaaaaaa"));
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(1, hits.length);
+    assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaaaa"));
     query = new FuzzyQuery(new Term("field", "aaaaccc"), FuzzyQuery.defaultMinSimilarity, 5);   
-    hits = searcher.search(query);
-    assertEquals(0, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(0, hits.length);
 
     // no match, more than half of the characters is wrong:
     query = new FuzzyQuery(new Term("field", "aaacccc"), FuzzyQuery.defaultMinSimilarity, 0);   
-    hits = searcher.search(query);
-    assertEquals(0, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(0, hits.length);
     
     // now with prefix
     query = new FuzzyQuery(new Term("field", "aaacccc"), FuzzyQuery.defaultMinSimilarity, 2);   
-    hits = searcher.search(query);
-    assertEquals(0, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(0, hits.length);
 
     // "student" and "stellent" are indeed similar to "segment" by default:
     query = new FuzzyQuery(new Term("field", "student"), FuzzyQuery.defaultMinSimilarity, 0);   
-    hits = searcher.search(query);
-    assertEquals(1, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(1, hits.length);
     query = new FuzzyQuery(new Term("field", "stellent"), FuzzyQuery.defaultMinSimilarity, 0);   
-    hits = searcher.search(query);
-    assertEquals(1, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(1, hits.length);
     
     // now with prefix
     query = new FuzzyQuery(new Term("field", "student"), FuzzyQuery.defaultMinSimilarity, 1);   
-    hits = searcher.search(query);
-    assertEquals(1, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(1, hits.length);
     query = new FuzzyQuery(new Term("field", "stellent"), FuzzyQuery.defaultMinSimilarity, 1);   
-    hits = searcher.search(query);
-    assertEquals(1, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(1, hits.length);
     query = new FuzzyQuery(new Term("field", "student"), FuzzyQuery.defaultMinSimilarity, 2);   
-    hits = searcher.search(query);
-    assertEquals(0, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(0, hits.length);
     query = new FuzzyQuery(new Term("field", "stellent"), FuzzyQuery.defaultMinSimilarity, 2);   
-    hits = searcher.search(query);
-    assertEquals(0, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(0, hits.length);
     
     // "student" doesn't match anymore thanks to increased minimum similarity:
     query = new FuzzyQuery(new Term("field", "student"), 0.6f, 0);   
-    hits = searcher.search(query);
-    assertEquals(0, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(0, hits.length);
 
     try {
       query = new FuzzyQuery(new Term("field", "student"), 1.1f);
diff --git a/src/test/org/apache/lucene/search/TestMatchAllDocsQuery.java b/src/test/org/apache/lucene/search/TestMatchAllDocsQuery.java
index 04f14b6..eba159d 100644
--- a/src/test/org/apache/lucene/search/TestMatchAllDocsQuery.java
+++ b/src/test/org/apache/lucene/search/TestMatchAllDocsQuery.java
@@ -43,27 +43,27 @@ public class TestMatchAllDocsQuery extends LuceneTestCase {
     iw.close();
     
     IndexSearcher is = new IndexSearcher(dir);
-    Hits hits = is.search(new MatchAllDocsQuery());
-    assertEquals(3, hits.length());
+    ScoreDoc[] hits = is.search(new MatchAllDocsQuery(), null, 1000).scoreDocs;
+    assertEquals(3, hits.length);
 
     // some artificial queries to trigger the use of skipTo():
     
     BooleanQuery bq = new BooleanQuery();
     bq.add(new MatchAllDocsQuery(), BooleanClause.Occur.MUST);
     bq.add(new MatchAllDocsQuery(), BooleanClause.Occur.MUST);
-    hits = is.search(bq);
-    assertEquals(3, hits.length());
+    hits = is.search(bq, null, 1000).scoreDocs;
+    assertEquals(3, hits.length);
 
     bq = new BooleanQuery();
     bq.add(new MatchAllDocsQuery(), BooleanClause.Occur.MUST);
     bq.add(new TermQuery(new Term("key", "three")), BooleanClause.Occur.MUST);
-    hits = is.search(bq);
-    assertEquals(1, hits.length());
+    hits = is.search(bq, null, 1000).scoreDocs;
+    assertEquals(1, hits.length);
 
     // delete a document:
     is.getIndexReader().deleteDocument(0);
-    hits = is.search(new MatchAllDocsQuery());
-    assertEquals(2, hits.length());
+    hits = is.search(new MatchAllDocsQuery(), null, 1000).scoreDocs;
+    assertEquals(2, hits.length);
     
     is.close();
   }
diff --git a/src/test/org/apache/lucene/search/TestMultiPhraseQuery.java b/src/test/org/apache/lucene/search/TestMultiPhraseQuery.java
index ccc0659..6680aae 100644
--- a/src/test/org/apache/lucene/search/TestMultiPhraseQuery.java
+++ b/src/test/org/apache/lucene/search/TestMultiPhraseQuery.java
@@ -85,11 +85,11 @@ public class TestMultiPhraseQuery extends LuceneTestCase
         query2.add((Term[])termsWithPrefix.toArray(new Term[0]));
         assertEquals("body:\"strawberry (piccadilly pie pizza)\"", query2.toString());
 
-        Hits result;
-        result = searcher.search(query1);
-        assertEquals(2, result.length());
-        result = searcher.search(query2);
-        assertEquals(0, result.length());
+        ScoreDoc[] result;
+        result = searcher.search(query1, null, 1000).scoreDocs;
+        assertEquals(2, result.length);
+        result = searcher.search(query2, null, 1000).scoreDocs;
+        assertEquals(0, result.length);
 
         // search for "blue* pizza":
         MultiPhraseQuery query3 = new MultiPhraseQuery();
@@ -105,14 +105,14 @@ public class TestMultiPhraseQuery extends LuceneTestCase
         query3.add((Term[])termsWithPrefix.toArray(new Term[0]));
         query3.add(new Term("body", "pizza"));
 
-        result = searcher.search(query3);
-        assertEquals(2, result.length()); // blueberry pizza, bluebird pizza
+        result = searcher.search(query3, null, 1000).scoreDocs;
+        assertEquals(2, result.length); // blueberry pizza, bluebird pizza
         assertEquals("body:\"(blueberry bluebird) pizza\"", query3.toString());
 
         // test slop:
         query3.setSlop(1);
-        result = searcher.search(query3);
-        assertEquals(3, result.length()); // blueberry pizza, bluebird pizza, bluebird foobar pizza
+        result = searcher.search(query3, null, 1000).scoreDocs;
+        assertEquals(3, result.length); // blueberry pizza, bluebird pizza, bluebird foobar pizza
 
         MultiPhraseQuery query4 = new MultiPhraseQuery();
         try {
@@ -161,9 +161,9 @@ public class TestMultiPhraseQuery extends LuceneTestCase
       q.add(trouble, BooleanClause.Occur.MUST);
 
       // exception will be thrown here without fix
-      Hits hits = searcher.search(q);
+      ScoreDoc[] hits = searcher.search(q, null, 1000).scoreDocs;
 
-      assertEquals("Wrong number of hits", 2, hits.length());
+      assertEquals("Wrong number of hits", 2, hits.length);
       searcher.close();
   }
     
@@ -186,8 +186,8 @@ public class TestMultiPhraseQuery extends LuceneTestCase
     q.add(trouble, BooleanClause.Occur.MUST);
 
     // exception will be thrown here without fix for #35626:
-    Hits hits = searcher.search(q);
-    assertEquals("Wrong number of hits", 0, hits.length());
+    ScoreDoc[] hits = searcher.search(q, null, 1000).scoreDocs;
+    assertEquals("Wrong number of hits", 0, hits.length);
     searcher.close();
   }
   
diff --git a/src/test/org/apache/lucene/search/TestMultiSearcher.java b/src/test/org/apache/lucene/search/TestMultiSearcher.java
index 5b94774..6e3f187 100644
--- a/src/test/org/apache/lucene/search/TestMultiSearcher.java
+++ b/src/test/org/apache/lucene/search/TestMultiSearcher.java
@@ -114,13 +114,13 @@ public class TestMultiSearcher extends LuceneTestCase
         // creating the multiSearcher
         Searcher mSearcher = getMultiSearcherInstance(searchers);
         // performing the search
-        Hits hits = mSearcher.search(query);
+        ScoreDoc[] hits = mSearcher.search(query, null, 1000).scoreDocs;
 
-        assertEquals(3, hits.length());
+        assertEquals(3, hits.length);
 
         // iterating over the hit documents
-        for (int i = 0; i < hits.length(); i++) {
-            Document d = hits.doc(i);
+        for (int i = 0; i < hits.length; i++) {
+            Document d = mSearcher.doc(hits[i].doc);
         }
         mSearcher.close();
 
@@ -143,26 +143,26 @@ public class TestMultiSearcher extends LuceneTestCase
         // creating the mulitSearcher
         MultiSearcher mSearcher2 = getMultiSearcherInstance(searchers2);
         // performing the same search
-        Hits hits2 = mSearcher2.search(query);
+        ScoreDoc[] hits2 = mSearcher2.search(query, null, 1000).scoreDocs;
 
-        assertEquals(4, hits2.length());
+        assertEquals(4, hits2.length);
 
         // iterating over the hit documents
-        for (int i = 0; i < hits2.length(); i++) {
+        for (int i = 0; i < hits2.length; i++) {
             // no exception should happen at this point
-            Document d = hits2.doc(i);
+            Document d = mSearcher2.doc(hits2[i].doc);
         }
 
         // test the subSearcher() method:
         Query subSearcherQuery = parser.parse("id:doc1");
-        hits2 = mSearcher2.search(subSearcherQuery);
-        assertEquals(2, hits2.length());
-        assertEquals(0, mSearcher2.subSearcher(hits2.id(0)));   // hit from searchers2[0]
-        assertEquals(1, mSearcher2.subSearcher(hits2.id(1)));   // hit from searchers2[1]
+        hits2 = mSearcher2.search(subSearcherQuery, null, 1000).scoreDocs;
+        assertEquals(2, hits2.length);
+        assertEquals(0, mSearcher2.subSearcher(hits2[0].doc));   // hit from searchers2[0]
+        assertEquals(1, mSearcher2.subSearcher(hits2[1].doc));   // hit from searchers2[1]
         subSearcherQuery = parser.parse("id:doc2");
-        hits2 = mSearcher2.search(subSearcherQuery);
-        assertEquals(1, hits2.length());
-        assertEquals(1, mSearcher2.subSearcher(hits2.id(0)));   // hit from searchers2[1]
+        hits2 = mSearcher2.search(subSearcherQuery, null, 1000).scoreDocs;
+        assertEquals(1, hits2.length);
+        assertEquals(1, mSearcher2.subSearcher(hits2[0].doc));   // hit from searchers2[1]
         mSearcher2.close();
 
         //--------------------------------------------------------------------
@@ -188,13 +188,13 @@ public class TestMultiSearcher extends LuceneTestCase
         // creating the mulitSearcher
         Searcher mSearcher3 = getMultiSearcherInstance(searchers3);
         // performing the same search
-        Hits hits3 = mSearcher3.search(query);
+        ScoreDoc[] hits3 = mSearcher3.search(query, null, 1000).scoreDocs;
 
-        assertEquals(3, hits3.length());
+        assertEquals(3, hits3.length);
 
         // iterating over the hit documents
-        for (int i = 0; i < hits3.length(); i++) {
-            Document d = hits3.doc(i);
+        for (int i = 0; i < hits3.length; i++) {
+            Document d = mSearcher3.doc(hits3[i].doc);
         }
         mSearcher3.close();
         indexStoreA.close();
@@ -246,10 +246,10 @@ public class TestMultiSearcher extends LuceneTestCase
 
     MultiSearcher searcher = getMultiSearcherInstance(new Searcher[]{indexSearcher1, indexSearcher2});
     assertTrue("searcher is null and it shouldn't be", searcher != null);
-    Hits hits = searcher.search(query);
+    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
     assertTrue("hits is null and it shouldn't be", hits != null);
-    assertTrue(hits.length() + " does not equal: " + 2, hits.length() == 2);
-    Document document = searcher.doc(hits.id(0));
+    assertTrue(hits.length + " does not equal: " + 2, hits.length == 2);
+    Document document = searcher.doc(hits[0].doc);
     assertTrue("document is null and it shouldn't be", document != null);
     assertTrue("document.getFields() Size: " + document.getFields().size() + " is not: " + 2, document.getFields().size() == 2);
     //Should be one document from each directory
@@ -257,7 +257,7 @@ public class TestMultiSearcher extends LuceneTestCase
     Set ftl = new HashSet();
     ftl.add("other");
     SetBasedFieldSelector fs = new SetBasedFieldSelector(ftl, Collections.EMPTY_SET);
-    document = searcher.doc(hits.id(0), fs);
+    document = searcher.doc(hits[0].doc, fs);
     assertTrue("document is null and it shouldn't be", document != null);
     assertTrue("document.getFields() Size: " + document.getFields().size() + " is not: " + 1, document.getFields().size() == 1);
     String value = document.get("contents");
@@ -267,7 +267,7 @@ public class TestMultiSearcher extends LuceneTestCase
     ftl.clear();
     ftl.add("contents");
     fs = new SetBasedFieldSelector(ftl, Collections.EMPTY_SET);
-    document = searcher.doc(hits.id(1), fs);
+    document = searcher.doc(hits[1].doc, fs);
     value = document.get("contents");
     assertTrue("value is null and it shouldn't be", value != null);    
     value = document.get("other");
@@ -289,7 +289,7 @@ public class TestMultiSearcher extends LuceneTestCase
         
         RAMDirectory ramDirectory1;
         IndexSearcher indexSearcher1;
-        Hits hits;
+        ScoreDoc[] hits;
         
         ramDirectory1=new MockRAMDirectory();
         
@@ -299,14 +299,12 @@ public class TestMultiSearcher extends LuceneTestCase
         
         indexSearcher1=new IndexSearcher(ramDirectory1);
         
-        hits=indexSearcher1.search(query);
+        hits=indexSearcher1.search(query, null, 1000).scoreDocs;
         
-        assertEquals(message, 2, hits.length());
-        
-        assertEquals(message, 1, hits.score(0), 1e-6); // hits.score(0) is 0.594535 if only a single document is in first index
+        assertEquals(message, 2, hits.length);
         
         // Store the scores for use later
-        float[] scores={ hits.score(0), hits.score(1) };
+        float[] scores={ hits[0].score, hits[1].score };
         
         assertTrue(message, scores[0] > scores[1]);
         
@@ -331,23 +329,23 @@ public class TestMultiSearcher extends LuceneTestCase
         
         Searcher searcher=getMultiSearcherInstance(new Searcher[] { indexSearcher1, indexSearcher2 });
         
-        hits=searcher.search(query);
+        hits=searcher.search(query, null, 1000).scoreDocs;
         
-        assertEquals(message, 2, hits.length());
+        assertEquals(message, 2, hits.length);
         
         // The scores should be the same (within reason)
-        assertEquals(message, scores[0], hits.score(0), 1e-6); // This will a document from ramDirectory1
-        assertEquals(message, scores[1], hits.score(1), 1e-6); // This will a document from ramDirectory2
+        assertEquals(message, scores[0], hits[0].score, 1e-6); // This will a document from ramDirectory1
+        assertEquals(message, scores[1], hits[1].score, 1e-6); // This will a document from ramDirectory2
         
         
         
         // Adding a Sort.RELEVANCE object should not change anything
-        hits=searcher.search(query, Sort.RELEVANCE);
+        hits=searcher.search(query, null, 1000, Sort.RELEVANCE).scoreDocs;
         
-        assertEquals(message, 2, hits.length());
+        assertEquals(message, 2, hits.length);
         
-        assertEquals(message, scores[0], hits.score(0), 1e-6); // This will a document from ramDirectory1
-        assertEquals(message, scores[1], hits.score(1), 1e-6); // This will a document from ramDirectory2
+        assertEquals(message, scores[0], hits[0].score, 1e-6); // This will a document from ramDirectory1
+        assertEquals(message, scores[1], hits[1].score, 1e-6); // This will a document from ramDirectory2
         
         searcher.close();
         
diff --git a/src/test/org/apache/lucene/search/TestMultiSearcherRanking.java b/src/test/org/apache/lucene/search/TestMultiSearcherRanking.java
index 69337aa..758506b 100644
--- a/src/test/org/apache/lucene/search/TestMultiSearcherRanking.java
+++ b/src/test/org/apache/lucene/search/TestMultiSearcherRanking.java
@@ -90,17 +90,17 @@ public class TestMultiSearcherRanking extends LuceneTestCase {
     if(verbose) System.out.println("Query: " + queryStr);
       QueryParser queryParser = new QueryParser(FIELD_NAME, new StandardAnalyzer());
     Query query = queryParser.parse(queryStr);
-    Hits multiSearcherHits = multiSearcher.search(query);
-    Hits singleSearcherHits = singleSearcher.search(query);
-    assertEquals(multiSearcherHits.length(), singleSearcherHits.length());
-    for (int i = 0; i < multiSearcherHits.length(); i++) {
-      Document docMulti = multiSearcherHits.doc(i);
-      Document docSingle = singleSearcherHits.doc(i);
+    ScoreDoc[] multiSearcherHits = multiSearcher.search(query, null, 1000).scoreDocs;
+    ScoreDoc[] singleSearcherHits = singleSearcher.search(query, null, 1000).scoreDocs;
+    assertEquals(multiSearcherHits.length, singleSearcherHits.length);
+    for (int i = 0; i < multiSearcherHits.length; i++) {
+      Document docMulti = multiSearcher.doc(multiSearcherHits[i].doc);
+      Document docSingle = singleSearcher.doc(singleSearcherHits[i].doc);
       if(verbose) System.out.println("Multi:  " + docMulti.get(FIELD_NAME) + " score="
-          + multiSearcherHits.score(i));
+          + multiSearcherHits[i].score);
       if(verbose) System.out.println("Single: " + docSingle.get(FIELD_NAME) + " score="
-          + singleSearcherHits.score(i));
-      assertEquals(multiSearcherHits.score(i), singleSearcherHits.score(i),
+          + singleSearcherHits[i].score);
+      assertEquals(multiSearcherHits[i].score, singleSearcherHits[i].score,
           0.001f);
       assertEquals(docMulti.get(FIELD_NAME), docSingle.get(FIELD_NAME));
     }
diff --git a/src/test/org/apache/lucene/search/TestNot.java b/src/test/org/apache/lucene/search/TestNot.java
index 77a6799..77f8d4f 100644
--- a/src/test/org/apache/lucene/search/TestNot.java
+++ b/src/test/org/apache/lucene/search/TestNot.java
@@ -51,7 +51,7 @@ public class TestNot extends LuceneTestCase {
       QueryParser parser = new QueryParser("field", new SimpleAnalyzer());
     Query query = parser.parse("a NOT b");
     //System.out.println(query);
-    Hits hits = searcher.search(query);
-    assertEquals(0, hits.length());
+    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(0, hits.length);
   }
 }
diff --git a/src/test/org/apache/lucene/search/TestPhrasePrefixQuery.java b/src/test/org/apache/lucene/search/TestPhrasePrefixQuery.java
index 6362504..c7c27a5 100644
--- a/src/test/org/apache/lucene/search/TestPhrasePrefixQuery.java
+++ b/src/test/org/apache/lucene/search/TestPhrasePrefixQuery.java
@@ -95,11 +95,11 @@ public class TestPhrasePrefixQuery
         query1.add((Term[])termsWithPrefix.toArray(new Term[0]));
         query2.add((Term[])termsWithPrefix.toArray(new Term[0]));
 
-        Hits result;
-        result = searcher.search(query1);
-        assertEquals(2, result.length());
+        ScoreDoc[] result;
+        result = searcher.search(query1, null, 1000).scoreDocs;
+        assertEquals(2, result.length);
 
-        result = searcher.search(query2);
-        assertEquals(0, result.length());
+        result = searcher.search(query2, null, 1000).scoreDocs;
+        assertEquals(0, result.length);
     }
 }
diff --git a/src/test/org/apache/lucene/search/TestPhraseQuery.java b/src/test/org/apache/lucene/search/TestPhraseQuery.java
index 2318a55..21714c2 100644
--- a/src/test/org/apache/lucene/search/TestPhraseQuery.java
+++ b/src/test/org/apache/lucene/search/TestPhraseQuery.java
@@ -91,8 +91,8 @@ public class TestPhraseQuery extends LuceneTestCase {
     query.setSlop(2);
     query.add(new Term("field", "one"));
     query.add(new Term("field", "five"));
-    Hits hits = searcher.search(query);
-    assertEquals(0, hits.length());
+    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(0, hits.length);
     QueryUtils.check(query,searcher);
   }
 
@@ -100,8 +100,8 @@ public class TestPhraseQuery extends LuceneTestCase {
     query.setSlop(3);
     query.add(new Term("field", "one"));
     query.add(new Term("field", "five"));
-    Hits hits = searcher.search(query);
-    assertEquals(1, hits.length());
+    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(1, hits.length);
     QueryUtils.check(query,searcher);
   }
 
@@ -112,16 +112,16 @@ public class TestPhraseQuery extends LuceneTestCase {
     // slop is zero by default
     query.add(new Term("field", "four"));
     query.add(new Term("field", "five"));
-    Hits hits = searcher.search(query);
-    assertEquals("exact match", 1, hits.length());
+    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals("exact match", 1, hits.length);
     QueryUtils.check(query,searcher);
 
 
     query = new PhraseQuery();
     query.add(new Term("field", "two"));
     query.add(new Term("field", "one"));
-    hits = searcher.search(query);
-    assertEquals("reverse not exact", 0, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals("reverse not exact", 0, hits.length);
     QueryUtils.check(query,searcher);
   }
 
@@ -130,8 +130,8 @@ public class TestPhraseQuery extends LuceneTestCase {
     query.setSlop(1);
     query.add(new Term("field", "one"));
     query.add(new Term("field", "two"));
-    Hits hits = searcher.search(query);
-    assertEquals("in order", 1, hits.length());
+    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals("in order", 1, hits.length);
     QueryUtils.check(query,searcher);
 
 
@@ -141,8 +141,8 @@ public class TestPhraseQuery extends LuceneTestCase {
     query.setSlop(1);
     query.add(new Term("field", "two"));
     query.add(new Term("field", "one"));
-    hits = searcher.search(query);
-    assertEquals("reversed, slop not 2 or more", 0, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals("reversed, slop not 2 or more", 0, hits.length);
     QueryUtils.check(query,searcher);
   }
 
@@ -153,8 +153,8 @@ public class TestPhraseQuery extends LuceneTestCase {
     query.setSlop(2); // must be at least two for reverse order match
     query.add(new Term("field", "two"));
     query.add(new Term("field", "one"));
-    Hits hits = searcher.search(query);
-    assertEquals("just sloppy enough", 1, hits.length());
+    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals("just sloppy enough", 1, hits.length);
     QueryUtils.check(query,searcher);
 
 
@@ -162,8 +162,8 @@ public class TestPhraseQuery extends LuceneTestCase {
     query.setSlop(2);
     query.add(new Term("field", "three"));
     query.add(new Term("field", "one"));
-    hits = searcher.search(query);
-    assertEquals("not sloppy enough", 0, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals("not sloppy enough", 0, hits.length);
     QueryUtils.check(query,searcher);
 
   }
@@ -177,8 +177,8 @@ public class TestPhraseQuery extends LuceneTestCase {
     query.add(new Term("field", "one"));
     query.add(new Term("field", "three"));
     query.add(new Term("field", "five"));
-    Hits hits = searcher.search(query);
-    assertEquals("two total moves", 1, hits.length());
+    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals("two total moves", 1, hits.length);
     QueryUtils.check(query,searcher);
 
 
@@ -187,14 +187,14 @@ public class TestPhraseQuery extends LuceneTestCase {
     query.add(new Term("field", "five"));
     query.add(new Term("field", "three"));
     query.add(new Term("field", "one"));
-    hits = searcher.search(query);
-    assertEquals("slop of 5 not close enough", 0, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals("slop of 5 not close enough", 0, hits.length);
     QueryUtils.check(query,searcher);
 
 
     query.setSlop(6);
-    hits = searcher.search(query);
-    assertEquals("slop of 6 just right", 1, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals("slop of 6 just right", 1, hits.length);
     QueryUtils.check(query,searcher);
 
   }
@@ -215,8 +215,8 @@ public class TestPhraseQuery extends LuceneTestCase {
     PhraseQuery query = new PhraseQuery();
     query.add(new Term("field","stop"));
     query.add(new Term("field","words"));
-    Hits hits = searcher.search(query);
-    assertEquals(1, hits.length());
+    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(1, hits.length);
     QueryUtils.check(query,searcher);
 
 
@@ -224,8 +224,8 @@ public class TestPhraseQuery extends LuceneTestCase {
     query = new PhraseQuery();
     query.add(new Term("field", "words"));
     query.add(new Term("field", "here"));
-    hits = searcher.search(query);
-    assertEquals(1, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(1, hits.length);
     QueryUtils.check(query,searcher);
 
 
@@ -254,8 +254,8 @@ public class TestPhraseQuery extends LuceneTestCase {
     PhraseQuery phraseQuery = new PhraseQuery();
     phraseQuery.add(new Term("source", "marketing"));
     phraseQuery.add(new Term("source", "info"));
-    Hits hits = searcher.search(phraseQuery);
-    assertEquals(2, hits.length());
+    ScoreDoc[] hits = searcher.search(phraseQuery, null, 1000).scoreDocs;
+    assertEquals(2, hits.length);
     QueryUtils.check(phraseQuery,searcher);
 
     
@@ -263,8 +263,8 @@ public class TestPhraseQuery extends LuceneTestCase {
     BooleanQuery booleanQuery = new BooleanQuery();
     booleanQuery.add(termQuery, BooleanClause.Occur.MUST);
     booleanQuery.add(phraseQuery, BooleanClause.Occur.MUST);
-    hits = searcher.search(booleanQuery);
-    assertEquals(1, hits.length());
+    hits = searcher.search(booleanQuery, null, 1000).scoreDocs;
+    assertEquals(1, hits.length);
     QueryUtils.check(termQuery,searcher);
 
     
@@ -294,23 +294,23 @@ public class TestPhraseQuery extends LuceneTestCase {
     phraseQuery.add(new Term("contents","map"));
     phraseQuery.add(new Term("contents","entry"));
     
-    hits = searcher.search(termQuery);
-    assertEquals(3, hits.length());
-    hits = searcher.search(phraseQuery);
-    assertEquals(2, hits.length());
+    hits = searcher.search(termQuery, null, 1000).scoreDocs;
+    assertEquals(3, hits.length);
+    hits = searcher.search(phraseQuery, null, 1000).scoreDocs;
+    assertEquals(2, hits.length);
 
     
     booleanQuery = new BooleanQuery();
     booleanQuery.add(termQuery, BooleanClause.Occur.MUST);
     booleanQuery.add(phraseQuery, BooleanClause.Occur.MUST);
-    hits = searcher.search(booleanQuery);
-    assertEquals(2, hits.length());
+    hits = searcher.search(booleanQuery, null, 1000).scoreDocs;
+    assertEquals(2, hits.length);
     
     booleanQuery = new BooleanQuery();
     booleanQuery.add(phraseQuery, BooleanClause.Occur.MUST);
     booleanQuery.add(termQuery, BooleanClause.Occur.MUST);
-    hits = searcher.search(booleanQuery);
-    assertEquals(2, hits.length());
+    hits = searcher.search(booleanQuery, null, 1000).scoreDocs;
+    assertEquals(2, hits.length);
     QueryUtils.check(booleanQuery,searcher);
 
     
@@ -343,16 +343,16 @@ public class TestPhraseQuery extends LuceneTestCase {
     query.add(new Term("field", "firstname"));
     query.add(new Term("field", "lastname"));
     query.setSlop(Integer.MAX_VALUE);
-    Hits hits = searcher.search(query);
-    assertEquals(3, hits.length());
+    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(3, hits.length);
     // Make sure that those matches where the terms appear closer to
     // each other get a higher score:
-    assertEquals(0.71, hits.score(0), 0.01);
-    assertEquals(0, hits.id(0));
-    assertEquals(0.44, hits.score(1), 0.01);
-    assertEquals(1, hits.id(1));
-    assertEquals(0.31, hits.score(2), 0.01);
-    assertEquals(2, hits.id(2));
+    assertEquals(0.71, hits[0].score, 0.01);
+    assertEquals(0, hits[0].doc);
+    assertEquals(0.44, hits[1].score, 0.01);
+    assertEquals(1, hits[1].doc);
+    assertEquals(0.31, hits[2].score, 0.01);
+    assertEquals(2, hits[2].doc);
     QueryUtils.check(query,searcher);        
   }
 
@@ -363,14 +363,14 @@ public class TestPhraseQuery extends LuceneTestCase {
     query.add(new Term("repeated", "part"));
     query.setSlop(100);
 
-    Hits hits = searcher.search(query);
-    assertEquals("slop of 100 just right", 1, hits.length());
+    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals("slop of 100 just right", 1, hits.length);
     QueryUtils.check(query,searcher);
 
     query.setSlop(99);
 
-    hits = searcher.search(query);
-    assertEquals("slop of 99 not enough", 0, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals("slop of 99 not enough", 0, hits.length);
     QueryUtils.check(query,searcher);
   }
 
@@ -382,8 +382,8 @@ public class TestPhraseQuery extends LuceneTestCase {
     query.add(new Term("nonexist", "found"));
     query.setSlop(2); // would be found this way
 
-    Hits hits = searcher.search(query);
-    assertEquals("phrase without repetitions exists in 2 docs", 2, hits.length());
+    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals("phrase without repetitions exists in 2 docs", 2, hits.length);
     QueryUtils.check(query,searcher);
 
     // phrase with repetitions that exists in 2 docs
@@ -393,8 +393,8 @@ public class TestPhraseQuery extends LuceneTestCase {
     query.add(new Term("nonexist", "exist"));
     query.setSlop(1); // would be found 
 
-    hits = searcher.search(query);
-    assertEquals("phrase with repetitions exists in two docs", 2, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals("phrase with repetitions exists in two docs", 2, hits.length);
     QueryUtils.check(query,searcher);
 
     // phrase I with repetitions that does not exist in any doc
@@ -404,8 +404,8 @@ public class TestPhraseQuery extends LuceneTestCase {
     query.add(new Term("nonexist", "phrase"));
     query.setSlop(1000); // would not be found no matter how high the slop is
 
-    hits = searcher.search(query);
-    assertEquals("nonexisting phrase with repetitions does not exist in any doc", 0, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals("nonexisting phrase with repetitions does not exist in any doc", 0, hits.length);
     QueryUtils.check(query,searcher);
 
     // phrase II with repetitions that does not exist in any doc
@@ -416,8 +416,8 @@ public class TestPhraseQuery extends LuceneTestCase {
     query.add(new Term("nonexist", "exist"));
     query.setSlop(1000); // would not be found no matter how high the slop is
 
-    hits = searcher.search(query);
-    assertEquals("nonexisting phrase with repetitions does not exist in any doc", 0, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals("nonexisting phrase with repetitions does not exist in any doc", 0, hits.length);
     QueryUtils.check(query,searcher);
 
   }
@@ -437,17 +437,17 @@ public class TestPhraseQuery extends LuceneTestCase {
     query.setSlop(0); // to use exact phrase scorer
     query.add(new Term("field", "two"));
     query.add(new Term("field", "three"));
-    Hits hits = searcher.search(query);
-    assertEquals("phrase found with exact phrase scorer", 1, hits.length());
-    float score0 = hits.score(0);
+    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals("phrase found with exact phrase scorer", 1, hits.length);
+    float score0 = hits[0].score;
     //System.out.println("(exact) field: two three: "+score0);
     QueryUtils.check(query,searcher);
 
     // search on non palyndrome, find phrase with slop 2, though no slop required here.
     query.setSlop(2); // to use sloppy scorer 
-    hits = searcher.search(query);
-    assertEquals("just sloppy enough", 1, hits.length());
-    float score1 = hits.score(0);
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals("just sloppy enough", 1, hits.length);
+    float score1 = hits[0].score;
     //System.out.println("(sloppy) field: two three: "+score1);
     assertEquals("exact scorer and sloppy scorer score the same when slop does not matter",score0, score1, SCORE_COMP_THRESH);
     QueryUtils.check(query,searcher);
@@ -457,9 +457,9 @@ public class TestPhraseQuery extends LuceneTestCase {
     query.setSlop(2); // must be at least two for both ordered and reversed to match
     query.add(new Term("palindrome", "two"));
     query.add(new Term("palindrome", "three"));
-    hits = searcher.search(query);
-    assertEquals("just sloppy enough", 1, hits.length());
-    float score2 = hits.score(0);
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals("just sloppy enough", 1, hits.length);
+    float score2 = hits[0].score;
     //System.out.println("palindrome: two three: "+score2);
     QueryUtils.check(query,searcher);
     
@@ -471,9 +471,9 @@ public class TestPhraseQuery extends LuceneTestCase {
     query.setSlop(2); // must be at least two for both ordered and reversed to match
     query.add(new Term("palindrome", "three"));
     query.add(new Term("palindrome", "two"));
-    hits = searcher.search(query);
-    assertEquals("just sloppy enough", 1, hits.length());
-    float score3 = hits.score(0);
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals("just sloppy enough", 1, hits.length);
+    float score3 = hits[0].score;
     //System.out.println("palindrome: three two: "+score3);
     QueryUtils.check(query,searcher);
 
@@ -498,17 +498,17 @@ public class TestPhraseQuery extends LuceneTestCase {
     query.add(new Term("field", "one"));
     query.add(new Term("field", "two"));
     query.add(new Term("field", "three"));
-    Hits hits = searcher.search(query);
-    assertEquals("phrase found with exact phrase scorer", 1, hits.length());
-    float score0 = hits.score(0);
+    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals("phrase found with exact phrase scorer", 1, hits.length);
+    float score0 = hits[0].score;
     //System.out.println("(exact) field: one two three: "+score0);
     QueryUtils.check(query,searcher);
 
     // search on non palyndrome, find phrase with slop 3, though no slop required here.
     query.setSlop(4); // to use sloppy scorer 
-    hits = searcher.search(query);
-    assertEquals("just sloppy enough", 1, hits.length());
-    float score1 = hits.score(0);
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals("just sloppy enough", 1, hits.length);
+    float score1 = hits[0].score;
     //System.out.println("(sloppy) field: one two three: "+score1);
     assertEquals("exact scorer and sloppy scorer score the same when slop does not matter",score0, score1, SCORE_COMP_THRESH);
     QueryUtils.check(query,searcher);
@@ -519,9 +519,9 @@ public class TestPhraseQuery extends LuceneTestCase {
     query.add(new Term("palindrome", "one"));
     query.add(new Term("palindrome", "two"));
     query.add(new Term("palindrome", "three"));
-    hits = searcher.search(query);
-    assertEquals("just sloppy enough", 1, hits.length());
-    float score2 = hits.score(0);
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals("just sloppy enough", 1, hits.length);
+    float score2 = hits[0].score;
     //System.out.println("palindrome: one two three: "+score2);
     QueryUtils.check(query,searcher);
     
@@ -534,9 +534,9 @@ public class TestPhraseQuery extends LuceneTestCase {
     query.add(new Term("palindrome", "three"));
     query.add(new Term("palindrome", "two"));
     query.add(new Term("palindrome", "one"));
-    hits = searcher.search(query);
-    assertEquals("just sloppy enough", 1, hits.length());
-    float score3 = hits.score(0);
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals("just sloppy enough", 1, hits.length);
+    float score3 = hits[0].score;
     //System.out.println("palindrome: three two one: "+score3);
     QueryUtils.check(query,searcher);
 
diff --git a/src/test/org/apache/lucene/search/TestPositionIncrement.java b/src/test/org/apache/lucene/search/TestPositionIncrement.java
index 5f8f922..75a492a 100644
--- a/src/test/org/apache/lucene/search/TestPositionIncrement.java
+++ b/src/test/org/apache/lucene/search/TestPositionIncrement.java
@@ -17,25 +17,20 @@ package org.apache.lucene.search;
  * limitations under the License.
  */
 
-import org.apache.lucene.index.Term;
-import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.queryParser.QueryParser;
-import org.apache.lucene.search.PhraseQuery;
-import org.apache.lucene.search.Hits;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.store.RAMDirectory;
+import java.io.Reader;
+import java.io.StringReader;
+
 import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.StopAnalyzer;
 import org.apache.lucene.analysis.StopFilter;
 import org.apache.lucene.analysis.Token;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.WhitespaceAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
-
-import java.io.Reader;
-import java.io.StringReader;
-
+import org.apache.lucene.index.IndexWriter;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.queryParser.QueryParser;
+import org.apache.lucene.store.RAMDirectory;
 import org.apache.lucene.util.LuceneTestCase;
 
 /**
@@ -76,85 +71,85 @@ public class TestPositionIncrement extends LuceneTestCase {
 
     IndexSearcher searcher = new IndexSearcher(store);
     PhraseQuery q;
-    Hits hits;
+    ScoreDoc[] hits;
 
     q = new PhraseQuery();
     q.add(new Term("field", "1"));
     q.add(new Term("field", "2"));
-    hits = searcher.search(q);
-    assertEquals(0, hits.length());
+    hits = searcher.search(q, null, 1000).scoreDocs;
+    assertEquals(0, hits.length);
 
     // same as previous, just specify positions explicitely.
     q = new PhraseQuery(); 
     q.add(new Term("field", "1"),0);
     q.add(new Term("field", "2"),1);
-    hits = searcher.search(q);
-    assertEquals(0, hits.length());
+    hits = searcher.search(q, null, 1000).scoreDocs;
+    assertEquals(0, hits.length);
 
     // specifying correct positions should find the phrase.
     q = new PhraseQuery();
     q.add(new Term("field", "1"),0);
     q.add(new Term("field", "2"),2);
-    hits = searcher.search(q);
-    assertEquals(1, hits.length());
+    hits = searcher.search(q, null, 1000).scoreDocs;
+    assertEquals(1, hits.length);
 
     q = new PhraseQuery();
     q.add(new Term("field", "2"));
     q.add(new Term("field", "3"));
-    hits = searcher.search(q);
-    assertEquals(1, hits.length());
+    hits = searcher.search(q, null, 1000).scoreDocs;
+    assertEquals(1, hits.length);
 
     q = new PhraseQuery();
     q.add(new Term("field", "3"));
     q.add(new Term("field", "4"));
-    hits = searcher.search(q);
-    assertEquals(0, hits.length());
+    hits = searcher.search(q, null, 1000).scoreDocs;
+    assertEquals(0, hits.length);
 
     // phrase query would find it when correct positions are specified. 
     q = new PhraseQuery();
     q.add(new Term("field", "3"),0);
     q.add(new Term("field", "4"),0);
-    hits = searcher.search(q);
-    assertEquals(1, hits.length());
+    hits = searcher.search(q, null, 1000).scoreDocs;
+    assertEquals(1, hits.length);
 
     // phrase query should fail for non existing searched term 
     // even if there exist another searched terms in the same searched position. 
     q = new PhraseQuery();
     q.add(new Term("field", "3"),0);
     q.add(new Term("field", "9"),0);
-    hits = searcher.search(q);
-    assertEquals(0, hits.length());
+    hits = searcher.search(q, null, 1000).scoreDocs;
+    assertEquals(0, hits.length);
 
     // multi-phrase query should succed for non existing searched term
     // because there exist another searched terms in the same searched position. 
     MultiPhraseQuery mq = new MultiPhraseQuery();
     mq.add(new Term[]{new Term("field", "3"),new Term("field", "9")},0);
-    hits = searcher.search(mq);
-    assertEquals(1, hits.length());
+    hits = searcher.search(mq, null, 1000).scoreDocs;
+    assertEquals(1, hits.length);
 
     q = new PhraseQuery();
     q.add(new Term("field", "2"));
     q.add(new Term("field", "4"));
-    hits = searcher.search(q);
-    assertEquals(1, hits.length());
+    hits = searcher.search(q, null, 1000).scoreDocs;
+    assertEquals(1, hits.length);
 
     q = new PhraseQuery();
     q.add(new Term("field", "3"));
     q.add(new Term("field", "5"));
-    hits = searcher.search(q);
-    assertEquals(1, hits.length());
+    hits = searcher.search(q, null, 1000).scoreDocs;
+    assertEquals(1, hits.length);
 
     q = new PhraseQuery();
     q.add(new Term("field", "4"));
     q.add(new Term("field", "5"));
-    hits = searcher.search(q);
-    assertEquals(1, hits.length());
+    hits = searcher.search(q, null, 1000).scoreDocs;
+    assertEquals(1, hits.length);
 
     q = new PhraseQuery();
     q.add(new Term("field", "2"));
     q.add(new Term("field", "5"));
-    hits = searcher.search(q);
-    assertEquals(0, hits.length());
+    hits = searcher.search(q, null, 1000).scoreDocs;
+    assertEquals(0, hits.length);
 
     // analyzer to introduce stopwords and increment gaps 
     Analyzer stpa = new Analyzer() {
@@ -168,19 +163,19 @@ public class TestPositionIncrement extends LuceneTestCase {
     // should not find "1 2" because there is a gap of 1 in the index
     QueryParser qp = new QueryParser("field",stpa);
     q = (PhraseQuery) qp.parse("\"1 2\"");
-    hits = searcher.search(q);
-    assertEquals(0, hits.length());
+    hits = searcher.search(q, null, 1000).scoreDocs;
+    assertEquals(0, hits.length);
 
     // omitted stop word cannot help because stop filter swallows the increments. 
     q = (PhraseQuery) qp.parse("\"1 stop 2\"");
-    hits = searcher.search(q);
-    assertEquals(0, hits.length());
+    hits = searcher.search(q, null, 1000).scoreDocs;
+    assertEquals(0, hits.length);
 
     // query parser alone won't help, because stop filter swallows the increments. 
     qp.setEnablePositionIncrements(true);
     q = (PhraseQuery) qp.parse("\"1 stop 2\"");
-    hits = searcher.search(q);
-    assertEquals(0, hits.length());
+    hits = searcher.search(q, null, 1000).scoreDocs;
+    assertEquals(0, hits.length);
 
     boolean dflt = StopFilter.getEnablePositionIncrementsDefault();
     try {
@@ -188,14 +183,14 @@ public class TestPositionIncrement extends LuceneTestCase {
       qp.setEnablePositionIncrements(false);
       StopFilter.setEnablePositionIncrementsDefault(true);
       q = (PhraseQuery) qp.parse("\"1 stop 2\"");
-      hits = searcher.search(q);
-      assertEquals(0, hits.length());
+      hits = searcher.search(q, null, 1000).scoreDocs;
+      assertEquals(0, hits.length);
       
       // when both qp qnd stopFilter propagate increments, we should find the doc.
       qp.setEnablePositionIncrements(true);
       q = (PhraseQuery) qp.parse("\"1 stop 2\"");
-      hits = searcher.search(q);
-      assertEquals(1, hits.length());
+      hits = searcher.search(q, null, 1000).scoreDocs;
+      assertEquals(1, hits.length);
     } finally {
       StopFilter.setEnablePositionIncrementsDefault(dflt);
     }
diff --git a/src/test/org/apache/lucene/search/TestPrefixFilter.java b/src/test/org/apache/lucene/search/TestPrefixFilter.java
index cb93c8b..8ba822b 100644
--- a/src/test/org/apache/lucene/search/TestPrefixFilter.java
+++ b/src/test/org/apache/lucene/search/TestPrefixFilter.java
@@ -51,55 +51,55 @@ public class TestPrefixFilter extends LuceneTestCase {
     PrefixFilter filter = new PrefixFilter(new Term("category", "/Computers"));
     Query query = new ConstantScoreQuery(filter);
     IndexSearcher searcher = new IndexSearcher(directory);
-    Hits hits = searcher.search(query);
-    assertEquals(4, hits.length());
+    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(4, hits.length);
 
     // test middle of values
     filter = new PrefixFilter(new Term("category", "/Computers/Mac"));
     query = new ConstantScoreQuery(filter);
-    hits = searcher.search(query);
-    assertEquals(2, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(2, hits.length);
 
     // test start of values
     filter = new PrefixFilter(new Term("category", "/Computers/Linux"));
     query = new ConstantScoreQuery(filter);
-    hits = searcher.search(query);
-    assertEquals(1, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(1, hits.length);
 
     // test end of values
     filter = new PrefixFilter(new Term("category", "/Computers/Windows"));
     query = new ConstantScoreQuery(filter);
-    hits = searcher.search(query);
-    assertEquals(1, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(1, hits.length);
 
     // test non-existant
     filter = new PrefixFilter(new Term("category", "/Computers/ObsoleteOS"));
     query = new ConstantScoreQuery(filter);
-    hits = searcher.search(query);
-    assertEquals(0, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(0, hits.length);
 
     // test non-existant, before values
     filter = new PrefixFilter(new Term("category", "/Computers/AAA"));
     query = new ConstantScoreQuery(filter);
-    hits = searcher.search(query);
-    assertEquals(0, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(0, hits.length);
 
     // test non-existant, after values
     filter = new PrefixFilter(new Term("category", "/Computers/ZZZ"));
     query = new ConstantScoreQuery(filter);
-    hits = searcher.search(query);
-    assertEquals(0, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(0, hits.length);
 
     // test zero length prefix
     filter = new PrefixFilter(new Term("category", ""));
     query = new ConstantScoreQuery(filter);
-    hits = searcher.search(query);
-    assertEquals(4, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(4, hits.length);
 
     // test non existent field
     filter = new PrefixFilter(new Term("nonexistantfield", "/Computers"));
     query = new ConstantScoreQuery(filter);
-    hits = searcher.search(query);
-    assertEquals(0, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(0, hits.length);
   }
 }
diff --git a/src/test/org/apache/lucene/search/TestPrefixQuery.java b/src/test/org/apache/lucene/search/TestPrefixQuery.java
index 2d79891..7d64c14 100644
--- a/src/test/org/apache/lucene/search/TestPrefixQuery.java
+++ b/src/test/org/apache/lucene/search/TestPrefixQuery.java
@@ -47,11 +47,11 @@ public class TestPrefixQuery extends LuceneTestCase {
 
     PrefixQuery query = new PrefixQuery(new Term("category", "/Computers"));
     IndexSearcher searcher = new IndexSearcher(directory);
-    Hits hits = searcher.search(query);
-    assertEquals("All documents in /Computers category and below", 3, hits.length());
+    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals("All documents in /Computers category and below", 3, hits.length);
 
     query = new PrefixQuery(new Term("category", "/Computers/Mac"));
-    hits = searcher.search(query);
-    assertEquals("One in /Computers/Mac", 1, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals("One in /Computers/Mac", 1, hits.length);
   }
 }
diff --git a/src/test/org/apache/lucene/search/TestRangeFilter.java b/src/test/org/apache/lucene/search/TestRangeFilter.java
index 8057fb7..31554a3 100644
--- a/src/test/org/apache/lucene/search/TestRangeFilter.java
+++ b/src/test/org/apache/lucene/search/TestRangeFilter.java
@@ -55,70 +55,70 @@ public class TestRangeFilter extends BaseTestRangeFilter {
         
         assertEquals("num of docs", numDocs, 1+ maxId - minId);
         
-	Hits result;
+  ScoreDoc[] result;
         Query q = new TermQuery(new Term("body","body"));
 
         // test id, bounded on both ends
         
-	result = search.search(q,new RangeFilter("id",minIP,maxIP,T,T));
-	assertEquals("find all", numDocs, result.length());
+  result = search.search(q,new RangeFilter("id",minIP,maxIP,T,T), numDocs).scoreDocs;
+  assertEquals("find all", numDocs, result.length);
 
-	result = search.search(q,new RangeFilter("id",minIP,maxIP,T,F));
-	assertEquals("all but last", numDocs-1, result.length());
+  result = search.search(q,new RangeFilter("id",minIP,maxIP,T,F), numDocs).scoreDocs;
+  assertEquals("all but last", numDocs-1, result.length);
 
-	result = search.search(q,new RangeFilter("id",minIP,maxIP,F,T));
-	assertEquals("all but first", numDocs-1, result.length());
+  result = search.search(q,new RangeFilter("id",minIP,maxIP,F,T), numDocs).scoreDocs;
+  assertEquals("all but first", numDocs-1, result.length);
         
-	result = search.search(q,new RangeFilter("id",minIP,maxIP,F,F));
-        assertEquals("all but ends", numDocs-2, result.length());
+  result = search.search(q,new RangeFilter("id",minIP,maxIP,F,F), numDocs).scoreDocs;
+        assertEquals("all but ends", numDocs-2, result.length);
     
-        result = search.search(q,new RangeFilter("id",medIP,maxIP,T,T));
-        assertEquals("med and up", 1+ maxId-medId, result.length());
+        result = search.search(q,new RangeFilter("id",medIP,maxIP,T,T), numDocs).scoreDocs;
+        assertEquals("med and up", 1+ maxId-medId, result.length);
         
-        result = search.search(q,new RangeFilter("id",minIP,medIP,T,T));
-        assertEquals("up to med", 1+ medId-minId, result.length());
+        result = search.search(q,new RangeFilter("id",minIP,medIP,T,T), numDocs).scoreDocs;
+        assertEquals("up to med", 1+ medId-minId, result.length);
 
         // unbounded id
 
-	result = search.search(q,new RangeFilter("id",minIP,null,T,F));
-	assertEquals("min and up", numDocs, result.length());
+  result = search.search(q,new RangeFilter("id",minIP,null,T,F), numDocs).scoreDocs;
+  assertEquals("min and up", numDocs, result.length);
 
-	result = search.search(q,new RangeFilter("id",null,maxIP,F,T));
-	assertEquals("max and down", numDocs, result.length());
+  result = search.search(q,new RangeFilter("id",null,maxIP,F,T), numDocs).scoreDocs;
+  assertEquals("max and down", numDocs, result.length);
 
-	result = search.search(q,new RangeFilter("id",minIP,null,F,F));
-	assertEquals("not min, but up", numDocs-1, result.length());
+  result = search.search(q,new RangeFilter("id",minIP,null,F,F), numDocs).scoreDocs;
+  assertEquals("not min, but up", numDocs-1, result.length);
         
-	result = search.search(q,new RangeFilter("id",null,maxIP,F,F));
-	assertEquals("not max, but down", numDocs-1, result.length());
+  result = search.search(q,new RangeFilter("id",null,maxIP,F,F), numDocs).scoreDocs;
+  assertEquals("not max, but down", numDocs-1, result.length);
         
-        result = search.search(q,new RangeFilter("id",medIP,maxIP,T,F));
-        assertEquals("med and up, not max", maxId-medId, result.length());
+        result = search.search(q,new RangeFilter("id",medIP,maxIP,T,F), numDocs).scoreDocs;
+        assertEquals("med and up, not max", maxId-medId, result.length);
         
-        result = search.search(q,new RangeFilter("id",minIP,medIP,F,T));
-        assertEquals("not min, up to med", medId-minId, result.length());
+        result = search.search(q,new RangeFilter("id",minIP,medIP,F,T), numDocs).scoreDocs;
+        assertEquals("not min, up to med", medId-minId, result.length);
 
         // very small sets
 
-	result = search.search(q,new RangeFilter("id",minIP,minIP,F,F));
-	assertEquals("min,min,F,F", 0, result.length());
-	result = search.search(q,new RangeFilter("id",medIP,medIP,F,F));
-	assertEquals("med,med,F,F", 0, result.length());
-	result = search.search(q,new RangeFilter("id",maxIP,maxIP,F,F));
-	assertEquals("max,max,F,F", 0, result.length());
+  result = search.search(q,new RangeFilter("id",minIP,minIP,F,F), numDocs).scoreDocs;
+  assertEquals("min,min,F,F", 0, result.length);
+  result = search.search(q,new RangeFilter("id",medIP,medIP,F,F), numDocs).scoreDocs;
+  assertEquals("med,med,F,F", 0, result.length);
+  result = search.search(q,new RangeFilter("id",maxIP,maxIP,F,F), numDocs).scoreDocs;
+  assertEquals("max,max,F,F", 0, result.length);
                      
-	result = search.search(q,new RangeFilter("id",minIP,minIP,T,T));
-	assertEquals("min,min,T,T", 1, result.length());
-	result = search.search(q,new RangeFilter("id",null,minIP,F,T));
-	assertEquals("nul,min,F,T", 1, result.length());
+  result = search.search(q,new RangeFilter("id",minIP,minIP,T,T), numDocs).scoreDocs;
+  assertEquals("min,min,T,T", 1, result.length);
+  result = search.search(q,new RangeFilter("id",null,minIP,F,T), numDocs).scoreDocs;
+  assertEquals("nul,min,F,T", 1, result.length);
 
-	result = search.search(q,new RangeFilter("id",maxIP,maxIP,T,T));
-	assertEquals("max,max,T,T", 1, result.length());
-	result = search.search(q,new RangeFilter("id",maxIP,null,T,F));
-	assertEquals("max,nul,T,T", 1, result.length());
+  result = search.search(q,new RangeFilter("id",maxIP,maxIP,T,T), numDocs).scoreDocs;
+  assertEquals("max,max,T,T", 1, result.length);
+  result = search.search(q,new RangeFilter("id",maxIP,null,T,F), numDocs).scoreDocs;
+  assertEquals("max,nul,T,T", 1, result.length);
 
-	result = search.search(q,new RangeFilter("id",medIP,medIP,T,T));
-	assertEquals("med,med,T,T", 1, result.length());
+  result = search.search(q,new RangeFilter("id",medIP,medIP,T,T), numDocs).scoreDocs;
+  assertEquals("med,med,T,T", 1, result.length);
         
     }
 
@@ -134,53 +134,53 @@ public class TestRangeFilter extends BaseTestRangeFilter {
         
         assertEquals("num of docs", numDocs, 1+ maxId - minId);
         
-	Hits result;
+  ScoreDoc[] result;
         Query q = new TermQuery(new Term("body","body"));
 
         // test extremes, bounded on both ends
         
-	result = search.search(q,new RangeFilter("rand",minRP,maxRP,T,T));
-	assertEquals("find all", numDocs, result.length());
+  result = search.search(q,new RangeFilter("rand",minRP,maxRP,T,T), numDocs).scoreDocs;
+  assertEquals("find all", numDocs, result.length);
 
-	result = search.search(q,new RangeFilter("rand",minRP,maxRP,T,F));
-	assertEquals("all but biggest", numDocs-1, result.length());
+  result = search.search(q,new RangeFilter("rand",minRP,maxRP,T,F), numDocs).scoreDocs;
+  assertEquals("all but biggest", numDocs-1, result.length);
 
-	result = search.search(q,new RangeFilter("rand",minRP,maxRP,F,T));
-	assertEquals("all but smallest", numDocs-1, result.length());
+  result = search.search(q,new RangeFilter("rand",minRP,maxRP,F,T), numDocs).scoreDocs;
+  assertEquals("all but smallest", numDocs-1, result.length);
         
-	result = search.search(q,new RangeFilter("rand",minRP,maxRP,F,F));
-        assertEquals("all but extremes", numDocs-2, result.length());
+  result = search.search(q,new RangeFilter("rand",minRP,maxRP,F,F), numDocs).scoreDocs;
+        assertEquals("all but extremes", numDocs-2, result.length);
     
         // unbounded
 
-	result = search.search(q,new RangeFilter("rand",minRP,null,T,F));
-	assertEquals("smallest and up", numDocs, result.length());
+  result = search.search(q,new RangeFilter("rand",minRP,null,T,F), numDocs).scoreDocs;
+  assertEquals("smallest and up", numDocs, result.length);
 
-	result = search.search(q,new RangeFilter("rand",null,maxRP,F,T));
-	assertEquals("biggest and down", numDocs, result.length());
+  result = search.search(q,new RangeFilter("rand",null,maxRP,F,T), numDocs).scoreDocs;
+  assertEquals("biggest and down", numDocs, result.length);
 
-	result = search.search(q,new RangeFilter("rand",minRP,null,F,F));
-	assertEquals("not smallest, but up", numDocs-1, result.length());
+  result = search.search(q,new RangeFilter("rand",minRP,null,F,F), numDocs).scoreDocs;
+  assertEquals("not smallest, but up", numDocs-1, result.length);
         
-	result = search.search(q,new RangeFilter("rand",null,maxRP,F,F));
-	assertEquals("not biggest, but down", numDocs-1, result.length());
+  result = search.search(q,new RangeFilter("rand",null,maxRP,F,F), numDocs).scoreDocs;
+  assertEquals("not biggest, but down", numDocs-1, result.length);
         
         // very small sets
 
-	result = search.search(q,new RangeFilter("rand",minRP,minRP,F,F));
-	assertEquals("min,min,F,F", 0, result.length());
-	result = search.search(q,new RangeFilter("rand",maxRP,maxRP,F,F));
-	assertEquals("max,max,F,F", 0, result.length());
+  result = search.search(q,new RangeFilter("rand",minRP,minRP,F,F), numDocs).scoreDocs;
+  assertEquals("min,min,F,F", 0, result.length);
+  result = search.search(q,new RangeFilter("rand",maxRP,maxRP,F,F), numDocs).scoreDocs;
+  assertEquals("max,max,F,F", 0, result.length);
                      
-	result = search.search(q,new RangeFilter("rand",minRP,minRP,T,T));
-	assertEquals("min,min,T,T", 1, result.length());
-	result = search.search(q,new RangeFilter("rand",null,minRP,F,T));
-	assertEquals("nul,min,F,T", 1, result.length());
-
-	result = search.search(q,new RangeFilter("rand",maxRP,maxRP,T,T));
-	assertEquals("max,max,T,T", 1, result.length());
-	result = search.search(q,new RangeFilter("rand",maxRP,null,T,F));
-	assertEquals("max,nul,T,T", 1, result.length());
+  result = search.search(q,new RangeFilter("rand",minRP,minRP,T,T), numDocs).scoreDocs;
+  assertEquals("min,min,T,T", 1, result.length);
+  result = search.search(q,new RangeFilter("rand",null,minRP,F,T), numDocs).scoreDocs;
+  assertEquals("nul,min,F,T", 1, result.length);
+
+  result = search.search(q,new RangeFilter("rand",maxRP,maxRP,T,T), numDocs).scoreDocs;
+  assertEquals("max,max,T,T", 1, result.length);
+  result = search.search(q,new RangeFilter("rand",maxRP,null,T,F), numDocs).scoreDocs;
+  assertEquals("max,nul,T,T", 1, result.length);
         
     }
 
diff --git a/src/test/org/apache/lucene/search/TestRangeQuery.java b/src/test/org/apache/lucene/search/TestRangeQuery.java
index 61a93f6..8f38340 100644
--- a/src/test/org/apache/lucene/search/TestRangeQuery.java
+++ b/src/test/org/apache/lucene/search/TestRangeQuery.java
@@ -46,20 +46,20 @@ public class TestRangeQuery extends LuceneTestCase {
                                  false);
     initializeIndex(new String[] {"A", "B", "C", "D"});
     IndexSearcher searcher = new IndexSearcher(dir);
-    Hits hits = searcher.search(query);
-    assertEquals("A,B,C,D, only B in range", 1, hits.length());
+    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals("A,B,C,D, only B in range", 1, hits.length);
     searcher.close();
 
     initializeIndex(new String[] {"A", "B", "D"});
     searcher = new IndexSearcher(dir);
-    hits = searcher.search(query);
-    assertEquals("A,B,D, only B in range", 1, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals("A,B,D, only B in range", 1, hits.length);
     searcher.close();
 
     addDoc("C");
     searcher = new IndexSearcher(dir);
-    hits = searcher.search(query);
-    assertEquals("C added, still only B in range", 1, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals("C added, still only B in range", 1, hits.length);
     searcher.close();
   }
 
@@ -70,20 +70,20 @@ public class TestRangeQuery extends LuceneTestCase {
 
     initializeIndex(new String[]{"A", "B", "C", "D"});
     IndexSearcher searcher = new IndexSearcher(dir);
-    Hits hits = searcher.search(query);
-    assertEquals("A,B,C,D - A,B,C in range", 3, hits.length());
+    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals("A,B,C,D - A,B,C in range", 3, hits.length);
     searcher.close();
 
     initializeIndex(new String[]{"A", "B", "D"});
     searcher = new IndexSearcher(dir);
-    hits = searcher.search(query);
-    assertEquals("A,B,D - A and B in range", 2, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals("A,B,D - A and B in range", 2, hits.length);
     searcher.close();
 
     addDoc("C");
     searcher = new IndexSearcher(dir);
-    hits = searcher.search(query);
-    assertEquals("C added - A, B, C in range", 3, hits.length());
+    hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals("C added - A, B, C in range", 3, hits.length);
     searcher.close();
   }
 
@@ -158,3 +158,4 @@ public class TestRangeQuery extends LuceneTestCase {
 }
 
 
+
diff --git a/src/test/org/apache/lucene/search/TestRemoteCachingWrapperFilter.java b/src/test/org/apache/lucene/search/TestRemoteCachingWrapperFilter.java
index 63779c9..2be6d10 100644
--- a/src/test/org/apache/lucene/search/TestRemoteCachingWrapperFilter.java
+++ b/src/test/org/apache/lucene/search/TestRemoteCachingWrapperFilter.java
@@ -81,9 +81,9 @@ public class TestRemoteCachingWrapperFilter extends LuceneTestCase {
   private static void search(Query query, Filter filter, int hitNumber, String typeValue) throws Exception {
     Searchable[] searchables = { getRemote() };
     Searcher searcher = new MultiSearcher(searchables);
-    Hits result = searcher.search(query,filter);
-    assertEquals(1, result.length());
-    Document document = result.doc(hitNumber);
+    ScoreDoc[] result = searcher.search(query,filter, 1000).scoreDocs;
+    assertEquals(1, result.length);
+    Document document = searcher.doc(result[hitNumber].doc);
     assertTrue("document is null and it shouldn't be", document != null);
     assertEquals(typeValue, document.get("type"));
     assertTrue("document.getFields() Size: " + document.getFields().size() + " is not: " + 3, document.getFields().size() == 3);
diff --git a/src/test/org/apache/lucene/search/TestRemoteSearchable.java b/src/test/org/apache/lucene/search/TestRemoteSearchable.java
index 8c35d1f..ba1f3b21 100644
--- a/src/test/org/apache/lucene/search/TestRemoteSearchable.java
+++ b/src/test/org/apache/lucene/search/TestRemoteSearchable.java
@@ -73,10 +73,10 @@ public class TestRemoteSearchable extends LuceneTestCase {
     // try to search the published index
     Searchable[] searchables = { getRemote() };
     Searcher searcher = new MultiSearcher(searchables);
-    Hits result = searcher.search(query);
+    ScoreDoc[] result = searcher.search(query, null, 1000).scoreDocs;
 
-    assertEquals(1, result.length());
-    Document document = result.doc(0);
+    assertEquals(1, result.length);
+    Document document = searcher.doc(result[0].doc);
     assertTrue("document is null and it shouldn't be", document != null);
     assertEquals("test text", document.get("test"));
     assertTrue("document.getFields() Size: " + document.getFields().size() + " is not: " + 2, document.getFields().size() == 2);
@@ -114,23 +114,23 @@ public class TestRemoteSearchable extends LuceneTestCase {
     // try to search the published index
     Searchable[] searchables = { getRemote() };
     Searcher searcher = new MultiSearcher(searchables);
-    Hits hits = searcher.search(
+    ScoreDoc[] hits = searcher.search(
           new TermQuery(new Term("test", "text")),
-          new QueryWrapperFilter(new TermQuery(new Term("test", "test"))));
-    assertEquals(1, hits.length());
-    Hits nohits = searcher.search(
+          new QueryWrapperFilter(new TermQuery(new Term("test", "test"))), 1000).scoreDocs;
+    assertEquals(1, hits.length);
+    ScoreDoc[] nohits = searcher.search(
           new TermQuery(new Term("test", "text")),
-          new QueryWrapperFilter(new TermQuery(new Term("test", "non-existent-term"))));
-    assertEquals(0, nohits.length());
+          new QueryWrapperFilter(new TermQuery(new Term("test", "non-existent-term"))), 1000).scoreDocs;
+    assertEquals(0, nohits.length);
   }
 
   public void testConstantScoreQuery() throws Exception {
     // try to search the published index
     Searchable[] searchables = { getRemote() };
     Searcher searcher = new MultiSearcher(searchables);
-    Hits hits = searcher.search(
+    ScoreDoc[] hits = searcher.search(
           new ConstantScoreQuery(new QueryWrapperFilter(
-                                   new TermQuery(new Term("test", "test")))));
-    assertEquals(1, hits.length());
+                                   new TermQuery(new Term("test", "test")))), null, 1000).scoreDocs;
+    assertEquals(1, hits.length);
   }
 }
diff --git a/src/test/org/apache/lucene/search/TestSearchHitsWithDeletions.java b/src/test/org/apache/lucene/search/TestSearchHitsWithDeletions.java
index 8c0f221..0eb5159 100644
--- a/src/test/org/apache/lucene/search/TestSearchHitsWithDeletions.java
+++ b/src/test/org/apache/lucene/search/TestSearchHitsWithDeletions.java
@@ -37,6 +37,7 @@ import org.apache.lucene.store.RAMDirectory;
  * Test Hits searches with interleaved deletions.
  * 
  * See {@link http://issues.apache.org/jira/browse/LUCENE-1096}.
+ * @deprecated Hits will be removed in Lucene 3.0
  */
 public class TestSearchHitsWithDeletions extends TestCase {
 
diff --git a/src/test/org/apache/lucene/search/TestSort.java b/src/test/org/apache/lucene/search/TestSort.java
index a93a22c..760bdf8 100644
--- a/src/test/org/apache/lucene/search/TestSort.java
+++ b/src/test/org/apache/lucene/search/TestSort.java
@@ -459,9 +459,9 @@ implements Serializable {
 	public void testNormalizedScores() throws Exception {
 
 		// capture relevancy scores
-		HashMap scoresX = getScores (full.search (queryX));
-		HashMap scoresY = getScores (full.search (queryY));
-		HashMap scoresA = getScores (full.search (queryA));
+    HashMap scoresX = getScores (full.search (queryX, null, 1000).scoreDocs, full);
+    HashMap scoresY = getScores (full.search (queryY, null, 1000).scoreDocs, full);
+    HashMap scoresA = getScores (full.search (queryA, null, 1000).scoreDocs, full);
 
 		// we'll test searching locally, remote and multi
 		MultiSearcher remote = new MultiSearcher (new Searchable[] { getRemote() });
@@ -470,92 +470,92 @@ implements Serializable {
 		// change sorting and make sure relevancy stays the same
 
 		sort = new Sort();
-		assertSameValues (scoresX, getScores(full.search(queryX,sort)));
-		assertSameValues (scoresX, getScores(remote.search(queryX,sort)));
-		assertSameValues (scoresX, getScores(multi.search(queryX,sort)));
-		assertSameValues (scoresY, getScores(full.search(queryY,sort)));
-		assertSameValues (scoresY, getScores(remote.search(queryY,sort)));
-		assertSameValues (scoresY, getScores(multi.search(queryY,sort)));
-		assertSameValues (scoresA, getScores(full.search(queryA,sort)));
-		assertSameValues (scoresA, getScores(remote.search(queryA,sort)));
-		assertSameValues (scoresA, getScores(multi.search(queryA,sort)));
+    assertSameValues (scoresX, getScores (full.search (queryX, null, 1000, sort).scoreDocs, full));
+    assertSameValues (scoresX, getScores (remote.search (queryX, null, 1000, sort).scoreDocs, remote));
+    assertSameValues (scoresX, getScores (multi.search (queryX, null, 1000, sort).scoreDocs, multi));
+    assertSameValues (scoresY, getScores (full.search (queryY, null, 1000, sort).scoreDocs, full));
+    assertSameValues (scoresY, getScores (remote.search (queryY, null, 1000, sort).scoreDocs, remote));
+    assertSameValues (scoresY, getScores (multi.search (queryY, null, 1000, sort).scoreDocs, multi));
+    assertSameValues (scoresA, getScores (full.search (queryA, null, 1000, sort).scoreDocs, full));
+    assertSameValues (scoresA, getScores (remote.search (queryA, null, 1000, sort).scoreDocs, remote));
+    assertSameValues (scoresA, getScores (multi.search (queryA, null, 1000, sort).scoreDocs, multi));
 
 		sort.setSort(SortField.FIELD_DOC);
-		assertSameValues (scoresX, getScores(full.search(queryX,sort)));
-		assertSameValues (scoresX, getScores(remote.search(queryX,sort)));
-		assertSameValues (scoresX, getScores(multi.search(queryX,sort)));
-		assertSameValues (scoresY, getScores(full.search(queryY,sort)));
-		assertSameValues (scoresY, getScores(remote.search(queryY,sort)));
-		assertSameValues (scoresY, getScores(multi.search(queryY,sort)));
-		assertSameValues (scoresA, getScores(full.search(queryA,sort)));
-		assertSameValues (scoresA, getScores(remote.search(queryA,sort)));
-		assertSameValues (scoresA, getScores(multi.search(queryA,sort)));
+    assertSameValues (scoresX, getScores (full.search (queryX, null, 1000, sort).scoreDocs, full));
+    assertSameValues (scoresX, getScores (remote.search (queryX, null, 1000, sort).scoreDocs, remote));
+    assertSameValues (scoresX, getScores (multi.search (queryX, null, 1000, sort).scoreDocs, multi));
+    assertSameValues (scoresY, getScores (full.search (queryY, null, 1000, sort).scoreDocs, full));
+    assertSameValues (scoresY, getScores (remote.search (queryY, null, 1000, sort).scoreDocs, remote));
+    assertSameValues (scoresY, getScores (multi.search (queryY, null, 1000, sort).scoreDocs, multi));
+    assertSameValues (scoresA, getScores (full.search (queryA, null, 1000, sort).scoreDocs, full));
+    assertSameValues (scoresA, getScores (remote.search (queryA, null, 1000, sort).scoreDocs, remote));
+    assertSameValues (scoresA, getScores (multi.search (queryA, null, 1000, sort).scoreDocs, multi));
 
 		sort.setSort ("int");
-		assertSameValues (scoresX, getScores(full.search(queryX,sort)));
-		assertSameValues (scoresX, getScores(remote.search(queryX,sort)));
-		assertSameValues (scoresX, getScores(multi.search(queryX,sort)));
-		assertSameValues (scoresY, getScores(full.search(queryY,sort)));
-		assertSameValues (scoresY, getScores(remote.search(queryY,sort)));
-		assertSameValues (scoresY, getScores(multi.search(queryY,sort)));
-		assertSameValues (scoresA, getScores(full.search(queryA,sort)));
-		assertSameValues (scoresA, getScores(remote.search(queryA,sort)));
-		assertSameValues (scoresA, getScores(multi.search(queryA,sort)));
+    assertSameValues (scoresX, getScores (full.search (queryX, null, 1000, sort).scoreDocs, full));
+    assertSameValues (scoresX, getScores (remote.search (queryX, null, 1000, sort).scoreDocs, remote));
+    assertSameValues (scoresX, getScores (multi.search (queryX, null, 1000, sort).scoreDocs, multi));
+    assertSameValues (scoresY, getScores (full.search (queryY, null, 1000, sort).scoreDocs, full));
+    assertSameValues (scoresY, getScores (remote.search (queryY, null, 1000, sort).scoreDocs, remote));
+    assertSameValues (scoresY, getScores (multi.search (queryY, null, 1000, sort).scoreDocs, multi));
+    assertSameValues (scoresA, getScores (full.search (queryA, null, 1000, sort).scoreDocs, full));
+    assertSameValues (scoresA, getScores (remote.search (queryA, null, 1000, sort).scoreDocs, remote));
+    assertSameValues (scoresA, getScores (multi.search (queryA, null, 1000, sort).scoreDocs, multi));
 
 		sort.setSort ("float");
-		assertSameValues (scoresX, getScores(full.search(queryX,sort)));
-		assertSameValues (scoresX, getScores(remote.search(queryX,sort)));
-		assertSameValues (scoresX, getScores(multi.search(queryX,sort)));
-		assertSameValues (scoresY, getScores(full.search(queryY,sort)));
-		assertSameValues (scoresY, getScores(remote.search(queryY,sort)));
-		assertSameValues (scoresY, getScores(multi.search(queryY,sort)));
-		assertSameValues (scoresA, getScores(full.search(queryA,sort)));
-		assertSameValues (scoresA, getScores(remote.search(queryA,sort)));
-		assertSameValues (scoresA, getScores(multi.search(queryA,sort)));
+    assertSameValues (scoresX, getScores (full.search (queryX, null, 1000, sort).scoreDocs, full));
+    assertSameValues (scoresX, getScores (remote.search (queryX, null, 1000, sort).scoreDocs, remote));
+    assertSameValues (scoresX, getScores (multi.search (queryX, null, 1000, sort).scoreDocs, multi));
+    assertSameValues (scoresY, getScores (full.search (queryY, null, 1000, sort).scoreDocs, full));
+    assertSameValues (scoresY, getScores (remote.search (queryY, null, 1000, sort).scoreDocs, remote));
+    assertSameValues (scoresY, getScores (multi.search (queryY, null, 1000, sort).scoreDocs, multi));
+    assertSameValues (scoresA, getScores (full.search (queryA, null, 1000, sort).scoreDocs, full));
+    assertSameValues (scoresA, getScores (remote.search (queryA, null, 1000, sort).scoreDocs, remote));
+    assertSameValues (scoresA, getScores (multi.search (queryA, null, 1000, sort).scoreDocs, multi));
 
 		sort.setSort ("string");
-		assertSameValues (scoresX, getScores(full.search(queryX,sort)));
-		assertSameValues (scoresX, getScores(remote.search(queryX,sort)));
-		assertSameValues (scoresX, getScores(multi.search(queryX,sort)));
-		assertSameValues (scoresY, getScores(full.search(queryY,sort)));
-		assertSameValues (scoresY, getScores(remote.search(queryY,sort)));
-		assertSameValues (scoresY, getScores(multi.search(queryY,sort)));
-		assertSameValues (scoresA, getScores(full.search(queryA,sort)));
-		assertSameValues (scoresA, getScores(remote.search(queryA,sort)));
-		assertSameValues (scoresA, getScores(multi.search(queryA,sort)));
+    assertSameValues (scoresX, getScores (full.search (queryX, null, 1000, sort).scoreDocs, full));
+    assertSameValues (scoresX, getScores (remote.search (queryX, null, 1000, sort).scoreDocs, remote));
+    assertSameValues (scoresX, getScores (multi.search (queryX, null, 1000, sort).scoreDocs, multi));
+    assertSameValues (scoresY, getScores (full.search (queryY, null, 1000, sort).scoreDocs, full));
+    assertSameValues (scoresY, getScores (remote.search (queryY, null, 1000, sort).scoreDocs, remote));
+    assertSameValues (scoresY, getScores (multi.search (queryY, null, 1000, sort).scoreDocs, multi));
+    assertSameValues (scoresA, getScores (full.search (queryA, null, 1000, sort).scoreDocs, full));
+    assertSameValues (scoresA, getScores (remote.search (queryA, null, 1000, sort).scoreDocs, remote));
+    assertSameValues (scoresA, getScores (multi.search (queryA, null, 1000, sort).scoreDocs, multi));
 
 		sort.setSort (new String[] {"int","float"});
-		assertSameValues (scoresX, getScores(full.search(queryX,sort)));
-		assertSameValues (scoresX, getScores(remote.search(queryX,sort)));
-		assertSameValues (scoresX, getScores(multi.search(queryX,sort)));
-		assertSameValues (scoresY, getScores(full.search(queryY,sort)));
-		assertSameValues (scoresY, getScores(remote.search(queryY,sort)));
-		assertSameValues (scoresY, getScores(multi.search(queryY,sort)));
-		assertSameValues (scoresA, getScores(full.search(queryA,sort)));
-		assertSameValues (scoresA, getScores(remote.search(queryA,sort)));
-		assertSameValues (scoresA, getScores(multi.search(queryA,sort)));
+    assertSameValues (scoresX, getScores (full.search (queryX, null, 1000, sort).scoreDocs, full));
+    assertSameValues (scoresX, getScores (remote.search (queryX, null, 1000, sort).scoreDocs, remote));
+    assertSameValues (scoresX, getScores (multi.search (queryX, null, 1000, sort).scoreDocs, multi));
+    assertSameValues (scoresY, getScores (full.search (queryY, null, 1000, sort).scoreDocs, full));
+    assertSameValues (scoresY, getScores (remote.search (queryY, null, 1000, sort).scoreDocs, remote));
+    assertSameValues (scoresY, getScores (multi.search (queryY, null, 1000, sort).scoreDocs, multi));
+    assertSameValues (scoresA, getScores (full.search (queryA, null, 1000, sort).scoreDocs, full));
+    assertSameValues (scoresA, getScores (remote.search (queryA, null, 1000, sort).scoreDocs, remote));
+    assertSameValues (scoresA, getScores (multi.search (queryA, null, 1000, sort).scoreDocs, multi));
 
 		sort.setSort (new SortField[] { new SortField ("int", true), new SortField (null, SortField.DOC, true) });
-		assertSameValues (scoresX, getScores(full.search(queryX,sort)));
-		assertSameValues (scoresX, getScores(remote.search(queryX,sort)));
-		assertSameValues (scoresX, getScores(multi.search(queryX,sort)));
-		assertSameValues (scoresY, getScores(full.search(queryY,sort)));
-		assertSameValues (scoresY, getScores(remote.search(queryY,sort)));
-		assertSameValues (scoresY, getScores(multi.search(queryY,sort)));
-		assertSameValues (scoresA, getScores(full.search(queryA,sort)));
-		assertSameValues (scoresA, getScores(remote.search(queryA,sort)));
-		assertSameValues (scoresA, getScores(multi.search(queryA,sort)));
+    assertSameValues (scoresX, getScores (full.search (queryX, null, 1000, sort).scoreDocs, full));
+    assertSameValues (scoresX, getScores (remote.search (queryX, null, 1000, sort).scoreDocs, remote));
+    assertSameValues (scoresX, getScores (multi.search (queryX, null, 1000, sort).scoreDocs, multi));
+    assertSameValues (scoresY, getScores (full.search (queryY, null, 1000, sort).scoreDocs, full));
+    assertSameValues (scoresY, getScores (remote.search (queryY, null, 1000, sort).scoreDocs, remote));
+    assertSameValues (scoresY, getScores (multi.search (queryY, null, 1000, sort).scoreDocs, multi));
+    assertSameValues (scoresA, getScores (full.search (queryA, null, 1000, sort).scoreDocs, full));
+    assertSameValues (scoresA, getScores (remote.search (queryA, null, 1000, sort).scoreDocs, remote));
+    assertSameValues (scoresA, getScores (multi.search (queryA, null, 1000, sort).scoreDocs, multi));
 
 		sort.setSort (new String[] {"float","string"});
-		assertSameValues (scoresX, getScores(full.search(queryX,sort)));
-		assertSameValues (scoresX, getScores(remote.search(queryX,sort)));
-		assertSameValues (scoresX, getScores(multi.search(queryX,sort)));
-		assertSameValues (scoresY, getScores(full.search(queryY,sort)));
-		assertSameValues (scoresY, getScores(remote.search(queryY,sort)));
-		assertSameValues (scoresY, getScores(multi.search(queryY,sort)));
-		assertSameValues (scoresA, getScores(full.search(queryA,sort)));
-		assertSameValues (scoresA, getScores(remote.search(queryA,sort)));
-		assertSameValues (scoresA, getScores(multi.search(queryA,sort)));
+    assertSameValues (scoresX, getScores (full.search (queryX, null, 1000, sort).scoreDocs, full));
+    assertSameValues (scoresX, getScores (remote.search (queryX, null, 1000, sort).scoreDocs, remote));
+    assertSameValues (scoresX, getScores (multi.search (queryX, null, 1000, sort).scoreDocs, multi));
+    assertSameValues (scoresY, getScores (full.search (queryY, null, 1000, sort).scoreDocs, full));
+    assertSameValues (scoresY, getScores (remote.search (queryY, null, 1000, sort).scoreDocs, remote));
+    assertSameValues (scoresY, getScores (multi.search (queryY, null, 1000, sort).scoreDocs, multi));
+    assertSameValues (scoresA, getScores (full.search (queryA, null, 1000, sort).scoreDocs, full));
+    assertSameValues (scoresA, getScores (remote.search (queryA, null, 1000, sort).scoreDocs, remote));
+    assertSameValues (scoresA, getScores (multi.search (queryA, null, 1000, sort).scoreDocs, multi));
 
 	}
 
@@ -648,11 +648,11 @@ implements Serializable {
 	// make sure the documents returned by the search match the expected list
 	private void assertMatches (Searcher searcher, Query query, Sort sort, String expectedResult)
 	throws IOException {
-		Hits result = searcher.search (query, sort);
+    ScoreDoc[] result = searcher.search (query, null, 1000, sort).scoreDocs;
 		StringBuffer buff = new StringBuffer(10);
-		int n = result.length();
+    int n = result.length;
 		for (int i=0; i<n; ++i) {
-			Document doc = result.doc(i);
+      Document doc = searcher.doc(result[i].doc);
 			String[] v = doc.getValues("tracer");
 			for (int j=0; j<v.length; ++j) {
 				buff.append (v[j]);
@@ -664,11 +664,11 @@ implements Serializable {
 	// make sure the documents returned by the search match the expected list pattern
 	private void assertMatchesPattern (Searcher searcher, Query query, Sort sort, String pattern)
 	throws IOException {
-		Hits result = searcher.search (query, sort);
+    ScoreDoc[] result = searcher.search (query, null, 1000, sort).scoreDocs;
 		StringBuffer buff = new StringBuffer(10);
-		int n = result.length();
+    int n = result.length;
 		for (int i=0; i<n; ++i) {
-			Document doc = result.doc(i);
+      Document doc = searcher.doc(result[i].doc);
 			String[] v = doc.getValues("tracer");
 			for (int j=0; j<v.length; ++j) {
 				buff.append (v[j]);
@@ -678,15 +678,15 @@ implements Serializable {
 		assertTrue (Pattern.compile(pattern).matcher(buff.toString()).matches());
 	}
 
-	private HashMap getScores (Hits hits)
+  private HashMap getScores (ScoreDoc[] hits, Searcher searcher)
 	throws IOException {
 		HashMap scoreMap = new HashMap();
-		int n = hits.length();
+    int n = hits.length;
 		for (int i=0; i<n; ++i) {
-			Document doc = hits.doc(i);
+      Document doc = searcher.doc(hits[i].doc);
 			String[] v = doc.getValues("tracer");
 			assertEquals (v.length, 1);
-			scoreMap.put (v[0], new Float(hits.score(i)));
+      scoreMap.put (v[0], new Float(hits[i].score));
 		}
 		return scoreMap;
 	}
diff --git a/src/test/org/apache/lucene/search/TestTermVectors.java b/src/test/org/apache/lucene/search/TestTermVectors.java
index 79a816f..8159c34 100644
--- a/src/test/org/apache/lucene/search/TestTermVectors.java
+++ b/src/test/org/apache/lucene/search/TestTermVectors.java
@@ -77,12 +77,12 @@ public class TestTermVectors extends LuceneTestCase {
   public void testTermVectors() {
     Query query = new TermQuery(new Term("field", "seventy"));
     try {
-      Hits hits = searcher.search(query);
-      assertEquals(100, hits.length());
+      ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+      assertEquals(100, hits.length);
       
-      for (int i = 0; i < hits.length(); i++)
+      for (int i = 0; i < hits.length; i++)
       {
-        TermFreqVector [] vector = searcher.reader.getTermFreqVectors(hits.id(i));
+        TermFreqVector [] vector = searcher.reader.getTermFreqVectors(hits[i].doc);
         assertTrue(vector != null);
         assertTrue(vector.length == 1);
       }
@@ -125,19 +125,19 @@ public class TestTermVectors extends LuceneTestCase {
   public void testTermPositionVectors() {
     Query query = new TermQuery(new Term("field", "zero"));
     try {
-      Hits hits = searcher.search(query);
-      assertEquals(1, hits.length());
+      ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+      assertEquals(1, hits.length);
       
-      for (int i = 0; i < hits.length(); i++)
+      for (int i = 0; i < hits.length; i++)
       {
-        TermFreqVector [] vector = searcher.reader.getTermFreqVectors(hits.id(i));
+        TermFreqVector [] vector = searcher.reader.getTermFreqVectors(hits[i].doc);
         assertTrue(vector != null);
         assertTrue(vector.length == 1);
         
-        boolean shouldBePosVector = (hits.id(i) % 2 == 0) ? true : false;
+        boolean shouldBePosVector = (hits[i].doc % 2 == 0) ? true : false;
         assertTrue((shouldBePosVector == false) || (shouldBePosVector == true && (vector[0] instanceof TermPositionVector == true)));
        
-        boolean shouldBeOffVector = (hits.id(i) % 3 == 0) ? true : false;
+        boolean shouldBeOffVector = (hits[i].doc % 3 == 0) ? true : false;
         assertTrue((shouldBeOffVector == false) || (shouldBeOffVector == true && (vector[0] instanceof TermPositionVector == true)));
         
         if(shouldBePosVector || shouldBeOffVector){
@@ -186,12 +186,12 @@ public class TestTermVectors extends LuceneTestCase {
   public void testTermOffsetVectors() {
     Query query = new TermQuery(new Term("field", "fifty"));
     try {
-      Hits hits = searcher.search(query);
-      assertEquals(100, hits.length());
+      ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+      assertEquals(100, hits.length);
       
-      for (int i = 0; i < hits.length(); i++)
+      for (int i = 0; i < hits.length; i++)
       {
-        TermFreqVector [] vector = searcher.reader.getTermFreqVectors(hits.id(i));
+        TermFreqVector [] vector = searcher.reader.getTermFreqVectors(hits[i].doc);
         assertTrue(vector != null);
         assertTrue(vector.length == 1);
         
@@ -279,20 +279,20 @@ public class TestTermVectors extends LuceneTestCase {
         //System.out.println("--------");
       }
       Query query = new TermQuery(new Term("field", "chocolate"));
-      Hits hits = knownSearcher.search(query);
+      ScoreDoc[] hits = knownSearcher.search(query, null, 1000).scoreDocs;
       //doc 3 should be the first hit b/c it is the shortest match
-      assertTrue(hits.length() == 3);
-      float score = hits.score(0);
+      assertTrue(hits.length == 3);
+      float score = hits[0].score;
       /*System.out.println("Hit 0: " + hits.id(0) + " Score: " + hits.score(0) + " String: " + hits.doc(0).toString());
       System.out.println("Explain: " + knownSearcher.explain(query, hits.id(0)));
       System.out.println("Hit 1: " + hits.id(1) + " Score: " + hits.score(1) + " String: " + hits.doc(1).toString());
       System.out.println("Explain: " + knownSearcher.explain(query, hits.id(1)));
       System.out.println("Hit 2: " + hits.id(2) + " Score: " + hits.score(2) + " String: " +  hits.doc(2).toString());
       System.out.println("Explain: " + knownSearcher.explain(query, hits.id(2)));*/
-      assertTrue(hits.id(0) == 2);
-      assertTrue(hits.id(1) == 3);
-      assertTrue(hits.id(2) == 0);
-      TermFreqVector vector = knownSearcher.reader.getTermFreqVector(hits.id(1), "field");
+      assertTrue(hits[0].doc == 2);
+      assertTrue(hits[1].doc == 3);
+      assertTrue(hits[2].doc == 0);
+      TermFreqVector vector = knownSearcher.reader.getTermFreqVector(hits[1].doc, "field");
       assertTrue(vector != null);
       //System.out.println("Vector: " + vector);
       String[] terms = vector.getTerms();
@@ -308,7 +308,7 @@ public class TestTermVectors extends LuceneTestCase {
         assertTrue(freqInt.intValue() == freq);        
       }
       SortedTermVectorMapper mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());
-      knownSearcher.reader.getTermFreqVector(hits.id(1), mapper);
+      knownSearcher.reader.getTermFreqVector(hits[1].doc, mapper);
       SortedSet vectorEntrySet = mapper.getTermVectorEntrySet();
       assertTrue("mapper.getTermVectorEntrySet() Size: " + vectorEntrySet.size() + " is not: " + 10, vectorEntrySet.size() == 10);
       TermVectorEntry last = null;
@@ -326,7 +326,7 @@ public class TestTermVectors extends LuceneTestCase {
       }
 
       FieldSortedTermVectorMapper fieldMapper = new FieldSortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());
-      knownSearcher.reader.getTermFreqVector(hits.id(1), fieldMapper);
+      knownSearcher.reader.getTermFreqVector(hits[1].doc, fieldMapper);
       Map map = fieldMapper.getFieldToTerms();
       assertTrue("map Size: " + map.size() + " is not: " + 2, map.size() == 2);
       vectorEntrySet = (SortedSet) map.get("field");
@@ -369,10 +369,10 @@ public class TestTermVectors extends LuceneTestCase {
     searcher = new IndexSearcher(directory);
 
     Query query = new TermQuery(new Term("field", "hundred"));
-    Hits hits = searcher.search(query);
-    assertEquals(10, hits.length());
-    for (int i = 0; i < hits.length(); i++) {
-      TermFreqVector [] vector = searcher.reader.getTermFreqVectors(hits.id(i));
+    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(10, hits.length);
+    for (int i = 0; i < hits.length; i++) {
+      TermFreqVector [] vector = searcher.reader.getTermFreqVectors(hits[i].doc);
       assertTrue(vector != null);
       assertTrue(vector.length == 1);
     }
@@ -401,10 +401,10 @@ public class TestTermVectors extends LuceneTestCase {
     searcher = new IndexSearcher(directory);
 
     Query query = new TermQuery(new Term("field", "one"));
-    Hits hits = searcher.search(query);
-    assertEquals(1, hits.length());
+    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    assertEquals(1, hits.length);
 
-    TermFreqVector [] vector = searcher.reader.getTermFreqVectors(hits.id(0));
+    TermFreqVector [] vector = searcher.reader.getTermFreqVectors(hits[0].doc);
     assertTrue(vector != null);
     assertTrue(vector.length == 1);
     TermPositionVector tfv = (TermPositionVector) vector[0];
diff --git a/src/test/org/apache/lucene/search/TestTimeLimitedCollector.java b/src/test/org/apache/lucene/search/TestTimeLimitedCollector.java
index 7907043..4dea674 100755
--- a/src/test/org/apache/lucene/search/TestTimeLimitedCollector.java
+++ b/src/test/org/apache/lucene/search/TestTimeLimitedCollector.java
@@ -86,7 +86,7 @@ public class TestTimeLimitedCollector extends LuceneTestCase {
     query = queryParser.parse(qtxt);
     
     // warm the searcher
-    searcher.search(query);
+    searcher.search(query, null, 1000);
 
   }
 
diff --git a/src/test/org/apache/lucene/search/TestWildcard.java b/src/test/org/apache/lucene/search/TestWildcard.java
index 43cd1e9..4258546 100644
--- a/src/test/org/apache/lucene/search/TestWildcard.java
+++ b/src/test/org/apache/lucene/search/TestWildcard.java
@@ -153,8 +153,8 @@ public class TestWildcard
 
   private void assertMatches(IndexSearcher searcher, Query q, int expectedMatches)
       throws IOException {
-    Hits result = searcher.search(q);
-    assertEquals(expectedMatches, result.length());
+    ScoreDoc[] result = searcher.search(q, null, 1000).scoreDocs;
+    assertEquals(expectedMatches, result.length);
   }
 
   /**
@@ -212,8 +212,8 @@ public class TestWildcard
       String qtxt = matchAll[i];
       Query q = qp.parse(qtxt);
       if (dbg) System.out.println("matchAll: qtxt="+qtxt+" q="+q+" "+q.getClass().getName());
-      Hits hits = searcher.search(q);
-      assertEquals(docs.length,hits.length());
+      ScoreDoc[] hits = searcher.search(q, null, 1000).scoreDocs;
+      assertEquals(docs.length,hits.length);
     }
     
     // test queries that must find none
@@ -221,8 +221,8 @@ public class TestWildcard
       String qtxt = matchNone[i];
       Query q = qp.parse(qtxt);
       if (dbg) System.out.println("matchNone: qtxt="+qtxt+" q="+q+" "+q.getClass().getName());
-      Hits hits = searcher.search(q);
-      assertEquals(0,hits.length());
+      ScoreDoc[] hits = searcher.search(q, null, 1000).scoreDocs;
+      assertEquals(0,hits.length);
     }
 
     // test queries that must be prefix queries and must find only one doc
@@ -232,9 +232,9 @@ public class TestWildcard
         Query q = qp.parse(qtxt);
         if (dbg) System.out.println("match 1 prefix: doc="+docs[i]+" qtxt="+qtxt+" q="+q+" "+q.getClass().getName());
         assertEquals(PrefixQuery.class, q.getClass());
-        Hits hits = searcher.search(q);
-        assertEquals(1,hits.length());
-        assertEquals(i,hits.id(0));
+        ScoreDoc[] hits = searcher.search(q, null, 1000).scoreDocs;
+        assertEquals(1,hits.length);
+        assertEquals(i,hits[0].doc);
       }
     }
 
@@ -245,9 +245,9 @@ public class TestWildcard
         Query q = qp.parse(qtxt);
         if (dbg) System.out.println("match 1 wild: doc="+docs[i]+" qtxt="+qtxt+" q="+q+" "+q.getClass().getName());
         assertEquals(WildcardQuery.class, q.getClass());
-        Hits hits = searcher.search(q);
-        assertEquals(1,hits.length());
-        assertEquals(i,hits.id(0));
+        ScoreDoc[] hits = searcher.search(q, null, 1000).scoreDocs;
+        assertEquals(1,hits.length);
+        assertEquals(i,hits[0].doc);
       }
     }
 
diff --git a/src/test/org/apache/lucene/search/function/TestFieldScoreQuery.java b/src/test/org/apache/lucene/search/function/TestFieldScoreQuery.java
index 4d7f70a..8a25f63 100755
--- a/src/test/org/apache/lucene/search/function/TestFieldScoreQuery.java
+++ b/src/test/org/apache/lucene/search/function/TestFieldScoreQuery.java
@@ -17,11 +17,9 @@ package org.apache.lucene.search.function;
  * limitations under the License.
  */
 
-import java.io.ObjectInputStream.GetField;
 import java.util.HashMap;
 
 import org.apache.lucene.index.CorruptIndexException;
-import org.apache.lucene.search.Hits;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.QueryUtils;
@@ -88,13 +86,13 @@ public class TestFieldScoreQuery extends FunctionTestSetup {
     Query q = new FieldScoreQuery(field,tp);
     log("test: "+q);
     QueryUtils.check(q,s);
-    Hits h = s.search(q);
-    assertEquals("All docs should be matched!",N_DOCS,h.length());
+    ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
+    assertEquals("All docs should be matched!",N_DOCS,h.length);
     String prevID = "ID"+(N_DOCS+1); // greater than all ids of docs in this test
-    for (int i=0; i<h.length(); i++) {
-      String resID = h.doc(i).get(ID_FIELD);
-      log(i+".   score="+h.score(i)+"  -  "+resID);
-      log(s.explain(q,h.id(i)));
+    for (int i=0; i<h.length; i++) {
+      String resID = s.doc(h[i].doc).get(ID_FIELD);
+      log(i+".   score="+h[i].score+"  -  "+resID);
+      log(s.explain(q,h[i].doc));
       assertTrue("res id "+resID+" should be < prev res id "+prevID, resID.compareTo(prevID)<0);
       prevID = resID;
     }
@@ -181,8 +179,8 @@ public class TestFieldScoreQuery extends FunctionTestSetup {
     boolean warned = false; // print warning once.
     for (int i=0; i<10; i++) {
       FieldScoreQuery q = new FieldScoreQuery(field,tp);
-      Hits h = s.search(q);
-      assertEquals("All docs should be matched!",N_DOCS,h.length());
+      ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
+      assertEquals("All docs should be matched!",N_DOCS,h.length);
       try {
         if (i==0) {
           innerArray = q.valSrc.getValues(s.getIndexReader()).getInnerArray();
@@ -203,8 +201,8 @@ public class TestFieldScoreQuery extends FunctionTestSetup {
     // verify new values are reloaded (not reused) for a new reader
     s = new IndexSearcher(dir);
     FieldScoreQuery q = new FieldScoreQuery(field,tp);
-    Hits h = s.search(q);
-    assertEquals("All docs should be matched!",N_DOCS,h.length());
+    ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
+    assertEquals("All docs should be matched!",N_DOCS,h.length);
     try {
       log("compare: "+innerArray+" to "+q.valSrc.getValues(s.getIndexReader()).getInnerArray());
       assertNotSame("cached field values should not be reused if reader as changed!", innerArray, q.valSrc.getValues(s.getIndexReader()).getInnerArray());
diff --git a/src/test/org/apache/lucene/search/function/TestOrdValues.java b/src/test/org/apache/lucene/search/function/TestOrdValues.java
index 64c0cd4..75cdf24 100644
--- a/src/test/org/apache/lucene/search/function/TestOrdValues.java
+++ b/src/test/org/apache/lucene/search/function/TestOrdValues.java
@@ -18,7 +18,6 @@ package org.apache.lucene.search.function;
  */
 
 import org.apache.lucene.index.CorruptIndexException;
-import org.apache.lucene.search.Hits;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.QueryUtils;
@@ -77,16 +76,16 @@ public class TestOrdValues extends FunctionTestSetup {
     Query q = new ValueSourceQuery(vs);
     log("test: "+q);
     QueryUtils.check(q,s);
-    Hits h = s.search(q);
-    assertEquals("All docs should be matched!",N_DOCS,h.length());
+    ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
+    assertEquals("All docs should be matched!",N_DOCS,h.length);
     String prevID = inOrder
       ? "IE"   // greater than all ids of docs in this test ("ID0001", etc.)
       : "IC";  // smaller than all ids of docs in this test ("ID0001", etc.)
           
-    for (int i=0; i<h.length(); i++) {
-      String resID = h.doc(i).get(ID_FIELD);
-      log(i+".   score="+h.score(i)+"  -  "+resID);
-      log(s.explain(q,h.id(i)));
+    for (int i=0; i<h.length; i++) {
+      String resID = s.doc(h[i].doc).get(ID_FIELD);
+      log(i+".   score="+h[i].score+"  -  "+resID);
+      log(s.explain(q,h[i].doc));
       if (inOrder) {
         assertTrue("res id "+resID+" should be < prev res id "+prevID, resID.compareTo(prevID)<0);
       } else {
@@ -159,9 +158,9 @@ public class TestOrdValues extends FunctionTestSetup {
         vs = new ReverseOrdFieldSource(field);
       }
       ValueSourceQuery q = new ValueSourceQuery(vs);
-      Hits h = s.search(q);
+      ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
       try {
-        assertEquals("All docs should be matched!",N_DOCS,h.length());
+        assertEquals("All docs should be matched!",N_DOCS,h.length);
         if (i==0) {
           innerArray = q.valSrc.getValues(s.getIndexReader()).getInnerArray();
         } else {
@@ -178,7 +177,7 @@ public class TestOrdValues extends FunctionTestSetup {
     
     ValueSource vs;
     ValueSourceQuery q;
-    Hits h;
+    ScoreDoc[] h;
     
     // verify that different values are loaded for a different field
     String field2 = INT_FIELD;
@@ -189,8 +188,8 @@ public class TestOrdValues extends FunctionTestSetup {
       vs = new ReverseOrdFieldSource(field2);
     }
     q = new ValueSourceQuery(vs);
-    h = s.search(q);
-    assertEquals("All docs should be matched!",N_DOCS,h.length());
+    h = s.search(q, null, 1000).scoreDocs;
+    assertEquals("All docs should be matched!",N_DOCS,h.length);
     try {
       log("compare (should differ): "+innerArray+" to "+q.valSrc.getValues(s.getIndexReader()).getInnerArray());
       assertNotSame("different values shuold be loaded for a different field!", innerArray, q.valSrc.getValues(s.getIndexReader()).getInnerArray());
@@ -209,8 +208,8 @@ public class TestOrdValues extends FunctionTestSetup {
       vs = new ReverseOrdFieldSource(field);
     }
     q = new ValueSourceQuery(vs);
-    h = s.search(q);
-    assertEquals("All docs should be matched!",N_DOCS,h.length());
+    h = s.search(q, null, 1000).scoreDocs;
+    assertEquals("All docs should be matched!",N_DOCS,h.length);
     try {
       log("compare (should differ): "+innerArray+" to "+q.valSrc.getValues(s.getIndexReader()).getInnerArray());
       assertNotSame("cached field values should not be reused if reader as changed!", innerArray, q.valSrc.getValues(s.getIndexReader()).getInnerArray());
diff --git a/src/test/org/apache/lucene/store/TestBufferedIndexInput.java b/src/test/org/apache/lucene/store/TestBufferedIndexInput.java
index af1773d..e45cdb9 100755
--- a/src/test/org/apache/lucene/store/TestBufferedIndexInput.java
+++ b/src/test/org/apache/lucene/store/TestBufferedIndexInput.java
@@ -17,24 +17,24 @@ package org.apache.lucene.store;
  * limitations under the License.
  */
 
-import java.io.IOException;
 import java.io.File;
-import java.util.List;
-import java.util.Random;
+import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Iterator;
-import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.IndexSearcher;
+import java.util.List;
+import java.util.Random;
+
 import org.apache.lucene.analysis.WhitespaceAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
-import org.apache.lucene.search.Hits;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.IndexWriter;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.TermQuery;
-import org.apache.lucene.util._TestUtil;
-
 import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util._TestUtil;
 
 public class TestBufferedIndexInput extends LuceneTestCase {
 	// Call readByte() repeatedly, past the buffer boundary, and see that it
@@ -184,16 +184,16 @@ public class TestBufferedIndexInput extends LuceneTestCase {
         dir.tweakBufferSizes();
 
         IndexSearcher searcher = new IndexSearcher(reader);
-        Hits hits = searcher.search(new TermQuery(bbb));
+        ScoreDoc[] hits = searcher.search(new TermQuery(bbb), null, 1000).scoreDocs;
         dir.tweakBufferSizes();
-        assertEquals(35, hits.length());
+        assertEquals(35, hits.length);
         dir.tweakBufferSizes();
-        hits = searcher.search(new TermQuery(new Term("id", "33")));
+        hits = searcher.search(new TermQuery(new Term("id", "33")), null, 1000).scoreDocs;
         dir.tweakBufferSizes();
-        assertEquals(1, hits.length());
-        hits = searcher.search(new TermQuery(aaa));
+        assertEquals(1, hits.length);
+        hits = searcher.search(new TermQuery(aaa), null, 1000).scoreDocs;
         dir.tweakBufferSizes();
-        assertEquals(35, hits.length());
+        assertEquals(35, hits.length);
         searcher.close();
         reader.close();
       } finally {
diff --git a/src/test/org/apache/lucene/store/TestLockFactory.java b/src/test/org/apache/lucene/store/TestLockFactory.java
index 900a949..be12690 100755
--- a/src/test/org/apache/lucene/store/TestLockFactory.java
+++ b/src/test/org/apache/lucene/store/TestLockFactory.java
@@ -17,24 +17,21 @@ package org.apache.lucene.store;
  * limitations under the License.
  */
 
-import org.apache.lucene.util.LuceneTestCase;
-
-import java.util.Hashtable;
-import java.util.Enumeration;
-
-import java.io.IOException;
 import java.io.File;
+import java.io.IOException;
+import java.util.Enumeration;
+import java.util.Hashtable;
 
+import org.apache.lucene.analysis.WhitespaceAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
-import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexWriter;
+import org.apache.lucene.index.Term;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
-import org.apache.lucene.index.Term;
+import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.TermQuery;
-import org.apache.lucene.search.Hits;
-import org.apache.lucene.analysis.WhitespaceAnalyzer;
+import org.apache.lucene.util.LuceneTestCase;
 
 public class TestLockFactory extends LuceneTestCase {
 
@@ -498,9 +495,9 @@ public class TestLockFactory extends LuceneTestCase {
                     break;
                 }
                 if (searcher != null) {
-                    Hits hits = null;
+                    ScoreDoc[] hits = null;
                     try {
-                        hits = searcher.search(query);
+                        hits = searcher.search(query, null, 1000).scoreDocs;
                     } catch (IOException e) {
                         hitException = true;
                         System.out.println("Stress Test Index Searcher: search hit unexpected exception: " + e.toString());

