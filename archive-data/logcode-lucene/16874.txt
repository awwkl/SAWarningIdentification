GitDiffStart: 399c93850c5a80cf2f6ddd2491bc9656daa8119a | Tue Nov 30 14:45:45 2010 +0000
diff --git a/lucene/src/java/org/apache/lucene/index/DocFieldProcessor.java b/lucene/src/java/org/apache/lucene/index/DocFieldProcessor.java
index 1eeeacb..4b37b04 100644
--- a/lucene/src/java/org/apache/lucene/index/DocFieldProcessor.java
+++ b/lucene/src/java/org/apache/lucene/index/DocFieldProcessor.java
@@ -64,6 +64,7 @@ final class DocFieldProcessor extends DocConsumer {
       }
       valuesConsumer = fieldsConsumer.addValuesField(fieldInfo);
       docValues.put(name, valuesConsumer);
+      
     }
     return valuesConsumer;
 
diff --git a/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java b/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
index 175ab09..296c57a 100644
--- a/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
+++ b/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
@@ -604,14 +604,14 @@ final class DocumentsWriter {
     initSegmentName(onlyDocStore);
     final SegmentCodecs info = SegmentCodecs.build(docFieldProcessor.fieldInfos, writer.codecs);
     flushState = new SegmentWriteState(infoStream, directory, segment, docFieldProcessor.fieldInfos,
-                                       docStoreSegment, numDocsInRAM, numDocsInStore, writer.getConfig().getTermIndexInterval(), info);
+                                       docStoreSegment, numDocsInRAM, numDocsInStore, writer.getConfig().getTermIndexInterval(), info, bytesUsed);
   }
   
   SegmentWriteState segWriteState() { 
     final SegmentCodecs info = SegmentCodecs.build(docFieldProcessor.fieldInfos, writer.codecs);
     return new SegmentWriteState(infoStream, directory, segment, docFieldProcessor.fieldInfos,
         docStoreSegment, numDocsInRAM, numDocsInStore, writer.getConfig().getTermIndexInterval(),
-        info);
+        info, bytesUsed);
   }
 
   /** Returns the SegmentCodecs used to flush the last segment */
diff --git a/lucene/src/java/org/apache/lucene/index/SegmentMerger.java b/lucene/src/java/org/apache/lucene/index/SegmentMerger.java
index 05ded0a..d66de3d 100644
--- a/lucene/src/java/org/apache/lucene/index/SegmentMerger.java
+++ b/lucene/src/java/org/apache/lucene/index/SegmentMerger.java
@@ -23,6 +23,7 @@ import java.util.Collection;
 import java.util.Set;
 import java.util.HashSet;
 import java.util.List;
+import java.util.concurrent.atomic.AtomicLong;
 
 import org.apache.lucene.document.Document;
 import org.apache.lucene.index.IndexReader.FieldOption;
@@ -366,7 +367,7 @@ final class SegmentMerger {
       }
     }
 
-    segmentWriteState = new SegmentWriteState(null, directory, segment, fieldInfos, null, docCount, 0, termIndexInterval, codecInfo);
+    segmentWriteState = new SegmentWriteState(null, directory, segment, fieldInfos, null, docCount, 0, termIndexInterval, codecInfo, new AtomicLong(0));
     
     return docCount;
   }
diff --git a/lucene/src/java/org/apache/lucene/index/SegmentWriteState.java b/lucene/src/java/org/apache/lucene/index/SegmentWriteState.java
index 427e6ba..30d8db6 100644
--- a/lucene/src/java/org/apache/lucene/index/SegmentWriteState.java
+++ b/lucene/src/java/org/apache/lucene/index/SegmentWriteState.java
@@ -20,6 +20,7 @@ package org.apache.lucene.index;
 import java.io.PrintStream;
 import java.util.Collection;
 import java.util.HashSet;
+import java.util.concurrent.atomic.AtomicLong;
 
 import org.apache.lucene.store.Directory;
 
@@ -35,6 +36,7 @@ public class SegmentWriteState {
   public final int numDocs;
   public int numDocsInStore;
   public final Collection<String> flushedFiles;
+  public final AtomicLong bytesUsed;
 
   final SegmentCodecs segmentCodecs;
   public final String codecId;
@@ -62,7 +64,7 @@ public class SegmentWriteState {
 
   public SegmentWriteState(PrintStream infoStream, Directory directory, String segmentName, FieldInfos fieldInfos,
                            String docStoreSegmentName, int numDocs,
-                           int numDocsInStore, int termIndexInterval, SegmentCodecs segmentCodecs) {
+                           int numDocsInStore, int termIndexInterval, SegmentCodecs segmentCodecs, AtomicLong bytesUsed) {
     this.infoStream = infoStream;
     this.directory = directory;
     this.segmentName = segmentName;
@@ -74,6 +76,7 @@ public class SegmentWriteState {
     this.segmentCodecs = segmentCodecs;
     flushedFiles = new HashSet<String>();
     codecId = "";
+    this.bytesUsed = bytesUsed;
   }
   
   /**
@@ -91,5 +94,6 @@ public class SegmentWriteState {
     segmentCodecs = state.segmentCodecs;
     flushedFiles = state.flushedFiles;
     this.codecId = codecId;
+    bytesUsed = state.bytesUsed;
   }
 }
diff --git a/lucene/src/java/org/apache/lucene/index/codecs/FieldsConsumer.java b/lucene/src/java/org/apache/lucene/index/codecs/FieldsConsumer.java
index e4e29b7..27d1a87 100644
--- a/lucene/src/java/org/apache/lucene/index/codecs/FieldsConsumer.java
+++ b/lucene/src/java/org/apache/lucene/index/codecs/FieldsConsumer.java
@@ -44,7 +44,7 @@ public abstract class FieldsConsumer implements Closeable {
   public abstract TermsConsumer addField(FieldInfo field) throws IOException;
   
   /** Adds a new DocValuesField */
-  public /*abstract*/ DocValuesConsumer addValuesField(FieldInfo field) throws IOException {
+  public DocValuesConsumer addValuesField(FieldInfo field) throws IOException {
     throw new UnsupportedOperationException("docvalues are not supported");
   }
   
diff --git a/lucene/src/java/org/apache/lucene/index/codecs/docvalues/DocValuesCodec.java b/lucene/src/java/org/apache/lucene/index/codecs/docvalues/DocValuesCodec.java
index 2a4a880..43264f6 100644
--- a/lucene/src/java/org/apache/lucene/index/codecs/docvalues/DocValuesCodec.java
+++ b/lucene/src/java/org/apache/lucene/index/codecs/docvalues/DocValuesCodec.java
@@ -22,6 +22,7 @@ import java.util.HashSet;
 import java.util.Iterator;
 import java.util.Set;
 import java.util.Map.Entry;
+import java.util.concurrent.atomic.AtomicLong;
 
 import org.apache.lucene.index.FieldInfo;
 import org.apache.lucene.index.FieldsEnum;
@@ -107,7 +108,7 @@ public class DocValuesCodec extends Codec {
           + field.number),
       // TODO can we have a compound file per segment and codec for
           // docvalues?
-          state.directory, field, comparator);
+          state.directory, field, comparator, state.bytesUsed);
       info.add(field.number);
       return consumer;
     }
diff --git a/lucene/src/java/org/apache/lucene/index/codecs/docvalues/DocValuesConsumer.java b/lucene/src/java/org/apache/lucene/index/codecs/docvalues/DocValuesConsumer.java
index 5f9cd97..2a6a7c7a 100644
--- a/lucene/src/java/org/apache/lucene/index/codecs/docvalues/DocValuesConsumer.java
+++ b/lucene/src/java/org/apache/lucene/index/codecs/docvalues/DocValuesConsumer.java
@@ -19,6 +19,7 @@ package org.apache.lucene.index.codecs.docvalues;
 import java.io.IOException;
 import java.util.Collection;
 import java.util.Comparator;
+import java.util.concurrent.atomic.AtomicLong;
 
 import org.apache.lucene.index.FieldInfo;
 import org.apache.lucene.index.IndexReader;
@@ -35,6 +36,16 @@ import org.apache.lucene.util.BytesRef;
 // TODO this might need to go in the codec package since is a direct relative to
 // TermsConsumer
 public abstract class DocValuesConsumer {
+  
+  protected AtomicLong bytesUsed = new AtomicLong(0);
+  
+  protected DocValuesConsumer(AtomicLong bytesUsed) {
+    this.bytesUsed = bytesUsed;
+  }
+
+  public final long bytesUsed() {
+    return this.bytesUsed.get();
+  }
 
   public abstract void add(int docID, ValuesAttribute attr) throws IOException;
 
@@ -89,8 +100,8 @@ public abstract class DocValuesConsumer {
   }
 
   public static DocValuesConsumer create(String id,
-      Directory directory, FieldInfo field, Comparator<BytesRef> comp)
+      Directory directory, FieldInfo field, Comparator<BytesRef> comp, AtomicLong bytesUsed)
       throws IOException {
-    return Writer.create(field.getDocValues(), id, directory, comp);
+    return Writer.create(field.getDocValues(), id, directory, comp, bytesUsed);
   }
 }
diff --git a/lucene/src/java/org/apache/lucene/index/values/Bytes.java b/lucene/src/java/org/apache/lucene/index/values/Bytes.java
index f9eeff5..89cd344 100644
--- a/lucene/src/java/org/apache/lucene/index/values/Bytes.java
+++ b/lucene/src/java/org/apache/lucene/index/values/Bytes.java
@@ -24,7 +24,7 @@ import java.util.Comparator;
 import java.util.concurrent.atomic.AtomicLong;
 
 import org.apache.lucene.index.IndexFileNames;
-import org.apache.lucene.index.values.DocValues.MissingValues;
+import org.apache.lucene.index.values.DocValues.MissingValue;
 import org.apache.lucene.index.values.DocValues.SortedSource;
 import org.apache.lucene.index.values.DocValues.Source;
 import org.apache.lucene.index.values.DocValues.SourceEnum;
@@ -64,7 +64,7 @@ public final class Bytes {
   // TODO -- i shouldn't have to specify fixed? can
   // track itself & do the write thing at write time?
   public static Writer getWriter(Directory dir, String id, Mode mode,
-      Comparator<BytesRef> comp, boolean fixedSize) throws IOException {
+      Comparator<BytesRef> comp, boolean fixedSize, AtomicLong bytesUsed) throws IOException {
 
     if (comp == null) {
       comp = BytesRef.getUTF8SortedAsUnicodeComparator();
@@ -74,17 +74,17 @@ public final class Bytes {
       if (mode == Mode.STRAIGHT) {
         return new FixedStraightBytesImpl.Writer(dir, id);
       } else if (mode == Mode.DEREF) {
-        return new FixedDerefBytesImpl.Writer(dir, id);
+        return new FixedDerefBytesImpl.Writer(dir, id, bytesUsed);
       } else if (mode == Mode.SORTED) {
-        return new FixedSortedBytesImpl.Writer(dir, id, comp);
+        return new FixedSortedBytesImpl.Writer(dir, id, comp, bytesUsed);
       }
     } else {
       if (mode == Mode.STRAIGHT) {
-        return new VarStraightBytesImpl.Writer(dir, id);
+        return new VarStraightBytesImpl.Writer(dir, id, bytesUsed);
       } else if (mode == Mode.DEREF) {
-        return new VarDerefBytesImpl.Writer(dir, id);
+        return new VarDerefBytesImpl.Writer(dir, id, bytesUsed);
       } else if (mode == Mode.SORTED) {
-        return new VarSortedBytesImpl.Writer(dir, id, comp);
+        return new VarSortedBytesImpl.Writer(dir, id, comp, bytesUsed);
       }
     }
 
@@ -162,7 +162,7 @@ public final class Bytes {
 
     @Override
     public ValuesEnum getEnum(AttributeSource attrSource) throws IOException {
-      final MissingValues missing = getMissing();
+      final MissingValue missing = getMissing();
       return new SourceEnum(attrSource, type(), this, maxDoc()) {
         final BytesRef bytesRef = attr.bytes();
 
@@ -248,7 +248,7 @@ public final class Bytes {
 
     @Override
     public ValuesEnum getEnum(AttributeSource attrSource) throws IOException {
-      final MissingValues missing = getMissing();
+      final MissingValue missing = getMissing();
       return new SourceEnum(attrSource, type(), this, maxDoc()) {
         final BytesRef bytesRef = attr.bytes();
 
@@ -275,20 +275,19 @@ public final class Bytes {
     protected IndexOutput idxOut;
     protected IndexOutput datOut;
     protected BytesRef bytesRef;
-    private String codecName;
-    private int version;
+    private final String codecName;
+    private final int version;
     protected final ByteBlockPool pool;
-    protected final AtomicLong bytesUsed;
 
     protected BytesWriterBase(Directory dir, String id, String codecName,
         int version, boolean initIndex, boolean initData, ByteBlockPool pool,
         AtomicLong bytesUsed) throws IOException {
+      super(bytesUsed);
       this.dir = dir;
       this.id = id;
       this.codecName = codecName;
       this.version = version;
       this.pool = pool;
-      this.bytesUsed = bytesUsed;
       if (initData)
         initDataOut();
       if (initIndex)
diff --git a/lucene/src/java/org/apache/lucene/index/values/DocValues.java b/lucene/src/java/org/apache/lucene/index/values/DocValues.java
index a0d84ff..d734d5e 100644
--- a/lucene/src/java/org/apache/lucene/index/values/DocValues.java
+++ b/lucene/src/java/org/apache/lucene/index/values/DocValues.java
@@ -70,7 +70,7 @@ public abstract class DocValues implements Closeable {
    * used since it can handle all precisions.
    */
   public static abstract class Source {
-    protected final MissingValues missingValues = new MissingValues();
+    protected final MissingValue missingValue = new MissingValue();
 
     public long getInt(int docID) {
       throw new UnsupportedOperationException("ints are not supported");
@@ -96,8 +96,8 @@ public abstract class DocValues implements Closeable {
       return getEnum(new AttributeSource());
     }
     
-    public MissingValues getMissing() {
-      return missingValues;
+    public MissingValue getMissing() {
+      return missingValue;
     }
     
     public abstract Values type();
@@ -105,8 +105,6 @@ public abstract class DocValues implements Closeable {
     public abstract ValuesEnum getEnum(AttributeSource attrSource)
         throws IOException;
 
-    public abstract long ramBytesUsed();
-    
   }
 
   abstract static class SourceEnum extends ValuesEnum {
@@ -171,12 +169,12 @@ public abstract class DocValues implements Closeable {
     public abstract LookupResult getByValue(BytesRef value, BytesRef tmpRef);
   }
   
-  public final static class MissingValues {
+  public final static class MissingValue {
     public long longValue;
     public double doubleValue;
     public BytesRef bytesValue;
     
-    public final void copy(MissingValues values) {
+    public final void copy(MissingValue values) {
       longValue = values.longValue;
       doubleValue = values.doubleValue;
       bytesValue = values.bytesValue;
diff --git a/lucene/src/java/org/apache/lucene/index/values/FixedDerefBytesImpl.java b/lucene/src/java/org/apache/lucene/index/values/FixedDerefBytesImpl.java
index 06a322b..f5df15d 100644
--- a/lucene/src/java/org/apache/lucene/index/values/FixedDerefBytesImpl.java
+++ b/lucene/src/java/org/apache/lucene/index/values/FixedDerefBytesImpl.java
@@ -34,6 +34,7 @@ import org.apache.lucene.util.PagedBytes;
 import org.apache.lucene.util.RamUsageEstimator;
 import org.apache.lucene.util.ByteBlockPool.Allocator;
 import org.apache.lucene.util.ByteBlockPool.DirectAllocator;
+import org.apache.lucene.util.BytesRefHash.TrackingDirectBytesStartArray;
 import org.apache.lucene.util.packed.PackedInts;
 
 // Stores fixed-length byte[] by deref, ie when two docs
@@ -48,11 +49,12 @@ class FixedDerefBytesImpl {
   static class Writer extends BytesWriterBase {
     private int size = -1;
     private int[] docToID;
-    private final BytesRefHash hash = new BytesRefHash(pool);
+    private final BytesRefHash hash = new BytesRefHash(pool, BytesRefHash.DEFAULT_CAPACITY,
+        new TrackingDirectBytesStartArray(BytesRefHash.DEFAULT_CAPACITY, bytesUsed));
 
-    public Writer(Directory dir, String id) throws IOException {
+    public Writer(Directory dir, String id, AtomicLong bytesUsed) throws IOException {
       this(dir, id, new DirectAllocator(ByteBlockPool.BYTE_BLOCK_SIZE),
-          new AtomicLong());
+          bytesUsed);
     }
 
     public Writer(Directory dir, String id, Allocator allocator,
@@ -60,7 +62,7 @@ class FixedDerefBytesImpl {
       super(dir, id, CODEC_NAME, VERSION_CURRENT, false, false,
           new ByteBlockPool(allocator), bytesUsed);
       docToID = new int[1];
-      bytesUsed.addAndGet(RamUsageEstimator.NUM_BYTES_INT);
+      bytesUsed.addAndGet(RamUsageEstimator.NUM_BYTES_INT); // TODO BytesRefHash uses bytes too!
     }
 
     @Override
@@ -85,7 +87,7 @@ class FixedDerefBytesImpl {
       }
 
       if (docID >= docToID.length) {
-        int size = docToID.length;
+        final int size = docToID.length;
         docToID = ArrayUtil.grow(docToID, 1 + docID);
         bytesUsed.addAndGet((docToID.length - size)
             * RamUsageEstimator.NUM_BYTES_INT);
@@ -114,9 +116,11 @@ class FixedDerefBytesImpl {
         w.add(0);
       }
       w.finish();
-      hash.clear();
-
+      hash.close();
       super.finish(docCount);
+      bytesUsed.addAndGet((-docToID.length)
+          * RamUsageEstimator.NUM_BYTES_INT);
+      docToID = null;
     }
   }
 
diff --git a/lucene/src/java/org/apache/lucene/index/values/FixedSortedBytesImpl.java b/lucene/src/java/org/apache/lucene/index/values/FixedSortedBytesImpl.java
index e826a70..f19ac89 100644
--- a/lucene/src/java/org/apache/lucene/index/values/FixedSortedBytesImpl.java
+++ b/lucene/src/java/org/apache/lucene/index/values/FixedSortedBytesImpl.java
@@ -37,6 +37,7 @@ import org.apache.lucene.util.PagedBytes;
 import org.apache.lucene.util.RamUsageEstimator;
 import org.apache.lucene.util.ByteBlockPool.Allocator;
 import org.apache.lucene.util.ByteBlockPool.DirectAllocator;
+import org.apache.lucene.util.BytesRefHash.TrackingDirectBytesStartArray;
 import org.apache.lucene.util.packed.PackedInts;
 
 // Stores fixed-length byte[] by deref, ie when two docs
@@ -53,12 +54,13 @@ class FixedSortedBytesImpl {
     private int[] docToEntry;
     private final Comparator<BytesRef> comp;
 
-    private final BytesRefHash hash = new BytesRefHash(pool);
+    private final BytesRefHash hash = new BytesRefHash(pool, BytesRefHash.DEFAULT_CAPACITY,
+        new TrackingDirectBytesStartArray(BytesRefHash.DEFAULT_CAPACITY, bytesUsed));
 
-    public Writer(Directory dir, String id, Comparator<BytesRef> comp)
+    public Writer(Directory dir, String id, Comparator<BytesRef> comp, AtomicLong bytesUsed)
         throws IOException {
       this(dir, id, comp, new DirectAllocator(ByteBlockPool.BYTE_BLOCK_SIZE),
-          new AtomicLong());
+          bytesUsed);
     }
 
     public Writer(Directory dir, String id, Comparator<BytesRef> comp,
@@ -148,6 +150,7 @@ class FixedSortedBytesImpl {
       bytesUsed.addAndGet((-docToEntry.length)
           * RamUsageEstimator.NUM_BYTES_INT);
       docToEntry = null;
+      hash.close();
     }
   }
 
@@ -199,16 +202,6 @@ class FixedSortedBytesImpl {
         return binarySearch(bytes, tmpRef, 0, numValue - 1);
       }
 
-      public long ramBytesUsed() {
-        // TODO(simonw): move ram calcultation to PackedInts?
-        return RamUsageEstimator.NUM_BYTES_ARRAY_HEADER
-            + size
-            * numValue
-            + (RamUsageEstimator.NUM_BYTES_ARRAY_HEADER + index
-                .getBitsPerValue()
-                * index.size());
-      }
-
       @Override
       public int getValueCount() {
         return numValue;
diff --git a/lucene/src/java/org/apache/lucene/index/values/FixedStraightBytesImpl.java b/lucene/src/java/org/apache/lucene/index/values/FixedStraightBytesImpl.java
index 1ee7b6e..ef76083 100644
--- a/lucene/src/java/org/apache/lucene/index/values/FixedStraightBytesImpl.java
+++ b/lucene/src/java/org/apache/lucene/index/values/FixedStraightBytesImpl.java
@@ -81,7 +81,7 @@ class FixedStraightBytesImpl {
           oneRecord = new byte[size];
         }
        fill(state.docBase);
-       // nocommit should we add a transfer to API to each reader?
+       // TODO should we add a transfer to API to each reader?
        datOut.copyBytes(reader.cloneData(), size * maxDocs);
        lastDocID += maxDocs-1;
       } else
@@ -139,7 +139,7 @@ class FixedStraightBytesImpl {
       public Source(IndexInput datIn, IndexInput idxIn, int size, int maxDoc) throws IOException {
         super(datIn, idxIn, new PagedBytes(PAGED_BYTES_BITS), size*maxDoc);
         this.size = size;
-        this.missingValues.bytesValue = new BytesRef(size);
+        this.missingValue.bytesValue = new BytesRef(size);
         this.maxDoc = maxDoc;
       }
       
diff --git a/lucene/src/java/org/apache/lucene/index/values/Floats.java b/lucene/src/java/org/apache/lucene/index/values/Floats.java
index 38afe7d..f53345c 100644
--- a/lucene/src/java/org/apache/lucene/index/values/Floats.java
+++ b/lucene/src/java/org/apache/lucene/index/values/Floats.java
@@ -20,6 +20,7 @@ import java.nio.ByteBuffer;
 import java.nio.DoubleBuffer;
 import java.nio.FloatBuffer;
 import java.util.Collection;
+import java.util.concurrent.atomic.AtomicLong;
 
 import org.apache.lucene.index.IndexFileNames;
 import org.apache.lucene.store.Directory;
@@ -44,16 +45,16 @@ public class Floats {
   private static final long LONG_DEFAULT = Double
       .doubleToRawLongBits(Double.NEGATIVE_INFINITY);
 
-  public static Writer getWriter(Directory dir, String id, int precisionBytes)
+  public static Writer getWriter(Directory dir, String id, int precisionBytes, AtomicLong bytesUsed)
       throws IOException {
     if (precisionBytes != 4 && precisionBytes != 8) {
       throw new IllegalArgumentException("precisionBytes must be 4 or 8; got "
           + precisionBytes);
     }
     if (precisionBytes == 4) {
-      return new Float4Writer(dir, id);
+      return new Float4Writer(dir, id, bytesUsed);
     } else {
-      return new Float8Writer(dir, id);
+      return new Float8Writer(dir, id, bytesUsed);
     }
   }
 
@@ -63,7 +64,6 @@ public class Floats {
   }
 
   abstract static class FloatsWriter extends Writer {
-
     private final Directory dir;
     private final String id;
     private FloatsRef floatsRef;
@@ -71,8 +71,9 @@ public class Floats {
     protected IndexOutput datOut;
     private final byte precision;
 
-    protected FloatsWriter(Directory dir, String id, int precision)
+    protected FloatsWriter(Directory dir, String id, int precision, AtomicLong bytesUsed)
         throws IOException {
+      super(bytesUsed);
       this.dir = dir;
       this.id = id;
       this.precision = (byte) precision;
@@ -113,7 +114,7 @@ public class Floats {
     protected void merge(MergeState state) throws IOException {
       if (state.bits == null && state.reader instanceof FloatsReader) {
         // no deletes - bulk copy
-        // nocommit - should be do bulks with deletes too?
+        // TODO: should be do bulks with deletes too?
         final FloatsReader reader = (FloatsReader) state.reader;
         assert reader.precisionBytes == (int) precision;
         if (reader.maxDoc == 0)
@@ -140,8 +141,8 @@ public class Floats {
   // Writes 4 bytes (float) per value
   static class Float4Writer extends FloatsWriter {
 
-    protected Float4Writer(Directory dir, String id) throws IOException {
-      super(dir, id, 4);
+    protected Float4Writer(Directory dir, String id, AtomicLong bytesUsed) throws IOException {
+      super(dir, id, 4, bytesUsed);
     }
 
     @Override
@@ -184,8 +185,8 @@ public class Floats {
   // Writes 8 bytes (double) per value
   static class Float8Writer extends FloatsWriter {
 
-    protected Float8Writer(Directory dir, String id) throws IOException {
-      super(dir, id, 8);
+    protected Float8Writer(Directory dir, String id, AtomicLong bytesUsed) throws IOException {
+      super(dir, id, 8, bytesUsed);
     }
 
     @Override
@@ -280,7 +281,7 @@ public class Floats {
 
       Source4(ByteBuffer buffer) {
         values = buffer.asFloatBuffer();
-        missingValues.doubleValue = Float.NEGATIVE_INFINITY;
+        missingValue.doubleValue = Float.NEGATIVE_INFINITY;
       }
 
       @Override
@@ -295,7 +296,7 @@ public class Floats {
 
       @Override
       public ValuesEnum getEnum(AttributeSource attrSource) throws IOException {
-        final MissingValues missing = getMissing();
+        final MissingValue missing = getMissing();
         return new SourceEnum(attrSource, Values.SIMPLE_FLOAT_4BYTE, this, maxDoc) {
           private final FloatsRef ref = attr.floats();
           @Override
@@ -324,7 +325,7 @@ public class Floats {
 
       Source8(ByteBuffer buffer) {
         values = buffer.asDoubleBuffer();
-        missingValues.doubleValue = Double.NEGATIVE_INFINITY;
+        missingValue.doubleValue = Double.NEGATIVE_INFINITY;
 
       }
 
@@ -340,7 +341,7 @@ public class Floats {
 
       @Override
       public ValuesEnum getEnum(AttributeSource attrSource) throws IOException {
-        final MissingValues missing = getMissing();
+        final MissingValue missing = getMissing();
         return new SourceEnum(attrSource, type(), this, maxDoc) {
           private final FloatsRef ref = attr.floats();
           @Override
diff --git a/lucene/src/java/org/apache/lucene/index/values/Ints.java b/lucene/src/java/org/apache/lucene/index/values/Ints.java
index d3f0e69..7955d7c 100644
--- a/lucene/src/java/org/apache/lucene/index/values/Ints.java
+++ b/lucene/src/java/org/apache/lucene/index/values/Ints.java
@@ -17,6 +17,7 @@ package org.apache.lucene.index.values;
  */
 
 import java.io.IOException;
+import java.util.concurrent.atomic.AtomicLong;
 
 import org.apache.lucene.index.values.PackedIntsImpl.IntsReader;
 import org.apache.lucene.index.values.PackedIntsImpl.IntsWriter;
@@ -28,10 +29,10 @@ public class Ints {
   private Ints() {
   }
 
-  public static Writer getWriter(Directory dir, String id, boolean useFixedArray)
+  public static Writer getWriter(Directory dir, String id, boolean useFixedArray, AtomicLong bytesUsed)
       throws IOException {
     // TODO - implement fixed?!
-    return new IntsWriter(dir, id);
+    return new IntsWriter(dir, id, bytesUsed);
   }
 
   public static DocValues getValues(Directory dir, String id,
diff --git a/lucene/src/java/org/apache/lucene/index/values/MultiDocValues.java b/lucene/src/java/org/apache/lucene/index/values/MultiDocValues.java
index d178093..0e81c25 100644
--- a/lucene/src/java/org/apache/lucene/index/values/MultiDocValues.java
+++ b/lucene/src/java/org/apache/lucene/index/values/MultiDocValues.java
@@ -192,7 +192,7 @@ public class MultiDocValues extends DocValues {
         assert docValuesIdx[idx] != null;
         try {
           current = docValuesIdx[idx].docValues.getSource();
-          missingValues.copy(current.getMissing());
+          missingValue.copy(current.getMissing());
         } catch (IOException e) {
           throw new RuntimeException("load failed", e); // TODO how should we
           // handle this
@@ -215,10 +215,6 @@ public class MultiDocValues extends DocValues {
       return current.getBytes(doc, bytesRef);
     }
 
-    public long ramBytesUsed() {
-      return current.ramBytesUsed();
-    }
-
     @Override
     public ValuesEnum getEnum(AttributeSource attrSource) throws IOException {
       throw new UnsupportedOperationException(); // TODO
@@ -240,18 +236,18 @@ public class MultiDocValues extends DocValues {
 
     @Override
     public BytesRef getBytes(int docID, BytesRef ref) {
-      return this.missingValues.bytesValue;
+      return this.missingValue.bytesValue;
 
     }
 
     @Override
     public double getFloat(int docID) {
-      return missingValues.doubleValue;
+      return missingValue.doubleValue;
     }
 
     @Override
     public long getInt(int docID) {
-      return missingValues.longValue;
+      return missingValue.longValue;
     }
 
     public long ramBytesUsed() {
diff --git a/lucene/src/java/org/apache/lucene/index/values/PackedIntsImpl.java b/lucene/src/java/org/apache/lucene/index/values/PackedIntsImpl.java
index 91f56bd..61f19e7 100644
--- a/lucene/src/java/org/apache/lucene/index/values/PackedIntsImpl.java
+++ b/lucene/src/java/org/apache/lucene/index/values/PackedIntsImpl.java
@@ -18,9 +18,9 @@ package org.apache.lucene.index.values;
  */
 import java.io.IOException;
 import java.util.Collection;
+import java.util.concurrent.atomic.AtomicLong;
 
 import org.apache.lucene.index.IndexFileNames;
-import org.apache.lucene.index.values.DocValues.MissingValues;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.store.IndexOutput;
@@ -50,13 +50,15 @@ class PackedIntsImpl {
     private boolean started;
     private final Directory dir;
     private final String id;
-    private OpenBitSet defaultValues = new OpenBitSet(1);
+    private final OpenBitSet defaultValues = new OpenBitSet(1);
     private int lastDocId = -1;
 
-    protected IntsWriter(Directory dir, String id) throws IOException {
+    protected IntsWriter(Directory dir, String id, AtomicLong bytesUsed) throws IOException {
+      super(bytesUsed);
       this.dir = dir;
       this.id = id;
       docToValue = new long[1];
+      bytesUsed.addAndGet(RamUsageEstimator.NUM_BYTES_LONG); // TODO the bitset needs memory too
     }
 
     @Override
@@ -76,9 +78,10 @@ class PackedIntsImpl {
       lastDocId = docID;
 
       if (docID >= docToValue.length) {
+        final long len = docToValue.length ;
         docToValue = ArrayUtil.grow(docToValue, 1 + docID);
         defaultValues.ensureCapacity(docToValue.length);
-
+        bytesUsed.addAndGet(RamUsageEstimator.NUM_BYTES_LONG * ((docToValue.length) - len));
       }
       docToValue[docID] = v;
     }
@@ -115,13 +118,10 @@ class PackedIntsImpl {
         w.add(defaultValue);
       }
       w.finish();
-
       datOut.close();
-    }
-
-    public long ramBytesUsed() {
-      return RamUsageEstimator.NUM_BYTES_ARRAY_HEADER + docToValue.length
-          * RamUsageEstimator.NUM_BYTES_LONG;
+      bytesUsed.addAndGet(-(RamUsageEstimator.NUM_BYTES_LONG * docToValue.length ));
+      docToValue = null;
+      
     }
 
     @Override
@@ -180,7 +180,7 @@ class PackedIntsImpl {
         minValue = dataIn.readLong();
         defaultValue = dataIn.readLong();
         values = PackedInts.getReader(dataIn);
-        missingValues.longValue = minValue + defaultValue;
+        missingValue.longValue = minValue + defaultValue;
       }
 
       @Override
@@ -199,7 +199,7 @@ class PackedIntsImpl {
 
       @Override
       public ValuesEnum getEnum(AttributeSource attrSource) throws IOException {
-        final MissingValues missing = getMissing();
+        final MissingValue missing = getMissing();
         return new SourceEnum(attrSource, type(), this, values.size()) {
           private final LongsRef ref = attr.ints();
           @Override
diff --git a/lucene/src/java/org/apache/lucene/index/values/Values.java b/lucene/src/java/org/apache/lucene/index/values/Values.java
index e33c0cb..56921dd 100644
--- a/lucene/src/java/org/apache/lucene/index/values/Values.java
+++ b/lucene/src/java/org/apache/lucene/index/values/Values.java
@@ -22,8 +22,8 @@ package org.apache.lucene.index.values;
  *  values into RAM, exposing a random access API, when
  *  loaded.
  *
- * <p><b>NOTE</b>: This feature is experimental and the
- * API is free to change in non-backwards-compatible ways.  */
+ * @lucene.experimenta 
+ */
 public enum Values {
 
   /** Integral value is stored as packed ints.  The bit
diff --git a/lucene/src/java/org/apache/lucene/index/values/VarDerefBytesImpl.java b/lucene/src/java/org/apache/lucene/index/values/VarDerefBytesImpl.java
index 2dfa5bd..b0e89ce 100644
--- a/lucene/src/java/org/apache/lucene/index/values/VarDerefBytesImpl.java
+++ b/lucene/src/java/org/apache/lucene/index/values/VarDerefBytesImpl.java
@@ -37,8 +37,7 @@ import org.apache.lucene.util.PagedBytes;
 import org.apache.lucene.util.RamUsageEstimator;
 import org.apache.lucene.util.ByteBlockPool.Allocator;
 import org.apache.lucene.util.ByteBlockPool.DirectAllocator;
-import org.apache.lucene.util.BytesRefHash.ParallelArrayBase;
-import org.apache.lucene.util.BytesRefHash.ParallelBytesStartArray;
+import org.apache.lucene.util.BytesRefHash.TrackingDirectBytesStartArray;
 import org.apache.lucene.util.packed.PackedInts;
 
 // Stores variable-length byte[] by deref, ie when two docs
@@ -51,30 +50,47 @@ class VarDerefBytesImpl {
   static final int VERSION_START = 0;
   static final int VERSION_CURRENT = VERSION_START;
 
-  private static class AddressParallelArray extends
-      ParallelArrayBase<AddressParallelArray> {
-    final int[] address;
+  private static final class AddressByteStartArray extends
+      TrackingDirectBytesStartArray {
+    int[] address;
 
-    AddressParallelArray(int size, AtomicLong bytesUsed) {
+    AddressByteStartArray(int size, AtomicLong bytesUsed) {
       super(size, bytesUsed);
-      address = new int[size];
     }
 
     @Override
-    protected int bytesPerEntry() {
-      return RamUsageEstimator.NUM_BYTES_INT + super.bytesPerEntry();
+    public AtomicLong bytesUsed() {
+      return bytesUsed;
     }
 
     @Override
-    protected void copyTo(AddressParallelArray toArray, int numToCopy) {
-      super.copyTo(toArray, numToCopy);
-      System.arraycopy(address, 0, toArray.address, 0, size);
+    public int[] clear() {
+      if (address != null) {
+        bytesUsed.addAndGet(-address.length * RamUsageEstimator.NUM_BYTES_INT);
+        address = null;
+      }
+      return super.clear();
+    }
 
+    @Override
+    public int[] grow() {
+      assert address != null;
+      final int oldSize = address.length;
+      final int[] retVal = super.grow();
+      address = ArrayUtil.grow(address, retVal.length);
+      bytesUsed.addAndGet(RamUsageEstimator.NUM_BYTES_INT
+          * (address.length - oldSize));
+      return retVal;
     }
 
     @Override
-    public AddressParallelArray newInstance(int size) {
-      return new AddressParallelArray(size, bytesUsed);
+    public int[] init() {
+      if (address == null) {
+        address = new int[ArrayUtil.oversize(initSize,
+            RamUsageEstimator.NUM_BYTES_INT)];
+        bytesUsed.addAndGet((address.length) * RamUsageEstimator.NUM_BYTES_INT);
+      }
+      return super.init();
     }
 
   }
@@ -83,13 +99,14 @@ class VarDerefBytesImpl {
     private int[] docToAddress;
     private int address = 1;
 
-    private final ParallelBytesStartArray<AddressParallelArray> array = new ParallelBytesStartArray<AddressParallelArray>(
-        new AddressParallelArray(0, bytesUsed));
+    private final AddressByteStartArray array = new AddressByteStartArray(1,
+        bytesUsed);
     private final BytesRefHash hash = new BytesRefHash(pool, 16, array);
 
-    public Writer(Directory dir, String id) throws IOException {
+    public Writer(Directory dir, String id, AtomicLong bytesUsed)
+        throws IOException {
       this(dir, id, new DirectAllocator(ByteBlockPool.BYTE_BLOCK_SIZE),
-          new AtomicLong());
+          bytesUsed);
     }
 
     public Writer(Directory dir, String id, Allocator allocator,
@@ -116,12 +133,12 @@ class VarDerefBytesImpl {
       }
       final int docAddress;
       if (e >= 0) {
-        docAddress = array.array.address[e] = address;
+        docAddress = array.address[e] = address;
         address += writePrefixLength(datOut, bytes);
         datOut.writeBytes(bytes.bytes, bytes.offset, bytes.length);
         address += bytes.length;
       } else {
-        docAddress = array.array.address[(-e) - 1];
+        docAddress = array.address[(-e) - 1];
       }
       docToAddress[docID] = docAddress;
     }
@@ -138,10 +155,6 @@ class VarDerefBytesImpl {
       }
     }
 
-    public long ramBytesUsed() {
-      return bytesUsed.get();
-    }
-
     // Important that we get docCount, in case there were
     // some last docs that we didn't see
     @Override
@@ -169,8 +182,11 @@ class VarDerefBytesImpl {
         w.add(0);
       }
       w.finish();
-      hash.clear(true);
+      hash.close();
       super.finish(docCount);
+      bytesUsed.addAndGet(RamUsageEstimator.NUM_BYTES_INT
+          * (-docToAddress.length));
+      docToAddress = null;
     }
   }
 
@@ -202,7 +218,7 @@ class VarDerefBytesImpl {
       @Override
       public BytesRef getBytes(int docID, BytesRef bytesRef) {
         long address = index.get(docID);
-        return address == 0 ? null : data.fillUsingLengthPrefix4(bytesRef,
+        return address == 0 ? null : data.fillSliceWithPrefix(bytesRef,
             --address);
       }
 
diff --git a/lucene/src/java/org/apache/lucene/index/values/VarSortedBytesImpl.java b/lucene/src/java/org/apache/lucene/index/values/VarSortedBytesImpl.java
index 4504ee4..0c22fd8 100644
--- a/lucene/src/java/org/apache/lucene/index/values/VarSortedBytesImpl.java
+++ b/lucene/src/java/org/apache/lucene/index/values/VarSortedBytesImpl.java
@@ -36,6 +36,7 @@ import org.apache.lucene.util.PagedBytes;
 import org.apache.lucene.util.RamUsageEstimator;
 import org.apache.lucene.util.ByteBlockPool.Allocator;
 import org.apache.lucene.util.ByteBlockPool.DirectAllocator;
+import org.apache.lucene.util.BytesRefHash.TrackingDirectBytesStartArray;
 import org.apache.lucene.util.packed.PackedInts;
 
 // Stores variable-length byte[] by deref, ie when two docs
@@ -52,12 +53,12 @@ class VarSortedBytesImpl {
     private int[] docToEntry;
     private final Comparator<BytesRef> comp;
 
-    private final BytesRefHash hash = new BytesRefHash(pool);
+    private final BytesRefHash hash = new BytesRefHash(pool, BytesRefHash.DEFAULT_CAPACITY,
+        new TrackingDirectBytesStartArray(BytesRefHash.DEFAULT_CAPACITY, bytesUsed));
 
-    public Writer(Directory dir, String id, Comparator<BytesRef> comp)
+    public Writer(Directory dir, String id, Comparator<BytesRef> comp, AtomicLong bytesUsed)
         throws IOException {
-      this(dir, id, comp, new DirectAllocator(ByteBlockPool.BYTE_BLOCK_SIZE),
-          new AtomicLong());
+      this(dir, id, comp, new DirectAllocator(ByteBlockPool.BYTE_BLOCK_SIZE), bytesUsed);
     }
 
     public Writer(Directory dir, String id, Comparator<BytesRef> comp,
@@ -147,6 +148,7 @@ class VarSortedBytesImpl {
       super.finish(docCount);
       bytesUsed.addAndGet((-docToEntry.length)
           * RamUsageEstimator.NUM_BYTES_INT);
+      hash.close();
 
     }
   }
@@ -195,18 +197,6 @@ class VarSortedBytesImpl {
         return binarySearch(bytes, tmpRef, 0, valueCount - 1);
       }
 
-      public long ramBytesUsed() {
-        // TODO(simonw): move ram usage to PackedInts?
-        return RamUsageEstimator.NUM_BYTES_ARRAY_HEADER
-            + totBytes
-            + (RamUsageEstimator.NUM_BYTES_ARRAY_HEADER + docToOrdIndex
-                .getBitsPerValue()
-                * docToOrdIndex.getBitsPerValue())
-            + (RamUsageEstimator.NUM_BYTES_ARRAY_HEADER + ordToOffsetIndex
-                .getBitsPerValue()
-                * ordToOffsetIndex.getBitsPerValue());
-      }
-
       @Override
       public int getValueCount() {
         return valueCount;
diff --git a/lucene/src/java/org/apache/lucene/index/values/VarStraightBytesImpl.java b/lucene/src/java/org/apache/lucene/index/values/VarStraightBytesImpl.java
index 0f3f6df..ccff45e 100644
--- a/lucene/src/java/org/apache/lucene/index/values/VarStraightBytesImpl.java
+++ b/lucene/src/java/org/apache/lucene/index/values/VarStraightBytesImpl.java
@@ -62,7 +62,7 @@ class VarStraightBytesImpl {
       if (docID >= docToAddress.length) {
         int oldSize = docToAddress.length;
         docToAddress = ArrayUtil.grow(docToAddress, 1 + docID);
-        bytesUsed.addAndGet(-(docToAddress.length - oldSize)
+        bytesUsed.addAndGet((docToAddress.length - oldSize)
             * RamUsageEstimator.NUM_BYTES_INT);
       }
       for (int i = lastDocID + 1; i < docID; i++) {
@@ -127,7 +127,7 @@ class VarStraightBytesImpl {
       public Source(IndexInput datIn, IndexInput idxIn) throws IOException {
         super(datIn, idxIn, new PagedBytes(PAGED_BYTES_BITS), idxIn.readVLong()); 
         addresses = PackedInts.getReader(idxIn);
-        missingValues.bytesValue = new BytesRef(0); // empty
+        missingValue.bytesValue = new BytesRef(0); // empty
       }
 
       @Override
diff --git a/lucene/src/java/org/apache/lucene/index/values/Writer.java b/lucene/src/java/org/apache/lucene/index/values/Writer.java
index 04471b2..82dc03b 100644
--- a/lucene/src/java/org/apache/lucene/index/values/Writer.java
+++ b/lucene/src/java/org/apache/lucene/index/values/Writer.java
@@ -18,6 +18,7 @@ package org.apache.lucene.index.values;
  */
 import java.io.IOException;
 import java.util.Comparator;
+import java.util.concurrent.atomic.AtomicLong;
 
 import org.apache.lucene.index.codecs.docvalues.DocValuesConsumer;
 import org.apache.lucene.store.Directory;
@@ -26,6 +27,10 @@ import org.apache.lucene.util.BytesRef;
 
 public abstract class Writer extends DocValuesConsumer {
 
+  protected Writer(AtomicLong bytesUsed) {
+    super(bytesUsed);
+  }
+
   public static final String INDEX_EXTENSION = "idx";
   public static final String DATA_EXTENSION = "dat";
 
@@ -85,26 +90,26 @@ public abstract class Writer extends DocValuesConsumer {
   }
 
   public static Writer create(Values v, String id, Directory directory,
-      Comparator<BytesRef> comp) throws IOException {
+      Comparator<BytesRef> comp, AtomicLong bytesUsed) throws IOException {
     switch (v) {
     case PACKED_INTS:
-      return Ints.getWriter(directory, id, true);
+      return Ints.getWriter(directory, id, true, bytesUsed);
     case SIMPLE_FLOAT_4BYTE:
-      return Floats.getWriter(directory, id, 4);
+      return Floats.getWriter(directory, id, 4, bytesUsed);
     case SIMPLE_FLOAT_8BYTE:
-      return Floats.getWriter(directory, id, 8);
+      return Floats.getWriter(directory, id, 8, bytesUsed);
     case BYTES_FIXED_STRAIGHT:
-      return Bytes.getWriter(directory, id, Bytes.Mode.STRAIGHT, comp, true);
+      return Bytes.getWriter(directory, id, Bytes.Mode.STRAIGHT, comp, true, bytesUsed);
     case BYTES_FIXED_DEREF:
-      return Bytes.getWriter(directory, id, Bytes.Mode.DEREF, comp, true);
+      return Bytes.getWriter(directory, id, Bytes.Mode.DEREF, comp, true, bytesUsed);
     case BYTES_FIXED_SORTED:
-      return Bytes.getWriter(directory, id, Bytes.Mode.SORTED, comp, true);
+      return Bytes.getWriter(directory, id, Bytes.Mode.SORTED, comp, true, bytesUsed);
     case BYTES_VAR_STRAIGHT:
-      return Bytes.getWriter(directory, id, Bytes.Mode.STRAIGHT, comp, false);
+      return Bytes.getWriter(directory, id, Bytes.Mode.STRAIGHT, comp, false, bytesUsed);
     case BYTES_VAR_DEREF:
-      return Bytes.getWriter(directory, id, Bytes.Mode.DEREF, comp, false);
+      return Bytes.getWriter(directory, id, Bytes.Mode.DEREF, comp, false, bytesUsed);
     case BYTES_VAR_SORTED:
-      return Bytes.getWriter(directory, id, Bytes.Mode.SORTED, comp, false);
+      return Bytes.getWriter(directory, id, Bytes.Mode.SORTED, comp, false, bytesUsed);
     default:
       throw new IllegalArgumentException("Unknown Values: " + v);
     }
diff --git a/lucene/src/java/org/apache/lucene/util/BytesRefHash.java b/lucene/src/java/org/apache/lucene/util/BytesRefHash.java
index 5a4336f..c5b180c 100644
--- a/lucene/src/java/org/apache/lucene/util/BytesRefHash.java
+++ b/lucene/src/java/org/apache/lucene/util/BytesRefHash.java
@@ -227,8 +227,9 @@ public final class BytesRefHash {
   public void clear(boolean resetPool) {
     lastCount = count;
     count = 0;
-    if (resetPool)
+    if (resetPool) {
       pool.reset();
+    }
     bytesStart = bytesStartArray.clear();
     if (lastCount != -1 && shrink(lastCount)) {
       // shrink clears the hash entries
@@ -240,6 +241,16 @@ public final class BytesRefHash {
   public void clear() {
     clear(true);
   }
+  
+  /**
+   * Closes the BytesRefHash and releases all internally used memory
+   */
+  public void close() {
+    clear(true);
+    ords = null;
+    bytesUsed.addAndGet(RamUsageEstimator.NUM_BYTES_INT
+        * -hashSize);
+  }
 
   /**
    * Adds a new {@link BytesRef}
@@ -453,8 +464,14 @@ public final class BytesRefHash {
    * effect.
    */
   public void reinit() {
-    if (bytesStart == null)
+    if (bytesStart == null) {
       bytesStart = bytesStartArray.init();
+    }
+    
+    if (ords == null) {
+      ords = new int[hashSize];
+      bytesUsed.addAndGet(RamUsageEstimator.NUM_BYTES_INT * hashSize);
+    }
   }
 
   /**
@@ -515,98 +532,82 @@ public final class BytesRefHash {
      */
     public abstract AtomicLong bytesUsed();
   }
-
-  public static class DirectBytesStartArray extends BytesStartArray {
-
+  
+  /**
+   * A direct {@link BytesStartArray} that tracks all memory allocation using an {@link AtomicLong} instance.
+   */
+  public static class TrackingDirectBytesStartArray extends BytesStartArray {
     protected final int initSize;
     private int[] bytesStart;
-    private final AtomicLong bytesUsed = new AtomicLong(0);
-
-    public DirectBytesStartArray(int initSize) {
+    protected final AtomicLong bytesUsed;
+    
+    public TrackingDirectBytesStartArray(int initSize, AtomicLong bytesUsed) {
       this.initSize = initSize;
+      this.bytesUsed = bytesUsed;
     }
 
     @Override
     public int[] clear() {
+      if (bytesStart != null) {
+        bytesUsed.addAndGet(-bytesStart.length * RamUsageEstimator.NUM_BYTES_INT);
+      }
       return bytesStart = null;
     }
 
     @Override
     public int[] grow() {
       assert bytesStart != null;
-      return bytesStart = ArrayUtil.grow(bytesStart, bytesStart.length + 1);
+      final int oldSize = bytesStart.length;
+      bytesStart = ArrayUtil.grow(bytesStart, bytesStart.length + 1);
+      bytesUsed.addAndGet((bytesStart.length - oldSize) * RamUsageEstimator.NUM_BYTES_INT);
+      return bytesStart;
     }
 
     @Override
     public int[] init() {
-      return bytesStart = new int[ArrayUtil.oversize(initSize,
+      bytesStart = new int[ArrayUtil.oversize(initSize,
           RamUsageEstimator.NUM_BYTES_INT)];
+      bytesUsed.addAndGet((bytesStart.length) * RamUsageEstimator.NUM_BYTES_INT);
+      return bytesStart;
     }
 
     @Override
     public AtomicLong bytesUsed() {
       return bytesUsed;
     }
-
   }
-  
-  public static class ParallelBytesStartArray<T extends ParallelArrayBase<T>> extends BytesStartArray {
-    private final T prototype;
-    public T array;
+
+  public static class DirectBytesStartArray extends BytesStartArray {
+    protected final int initSize;
+    private int[] bytesStart;
+    private final AtomicLong bytesUsed;
     
-    public ParallelBytesStartArray(T template) {
-      this.prototype = template;
-    }
-    @Override
-    public int[] init() {
-      if(array == null) { 
-        array = prototype.newInstance(2);
-      }
-      return array.textStart;
+    public DirectBytesStartArray(int initSize) {
+      this.bytesUsed = new AtomicLong(0);
+      this.initSize = initSize;
     }
 
-    @Override
-    public int[] grow() {
-      array = array.grow();
-      return array.textStart;
-    }
 
     @Override
     public int[] clear() {
-      if(array != null) {
-        array.deref();
-        array = null;
-      }
-      return null;
+      return bytesStart = null;
     }
 
     @Override
-    public AtomicLong bytesUsed() {
-      return array.bytesUsed();
-    }
-    
-  }
-  
-  public abstract static class ParallelArrayBase<T extends ParallelArrayBase<T>> extends ParallelArray<T> {
-    final int[] textStart;
-    
-    protected ParallelArrayBase(int size, AtomicLong bytesUsed) {
-      super(size, bytesUsed);
-      textStart = new int[size];
+    public int[] grow() {
+      assert bytesStart != null;
+      return bytesStart = ArrayUtil.grow(bytesStart, bytesStart.length + 1);
     }
 
     @Override
-    protected int bytesPerEntry() {
-      return RamUsageEstimator.NUM_BYTES_INT;
+    public int[] init() {
+      return bytesStart = new int[ArrayUtil.oversize(initSize,
+          RamUsageEstimator.NUM_BYTES_INT)];
     }
 
     @Override
-    protected void copyTo(T toArray, int numToCopy) {
-      System.arraycopy(textStart, 0, toArray.textStart, 0, size);
+    public AtomicLong bytesUsed() {
+      return bytesUsed;
     }
-
-    @Override
-    public abstract T newInstance(int size);
-    
   }
 }
diff --git a/lucene/src/java/org/apache/lucene/util/FloatsRef.java b/lucene/src/java/org/apache/lucene/util/FloatsRef.java
index 9dd107e..6706674 100644
--- a/lucene/src/java/org/apache/lucene/util/FloatsRef.java
+++ b/lucene/src/java/org/apache/lucene/util/FloatsRef.java
@@ -1,9 +1,27 @@
-/**
- * 
- */
 package org.apache.lucene.util;
 
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
 
+/**
+ * Represents float[], as a slice (offset + length) into an existing float[].
+ * 
+ * @lucene.internal
+ */
 public final class FloatsRef implements Cloneable{
   public double[] floats;
   public int offset;
diff --git a/lucene/src/java/org/apache/lucene/util/LongsRef.java b/lucene/src/java/org/apache/lucene/util/LongsRef.java
index c5dee1a..2a9bb2e 100644
--- a/lucene/src/java/org/apache/lucene/util/LongsRef.java
+++ b/lucene/src/java/org/apache/lucene/util/LongsRef.java
@@ -1,9 +1,27 @@
-/**
- * 
- */
 package org.apache.lucene.util;
 
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
 
+/**
+ * Represents long[], as a slice (offset + length) into an existing long[].
+ * 
+ * @lucene.internal
+ */
 public final class LongsRef implements Cloneable {
   public long[] ints;
   public int offset;
@@ -30,11 +48,11 @@ public final class LongsRef implements Cloneable {
   public Object clone() {
     return new LongsRef(this);
   }
-  
+
   public void set(long value) {
     ints[offset] = value;
   }
-  
+
   public long get() {
     return ints[offset];
   }
@@ -44,13 +62,13 @@ public final class LongsRef implements Cloneable {
     final int prime = 31;
     int result = 0;
     final int end = offset + length;
-    for(int i = offset; i < end; i++) {
+    for (int i = offset; i < end; i++) {
       long value = ints[i];
       result = prime * result + (int) (value ^ (value >>> 32));
     }
     return result;
   }
-  
+
   @Override
   public boolean equals(Object other) {
     return this.intsEquals((LongsRef) other);
@@ -61,7 +79,7 @@ public final class LongsRef implements Cloneable {
       int otherUpto = other.offset;
       final long[] otherInts = other.ints;
       final int end = offset + length;
-      for(int upto=offset;upto<end;upto++,otherUpto++) {
+      for (int upto = offset; upto < end; upto++, otherUpto++) {
         if (ints[upto] != otherInts[otherUpto]) {
           return false;
         }
diff --git a/lucene/src/java/org/apache/lucene/util/PagedBytes.java b/lucene/src/java/org/apache/lucene/util/PagedBytes.java
index d09ef80..331d066 100644
--- a/lucene/src/java/org/apache/lucene/util/PagedBytes.java
+++ b/lucene/src/java/org/apache/lucene/util/PagedBytes.java
@@ -146,13 +146,19 @@ public final class PagedBytes {
       return start;
     }
     
+  
     /**
-     * Reads length as 1 or 2 byte vInt prefix, starting @ start and fill the
-     * given {@link BytesRef} with the byte slice starting after the length
-     * prefix.
+     * Gets a slice out of {@link PagedBytes} starting at <i>start</i>, the
+     * length is read as 1 or 2 byte vInt prefix. Iff the slice spans across a
+     * block border this method will allocate sufficient resources and copy the
+     * paged data.
+     * <p>
+     * Slices spanning more than one block are not supported.
+     * </p>
+     * 
      * @lucene.internal
      **/
-    public BytesRef fillUsingLengthPrefix4(BytesRef b, long start) {
+    public BytesRef fillSliceWithPrefix(BytesRef b, long start) {
       final int index = (int) (start >> blockBits);
       int offset = (int) (start & blockMask);
       final byte[] block = blocks[index];
diff --git a/lucene/src/test/org/apache/lucene/index/TestCodecs.java b/lucene/src/test/org/apache/lucene/index/TestCodecs.java
index 769ea0e..38c80c3 100644
--- a/lucene/src/test/org/apache/lucene/index/TestCodecs.java
+++ b/lucene/src/test/org/apache/lucene/index/TestCodecs.java
@@ -20,6 +20,7 @@ package org.apache.lucene.index;
 import java.io.IOException;
 import java.util.Arrays;
 import java.util.HashSet;
+import java.util.concurrent.atomic.AtomicLong;
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
@@ -607,7 +608,7 @@ public class TestCodecs extends LuceneTestCase {
 
     final int termIndexInterval = this.nextInt(13, 27);
     final SegmentCodecs codecInfo = SegmentCodecs.build(fieldInfos, CodecProvider.getDefault());
-    final SegmentWriteState state = new SegmentWriteState(null, dir, SEGMENT, fieldInfos, null, 10000, 10000, termIndexInterval, codecInfo);
+    final SegmentWriteState state = new SegmentWriteState(null, dir, SEGMENT, fieldInfos, null, 10000, 10000, termIndexInterval, codecInfo, new AtomicLong());
 
     final FieldsConsumer consumer = state.segmentCodecs.codec().fieldsConsumer(state);
     Arrays.sort(fields);
diff --git a/lucene/src/test/org/apache/lucene/index/values/TestDocValues.java b/lucene/src/test/org/apache/lucene/index/values/TestDocValues.java
index 2b2015c..02a49cc 100644
--- a/lucene/src/test/org/apache/lucene/index/values/TestDocValues.java
+++ b/lucene/src/test/org/apache/lucene/index/values/TestDocValues.java
@@ -19,6 +19,7 @@ package org.apache.lucene.index.values;
 
 import java.io.IOException;
 import java.util.Comparator;
+import java.util.concurrent.atomic.AtomicLong;
 
 import org.apache.lucene.index.values.DocValues.SortedSource;
 import org.apache.lucene.index.values.DocValues.Source;
@@ -59,7 +60,8 @@ public class TestDocValues extends LuceneTestCase {
         .getUTF8SortedAsUnicodeComparator() : null;
 
     Directory dir = newDirectory();
-    Writer w = Bytes.getWriter(dir, "test", mode, comp, fixedSize);
+    final AtomicLong trackBytes = new AtomicLong(0);
+    Writer w = Bytes.getWriter(dir, "test", mode, comp, fixedSize, trackBytes);
     int maxDoc = 220;
     final String[] values = new String[maxDoc];
     final int lenMin, lenMax;
@@ -83,6 +85,7 @@ public class TestDocValues extends LuceneTestCase {
       w.add(2 * i, bytesRef);
     }
     w.finish(maxDoc);
+    assertEquals(0, trackBytes.get());
 
     DocValues r = Bytes.getValues(dir, "test", mode, fixedSize, maxDoc);
     for (int iter = 0; iter < 2; iter++) {
@@ -186,7 +189,8 @@ public class TestDocValues extends LuceneTestCase {
     final long[] values = new long[NUM_VALUES];
     for (int rx = 1; rx < 63; rx++, maxV *= 2) {
       Directory dir = newDirectory();
-      Writer w = Ints.getWriter(dir, "test", false);
+      final AtomicLong trackBytes = new AtomicLong(0);
+      Writer w = Ints.getWriter(dir, "test", false, trackBytes);
       for (int i = 0; i < NUM_VALUES; i++) {
         final long v = random.nextLong() % (1 + maxV);
         values[i] = v;
@@ -194,6 +198,8 @@ public class TestDocValues extends LuceneTestCase {
       }
       final int additionalDocs = 1 + random.nextInt(9);
       w.finish(NUM_VALUES + additionalDocs);
+      assertEquals(0, trackBytes.get());
+
 
       DocValues r = Ints.getValues(dir, "test", false);
       for (int iter = 0; iter < 2; iter++) {
@@ -250,7 +256,8 @@ public class TestDocValues extends LuceneTestCase {
 
   private void runTestFloats(int precision, double delta) throws IOException {
     Directory dir = newDirectory();
-    Writer w = Floats.getWriter(dir, "test", precision);
+    final AtomicLong trackBytes = new AtomicLong(0);
+    Writer w = Floats.getWriter(dir, "test", precision, trackBytes);
     final int NUM_VALUES = 777 + random.nextInt(777);;
     final double[] values = new double[NUM_VALUES];
     for (int i = 0; i < NUM_VALUES; i++) {
@@ -261,6 +268,7 @@ public class TestDocValues extends LuceneTestCase {
     }
     final int additionalValues = 1 + random.nextInt(10);
     w.finish(NUM_VALUES + additionalValues);
+    assertEquals(0, trackBytes.get());
 
     DocValues r = Floats.getValues(dir, "test", NUM_VALUES + additionalValues);
     for (int iter = 0; iter < 2; iter++) {
diff --git a/lucene/src/test/org/apache/lucene/index/values/TestDocValuesIndexing.java b/lucene/src/test/org/apache/lucene/index/values/TestDocValuesIndexing.java
index 5ab0c64..9cca81f 100644
--- a/lucene/src/test/org/apache/lucene/index/values/TestDocValuesIndexing.java
+++ b/lucene/src/test/org/apache/lucene/index/values/TestDocValuesIndexing.java
@@ -43,8 +43,13 @@ import org.apache.lucene.index.MultiFields;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.index.codecs.CodecProvider;
 import org.apache.lucene.index.codecs.docvalues.DocValuesCodec;
-import org.apache.lucene.index.values.DocValues.MissingValues;
+import org.apache.lucene.index.values.DocValues.MissingValue;
 import org.apache.lucene.index.values.DocValues.Source;
+import org.apache.lucene.queryParser.ParseException;
+import org.apache.lucene.queryParser.QueryParser;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.ScoreDoc;
+import org.apache.lucene.search.TopDocs;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.LockObtainFailedException;
 import org.apache.lucene.util.BytesRef;
@@ -62,8 +67,27 @@ import org.junit.BeforeClass;
  * 
  */
 public class TestDocValuesIndexing extends LuceneTestCase {
-  // TODO Add a test for addIndexes
-  // TODO add test for unoptimized case with deletes
+  /*
+   * TODO:
+   * Roadmap to land on trunk
+   *   - Cut over to a direct API on ValuesEnum vs. ValuesAttribute 
+   *   - Add documentation for:
+   *      - Source and ValuesEnum
+   *      - DocValues
+   *      - ValuesField
+   *      - ValuesAttribute
+   *      - Values
+   *   - Add @lucene.experimental to all necessary classes
+   *   - Try to make ValuesField more lightweight -> AttributeSource
+   *   - add test for unoptimized case with deletes
+   *   - add a test for addIndexes
+   *   - split up existing testcases and give them meaningfull names
+   *   - use consistent naming throughout DocValues
+   *     - Values -> DocValueType
+   *     - PackedIntsImpl -> Ints
+   *   - run RAT
+   *   - add tests for FieldComparator FloatIndexValuesComparator vs. FloatValuesComparator etc.
+   */
 
   private static DocValuesCodec docValuesCodec;
   private static CodecProvider provider;
@@ -82,6 +106,43 @@ public class TestDocValuesIndexing extends LuceneTestCase {
   public static void afterClassLuceneTestCaseJ4() {
     LuceneTestCase.afterClassLuceneTestCaseJ4();
   }
+  
+  /*
+   * Simple test case to show how to use the API
+   */
+  public void testDocValuesSimple() throws CorruptIndexException, IOException, ParseException {
+    Directory dir = newDirectory();
+    IndexWriter writer = new IndexWriter(dir, writerConfig(false));
+    for (int i = 0; i < 5; i++) {
+      Document doc = new Document();
+      ValuesField valuesField = new ValuesField("docId");
+      valuesField.setInt(i);
+      doc.add(valuesField);
+      doc.add(new Field("docId", "" + i, Store.NO, Index.ANALYZED));
+      writer.addDocument(doc);
+    }
+    writer.commit();
+    writer.optimize(true);
+   
+    writer.close();
+    
+    IndexReader reader = IndexReader.open(dir, null, true, 1, provider);
+    assertTrue(reader.isOptimized());
+   
+    IndexSearcher searcher = new IndexSearcher(reader);
+    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, "docId", new MockAnalyzer());
+    TopDocs search = searcher.search(parser.parse("0 OR 1 OR 2 OR 3 OR 4"), 10);
+    assertEquals(5, search.totalHits);
+    ScoreDoc[] scoreDocs = search.scoreDocs;
+    DocValues docValues = MultiFields.getDocValues(reader, "docId");
+    Source source = docValues.getSource();
+    for (int i = 0; i < scoreDocs.length; i++) {
+      assertEquals(i, scoreDocs[i].doc);
+      assertEquals(i, source.getInt(scoreDocs[i].doc));
+    }
+    reader.close();
+    dir.close();
+  }
 
   /**
    * Tests complete indexing of {@link Values} including deletions, merging and
@@ -160,7 +221,7 @@ public class TestDocValuesIndexing extends LuceneTestCase {
         assertNotNull(intsReader);
 
         Source ints = getSource(intsReader);
-        MissingValues missing = ints.getMissing();
+        MissingValue missing = ints.getMissing();
 
         for (int i = 0; i < base; i++) {
           long value = ints.getInt(i);
@@ -191,7 +252,7 @@ public class TestDocValuesIndexing extends LuceneTestCase {
         DocValues floatReader = getDocValues(r, val.name());
         assertNotNull(floatReader);
         Source floats = getSource(floatReader);
-        MissingValues missing = floats.getMissing();
+        MissingValue missing = floats.getMissing();
 
         for (int i = 0; i < base; i++) {
           double value = floats.getFloat(i);
@@ -254,7 +315,7 @@ public class TestDocValuesIndexing extends LuceneTestCase {
       byte upto = 0;
 
       // test the filled up slots for correctness
-      MissingValues missing = bytes.getMissing();
+      MissingValue missing = bytes.getMissing();
       for (int i = 0; i < base; i++) {
 
         BytesRef br = bytes.getBytes(i, new BytesRef());

