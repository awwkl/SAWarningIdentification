GitDiffStart: d671dd8d890a8e5eb56cbcd94873c3057745a17f | Thu Jun 25 13:59:19 2015 +0000
diff --git a/lucene/CHANGES.txt b/lucene/CHANGES.txt
index 49bfe50..e8def73 100644
--- a/lucene/CHANGES.txt
+++ b/lucene/CHANGES.txt
@@ -42,6 +42,7 @@ API Changes
   BooleanQuery with one MUST clause for the query, and one FILTER clause for
   the filter. (Adrien Grand)
 
+
 ======================= Lucene 5.3.0 =======================
 
 New Features
@@ -132,6 +133,10 @@ API Changes
   be replaced with a BooleanQuery which handle the query as a MUST clause and
   the filter as a FILTER clause. (Adrien Grand)
 
+* LUCENE-6553: The postings, spans and scorer APIs no longer take an acceptDocs
+  parameter. Live docs are now always checked on top of these APIs.
+  (Adrien Grand)
+
 Bug fixes
 
 * LUCENE-6500: ParallelCompositeReader did not always call
@@ -225,6 +230,12 @@ Build
 * LUCENE-6567: Simplify payload checking in SpanPayloadCheckQuery (Alan
   Woodward)
 
+Changes in Backwards Compatibility Policy
+
+* LUCENE-6553: The iterator returned by the LeafReader.postings method now
+  always includes deleted docs, so you have to check for deleted documents on
+  top of the iterator. (Adrien Grand)
+
 ======================= Lucene 5.2.1 =======================
 
 Bug Fixes
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestKeywordAnalyzer.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestKeywordAnalyzer.java
index 03746bb..e03a5f2 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestKeywordAnalyzer.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestKeywordAnalyzer.java
@@ -101,7 +101,6 @@ public class TestKeywordAnalyzer extends BaseTokenStreamTestCase {
         reader,
         "partnum",
         new BytesRef("Q36"),
-        MultiFields.getLiveDocs(reader),
         null,
         0);
     assertTrue(td.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
@@ -109,7 +108,6 @@ public class TestKeywordAnalyzer extends BaseTokenStreamTestCase {
         reader,
         "partnum",
         new BytesRef("Q37"),
-        MultiFields.getLiveDocs(reader),
         null,
         0);
     assertTrue(td.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/sinks/TestTeeSinkTokenFilter.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/sinks/TestTeeSinkTokenFilter.java
index 03c0d72..87e6a64 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/sinks/TestTeeSinkTokenFilter.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/sinks/TestTeeSinkTokenFilter.java
@@ -111,7 +111,7 @@ public class TestTeeSinkTokenFilter extends BaseTokenStreamTestCase {
     TermsEnum termsEnum = vector.iterator();
     termsEnum.next();
     assertEquals(2, termsEnum.totalTermFreq());
-    PostingsEnum positions = termsEnum.postings(null, null, PostingsEnum.ALL);
+    PostingsEnum positions = termsEnum.postings(null, PostingsEnum.ALL);
     assertTrue(positions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
     assertEquals(2, positions.freq());
     positions.nextPosition();
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/TestClassicAnalyzer.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/TestClassicAnalyzer.java
index 5f00575..90b31d2 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/TestClassicAnalyzer.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/TestClassicAnalyzer.java
@@ -300,7 +300,6 @@ public class TestClassicAnalyzer extends BaseTokenStreamTestCase {
     // Make sure position is still incremented when
     // massive term is skipped:
     PostingsEnum tps = MultiFields.getTermPositionsEnum(reader,
-                                                                MultiFields.getLiveDocs(reader),
                                                                 "content",
                                                                 new BytesRef("another"));
     assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
diff --git a/lucene/backward-codecs/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java b/lucene/backward-codecs/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java
index 8672b8f..0b143f0 100644
--- a/lucene/backward-codecs/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java
+++ b/lucene/backward-codecs/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java
@@ -991,7 +991,7 @@ public class TestBackwardsCompatibility extends LuceneTestCase {
       // should be found exactly
       assertEquals(TermsEnum.SeekStatus.FOUND,
                    terms.seekCeil(aaaTerm));
-      assertEquals(35, countDocs(TestUtil.docs(random(), terms, null, null, PostingsEnum.NONE)));
+      assertEquals(35, countDocs(TestUtil.docs(random(), terms, null, PostingsEnum.NONE)));
       assertNull(terms.next());
 
       // should hit end of field
@@ -1003,12 +1003,12 @@ public class TestBackwardsCompatibility extends LuceneTestCase {
       assertEquals(TermsEnum.SeekStatus.NOT_FOUND,
                    terms.seekCeil(new BytesRef("a")));
       assertTrue(terms.term().bytesEquals(aaaTerm));
-      assertEquals(35, countDocs(TestUtil.docs(random(), terms, null, null, PostingsEnum.NONE)));
+      assertEquals(35, countDocs(TestUtil.docs(random(), terms, null, PostingsEnum.NONE)));
       assertNull(terms.next());
 
       assertEquals(TermsEnum.SeekStatus.FOUND,
                    terms.seekCeil(aaaTerm));
-      assertEquals(35, countDocs(TestUtil.docs(random(), terms, null, null, PostingsEnum.NONE)));
+      assertEquals(35, countDocs(TestUtil.docs(random(), terms, null, PostingsEnum.NONE)));
       assertNull(terms.next());
 
       r.close();
diff --git a/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic.java b/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic.java
index ddbd774..d894f01 100644
--- a/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic.java
+++ b/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic.java
@@ -499,7 +499,7 @@ public class TestPerfTasksLogic extends BenchmarkTestCase {
       TermsEnum termsEnum = terms.iterator();
       PostingsEnum docs = null;
       while(termsEnum.next() != null) {
-        docs = TestUtil.docs(random(), termsEnum, MultiFields.getLiveDocs(reader), docs, PostingsEnum.FREQS);
+        docs = TestUtil.docs(random(), termsEnum, docs, PostingsEnum.FREQS);
         while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
           totalTokenCount2 += docs.freq();
         }
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsReader.java b/lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsReader.java
index 5c1792c..354957a 100644
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsReader.java
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsReader.java
@@ -651,11 +651,11 @@ public class BlockTermsReader extends FieldsProducer {
       }
 
       @Override
-      public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
+      public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
         //System.out.println("BTR.docs this=" + this);
         decodeMetaData();
         //System.out.println("BTR.docs:  state.docFreq=" + state.docFreq);
-        return postingsReader.postings(fieldInfo, state, liveDocs, reuse, flags);
+        return postingsReader.postings(fieldInfo, state, reuse, flags);
       }
 
       @Override
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/blocktreeords/OrdsIntersectTermsEnum.java b/lucene/codecs/src/java/org/apache/lucene/codecs/blocktreeords/OrdsIntersectTermsEnum.java
index 3cf1c26..e5508e8 100644
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/blocktreeords/OrdsIntersectTermsEnum.java
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/blocktreeords/OrdsIntersectTermsEnum.java
@@ -202,9 +202,9 @@ final class OrdsIntersectTermsEnum extends TermsEnum {
   }
 
   @Override
-  public PostingsEnum postings(Bits skipDocs, PostingsEnum reuse, int flags) throws IOException {
+  public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
     currentFrame.decodeMetaData();
-    return fr.parent.postingsReader.postings(fr.fieldInfo, currentFrame.termState, skipDocs, reuse, flags);
+    return fr.parent.postingsReader.postings(fr.fieldInfo, currentFrame.termState, reuse, flags);
   }
 
   private int getState() {
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/blocktreeords/OrdsSegmentTermsEnum.java b/lucene/codecs/src/java/org/apache/lucene/codecs/blocktreeords/OrdsSegmentTermsEnum.java
index 9073a86..b361590 100644
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/blocktreeords/OrdsSegmentTermsEnum.java
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/blocktreeords/OrdsSegmentTermsEnum.java
@@ -923,7 +923,7 @@ public final class OrdsSegmentTermsEnum extends TermsEnum {
   }
 
   @Override
-  public PostingsEnum postings(Bits skipDocs, PostingsEnum reuse, int flags) throws IOException {
+  public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
     assert !eof;
     //if (DEBUG) {
     //System.out.println("BTTR.docs seg=" + segment);
@@ -932,7 +932,7 @@ public final class OrdsSegmentTermsEnum extends TermsEnum {
     //if (DEBUG) {
     //System.out.println("  state=" + currentFrame.state);
     //}
-    return fr.parent.postingsReader.postings(fr.fieldInfo, currentFrame.state, skipDocs, reuse, flags);
+    return fr.parent.postingsReader.postings(fr.fieldInfo, currentFrame.state, reuse, flags);
   }
 
   @Override
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.java b/lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.java
index af7744d..d8a98a5 100644
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.java
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.java
@@ -369,9 +369,9 @@ public final class BloomFilteringPostingsFormat extends PostingsFormat {
       }
 
       @Override
-      public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags)
+      public PostingsEnum postings(PostingsEnum reuse, int flags)
           throws IOException {
-        return delegate().postings(liveDocs, reuse, flags);
+        return delegate().postings(reuse, flags);
       }
 
     }
@@ -455,7 +455,7 @@ public final class BloomFilteringPostingsFormat extends PostingsFormat {
             bloomFilters.put(fieldInfo, bloomFilter);
           }
           // Make sure there's at least one doc for this term:
-          postingsEnum = termsEnum.postings(null, postingsEnum, 0);
+          postingsEnum = termsEnum.postings(postingsEnum, 0);
           if (postingsEnum.nextDoc() != PostingsEnum.NO_MORE_DOCS) {
             bloomFilter.addValue(term);
           }
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/memory/DirectPostingsFormat.java b/lucene/codecs/src/java/org/apache/lucene/codecs/memory/DirectPostingsFormat.java
index 23c0ac9..b12a5c6 100644
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/memory/DirectPostingsFormat.java
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/memory/DirectPostingsFormat.java
@@ -43,7 +43,6 @@ import org.apache.lucene.store.RAMOutputStream;
 import org.apache.lucene.util.Accountable;
 import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.ArrayUtil;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.RamUsageEstimator;
 import org.apache.lucene.util.automaton.CompiledAutomaton;
@@ -357,9 +356,9 @@ public final class DirectPostingsFormat extends PostingsFormat {
         termOffsets[count+1] = termOffset;
 
         if (hasPos) {
-          docsAndPositionsEnum = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.ALL);
+          docsAndPositionsEnum = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.ALL);
         } else {
-          postingsEnum = termsEnum.postings(null, postingsEnum);
+          postingsEnum = termsEnum.postings(postingsEnum);
         }
 
         final TermAndSkip ent;
@@ -848,7 +847,7 @@ public final class DirectPostingsFormat extends PostingsFormat {
       }
 
       @Override
-      public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
+      public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
         // TODO: implement reuse
         // it's hairy!
 
@@ -862,11 +861,8 @@ public final class DirectPostingsFormat extends PostingsFormat {
               LowFreqDocsEnumNoTF docsEnum;
               if (reuse instanceof LowFreqDocsEnumNoTF) {
                 docsEnum = (LowFreqDocsEnumNoTF) reuse;
-                if (!docsEnum.canReuse(liveDocs)) {
-                  docsEnum = new LowFreqDocsEnumNoTF(liveDocs);
-                }
               } else {
-                docsEnum = new LowFreqDocsEnumNoTF(liveDocs);
+                docsEnum = new LowFreqDocsEnumNoTF();
               }
 
               return docsEnum.reset(postings);
@@ -875,23 +871,20 @@ public final class DirectPostingsFormat extends PostingsFormat {
               LowFreqDocsEnumNoPos docsEnum;
               if (reuse instanceof LowFreqDocsEnumNoPos) {
                 docsEnum = (LowFreqDocsEnumNoPos) reuse;
-                if (!docsEnum.canReuse(liveDocs)) {
-                  docsEnum = new LowFreqDocsEnumNoPos(liveDocs);
-                }
               } else {
-                docsEnum = new LowFreqDocsEnumNoPos(liveDocs);
+                docsEnum = new LowFreqDocsEnumNoPos();
               }
 
               return docsEnum.reset(postings);
             }
             final byte[] payloads = term.payloads;
-            return new LowFreqPostingsEnum(liveDocs, hasOffsets, hasPayloads).reset(postings, payloads);
+            return new LowFreqPostingsEnum(hasOffsets, hasPayloads).reset(postings, payloads);
           } else {
             final HighFreqTerm term = (HighFreqTerm) terms[termOrd];
             if (hasPos == false) {
-              return new HighFreqDocsEnum(liveDocs).reset(term.docIDs, term.freqs);
+              return new HighFreqDocsEnum().reset(term.docIDs, term.freqs);
             } else {
-              return new HighFreqPostingsEnum(liveDocs, hasOffsets).reset(term.docIDs, term.freqs, term.positions, term.payloads);
+              return new HighFreqPostingsEnum(hasOffsets).reset(term.docIDs, term.freqs, term.positions, term.payloads);
             }
           }
         }
@@ -912,11 +905,8 @@ public final class DirectPostingsFormat extends PostingsFormat {
               LowFreqDocsEnum docsEnum;
               if (reuse instanceof LowFreqDocsEnum) {
                 docsEnum = (LowFreqDocsEnum) reuse;
-                if (!docsEnum.canReuse(liveDocs, posLen)) {
-                  docsEnum = new LowFreqDocsEnum(liveDocs, posLen);
-                }
               } else {
-                docsEnum = new LowFreqDocsEnum(liveDocs, posLen);
+                docsEnum = new LowFreqDocsEnum( posLen);
               }
 
               return docsEnum.reset(postings);
@@ -924,11 +914,8 @@ public final class DirectPostingsFormat extends PostingsFormat {
               LowFreqDocsEnumNoPos docsEnum;
               if (reuse instanceof LowFreqDocsEnumNoPos) {
                 docsEnum = (LowFreqDocsEnumNoPos) reuse;
-                if (!docsEnum.canReuse(liveDocs)) {
-                  docsEnum = new LowFreqDocsEnumNoPos(liveDocs);
-                }
               } else {
-                docsEnum = new LowFreqDocsEnumNoPos(liveDocs);
+                docsEnum = new LowFreqDocsEnumNoPos();
               }
 
               return docsEnum.reset(postings);
@@ -937,11 +924,8 @@ public final class DirectPostingsFormat extends PostingsFormat {
             LowFreqDocsEnumNoTF docsEnum;
             if (reuse instanceof LowFreqDocsEnumNoTF) {
               docsEnum = (LowFreqDocsEnumNoTF) reuse;
-              if (!docsEnum.canReuse(liveDocs)) {
-                docsEnum = new LowFreqDocsEnumNoTF(liveDocs);
-              }
             } else {
-              docsEnum = new LowFreqDocsEnumNoTF(liveDocs);
+              docsEnum = new LowFreqDocsEnumNoTF();
             }
 
             return docsEnum.reset(postings);
@@ -952,11 +936,8 @@ public final class DirectPostingsFormat extends PostingsFormat {
           HighFreqDocsEnum docsEnum;
           if (reuse instanceof HighFreqDocsEnum) {
             docsEnum = (HighFreqDocsEnum) reuse;
-            if (!docsEnum.canReuse(liveDocs)) {
-              docsEnum = new HighFreqDocsEnum(liveDocs);
-            }
           } else {
-            docsEnum = new HighFreqDocsEnum(liveDocs);
+            docsEnum = new HighFreqDocsEnum();
           }
 
           //System.out.println("  DE for term=" + new BytesRef(terms[termOrd].term).utf8ToString() + ": " + term.docIDs.length + " docs");
@@ -1471,7 +1452,7 @@ public final class DirectPostingsFormat extends PostingsFormat {
       }
 
       @Override
-      public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) {
+      public PostingsEnum postings(PostingsEnum reuse, int flags) {
         // TODO: implement reuse
         // it's hairy!
 
@@ -1481,10 +1462,10 @@ public final class DirectPostingsFormat extends PostingsFormat {
             final LowFreqTerm term = ((LowFreqTerm) terms[termOrd]);
             final int[] postings = term.postings;
             final byte[] payloads = term.payloads;
-            return new LowFreqPostingsEnum(liveDocs, hasOffsets, hasPayloads).reset(postings, payloads);
+            return new LowFreqPostingsEnum(hasOffsets, hasPayloads).reset(postings, payloads);
           } else {
             final HighFreqTerm term = (HighFreqTerm) terms[termOrd];
-            return new HighFreqPostingsEnum(liveDocs, hasOffsets).reset(term.docIDs, term.freqs, term.positions, term.payloads);
+            return new HighFreqPostingsEnum(hasOffsets).reset(term.docIDs, term.freqs, term.positions, term.payloads);
           }
         }
 
@@ -1501,17 +1482,17 @@ public final class DirectPostingsFormat extends PostingsFormat {
               if (hasPayloads) {
                 posLen++;
               }
-              return new LowFreqDocsEnum(liveDocs, posLen).reset(postings);
+              return new LowFreqDocsEnum(posLen).reset(postings);
             } else {
-              return new LowFreqDocsEnumNoPos(liveDocs).reset(postings);
+              return new LowFreqDocsEnumNoPos().reset(postings);
             }
           } else {
-            return new LowFreqDocsEnumNoTF(liveDocs).reset(postings);
+            return new LowFreqDocsEnumNoTF().reset(postings);
           }
         } else {
           final HighFreqTerm term = (HighFreqTerm) terms[termOrd];
           //  System.out.println("DE for term=" + new BytesRef(terms[termOrd].term).utf8ToString() + ": " + term.docIDs.length + " docs");
-          return new HighFreqDocsEnum(liveDocs).reset(term.docIDs, term.freqs);
+          return new HighFreqDocsEnum().reset(term.docIDs, term.freqs);
         }
       }
 
@@ -1530,17 +1511,8 @@ public final class DirectPostingsFormat extends PostingsFormat {
   // Docs only:
   private final static class LowFreqDocsEnumNoTF extends PostingsEnum {
     private int[] postings;
-    private final Bits liveDocs;
     private int upto;
 
-    public LowFreqDocsEnumNoTF(Bits liveDocs) {
-      this.liveDocs = liveDocs;
-    }
-
-    public boolean canReuse(Bits liveDocs) {
-      return liveDocs == this.liveDocs;
-    }
-
     public PostingsEnum reset(int[] postings) {
       this.postings = postings;
       upto = -1;
@@ -1552,17 +1524,8 @@ public final class DirectPostingsFormat extends PostingsFormat {
     @Override
     public int nextDoc() {
       upto++;
-      if (liveDocs == null) {
-        if (upto < postings.length) {
-          return postings[upto];
-        }
-      } else {
-        while (upto < postings.length) {
-          if (liveDocs.get(postings[upto])) {
-            return postings[upto];
-          }
-          upto++;
-        }
+      if (upto < postings.length) {
+        return postings[upto];
       }
       return NO_MORE_DOCS;
     }
@@ -1619,16 +1582,9 @@ public final class DirectPostingsFormat extends PostingsFormat {
   // Docs + freqs:
   private final static class LowFreqDocsEnumNoPos extends PostingsEnum {
     private int[] postings;
-    private final Bits liveDocs;
     private int upto;
 
-    public LowFreqDocsEnumNoPos(Bits liveDocs) {
-      this.liveDocs = liveDocs;
-    }
-
-    public boolean canReuse(Bits liveDocs) {
-      return liveDocs == this.liveDocs;
-    }
+    public LowFreqDocsEnumNoPos() {}
 
     public PostingsEnum reset(int[] postings) {
       this.postings = postings;
@@ -1640,17 +1596,8 @@ public final class DirectPostingsFormat extends PostingsFormat {
     @Override
     public int nextDoc() {
       upto += 2;
-      if (liveDocs == null) {
-        if (upto < postings.length) {
-          return postings[upto];
-        }
-      } else {
-        while (upto < postings.length) {
-          if (liveDocs.get(postings[upto])) {
-            return postings[upto];
-          }
-          upto += 2;
-        }
+      if (upto < postings.length) {
+        return postings[upto];
       }
       return NO_MORE_DOCS;
     }
@@ -1707,23 +1654,17 @@ public final class DirectPostingsFormat extends PostingsFormat {
   // Docs + freqs + positions/offets:
   private final static class LowFreqDocsEnum extends PostingsEnum {
     private int[] postings;
-    private final Bits liveDocs;
     private final int posMult;
     private int upto;
     private int freq;
 
-    public LowFreqDocsEnum(Bits liveDocs, int posMult) {
-      this.liveDocs = liveDocs;
+    public LowFreqDocsEnum(int posMult) {
       this.posMult = posMult;
       // if (DEBUG) {
       //   System.out.println("LowFreqDE: posMult=" + posMult);
       // }
     }
 
-    public boolean canReuse(Bits liveDocs, int posMult) {
-      return liveDocs == this.liveDocs && posMult == this.posMult;
-    }
-
     public PostingsEnum reset(int[] postings) {
       this.postings = postings;
       upto = -2;
@@ -1738,21 +1679,10 @@ public final class DirectPostingsFormat extends PostingsFormat {
       // if (DEBUG) {
       //   System.out.println("  nextDoc freq=" + freq + " upto=" + upto + " vs " + postings.length);
       // }
-      if (liveDocs == null) {
-        if (upto < postings.length) {
-          freq = postings[upto+1];
-          assert freq > 0;
-          return postings[upto];
-        }
-      } else {
-        while (upto < postings.length) {
-          freq = postings[upto+1];
-          assert freq > 0;
-          if (liveDocs.get(postings[upto])) {
-            return postings[upto];
-          }
-          upto += 2 + freq*posMult;
-        }
+      if (upto < postings.length) {
+        freq = postings[upto+1];
+        assert freq > 0;
+        return postings[upto];
       }
       return NO_MORE_DOCS;
     }
@@ -1811,7 +1741,6 @@ public final class DirectPostingsFormat extends PostingsFormat {
 
   private final static class LowFreqPostingsEnum extends PostingsEnum {
     private int[] postings;
-    private final Bits liveDocs;
     private final int posMult;
     private final boolean hasOffsets;
     private final boolean hasPayloads;
@@ -1828,8 +1757,7 @@ public final class DirectPostingsFormat extends PostingsFormat {
     private int payloadLength;
     private byte[] payloadBytes;
 
-    public LowFreqPostingsEnum(Bits liveDocs, boolean hasOffsets, boolean hasPayloads) {
-      this.liveDocs = liveDocs;
+    public LowFreqPostingsEnum(boolean hasOffsets, boolean hasPayloads) {
       this.hasOffsets = hasOffsets;
       this.hasPayloads = hasPayloads;
       if (hasOffsets) {
@@ -1873,33 +1801,11 @@ public final class DirectPostingsFormat extends PostingsFormat {
         upto += posMult * skipPositions;
       }
 
-      if (liveDocs == null) {
-        if (upto < postings.length) {
-          docID = postings[upto++];
-          freq = postings[upto++];
-          skipPositions = freq;
-          return docID;
-        }
-      } else {
-        while(upto < postings.length) {
-          docID = postings[upto++];
-          freq = postings[upto++];
-          if (liveDocs.get(docID)) {
-            skipPositions = freq;
-            return docID;
-          }
-          if (hasPayloads) {
-            for(int i=0;i<freq;i++) {
-              upto++;
-              if (hasOffsets) {
-                upto += 2;
-              }
-              payloadOffset += postings[upto++];
-            }
-          } else {
-            upto += posMult * freq;
-          }
-        }
+      if (upto < postings.length) {
+        docID = postings[upto++];
+        freq = postings[upto++];
+        skipPositions = freq;
+        return docID;
       }
 
       return docID = NO_MORE_DOCS;
@@ -1970,17 +1876,10 @@ public final class DirectPostingsFormat extends PostingsFormat {
   private final static class HighFreqDocsEnum extends PostingsEnum {
     private int[] docIDs;
     private int[] freqs;
-    private final Bits liveDocs;
     private int upto;
     private int docID = -1;
 
-    public HighFreqDocsEnum(Bits liveDocs) {
-      this.liveDocs = liveDocs;
-    }
-
-    public boolean canReuse(Bits liveDocs) {
-      return liveDocs == this.liveDocs;
-    }
+    public HighFreqDocsEnum() {}
 
     public int[] getDocIDs() {
       return docIDs;
@@ -2000,18 +1899,9 @@ public final class DirectPostingsFormat extends PostingsFormat {
     @Override
     public int nextDoc() {
       upto++;
-      if (liveDocs == null) {
-        try {
-          return docID = docIDs[upto];
-        } catch (ArrayIndexOutOfBoundsException e) {
-        }
-      } else {
-        while (upto < docIDs.length) {
-          if (liveDocs.get(docIDs[upto])) {
-            return docID = docIDs[upto];
-          }
-          upto++;
-        }
+      try {
+        return docID = docIDs[upto];
+      } catch (ArrayIndexOutOfBoundsException e) {
       }
       return docID = NO_MORE_DOCS;
     }
@@ -2121,14 +2011,6 @@ public final class DirectPostingsFormat extends PostingsFormat {
 
       //System.out.println("    end upto=" + upto + " docID=" + (upto >= docIDs.length ? NO_MORE_DOCS : docIDs[upto]));
 
-      if (liveDocs != null) {
-        while (upto < docIDs.length) {
-          if (liveDocs.get(docIDs[upto])) {
-            break;
-          }
-          upto++;
-        }
-      }
       if (upto == docIDs.length) {
         //System.out.println("    return END");
         return docID = NO_MORE_DOCS;
@@ -2170,7 +2052,6 @@ public final class DirectPostingsFormat extends PostingsFormat {
     private int[] freqs;
     private int[][] positions;
     private byte[][][] payloads;
-    private final Bits liveDocs;
     private final boolean hasOffsets;
     private final int posJump;
     private int upto;
@@ -2178,8 +2059,7 @@ public final class DirectPostingsFormat extends PostingsFormat {
     private int posUpto;
     private int[] curPositions;
 
-    public HighFreqPostingsEnum(Bits liveDocs, boolean hasOffsets) {
-      this.liveDocs = liveDocs;
+    public HighFreqPostingsEnum(boolean hasOffsets) {
       this.hasOffsets = hasOffsets;
       posJump = hasOffsets ? 3 : 1;
     }
@@ -2196,10 +2076,6 @@ public final class DirectPostingsFormat extends PostingsFormat {
       return posJump;
     }
 
-    public Bits getLiveDocs() {
-      return liveDocs;
-    }
-
     public PostingsEnum reset(int[] docIDs, int[] freqs, int[][] positions, byte[][][] payloads) {
       this.docIDs = docIDs;
       this.freqs = freqs;
@@ -2212,21 +2088,10 @@ public final class DirectPostingsFormat extends PostingsFormat {
     @Override
     public int nextDoc() {
       upto++;
-      if (liveDocs == null) {
-        if (upto < docIDs.length) {
-          posUpto = -posJump;
-          curPositions = positions[upto];
-          return docID = docIDs[upto];
-        }
-      } else {
-        while (upto < docIDs.length) {
-          if (liveDocs.get(docIDs[upto])) {
-            posUpto = -posJump;
-            curPositions = positions[upto];
-            return docID = docIDs[upto];
-          }
-          upto++;
-        }
+      if (upto < docIDs.length) {
+        posUpto = -posJump;
+        curPositions = positions[upto];
+        return docID = docIDs[upto];
       }
 
       return docID = NO_MORE_DOCS;
@@ -2360,14 +2225,6 @@ public final class DirectPostingsFormat extends PostingsFormat {
 
       //System.out.println("    end upto=" + upto + " docID=" + (upto >= docIDs.length ? NO_MORE_DOCS : docIDs[upto]));
 
-      if (liveDocs != null) {
-        while (upto < docIDs.length) {
-          if (liveDocs.get(docIDs[upto])) {
-            break;
-          }
-          upto++;
-        }
-      }
       if (upto == docIDs.length) {
         //System.out.println("    return END");
         return docID = NO_MORE_DOCS;
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader.java b/lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader.java
index ddce8d3..4f0d1e2 100644
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader.java
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader.java
@@ -427,9 +427,9 @@ public class FSTOrdTermsReader extends FieldsProducer {
       }
 
       @Override
-      public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
+      public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
         decodeMetaData();
-        return postingsReader.postings(fieldInfo, state, liveDocs, reuse, flags);
+        return postingsReader.postings(fieldInfo, state, reuse, flags);
       }
 
       // TODO: this can be achieved by making use of Util.getByOutput()
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader.java b/lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader.java
index 4676f87..95ff20f 100644
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader.java
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader.java
@@ -46,7 +46,6 @@ import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.util.Accountable;
 import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.ArrayUtil;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
 import org.apache.lucene.util.IOUtils;
@@ -290,9 +289,9 @@ public class FSTTermsReader extends FieldsProducer {
       }
 
       @Override
-      public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
+      public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
         decodeMetaData();
-        return postingsReader.postings(fieldInfo, state, liveDocs, reuse, flags);
+        return postingsReader.postings(fieldInfo, state, reuse, flags);
       }
 
       @Override
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryDocValuesProducer.java b/lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryDocValuesProducer.java
index 6d6aa8b..fe769a6 100644
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryDocValuesProducer.java
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryDocValuesProducer.java
@@ -892,7 +892,7 @@ class MemoryDocValuesProducer extends DocValuesProducer {
     }
 
     @Override
-    public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
+    public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
       throw new UnsupportedOperationException();
     }
 
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat.java b/lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat.java
index e32f6df..be0fab2 100644
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat.java
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat.java
@@ -353,10 +353,10 @@ public final class MemoryPostingsFormat extends PostingsFormat {
           termsWriter.postingsWriter.reset();
 
           if (writePositions) {
-            posEnum = termsEnum.postings(null, posEnum, enumFlags);
+            posEnum = termsEnum.postings(posEnum, enumFlags);
             postingsEnum = posEnum;
           } else {
-            postingsEnum = termsEnum.postings(null, postingsEnum, enumFlags);
+            postingsEnum = termsEnum.postings(postingsEnum, enumFlags);
             posEnum = null;
           }
 
@@ -433,7 +433,6 @@ public final class MemoryPostingsFormat extends PostingsFormat {
     private byte[] buffer = new byte[16];
     private final ByteArrayDataInput in = new ByteArrayDataInput(buffer);
 
-    private Bits liveDocs;
     private int docUpto;
     private int docID = -1;
     private int accum;
@@ -450,14 +449,13 @@ public final class MemoryPostingsFormat extends PostingsFormat {
       return indexOptions == this.indexOptions && storePayloads == this.storePayloads;
     }
     
-    public FSTDocsEnum reset(BytesRef bufferIn, Bits liveDocs, int numDocs) {
+    public FSTDocsEnum reset(BytesRef bufferIn, int numDocs) {
       assert numDocs > 0;
       if (buffer.length < bufferIn.length) {
         buffer = ArrayUtil.grow(buffer, bufferIn.length);
       }
       in.reset(buffer, 0, bufferIn.length);
       System.arraycopy(bufferIn.bytes, bufferIn.offset, buffer, 0, bufferIn.length);
-      this.liveDocs = liveDocs;
       docID = -1;
       accum = 0;
       docUpto = 0;
@@ -469,62 +467,58 @@ public final class MemoryPostingsFormat extends PostingsFormat {
 
     @Override
     public int nextDoc() {
-      while(true) {
-        //System.out.println("  nextDoc cycle docUpto=" + docUpto + " numDocs=" + numDocs + " fp=" + in.getPosition() + " this=" + this);
-        if (docUpto == numDocs) {
-          // System.out.println("    END");
-          return docID = NO_MORE_DOCS;
-        }
-        docUpto++;
-        if (indexOptions == IndexOptions.DOCS) {
-          accum += in.readVInt();
+      //System.out.println("  nextDoc cycle docUpto=" + docUpto + " numDocs=" + numDocs + " fp=" + in.getPosition() + " this=" + this);
+      if (docUpto == numDocs) {
+        // System.out.println("    END");
+        return docID = NO_MORE_DOCS;
+      }
+      docUpto++;
+      if (indexOptions == IndexOptions.DOCS) {
+        accum += in.readVInt();
+      } else {
+        final int code = in.readVInt();
+        accum += code >>> 1;
+        //System.out.println("  docID=" + accum + " code=" + code);
+        if ((code & 1) != 0) {
+          freq = 1;
         } else {
-          final int code = in.readVInt();
-          accum += code >>> 1;
-          //System.out.println("  docID=" + accum + " code=" + code);
-          if ((code & 1) != 0) {
-            freq = 1;
-          } else {
-            freq = in.readVInt();
-            assert freq > 0;
-          }
+          freq = in.readVInt();
+          assert freq > 0;
+        }
 
-          if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {
-            // Skip positions/payloads
-            for(int posUpto=0;posUpto<freq;posUpto++) {
-              if (!storePayloads) {
-                in.readVInt();
-              } else {
-                final int posCode = in.readVInt();
-                if ((posCode & 1) != 0) {
-                  payloadLen = in.readVInt();
-                }
-                in.skipBytes(payloadLen);
-              }
-            }
-          } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) {
-            // Skip positions/offsets/payloads
-            for(int posUpto=0;posUpto<freq;posUpto++) {
-              int posCode = in.readVInt();
-              if (storePayloads && ((posCode & 1) != 0)) {
+        if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {
+          // Skip positions/payloads
+          for(int posUpto=0;posUpto<freq;posUpto++) {
+            if (!storePayloads) {
+              in.readVInt();
+            } else {
+              final int posCode = in.readVInt();
+              if ((posCode & 1) != 0) {
                 payloadLen = in.readVInt();
               }
-              if ((in.readVInt() & 1) != 0) {
-                // new offset length
-                in.readVInt();
-              }
-              if (storePayloads) {
-                in.skipBytes(payloadLen);
-              }
+              in.skipBytes(payloadLen);
+            }
+          }
+        } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) {
+          // Skip positions/offsets/payloads
+          for(int posUpto=0;posUpto<freq;posUpto++) {
+            int posCode = in.readVInt();
+            if (storePayloads && ((posCode & 1) != 0)) {
+              payloadLen = in.readVInt();
+            }
+            if ((in.readVInt() & 1) != 0) {
+              // new offset length
+              in.readVInt();
+            }
+            if (storePayloads) {
+              in.skipBytes(payloadLen);
             }
           }
-        }
-
-        if (liveDocs == null || liveDocs.get(accum)) {
-          //System.out.println("    return docID=" + accum + " freq=" + freq);
-          return (docID = accum);
         }
       }
+
+      //System.out.println("    return docID=" + accum + " freq=" + freq);
+      return (docID = accum);
     }
 
     @Override
@@ -577,7 +571,6 @@ public final class MemoryPostingsFormat extends PostingsFormat {
     private byte[] buffer = new byte[16];
     private final ByteArrayDataInput in = new ByteArrayDataInput(buffer);
 
-    private Bits liveDocs;
     private int docUpto;
     private int docID = -1;
     private int accum;
@@ -601,7 +594,7 @@ public final class MemoryPostingsFormat extends PostingsFormat {
       return storePayloads == this.storePayloads && storeOffsets == this.storeOffsets;
     }
     
-    public FSTPostingsEnum reset(BytesRef bufferIn, Bits liveDocs, int numDocs) {
+    public FSTPostingsEnum reset(BytesRef bufferIn, int numDocs) {
       assert numDocs > 0;
 
       // System.out.println("D&P reset bytes this=" + this);
@@ -614,7 +607,6 @@ public final class MemoryPostingsFormat extends PostingsFormat {
       }
       in.reset(buffer, 0, bufferIn.length - bufferIn.offset);
       System.arraycopy(bufferIn.bytes, bufferIn.offset, buffer, 0, bufferIn.length);
-      this.liveDocs = liveDocs;
       docID = -1;
       accum = 0;
       docUpto = 0;
@@ -649,37 +641,11 @@ public final class MemoryPostingsFormat extends PostingsFormat {
           assert freq > 0;
         }
 
-        if (liveDocs == null || liveDocs.get(accum)) {
-          pos = 0;
-          startOffset = storeOffsets ? 0 : -1;
-          posPending = freq;
-          //System.out.println("    return docID=" + accum + " freq=" + freq);
-          return (docID = accum);
-        }
-
-        // Skip positions
-        for(int posUpto=0;posUpto<freq;posUpto++) {
-          if (!storePayloads) {
-            in.readVInt();
-          } else {
-            final int skipCode = in.readVInt();
-            if ((skipCode & 1) != 0) {
-              payloadLength = in.readVInt();
-              //System.out.println("    new payloadLen=" + payloadLength);
-            }
-          }
-          
-          if (storeOffsets) {
-            if ((in.readVInt() & 1) != 0) {
-              // new offset length
-              offsetLength = in.readVInt();
-            }
-          }
-          
-          if (storePayloads) {
-            in.skipBytes(payloadLength);
-          }
-        }
+        pos = 0;
+        startOffset = storeOffsets ? 0 : -1;
+        posPending = freq;
+        //System.out.println("    return docID=" + accum + " freq=" + freq);
+        return (docID = accum);
       }
     }
 
@@ -827,7 +793,7 @@ public final class MemoryPostingsFormat extends PostingsFormat {
     }
     
     @Override
-    public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) {
+    public PostingsEnum postings(PostingsEnum reuse, int flags) {
 
       // TODO: the logic of which enum impl to choose should be refactored to be simpler...
       boolean hasPositions = field.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;
@@ -844,7 +810,7 @@ public final class MemoryPostingsFormat extends PostingsFormat {
           }
         }
         //System.out.println("D&P reset this=" + this);
-        return docsAndPositionsEnum.reset(postingsSpare, liveDocs, docFreq);
+        return docsAndPositionsEnum.reset(postingsSpare, docFreq);
       }
 
       decodeMetaData();
@@ -858,7 +824,7 @@ public final class MemoryPostingsFormat extends PostingsFormat {
           docsEnum = new FSTDocsEnum(field.getIndexOptions(), field.hasPayloads());
         }
       }
-      return docsEnum.reset(this.postingsSpare, liveDocs, docFreq);
+      return docsEnum.reset(this.postingsSpare, docFreq);
     }
 
     @Override
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextFieldsReader.java b/lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextFieldsReader.java
index 997a34c..20a0b8b 100644
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextFieldsReader.java
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextFieldsReader.java
@@ -207,7 +207,7 @@ class SimpleTextFieldsReader extends FieldsProducer {
     }
 
     @Override
-    public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
+    public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
 
       boolean hasPositions = indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;
       if (hasPositions && PostingsEnum.featureRequested(flags, PostingsEnum.POSITIONS)) {
@@ -218,7 +218,7 @@ class SimpleTextFieldsReader extends FieldsProducer {
         } else {
           docsAndPositionsEnum = new SimpleTextPostingsEnum();
         }
-        return docsAndPositionsEnum.reset(docsStart, liveDocs, indexOptions, docFreq);
+        return docsAndPositionsEnum.reset(docsStart, indexOptions, docFreq);
 
       }
 
@@ -228,7 +228,7 @@ class SimpleTextFieldsReader extends FieldsProducer {
       } else {
         docsEnum = new SimpleTextDocsEnum();
       }
-      return docsEnum.reset(docsStart, liveDocs, indexOptions == IndexOptions.DOCS, docFreq);
+      return docsEnum.reset(docsStart, indexOptions == IndexOptions.DOCS, docFreq);
     }
 
   }
@@ -239,7 +239,6 @@ class SimpleTextFieldsReader extends FieldsProducer {
     private boolean omitTF;
     private int docID = -1;
     private int tf;
-    private Bits liveDocs;
     private final BytesRefBuilder scratch = new BytesRefBuilder();
     private final CharsRefBuilder scratchUTF16 = new CharsRefBuilder();
     private int cost;
@@ -253,8 +252,7 @@ class SimpleTextFieldsReader extends FieldsProducer {
       return in == inStart;
     }
 
-    public SimpleTextDocsEnum reset(long fp, Bits liveDocs, boolean omitTF, int docFreq) throws IOException {
-      this.liveDocs = liveDocs;
+    public SimpleTextDocsEnum reset(long fp, boolean omitTF, int docFreq) throws IOException {
       in.seek(fp);
       this.omitTF = omitTF;
       docID = -1;
@@ -304,7 +302,7 @@ class SimpleTextFieldsReader extends FieldsProducer {
         final long lineStart = in.getFilePointer();
         SimpleTextUtil.readLine(in, scratch);
         if (StringHelper.startsWith(scratch.get(), DOC)) {
-          if (!first && (liveDocs == null || liveDocs.get(docID))) {
+          if (!first) {
             in.seek(lineStart);
             if (!omitTF) {
               tf = termFreq;
@@ -328,7 +326,7 @@ class SimpleTextFieldsReader extends FieldsProducer {
           // skip
         } else {
           assert StringHelper.startsWith(scratch.get(), TERM) || StringHelper.startsWith(scratch.get(), FIELD) || StringHelper.startsWith(scratch.get(), END): "scratch=" + scratch.get().utf8ToString();
-          if (!first && (liveDocs == null || liveDocs.get(docID))) {
+          if (!first) {
             in.seek(lineStart);
             if (!omitTF) {
               tf = termFreq;
@@ -357,7 +355,6 @@ class SimpleTextFieldsReader extends FieldsProducer {
     private final IndexInput in;
     private int docID = -1;
     private int tf;
-    private Bits liveDocs;
     private final BytesRefBuilder scratch = new BytesRefBuilder();
     private final BytesRefBuilder scratch2 = new BytesRefBuilder();
     private final CharsRefBuilder scratchUTF16 = new CharsRefBuilder();
@@ -380,8 +377,7 @@ class SimpleTextFieldsReader extends FieldsProducer {
       return in == inStart;
     }
 
-    public SimpleTextPostingsEnum reset(long fp, Bits liveDocs, IndexOptions indexOptions, int docFreq) {
-      this.liveDocs = liveDocs;
+    public SimpleTextPostingsEnum reset(long fp, IndexOptions indexOptions, int docFreq) {
       nextDocStart = fp;
       docID = -1;
       readPositions = indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;
@@ -414,7 +410,7 @@ class SimpleTextFieldsReader extends FieldsProducer {
         SimpleTextUtil.readLine(in, scratch);
         //System.out.println("NEXT DOC: " + scratch.utf8ToString());
         if (StringHelper.startsWith(scratch.get(), DOC)) {
-          if (!first && (liveDocs == null || liveDocs.get(docID))) {
+          if (!first) {
             nextDocStart = lineStart;
             in.seek(posStart);
             return docID;
@@ -437,7 +433,7 @@ class SimpleTextFieldsReader extends FieldsProducer {
           // skip
         } else {
           assert StringHelper.startsWith(scratch.get(), TERM) || StringHelper.startsWith(scratch.get(), FIELD) || StringHelper.startsWith(scratch.get(), END);
-          if (!first && (liveDocs == null || liveDocs.get(docID))) {
+          if (!first) {
             nextDocStart = lineStart;
             in.seek(posStart);
             return docID;
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextFieldsWriter.java b/lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextFieldsWriter.java
index 6ee43c8..476d102 100644
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextFieldsWriter.java
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextFieldsWriter.java
@@ -101,7 +101,7 @@ class SimpleTextFieldsWriter extends FieldsConsumer {
           break;
         }
 
-        postingsEnum = termsEnum.postings(null, postingsEnum, flags);
+        postingsEnum = termsEnum.postings(postingsEnum, flags);
 
         assert postingsEnum != null: "termsEnum=" + termsEnum + " hasPos=" + hasPositions + " flags=" + flags;
 
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextTermVectorsReader.java b/lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextTermVectorsReader.java
index 35e7388..9211367 100644
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextTermVectorsReader.java
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextTermVectorsReader.java
@@ -387,21 +387,21 @@ public class SimpleTextTermVectorsReader extends TermVectorsReader {
     }
 
     @Override
-    public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
+    public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
       
       if (PostingsEnum.featureRequested(flags, PostingsEnum.POSITIONS)) {
         SimpleTVPostings postings = current.getValue();
         if (postings.positions != null || postings.startOffsets != null) {
           // TODO: reuse
           SimpleTVPostingsEnum e = new SimpleTVPostingsEnum();
-          e.reset(liveDocs, postings.positions, postings.startOffsets, postings.endOffsets, postings.payloads);
+          e.reset(postings.positions, postings.startOffsets, postings.endOffsets, postings.payloads);
           return e;
         }
       }
 
       // TODO: reuse
       SimpleTVDocsEnum e = new SimpleTVDocsEnum();
-      e.reset(liveDocs, PostingsEnum.featureRequested(flags, PostingsEnum.FREQS) == false ? 1 : current.getValue().freq);
+      e.reset(PostingsEnum.featureRequested(flags, PostingsEnum.FREQS) == false ? 1 : current.getValue().freq);
       return e;
     }
 
@@ -412,7 +412,6 @@ public class SimpleTextTermVectorsReader extends TermVectorsReader {
     private boolean didNext;
     private int doc = -1;
     private int freq;
-    private Bits liveDocs;
 
     @Override
     public int freq() throws IOException {
@@ -447,7 +446,7 @@ public class SimpleTextTermVectorsReader extends TermVectorsReader {
 
     @Override
     public int nextDoc() {
-      if (!didNext && (liveDocs == null || liveDocs.get(0))) {
+      if (!didNext) {
         didNext = true;
         return (doc = 0);
       } else {
@@ -460,8 +459,7 @@ public class SimpleTextTermVectorsReader extends TermVectorsReader {
       return slowAdvance(target);
     }
 
-    public void reset(Bits liveDocs, int freq) {
-      this.liveDocs = liveDocs;
+    public void reset(int freq) {
       this.freq = freq;
       this.doc = -1;
       didNext = false;
@@ -477,7 +475,6 @@ public class SimpleTextTermVectorsReader extends TermVectorsReader {
     private boolean didNext;
     private int doc = -1;
     private int nextPos;
-    private Bits liveDocs;
     private int[] positions;
     private BytesRef[] payloads;
     private int[] startOffsets;
@@ -500,7 +497,7 @@ public class SimpleTextTermVectorsReader extends TermVectorsReader {
 
     @Override
     public int nextDoc() {
-      if (!didNext && (liveDocs == null || liveDocs.get(0))) {
+      if (!didNext) {
         didNext = true;
         return (doc = 0);
       } else {
@@ -513,8 +510,7 @@ public class SimpleTextTermVectorsReader extends TermVectorsReader {
       return slowAdvance(target);
     }
 
-    public void reset(Bits liveDocs, int[] positions, int[] startOffsets, int[] endOffsets, BytesRef payloads[]) {
-      this.liveDocs = liveDocs;
+    public void reset(int[] positions, int[] startOffsets, int[] endOffsets, BytesRef payloads[]) {
       this.positions = positions;
       this.startOffsets = startOffsets;
       this.endOffsets = endOffsets;
diff --git a/lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms.java b/lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms.java
index 68e6ebc..d238e2d 100644
--- a/lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms.java
+++ b/lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms.java
@@ -55,7 +55,6 @@ import org.apache.lucene.index.Terms;
 import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.MultiTermQuery;
 import org.apache.lucene.search.PrefixQuery;
 import org.apache.lucene.search.TermRangeQuery;
 import org.apache.lucene.store.Directory;
@@ -169,7 +168,7 @@ public class TestAutoPrefixTerms extends LuceneTestCase {
           System.out.println("  got term=" + te.term().utf8ToString());
         }
         verifier.sawTerm(te.term());
-        postingsEnum = te.postings(null, postingsEnum);
+        postingsEnum = te.postings(postingsEnum);
         int docID;
         while ((docID = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {
           long v = docValues.get(docID);
@@ -296,7 +295,7 @@ public class TestAutoPrefixTerms extends LuceneTestCase {
           System.out.println("  got term=" + te.term() + " docFreq=" + te.docFreq());
         }
         verifier.sawTerm(te.term());        
-        postingsEnum = te.postings(null, postingsEnum);
+        postingsEnum = te.postings(postingsEnum);
         int docID;
         while ((docID = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {
           long v = docValues.get(docID);
@@ -415,7 +414,7 @@ public class TestAutoPrefixTerms extends LuceneTestCase {
           System.out.println("TEST: got term=" + te.term().utf8ToString() + " docFreq=" + te.docFreq());
         }
         verifier.sawTerm(te.term());        
-        postingsEnum = te.postings(null, postingsEnum);
+        postingsEnum = te.postings(postingsEnum);
         int docID;
         while ((docID = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {
           assertTrue("prefixBR=" + prefixBR + " docBR=" + docValues.get(docID), StringHelper.startsWith(docValues.get(docID), prefixBR));
@@ -491,7 +490,7 @@ public class TestAutoPrefixTerms extends LuceneTestCase {
     //TermsEnum te = terms.intersect(new CompiledAutomaton(a, true, false), null);
     while (te.next() != null) {
       verifier.sawTerm(te.term());
-      postingsEnum = te.postings(null, postingsEnum);
+      postingsEnum = te.postings(postingsEnum);
       int docID;
       while ((docID = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {
         // The auto-prefix terms should never "overlap" one another, so we should only ever see a given docID one time:
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/PostingsReaderBase.java b/lucene/core/src/java/org/apache/lucene/codecs/PostingsReaderBase.java
index baf69c0..f054384 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/PostingsReaderBase.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/PostingsReaderBase.java
@@ -26,7 +26,6 @@ import org.apache.lucene.index.SegmentReadState;
 import org.apache.lucene.store.DataInput;
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Bits;
 
 /** The core terms dictionaries (BlockTermsReader,
  *  BlockTreeTermsReader) interact with a single instance
@@ -65,7 +64,7 @@ public abstract class PostingsReaderBase implements Closeable, Accountable {
 
   /** Must fully consume state, since after this call that
    *  TermState may be reused. */
-  public abstract PostingsEnum postings(FieldInfo fieldInfo, BlockTermState state, Bits skipDocs, PostingsEnum reuse, int flags) throws IOException;
+  public abstract PostingsEnum postings(FieldInfo fieldInfo, BlockTermState state, PostingsEnum reuse, int flags) throws IOException;
   
   /** 
    * Checks consistency of this reader.
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/PushPostingsWriterBase.java b/lucene/core/src/java/org/apache/lucene/codecs/PushPostingsWriterBase.java
index 231eb9d..3308e48 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/PushPostingsWriterBase.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/PushPostingsWriterBase.java
@@ -119,7 +119,7 @@ public abstract class PushPostingsWriterBase extends PostingsWriterBase {
   @Override
   public final BlockTermState writeTerm(BytesRef term, TermsEnum termsEnum, FixedBitSet docsSeen) throws IOException {
     startTerm();
-    postingsEnum = termsEnum.postings(null, postingsEnum, enumFlags);
+    postingsEnum = termsEnum.postings(postingsEnum, enumFlags);
     assert postingsEnum != null;
 
     int docFreq = 0;
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter.java b/lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter.java
index 059a3d5..37f268b 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter.java
@@ -267,7 +267,7 @@ public abstract class TermVectorsWriter implements Closeable {
         startTerm(termsEnum.term(), freq);
 
         if (hasPositions || hasOffsets) {
-          docsAndPositionsEnum = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.OFFSETS | PostingsEnum.PAYLOADS);
+          docsAndPositionsEnum = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.OFFSETS | PostingsEnum.PAYLOADS);
           assert docsAndPositionsEnum != null;
           
           final int docID = docsAndPositionsEnum.nextDoc();
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/blocktree/BitSetTermsEnum.java b/lucene/core/src/java/org/apache/lucene/codecs/blocktree/BitSetTermsEnum.java
index 90c6aa4..b94eb2f 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/blocktree/BitSetTermsEnum.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/blocktree/BitSetTermsEnum.java
@@ -21,7 +21,6 @@ import org.apache.lucene.codecs.PostingsWriterBase;
 import org.apache.lucene.index.PostingsEnum;
 import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.util.BitSet;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 
 /** Silly stub class, used only when writing an auto-prefix
@@ -73,14 +72,11 @@ class BitSetTermsEnum extends TermsEnum {
   }
 
   @Override
-  public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) {
+  public PostingsEnum postings(PostingsEnum reuse, int flags) {
     if (flags != PostingsEnum.NONE) {
       // We only work with DOCS_ONLY fields
       return null;
     }
-    if (liveDocs != null) {
-      throw new IllegalArgumentException("cannot handle live docs");
-    }
     postingsEnum.reset();
     return postingsEnum;
   }
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.java b/lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.java
index 1f5404d..eb242d8 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.java
@@ -474,7 +474,7 @@ public final class BlockTreeTermsWriter extends FieldsConsumer {
     while (prefixTermsEnum.next() != null) {
       //System.out.println("    got term=" + prefixTermsEnum.term().utf8ToString());
       //termCount++;
-      prefixDocsEnum = prefixTermsEnum.postings(null, prefixDocsEnum, 0);
+      prefixDocsEnum = prefixTermsEnum.postings(prefixDocsEnum, 0);
       //System.out.println("      " + prefixDocsEnum + " doc=" + prefixDocsEnum.docID());
       prefixDocs.or(prefixDocsEnum);
     }
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/blocktree/IntersectTermsEnum.java b/lucene/core/src/java/org/apache/lucene/codecs/blocktree/IntersectTermsEnum.java
index dac578f..4764da7 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/blocktree/IntersectTermsEnum.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/blocktree/IntersectTermsEnum.java
@@ -25,7 +25,6 @@ import org.apache.lucene.index.Terms;
 import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.util.ArrayUtil;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.RamUsageEstimator;
 import org.apache.lucene.util.StringHelper;
@@ -231,9 +230,9 @@ final class IntersectTermsEnum extends TermsEnum {
   }
 
   @Override
-  public PostingsEnum postings(Bits skipDocs, PostingsEnum reuse, int flags) throws IOException {
+  public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
     currentFrame.decodeMetaData();
-    return fr.parent.postingsReader.postings(fr.fieldInfo, currentFrame.termState, skipDocs, reuse, flags);
+    return fr.parent.postingsReader.postings(fr.fieldInfo, currentFrame.termState, reuse, flags);
   }
 
   private int getState() {
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/blocktree/SegmentTermsEnum.java b/lucene/core/src/java/org/apache/lucene/codecs/blocktree/SegmentTermsEnum.java
index 957f375..9255698 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/blocktree/SegmentTermsEnum.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/blocktree/SegmentTermsEnum.java
@@ -27,7 +27,6 @@ import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.store.ByteArrayDataInput;
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.util.ArrayUtil;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
 import org.apache.lucene.util.RamUsageEstimator;
@@ -993,7 +992,7 @@ final class SegmentTermsEnum extends TermsEnum {
   }
 
   @Override
-  public PostingsEnum postings(Bits skipDocs, PostingsEnum reuse, int flags) throws IOException {
+  public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
     assert !eof;
     //if (DEBUG) {
     //System.out.println("BTTR.docs seg=" + segment);
@@ -1002,7 +1001,7 @@ final class SegmentTermsEnum extends TermsEnum {
     //if (DEBUG) {
     //System.out.println("  state=" + currentFrame.state);
     //}
-    return fr.parent.postingsReader.postings(fr.fieldInfo, currentFrame.state, skipDocs, reuse, flags);
+    return fr.parent.postingsReader.postings(fr.fieldInfo, currentFrame.state, reuse, flags);
   }
 
   @Override
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader.java b/lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader.java
index b4b3ed4..0cdeae1 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader.java
@@ -44,7 +44,6 @@ import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.util.Accountable;
 import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.ArrayUtil;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.LongsRef;
@@ -930,7 +929,7 @@ public final class CompressingTermVectorsReader extends TermVectorsReader implem
     }
 
     @Override
-    public final PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
+    public final PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
       final TVPostingsEnum docsEnum;
       if (reuse != null && reuse instanceof TVPostingsEnum) {
         docsEnum = (TVPostingsEnum) reuse;
@@ -938,7 +937,7 @@ public final class CompressingTermVectorsReader extends TermVectorsReader implem
         docsEnum = new TVPostingsEnum();
       }
 
-      docsEnum.reset(liveDocs, termFreqs[ord], positionIndex[ord], positions, startOffsets, lengths, payloads, payloadIndex);
+      docsEnum.reset(termFreqs[ord], positionIndex[ord], positions, startOffsets, lengths, payloads, payloadIndex);
       return docsEnum;
     }
 
@@ -946,7 +945,6 @@ public final class CompressingTermVectorsReader extends TermVectorsReader implem
 
   private static class TVPostingsEnum extends PostingsEnum {
 
-    private Bits liveDocs;
     private int doc = -1;
     private int termFreq;
     private int positionIndex;
@@ -962,10 +960,9 @@ public final class CompressingTermVectorsReader extends TermVectorsReader implem
       payload = new BytesRef();
     }
 
-    public void reset(Bits liveDocs, int freq, int positionIndex, int[] positions,
+    public void reset(int freq, int positionIndex, int[] positions,
         int[] startOffsets, int[] lengths, BytesRef payloads,
         int[] payloadIndex) {
-      this.liveDocs = liveDocs;
       this.termFreq = freq;
       this.positionIndex = positionIndex;
       this.positions = positions;
@@ -1061,7 +1058,7 @@ public final class CompressingTermVectorsReader extends TermVectorsReader implem
 
     @Override
     public int nextDoc() throws IOException {
-      if (doc == -1 && (liveDocs == null || liveDocs.get(0))) {
+      if (doc == -1) {
         return (doc = 0);
       } else {
         return (doc = NO_MORE_DOCS);
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50DocValuesProducer.java b/lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50DocValuesProducer.java
index 9eb4e79..3e6b16a 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50DocValuesProducer.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50DocValuesProducer.java
@@ -1122,7 +1122,7 @@ class Lucene50DocValuesProducer extends DocValuesProducer implements Closeable {
       }
       
       @Override
-      public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
+      public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
         throw new UnsupportedOperationException();
       }
 
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50PostingsReader.java b/lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50PostingsReader.java
index a77bfe5..3152268 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50PostingsReader.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50PostingsReader.java
@@ -32,7 +32,6 @@ import org.apache.lucene.index.SegmentReadState;
 import org.apache.lucene.store.DataInput;
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.util.ArrayUtil;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.RamUsageEstimator;
@@ -192,7 +191,7 @@ public final class Lucene50PostingsReader extends PostingsReaderBase {
   }
     
   @Override
-  public PostingsEnum postings(FieldInfo fieldInfo, BlockTermState termState, Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
+  public PostingsEnum postings(FieldInfo fieldInfo, BlockTermState termState, PostingsEnum reuse, int flags) throws IOException {
     
     boolean indexHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;
     boolean indexHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;
@@ -208,7 +207,7 @@ public final class Lucene50PostingsReader extends PostingsReaderBase {
       } else {
         docsEnum = new BlockDocsEnum(fieldInfo);
       }
-      return docsEnum.reset(liveDocs, (IntBlockTermState) termState, flags);
+      return docsEnum.reset((IntBlockTermState) termState, flags);
     } else if ((indexHasOffsets == false || PostingsEnum.featureRequested(flags, PostingsEnum.OFFSETS) == false) &&
                (indexHasPayloads == false || PostingsEnum.featureRequested(flags, PostingsEnum.PAYLOADS) == false)) {
       BlockPostingsEnum docsAndPositionsEnum;
@@ -220,7 +219,7 @@ public final class Lucene50PostingsReader extends PostingsReaderBase {
       } else {
         docsAndPositionsEnum = new BlockPostingsEnum(fieldInfo);
       }
-      return docsAndPositionsEnum.reset(liveDocs, (IntBlockTermState) termState);
+      return docsAndPositionsEnum.reset((IntBlockTermState) termState);
     } else {
       EverythingEnum everythingEnum;
       if (reuse instanceof EverythingEnum) {
@@ -231,7 +230,7 @@ public final class Lucene50PostingsReader extends PostingsReaderBase {
       } else {
         everythingEnum = new EverythingEnum(fieldInfo);
       }
-      return everythingEnum.reset(liveDocs, (IntBlockTermState) termState, flags);
+      return everythingEnum.reset((IntBlockTermState) termState, flags);
     }
   }
 
@@ -272,8 +271,6 @@ public final class Lucene50PostingsReader extends PostingsReaderBase {
     // docID for next skip point, we won't use skipper if 
     // target docID is not larger than this
     private int nextSkipDoc;
-
-    private Bits liveDocs;
     
     private boolean needsFreq; // true if the caller actually needs frequencies
     private int singletonDocID; // docid when there is a single pulsed posting, otherwise -1
@@ -295,9 +292,7 @@ public final class Lucene50PostingsReader extends PostingsReaderBase {
         indexHasPayloads == fieldInfo.hasPayloads();
     }
     
-    public PostingsEnum reset(Bits liveDocs, IntBlockTermState termState, int flags) throws IOException {
-      this.liveDocs = liveDocs;
-
+    public PostingsEnum reset(IntBlockTermState termState, int flags) throws IOException {
       docFreq = termState.docFreq;
       totalTermFreq = indexHasFreq ? termState.totalTermFreq : docFreq;
       docTermStartFP = termState.docStartFP;
@@ -380,26 +375,20 @@ public final class Lucene50PostingsReader extends PostingsReaderBase {
 
     @Override
     public int nextDoc() throws IOException {
-      while (true) {
-
-        if (docUpto == docFreq) {
-          return doc = NO_MORE_DOCS;
-        }
-        if (docBufferUpto == BLOCK_SIZE) {
-          refillDocs();
-        }
+      if (docUpto == docFreq) {
+        return doc = NO_MORE_DOCS;
+      }
+      if (docBufferUpto == BLOCK_SIZE) {
+        refillDocs();
+      }
 
-        accum += docDeltaBuffer[docBufferUpto];
-        docUpto++;
+      accum += docDeltaBuffer[docBufferUpto];
+      docUpto++;
 
-        if (liveDocs == null || liveDocs.get(accum)) {
-          doc = accum;
-          freq = freqBuffer[docBufferUpto];
-          docBufferUpto++;
-          return doc;
-        }
-        docBufferUpto++;
-      }
+      doc = accum;
+      freq = freqBuffer[docBufferUpto];
+      docBufferUpto++;
+      return doc;
     }
 
     @Override
@@ -467,14 +456,9 @@ public final class Lucene50PostingsReader extends PostingsReaderBase {
         }
       }
 
-      if (liveDocs == null || liveDocs.get(accum)) {
-        freq = freqBuffer[docBufferUpto];
-        docBufferUpto++;
-        return doc = accum;
-      } else {
-        docBufferUpto++;
-        return nextDoc();
-      }
+      freq = freqBuffer[docBufferUpto];
+      docBufferUpto++;
+      return doc = accum;
     }
     
     @Override
@@ -544,7 +528,6 @@ public final class Lucene50PostingsReader extends PostingsReaderBase {
 
     private int nextSkipDoc;
 
-    private Bits liveDocs;
     private int singletonDocID; // docid when there is a single pulsed posting, otherwise -1
     
     public BlockPostingsEnum(FieldInfo fieldInfo) throws IOException {
@@ -562,9 +545,7 @@ public final class Lucene50PostingsReader extends PostingsReaderBase {
         indexHasPayloads == fieldInfo.hasPayloads();
     }
     
-    public PostingsEnum reset(Bits liveDocs, IntBlockTermState termState) throws IOException {
-      this.liveDocs = liveDocs;
-
+    public PostingsEnum reset(IntBlockTermState termState) throws IOException {
       docFreq = termState.docFreq;
       docTermStartFP = termState.docStartFP;
       posTermStartFP = termState.posStartFP;
@@ -660,26 +641,22 @@ public final class Lucene50PostingsReader extends PostingsReaderBase {
 
     @Override
     public int nextDoc() throws IOException {
-      while (true) {
-        if (docUpto == docFreq) {
-          return doc = NO_MORE_DOCS;
-        }
-        if (docBufferUpto == BLOCK_SIZE) {
-          refillDocs();
-        }
+      if (docUpto == docFreq) {
+        return doc = NO_MORE_DOCS;
+      }
+      if (docBufferUpto == BLOCK_SIZE) {
+        refillDocs();
+      }
 
-        accum += docDeltaBuffer[docBufferUpto];
-        freq = freqBuffer[docBufferUpto];
-        posPendingCount += freq;
-        docBufferUpto++;
-        docUpto++;
+      accum += docDeltaBuffer[docBufferUpto];
+      freq = freqBuffer[docBufferUpto];
+      posPendingCount += freq;
+      docBufferUpto++;
+      docUpto++;
 
-        if (liveDocs == null || liveDocs.get(accum)) {
-          doc = accum;
-          position = 0;
-          return doc;
-        }
-      }
+      doc = accum;
+      position = 0;
+      return doc;
     }
     
     @Override
@@ -745,12 +722,8 @@ public final class Lucene50PostingsReader extends PostingsReaderBase {
         }
       }
 
-      if (liveDocs == null || liveDocs.get(accum)) {
-        position = 0;
-        return doc = accum;
-      } else {
-        return nextDoc();
-      }
+      position = 0;
+      return doc = accum;
     }
 
     // TODO: in theory we could avoid loading frq block
@@ -904,8 +877,6 @@ public final class Lucene50PostingsReader extends PostingsReaderBase {
     private long skipOffset;
 
     private int nextSkipDoc;
-
-    private Bits liveDocs;
     
     private boolean needsOffsets; // true if we actually need offsets
     private boolean needsPayloads; // true if we actually need payloads
@@ -946,9 +917,7 @@ public final class Lucene50PostingsReader extends PostingsReaderBase {
         indexHasPayloads == fieldInfo.hasPayloads();
     }
     
-    public EverythingEnum reset(Bits liveDocs, IntBlockTermState termState, int flags) throws IOException {
-      this.liveDocs = liveDocs;
-
+    public EverythingEnum reset(IntBlockTermState termState, int flags) throws IOException {
       docFreq = termState.docFreq;
       docTermStartFP = termState.docStartFP;
       posTermStartFP = termState.posStartFP;
@@ -1087,27 +1056,23 @@ public final class Lucene50PostingsReader extends PostingsReaderBase {
 
     @Override
     public int nextDoc() throws IOException {
-      while (true) {
-        if (docUpto == docFreq) {
-          return doc = NO_MORE_DOCS;
-        }
-        if (docBufferUpto == BLOCK_SIZE) {
-          refillDocs();
-        }
+      if (docUpto == docFreq) {
+        return doc = NO_MORE_DOCS;
+      }
+      if (docBufferUpto == BLOCK_SIZE) {
+        refillDocs();
+      }
 
-        accum += docDeltaBuffer[docBufferUpto];
-        freq = freqBuffer[docBufferUpto];
-        posPendingCount += freq;
-        docBufferUpto++;
-        docUpto++;
+      accum += docDeltaBuffer[docBufferUpto];
+      freq = freqBuffer[docBufferUpto];
+      posPendingCount += freq;
+      docBufferUpto++;
+      docUpto++;
 
-        if (liveDocs == null || liveDocs.get(accum)) {
-          doc = accum;
-          position = 0;
-          lastStartOffset = 0;
-          return doc;
-        }
-      }
+      doc = accum;
+      position = 0;
+      lastStartOffset = 0;
+      return doc;
     }
     
     @Override
@@ -1174,13 +1139,9 @@ public final class Lucene50PostingsReader extends PostingsReaderBase {
         }
       }
 
-      if (liveDocs == null || liveDocs.get(accum)) {
-        position = 0;
-        lastStartOffset = 0;
-        return doc = accum;
-      } else {
-        return nextDoc();
-      }
+      position = 0;
+      lastStartOffset = 0;
+      return doc = accum;
     }
 
     // TODO: in theory we could avoid loading frq block
diff --git a/lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream.java b/lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream.java
index 8926efa..b251e02 100644
--- a/lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream.java
+++ b/lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream.java
@@ -31,9 +31,9 @@ import org.apache.lucene.search.DocIdSet;
 import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.QueryWrapperFilter;
-import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IOContext;
 import org.apache.lucene.util.Accountable;
+import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.InfoStream;
@@ -550,7 +550,8 @@ class BufferedUpdatesStream implements Accountable {
         if (state.delGen < delGen) {
 
           // we don't need term frequencies for this
-          state.postingsEnum = state.termsEnum.postings(state.rld.getLiveDocs(), state.postingsEnum, PostingsEnum.NONE);
+          final Bits acceptDocs = state.rld.getLiveDocs();
+          state.postingsEnum = state.termsEnum.postings(state.postingsEnum, PostingsEnum.NONE);
 
           assert state.postingsEnum != null;
 
@@ -559,6 +560,9 @@ class BufferedUpdatesStream implements Accountable {
             if (docID == DocIdSetIterator.NO_MORE_DOCS) {
               break;
             }
+            if (acceptDocs != null && acceptDocs.get(docID) == false) {
+              continue;
+            }
             if (!state.any) {
               state.rld.initWritableLiveDocs();
               state.any = true;
@@ -646,7 +650,8 @@ class BufferedUpdatesStream implements Accountable {
 
       if (termsEnum.seekExact(term.bytes())) {
         // we don't need term frequencies for this
-        postingsEnum = termsEnum.postings(segState.rld.getLiveDocs(), postingsEnum, PostingsEnum.NONE);
+        final Bits acceptDocs = segState.rld.getLiveDocs();
+        postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);
 
         DocValuesFieldUpdates dvUpdates = dvUpdatesContainer.getUpdates(update.field, update.type);
         if (dvUpdates == null) {
@@ -657,6 +662,9 @@ class BufferedUpdatesStream implements Accountable {
           if (doc >= limit) {
             break; // no more docs that can be updated for this term
           }
+          if (acceptDocs != null && acceptDocs.get(doc) == false) {
+            continue;
+          }
           dvUpdates.add(doc, update.value);
         }
       }
diff --git a/lucene/core/src/java/org/apache/lucene/index/CheckIndex.java b/lucene/core/src/java/org/apache/lucene/index/CheckIndex.java
index 38f1773..9c4b83b 100644
--- a/lucene/core/src/java/org/apache/lucene/index/CheckIndex.java
+++ b/lucene/core/src/java/org/apache/lucene/index/CheckIndex.java
@@ -528,9 +528,8 @@ public class CheckIndex implements Closeable {
       result.cantOpenSegments = true;
       return result;
     }
-    int format = 0;
     try {
-      format = input.readInt();
+      /*int format =*/ input.readInt();
     } catch (Throwable t) {
       if (failFast) {
         IOUtils.reThrow(t);
@@ -959,7 +958,7 @@ public class CheckIndex implements Closeable {
         }
       }
 
-      postingsEnum = termsEnum.postings(null, postingsEnum, 0);
+      postingsEnum = termsEnum.postings(postingsEnum, 0);
 
       int lastDoc = -1;
       while (true) {
@@ -1203,7 +1202,6 @@ public class CheckIndex implements Closeable {
       
       long sumTotalTermFreq = 0;
       long sumDocFreq = 0;
-      long upto = 0;
       FixedBitSet visitedDocs = new FixedBitSet(maxDoc);
       while(true) {
         
@@ -1249,7 +1247,7 @@ public class CheckIndex implements Closeable {
         }
         sumDocFreq += docFreq;
 
-        postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);
+        postings = termsEnum.postings(postings, PostingsEnum.ALL);
 
         if (hasFreqs == false) {
           if (termsEnum.totalTermFreq() != -1) {
@@ -1275,13 +1273,13 @@ public class CheckIndex implements Closeable {
         
         int lastDoc = -1;
         int docCount = 0;
+        boolean hasNonDeletedDocs = false;
         long totalTermFreq = 0;
         while(true) {
           final int doc = postings.nextDoc();
           if (doc == DocIdSetIterator.NO_MORE_DOCS) {
             break;
           }
-          status.totFreq++;
           visitedDocs.set(doc);
           int freq = -1;
           if (hasFreqs) {
@@ -1289,7 +1287,6 @@ public class CheckIndex implements Closeable {
             if (freq <= 0) {
               throw new RuntimeException("term " + term + ": doc " + doc + ": freq " + freq + " is out of bounds");
             }
-            status.totPos += freq;
             totalTermFreq += freq;
           } else {
             // When a field didn't index freq, it must
@@ -1299,6 +1296,13 @@ public class CheckIndex implements Closeable {
               throw new RuntimeException("term " + term + ": doc " + doc + ": freq " + freq + " != 1 when Terms.hasFreqs() is false");
             }
           }
+          if (liveDocs == null || liveDocs.get(doc)) {
+            hasNonDeletedDocs = true;
+            status.totFreq++;
+            if (freq >= 0) {
+              status.totPos += freq;
+            }
+          }
           docCount++;
           
           if (doc <= lastDoc) {
@@ -1358,7 +1362,7 @@ public class CheckIndex implements Closeable {
           }
         }
         
-        if (docCount != 0) {
+        if (hasNonDeletedDocs) {
           status.termCount++;
         } else {
           status.delTermCount++;
@@ -1367,28 +1371,6 @@ public class CheckIndex implements Closeable {
         final long totalTermFreq2 = termsEnum.totalTermFreq();
         final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;
         
-        // Re-count if there are deleted docs:
-        if (liveDocs != null) {
-          if (hasFreqs) {
-            postings = termsEnum.postings(null, postings);
-            docCount = 0;
-            totalTermFreq = 0;
-            while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
-              visitedDocs.set(postings.docID());
-              docCount++;
-              totalTermFreq += postings.freq();
-            }
-          } else {
-            postings = termsEnum.postings(null, postings, PostingsEnum.NONE);
-            docCount = 0;
-            totalTermFreq = -1;
-            while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
-              visitedDocs.set(postings.docID());
-              docCount++;
-            }
-          }
-        }
-        
         if (docCount != docFreq) {
           throw new RuntimeException("term " + term + " docFreq=" + docFreq + " != tot docs w/o deletions " + docCount);
         }
@@ -1406,7 +1388,7 @@ public class CheckIndex implements Closeable {
         if (hasPositions) {
           for(int idx=0;idx<7;idx++) {
             final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);
-            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);
+            postings = termsEnum.postings(postings, PostingsEnum.ALL);
             final int docID = postings.advance(skipDocID);
             if (docID == DocIdSetIterator.NO_MORE_DOCS) {
               break;
@@ -1470,7 +1452,7 @@ public class CheckIndex implements Closeable {
         } else {
           for(int idx=0;idx<7;idx++) {
             final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);
-            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.NONE);
+            postings = termsEnum.postings(postings, PostingsEnum.NONE);
             final int docID = postings.advance(skipDocID);
             if (docID == DocIdSetIterator.NO_MORE_DOCS) {
               break;
@@ -1552,7 +1534,7 @@ public class CheckIndex implements Closeable {
           }
           
           int expectedDocFreq = termsEnum.docFreq();
-          PostingsEnum d = termsEnum.postings(null, null, PostingsEnum.NONE);
+          PostingsEnum d = termsEnum.postings(null, PostingsEnum.NONE);
           int docFreq = 0;
           while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
             docFreq++;
@@ -1591,7 +1573,6 @@ public class CheckIndex implements Closeable {
             }
             
             // Seek by term
-            long totDocCount = 0;
             for(int i=seekCount-1;i>=0;i--) {
               if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {
                 throw new RuntimeException("seek to existing term " + seekTerms[i] + " failed");
@@ -1600,40 +1581,10 @@ public class CheckIndex implements Closeable {
                 throw new RuntimeException("seek to existing term " + seekTerms[i] + " returned FOUND but seeked to the wrong term " + termsEnum.term());
               }
               
-              postings = termsEnum.postings(liveDocs, postings, PostingsEnum.NONE);
-              if (postings == null) {
-                throw new RuntimeException("null DocsEnum from to existing term " + seekTerms[i]);
-              }
-
-              while (postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
-                totDocCount++;
-              }
-            }
-            
-            long totDocCountNoDeletes = 0;
-            long totDocFreq = 0;
-            for(int i=0;i<seekCount;i++) {
-              if (!termsEnum.seekExact(seekTerms[i])) {
-                throw new RuntimeException("seek to existing term " + seekTerms[i] + " failed");
-              }
-              
-              totDocFreq += termsEnum.docFreq();
-              postings = termsEnum.postings(null, postings, PostingsEnum.NONE);
+              postings = termsEnum.postings(postings, PostingsEnum.NONE);
               if (postings == null) {
                 throw new RuntimeException("null DocsEnum from to existing term " + seekTerms[i]);
               }
-              
-              while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
-                totDocCountNoDeletes++;
-              }
-            }
-            
-            if (totDocCount > totDocCountNoDeletes) {
-              throw new RuntimeException("more postings with deletes=" + totDocCount + " than without=" + totDocCountNoDeletes);
-            }
-            
-            if (totDocCountNoDeletes != totDocFreq) {
-              throw new RuntimeException("docfreqs=" + totDocFreq + " != recomputed docfreqs=" + totDocCountNoDeletes);
             }
           }
         }
@@ -1685,7 +1636,6 @@ public class CheckIndex implements Closeable {
 
     Status.TermIndexStatus status;
     final int maxDoc = reader.maxDoc();
-    final Bits liveDocs = reader.getLiveDocs();
 
     try {
       if (infoStream != null) {
@@ -1694,13 +1644,7 @@ public class CheckIndex implements Closeable {
 
       final Fields fields = reader.getPostingsReader().getMergeInstance();
       final FieldInfos fieldInfos = reader.getFieldInfos();
-      status = checkFields(fields, liveDocs, maxDoc, fieldInfos, true, false, infoStream, verbose);
-      if (liveDocs != null) {
-        if (infoStream != null) {
-          infoStream.print("    test (ignoring deletes): terms, freq, prox...");
-        }
-        checkFields(fields, null, maxDoc, fieldInfos, true, false, infoStream, verbose);
-      }
+      status = checkFields(fields, reader.getLiveDocs(), maxDoc, fieldInfos, true, false, infoStream, verbose);
     } catch (Throwable e) {
       if (failFast) {
         IOUtils.reThrow(e);
@@ -2015,7 +1959,6 @@ public class CheckIndex implements Closeable {
     long startNS = System.nanoTime();
     final Status.TermVectorStatus status = new Status.TermVectorStatus();
     final FieldInfos fieldInfos = reader.getFieldInfos();
-    final Bits onlyDocIsDeleted = new FixedBitSet(1);
     
     try {
       if (infoStream != null) {
@@ -2026,7 +1969,6 @@ public class CheckIndex implements Closeable {
 
       // Only used if crossCheckTermVectors is true:
       PostingsEnum postingsDocs = null;
-      PostingsEnum postingsDocs2 = null;
 
       final Bits liveDocs = reader.getLiveDocs();
 
@@ -2055,12 +1997,6 @@ public class CheckIndex implements Closeable {
             // First run with no deletions:
             checkFields(tfv, null, 1, fieldInfos, false, true, infoStream, verbose);
             
-            if (j == 0) {
-              // Also test with the 1 doc deleted; we only do this for first doc because this really is just looking for a [slightly] buggy
-              // TermVectors impl that fails to respect the incoming live docs:
-              checkFields(tfv, onlyDocIsDeleted, 1, fieldInfos, false, true, infoStream, verbose);
-            }
-            
             // Only agg stats if the doc is live:
             final boolean doStats = liveDocs == null || liveDocs.get(j);
             
@@ -2097,7 +2033,7 @@ public class CheckIndex implements Closeable {
                 while ((term = termsEnum.next()) != null) {
 
                   // This is the term vectors:
-                  postings = termsEnum.postings(null, postings, PostingsEnum.ALL);
+                  postings = termsEnum.postings(postings, PostingsEnum.ALL);
                   assert postings != null;
 
                   if (!postingsTermsEnum.seekExact(term)) {
@@ -2105,11 +2041,11 @@ public class CheckIndex implements Closeable {
                   }
 
                   // This is the inverted index ("real" postings):
-                  postingsDocs2 = postingsTermsEnum.postings(null, postingsDocs2, PostingsEnum.ALL);
-                  assert postingsDocs2 != null;
+                  postingsDocs = postingsTermsEnum.postings(postingsDocs, PostingsEnum.ALL);
+                  assert postingsDocs != null;
 
                   
-                  final int advanceDoc = postingsDocs2.advance(j);
+                  final int advanceDoc = postingsDocs.advance(j);
                   if (advanceDoc != j) {
                     throw new RuntimeException("vector term=" + term + " field=" + field + ": doc=" + j + " was not found in postings (got: " + advanceDoc + ")");
                   }
@@ -2122,8 +2058,8 @@ public class CheckIndex implements Closeable {
                   
                   if (postingsHasFreq) {
                     final int tf = postings.freq();
-                    if (postingsHasFreq && postingsDocs2.freq() != tf) {
-                      throw new RuntimeException("vector term=" + term + " field=" + field + " doc=" + j + ": freq=" + tf + " differs from postings freq=" + postingsDocs2.freq());
+                    if (postingsHasFreq && postingsDocs.freq() != tf) {
+                      throw new RuntimeException("vector term=" + term + " field=" + field + " doc=" + j + ": freq=" + tf + " differs from postings freq=" + postingsDocs.freq());
                     }
 
                     // Term vectors has prox?
@@ -2131,7 +2067,7 @@ public class CheckIndex implements Closeable {
                       for (int i = 0; i < tf; i++) {
                         int pos = postings.nextPosition();
                         if (postingsTerms.hasPositions()) {
-                          int postingsPos = postingsDocs2.nextPosition();
+                          int postingsPos = postingsDocs.nextPosition();
                           if (terms.hasPositions() && pos != postingsPos) {
                             throw new RuntimeException("vector term=" + term + " field=" + field + " doc=" + j + ": pos=" + pos + " differs from postings pos=" + postingsPos);
                           }
@@ -2153,8 +2089,8 @@ public class CheckIndex implements Closeable {
                          */
 
                         if (startOffset != -1 && endOffset != -1 && postingsTerms.hasOffsets()) {
-                          int postingsStartOffset = postingsDocs2.startOffset();
-                          int postingsEndOffset = postingsDocs2.endOffset();
+                          int postingsStartOffset = postingsDocs.startOffset();
+                          int postingsEndOffset = postingsDocs.endOffset();
                           if (startOffset != postingsStartOffset) {
                             throw new RuntimeException("vector term=" + term + " field=" + field + " doc=" + j + ": startOffset=" + startOffset + " differs from postings startOffset=" + postingsStartOffset);
                           }
@@ -2174,16 +2110,16 @@ public class CheckIndex implements Closeable {
                           if (payload == null) {
                             // we have payloads, but not at this position. 
                             // postings has payloads too, it should not have one at this position
-                            if (postingsDocs2.getPayload() != null) {
-                              throw new RuntimeException("vector term=" + term + " field=" + field + " doc=" + j + " has no payload but postings does: " + postingsDocs2.getPayload());
+                            if (postingsDocs.getPayload() != null) {
+                              throw new RuntimeException("vector term=" + term + " field=" + field + " doc=" + j + " has no payload but postings does: " + postingsDocs.getPayload());
                             }
                           } else {
                             // we have payloads, and one at this position
                             // postings should also have one at this position, with the same bytes.
-                            if (postingsDocs2.getPayload() == null) {
+                            if (postingsDocs.getPayload() == null) {
                               throw new RuntimeException("vector term=" + term + " field=" + field + " doc=" + j + " has payload=" + payload + " but postings does not.");
                             }
-                            BytesRef postingsPayload = postingsDocs2.getPayload();
+                            BytesRef postingsPayload = postingsDocs.getPayload();
                             if (!payload.equals(postingsPayload)) {
                               throw new RuntimeException("vector term=" + term + " field=" + field + " doc=" + j + " has payload=" + payload + " but differs from postings payload=" + postingsPayload);
                             }
diff --git a/lucene/core/src/java/org/apache/lucene/index/FilterLeafReader.java b/lucene/core/src/java/org/apache/lucene/index/FilterLeafReader.java
index c7d77cf..6e896af 100644
--- a/lucene/core/src/java/org/apache/lucene/index/FilterLeafReader.java
+++ b/lucene/core/src/java/org/apache/lucene/index/FilterLeafReader.java
@@ -216,8 +216,8 @@ public class FilterLeafReader extends LeafReader {
     }
 
     @Override
-    public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
-      return in.postings(liveDocs, reuse, flags);
+    public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
+      return in.postings(reuse, flags);
     }
 
   }
diff --git a/lucene/core/src/java/org/apache/lucene/index/FilteredTermsEnum.java b/lucene/core/src/java/org/apache/lucene/index/FilteredTermsEnum.java
index 85bde39..3bb6f43 100644
--- a/lucene/core/src/java/org/apache/lucene/index/FilteredTermsEnum.java
+++ b/lucene/core/src/java/org/apache/lucene/index/FilteredTermsEnum.java
@@ -21,7 +21,6 @@ import java.io.IOException;
 
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.AttributeSource;
-import org.apache.lucene.util.Bits;
 
 /**
  * Abstract class for enumerating a subset of all terms. 
@@ -179,8 +178,8 @@ public abstract class FilteredTermsEnum extends TermsEnum {
   }
 
   @Override
-  public PostingsEnum postings(Bits bits, PostingsEnum reuse, int flags) throws IOException {
-    return tenum.postings(bits, reuse, flags);
+  public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
+    return tenum.postings(reuse, flags);
   }
   
   /** This enum does not support seeking!
diff --git a/lucene/core/src/java/org/apache/lucene/index/FreqProxFields.java b/lucene/core/src/java/org/apache/lucene/index/FreqProxFields.java
index 7477e0a..e078748 100644
--- a/lucene/core/src/java/org/apache/lucene/index/FreqProxFields.java
+++ b/lucene/core/src/java/org/apache/lucene/index/FreqProxFields.java
@@ -25,7 +25,6 @@ import java.util.Map;
 
 import org.apache.lucene.index.FreqProxTermsWriterPerField.FreqProxPostingsArray;
 import org.apache.lucene.util.AttributeSource;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
 
@@ -226,11 +225,7 @@ class FreqProxFields extends Fields {
     }
 
     @Override
-    public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) {
-      if (liveDocs != null) {
-        throw new IllegalArgumentException("liveDocs must be null");
-      }
-
+    public PostingsEnum postings(PostingsEnum reuse, int flags) {
       if (PostingsEnum.featureRequested(flags, PostingsEnum.POSITIONS)) {
         FreqProxPostingsEnum posEnum;
 
diff --git a/lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter.java b/lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter.java
index a697d6d..e4a6446 100644
--- a/lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter.java
+++ b/lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter.java
@@ -56,7 +56,7 @@ final class FreqProxTermsWriter extends TermsHash {
         }
 
         if (termsEnum != null && termsEnum.seekExact(deleteTerm.bytes())) {
-          postingsEnum = termsEnum.postings(null, postingsEnum, 0);
+          postingsEnum = termsEnum.postings(postingsEnum, 0);
           int delDocLimit = segDeletes.get(deleteTerm);
           assert delDocLimit < PostingsEnum.NO_MORE_DOCS;
           while (true) {
diff --git a/lucene/core/src/java/org/apache/lucene/index/LeafReader.java b/lucene/core/src/java/org/apache/lucene/index/LeafReader.java
index 6f18c39..8b27b15 100644
--- a/lucene/core/src/java/org/apache/lucene/index/LeafReader.java
+++ b/lucene/core/src/java/org/apache/lucene/index/LeafReader.java
@@ -210,7 +210,8 @@ public abstract class LeafReader extends IndexReader {
   /** Returns {@link PostingsEnum} for the specified term.
    *  This will return null if either the field or
    *  term does not exist.
-   *  @see TermsEnum#postings(Bits, PostingsEnum) */
+   *  <p><b>NOTE:</b> The returned {@link PostingsEnum} may contain deleted docs.
+   *  @see TermsEnum#postings(PostingsEnum) */
   public final PostingsEnum postings(Term term, int flags) throws IOException {
     assert term.field() != null;
     assert term.bytes() != null;
@@ -218,7 +219,7 @@ public abstract class LeafReader extends IndexReader {
     if (terms != null) {
       final TermsEnum termsEnum = terms.iterator();
       if (termsEnum.seekExact(term.bytes())) {
-        return termsEnum.postings(getLiveDocs(), null, flags);
+        return termsEnum.postings(null, flags);
       }
     }
     return null;
@@ -231,6 +232,7 @@ public abstract class LeafReader extends IndexReader {
    *  and do not need any proximity data.
    *  This method is equivalent to 
    *  {@link #postings(Term, int) postings(term, PostingsEnum.FREQS)}
+   *  <p><b>NOTE:</b> The returned {@link PostingsEnum} may contain deleted docs.
    *  @see #postings(Term, int)
    */
   public final PostingsEnum postings(Term term) throws IOException {
diff --git a/lucene/core/src/java/org/apache/lucene/index/MappedMultiFields.java b/lucene/core/src/java/org/apache/lucene/index/MappedMultiFields.java
index 5e91cb3..b4c9b3a 100644
--- a/lucene/core/src/java/org/apache/lucene/index/MappedMultiFields.java
+++ b/lucene/core/src/java/org/apache/lucene/index/MappedMultiFields.java
@@ -19,8 +19,6 @@ package org.apache.lucene.index;
 
 import java.io.IOException;
 
-import org.apache.lucene.util.Bits;
-
 import static org.apache.lucene.index.FilterLeafReader.FilterFields;
 import static org.apache.lucene.index.FilterLeafReader.FilterTerms;
 import static org.apache.lucene.index.FilterLeafReader.FilterTermsEnum;
@@ -107,11 +105,7 @@ public class MappedMultiFields extends FilterFields {
     }
 
     @Override
-    public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
-      if (liveDocs != null) {
-        throw new IllegalArgumentException("liveDocs must be null");
-      }
-
+    public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
       MappingMultiPostingsEnum mappingDocsAndPositionsEnum;
       if (reuse instanceof MappingMultiPostingsEnum) {
         MappingMultiPostingsEnum postings = (MappingMultiPostingsEnum) reuse;
@@ -124,7 +118,7 @@ public class MappedMultiFields extends FilterFields {
         mappingDocsAndPositionsEnum = new MappingMultiPostingsEnum(field, mergeState);
       }
 
-      MultiPostingsEnum docsAndPositionsEnum = (MultiPostingsEnum) in.postings(liveDocs, mappingDocsAndPositionsEnum.multiDocsAndPositionsEnum, flags);
+      MultiPostingsEnum docsAndPositionsEnum = (MultiPostingsEnum) in.postings(mappingDocsAndPositionsEnum.multiDocsAndPositionsEnum, flags);
       mappingDocsAndPositionsEnum.reset(docsAndPositionsEnum);
       return mappingDocsAndPositionsEnum;
     }
diff --git a/lucene/core/src/java/org/apache/lucene/index/MultiFields.java b/lucene/core/src/java/org/apache/lucene/index/MultiFields.java
index 52f4f6a..a0f0d50 100644
--- a/lucene/core/src/java/org/apache/lucene/index/MultiFields.java
+++ b/lucene/core/src/java/org/apache/lucene/index/MultiFields.java
@@ -123,8 +123,8 @@ public final class MultiFields extends Fields {
   /** Returns {@link PostingsEnum} for the specified field and
    *  term.  This will return null if the field or term does
    *  not exist. */
-  public static PostingsEnum getTermDocsEnum(IndexReader r, Bits liveDocs, String field, BytesRef term) throws IOException {
-    return getTermDocsEnum(r, liveDocs, field, term, PostingsEnum.FREQS);
+  public static PostingsEnum getTermDocsEnum(IndexReader r, String field, BytesRef term) throws IOException {
+    return getTermDocsEnum(r, field, term, PostingsEnum.FREQS);
   }
   
   /** Returns {@link PostingsEnum} for the specified field and
@@ -132,15 +132,15 @@ public final class MultiFields extends Fields {
    *  Some codecs may be able to optimize their
    *  implementation when freqs are not required.  This will
    *  return null if the field or term does not exist.  See {@link
-   *  TermsEnum#postings(Bits, PostingsEnum,int)}.*/
-  public static PostingsEnum getTermDocsEnum(IndexReader r, Bits liveDocs, String field, BytesRef term, int flags) throws IOException {
+   *  TermsEnum#postings(PostingsEnum,int)}.*/
+  public static PostingsEnum getTermDocsEnum(IndexReader r, String field, BytesRef term, int flags) throws IOException {
     assert field != null;
     assert term != null;
     final Terms terms = getTerms(r, field);
     if (terms != null) {
       final TermsEnum termsEnum = terms.iterator();
       if (termsEnum.seekExact(term)) {
-        return termsEnum.postings(liveDocs, null, flags);
+        return termsEnum.postings(null, flags);
       }
     }
     return null;
@@ -149,9 +149,9 @@ public final class MultiFields extends Fields {
   /** Returns {@link PostingsEnum} for the specified
    *  field and term.  This will return null if the field or
    *  term does not exist or positions were not indexed. 
-   *  @see #getTermPositionsEnum(IndexReader, Bits, String, BytesRef, int) */
-  public static PostingsEnum getTermPositionsEnum(IndexReader r, Bits liveDocs, String field, BytesRef term) throws IOException {
-    return getTermPositionsEnum(r, liveDocs, field, term, PostingsEnum.ALL);
+   *  @see #getTermPositionsEnum(IndexReader, String, BytesRef, int) */
+  public static PostingsEnum getTermPositionsEnum(IndexReader r, String field, BytesRef term) throws IOException {
+    return getTermPositionsEnum(r, field, term, PostingsEnum.ALL);
   }
 
   /** Returns {@link PostingsEnum} for the specified
@@ -159,15 +159,15 @@ public final class MultiFields extends Fields {
    *  required.  Some codecs may be able to optimize
    *  their implementation when offsets and/or payloads are not
    *  required. This will return null if the field or term does not
-   *  exist. See {@link TermsEnum#postings(Bits, PostingsEnum,int)}. */
-  public static PostingsEnum getTermPositionsEnum(IndexReader r, Bits liveDocs, String field, BytesRef term, int flags) throws IOException {
+   *  exist. See {@link TermsEnum#postings(PostingsEnum,int)}. */
+  public static PostingsEnum getTermPositionsEnum(IndexReader r, String field, BytesRef term, int flags) throws IOException {
     assert field != null;
     assert term != null;
     final Terms terms = getTerms(r, field);
     if (terms != null) {
       final TermsEnum termsEnum = terms.iterator();
       if (termsEnum.seekExact(term)) {
-        return termsEnum.postings(liveDocs, null, flags);
+        return termsEnum.postings(null, flags);
       }
     }
     return null;
diff --git a/lucene/core/src/java/org/apache/lucene/index/MultiTermsEnum.java b/lucene/core/src/java/org/apache/lucene/index/MultiTermsEnum.java
index cb6518f..6c0a7cc 100644
--- a/lucene/core/src/java/org/apache/lucene/index/MultiTermsEnum.java
+++ b/lucene/core/src/java/org/apache/lucene/index/MultiTermsEnum.java
@@ -20,7 +20,6 @@ package org.apache.lucene.index;
 import java.io.IOException;
 import java.util.Arrays;
 
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
 import org.apache.lucene.util.PriorityQueue;
@@ -327,7 +326,7 @@ public final class MultiTermsEnum extends TermsEnum {
   }
 
   @Override
-  public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
+  public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
     MultiPostingsEnum docsEnum;
 
     // Can only reuse if incoming enum is also a MultiDocsEnum
@@ -340,13 +339,6 @@ public final class MultiTermsEnum extends TermsEnum {
     } else {
       docsEnum = new MultiPostingsEnum(this, subs.length);
     }
-    
-    final MultiBits multiLiveDocs;
-    if (liveDocs instanceof MultiBits) {
-      multiLiveDocs = (MultiBits) liveDocs;
-    } else {
-      multiLiveDocs = null;
-    }
 
     int upto = 0;
 
@@ -354,31 +346,8 @@ public final class MultiTermsEnum extends TermsEnum {
 
       final TermsEnumWithSlice entry = top[i];
 
-      final Bits b;
-
-      if (multiLiveDocs != null) {
-        // optimize for common case: requested skip docs is a
-        // congruent sub-slice of MultiBits: in this case, we
-        // just pull the liveDocs from the sub reader, rather
-        // than making the inefficient
-        // Slice(Multi(sub-readers)):
-        final MultiBits.SubResult sub = multiLiveDocs.getMatchingSub(entry.subSlice);
-        if (sub.matches) {
-          b = sub.result;
-        } else {
-          // custom case: requested skip docs is foreign:
-          // must slice it on every access
-          b = new BitsSlice(liveDocs, entry.subSlice);
-        }
-      } else if (liveDocs != null) {
-        b = new BitsSlice(liveDocs, entry.subSlice);
-      } else {
-        // no deletions
-        b = null;
-      }
-
       assert entry.index < docsEnum.subPostingsEnums.length: entry.index + " vs " + docsEnum.subPostingsEnums.length + "; " + subs.length;
-      final PostingsEnum subPostingsEnum = entry.terms.postings(b, docsEnum.subPostingsEnums[entry.index], flags);
+      final PostingsEnum subPostingsEnum = entry.terms.postings(docsEnum.subPostingsEnums[entry.index], flags);
       assert subPostingsEnum != null;
       docsEnum.subPostingsEnums[entry.index] = subPostingsEnum;
       subDocs[upto].postingsEnum = subPostingsEnum;
diff --git a/lucene/core/src/java/org/apache/lucene/index/PostingsEnum.java b/lucene/core/src/java/org/apache/lucene/index/PostingsEnum.java
index 374ae26..3a28f5c 100644
--- a/lucene/core/src/java/org/apache/lucene/index/PostingsEnum.java
+++ b/lucene/core/src/java/org/apache/lucene/index/PostingsEnum.java
@@ -21,7 +21,6 @@ import java.io.IOException;
 
 import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.util.AttributeSource;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 
 /** Iterates through the postings.
@@ -30,29 +29,29 @@ import org.apache.lucene.util.BytesRef;
 public abstract class PostingsEnum extends DocIdSetIterator {
   
   /**
-   * Flag to pass to {@link TermsEnum#postings(Bits, PostingsEnum, int)} if you don't
+   * Flag to pass to {@link TermsEnum#postings(PostingsEnum, int)} if you don't
    * require per-document postings in the returned enum.
    */
   public static final short NONE = 0;
 
-  /** Flag to pass to {@link TermsEnum#postings(Bits, PostingsEnum, int)}
+  /** Flag to pass to {@link TermsEnum#postings(PostingsEnum, int)}
    *  if you require term frequencies in the returned enum. */
   public static final short FREQS = 1 << 3;
 
-  /** Flag to pass to {@link TermsEnum#postings(Bits, PostingsEnum, int)}
+  /** Flag to pass to {@link TermsEnum#postings(PostingsEnum, int)}
    * if you require term positions in the returned enum. */
   public static final short POSITIONS = FREQS | 1 << 4;
   
-  /** Flag to pass to {@link TermsEnum#postings(Bits, PostingsEnum, int)}
+  /** Flag to pass to {@link TermsEnum#postings(PostingsEnum, int)}
    *  if you require offsets in the returned enum. */
   public static final short OFFSETS = POSITIONS | 1 << 5;
 
-  /** Flag to pass to  {@link TermsEnum#postings(Bits, PostingsEnum, int)}
+  /** Flag to pass to  {@link TermsEnum#postings(PostingsEnum, int)}
    *  if you require payloads in the returned enum. */
   public static final short PAYLOADS = POSITIONS | 1 << 6;
 
   /**
-   * Flag to pass to {@link TermsEnum#postings(Bits, PostingsEnum, int)}
+   * Flag to pass to {@link TermsEnum#postings(PostingsEnum, int)}
    * to get positions, payloads and offsets in the returned enum
    */
   public static final short ALL = OFFSETS | PAYLOADS;
diff --git a/lucene/core/src/java/org/apache/lucene/index/SortedDocValuesTermsEnum.java b/lucene/core/src/java/org/apache/lucene/index/SortedDocValuesTermsEnum.java
index f32f690..48b57c0 100644
--- a/lucene/core/src/java/org/apache/lucene/index/SortedDocValuesTermsEnum.java
+++ b/lucene/core/src/java/org/apache/lucene/index/SortedDocValuesTermsEnum.java
@@ -19,7 +19,6 @@ package org.apache.lucene.index;
 
 import java.io.IOException;
 
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
 
@@ -106,7 +105,7 @@ class SortedDocValuesTermsEnum extends TermsEnum {
   }
 
   @Override
-  public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
+  public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
     throw new UnsupportedOperationException();
   }
 
diff --git a/lucene/core/src/java/org/apache/lucene/index/SortedSetDocValuesTermsEnum.java b/lucene/core/src/java/org/apache/lucene/index/SortedSetDocValuesTermsEnum.java
index d0d9ee7..5e1b443 100644
--- a/lucene/core/src/java/org/apache/lucene/index/SortedSetDocValuesTermsEnum.java
+++ b/lucene/core/src/java/org/apache/lucene/index/SortedSetDocValuesTermsEnum.java
@@ -17,7 +17,6 @@ package org.apache.lucene.index;
  * limitations under the License.
  */
 
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
 
@@ -106,7 +105,7 @@ class SortedSetDocValuesTermsEnum extends TermsEnum {
   }
 
   @Override
-  public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
+  public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
     throw new UnsupportedOperationException();
   }
 
diff --git a/lucene/core/src/java/org/apache/lucene/index/TermsEnum.java b/lucene/core/src/java/org/apache/lucene/index/TermsEnum.java
index 7844bd3..8397c43 100644
--- a/lucene/core/src/java/org/apache/lucene/index/TermsEnum.java
+++ b/lucene/core/src/java/org/apache/lucene/index/TermsEnum.java
@@ -20,7 +20,6 @@ package org.apache.lucene.index;
 import java.io.IOException;
 
 import org.apache.lucene.util.AttributeSource;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefIterator;
 
@@ -142,18 +141,19 @@ public abstract class TermsEnum implements BytesRefIterator {
    *  call this when the enum is unpositioned.  This method
    *  will not return null.
    *  <p>
+   *  <b>NOTE</b>: the returned iterator may return deleted documents, so
+   *  deleted documents have to be checked on top of the {@link PostingsEnum}.
+   *  <p>
    *  Use this method if you only require documents and frequencies,
    *  and do not need any proximity data.
    *  This method is equivalent to 
-   *  {@link #postings(Bits, PostingsEnum, int) postings(liveDocs, reuse, PostingsEnum.FREQS)}
-   *  
-   * @param liveDocs unset bits are documents that should not
-   * be returned
+   *  {@link #postings(PostingsEnum, int) postings(reuse, PostingsEnum.FREQS)}
+   *
    * @param reuse pass a prior PostingsEnum for possible reuse 
-   * @see #postings(Bits, PostingsEnum, int)
+   * @see #postings(PostingsEnum, int)
    */
-  public final PostingsEnum postings(Bits liveDocs, PostingsEnum reuse) throws IOException {
-    return postings(liveDocs, reuse, PostingsEnum.FREQS);
+  public final PostingsEnum postings(PostingsEnum reuse) throws IOException {
+    return postings(reuse, PostingsEnum.FREQS);
   }
 
   /** Get {@link PostingsEnum} for the current term, with
@@ -161,14 +161,15 @@ public abstract class TermsEnum implements BytesRefIterator {
    *  are required.  Do not call this when the enum is
    *  unpositioned.  This method may return null if the postings
    *  information required is not available from the index
-   *  
-   * @param liveDocs unset bits are documents that should not
-   * be returned
+   *  <p>
+   *  <b>NOTE</b>: the returned iterator may return deleted documents, so
+   *  deleted documents have to be checked on top of the {@link PostingsEnum}.
+   *
    * @param reuse pass a prior PostingsEnum for possible reuse
    * @param flags specifies which optional per-document values
    *        you require; see {@link PostingsEnum#FREQS}
    */
-  public abstract PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException;
+  public abstract PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException;
 
   /**
    * Expert: Returns the TermsEnums internal state to position the TermsEnum
@@ -225,7 +226,7 @@ public abstract class TermsEnum implements BytesRefIterator {
     }
 
     @Override
-    public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) {
+    public PostingsEnum postings(PostingsEnum reuse, int flags) {
       throw new IllegalStateException("this method should never be called");
     }
       
diff --git a/lucene/core/src/java/org/apache/lucene/search/BooleanScorer.java b/lucene/core/src/java/org/apache/lucene/search/BooleanScorer.java
index 826f59e..7a16414 100644
--- a/lucene/core/src/java/org/apache/lucene/search/BooleanScorer.java
+++ b/lucene/core/src/java/org/apache/lucene/search/BooleanScorer.java
@@ -21,7 +21,7 @@ import java.io.IOException;
 import java.util.Arrays;
 import java.util.Collection;
 
-import org.apache.lucene.search.BooleanWeight;
+import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.PriorityQueue;
 
 /**
@@ -41,7 +41,7 @@ final class BooleanScorer extends BulkScorer {
     return new BulkScorer() {
 
       @Override
-      public int score(final LeafCollector collector, int min, int max) throws IOException {
+      public int score(final LeafCollector collector, Bits acceptDocs, int min, int max) throws IOException {
         final LeafCollector noScoreCollector = new LeafCollector() {
           FakeScorer fake = new FakeScorer();
 
@@ -56,7 +56,7 @@ final class BooleanScorer extends BulkScorer {
             collector.collect(doc);
           }
         };
-        return scorer.score(noScoreCollector, min, max);
+        return scorer.score(noScoreCollector, acceptDocs, min, max);
       }
 
       @Override
@@ -83,11 +83,11 @@ final class BooleanScorer extends BulkScorer {
     }
 
     void advance(int min) throws IOException {
-      score(min, min);
+      score(null, min, min);
     }
 
-    void score(int min, int max) throws IOException {
-      next = scorer.score(orCollector, min, max);
+    void score(Bits acceptDocs, int min, int max) throws IOException {
+      next = scorer.score(orCollector, acceptDocs, min, max);
     }
   }
 
@@ -237,12 +237,12 @@ final class BooleanScorer extends BulkScorer {
     }
   }
 
-  private void scoreWindow(LeafCollector collector, int base, int min, int max,
+  private void scoreWindow(LeafCollector collector, Bits acceptDocs, int base, int min, int max,
       BulkScorerAndDoc[] scorers, int numScorers) throws IOException {
     for (int i = 0; i < numScorers; ++i) {
       final BulkScorerAndDoc scorer = scorers[i];
       assert scorer.next < max;
-      scorer.score(min, max);
+      scorer.score(acceptDocs, min, max);
     }
 
     scoreMatches(collector, base);
@@ -270,7 +270,7 @@ final class BooleanScorer extends BulkScorer {
     return headTop;
   }
 
-  private void scoreWindow(LeafCollector collector, int windowBase, int windowMin, int windowMax) throws IOException {
+  private void scoreWindow(LeafCollector collector, Bits acceptDocs, int windowBase, int windowMin, int windowMax) throws IOException {
     // Fill 'leads' with all scorers from 'head' that are in the right window
     leads[0] = head.pop();
     int maxFreq = 1;
@@ -296,7 +296,7 @@ final class BooleanScorer extends BulkScorer {
       }
       tail.clear();
 
-      scoreWindow(collector, windowBase, windowMin, windowMax, leads, maxFreq);
+      scoreWindow(collector, acceptDocs, windowBase, windowMin, windowMax, leads, maxFreq);
     }
 
     // Push back scorers into head and tail
@@ -309,7 +309,7 @@ final class BooleanScorer extends BulkScorer {
   }
 
   @Override
-  public int score(LeafCollector collector, int min, int max) throws IOException {
+  public int score(LeafCollector collector, Bits acceptDocs, int min, int max) throws IOException {
     fakeScorer.doc = -1;
     collector.setScorer(fakeScorer);
 
@@ -321,7 +321,7 @@ final class BooleanScorer extends BulkScorer {
       final int windowMax = Math.min(max, windowBase + SIZE);
 
       // general case
-      scoreWindow(collector, windowBase, windowMin, windowMax);
+      scoreWindow(collector, acceptDocs, windowBase, windowMin, windowMax);
       top = head.top();
     }
 
diff --git a/lucene/core/src/java/org/apache/lucene/search/BooleanWeight.java b/lucene/core/src/java/org/apache/lucene/search/BooleanWeight.java
index d4df0a0..c619bcc 100644
--- a/lucene/core/src/java/org/apache/lucene/search/BooleanWeight.java
+++ b/lucene/core/src/java/org/apache/lucene/search/BooleanWeight.java
@@ -28,7 +28,6 @@ import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.search.similarities.Similarity;
-import org.apache.lucene.util.Bits;
 
 /**
  * Expert: the Weight for BooleanQuery, used to
@@ -194,12 +193,12 @@ final class BooleanWeight extends Weight {
   /** Try to build a boolean scorer for this weight. Returns null if {@link BooleanScorer}
    *  cannot be used. */
   // pkg-private for forcing use of BooleanScorer in tests
-  BooleanScorer booleanScorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+  BooleanScorer booleanScorer(LeafReaderContext context) throws IOException {
     List<BulkScorer> optional = new ArrayList<BulkScorer>();
     Iterator<BooleanClause> cIter = query.iterator();
     for (Weight w  : weights) {
       BooleanClause c =  cIter.next();
-      BulkScorer subScorer = w.bulkScorer(context, acceptDocs);
+      BulkScorer subScorer = w.bulkScorer(context);
       
       if (subScorer == null) {
         if (c.isRequired()) {
@@ -230,8 +229,8 @@ final class BooleanWeight extends Weight {
   }
 
   @Override
-  public BulkScorer bulkScorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-    final BooleanScorer bulkScorer = booleanScorer(context, acceptDocs);
+  public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {
+    final BooleanScorer bulkScorer = booleanScorer(context);
     if (bulkScorer != null) { // BooleanScorer is applicable
       // TODO: what is the right heuristic here?
       final long costThreshold;
@@ -254,11 +253,11 @@ final class BooleanWeight extends Weight {
         return bulkScorer;
       }
     }
-    return super.bulkScorer(context, acceptDocs);
+    return super.bulkScorer(context);
   }
 
   @Override
-  public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+  public Scorer scorer(LeafReaderContext context) throws IOException {
     // initially the user provided value,
     // but if minNrShouldMatch == optional.size(),
     // we will optimize and move these to required, making this 0
@@ -272,7 +271,7 @@ final class BooleanWeight extends Weight {
     Iterator<BooleanClause> cIter = query.iterator();
     for (Weight w  : weights) {
       BooleanClause c =  cIter.next();
-      Scorer subScorer = w.scorer(context, acceptDocs);
+      Scorer subScorer = w.scorer(context);
       if (subScorer == null) {
         if (c.isRequired()) {
           return null;
diff --git a/lucene/core/src/java/org/apache/lucene/search/BulkScorer.java b/lucene/core/src/java/org/apache/lucene/search/BulkScorer.java
index c84a73a..de5564a 100644
--- a/lucene/core/src/java/org/apache/lucene/search/BulkScorer.java
+++ b/lucene/core/src/java/org/apache/lucene/search/BulkScorer.java
@@ -19,6 +19,8 @@ package org.apache.lucene.search;
 
 import java.io.IOException;
 
+import org.apache.lucene.util.Bits;
+
 /** This class is used to score a range of documents at
  *  once, and is returned by {@link Weight#bulkScorer}.  Only
  *  queries that have a more optimized means of scoring
@@ -30,9 +32,11 @@ public abstract class BulkScorer {
 
   /** Scores and collects all matching documents.
    * @param collector The collector to which all matching documents are passed.
+   * @param acceptDocs {@link Bits} that represents the allowed documents to match, or
+   *                   {@code null} if they are all allowed to match.
    */
-  public void score(LeafCollector collector) throws IOException {
-    final int next = score(collector, 0, DocIdSetIterator.NO_MORE_DOCS);
+  public void score(LeafCollector collector, Bits acceptDocs) throws IOException {
+    final int next = score(collector, acceptDocs, 0, DocIdSetIterator.NO_MORE_DOCS);
     assert next == DocIdSetIterator.NO_MORE_DOCS;
   }
 
@@ -54,14 +58,16 @@ public abstract class BulkScorer {
    * <pre class="prettyprint">
    * private final Scorer scorer; // set via constructor
    *
-   * public int score(LeafCollector collector, int min, int max) throws IOException {
+   * public int score(LeafCollector collector, Bits acceptDocs, int min, int max) throws IOException {
    *   collector.setScorer(scorer);
    *   int doc = scorer.docID();
    *   if (doc &lt; min) {
    *     doc = scorer.advance(min);
    *   }
    *   while (doc &lt; max) {
-   *     collector.collect(doc);
+   *     if (acceptDocs == null || acceptDocs.get(doc)) {
+   *       collector.collect(doc);
+   *     }
    *     doc = scorer.nextDoc();
    *   }
    *   return doc;
@@ -69,11 +75,13 @@ public abstract class BulkScorer {
    * </pre>
    *
    * @param  collector The collector to which all matching documents are passed.
+   * @param acceptDocs {@link Bits} that represents the allowed documents to match, or
+   *                   {@code null} if they are all allowed to match.
    * @param  min Score starting at, including, this document 
    * @param  max Score up to, but not including, this doc
    * @return an under-estimation of the next matching doc after max
    */
-  public abstract int score(LeafCollector collector, int min, int max) throws IOException;
+  public abstract int score(LeafCollector collector, Bits acceptDocs, int min, int max) throws IOException;
 
   /**
    * Same as {@link Scorer#cost()} for bulk scorers.
diff --git a/lucene/core/src/java/org/apache/lucene/search/CachingWrapperQuery.java b/lucene/core/src/java/org/apache/lucene/search/CachingWrapperQuery.java
index 5b54b77..871532c 100644
--- a/lucene/core/src/java/org/apache/lucene/search/CachingWrapperQuery.java
+++ b/lucene/core/src/java/org/apache/lucene/search/CachingWrapperQuery.java
@@ -33,7 +33,6 @@ import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.util.Accountable;
 import org.apache.lucene.util.Accountables;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.RoaringDocIdSet;
 
 /**
@@ -124,7 +123,7 @@ public class CachingWrapperQuery extends Query implements Accountable {
       }
 
       @Override
-      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+      public Scorer scorer(LeafReaderContext context) throws IOException {
         final LeafReader reader = context.reader();
         final Object key = reader.getCoreCacheKey();
 
@@ -133,7 +132,7 @@ public class CachingWrapperQuery extends Query implements Accountable {
           hitCount++;
         } else if (policy.shouldCache(query, context)) {
           missCount++;
-          final Scorer scorer = weight.scorer(context, null);
+          final Scorer scorer = weight.scorer(context);
           if (scorer == null) {
             docIdSet = DocIdSet.EMPTY;
           } else {
@@ -141,7 +140,7 @@ public class CachingWrapperQuery extends Query implements Accountable {
           }
           cache.put(key, docIdSet);
         } else {
-          return weight.scorer(context, acceptDocs);
+          return weight.scorer(context);
         }
 
         assert docIdSet != null;
@@ -153,21 +152,7 @@ public class CachingWrapperQuery extends Query implements Accountable {
           return null;
         }
 
-        // We apply acceptDocs as an approximation
-        if (acceptDocs == null) {
-          return new ConstantScoreScorer(this, 0f, disi);
-        } else {
-          final TwoPhaseIterator twoPhaseView = new TwoPhaseIterator(disi) {
-
-            @Override
-            public boolean matches() throws IOException {
-              final int doc = approximation.docID();
-              return acceptDocs.get(doc);
-            }
-
-          };
-          return new ConstantScoreScorer(this, 0f, twoPhaseView);
-        }
+        return new ConstantScoreScorer(this, 0f, disi);
       }
     };
   }
diff --git a/lucene/core/src/java/org/apache/lucene/search/ConstantScoreQuery.java b/lucene/core/src/java/org/apache/lucene/search/ConstantScoreQuery.java
index 4e534fc..8c65778 100644
--- a/lucene/core/src/java/org/apache/lucene/search/ConstantScoreQuery.java
+++ b/lucene/core/src/java/org/apache/lucene/search/ConstantScoreQuery.java
@@ -83,8 +83,8 @@ public class ConstantScoreQuery extends Query {
     }
 
     @Override
-    public int score(LeafCollector collector, int min, int max) throws IOException {
-      return bulkScorer.score(wrapCollector(collector), min, max);
+    public int score(LeafCollector collector, Bits acceptDocs, int min, int max) throws IOException {
+      return bulkScorer.score(wrapCollector(collector), acceptDocs, min, max);
     }
 
     private LeafCollector wrapCollector(LeafCollector collector) {
@@ -119,8 +119,8 @@ public class ConstantScoreQuery extends Query {
       return new ConstantScoreWeight(this) {
 
         @Override
-        public BulkScorer bulkScorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-          final BulkScorer innerScorer = innerWeight.bulkScorer(context, acceptDocs);
+        public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {
+          final BulkScorer innerScorer = innerWeight.bulkScorer(context);
           if (innerScorer == null) {
             return null;
           }
@@ -128,8 +128,8 @@ public class ConstantScoreQuery extends Query {
         }
 
         @Override
-        public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-          final Scorer innerScorer = innerWeight.scorer(context, acceptDocs);
+        public Scorer scorer(LeafReaderContext context) throws IOException {
+          final Scorer innerScorer = innerWeight.scorer(context);
           if (innerScorer == null) {
             return null;
           }
diff --git a/lucene/core/src/java/org/apache/lucene/search/ConstantScoreWeight.java b/lucene/core/src/java/org/apache/lucene/search/ConstantScoreWeight.java
index 4405691..6631fd3 100644
--- a/lucene/core/src/java/org/apache/lucene/search/ConstantScoreWeight.java
+++ b/lucene/core/src/java/org/apache/lucene/search/ConstantScoreWeight.java
@@ -66,7 +66,7 @@ public abstract class ConstantScoreWeight extends Weight {
 
   @Override
   public final Explanation explain(LeafReaderContext context, int doc) throws IOException {
-    final Scorer s = scorer(context, context.reader().getLiveDocs());
+    final Scorer s = scorer(context);
     final boolean exists;
     if (s == null) {
       exists = false;
diff --git a/lucene/core/src/java/org/apache/lucene/search/DisjunctionMaxQuery.java b/lucene/core/src/java/org/apache/lucene/search/DisjunctionMaxQuery.java
index 5de3594..3abd023 100644
--- a/lucene/core/src/java/org/apache/lucene/search/DisjunctionMaxQuery.java
+++ b/lucene/core/src/java/org/apache/lucene/search/DisjunctionMaxQuery.java
@@ -27,7 +27,6 @@ import java.util.Set;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.Term;
-import org.apache.lucene.util.Bits;
 
 /**
  * A query that generates the union of documents produced by its subqueries, and that scores each document with the maximum
@@ -161,11 +160,11 @@ public class DisjunctionMaxQuery extends Query implements Iterable<Query> {
 
     /** Create the scorer used to score our associated DisjunctionMaxQuery */
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+    public Scorer scorer(LeafReaderContext context) throws IOException {
       List<Scorer> scorers = new ArrayList<>();
       for (Weight w : weights) {
         // we will advance() subscorers
-        Scorer subScorer = w.scorer(context, acceptDocs);
+        Scorer subScorer = w.scorer(context);
         if (subScorer != null) {
           scorers.add(subScorer);
         }
diff --git a/lucene/core/src/java/org/apache/lucene/search/Filter.java b/lucene/core/src/java/org/apache/lucene/search/Filter.java
index 835e79b..1c3aa7c 100644
--- a/lucene/core/src/java/org/apache/lucene/search/Filter.java
+++ b/lucene/core/src/java/org/apache/lucene/search/Filter.java
@@ -96,7 +96,7 @@ public abstract class Filter extends Query {
 
       @Override
       public Explanation explain(LeafReaderContext context, int doc) throws IOException {
-        final Scorer scorer = scorer(context, context.reader().getLiveDocs());
+        final Scorer scorer = scorer(context);
         final boolean match = (scorer != null && scorer.advance(doc) == doc);
         if (match) {
           assert scorer.score() == 0f;
@@ -107,8 +107,8 @@ public abstract class Filter extends Query {
       }
 
       @Override
-      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-        final DocIdSet set = getDocIdSet(context, acceptDocs);
+      public Scorer scorer(LeafReaderContext context) throws IOException {
+        final DocIdSet set = getDocIdSet(context, null);
         if (set == null) {
           return null;
         }
diff --git a/lucene/core/src/java/org/apache/lucene/search/FuzzyTermsEnum.java b/lucene/core/src/java/org/apache/lucene/search/FuzzyTermsEnum.java
index 6062118..24ab12f 100644
--- a/lucene/core/src/java/org/apache/lucene/search/FuzzyTermsEnum.java
+++ b/lucene/core/src/java/org/apache/lucene/search/FuzzyTermsEnum.java
@@ -31,7 +31,6 @@ import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.util.Attribute;
 import org.apache.lucene.util.AttributeImpl;
 import org.apache.lucene.util.AttributeSource;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
 import org.apache.lucene.util.UnicodeUtil;
@@ -265,8 +264,8 @@ public class FuzzyTermsEnum extends TermsEnum {
   }
   
   @Override
-  public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
-    return actualEnum.postings(liveDocs, reuse, flags);
+  public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
+    return actualEnum.postings(reuse, flags);
   }
   
   @Override
diff --git a/lucene/core/src/java/org/apache/lucene/search/IndexSearcher.java b/lucene/core/src/java/org/apache/lucene/search/IndexSearcher.java
index d81913d..a72df69 100644
--- a/lucene/core/src/java/org/apache/lucene/search/IndexSearcher.java
+++ b/lucene/core/src/java/org/apache/lucene/search/IndexSearcher.java
@@ -46,6 +46,7 @@ import org.apache.lucene.index.Terms;
 import org.apache.lucene.search.similarities.DefaultSimilarity;
 import org.apache.lucene.search.similarities.Similarity;
 import org.apache.lucene.store.NIOFSDirectory;    // javadoc
+import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.ThreadInterruptedException;
 
@@ -614,10 +615,10 @@ public class IndexSearcher {
         // continue with the following leaf
         continue;
       }
-      BulkScorer scorer = weight.bulkScorer(ctx, ctx.reader().getLiveDocs());
+      BulkScorer scorer = weight.bulkScorer(ctx);
       if (scorer != null) {
         try {
-          scorer.score(leafCollector);
+          scorer.score(leafCollector, ctx.reader().getLiveDocs());
         } catch (CollectionTerminatedException e) {
           // collection was terminated prematurely
           // continue with the following leaf
@@ -667,7 +668,10 @@ public class IndexSearcher {
     int n = ReaderUtil.subIndex(doc, leafContexts);
     final LeafReaderContext ctx = leafContexts.get(n);
     int deBasedDoc = doc - ctx.docBase;
-    
+    final Bits liveDocs = ctx.reader().getLiveDocs();
+    if (liveDocs != null && liveDocs.get(deBasedDoc) == false) {
+      return Explanation.noMatch("Document " + doc + " is deleted");
+    }
     return weight.explain(ctx, deBasedDoc);
   }
 
diff --git a/lucene/core/src/java/org/apache/lucene/search/LRUQueryCache.java b/lucene/core/src/java/org/apache/lucene/search/LRUQueryCache.java
index 681e333..6499501 100644
--- a/lucene/core/src/java/org/apache/lucene/search/LRUQueryCache.java
+++ b/lucene/core/src/java/org/apache/lucene/search/LRUQueryCache.java
@@ -36,7 +36,6 @@ import org.apache.lucene.index.ReaderUtil;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.util.Accountable;
 import org.apache.lucene.util.Accountables;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.RamUsageEstimator;
 import org.apache.lucene.util.RoaringDocIdSet;
 
@@ -566,7 +565,7 @@ public class LRUQueryCache implements QueryCache, Accountable {
     }
 
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+    public Scorer scorer(LeafReaderContext context) throws IOException {
       if (context.ord == 0) {
         policy.onUse(getQuery());
       }
@@ -574,7 +573,7 @@ public class LRUQueryCache implements QueryCache, Accountable {
       if (docIdSet == null) {
         if (cacheEntryHasReasonableWorstCaseSize(ReaderUtil.getTopLevelContext(context).reader().maxDoc())
             && policy.shouldCache(in.getQuery(), context)) {
-          final Scorer scorer = in.scorer(context, null);
+          final Scorer scorer = in.scorer(context);
           if (scorer == null) {
             docIdSet = DocIdSet.EMPTY;
           } else {
@@ -582,7 +581,7 @@ public class LRUQueryCache implements QueryCache, Accountable {
           }
           putIfAbsent(in.getQuery(), context, docIdSet);
         } else {
-          return in.scorer(context, acceptDocs);
+          return in.scorer(context);
         }
       }
 
@@ -595,19 +594,7 @@ public class LRUQueryCache implements QueryCache, Accountable {
         return null;
       }
 
-      // we apply acceptDocs as an approximation
-      if (acceptDocs == null) {
-        return new ConstantScoreScorer(this, 0f, disi);
-      } else {
-        final TwoPhaseIterator twoPhaseView = new TwoPhaseIterator(disi) {
-          @Override
-          public boolean matches() throws IOException {
-            final int doc = approximation.docID();
-            return acceptDocs.get(doc);
-          }
-        };
-        return new ConstantScoreScorer(this, 0f, twoPhaseView);
-      }
+      return new ConstantScoreScorer(this, 0f, disi);
     }
 
   }
diff --git a/lucene/core/src/java/org/apache/lucene/search/MultiPhraseQuery.java b/lucene/core/src/java/org/apache/lucene/search/MultiPhraseQuery.java
index 63a04c6..65556f5 100644
--- a/lucene/core/src/java/org/apache/lucene/search/MultiPhraseQuery.java
+++ b/lucene/core/src/java/org/apache/lucene/search/MultiPhraseQuery.java
@@ -33,7 +33,6 @@ import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.search.similarities.Similarity.SimScorer;
 import org.apache.lucene.search.similarities.Similarity;
 import org.apache.lucene.util.ArrayUtil;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.PriorityQueue;
 import org.apache.lucene.util.ToStringUtils;
@@ -173,10 +172,9 @@ public class MultiPhraseQuery extends Query {
     }
 
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+    public Scorer scorer(LeafReaderContext context) throws IOException {
       assert !termArrays.isEmpty();
       final LeafReader reader = context.reader();
-      final Bits liveDocs = acceptDocs;
       
       PhraseQuery.PostingsAndFreq[] postingsFreqs = new PhraseQuery.PostingsAndFreq[termArrays.size()];
 
@@ -201,7 +199,7 @@ public class MultiPhraseQuery extends Query {
           TermState termState = termContexts.get(term).get(context.ord);
           if (termState != null) {
             termsEnum.seekExact(term.bytes(), termState);
-            postings.add(termsEnum.postings(liveDocs, null, PostingsEnum.POSITIONS));
+            postings.add(termsEnum.postings(null, PostingsEnum.POSITIONS));
           }
         }
         
@@ -233,7 +231,7 @@ public class MultiPhraseQuery extends Query {
 
     @Override
     public Explanation explain(LeafReaderContext context, int doc) throws IOException {
-      Scorer scorer = scorer(context, context.reader().getLiveDocs());
+      Scorer scorer = scorer(context);
       if (scorer != null) {
         int newDoc = scorer.advance(doc);
         if (newDoc == doc) {
diff --git a/lucene/core/src/java/org/apache/lucene/search/MultiTermQueryConstantScoreWrapper.java b/lucene/core/src/java/org/apache/lucene/search/MultiTermQueryConstantScoreWrapper.java
index c0e9f8c..34821dc 100644
--- a/lucene/core/src/java/org/apache/lucene/search/MultiTermQueryConstantScoreWrapper.java
+++ b/lucene/core/src/java/org/apache/lucene/search/MultiTermQueryConstantScoreWrapper.java
@@ -31,7 +31,6 @@ import org.apache.lucene.index.Terms;
 import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.util.BitDocIdSet;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 
 /**
@@ -136,7 +135,7 @@ final class MultiTermQueryConstantScoreWrapper<Q extends MultiTermQuery> extends
        * On the given leaf context, try to either rewrite to a disjunction if
        * there are few terms, or build a bitset containing matching docs.
        */
-      private WeightOrBitSet rewrite(LeafReaderContext context, Bits acceptDocs) throws IOException {
+      private WeightOrBitSet rewrite(LeafReaderContext context) throws IOException {
         final Terms terms = context.reader().terms(query.field);
         if (terms == null) {
           // field does not exist
@@ -168,14 +167,14 @@ final class MultiTermQueryConstantScoreWrapper<Q extends MultiTermQuery> extends
           TermsEnum termsEnum2 = terms.iterator();
           for (TermAndState t : collectedTerms) {
             termsEnum2.seekExact(t.term, t.state);
-            docs = termsEnum2.postings(acceptDocs, docs, PostingsEnum.NONE);
+            docs = termsEnum2.postings(docs, PostingsEnum.NONE);
             builder.or(docs);
           }
         }
 
         // Then keep filling the bit set with remaining terms
         do {
-          docs = termsEnum.postings(acceptDocs, docs, PostingsEnum.NONE);
+          docs = termsEnum.postings(docs, PostingsEnum.NONE);
           builder.or(docs);
         } while (termsEnum.next() != null);
 
@@ -194,10 +193,10 @@ final class MultiTermQueryConstantScoreWrapper<Q extends MultiTermQuery> extends
       }
 
       @Override
-      public BulkScorer bulkScorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-        final WeightOrBitSet weightOrBitSet = rewrite(context, acceptDocs);
+      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {
+        final WeightOrBitSet weightOrBitSet = rewrite(context);
         if (weightOrBitSet.weight != null) {
-          return weightOrBitSet.weight.bulkScorer(context, acceptDocs);
+          return weightOrBitSet.weight.bulkScorer(context);
         } else {
           final Scorer scorer = scorer(weightOrBitSet.bitset);
           if (scorer == null) {
@@ -208,10 +207,10 @@ final class MultiTermQueryConstantScoreWrapper<Q extends MultiTermQuery> extends
       }
 
       @Override
-      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-        final WeightOrBitSet weightOrBitSet = rewrite(context, acceptDocs);
+      public Scorer scorer(LeafReaderContext context) throws IOException {
+        final WeightOrBitSet weightOrBitSet = rewrite(context);
         if (weightOrBitSet.weight != null) {
-          return weightOrBitSet.weight.scorer(context, acceptDocs);
+          return weightOrBitSet.weight.scorer(context);
         } else {
           return scorer(weightOrBitSet.bitset);
         }
diff --git a/lucene/core/src/java/org/apache/lucene/search/PhraseQuery.java b/lucene/core/src/java/org/apache/lucene/search/PhraseQuery.java
index a808378..0698aa9 100644
--- a/lucene/core/src/java/org/apache/lucene/search/PhraseQuery.java
+++ b/lucene/core/src/java/org/apache/lucene/search/PhraseQuery.java
@@ -37,7 +37,6 @@ import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.search.similarities.Similarity;
 import org.apache.lucene.search.similarities.Similarity.SimScorer;
 import org.apache.lucene.util.ArrayUtil;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.ToStringUtils;
 
@@ -396,10 +395,9 @@ public class PhraseQuery extends Query {
     }
 
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+    public Scorer scorer(LeafReaderContext context) throws IOException {
       assert terms.length > 0;
       final LeafReader reader = context.reader();
-      final Bits liveDocs = acceptDocs;
       PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];
 
       final Terms fieldTerms = reader.terms(field);
@@ -422,7 +420,7 @@ public class PhraseQuery extends Query {
           return null;
         }
         te.seekExact(t.bytes(), state);
-        PostingsEnum postingsEnum = te.postings(liveDocs, null, PostingsEnum.POSITIONS);
+        PostingsEnum postingsEnum = te.postings(null, PostingsEnum.POSITIONS);
         postingsFreqs[i] = new PostingsAndFreq(postingsEnum, positions[i], t);
       }
 
@@ -445,7 +443,7 @@ public class PhraseQuery extends Query {
 
     @Override
     public Explanation explain(LeafReaderContext context, int doc) throws IOException {
-      Scorer scorer = scorer(context, context.reader().getLiveDocs());
+      Scorer scorer = scorer(context);
       if (scorer != null) {
         int newDoc = scorer.advance(doc);
         if (newDoc == doc) {
diff --git a/lucene/core/src/java/org/apache/lucene/search/QueryRescorer.java b/lucene/core/src/java/org/apache/lucene/search/QueryRescorer.java
index 141db74..2e5fe78 100644
--- a/lucene/core/src/java/org/apache/lucene/search/QueryRescorer.java
+++ b/lucene/core/src/java/org/apache/lucene/search/QueryRescorer.java
@@ -82,7 +82,7 @@ public abstract class QueryRescorer extends Rescorer {
       if (readerContext != null) {
         // We advanced to another segment:
         docBase = readerContext.docBase;
-        scorer = weight.scorer(readerContext, null);
+        scorer = weight.scorer(readerContext);
       }
 
       if(scorer != null) {
diff --git a/lucene/core/src/java/org/apache/lucene/search/QueryWrapperFilter.java b/lucene/core/src/java/org/apache/lucene/search/QueryWrapperFilter.java
index f5965da..d08e36c 100644
--- a/lucene/core/src/java/org/apache/lucene/search/QueryWrapperFilter.java
+++ b/lucene/core/src/java/org/apache/lucene/search/QueryWrapperFilter.java
@@ -61,10 +61,11 @@ public class QueryWrapperFilter extends Filter {
     // get a private context that is used to rewrite, createWeight and score eventually
     final LeafReaderContext privateContext = context.reader().getContext();
     final Weight weight = new IndexSearcher(privateContext).createNormalizedWeight(query, false);
-    return new DocIdSet() {
+    
+    DocIdSet set = new DocIdSet() {
       @Override
       public DocIdSetIterator iterator() throws IOException {
-        return weight.scorer(privateContext, acceptDocs);
+        return weight.scorer(privateContext);
       }
 
       @Override
@@ -72,6 +73,7 @@ public class QueryWrapperFilter extends Filter {
         return 0L;
       }
     };
+    return BitsFilteredDocIdSet.wrap(set, acceptDocs);
   }
 
   @Override
diff --git a/lucene/core/src/java/org/apache/lucene/search/RandomAccessWeight.java b/lucene/core/src/java/org/apache/lucene/search/RandomAccessWeight.java
index 1d6a8bb..5e920cb 100644
--- a/lucene/core/src/java/org/apache/lucene/search/RandomAccessWeight.java
+++ b/lucene/core/src/java/org/apache/lucene/search/RandomAccessWeight.java
@@ -48,7 +48,7 @@ public abstract class RandomAccessWeight extends ConstantScoreWeight {
   protected abstract Bits getMatchingDocs(LeafReaderContext context) throws IOException;
 
   @Override
-  public final Scorer scorer(LeafReaderContext context, final Bits acceptDocs) throws IOException {
+  public final Scorer scorer(LeafReaderContext context) throws IOException {
     final Bits matchingDocs = getMatchingDocs(context);
     if (matchingDocs == null || matchingDocs instanceof MatchNoBits) {
       return null;
@@ -60,10 +60,6 @@ public abstract class RandomAccessWeight extends ConstantScoreWeight {
       public boolean matches() throws IOException {
         final int doc = approximation.docID();
 
-        if (acceptDocs != null && acceptDocs.get(doc) == false) {
-          return false;
-        }
-
         return matchingDocs.get(doc);
       }
     };
diff --git a/lucene/core/src/java/org/apache/lucene/search/TermQuery.java b/lucene/core/src/java/org/apache/lucene/search/TermQuery.java
index ebbfdb8..2de627b 100644
--- a/lucene/core/src/java/org/apache/lucene/search/TermQuery.java
+++ b/lucene/core/src/java/org/apache/lucene/search/TermQuery.java
@@ -32,7 +32,6 @@ import org.apache.lucene.index.TermState;
 import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.search.similarities.Similarity;
 import org.apache.lucene.search.similarities.Similarity.SimScorer;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.ToStringUtils;
 
 /**
@@ -98,13 +97,13 @@ public class TermQuery extends Query {
     }
 
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+    public Scorer scorer(LeafReaderContext context) throws IOException {
       assert termStates.topReaderContext == ReaderUtil.getTopLevelContext(context) : "The top-reader used to create Weight (" + termStates.topReaderContext + ") is not the same as the current reader's top-reader (" + ReaderUtil.getTopLevelContext(context);
       final TermsEnum termsEnum = getTermsEnum(context);
       if (termsEnum == null) {
         return null;
       }
-      PostingsEnum docs = termsEnum.postings(acceptDocs, null, needsScores ? PostingsEnum.FREQS : PostingsEnum.NONE);
+      PostingsEnum docs = termsEnum.postings(null, needsScores ? PostingsEnum.FREQS : PostingsEnum.NONE);
       assert docs != null;
       return new TermScorer(this, docs, similarity.simScorer(stats, context));
     }
@@ -136,7 +135,7 @@ public class TermQuery extends Query {
 
     @Override
     public Explanation explain(LeafReaderContext context, int doc) throws IOException {
-      Scorer scorer = scorer(context, context.reader().getLiveDocs());
+      Scorer scorer = scorer(context);
       if (scorer != null) {
         int newDoc = scorer.advance(doc);
         if (newDoc == doc) {
diff --git a/lucene/core/src/java/org/apache/lucene/search/Weight.java b/lucene/core/src/java/org/apache/lucene/search/Weight.java
index f377f6e..f00327b 100644
--- a/lucene/core/src/java/org/apache/lucene/search/Weight.java
+++ b/lucene/core/src/java/org/apache/lucene/search/Weight.java
@@ -36,7 +36,7 @@ import org.apache.lucene.util.Bits;
  * {@link org.apache.lucene.index.LeafReader} dependent state should reside in the {@link Scorer}.
  * <p>
  * Since {@link Weight} creates {@link Scorer} instances for a given
- * {@link org.apache.lucene.index.LeafReaderContext} ({@link #scorer(org.apache.lucene.index.LeafReaderContext, Bits)})
+ * {@link org.apache.lucene.index.LeafReaderContext} ({@link #scorer(org.apache.lucene.index.LeafReaderContext)})
  * callers must maintain the relationship between the searcher's top-level
  * {@link IndexReaderContext} and the context used to create a {@link Scorer}. 
  * <p>
@@ -51,7 +51,7 @@ import org.apache.lucene.util.Bits;
  * <li>The query normalization factor is passed to {@link #normalize(float, float)}. At
  * this point the weighting is complete.
  * <li>A <code>Scorer</code> is constructed by
- * {@link #scorer(org.apache.lucene.index.LeafReaderContext, Bits)}.
+ * {@link #scorer(org.apache.lucene.index.LeafReaderContext)}.
  * </ol>
  * 
  * @since 2.9
@@ -105,14 +105,11 @@ public abstract class Weight {
    * 
    * @param context
    *          the {@link org.apache.lucene.index.LeafReaderContext} for which to return the {@link Scorer}.
-   * @param acceptDocs
-   *          Bits that represent the allowable docs to match (typically deleted docs
-   *          but possibly filtering other documents)
    *          
    * @return a {@link Scorer} which scores documents in/out-of order.
    * @throws IOException if there is a low-level I/O error
    */
-  public abstract Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException;
+  public abstract Scorer scorer(LeafReaderContext context) throws IOException;
 
   /**
    * Optional method, to return a {@link BulkScorer} to
@@ -124,17 +121,14 @@ public abstract class Weight {
    *
    * @param context
    *          the {@link org.apache.lucene.index.LeafReaderContext} for which to return the {@link Scorer}.
-   * @param acceptDocs
-   *          Bits that represent the allowable docs to match (typically deleted docs
-   *          but possibly filtering other documents)
    *
    * @return a {@link BulkScorer} which scores documents and
    * passes them to a collector.
    * @throws IOException if there is a low-level I/O error
    */
-  public BulkScorer bulkScorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+  public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {
 
-    Scorer scorer = scorer(context, acceptDocs);
+    Scorer scorer = scorer(context);
     if (scorer == null) {
       // No docs match
       return null;
@@ -164,23 +158,22 @@ public abstract class Weight {
     }
 
     @Override
-    public int score(LeafCollector collector, int min, int max) throws IOException {
-      // TODO: this may be sort of weird, when we are
-      // embedded in a BooleanScorer, because we are
-      // called for every chunk of 2048 documents.  But,
-      // then, scorer is a FakeScorer in that case, so any
-      // Collector doing something "interesting" in
-      // setScorer will be forced to use BS2 anyways:
+    public int score(LeafCollector collector, Bits acceptDocs, int min, int max) throws IOException {
       collector.setScorer(scorer);
+      final TwoPhaseIterator twoPhase = scorer.asTwoPhaseIterator();
       if (scorer.docID() == -1 && min == 0 && max == DocIdSetIterator.NO_MORE_DOCS) {
-        scoreAll(collector, scorer);
+        scoreAll(collector, scorer, twoPhase, acceptDocs);
         return DocIdSetIterator.NO_MORE_DOCS;
       } else {
         int doc = scorer.docID();
         if (doc < min) {
-          doc = scorer.advance(min);
+          if (twoPhase == null) {
+            doc = scorer.advance(min);
+          } else {
+            doc = twoPhase.approximation().advance(min);
+          }
         }
-        return scoreRange(collector, scorer, doc, max);
+        return scoreRange(collector, scorer, twoPhase, acceptDocs, doc, max);
       }
     }
 
@@ -188,21 +181,47 @@ public abstract class Weight {
      *  separate this from {@link #scoreAll} to help out
      *  hotspot.
      *  See <a href="https://issues.apache.org/jira/browse/LUCENE-5487">LUCENE-5487</a> */
-    static int scoreRange(LeafCollector collector, Scorer scorer, int currentDoc, int end) throws IOException {
-      while (currentDoc < end) {
-        collector.collect(currentDoc);
-        currentDoc = scorer.nextDoc();
+    static int scoreRange(LeafCollector collector, Scorer scorer, TwoPhaseIterator twoPhase,
+        Bits acceptDocs, int currentDoc, int end) throws IOException {
+      if (twoPhase == null) {
+        while (currentDoc < end) {
+          if (acceptDocs == null || acceptDocs.get(currentDoc)) {
+            collector.collect(currentDoc);
+          }
+          currentDoc = scorer.nextDoc();
+        }
+        return currentDoc;
+      } else {
+        final DocIdSetIterator approximation = twoPhase.approximation();
+        while (currentDoc < end) {
+          if ((acceptDocs == null || acceptDocs.get(currentDoc)) && twoPhase.matches()) {
+            collector.collect(currentDoc);
+          }
+          currentDoc = approximation.nextDoc();
+        }
+        return currentDoc;
       }
-      return currentDoc;
     }
     
     /** Specialized method to bulk-score all hits; we
      *  separate this from {@link #scoreRange} to help out
      *  hotspot.
      *  See <a href="https://issues.apache.org/jira/browse/LUCENE-5487">LUCENE-5487</a> */
-    static void scoreAll(LeafCollector collector, Scorer scorer) throws IOException {
-      for (int doc = scorer.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = scorer.nextDoc()) {
-        collector.collect(doc);
+    static void scoreAll(LeafCollector collector, Scorer scorer, TwoPhaseIterator twoPhase, Bits acceptDocs) throws IOException {
+      if (twoPhase == null) {
+        for (int doc = scorer.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = scorer.nextDoc()) {
+          if (acceptDocs == null || acceptDocs.get(doc)) {
+            collector.collect(doc);
+          }
+        }
+      } else {
+        // The scorer has an approximation, so run the approximation first, then check acceptDocs, then confirm
+        final DocIdSetIterator approximation = twoPhase.approximation();
+        for (int doc = approximation.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = approximation.nextDoc()) {
+          if ((acceptDocs == null || acceptDocs.get(doc)) && twoPhase.matches()) {
+            collector.collect(doc);
+          }
+        }
       }
     }
   }
diff --git a/lucene/core/src/java/org/apache/lucene/search/package-info.java b/lucene/core/src/java/org/apache/lucene/search/package-info.java
index 3c36c4c..ea5981c 100644
--- a/lucene/core/src/java/org/apache/lucene/search/package-info.java
+++ b/lucene/core/src/java/org/apache/lucene/search/package-info.java
@@ -470,7 +470,7 @@
  *         abstract method:
  *         <ol>
  *             <li>
- *                 {@link org.apache.lucene.search.BulkScorer#score(org.apache.lucene.search.LeafCollector,int,int) score(LeafCollector,int,int)} &mdash;
+ *                 {@link org.apache.lucene.search.BulkScorer#score(org.apache.lucene.search.LeafCollector,org.apache.lucene.util.Bits,int,int) score(LeafCollector,Bits,int,int)} &mdash;
  *     Score all documents up to but not including the specified max document.
  *       </li>
  *         </ol>
@@ -522,7 +522,7 @@
  * <p>If a Filter is being used, some initial setup is done to determine which docs to include. 
  *    Otherwise, we ask the Weight for a {@link org.apache.lucene.search.Scorer Scorer} for each
  *    {@link org.apache.lucene.index.IndexReader IndexReader} segment and proceed by calling
- *    {@link org.apache.lucene.search.BulkScorer#score(org.apache.lucene.search.LeafCollector) BulkScorer.score(LeafCollector)}.
+ *    {@link org.apache.lucene.search.BulkScorer#score(org.apache.lucene.search.LeafCollector,org.apache.lucene.util.Bits) BulkScorer.score(LeafCollector,Bits)}.
  * <p>At last, we are actually going to score some documents. The score method takes in the Collector
  *    (most likely the TopScoreDocCollector or TopFieldCollector) and does its business.Of course, here 
  *    is where things get involved. The {@link org.apache.lucene.search.Scorer Scorer} that is returned
diff --git a/lucene/core/src/java/org/apache/lucene/search/payloads/PayloadNearQuery.java b/lucene/core/src/java/org/apache/lucene/search/payloads/PayloadNearQuery.java
index 5b3ac10..3438bc4 100644
--- a/lucene/core/src/java/org/apache/lucene/search/payloads/PayloadNearQuery.java
+++ b/lucene/core/src/java/org/apache/lucene/search/payloads/PayloadNearQuery.java
@@ -144,15 +144,15 @@ public class PayloadNearQuery extends SpanNearQuery {
     }
 
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-      Spans spans = super.getSpans(context, acceptDocs, Postings.PAYLOADS);
+    public Scorer scorer(LeafReaderContext context) throws IOException {
+      Spans spans = super.getSpans(context, Postings.PAYLOADS);
       Similarity.SimScorer simScorer = simWeight == null ? null : similarity.simScorer(simWeight, context);
       return (spans == null) ? null : new PayloadNearSpanScorer(spans, this, simScorer);
     }
     
     @Override
     public Explanation explain(LeafReaderContext context, int doc) throws IOException {
-      PayloadNearSpanScorer scorer = (PayloadNearSpanScorer) scorer(context, context.reader().getLiveDocs());
+      PayloadNearSpanScorer scorer = (PayloadNearSpanScorer) scorer(context);
       if (scorer != null) {
         int newDoc = scorer.advance(doc);
         if (newDoc == doc) {
diff --git a/lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil.java b/lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil.java
index 567d1ab..ba47728 100644
--- a/lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil.java
+++ b/lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil.java
@@ -179,7 +179,7 @@ public class PayloadSpanUtil {
 
     PayloadSpanCollector collector = new PayloadSpanCollector();
     for (LeafReaderContext leafReaderContext : context.leaves()) {
-      final Spans spans = w.getSpans(leafReaderContext, leafReaderContext.reader().getLiveDocs(), SpanWeight.Postings.PAYLOADS);
+      final Spans spans = w.getSpans(leafReaderContext, SpanWeight.Postings.PAYLOADS);
       if (spans != null) {
         while (spans.nextDoc() != Spans.NO_MORE_DOCS) {
           while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {
diff --git a/lucene/core/src/java/org/apache/lucene/search/payloads/PayloadTermQuery.java b/lucene/core/src/java/org/apache/lucene/search/payloads/PayloadTermQuery.java
index 4fe571f..7bb3a44 100644
--- a/lucene/core/src/java/org/apache/lucene/search/payloads/PayloadTermQuery.java
+++ b/lucene/core/src/java/org/apache/lucene/search/payloads/PayloadTermQuery.java
@@ -32,7 +32,6 @@ import org.apache.lucene.search.spans.SpanScorer;
 import org.apache.lucene.search.spans.SpanTermQuery;
 import org.apache.lucene.search.spans.SpanWeight;
 import org.apache.lucene.search.spans.Spans;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 
 import java.io.IOException;
@@ -98,8 +97,8 @@ public class PayloadTermQuery extends SpanTermQuery {
     }
 
     @Override
-    public PayloadTermSpanScorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-      Spans spans = super.getSpans(context, acceptDocs, Postings.PAYLOADS);
+    public PayloadTermSpanScorer scorer(LeafReaderContext context) throws IOException {
+      Spans spans = super.getSpans(context, Postings.PAYLOADS);
       Similarity.SimScorer simScorer = simWeight == null ? null : similarity.simScorer(simWeight, context);
       return (spans == null) ? null : new PayloadTermSpanScorer(spans, this, simScorer);
     }
@@ -184,7 +183,7 @@ public class PayloadTermQuery extends SpanTermQuery {
     
     @Override
     public Explanation explain(LeafReaderContext context, int doc) throws IOException {
-      PayloadTermSpanScorer scorer = scorer(context, context.reader().getLiveDocs());
+      PayloadTermSpanScorer scorer = scorer(context);
       if (scorer != null) {
         int newDoc = scorer.advance(doc);
         if (newDoc == doc) {
diff --git a/lucene/core/src/java/org/apache/lucene/search/payloads/SpanPayloadCheckQuery.java b/lucene/core/src/java/org/apache/lucene/search/payloads/SpanPayloadCheckQuery.java
index 56bc406..cc75eeb 100644
--- a/lucene/core/src/java/org/apache/lucene/search/payloads/SpanPayloadCheckQuery.java
+++ b/lucene/core/src/java/org/apache/lucene/search/payloads/SpanPayloadCheckQuery.java
@@ -36,7 +36,6 @@ import org.apache.lucene.search.spans.SpanQuery;
 import org.apache.lucene.search.spans.SpanScorer;
 import org.apache.lucene.search.spans.SpanWeight;
 import org.apache.lucene.search.spans.Spans;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.ToStringUtils;
 
 /**
@@ -90,9 +89,9 @@ public class SpanPayloadCheckQuery extends SpanQuery {
     }
 
     @Override
-    public Spans getSpans(final LeafReaderContext context, Bits acceptDocs, Postings requiredPostings) throws IOException {
+    public Spans getSpans(final LeafReaderContext context, Postings requiredPostings) throws IOException {
       final PayloadSpanCollector collector = new PayloadSpanCollector();
-      Spans matchSpans = matchWeight.getSpans(context, acceptDocs, requiredPostings.atLeast(Postings.PAYLOADS));
+      Spans matchSpans = matchWeight.getSpans(context, requiredPostings.atLeast(Postings.PAYLOADS));
       return (matchSpans == null) ? null : new FilterSpans(matchSpans) {
         @Override
         protected AcceptStatus accept(Spans candidate) throws IOException {
@@ -104,7 +103,7 @@ public class SpanPayloadCheckQuery extends SpanQuery {
     }
 
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+    public Scorer scorer(LeafReaderContext context) throws IOException {
       if (field == null)
         return null;
 
@@ -113,7 +112,7 @@ public class SpanPayloadCheckQuery extends SpanQuery {
         throw new IllegalStateException("field \"" + field + "\" was indexed without position data; cannot run SpanQuery (query=" + parentQuery + ")");
       }
 
-      Spans spans = getSpans(context, acceptDocs, Postings.PAYLOADS);
+      Spans spans = getSpans(context, Postings.PAYLOADS);
       Similarity.SimScorer simScorer = simWeight == null ? null : similarity.simScorer(simWeight, context);
       return (spans == null) ? null : new SpanScorer(spans, this, simScorer);
     }
diff --git a/lucene/core/src/java/org/apache/lucene/search/spans/SpanContainQuery.java b/lucene/core/src/java/org/apache/lucene/search/spans/SpanContainQuery.java
index 6048e08..d1bb8e4 100644
--- a/lucene/core/src/java/org/apache/lucene/search/spans/SpanContainQuery.java
+++ b/lucene/core/src/java/org/apache/lucene/search/spans/SpanContainQuery.java
@@ -23,7 +23,6 @@ import org.apache.lucene.index.Term;
 import org.apache.lucene.index.TermContext;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
-import org.apache.lucene.util.Bits;
 
 import java.io.IOException;
 import java.util.ArrayList;
@@ -71,12 +70,12 @@ abstract class SpanContainQuery extends SpanQuery implements Cloneable {
       littleWeight.extractTerms(terms);
     }
 
-    ArrayList<Spans> prepareConjunction(final LeafReaderContext context, final Bits acceptDocs, Postings postings) throws IOException {
-      Spans bigSpans = bigWeight.getSpans(context, acceptDocs, postings);
+    ArrayList<Spans> prepareConjunction(final LeafReaderContext context, Postings postings) throws IOException {
+      Spans bigSpans = bigWeight.getSpans(context, postings);
       if (bigSpans == null) {
         return null;
       }
-      Spans littleSpans = littleWeight.getSpans(context, acceptDocs, postings);
+      Spans littleSpans = littleWeight.getSpans(context, postings);
       if (littleSpans == null) {
         return null;
       }
diff --git a/lucene/core/src/java/org/apache/lucene/search/spans/SpanContainingQuery.java b/lucene/core/src/java/org/apache/lucene/search/spans/SpanContainingQuery.java
index 0a658ee..6c2e062 100644
--- a/lucene/core/src/java/org/apache/lucene/search/spans/SpanContainingQuery.java
+++ b/lucene/core/src/java/org/apache/lucene/search/spans/SpanContainingQuery.java
@@ -70,8 +70,8 @@ public class SpanContainingQuery extends SpanContainQuery {
      * The payload is from the spans of <code>big</code>.
      */
     @Override
-    public Spans getSpans(final LeafReaderContext context, final Bits acceptDocs, Postings requiredPostings) throws IOException {
-      ArrayList<Spans> containerContained = prepareConjunction(context, acceptDocs, requiredPostings);
+    public Spans getSpans(final LeafReaderContext context, Postings requiredPostings) throws IOException {
+      ArrayList<Spans> containerContained = prepareConjunction(context, requiredPostings);
       if (containerContained == null) {
         return null;
       }
diff --git a/lucene/core/src/java/org/apache/lucene/search/spans/SpanNearQuery.java b/lucene/core/src/java/org/apache/lucene/search/spans/SpanNearQuery.java
index 2eff449..b34f10f 100644
--- a/lucene/core/src/java/org/apache/lucene/search/spans/SpanNearQuery.java
+++ b/lucene/core/src/java/org/apache/lucene/search/spans/SpanNearQuery.java
@@ -31,7 +31,6 @@ import org.apache.lucene.index.TermContext;
 import org.apache.lucene.index.Terms;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.ToStringUtils;
 
 /** Matches spans which are near one another.  One can specify <i>slop</i>, the
@@ -131,7 +130,7 @@ public class SpanNearQuery extends SpanQuery implements Cloneable {
     }
 
     @Override
-    public Spans getSpans(final LeafReaderContext context, Bits acceptDocs, Postings requiredPostings) throws IOException {
+    public Spans getSpans(final LeafReaderContext context, Postings requiredPostings) throws IOException {
 
       Terms terms = context.reader().terms(field);
       if (terms == null) {
@@ -140,7 +139,7 @@ public class SpanNearQuery extends SpanQuery implements Cloneable {
 
       ArrayList<Spans> subSpans = new ArrayList<>(clauses.size());
       for (SpanWeight w : subWeights) {
-        Spans subSpan = w.getSpans(context, acceptDocs, requiredPostings);
+        Spans subSpan = w.getSpans(context, requiredPostings);
         if (subSpan != null) {
           subSpans.add(subSpan);
         } else {
diff --git a/lucene/core/src/java/org/apache/lucene/search/spans/SpanNotQuery.java b/lucene/core/src/java/org/apache/lucene/search/spans/SpanNotQuery.java
index d56bd24..72235e6 100644
--- a/lucene/core/src/java/org/apache/lucene/search/spans/SpanNotQuery.java
+++ b/lucene/core/src/java/org/apache/lucene/search/spans/SpanNotQuery.java
@@ -25,7 +25,6 @@ import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.TwoPhaseIterator;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.ToStringUtils;
 
 import java.io.IOException;
@@ -128,13 +127,13 @@ public class SpanNotQuery extends SpanQuery implements Cloneable {
     }
 
     @Override
-    public Spans getSpans(final LeafReaderContext context, final Bits acceptDocs, Postings requiredPostings) throws IOException {
-      Spans includeSpans = includeWeight.getSpans(context, acceptDocs, requiredPostings);
+    public Spans getSpans(final LeafReaderContext context, Postings requiredPostings) throws IOException {
+      Spans includeSpans = includeWeight.getSpans(context, requiredPostings);
       if (includeSpans == null) {
         return null;
       }
 
-      Spans excludeSpans = excludeWeight.getSpans(context, acceptDocs, requiredPostings);
+      Spans excludeSpans = excludeWeight.getSpans(context, requiredPostings);
       if (excludeSpans == null) {
         return includeSpans;
       }
diff --git a/lucene/core/src/java/org/apache/lucene/search/spans/SpanOrQuery.java b/lucene/core/src/java/org/apache/lucene/search/spans/SpanOrQuery.java
index 6dd8eb8..a59467c 100644
--- a/lucene/core/src/java/org/apache/lucene/search/spans/SpanOrQuery.java
+++ b/lucene/core/src/java/org/apache/lucene/search/spans/SpanOrQuery.java
@@ -27,7 +27,6 @@ import org.apache.lucene.search.DisjunctionDISIApproximation;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.TwoPhaseIterator;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.ToStringUtils;
 
 import java.io.IOException;
@@ -170,13 +169,13 @@ public class SpanOrQuery extends SpanQuery implements Cloneable {
     }
 
     @Override
-    public Spans getSpans(final LeafReaderContext context, final Bits acceptDocs, Postings requiredPostings)
+    public Spans getSpans(final LeafReaderContext context, Postings requiredPostings)
         throws IOException {
 
       ArrayList<Spans> subSpans = new ArrayList<>(clauses.size());
 
       for (SpanWeight w : subWeights) {
-        Spans spans = w.getSpans(context, acceptDocs, requiredPostings);
+        Spans spans = w.getSpans(context, requiredPostings);
         if (spans != null) {
           subSpans.add(spans);
         }
diff --git a/lucene/core/src/java/org/apache/lucene/search/spans/SpanPositionCheckQuery.java b/lucene/core/src/java/org/apache/lucene/search/spans/SpanPositionCheckQuery.java
index 1c20975..e01fa01 100644
--- a/lucene/core/src/java/org/apache/lucene/search/spans/SpanPositionCheckQuery.java
+++ b/lucene/core/src/java/org/apache/lucene/search/spans/SpanPositionCheckQuery.java
@@ -24,7 +24,6 @@ import org.apache.lucene.index.TermContext;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.spans.FilterSpans.AcceptStatus;
-import org.apache.lucene.util.Bits;
 
 import java.io.IOException;
 import java.util.Map;
@@ -93,8 +92,8 @@ public abstract class SpanPositionCheckQuery extends SpanQuery implements Clonea
     }
 
     @Override
-    public Spans getSpans(final LeafReaderContext context, Bits acceptDocs, Postings requiredPostings) throws IOException {
-      Spans matchSpans = matchWeight.getSpans(context, acceptDocs, requiredPostings);
+    public Spans getSpans(final LeafReaderContext context, Postings requiredPostings) throws IOException {
+      Spans matchSpans = matchWeight.getSpans(context, requiredPostings);
       return (matchSpans == null) ? null : new FilterSpans(matchSpans) {
         @Override
         protected AcceptStatus accept(Spans candidate) throws IOException {
diff --git a/lucene/core/src/java/org/apache/lucene/search/spans/SpanTermQuery.java b/lucene/core/src/java/org/apache/lucene/search/spans/SpanTermQuery.java
index 4ea9b3f..f9aa01f 100644
--- a/lucene/core/src/java/org/apache/lucene/search/spans/SpanTermQuery.java
+++ b/lucene/core/src/java/org/apache/lucene/search/spans/SpanTermQuery.java
@@ -27,7 +27,6 @@ import org.apache.lucene.index.TermState;
 import org.apache.lucene.index.Terms;
 import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.ToStringUtils;
 
 import java.io.IOException;
@@ -99,7 +98,7 @@ public class SpanTermQuery extends SpanQuery {
     }
 
     @Override
-    public Spans getSpans(final LeafReaderContext context, Bits acceptDocs, Postings requiredPostings) throws IOException {
+    public Spans getSpans(final LeafReaderContext context, Postings requiredPostings) throws IOException {
 
       assert termContext.topReaderContext == ReaderUtil.getTopLevelContext(context) : "The top-reader used to create Weight (" + termContext.topReaderContext + ") is not the same as the current reader's top-reader (" + ReaderUtil.getTopLevelContext(context);
 
@@ -118,7 +117,7 @@ public class SpanTermQuery extends SpanQuery {
       final TermsEnum termsEnum = terms.iterator();
       termsEnum.seekExact(term.bytes(), state);
 
-      final PostingsEnum postings = termsEnum.postings(acceptDocs, null, requiredPostings.getRequiredPostings());
+      final PostingsEnum postings = termsEnum.postings(null, requiredPostings.getRequiredPostings());
       return new TermSpans(postings, term);
     }
   }
diff --git a/lucene/core/src/java/org/apache/lucene/search/spans/SpanWeight.java b/lucene/core/src/java/org/apache/lucene/search/spans/SpanWeight.java
index ccb0d9c..fa3c87b 100644
--- a/lucene/core/src/java/org/apache/lucene/search/spans/SpanWeight.java
+++ b/lucene/core/src/java/org/apache/lucene/search/spans/SpanWeight.java
@@ -114,11 +114,10 @@ public abstract class SpanWeight extends Weight {
   /**
    * Expert: Return a Spans object iterating over matches from this Weight
    * @param ctx a LeafReaderContext for this Spans
-   * @param acceptDocs a bitset of documents to check
    * @return a Spans
    * @throws IOException on error
    */
-  public abstract Spans getSpans(LeafReaderContext ctx, Bits acceptDocs, Postings requiredPostings) throws IOException;
+  public abstract Spans getSpans(LeafReaderContext ctx, Postings requiredPostings) throws IOException;
 
   @Override
   public float getValueForNormalization() throws IOException {
@@ -133,7 +132,7 @@ public abstract class SpanWeight extends Weight {
   }
 
   @Override
-  public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+  public Scorer scorer(LeafReaderContext context) throws IOException {
     if (field == null) {
       return null;
     }
@@ -141,14 +140,14 @@ public abstract class SpanWeight extends Weight {
     if (terms != null && terms.hasPositions() == false) {
       throw new IllegalStateException("field \"" + field + "\" was indexed without position data; cannot run SpanQuery (query=" + parentQuery + ")");
     }
-    Spans spans = getSpans(context, acceptDocs, Postings.POSITIONS);
+    Spans spans = getSpans(context, Postings.POSITIONS);
     Similarity.SimScorer simScorer = simWeight == null ? null : similarity.simScorer(simWeight, context);
     return (spans == null) ? null : new SpanScorer(spans, this, simScorer);
   }
 
   @Override
   public Explanation explain(LeafReaderContext context, int doc) throws IOException {
-    SpanScorer scorer = (SpanScorer) scorer(context, context.reader().getLiveDocs());
+    SpanScorer scorer = (SpanScorer) scorer(context);
     if (scorer != null) {
       int newDoc = scorer.advance(doc);
       if (newDoc == doc) {
diff --git a/lucene/core/src/java/org/apache/lucene/search/spans/SpanWithinQuery.java b/lucene/core/src/java/org/apache/lucene/search/spans/SpanWithinQuery.java
index cbca8fe..d172c27 100644
--- a/lucene/core/src/java/org/apache/lucene/search/spans/SpanWithinQuery.java
+++ b/lucene/core/src/java/org/apache/lucene/search/spans/SpanWithinQuery.java
@@ -21,7 +21,6 @@ import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.index.TermContext;
 import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.util.Bits;
 
 import java.io.IOException;
 import java.util.ArrayList;
@@ -71,8 +70,8 @@ public class SpanWithinQuery extends SpanContainQuery {
      * The payload is from the spans of <code>little</code>.
      */
     @Override
-    public Spans getSpans(final LeafReaderContext context, final Bits acceptDocs, Postings requiredPostings) throws IOException {
-      ArrayList<Spans> containerContained = prepareConjunction(context, acceptDocs, requiredPostings);
+    public Spans getSpans(final LeafReaderContext context, Postings requiredPostings) throws IOException {
+      ArrayList<Spans> containerContained = prepareConjunction(context, requiredPostings);
       if (containerContained == null) {
         return null;
       }
diff --git a/lucene/core/src/test/org/apache/lucene/analysis/TestCachingTokenFilter.java b/lucene/core/src/test/org/apache/lucene/analysis/TestCachingTokenFilter.java
index 10619a3..66ee0ce 100644
--- a/lucene/core/src/test/org/apache/lucene/analysis/TestCachingTokenFilter.java
+++ b/lucene/core/src/test/org/apache/lucene/analysis/TestCachingTokenFilter.java
@@ -85,7 +85,6 @@ public class TestCachingTokenFilter extends BaseTokenStreamTestCase {
     
     IndexReader reader = writer.getReader();
     PostingsEnum termPositions = MultiFields.getTermPositionsEnum(reader,
-                                                                          MultiFields.getLiveDocs(reader),
                                                                           "preanalyzed",
                                                                           new BytesRef("term1"));
     assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
@@ -93,7 +92,6 @@ public class TestCachingTokenFilter extends BaseTokenStreamTestCase {
     assertEquals(0, termPositions.nextPosition());
 
     termPositions = MultiFields.getTermPositionsEnum(reader,
-                                                     MultiFields.getLiveDocs(reader),
                                                      "preanalyzed",
                                                      new BytesRef("term2"));
     assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
@@ -102,7 +100,6 @@ public class TestCachingTokenFilter extends BaseTokenStreamTestCase {
     assertEquals(3, termPositions.nextPosition());
     
     termPositions = MultiFields.getTermPositionsEnum(reader,
-                                                     MultiFields.getLiveDocs(reader),
                                                      "preanalyzed",
                                                      new BytesRef("term3"));
     assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
diff --git a/lucene/core/src/test/org/apache/lucene/codecs/lucene50/TestBlockPostingsFormat3.java b/lucene/core/src/test/org/apache/lucene/codecs/lucene50/TestBlockPostingsFormat3.java
index 61105b5..82fa465 100644
--- a/lucene/core/src/test/org/apache/lucene/codecs/lucene50/TestBlockPostingsFormat3.java
+++ b/lucene/core/src/test/org/apache/lucene/codecs/lucene50/TestBlockPostingsFormat3.java
@@ -283,7 +283,6 @@ public class TestBlockPostingsFormat3 extends LuceneTestCase {
    */
   public void assertTermsEnum(TermsEnum leftTermsEnum, TermsEnum rightTermsEnum, boolean deep, boolean hasPositions) throws Exception {
     BytesRef term;
-    Bits randomBits = new RandomBits(MAXDOC, random().nextDouble(), random());
     PostingsEnum leftPositions = null;
     PostingsEnum rightPositions = null;
     PostingsEnum leftDocs = null;
@@ -295,84 +294,54 @@ public class TestBlockPostingsFormat3 extends LuceneTestCase {
       if (deep) {
         if (hasPositions) {
           // with payloads + off
-          assertDocsAndPositionsEnum(leftPositions = leftTermsEnum.postings(null, leftPositions, PostingsEnum.ALL),
-                                     rightPositions = rightTermsEnum.postings(null, rightPositions, PostingsEnum.ALL));
-          assertDocsAndPositionsEnum(leftPositions = leftTermsEnum.postings(randomBits, leftPositions, PostingsEnum.ALL),
-                                     rightPositions = rightTermsEnum.postings(randomBits, rightPositions, PostingsEnum.ALL));
+          assertDocsAndPositionsEnum(leftPositions = leftTermsEnum.postings(leftPositions, PostingsEnum.ALL),
+                                     rightPositions = rightTermsEnum.postings(rightPositions, PostingsEnum.ALL));
 
           assertPositionsSkipping(leftTermsEnum.docFreq(),
-                                  leftPositions = leftTermsEnum.postings(null, leftPositions, PostingsEnum.ALL),
-                                  rightPositions = rightTermsEnum.postings(null, rightPositions, PostingsEnum.ALL));
-          assertPositionsSkipping(leftTermsEnum.docFreq(),
-                                  leftPositions = leftTermsEnum.postings(randomBits, leftPositions, PostingsEnum.ALL),
-                                  rightPositions = rightTermsEnum.postings(randomBits, rightPositions, PostingsEnum.ALL));
+                                  leftPositions = leftTermsEnum.postings(leftPositions, PostingsEnum.ALL),
+                                  rightPositions = rightTermsEnum.postings(rightPositions, PostingsEnum.ALL));
           // with payloads only
-          assertDocsAndPositionsEnum(leftPositions = leftTermsEnum.postings(null, leftPositions, PostingsEnum.PAYLOADS),
-                                     rightPositions = rightTermsEnum.postings(null, rightPositions, PostingsEnum.PAYLOADS));
-          assertDocsAndPositionsEnum(leftPositions = leftTermsEnum.postings(randomBits, leftPositions, PostingsEnum.PAYLOADS),
-                                     rightPositions = rightTermsEnum.postings(randomBits, rightPositions, PostingsEnum.PAYLOADS));
+          assertDocsAndPositionsEnum(leftPositions = leftTermsEnum.postings(leftPositions, PostingsEnum.PAYLOADS),
+                                     rightPositions = rightTermsEnum.postings(rightPositions, PostingsEnum.PAYLOADS));
 
           assertPositionsSkipping(leftTermsEnum.docFreq(),
-                                  leftPositions = leftTermsEnum.postings(null, leftPositions, PostingsEnum.PAYLOADS),
-                                  rightPositions = rightTermsEnum.postings(null, rightPositions, PostingsEnum.PAYLOADS));
-          assertPositionsSkipping(leftTermsEnum.docFreq(),
-                                  leftPositions = leftTermsEnum.postings(randomBits, leftPositions, PostingsEnum.PAYLOADS),
-                                  rightPositions = rightTermsEnum.postings(randomBits, rightPositions, PostingsEnum.PAYLOADS));
+                                  leftPositions = leftTermsEnum.postings(leftPositions, PostingsEnum.PAYLOADS),
+                                  rightPositions = rightTermsEnum.postings(rightPositions, PostingsEnum.PAYLOADS));
 
           // with offsets only
-          assertDocsAndPositionsEnum(leftPositions = leftTermsEnum.postings(null, leftPositions, PostingsEnum.OFFSETS),
-                                     rightPositions = rightTermsEnum.postings(null, rightPositions, PostingsEnum.OFFSETS));
-          assertDocsAndPositionsEnum(leftPositions = leftTermsEnum.postings(randomBits, leftPositions, PostingsEnum.OFFSETS),
-                                     rightPositions = rightTermsEnum.postings(randomBits, rightPositions, PostingsEnum.OFFSETS));
+          assertDocsAndPositionsEnum(leftPositions = leftTermsEnum.postings(leftPositions, PostingsEnum.OFFSETS),
+                                     rightPositions = rightTermsEnum.postings(rightPositions, PostingsEnum.OFFSETS));
 
           assertPositionsSkipping(leftTermsEnum.docFreq(),
-                                  leftPositions = leftTermsEnum.postings(null, leftPositions, PostingsEnum.OFFSETS),
-                                  rightPositions = rightTermsEnum.postings(null, rightPositions, PostingsEnum.OFFSETS));
-          assertPositionsSkipping(leftTermsEnum.docFreq(),
-                                  leftPositions = leftTermsEnum.postings(randomBits, leftPositions, PostingsEnum.OFFSETS),
-                                  rightPositions = rightTermsEnum.postings(randomBits, rightPositions, PostingsEnum.OFFSETS));
+                                  leftPositions = leftTermsEnum.postings(leftPositions, PostingsEnum.OFFSETS),
+                                  rightPositions = rightTermsEnum.postings(rightPositions, PostingsEnum.OFFSETS));
 
           // with positions only
-          assertDocsAndPositionsEnum(leftPositions = leftTermsEnum.postings(null, leftPositions, PostingsEnum.POSITIONS),
-                                     rightPositions = rightTermsEnum.postings(null, rightPositions, PostingsEnum.POSITIONS));
-          assertDocsAndPositionsEnum(leftPositions = leftTermsEnum.postings(randomBits, leftPositions, PostingsEnum.POSITIONS),
-                                     rightPositions = rightTermsEnum.postings(randomBits, rightPositions, PostingsEnum.POSITIONS));
+          assertDocsAndPositionsEnum(leftPositions = leftTermsEnum.postings(leftPositions, PostingsEnum.POSITIONS),
+                                     rightPositions = rightTermsEnum.postings(rightPositions, PostingsEnum.POSITIONS));
 
           assertPositionsSkipping(leftTermsEnum.docFreq(),
-                                  leftPositions = leftTermsEnum.postings(null, leftPositions, PostingsEnum.POSITIONS),
-                                  rightPositions = rightTermsEnum.postings(null, rightPositions, PostingsEnum.POSITIONS));
-          assertPositionsSkipping(leftTermsEnum.docFreq(),
-                                  leftPositions = leftTermsEnum.postings(randomBits, leftPositions, PostingsEnum.POSITIONS),
-                                  rightPositions = rightTermsEnum.postings(randomBits, rightPositions, PostingsEnum.POSITIONS));
+                                  leftPositions = leftTermsEnum.postings(leftPositions, PostingsEnum.POSITIONS),
+                                  rightPositions = rightTermsEnum.postings(rightPositions, PostingsEnum.POSITIONS));
         }
         
         // with freqs:
-        assertDocsEnum(leftDocs = leftTermsEnum.postings(null, leftDocs),
-            rightDocs = rightTermsEnum.postings(null, rightDocs));
-        assertDocsEnum(leftDocs = leftTermsEnum.postings(randomBits, leftDocs),
-            rightDocs = rightTermsEnum.postings(randomBits, rightDocs));
+        assertDocsEnum(leftDocs = leftTermsEnum.postings(leftDocs),
+            rightDocs = rightTermsEnum.postings(rightDocs));
 
         // w/o freqs:
-        assertDocsEnum(leftDocs = leftTermsEnum.postings(null, leftDocs, PostingsEnum.NONE),
-            rightDocs = rightTermsEnum.postings(null, rightDocs, PostingsEnum.NONE));
-        assertDocsEnum(leftDocs = leftTermsEnum.postings(randomBits, leftDocs, PostingsEnum.NONE),
-            rightDocs = rightTermsEnum.postings(randomBits, rightDocs, PostingsEnum.NONE));
-        
+        assertDocsEnum(leftDocs = leftTermsEnum.postings(leftDocs, PostingsEnum.NONE),
+            rightDocs = rightTermsEnum.postings(rightDocs, PostingsEnum.NONE));
+
         // with freqs:
         assertDocsSkipping(leftTermsEnum.docFreq(), 
-            leftDocs = leftTermsEnum.postings(null, leftDocs),
-            rightDocs = rightTermsEnum.postings(null, rightDocs));
-        assertDocsSkipping(leftTermsEnum.docFreq(), 
-            leftDocs = leftTermsEnum.postings(randomBits, leftDocs),
-            rightDocs = rightTermsEnum.postings(randomBits, rightDocs));
+            leftDocs = leftTermsEnum.postings(leftDocs),
+            rightDocs = rightTermsEnum.postings(rightDocs));
 
         // w/o freqs:
         assertDocsSkipping(leftTermsEnum.docFreq(), 
-            leftDocs = leftTermsEnum.postings(null, leftDocs, PostingsEnum.NONE),
-            rightDocs = rightTermsEnum.postings(null, rightDocs, PostingsEnum.NONE));
-        assertDocsSkipping(leftTermsEnum.docFreq(), 
-            leftDocs = leftTermsEnum.postings(randomBits, leftDocs, PostingsEnum.NONE),
-            rightDocs = rightTermsEnum.postings(randomBits, rightDocs, PostingsEnum.NONE));
+            leftDocs = leftTermsEnum.postings(leftDocs, PostingsEnum.NONE),
+            rightDocs = rightTermsEnum.postings(rightDocs, PostingsEnum.NONE));
       }
     }
     assertNull(rightTermsEnum.next());
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestAddIndexes.java b/lucene/core/src/test/org/apache/lucene/index/TestAddIndexes.java
index 1beb2dc..8f1a680 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestAddIndexes.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestAddIndexes.java
@@ -532,7 +532,7 @@ public class TestAddIndexes extends LuceneTestCase {
   private void verifyTermDocs(Directory dir, Term term, int numDocs)
       throws IOException {
     IndexReader reader = DirectoryReader.open(dir);
-    PostingsEnum postingsEnum = TestUtil.docs(random(), reader, term.field, term.bytes, null, null, PostingsEnum.NONE);
+    PostingsEnum postingsEnum = TestUtil.docs(random(), reader, term.field, term.bytes, null, PostingsEnum.NONE);
     int count = 0;
     while (postingsEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)
       count++;
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestCodecs.java b/lucene/core/src/test/org/apache/lucene/index/TestCodecs.java
index cd5fb20..52d47ec 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestCodecs.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestCodecs.java
@@ -245,7 +245,7 @@ public class TestCodecs extends LuceneTestCase {
       // make sure it properly fully resets (rewinds) its
       // internal state:
       for(int iter=0;iter<2;iter++) {
-        postingsEnum = TestUtil.docs(random(), termsEnum, null, postingsEnum, PostingsEnum.NONE);
+        postingsEnum = TestUtil.docs(random(), termsEnum, postingsEnum, PostingsEnum.NONE);
         assertEquals(terms[i].docs[0], postingsEnum.nextDoc());
         assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());
       }
@@ -382,9 +382,9 @@ public class TestCodecs extends LuceneTestCase {
         assertEquals(status, TermsEnum.SeekStatus.FOUND);
         assertEquals(term.docs.length, termsEnum.docFreq());
         if (field.omitTF) {
-          this.verifyDocs(term.docs, term.positions, TestUtil.docs(random(), termsEnum, null, null, PostingsEnum.NONE), false);
+          this.verifyDocs(term.docs, term.positions, TestUtil.docs(random(), termsEnum, null, PostingsEnum.NONE), false);
         } else {
-          this.verifyDocs(term.docs, term.positions, termsEnum.postings(null, null, PostingsEnum.ALL), true);
+          this.verifyDocs(term.docs, term.positions, termsEnum.postings(null, PostingsEnum.ALL), true);
         }
 
         // Test random seek by ord:
@@ -402,9 +402,9 @@ public class TestCodecs extends LuceneTestCase {
           assertTrue(termsEnum.term().bytesEquals(new BytesRef(term.text2)));
           assertEquals(term.docs.length, termsEnum.docFreq());
           if (field.omitTF) {
-            this.verifyDocs(term.docs, term.positions, TestUtil.docs(random(), termsEnum, null, null, PostingsEnum.NONE), false);
+            this.verifyDocs(term.docs, term.positions, TestUtil.docs(random(), termsEnum, null, PostingsEnum.NONE), false);
           } else {
-            this.verifyDocs(term.docs, term.positions, termsEnum.postings(null, null, PostingsEnum.ALL), true);
+            this.verifyDocs(term.docs, term.positions, termsEnum.postings(null, PostingsEnum.ALL), true);
           }
         }
 
@@ -456,9 +456,9 @@ public class TestCodecs extends LuceneTestCase {
             if (!field.omitTF) {
               // TODO: we should randomize which postings features are available, but
               // need to coordinate this with the checks below that rely on such features
-              postings = termsEnum.postings(null, null, PostingsEnum.ALL);
+              postings = termsEnum.postings(null, PostingsEnum.ALL);
             } else {
-              postings = TestUtil.docs(random(), termsEnum, null, null, PostingsEnum.FREQS);
+              postings = TestUtil.docs(random(), termsEnum, null, PostingsEnum.FREQS);
             }
             assertNotNull(postings);
             int upto2 = -1;
@@ -677,8 +677,7 @@ public class TestCodecs extends LuceneTestCase {
     }
 
     @Override
-    public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) {
-      assert liveDocs == null;
+    public PostingsEnum postings(PostingsEnum reuse, int flags) {
       return new DataPostingsEnum(fieldData.terms[upto]);
     }
 
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader.java b/lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader.java
index 2a3a2fd..589f16c 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader.java
@@ -96,13 +96,12 @@ public class TestDirectoryReader extends LuceneTestCase {
     PostingsEnum td = TestUtil.docs(random(), mr2,
         "body",
         te2.term(),
-        MultiFields.getLiveDocs(mr2),
         null,
         0);
 
     TermsEnum te3 = MultiFields.getTerms(mr3, "body").iterator();
     te3.seekCeil(new BytesRef("wow"));
-    td = TestUtil.docs(random(), te3, MultiFields.getLiveDocs(mr3),
+    td = TestUtil.docs(random(), te3,
         td,
         0);
     
@@ -351,7 +350,6 @@ void assertTermDocsCount(String msg,
   PostingsEnum tdocs = TestUtil.docs(random(), reader,
       term.field(),
       new BytesRef(term.text()),
-      MultiFields.getLiveDocs(reader),
       null,
       0);
   int count = 0;
@@ -617,7 +615,6 @@ public void testFilesOpenClose() throws IOException {
     Fields fields1 = MultiFields.getFields(index1);
     Fields fields2 = MultiFields.getFields(index2);
     Iterator<String> fenum2 = fields2.iterator();
-    Bits liveDocs = MultiFields.getLiveDocs(index1);
     for (String field1 : fields1) {
       assertEquals("Different fields", field1, fenum2.next());
       Terms terms1 = fields1.terms(field1);
@@ -633,8 +630,8 @@ public void testFilesOpenClose() throws IOException {
 
       while(enum1.next() != null) {
         assertEquals("Different terms", enum1.term(), enum2.next());
-        PostingsEnum tp1 = enum1.postings(liveDocs, null, PostingsEnum.ALL);
-        PostingsEnum tp2 = enum2.postings(liveDocs, null, PostingsEnum.ALL);
+        PostingsEnum tp1 = enum1.postings(null, PostingsEnum.ALL);
+        PostingsEnum tp2 = enum2.postings(null, PostingsEnum.ALL);
 
         while(tp1.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
           assertTrue(tp2.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestDoc.java b/lucene/core/src/test/org/apache/lucene/index/TestDoc.java
index 6cbaf34..91f9753 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestDoc.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestDoc.java
@@ -44,6 +44,7 @@ import org.apache.lucene.store.IOContext;
 import org.apache.lucene.store.MergeInfo;
 import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.store.TrackingDirectoryWrapper;
+import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.InfoStream;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.StringHelper;
@@ -262,9 +263,13 @@ public class TestDoc extends LuceneTestCase {
         out.print("  term=" + field + ":" + tis.term());
         out.println("    DF=" + tis.docFreq());
 
-        PostingsEnum positions = tis.postings(reader.getLiveDocs(), null, PostingsEnum.POSITIONS);
+        PostingsEnum positions = tis.postings(null, PostingsEnum.POSITIONS);
 
+        final Bits liveDocs = reader.getLiveDocs();
         while (positions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
+          if (liveDocs != null && liveDocs.get(positions.docID()) == false) {
+            continue;
+          }
           out.print(" doc=" + positions.docID());
           out.print(" TF=" + positions.freq());
           out.print(" pos=");
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestDocCount.java b/lucene/core/src/test/org/apache/lucene/index/TestDocCount.java
index aa40922..18089bf 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestDocCount.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestDocCount.java
@@ -67,7 +67,7 @@ public class TestDocCount extends LuceneTestCase {
       FixedBitSet visited = new FixedBitSet(ir.maxDoc());
       TermsEnum te = terms.iterator();
       while (te.next() != null) {
-        PostingsEnum de = TestUtil.docs(random(), te, null, null, PostingsEnum.NONE);
+        PostingsEnum de = TestUtil.docs(random(), te, null, PostingsEnum.NONE);
         while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
           visited.set(de.docID());
         }
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions.java b/lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions.java
index ae58fbf..d9f5dd7 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions.java
@@ -66,7 +66,7 @@ public class TestDocsAndPositions extends LuceneTestCase {
       IndexReaderContext topReaderContext = reader.getContext();
       for (LeafReaderContext leafReaderContext : topReaderContext.leaves()) {
         PostingsEnum docsAndPosEnum = getDocsAndPositions(
-            leafReaderContext.reader(), bytes, null);
+            leafReaderContext.reader(), bytes);
         assertNotNull(docsAndPosEnum);
         if (leafReaderContext.reader().maxDoc() == 0) {
           continue;
@@ -91,12 +91,12 @@ public class TestDocsAndPositions extends LuceneTestCase {
   }
 
   public PostingsEnum getDocsAndPositions(LeafReader reader,
-      BytesRef bytes, Bits liveDocs) throws IOException {
+      BytesRef bytes) throws IOException {
     Terms terms = reader.terms(fieldName);
     if (terms != null) {
       TermsEnum te = terms.iterator();
       if (te.seekExact(bytes)) {
-        return te.postings(liveDocs, null, PostingsEnum.ALL);
+        return te.postings(null, PostingsEnum.ALL);
       }
     }
     return null;
@@ -149,7 +149,7 @@ public class TestDocsAndPositions extends LuceneTestCase {
       IndexReaderContext topReaderContext = reader.getContext();
       for (LeafReaderContext leafReaderContext : topReaderContext.leaves()) {
         PostingsEnum docsAndPosEnum = getDocsAndPositions(
-            leafReaderContext.reader(), bytes, null);
+            leafReaderContext.reader(), bytes);
         assertNotNull(docsAndPosEnum);
         int initDoc = 0;
         int maxDoc = leafReaderContext.reader().maxDoc();
@@ -226,7 +226,7 @@ public class TestDocsAndPositions extends LuceneTestCase {
       IndexReaderContext topReaderContext = reader.getContext();
       for (LeafReaderContext context : topReaderContext.leaves()) {
         int maxDoc = context.reader().maxDoc();
-        PostingsEnum postingsEnum = TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, PostingsEnum.FREQS);
+        PostingsEnum postingsEnum = TestUtil.docs(random(), context.reader(), fieldName, bytes, null, PostingsEnum.FREQS);
         if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {
           assertNull(postingsEnum);
           continue;
@@ -304,7 +304,7 @@ public class TestDocsAndPositions extends LuceneTestCase {
       IndexReaderContext topReaderContext = reader.getContext();
       for (LeafReaderContext leafReaderContext : topReaderContext.leaves()) {
         PostingsEnum docsAndPosEnum = getDocsAndPositions(
-            leafReaderContext.reader(), bytes, null);
+            leafReaderContext.reader(), bytes);
         assertNotNull(docsAndPosEnum);
 
         int initDoc = 0;
@@ -336,7 +336,7 @@ public class TestDocsAndPositions extends LuceneTestCase {
     writer.addDocument(doc);
     DirectoryReader reader = writer.getReader();
     LeafReader r = getOnlySegmentReader(reader);
-    PostingsEnum disi = TestUtil.docs(random(), r, "foo", new BytesRef("bar"), null, null, PostingsEnum.NONE);
+    PostingsEnum disi = TestUtil.docs(random(), r, "foo", new BytesRef("bar"), null, PostingsEnum.NONE);
     int docid = disi.docID();
     assertEquals(-1, docid);
     assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
@@ -344,7 +344,7 @@ public class TestDocsAndPositions extends LuceneTestCase {
     // now reuse and check again
     TermsEnum te = r.terms("foo").iterator();
     assertTrue(te.seekExact(new BytesRef("bar")));
-    disi = TestUtil.docs(random(), te, null, disi, PostingsEnum.NONE);
+    disi = TestUtil.docs(random(), te, disi, PostingsEnum.NONE);
     docid = disi.docID();
     assertEquals(-1, docid);
     assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
@@ -369,7 +369,7 @@ public class TestDocsAndPositions extends LuceneTestCase {
     // now reuse and check again
     TermsEnum te = r.terms("foo").iterator();
     assertTrue(te.seekExact(new BytesRef("bar")));
-    disi = te.postings(null, disi, PostingsEnum.ALL);
+    disi = te.postings(disi, PostingsEnum.ALL);
     docid = disi.docID();
     assertEquals(-1, docid);
     assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter.java b/lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter.java
index d057bff..3670365 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter.java
@@ -125,8 +125,7 @@ public class TestDocumentWriter extends LuceneTestCase {
     writer.close();
     SegmentReader reader = new SegmentReader(info, newIOContext(random()));
 
-    PostingsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),
-                                                                          "repeated", new BytesRef("repeated"));
+    PostingsEnum termPositions = MultiFields.getTermPositionsEnum(reader, "repeated", new BytesRef("repeated"));
     assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
     int freq = termPositions.freq();
     assertEquals(2, freq);
@@ -197,7 +196,7 @@ public class TestDocumentWriter extends LuceneTestCase {
     writer.close();
     SegmentReader reader = new SegmentReader(info, newIOContext(random()));
 
-    PostingsEnum termPositions = MultiFields.getTermPositionsEnum(reader, reader.getLiveDocs(), "f1", new BytesRef("a"));
+    PostingsEnum termPositions = MultiFields.getTermPositionsEnum(reader, "f1", new BytesRef("a"));
     assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
     int freq = termPositions.freq();
     assertEquals(3, freq);
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestFilterLeafReader.java b/lucene/core/src/test/org/apache/lucene/index/TestFilterLeafReader.java
index a131d6f..c2d74a1 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestFilterLeafReader.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestFilterLeafReader.java
@@ -28,7 +28,6 @@ import org.apache.lucene.document.Field;
 import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.store.BaseDirectoryWrapper;
 import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
 
@@ -76,8 +75,8 @@ public class TestFilterLeafReader extends LuceneTestCase {
       }
 
       @Override
-      public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
-        return new TestPositions(super.postings(liveDocs, reuse == null ? null : ((FilterPostingsEnum) reuse).in, flags));
+      public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
+        return new TestPositions(super.postings(reuse == null ? null : ((FilterPostingsEnum) reuse).in, flags));
       }
     }
 
@@ -151,7 +150,7 @@ public class TestFilterLeafReader extends LuceneTestCase {
     
     assertEquals(TermsEnum.SeekStatus.FOUND, terms.seekCeil(new BytesRef("one")));
     
-    PostingsEnum positions = terms.postings(MultiFields.getLiveDocs(reader), null, PostingsEnum.ALL);
+    PostingsEnum positions = terms.postings(null, PostingsEnum.ALL);
     while (positions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
       assertTrue((positions.docID() % 2) == 1);
     }
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriter.java b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriter.java
index 646d719..9a27ad9 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriter.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriter.java
@@ -498,7 +498,6 @@ public class TestIndexWriter extends LuceneTestCase {
       PostingsEnum td = TestUtil.docs(random(), reader,
           "field",
           new BytesRef("a"),
-          MultiFields.getLiveDocs(reader),
           null,
           PostingsEnum.FREQS);
       td.nextDoc();
@@ -826,14 +825,14 @@ public class TestIndexWriter extends LuceneTestCase {
     Terms tpv = r.getTermVectors(0).terms("field");
     TermsEnum termsEnum = tpv.iterator();
     assertNotNull(termsEnum.next());
-    PostingsEnum dpEnum = termsEnum.postings(null, null, PostingsEnum.ALL);
+    PostingsEnum dpEnum = termsEnum.postings(null, PostingsEnum.ALL);
     assertNotNull(dpEnum);
     assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
     assertEquals(1, dpEnum.freq());
     assertEquals(100, dpEnum.nextPosition());
 
     assertNotNull(termsEnum.next());
-    dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);
+    dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);
     assertNotNull(dpEnum);
     assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
     assertEquals(1, dpEnum.freq());
@@ -1232,12 +1231,12 @@ public class TestIndexWriter extends LuceneTestCase {
 
 
     // test that the terms were indexed.
-    assertTrue(TestUtil.docs(random(), ir, "binary", new BytesRef("doc1field1"), null, null, PostingsEnum.NONE).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
-    assertTrue(TestUtil.docs(random(), ir, "binary", new BytesRef("doc2field1"), null, null, PostingsEnum.NONE).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
-    assertTrue(TestUtil.docs(random(), ir, "binary", new BytesRef("doc3field1"), null, null, PostingsEnum.NONE).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
-    assertTrue(TestUtil.docs(random(), ir, "string", new BytesRef("doc1field2"), null, null, PostingsEnum.NONE).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
-    assertTrue(TestUtil.docs(random(), ir, "string", new BytesRef("doc2field2"), null, null, PostingsEnum.NONE).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
-    assertTrue(TestUtil.docs(random(), ir, "string", new BytesRef("doc3field2"), null, null, PostingsEnum.NONE).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
+    assertTrue(TestUtil.docs(random(), ir, "binary", new BytesRef("doc1field1"), null, PostingsEnum.NONE).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
+    assertTrue(TestUtil.docs(random(), ir, "binary", new BytesRef("doc2field1"), null, PostingsEnum.NONE).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
+    assertTrue(TestUtil.docs(random(), ir, "binary", new BytesRef("doc3field1"), null, PostingsEnum.NONE).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
+    assertTrue(TestUtil.docs(random(), ir, "string", new BytesRef("doc1field2"), null, PostingsEnum.NONE).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
+    assertTrue(TestUtil.docs(random(), ir, "string", new BytesRef("doc2field2"), null, PostingsEnum.NONE).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
+    assertTrue(TestUtil.docs(random(), ir, "string", new BytesRef("doc3field2"), null, PostingsEnum.NONE).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
 
     ir.close();
     dir.close();
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java
index 6180828..859be6c 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java
@@ -531,13 +531,15 @@ public class TestIndexWriterExceptions extends LuceneTestCase {
     PostingsEnum tdocs = TestUtil.docs(random(), reader,
         t.field(),
         new BytesRef(t.text()),
-        MultiFields.getLiveDocs(reader),
         null,
         0);
 
+    final Bits liveDocs = MultiFields.getLiveDocs(reader);
     int count = 0;
     while(tdocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
-      count++;
+      if (liveDocs == null || liveDocs.get(tdocs.docID())) {
+        count++;
+      }
     }
     assertEquals(2, count);
 
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader.java b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader.java
index 30b6a92..d4e5ef5 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader.java
@@ -38,6 +38,7 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.MockDirectoryWrapper.FakeIOException;
 import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.store.RAMDirectory;
+import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.InfoStream;
 import org.apache.lucene.util.LuceneTestCase;
@@ -55,14 +56,16 @@ public class TestIndexWriterReader extends LuceneTestCase {
     int count = 0;
     PostingsEnum td = TestUtil.docs(random(), r,
         t.field(), new BytesRef(t.text()),
-        MultiFields.getLiveDocs(r),
         null,
         0);
 
     if (td != null) {
+      final Bits liveDocs = MultiFields.getLiveDocs(r);
       while (td.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
         td.docID();
-        count++;
+        if (liveDocs == null || liveDocs.get(td.docID())) {
+          count++;
+        }
       }
     }
     return count;
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterWithThreads.java b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterWithThreads.java
index 09f7830..e2348df 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterWithThreads.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterWithThreads.java
@@ -247,7 +247,6 @@ public class TestIndexWriterWithThreads extends LuceneTestCase {
       PostingsEnum tdocs = TestUtil.docs(random(), reader,
           "field",
           new BytesRef("aaa"),
-          MultiFields.getLiveDocs(reader),
           null,
           0);
       int count = 0;
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestIndexableField.java b/lucene/core/src/test/org/apache/lucene/index/TestIndexableField.java
index 999dd7c..f5a63aa 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestIndexableField.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestIndexableField.java
@@ -332,14 +332,14 @@ public class TestIndexableField extends LuceneTestCase {
             TermsEnum termsEnum = tfv.iterator();
             assertEquals(new BytesRef(""+counter), termsEnum.next());
             assertEquals(1, termsEnum.totalTermFreq());
-            PostingsEnum dpEnum = termsEnum.postings(null, null, PostingsEnum.ALL);
+            PostingsEnum dpEnum = termsEnum.postings(null, PostingsEnum.ALL);
             assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
             assertEquals(1, dpEnum.freq());
             assertEquals(1, dpEnum.nextPosition());
 
             assertEquals(new BytesRef("text"), termsEnum.next());
             assertEquals(1, termsEnum.totalTermFreq());
-            dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);
+            dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);
             assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
             assertEquals(1, dpEnum.freq());
             assertEquals(0, dpEnum.nextPosition());
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestLazyProxSkipping.java b/lucene/core/src/test/org/apache/lucene/index/TestLazyProxSkipping.java
index 1b96978..5f15ab1 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestLazyProxSkipping.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestLazyProxSkipping.java
@@ -153,7 +153,6 @@ public class TestLazyProxSkipping extends LuceneTestCase {
         IndexReader reader = DirectoryReader.open(directory);
 
         PostingsEnum tp = MultiFields.getTermPositionsEnum(reader,
-                                                                   MultiFields.getLiveDocs(reader),
                                                                    this.field,
                                                                    new BytesRef("b"));
 
@@ -164,7 +163,6 @@ public class TestLazyProxSkipping extends LuceneTestCase {
         }
 
         tp = MultiFields.getTermPositionsEnum(reader,
-                                              MultiFields.getLiveDocs(reader),
                                               this.field,
                                               new BytesRef("a"));
 
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestLongPostings.java b/lucene/core/src/test/org/apache/lucene/index/TestLongPostings.java
index 8c458e6..afa39ff 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestLongPostings.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestLongPostings.java
@@ -167,7 +167,7 @@ public class TestLongPostings extends LuceneTestCase {
         System.out.println("\nTEST: iter=" + iter + " doS1=" + doS1);
       }
         
-      final PostingsEnum postings = MultiFields.getTermPositionsEnum(r, null, "field", new BytesRef(term));
+      final PostingsEnum postings = MultiFields.getTermPositionsEnum(r, "field", new BytesRef(term));
 
       int docID = -1;
       while(docID < DocIdSetIterator.NO_MORE_DOCS) {
@@ -374,10 +374,10 @@ public class TestLongPostings extends LuceneTestCase {
       final PostingsEnum postings;
 
       if (options == IndexOptions.DOCS) {
-        docs = TestUtil.docs(random(), r, "field", new BytesRef(term), null, null, PostingsEnum.NONE);
+        docs = TestUtil.docs(random(), r, "field", new BytesRef(term), null, PostingsEnum.NONE);
         postings = null;
       } else {
-        docs = postings = TestUtil.docs(random(), r, "field", new BytesRef(term), null, null, PostingsEnum.FREQS);
+        docs = postings = TestUtil.docs(random(), r, "field", new BytesRef(term), null, PostingsEnum.FREQS);
         assert postings != null;
       }
       assert docs != null;
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestMaxPosition.java b/lucene/core/src/test/org/apache/lucene/index/TestMaxPosition.java
index e04215c..0d55ebd 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestMaxPosition.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestMaxPosition.java
@@ -81,7 +81,7 @@ public class TestMaxPosition extends LuceneTestCase {
     // Document should be visible:
     IndexReader r = DirectoryReader.open(iw, true);
     assertEquals(1, r.numDocs());
-    PostingsEnum postings = MultiFields.getTermPositionsEnum(r, null, "foo", new BytesRef("foo"));
+    PostingsEnum postings = MultiFields.getTermPositionsEnum(r, "foo", new BytesRef("foo"));
 
     // "foo" appears in docID=0
     assertEquals(0, postings.nextDoc());
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestMultiFields.java b/lucene/core/src/test/org/apache/lucene/index/TestMultiFields.java
index 8d46be9..7de3132 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestMultiFields.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestMultiFields.java
@@ -135,13 +135,11 @@ public class TestMultiFields extends LuceneTestCase {
           System.out.println("TEST: seek term="+ UnicodeUtil.toHexString(term.utf8ToString()) + " " + term);
         }
         
-        PostingsEnum postingsEnum = TestUtil.docs(random(), reader, "field", term, liveDocs, null, PostingsEnum.NONE);
+        PostingsEnum postingsEnum = TestUtil.docs(random(), reader, "field", term, null, PostingsEnum.NONE);
         assertNotNull(postingsEnum);
 
         for(int docID : docs.get(term)) {
-          if (!deleted.contains(docID)) {
-            assertEquals(docID, postingsEnum.nextDoc());
-          }
+          assertEquals(docID, postingsEnum.nextDoc());
         }
         assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());
       }
@@ -176,8 +174,8 @@ public class TestMultiFields extends LuceneTestCase {
     w.addDocument(d);
     IndexReader r = w.getReader();
     w.close();
-    PostingsEnum d1 = TestUtil.docs(random(), r, "f", new BytesRef("j"), null, null, PostingsEnum.NONE);
-    PostingsEnum d2 = TestUtil.docs(random(), r, "f", new BytesRef("j"), null, null, PostingsEnum.NONE);
+    PostingsEnum d1 = TestUtil.docs(random(), r, "f", new BytesRef("j"), null, PostingsEnum.NONE);
+    PostingsEnum d2 = TestUtil.docs(random(), r, "f", new BytesRef("j"), null, PostingsEnum.NONE);
     assertEquals(0, d1.nextDoc());
     assertEquals(0, d2.nextDoc());
     r.close();
@@ -194,7 +192,7 @@ public class TestMultiFields extends LuceneTestCase {
     w.addDocument(d);
     IndexReader r = w.getReader();
     w.close();
-    PostingsEnum de = MultiFields.getTermDocsEnum(r, null, "f", new BytesRef("j"));
+    PostingsEnum de = MultiFields.getTermDocsEnum(r, "f", new BytesRef("j"));
     assertEquals(0, de.nextDoc());
     assertEquals(1, de.nextDoc());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, de.nextDoc());
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestOmitPositions.java b/lucene/core/src/test/org/apache/lucene/index/TestOmitPositions.java
index f9e57a2..551a073 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestOmitPositions.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestOmitPositions.java
@@ -51,9 +51,9 @@ public class TestOmitPositions extends LuceneTestCase {
     IndexReader reader = w.getReader();
     w.close();
     
-    assertNotNull(MultiFields.getTermPositionsEnum(reader, null, "foo", new BytesRef("test")));
+    assertNotNull(MultiFields.getTermPositionsEnum(reader, "foo", new BytesRef("test")));
     
-    PostingsEnum de = TestUtil.docs(random(), reader, "foo", new BytesRef("test"), null, null, PostingsEnum.FREQS);
+    PostingsEnum de = TestUtil.docs(random(), reader, "foo", new BytesRef("test"), null, PostingsEnum.FREQS);
     while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
       assertEquals(2, de.freq());
     }
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestParallelTermEnum.java b/lucene/core/src/test/org/apache/lucene/index/TestParallelTermEnum.java
index 400e1b2..ae4e3c9 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestParallelTermEnum.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestParallelTermEnum.java
@@ -72,7 +72,7 @@ public class TestParallelTermEnum extends LuceneTestCase {
     super.tearDown();
   }
   
-  private void checkTerms(Terms terms, Bits liveDocs, String... termsList) throws IOException {
+  private void checkTerms(Terms terms, String... termsList) throws IOException {
     assertNotNull(terms);
     final TermsEnum te = terms.iterator();
     
@@ -80,7 +80,7 @@ public class TestParallelTermEnum extends LuceneTestCase {
       BytesRef b = te.next();
       assertNotNull(b);
       assertEquals(t, b.utf8ToString());
-      PostingsEnum td = TestUtil.docs(random(), te, liveDocs, null, PostingsEnum.NONE);
+      PostingsEnum td = TestUtil.docs(random(), te, null, PostingsEnum.NONE);
       assertTrue(td.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
       assertEquals(0, td.docID());
       assertEquals(td.nextDoc(), DocIdSetIterator.NO_MORE_DOCS);
@@ -91,22 +91,20 @@ public class TestParallelTermEnum extends LuceneTestCase {
   public void test1() throws IOException {
     ParallelLeafReader pr = new ParallelLeafReader(ir1, ir2);
 
-    Bits liveDocs = pr.getLiveDocs();
-
     Fields fields = pr.fields();
     Iterator<String> fe = fields.iterator();
 
     String f = fe.next();
     assertEquals("field1", f);
-    checkTerms(fields.terms(f), liveDocs, "brown", "fox", "jumps", "quick", "the");
+    checkTerms(fields.terms(f), "brown", "fox", "jumps", "quick", "the");
 
     f = fe.next();
     assertEquals("field2", f);
-    checkTerms(fields.terms(f), liveDocs, "brown", "fox", "jumps", "quick", "the");
+    checkTerms(fields.terms(f), "brown", "fox", "jumps", "quick", "the");
 
     f = fe.next();
     assertEquals("field3", f);
-    checkTerms(fields.terms(f), liveDocs, "dog", "fox", "jumps", "lazy", "over", "the");
+    checkTerms(fields.terms(f), "dog", "fox", "jumps", "lazy", "over", "the");
 
     assertFalse(fe.hasNext());
   }
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestPayloads.java b/lucene/core/src/test/org/apache/lucene/index/TestPayloads.java
index b10680b..26f09ba 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestPayloads.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestPayloads.java
@@ -193,7 +193,6 @@ public class TestPayloads extends LuceneTestCase {
     PostingsEnum[] tps = new PostingsEnum[numTerms];
     for (int i = 0; i < numTerms; i++) {
       tps[i] = MultiFields.getTermPositionsEnum(reader,
-                                                MultiFields.getLiveDocs(reader),
                                                 terms[i].field(),
                                                 new BytesRef(terms[i].text()));
     }
@@ -222,7 +221,6 @@ public class TestPayloads extends LuceneTestCase {
      *  test lazy skipping
      */        
     PostingsEnum tp = MultiFields.getTermPositionsEnum(reader,
-                                                               MultiFields.getLiveDocs(reader),
                                                                terms[0].field(),
                                                                new BytesRef(terms[0].text()));
     tp.nextDoc();
@@ -249,7 +247,6 @@ public class TestPayloads extends LuceneTestCase {
      * Test different lengths at skip points
      */
     tp = MultiFields.getTermPositionsEnum(reader,
-                                          MultiFields.getLiveDocs(reader),
                                           terms[1].field(),
                                           new BytesRef(terms[1].text()));
     tp.nextDoc();
@@ -287,7 +284,6 @@ public class TestPayloads extends LuceneTestCase {
         
     reader = DirectoryReader.open(dir);
     tp = MultiFields.getTermPositionsEnum(reader,
-                                          MultiFields.getLiveDocs(reader),
                                           fieldName,
                                           new BytesRef(singleTerm));
     tp.nextDoc();
@@ -485,11 +481,10 @@ public class TestPayloads extends LuceneTestCase {
     writer.close();
     IndexReader reader = DirectoryReader.open(dir);
     TermsEnum terms = MultiFields.getFields(reader).terms(field).iterator();
-    Bits liveDocs = MultiFields.getLiveDocs(reader);
     PostingsEnum tp = null;
     while (terms.next() != null) {
       String termText = terms.term().utf8ToString();
-      tp = terms.postings(liveDocs, tp, PostingsEnum.PAYLOADS);
+      tp = terms.postings(tp, PostingsEnum.PAYLOADS);
       while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
         int freq = tp.freq();
         for (int i = 0; i < freq; i++) {
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestPayloadsOnVectors.java b/lucene/core/src/test/org/apache/lucene/index/TestPayloadsOnVectors.java
index c264496..5450656 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestPayloadsOnVectors.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestPayloadsOnVectors.java
@@ -72,7 +72,7 @@ public class TestPayloadsOnVectors extends LuceneTestCase {
     assert terms != null;
     TermsEnum termsEnum = terms.iterator();
     assertTrue(termsEnum.seekExact(new BytesRef("withPayload")));
-    PostingsEnum de = termsEnum.postings(null, null, PostingsEnum.ALL);
+    PostingsEnum de = termsEnum.postings(null, PostingsEnum.ALL);
     assertEquals(0, de.nextDoc());
     assertEquals(0, de.nextPosition());
     assertEquals(new BytesRef("test"), de.getPayload());
@@ -114,7 +114,7 @@ public class TestPayloadsOnVectors extends LuceneTestCase {
     assert terms != null;
     TermsEnum termsEnum = terms.iterator();
     assertTrue(termsEnum.seekExact(new BytesRef("withPayload")));
-    PostingsEnum de = termsEnum.postings(null, null, PostingsEnum.ALL);
+    PostingsEnum de = termsEnum.postings(null, PostingsEnum.ALL);
     assertEquals(0, de.nextDoc());
     assertEquals(3, de.nextPosition());
     assertEquals(new BytesRef("test"), de.getPayload());
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestPerSegmentDeletes.java b/lucene/core/src/test/org/apache/lucene/index/TestPerSegmentDeletes.java
index b40aa5f..8b84319 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestPerSegmentDeletes.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestPerSegmentDeletes.java
@@ -226,7 +226,7 @@ public class TestPerSegmentDeletes extends LuceneTestCase {
     Terms cterms = fields.terms(term.field);
     TermsEnum ctermsEnum = cterms.iterator();
     if (ctermsEnum.seekExact(new BytesRef(term.text()))) {
-      PostingsEnum postingsEnum = TestUtil.docs(random(), ctermsEnum, bits, null, PostingsEnum.NONE);
+      PostingsEnum postingsEnum = TestUtil.docs(random(), ctermsEnum, null, PostingsEnum.NONE);
       return toArray(postingsEnum);
     }
     return null;
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets.java b/lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets.java
index 404ee5d..9b995f3 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets.java
@@ -82,7 +82,7 @@ public class TestPostingsOffsets extends LuceneTestCase {
     IndexReader r = w.getReader();
     w.close();
 
-    PostingsEnum dp = MultiFields.getTermPositionsEnum(r, null, "content", new BytesRef("a"));
+    PostingsEnum dp = MultiFields.getTermPositionsEnum(r, "content", new BytesRef("a"));
     assertNotNull(dp);
     assertEquals(0, dp.nextDoc());
     assertEquals(2, dp.freq());
@@ -94,7 +94,7 @@ public class TestPostingsOffsets extends LuceneTestCase {
     assertEquals(17, dp.endOffset());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());
 
-    dp = MultiFields.getTermPositionsEnum(r, null, "content", new BytesRef("b"));
+    dp = MultiFields.getTermPositionsEnum(r, "content", new BytesRef("b"));
     assertNotNull(dp);
     assertEquals(0, dp.nextDoc());
     assertEquals(1, dp.freq());
@@ -103,7 +103,7 @@ public class TestPostingsOffsets extends LuceneTestCase {
     assertEquals(9, dp.endOffset());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());
 
-    dp = MultiFields.getTermPositionsEnum(r, null, "content", new BytesRef("c"));
+    dp = MultiFields.getTermPositionsEnum(r, "content", new BytesRef("c"));
     assertNotNull(dp);
     assertEquals(0, dp.nextDoc());
     assertEquals(1, dp.freq());
@@ -154,7 +154,7 @@ public class TestPostingsOffsets extends LuceneTestCase {
     String terms[] = { "one", "two", "three", "four", "five", "six", "seven", "eight", "nine", "ten", "hundred" };
     
     for (String term : terms) {
-      PostingsEnum dp = MultiFields.getTermPositionsEnum(reader, null, "numbers", new BytesRef(term));
+      PostingsEnum dp = MultiFields.getTermPositionsEnum(reader, "numbers", new BytesRef(term));
       int doc;
       while((doc = dp.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
         String storedNumbers = reader.document(doc).get("numbers");
@@ -182,7 +182,7 @@ public class TestPostingsOffsets extends LuceneTestCase {
     
     for (int j = 0; j < numSkippingTests; j++) {
       int num = TestUtil.nextInt(random(), 100, Math.min(numDocs - 1, 999));
-      PostingsEnum dp = MultiFields.getTermPositionsEnum(reader, null, "numbers", new BytesRef("hundred"));
+      PostingsEnum dp = MultiFields.getTermPositionsEnum(reader, "numbers", new BytesRef("hundred"));
       int doc = dp.advance(num);
       assertEquals(num, doc);
       int freq = dp.freq();
@@ -207,7 +207,7 @@ public class TestPostingsOffsets extends LuceneTestCase {
     // check that other fields (without offsets) work correctly
     
     for (int i = 0; i < numDocs; i++) {
-      PostingsEnum dp = MultiFields.getTermDocsEnum(reader, null, "id", new BytesRef("" + i), 0);
+      PostingsEnum dp = MultiFields.getTermDocsEnum(reader, "id", new BytesRef("" + i), 0);
       assertEquals(i, dp.nextDoc());
       assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());
     }
@@ -301,7 +301,7 @@ public class TestPostingsOffsets extends LuceneTestCase {
       for(String term : terms) {
         //System.out.println("  term=" + term);
         if (termsEnum.seekExact(new BytesRef(term))) {
-          docs = termsEnum.postings(null, docs);
+          docs = termsEnum.postings(docs);
           assertNotNull(docs);
           int doc;
           //System.out.println("    doc/freq");
@@ -313,7 +313,7 @@ public class TestPostingsOffsets extends LuceneTestCase {
           }
 
           // explicitly exclude offsets here
-          docsAndPositions = termsEnum.postings(null, docsAndPositions, PostingsEnum.ALL);
+          docsAndPositions = termsEnum.postings(docsAndPositions, PostingsEnum.ALL);
           assertNotNull(docsAndPositions);
           //System.out.println("    doc/freq/pos");
           while((doc = docsAndPositions.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
@@ -328,7 +328,7 @@ public class TestPostingsOffsets extends LuceneTestCase {
             }
           }
 
-          docsAndPositionsAndOffsets = termsEnum.postings(null, docsAndPositions, PostingsEnum.ALL);
+          docsAndPositionsAndOffsets = termsEnum.postings(docsAndPositions, PostingsEnum.ALL);
           assertNotNull(docsAndPositionsAndOffsets);
           //System.out.println("    doc/freq/pos/offs");
           while((doc = docsAndPositionsAndOffsets.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestSegmentMerger.java b/lucene/core/src/test/org/apache/lucene/index/TestSegmentMerger.java
index 4948ac8..472d7e6 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestSegmentMerger.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestSegmentMerger.java
@@ -110,7 +110,6 @@ public class TestSegmentMerger extends LuceneTestCase {
     PostingsEnum termDocs = TestUtil.docs(random(), mergedReader,
         DocHelper.TEXT_FIELD_2_KEY,
         new BytesRef("field"),
-        MultiFields.getLiveDocs(mergedReader),
         null,
         0);
     assertTrue(termDocs != null);
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestSegmentReader.java b/lucene/core/src/test/org/apache/lucene/index/TestSegmentReader.java
index e0f60ff..10e4acc 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestSegmentReader.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestSegmentReader.java
@@ -130,7 +130,6 @@ public class TestSegmentReader extends LuceneTestCase {
     PostingsEnum termDocs = TestUtil.docs(random(), reader,
         DocHelper.TEXT_FIELD_1_KEY,
         new BytesRef("field"),
-        MultiFields.getLiveDocs(reader),
         null,
         0);
     assertTrue(termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
@@ -138,7 +137,6 @@ public class TestSegmentReader extends LuceneTestCase {
     termDocs = TestUtil.docs(random(), reader,
         DocHelper.NO_NORMS_KEY,
         new BytesRef(DocHelper.NO_NORMS_TEXT),
-        MultiFields.getLiveDocs(reader),
         null,
         0);
 
@@ -146,7 +144,6 @@ public class TestSegmentReader extends LuceneTestCase {
 
     
     PostingsEnum positions = MultiFields.getTermPositionsEnum(reader,
-                                                                      MultiFields.getLiveDocs(reader),
                                                                       DocHelper.TEXT_FIELD_1_KEY,
                                                                       new BytesRef("field"));
     // NOTE: prior rev of this test was failing to first
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs.java b/lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs.java
index 93da657..b914c57 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs.java
@@ -58,7 +58,7 @@ public class TestSegmentTermDocs extends LuceneTestCase {
 
     TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator();
     terms.seekCeil(new BytesRef("field"));
-    PostingsEnum termDocs = TestUtil.docs(random(), terms, reader.getLiveDocs(), null, PostingsEnum.FREQS);
+    PostingsEnum termDocs = TestUtil.docs(random(), terms, null, PostingsEnum.FREQS);
     if (termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)    {
       int docId = termDocs.docID();
       assertTrue(docId == 0);
@@ -76,7 +76,6 @@ public class TestSegmentTermDocs extends LuceneTestCase {
       PostingsEnum termDocs = TestUtil.docs(random(), reader,
           "textField2",
           new BytesRef("bad"),
-          reader.getLiveDocs(),
           null,
           0);
 
@@ -90,7 +89,6 @@ public class TestSegmentTermDocs extends LuceneTestCase {
       PostingsEnum termDocs = TestUtil.docs(random(), reader,
           "junk",
           new BytesRef("bad"),
-          reader.getLiveDocs(),
           null,
           0);
       assertNull(termDocs);
@@ -124,7 +122,6 @@ public class TestSegmentTermDocs extends LuceneTestCase {
     PostingsEnum tdocs = TestUtil.docs(random(), reader,
         ta.field(),
         new BytesRef(ta.text()),
-        MultiFields.getLiveDocs(reader),
         null,
         PostingsEnum.FREQS);
     
@@ -149,7 +146,6 @@ public class TestSegmentTermDocs extends LuceneTestCase {
     tdocs = TestUtil.docs(random(), reader,
         ta.field(),
         new BytesRef(ta.text()),
-        MultiFields.getLiveDocs(reader),
         null,
         0);
     
@@ -167,7 +163,6 @@ public class TestSegmentTermDocs extends LuceneTestCase {
     tdocs = TestUtil.docs(random(), reader,
         tb.field(),
         new BytesRef(tb.text()),
-        MultiFields.getLiveDocs(reader),
         null,
         PostingsEnum.FREQS);
 
@@ -191,7 +186,6 @@ public class TestSegmentTermDocs extends LuceneTestCase {
     tdocs = TestUtil.docs(random(), reader,
         tb.field(),
         new BytesRef(tb.text()),
-        MultiFields.getLiveDocs(reader),
         null,
         PostingsEnum.FREQS);
     
@@ -211,7 +205,6 @@ public class TestSegmentTermDocs extends LuceneTestCase {
     tdocs = TestUtil.docs(random(), reader,
         tc.field(),
         new BytesRef(tc.text()),
-        MultiFields.getLiveDocs(reader),
         null,
         PostingsEnum.FREQS);
 
@@ -237,7 +230,6 @@ public class TestSegmentTermDocs extends LuceneTestCase {
     tdocs = TestUtil.docs(random(), reader,
         tc.field(),
         new BytesRef(tc.text()),
-        MultiFields.getLiveDocs(reader),
         null,
         0);
     assertTrue(tdocs.advance(5) != DocIdSetIterator.NO_MORE_DOCS);
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestStressAdvance.java b/lucene/core/src/test/org/apache/lucene/index/TestStressAdvance.java
index 5e38cfb..7a9ddd3 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestStressAdvance.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestStressAdvance.java
@@ -82,11 +82,11 @@ public class TestStressAdvance extends LuceneTestCase {
           System.out.println("\nTEST: iter=" + iter + " iter2=" + iter2);
         }
         assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef("a")));
-        de = TestUtil.docs(random(), te, null, de, PostingsEnum.NONE);
+        de = TestUtil.docs(random(), te, de, PostingsEnum.NONE);
         testOne(de, aDocIDs);
 
         assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef("b")));
-        de = TestUtil.docs(random(), te, null, de, PostingsEnum.NONE);
+        de = TestUtil.docs(random(), te, de, PostingsEnum.NONE);
         testOne(de, bDocIDs);
       }
 
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestStressIndexing2.java b/lucene/core/src/test/org/apache/lucene/index/TestStressIndexing2.java
index 923c158..a977bbf 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestStressIndexing2.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestStressIndexing2.java
@@ -32,9 +32,13 @@ import org.apache.lucene.document.FieldType;
 import org.apache.lucene.document.TextField;
 import org.apache.lucene.index.IndexWriterConfig.OpenMode;
 import org.apache.lucene.search.DocIdSetIterator;
+import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.*;
+import org.apache.lucene.util.Bits;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.TestUtil;
 
 public class TestStressIndexing2 extends LuceneTestCase {
   static int maxFields=4;
@@ -285,6 +289,13 @@ public class TestStressIndexing2 extends LuceneTestCase {
     }
   }
 
+  private static int nextNonDeletedDoc(PostingsEnum it, Bits liveDocs) throws IOException {
+    int doc = it.nextDoc();
+    while (doc != DocIdSetIterator.NO_MORE_DOCS && liveDocs != null && liveDocs.get(doc) == false) {
+      doc = it.nextDoc();
+    }
+    return doc;
+  }
 
   public void verifyEquals(DirectoryReader r1, DirectoryReader r2, String idField) throws Throwable {
     if (VERBOSE) {
@@ -326,8 +337,8 @@ public class TestStressIndexing2 extends LuceneTestCase {
       Bits liveDocs = MultiFields.getLiveDocs(r1);
       PostingsEnum docs = null;
       while(termsEnum.next() != null) {
-        docs = TestUtil.docs(random(), termsEnum, liveDocs, docs, PostingsEnum.NONE);
-        while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
+        docs = TestUtil.docs(random(), termsEnum, docs, PostingsEnum.NONE);
+        while(nextNonDeletedDoc(docs, liveDocs) != DocIdSetIterator.NO_MORE_DOCS) {
           fail("r1 is not empty but r2 is");
         }
       }
@@ -345,25 +356,25 @@ public class TestStressIndexing2 extends LuceneTestCase {
         break;
       }
 
-      termDocs1 = TestUtil.docs(random(), termsEnum, liveDocs1, termDocs1, PostingsEnum.NONE);
+      termDocs1 = TestUtil.docs(random(), termsEnum, termDocs1, PostingsEnum.NONE);
       if (termsEnum2.seekExact(term)) {
-        termDocs2 = TestUtil.docs(random(), termsEnum2, liveDocs2, termDocs2, PostingsEnum.NONE);
+        termDocs2 = TestUtil.docs(random(), termsEnum2, termDocs2, PostingsEnum.NONE);
       } else {
         termDocs2 = null;
       }
 
-      if (termDocs1.nextDoc() == DocIdSetIterator.NO_MORE_DOCS) {
+      if (nextNonDeletedDoc(termDocs1, liveDocs1) == DocIdSetIterator.NO_MORE_DOCS) {
         // This doc is deleted and wasn't replaced
-        assertTrue(termDocs2 == null || termDocs2.nextDoc() == DocIdSetIterator.NO_MORE_DOCS);
+        assertTrue(termDocs2 == null || nextNonDeletedDoc(termDocs2, liveDocs2) == DocIdSetIterator.NO_MORE_DOCS);
         continue;
       }
 
       int id1 = termDocs1.docID();
-      assertEquals(DocIdSetIterator.NO_MORE_DOCS, termDocs1.nextDoc());
+      assertEquals(DocIdSetIterator.NO_MORE_DOCS, nextNonDeletedDoc(termDocs1, liveDocs1));
 
-      assertTrue(termDocs2.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
+      assertTrue(nextNonDeletedDoc(termDocs2, liveDocs2) != DocIdSetIterator.NO_MORE_DOCS);
       int id2 = termDocs2.docID();
-      assertEquals(DocIdSetIterator.NO_MORE_DOCS, termDocs2.nextDoc());
+      assertEquals(DocIdSetIterator.NO_MORE_DOCS, nextNonDeletedDoc(termDocs2, liveDocs2));
 
       r2r1[id2] = id1;
 
@@ -395,7 +406,7 @@ public class TestStressIndexing2 extends LuceneTestCase {
             BytesRef term2;
             while((term2 = termsEnum3.next()) != null) {
               System.out.println("      " + term2.utf8ToString() + ": freq=" + termsEnum3.totalTermFreq());
-              dpEnum = termsEnum3.postings(null, dpEnum, PostingsEnum.ALL);
+              dpEnum = termsEnum3.postings(dpEnum, PostingsEnum.ALL);
               if (terms3.hasPositions()) {
                 assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
                 final int freq = dpEnum.freq();
@@ -404,7 +415,7 @@ public class TestStressIndexing2 extends LuceneTestCase {
                   System.out.println("          pos=" + dpEnum.nextPosition());
                 }
               } else {
-                dEnum = TestUtil.docs(random(), termsEnum3, null, dEnum, PostingsEnum.FREQS);
+                dEnum = TestUtil.docs(random(), termsEnum3, dEnum, PostingsEnum.FREQS);
                 assertNotNull(dEnum);
                 assertTrue(dEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
                 final int freq = dEnum.freq();
@@ -427,7 +438,7 @@ public class TestStressIndexing2 extends LuceneTestCase {
             BytesRef term2;
             while((term2 = termsEnum3.next()) != null) {
               System.out.println("      " + term2.utf8ToString() + ": freq=" + termsEnum3.totalTermFreq());
-              dpEnum = termsEnum3.postings(null, dpEnum, PostingsEnum.ALL);
+              dpEnum = termsEnum3.postings(dpEnum, PostingsEnum.ALL);
               if (dpEnum != null) {
                 assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
                 final int freq = dpEnum.freq();
@@ -436,7 +447,7 @@ public class TestStressIndexing2 extends LuceneTestCase {
                   System.out.println("          pos=" + dpEnum.nextPosition());
                 }
               } else {
-                dEnum = TestUtil.docs(random(), termsEnum3, null, dEnum, PostingsEnum.FREQS);
+                dEnum = TestUtil.docs(random(), termsEnum3, dEnum, PostingsEnum.FREQS);
                 assertNotNull(dEnum);
                 assertTrue(dEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
                 final int freq = dEnum.freq();
@@ -495,9 +506,12 @@ public class TestStressIndexing2 extends LuceneTestCase {
         }
         
         //System.out.println("TEST: term1=" + term1);
-        docs1 = TestUtil.docs(random(), termsEnum1, liveDocs1, docs1, PostingsEnum.FREQS);
+        docs1 = TestUtil.docs(random(), termsEnum1, docs1, PostingsEnum.FREQS);
         while (docs1.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
           int d = docs1.docID();
+          if (liveDocs1 != null && liveDocs1.get(d) == false) {
+            continue;
+          }
           int f = docs1.freq();
           info1[len1] = (((long)d)<<32) | f;
           len1++;
@@ -528,8 +542,11 @@ public class TestStressIndexing2 extends LuceneTestCase {
         }
         
         //System.out.println("TEST: term1=" + term1);
-        docs2 = TestUtil.docs(random(), termsEnum2, liveDocs2, docs2, PostingsEnum.FREQS);
+        docs2 = TestUtil.docs(random(), termsEnum2, docs2, PostingsEnum.FREQS);
         while (docs2.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
+          if (liveDocs2 != null && liveDocs2.get(docs2.docID()) == false) {
+            continue;
+          }
           int d = r2r1[docs2.docID()];
           int f = docs2.freq();
           info2[len2] = (((long)d)<<32) | f;
@@ -542,7 +559,7 @@ public class TestStressIndexing2 extends LuceneTestCase {
       if (len1==0) break;  // no more terms
 
       assertEquals(field1, field2);
-      assertTrue(term1.bytesEquals(term2));
+      assertEquals(term1, term2);
 
       if (!hasDeletes)
         assertEquals(termsEnum1.docFreq(), termsEnum2.docFreq());
@@ -617,8 +634,8 @@ public class TestStressIndexing2 extends LuceneTestCase {
         assertEquals(termsEnum1.totalTermFreq(),
                      termsEnum2.totalTermFreq());
         
-        dpEnum1 = termsEnum1.postings(null, dpEnum1, PostingsEnum.ALL);
-        dpEnum2 = termsEnum2.postings(null, dpEnum2, PostingsEnum.ALL);
+        dpEnum1 = termsEnum1.postings(dpEnum1, PostingsEnum.ALL);
+        dpEnum2 = termsEnum2.postings(dpEnum2, PostingsEnum.ALL);
 
         if (terms1.hasPositions()) {
           assertTrue(terms2.hasPositions());
@@ -648,8 +665,8 @@ public class TestStressIndexing2 extends LuceneTestCase {
           assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum1.nextDoc());
           assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum2.nextDoc());
         } else {
-          dEnum1 = TestUtil.docs(random(), termsEnum1, null, dEnum1, PostingsEnum.FREQS);
-          dEnum2 = TestUtil.docs(random(), termsEnum2, null, dEnum2, PostingsEnum.FREQS);
+          dEnum1 = TestUtil.docs(random(), termsEnum1, dEnum1, PostingsEnum.FREQS);
+          dEnum2 = TestUtil.docs(random(), termsEnum2, dEnum2, PostingsEnum.FREQS);
           assertNotNull(dEnum1);
           assertNotNull(dEnum2);
           int docID1 = dEnum1.nextDoc();
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java b/lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java
index ae0e5dd..3d6729a 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java
@@ -228,7 +228,7 @@ public class TestTermVectorsReader extends LuceneTestCase {
         //System.out.println("Term: " + term);
         assertEquals(testTerms[i], term);
         
-        postingsEnum = TestUtil.docs(random(), termsEnum, null, postingsEnum, PostingsEnum.NONE);
+        postingsEnum = TestUtil.docs(random(), termsEnum, postingsEnum, PostingsEnum.NONE);
         assertNotNull(postingsEnum);
         int doc = postingsEnum.docID();
         assertEquals(-1, doc);
@@ -255,7 +255,7 @@ public class TestTermVectorsReader extends LuceneTestCase {
       //System.out.println("Term: " + term);
       assertEquals(testTerms[i], term);
 
-      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);
+      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);
       assertNotNull(dpEnum);
       int doc = dpEnum.docID();
       assertEquals(-1, doc);
@@ -266,7 +266,7 @@ public class TestTermVectorsReader extends LuceneTestCase {
       }
       assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());
 
-      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);
+      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);
       doc = dpEnum.docID();
       assertEquals(-1, doc);
       assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
@@ -291,8 +291,8 @@ public class TestTermVectorsReader extends LuceneTestCase {
       String term = text.utf8ToString();
       //System.out.println("Term: " + term);
       assertEquals(testTerms[i], term);
-      assertNotNull(termsEnum.postings(null, null));
-      assertNotNull(termsEnum.postings(null, null, PostingsEnum.ALL));
+      assertNotNull(termsEnum.postings(null));
+      assertNotNull(termsEnum.postings(null, PostingsEnum.ALL));
     }
     reader.close();
   }
@@ -311,7 +311,7 @@ public class TestTermVectorsReader extends LuceneTestCase {
       String term = text.utf8ToString();
       assertEquals(testTerms[i], term);
 
-      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);
+      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);
       assertNotNull(dpEnum);
       assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
       assertEquals(dpEnum.freq(), positions[i].length);
@@ -320,7 +320,7 @@ public class TestTermVectorsReader extends LuceneTestCase {
       }
       assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());
 
-      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);
+      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);
       assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
       assertNotNull(dpEnum);
       assertEquals(dpEnum.freq(), positions[i].length);
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestTermVectorsWriter.java b/lucene/core/src/test/org/apache/lucene/index/TestTermVectorsWriter.java
index 9bd3a1f..2bb743c 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestTermVectorsWriter.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestTermVectorsWriter.java
@@ -68,7 +68,7 @@ public class TestTermVectorsWriter extends LuceneTestCase {
     // Token "" occurred once
     assertEquals(1, termsEnum.totalTermFreq());
 
-    PostingsEnum dpEnum = termsEnum.postings(null, null, PostingsEnum.ALL);
+    PostingsEnum dpEnum = termsEnum.postings(null, PostingsEnum.ALL);
     assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
     dpEnum.nextPosition();
     assertEquals(8, dpEnum.startOffset());
@@ -77,7 +77,7 @@ public class TestTermVectorsWriter extends LuceneTestCase {
 
     // Token "abcd" occurred three times
     assertEquals(new BytesRef("abcd"), termsEnum.next());
-    dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);
+    dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);
     assertEquals(3, termsEnum.totalTermFreq());
 
     assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
@@ -117,7 +117,7 @@ public class TestTermVectorsWriter extends LuceneTestCase {
     IndexReader r = DirectoryReader.open(dir);
     TermsEnum termsEnum = r.getTermVectors(0).terms("field").iterator();
     assertNotNull(termsEnum.next());
-    PostingsEnum dpEnum = termsEnum.postings(null, null, PostingsEnum.ALL);
+    PostingsEnum dpEnum = termsEnum.postings(null, PostingsEnum.ALL);
     assertEquals(2, termsEnum.totalTermFreq());
 
     assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
@@ -152,7 +152,7 @@ public class TestTermVectorsWriter extends LuceneTestCase {
     IndexReader r = DirectoryReader.open(dir);
     TermsEnum termsEnum = r.getTermVectors(0).terms("field").iterator();
     assertNotNull(termsEnum.next());
-    PostingsEnum dpEnum = termsEnum.postings(null, null, PostingsEnum.ALL);
+    PostingsEnum dpEnum = termsEnum.postings(null, PostingsEnum.ALL);
     assertEquals(2, termsEnum.totalTermFreq());
 
     assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
@@ -190,7 +190,7 @@ public class TestTermVectorsWriter extends LuceneTestCase {
     IndexReader r = DirectoryReader.open(dir);
     TermsEnum termsEnum = r.getTermVectors(0).terms("field").iterator();
     assertNotNull(termsEnum.next());
-    PostingsEnum dpEnum = termsEnum.postings(null, null, PostingsEnum.ALL);
+    PostingsEnum dpEnum = termsEnum.postings(null, PostingsEnum.ALL);
     assertEquals(2, termsEnum.totalTermFreq());
 
     assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
@@ -225,7 +225,7 @@ public class TestTermVectorsWriter extends LuceneTestCase {
     IndexReader r = DirectoryReader.open(dir);
     TermsEnum termsEnum = r.getTermVectors(0).terms("field").iterator();
     assertNotNull(termsEnum.next());
-    PostingsEnum dpEnum = termsEnum.postings(null, null, PostingsEnum.ALL);
+    PostingsEnum dpEnum = termsEnum.postings(null, PostingsEnum.ALL);
     assertEquals(2, termsEnum.totalTermFreq());
 
     assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
@@ -261,7 +261,7 @@ public class TestTermVectorsWriter extends LuceneTestCase {
     IndexReader r = DirectoryReader.open(dir);
     TermsEnum termsEnum = r.getTermVectors(0).terms("field").iterator();
     assertNotNull(termsEnum.next());
-    PostingsEnum dpEnum = termsEnum.postings(null, null, PostingsEnum.ALL);
+    PostingsEnum dpEnum = termsEnum.postings(null, PostingsEnum.ALL);
 
     assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
     dpEnum.nextPosition();
@@ -269,14 +269,14 @@ public class TestTermVectorsWriter extends LuceneTestCase {
     assertEquals(4, dpEnum.endOffset());
 
     assertNotNull(termsEnum.next());
-    dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);
+    dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);
     assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
     dpEnum.nextPosition();
     assertEquals(11, dpEnum.startOffset());
     assertEquals(17, dpEnum.endOffset());
 
     assertNotNull(termsEnum.next());
-    dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);
+    dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);
     assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
     dpEnum.nextPosition();
     assertEquals(18, dpEnum.startOffset());
@@ -305,7 +305,7 @@ public class TestTermVectorsWriter extends LuceneTestCase {
     IndexReader r = DirectoryReader.open(dir);
     TermsEnum termsEnum = r.getTermVectors(0).terms("field").iterator();
     assertNotNull(termsEnum.next());
-    PostingsEnum dpEnum = termsEnum.postings(null, null, PostingsEnum.ALL);
+    PostingsEnum dpEnum = termsEnum.postings(null, PostingsEnum.ALL);
 
     assertEquals(1, (int) termsEnum.totalTermFreq());
     assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
@@ -314,7 +314,7 @@ public class TestTermVectorsWriter extends LuceneTestCase {
     assertEquals(7, dpEnum.endOffset());
 
     assertNotNull(termsEnum.next());
-    dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);
+    dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);
     assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
     dpEnum.nextPosition();
     assertEquals(8, dpEnum.startOffset());
@@ -347,7 +347,7 @@ public class TestTermVectorsWriter extends LuceneTestCase {
     IndexReader r = DirectoryReader.open(dir);
     TermsEnum termsEnum = r.getTermVectors(0).terms("field").iterator();
     assertNotNull(termsEnum.next());
-    PostingsEnum dpEnum = termsEnum.postings(null, null, PostingsEnum.ALL);
+    PostingsEnum dpEnum = termsEnum.postings(null, PostingsEnum.ALL);
 
     assertEquals(1, (int) termsEnum.totalTermFreq());
     assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
@@ -356,7 +356,7 @@ public class TestTermVectorsWriter extends LuceneTestCase {
     assertEquals(4, dpEnum.endOffset());
 
     assertNotNull(termsEnum.next());
-    dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);
+    dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);
     assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
     dpEnum.nextPosition();
     assertEquals(6, dpEnum.startOffset());
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestTermdocPerf.java b/lucene/core/src/test/org/apache/lucene/index/TestTermdocPerf.java
index e4c965f..8295d6d 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestTermdocPerf.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestTermdocPerf.java
@@ -123,7 +123,7 @@ public class TestTermdocPerf extends LuceneTestCase {
     final Random random = new Random(random().nextLong());
     for (int i=0; i<iter; i++) {
       tenum.seekCeil(new BytesRef("val"));
-      tdocs = TestUtil.docs(random, tenum, MultiFields.getLiveDocs(reader), tdocs, PostingsEnum.NONE);
+      tdocs = TestUtil.docs(random, tenum, tdocs, PostingsEnum.NONE);
       while (tdocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
         ret += tdocs.docID();
       }
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestTermsEnum.java b/lucene/core/src/test/org/apache/lucene/index/TestTermsEnum.java
index c928ef9..fc2a3af 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestTermsEnum.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestTermsEnum.java
@@ -326,7 +326,7 @@ public class TestTermsEnum extends LuceneTestCase {
           }
           assertEquals(expected, actual);
           assertEquals(1, te.docFreq());
-          postingsEnum = TestUtil.docs(random(), te, null, postingsEnum, PostingsEnum.NONE);
+          postingsEnum = TestUtil.docs(random(), te, postingsEnum, PostingsEnum.NONE);
           final int docID = postingsEnum.nextDoc();
           assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);
           assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());
@@ -740,25 +740,25 @@ public class TestTermsEnum extends LuceneTestCase {
     CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    
     TermsEnum te = terms.intersect(ca, null);
     assertEquals("aaa", te.next().utf8ToString());
-    assertEquals(0, te.postings(null, null, PostingsEnum.NONE).nextDoc());
+    assertEquals(0, te.postings(null, PostingsEnum.NONE).nextDoc());
     assertEquals("bbb", te.next().utf8ToString());
-    assertEquals(1, te.postings(null, null, PostingsEnum.NONE).nextDoc());
+    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());
     assertEquals("ccc", te.next().utf8ToString());
-    assertEquals(2, te.postings(null, null, PostingsEnum.NONE).nextDoc());
+    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());
     assertNull(te.next());
 
     te = terms.intersect(ca, new BytesRef("abc"));
     assertEquals("bbb", te.next().utf8ToString());
-    assertEquals(1, te.postings(null, null, PostingsEnum.NONE).nextDoc());
+    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());
     assertEquals("ccc", te.next().utf8ToString());
-    assertEquals(2, te.postings(null, null, PostingsEnum.NONE).nextDoc());
+    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());
     assertNull(te.next());
 
     te = terms.intersect(ca, new BytesRef("aaa"));
     assertEquals("bbb", te.next().utf8ToString());
-    assertEquals(1, te.postings(null, null, PostingsEnum.NONE).nextDoc());
+    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());
     assertEquals("ccc", te.next().utf8ToString());
-    assertEquals(2, te.postings(null, null, PostingsEnum.NONE).nextDoc());
+    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());
     assertNull(te.next());
 
     r.close();
@@ -798,17 +798,17 @@ public class TestTermsEnum extends LuceneTestCase {
     // should seek to startTerm
     te = terms.intersect(ca, new BytesRef("aad"));
     assertEquals("abd", te.next().utf8ToString());
-    assertEquals(1, te.postings(null, null, PostingsEnum.NONE).nextDoc());
+    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());
     assertEquals("acd", te.next().utf8ToString());
-    assertEquals(2, te.postings(null, null, PostingsEnum.NONE).nextDoc());
+    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());
     assertEquals("bcd", te.next().utf8ToString());
-    assertEquals(3, te.postings(null, null, PostingsEnum.NONE).nextDoc());
+    assertEquals(3, te.postings(null, PostingsEnum.NONE).nextDoc());
     assertNull(te.next());
 
     // should fail to find ceil label on second arc, rewind 
     te = terms.intersect(ca, new BytesRef("add"));
     assertEquals("bcd", te.next().utf8ToString());
-    assertEquals(3, te.postings(null, null, PostingsEnum.NONE).nextDoc());
+    assertEquals(3, te.postings(null, PostingsEnum.NONE).nextDoc());
     assertNull(te.next());
 
     // should reach end
@@ -852,12 +852,12 @@ public class TestTermsEnum extends LuceneTestCase {
     PostingsEnum de;
 
     assertEquals("", te.next().utf8ToString());
-    de = te.postings(null, null, PostingsEnum.NONE);
+    de = te.postings(null, PostingsEnum.NONE);
     assertEquals(0, de.nextDoc());
     assertEquals(1, de.nextDoc());
 
     assertEquals("abc", te.next().utf8ToString());
-    de = te.postings(null, null, PostingsEnum.NONE);
+    de = te.postings(null, PostingsEnum.NONE);
     assertEquals(0, de.nextDoc());
     assertEquals(1, de.nextDoc());
 
@@ -867,7 +867,7 @@ public class TestTermsEnum extends LuceneTestCase {
     te = terms.intersect(ca, new BytesRef(""));
 
     assertEquals("abc", te.next().utf8ToString());
-    de = te.postings(null, null, PostingsEnum.NONE);
+    de = te.postings(null, PostingsEnum.NONE);
     assertEquals(0, de.nextDoc());
     assertEquals(1, de.nextDoc());
 
@@ -929,7 +929,7 @@ public class TestTermsEnum extends LuceneTestCase {
       boolean actualResult = termsEnum.seekExact(termBytesRef);
       assertEquals(shouldExist, actualResult);
       if (shouldExist) {
-        postingsEnum = termsEnum.postings(null, postingsEnum, 0);
+        postingsEnum = termsEnum.postings(postingsEnum, 0);
         int docID = postingsEnum.nextDoc();
         assertTrue(docID != PostingsEnum.NO_MORE_DOCS);
         assertEquals(docID, pkLookup.lookup(termBytesRef));
diff --git a/lucene/core/src/test/org/apache/lucene/search/JustCompileSearch.java b/lucene/core/src/test/org/apache/lucene/search/JustCompileSearch.java
index 2cc18a9..6387d25 100644
--- a/lucene/core/src/test/org/apache/lucene/search/JustCompileSearch.java
+++ b/lucene/core/src/test/org/apache/lucene/search/JustCompileSearch.java
@@ -298,7 +298,7 @@ final class JustCompileSearch {
     }
 
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) {
+    public Scorer scorer(LeafReaderContext context) {
       throw new UnsupportedOperationException(UNSUPPORTED_MSG);
     }
 
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestBooleanCoord.java b/lucene/core/src/test/org/apache/lucene/search/TestBooleanCoord.java
index 3f844b3..dcb1bc7 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestBooleanCoord.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestBooleanCoord.java
@@ -822,14 +822,14 @@ public class TestBooleanCoord extends LuceneTestCase {
   private void assertScore(final float expected, Query query) throws Exception {
     // test in-order
     Weight weight = searcher.createNormalizedWeight(query, true);
-    Scorer scorer = weight.scorer(reader.leaves().get(0), null);
+    Scorer scorer = weight.scorer(reader.leaves().get(0));
     assertTrue(scorer.docID() == -1 || scorer.docID() == DocIdSetIterator.NO_MORE_DOCS);
     assertEquals(0, scorer.nextDoc());
     assertEquals(expected, scorer.score(), 0.0001f);
 
     // test bulk scorer
     final AtomicBoolean seen = new AtomicBoolean(false);
-    BulkScorer bulkScorer = weight.bulkScorer(reader.leaves().get(0), null);
+    BulkScorer bulkScorer = weight.bulkScorer(reader.leaves().get(0));
     assertNotNull(bulkScorer);
     bulkScorer.score(new LeafCollector() {
       Scorer scorer;
@@ -846,7 +846,7 @@ public class TestBooleanCoord extends LuceneTestCase {
         assertEquals(expected, scorer.score(), 0.0001f);
         seen.set(true);
       }
-    }, 0, 1);
+    }, null, 0, 1);
     assertTrue(seen.get());
 
     // test the explanation
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestBooleanOr.java b/lucene/core/src/test/org/apache/lucene/search/TestBooleanOr.java
index a870bd4..d40dfe1 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestBooleanOr.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestBooleanOr.java
@@ -22,8 +22,6 @@ import java.util.Collections;
 import java.util.List;
 import java.util.concurrent.atomic.AtomicInteger;
 
-import com.carrotsearch.randomizedtesting.generators.RandomInts;
-
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.TextField;
@@ -31,10 +29,13 @@ import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.TestUtil;
 
+import com.carrotsearch.randomizedtesting.generators.RandomInts;
+
 public class TestBooleanOr extends LuceneTestCase {
 
   private static String FIELD_T = "T";
@@ -188,7 +189,7 @@ public class TestBooleanOr extends LuceneTestCase {
     Weight w = s.createNormalizedWeight(bq.build(), true);
 
     assertEquals(1, s.getIndexReader().leaves().size());
-    BulkScorer scorer = w.bulkScorer(s.getIndexReader().leaves().get(0), null);
+    BulkScorer scorer = w.bulkScorer(s.getIndexReader().leaves().get(0));
 
     final FixedBitSet hits = new FixedBitSet(docCount);
     final AtomicInteger end = new AtomicInteger();
@@ -210,7 +211,7 @@ public class TestBooleanOr extends LuceneTestCase {
       final int min = end.intValue();
       final int inc = TestUtil.nextInt(random(), 1, 1000);
       final int max = end.addAndGet(inc);
-      scorer.score(c, min, max);
+      scorer.score(c, null, min, max);
     }
 
     assertEquals(docCount, hits.cardinality());
@@ -223,14 +224,16 @@ public class TestBooleanOr extends LuceneTestCase {
       final FakeScorer scorer = new FakeScorer();
       int i = 0;
       @Override
-      public int score(LeafCollector collector, int min, int max) throws IOException {
+      public int score(LeafCollector collector, Bits acceptDocs, int min, int max) throws IOException {
         collector.setScorer(scorer);
         while (i < matches.length && matches[i] < min) {
           i += 1;
         }
         while (i < matches.length && matches[i] < max) {
           scorer.doc = matches[i];
-          collector.collect(scorer.doc);
+          if (acceptDocs == null || acceptDocs.get(scorer.doc)) {
+            collector.collect(scorer.doc);
+          }
           i += 1;
         }
         if (i == matches.length) {
@@ -266,7 +269,7 @@ public class TestBooleanOr extends LuceneTestCase {
         matches.add(doc);
       }
       
-    });
+    }, null);
     assertEquals(Arrays.asList(4000, 5000, 100000, 1000001, 1000051, 9999998, 9999999), matches);
   }
 }
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestBooleanQuery.java b/lucene/core/src/test/org/apache/lucene/search/TestBooleanQuery.java
index b4f7cde..43c0f48 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestBooleanQuery.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestBooleanQuery.java
@@ -242,7 +242,7 @@ public class TestBooleanQuery extends LuceneTestCase {
 
       Weight weight = s.createNormalizedWeight(q.build(), true);
 
-      Scorer scorer = weight.scorer(s.leafContexts.get(0), null);
+      Scorer scorer = weight.scorer(s.leafContexts.get(0));
 
       // First pass: just use .nextDoc() to gather all hits
       final List<ScoreDoc> hits = new ArrayList<>();
@@ -259,7 +259,7 @@ public class TestBooleanQuery extends LuceneTestCase {
       for(int iter2=0;iter2<10;iter2++) {
 
         weight = s.createNormalizedWeight(q.build(), true);
-        scorer = weight.scorer(s.leafContexts.get(0), null);
+        scorer = weight.scorer(s.leafContexts.get(0));
 
         if (VERBOSE) {
           System.out.println("  iter2=" + iter2);
@@ -595,7 +595,7 @@ public class TestBooleanQuery extends LuceneTestCase {
     query2.add(new TermQuery(new Term("field", "a")), Occur.FILTER);
     query2.add(new TermQuery(new Term("field", "b")), Occur.SHOULD);
     final Weight weight = searcher.createNormalizedWeight(query2.build(), true);
-    final Scorer scorer = weight.scorer(reader.leaves().get(0), null);
+    final Scorer scorer = weight.scorer(reader.leaves().get(0));
     assertEquals(0, scorer.nextDoc());
     assertTrue(scorer.getClass().getName(), scorer instanceof FilterScorer);
     assertEquals(0f, scorer.score(), 0f);
@@ -627,7 +627,7 @@ public class TestBooleanQuery extends LuceneTestCase {
     q.add(new TermQuery(new Term("field", "c")), Occur.FILTER);
 
     final Weight weight = searcher.createNormalizedWeight(q.build(), random().nextBoolean());
-    final Scorer scorer = weight.scorer(searcher.getIndexReader().leaves().get(0), null);
+    final Scorer scorer = weight.scorer(searcher.getIndexReader().leaves().get(0));
     assertTrue(scorer instanceof ConjunctionScorer);
     assertNotNull(scorer.asTwoPhaseIterator());
 
@@ -656,7 +656,7 @@ public class TestBooleanQuery extends LuceneTestCase {
     q.add(new TermQuery(new Term("field", "c")), Occur.SHOULD);
 
     final Weight weight = searcher.createNormalizedWeight(q.build(), random().nextBoolean());
-    final Scorer scorer = weight.scorer(reader.leaves().get(0), null);
+    final Scorer scorer = weight.scorer(reader.leaves().get(0));
     assertTrue(scorer instanceof DisjunctionScorer);
     assertNotNull(scorer.asTwoPhaseIterator());
 
@@ -687,7 +687,7 @@ public class TestBooleanQuery extends LuceneTestCase {
     q.add(new TermQuery(new Term("field", "d")), Occur.SHOULD);
 
     final Weight weight = searcher.createNormalizedWeight(q.build(), random().nextBoolean());
-    final Scorer scorer = weight.scorer(searcher.getIndexReader().leaves().get(0), null);
+    final Scorer scorer = weight.scorer(searcher.getIndexReader().leaves().get(0));
     assertTrue(scorer instanceof BoostedScorer || scorer instanceof ExactPhraseScorer);
     assertNotNull(scorer.asTwoPhaseIterator());
 
@@ -716,7 +716,7 @@ public class TestBooleanQuery extends LuceneTestCase {
     q.add(new TermQuery(new Term("field", "c")), Occur.MUST_NOT);
 
     final Weight weight = searcher.createNormalizedWeight(q.build(), random().nextBoolean());
-    final Scorer scorer = weight.scorer(reader.leaves().get(0), null);
+    final Scorer scorer = weight.scorer(reader.leaves().get(0));
     assertTrue(scorer instanceof ReqExclScorer);
     assertNotNull(scorer.asTwoPhaseIterator());
 
@@ -745,7 +745,7 @@ public class TestBooleanQuery extends LuceneTestCase {
     q.add(new TermQuery(new Term("field", "c")), Occur.SHOULD);
 
     final Weight weight = searcher.createNormalizedWeight(q.build(), true);
-    final Scorer scorer = weight.scorer(reader.leaves().get(0), null);
+    final Scorer scorer = weight.scorer(reader.leaves().get(0));
     assertTrue(scorer instanceof ReqOptSumScorer);
     assertNotNull(scorer.asTwoPhaseIterator());
 
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestBooleanScorer.java b/lucene/core/src/test/org/apache/lucene/search/TestBooleanScorer.java
index 5c3211f..72da86a 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestBooleanScorer.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestBooleanScorer.java
@@ -93,15 +93,15 @@ public class TestBooleanScorer extends LuceneTestCase {
         }
 
         @Override
-        public Scorer scorer(LeafReaderContext context, Bits acceptDocs) {
+        public Scorer scorer(LeafReaderContext context) {
           throw new UnsupportedOperationException();
         }
 
         @Override
-        public BulkScorer bulkScorer(LeafReaderContext context, Bits acceptDocs) {
+        public BulkScorer bulkScorer(LeafReaderContext context) {
           return new BulkScorer() {
             @Override
-            public int score(LeafCollector collector, int min, int max) throws IOException {
+            public int score(LeafCollector collector, Bits acceptDocs, int min, int max) throws IOException {
               assert min == 0;
               collector.setScorer(new FakeScorer());
               collector.collect(0);
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperQuery.java b/lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperQuery.java
index 0d48a1b..9015e37 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperQuery.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperQuery.java
@@ -139,15 +139,15 @@ public class TestCachingWrapperQuery extends LuceneTestCase {
     CachingWrapperQuery cacher = new CachingWrapperQuery(filter, QueryCachingPolicy.ALWAYS_CACHE);
 
     // first time, nested filter is called
-    cacher.createWeight(searcher, false).scorer(context, context.reader().getLiveDocs());
+    cacher.createWeight(searcher, false).scorer(context);
     assertTrue("first time", filter.wasCalled());
 
     // make sure no exception if cache is holding the wrong docIdSet
-    cacher.createWeight(searcher, false).scorer(context, context.reader().getLiveDocs());
+    cacher.createWeight(searcher, false).scorer(context);
 
     // second time, nested filter should not be called
     filter.clear();
-    cacher.createWeight(searcher, false).scorer(context, context.reader().getLiveDocs());
+    cacher.createWeight(searcher, false).scorer(context);
     assertFalse("second time", filter.wasCalled());
 
     reader.close();
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestConstantScoreQuery.java b/lucene/core/src/test/org/apache/lucene/search/TestConstantScoreQuery.java
index 7ceec72..b7a1a72 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestConstantScoreQuery.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestConstantScoreQuery.java
@@ -245,7 +245,7 @@ public class TestConstantScoreQuery extends LuceneTestCase {
     ConstantScoreQuery q = new ConstantScoreQuery(pq);
 
     final Weight weight = searcher.createNormalizedWeight(q, true);
-    final Scorer scorer = weight.scorer(searcher.getIndexReader().leaves().get(0), null);
+    final Scorer scorer = weight.scorer(searcher.getIndexReader().leaves().get(0));
     assertNotNull(scorer.asTwoPhaseIterator());
 
     reader.close();
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestDisjunctionMaxQuery.java b/lucene/core/src/test/org/apache/lucene/search/TestDisjunctionMaxQuery.java
index 05f24dd..8ee551a 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestDisjunctionMaxQuery.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestDisjunctionMaxQuery.java
@@ -180,7 +180,7 @@ public class TestDisjunctionMaxQuery extends LuceneTestCase {
     assertTrue(s.getTopReaderContext() instanceof LeafReaderContext);
     final Weight dw = s.createNormalizedWeight(dq, true);
     LeafReaderContext context = (LeafReaderContext)s.getTopReaderContext();
-    final Scorer ds = dw.scorer(context, context.reader().getLiveDocs());
+    final Scorer ds = dw.scorer(context);
     final boolean skipOk = ds.advance(3) != DocIdSetIterator.NO_MORE_DOCS;
     if (skipOk) {
       fail("firsttime skipTo found a match? ... "
@@ -196,7 +196,7 @@ public class TestDisjunctionMaxQuery extends LuceneTestCase {
     QueryUtils.check(random(), dq, s);
     final Weight dw = s.createNormalizedWeight(dq, true);
     LeafReaderContext context = (LeafReaderContext)s.getTopReaderContext();
-    final Scorer ds = dw.scorer(context, context.reader().getLiveDocs());
+    final Scorer ds = dw.scorer(context);
     assertTrue("firsttime skipTo found no match",
         ds.advance(3) != DocIdSetIterator.NO_MORE_DOCS);
     assertEquals("found wrong docid", "d4", r.document(ds.docID()).get("id"));
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache.java b/lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache.java
index dae1f93..4e6e8e3 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache.java
@@ -349,7 +349,7 @@ public class TestLRUQueryCache extends LuceneTestCase {
     public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
       return new ConstantScoreWeight(this) {
         @Override
-        public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+        public Scorer scorer(LeafReaderContext context) throws IOException {
           return null;
         }
       };
@@ -934,7 +934,7 @@ public class TestLRUQueryCache extends LuceneTestCase {
     public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
       return new ConstantScoreWeight(this) {
         @Override
-        public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+        public Scorer scorer(LeafReaderContext context) throws IOException {
           return null;
         }
       };
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestMinShouldMatch2.java b/lucene/core/src/test/org/apache/lucene/search/TestMinShouldMatch2.java
index e21a573..4c3690a 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestMinShouldMatch2.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestMinShouldMatch2.java
@@ -130,11 +130,11 @@ public class TestMinShouldMatch2 extends LuceneTestCase {
     case DOC_VALUES:
       return new SlowMinShouldMatchScorer(weight, reader, searcher);
     case SCORER:
-      return weight.scorer(reader.getContext(), null);
+      return weight.scorer(reader.getContext());
     case BULK_SCORER:
-      final BulkScorer bulkScorer = weight.booleanScorer(reader.getContext(), null);
+      final BulkScorer bulkScorer = weight.booleanScorer(reader.getContext());
       if (bulkScorer == null) {
-        if (weight.scorer(reader.getContext(), null) != null) {
+        if (weight.scorer(reader.getContext()) != null) {
           throw new AssertionError("BooleanScorer should be applicable for this query");
         }
         return null;
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestNeedsScores.java b/lucene/core/src/test/org/apache/lucene/search/TestNeedsScores.java
index d5670f7..3549fed 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestNeedsScores.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestNeedsScores.java
@@ -132,9 +132,9 @@ public class TestNeedsScores extends LuceneTestCase {
         }
 
         @Override
-        public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+        public Scorer scorer(LeafReaderContext context) throws IOException {
           assertEquals("query=" + in, value, needsScores);
-          return w.scorer(context, acceptDocs);
+          return w.scorer(context);
         }
       };
     }
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestPositionIncrement.java b/lucene/core/src/test/org/apache/lucene/search/TestPositionIncrement.java
index a12fe09..8d05769 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestPositionIncrement.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestPositionIncrement.java
@@ -105,7 +105,6 @@ public class TestPositionIncrement extends LuceneTestCase {
     IndexSearcher searcher = newSearcher(reader);
     
     PostingsEnum pos = MultiFields.getTermPositionsEnum(searcher.getIndexReader(),
-                                                                MultiFields.getLiveDocs(searcher.getIndexReader()),
                                                                 "field",
                                                                 new BytesRef("1"));
     pos.nextDoc();
@@ -113,7 +112,6 @@ public class TestPositionIncrement extends LuceneTestCase {
     assertEquals(0, pos.nextPosition());
     
     pos = MultiFields.getTermPositionsEnum(searcher.getIndexReader(),
-                                           MultiFields.getLiveDocs(searcher.getIndexReader()),
                                            "field",
                                            new BytesRef("2"));
     pos.nextDoc();
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestQueryRescorer.java b/lucene/core/src/test/org/apache/lucene/search/TestQueryRescorer.java
index 1d5e7b2..de8186d 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestQueryRescorer.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestQueryRescorer.java
@@ -431,7 +431,7 @@ public class TestQueryRescorer extends LuceneTestCase {
         }
 
         @Override
-        public Scorer scorer(final LeafReaderContext context, Bits acceptDocs) throws IOException {
+        public Scorer scorer(final LeafReaderContext context) throws IOException {
 
           return new Scorer(null) {
             int docID = -1;
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestQueryWrapperFilter.java b/lucene/core/src/test/org/apache/lucene/search/TestQueryWrapperFilter.java
index cf9f997..ef6d214 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestQueryWrapperFilter.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestQueryWrapperFilter.java
@@ -217,7 +217,7 @@ public class TestQueryWrapperFilter extends LuceneTestCase {
     searcher.setQueryCache(null); // to still have approximations
     final Query query = new QueryWrapperFilter(new RandomApproximationQuery(new TermQuery(new Term("foo", "bar")), random()));
     final Weight weight = searcher.createNormalizedWeight(query, random().nextBoolean());
-    final Scorer scorer = weight.scorer(reader.leaves().get(0), null);
+    final Scorer scorer = weight.scorer(reader.leaves().get(0));
     assertNotNull(scorer.asTwoPhaseIterator());
     reader.close();
     dir.close();
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestTermScorer.java b/lucene/core/src/test/org/apache/lucene/search/TestTermScorer.java
index 0b61e58..aa5731c 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestTermScorer.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestTermScorer.java
@@ -80,7 +80,7 @@ public class TestTermScorer extends LuceneTestCase {
     Weight weight = indexSearcher.createNormalizedWeight(termQuery, true);
     assertTrue(indexSearcher.getTopReaderContext() instanceof LeafReaderContext);
     LeafReaderContext context = (LeafReaderContext)indexSearcher.getTopReaderContext();
-    BulkScorer ts = weight.bulkScorer(context, context.reader().getLiveDocs());
+    BulkScorer ts = weight.bulkScorer(context);
     // we have 2 documents with the term all in them, one document for all the
     // other values
     final List<TestHit> docs = new ArrayList<>();
@@ -114,7 +114,7 @@ public class TestTermScorer extends LuceneTestCase {
       public boolean needsScores() {
         return true;
       }
-    });
+    }, null);
     assertTrue("docs Size: " + docs.size() + " is not: " + 2, docs.size() == 2);
     TestHit doc0 = docs.get(0);
     TestHit doc5 = docs.get(1);
@@ -142,7 +142,7 @@ public class TestTermScorer extends LuceneTestCase {
     Weight weight = indexSearcher.createNormalizedWeight(termQuery, true);
     assertTrue(indexSearcher.getTopReaderContext() instanceof LeafReaderContext);
     LeafReaderContext context = (LeafReaderContext) indexSearcher.getTopReaderContext();
-    Scorer ts = weight.scorer(context, context.reader().getLiveDocs());
+    Scorer ts = weight.scorer(context);
     assertTrue("next did not return a doc",
         ts.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
     assertTrue("score is not correct", ts.score() == 1.6931472f);
@@ -161,7 +161,7 @@ public class TestTermScorer extends LuceneTestCase {
     Weight weight = indexSearcher.createNormalizedWeight(termQuery, true);
     assertTrue(indexSearcher.getTopReaderContext() instanceof LeafReaderContext);
     LeafReaderContext context = (LeafReaderContext) indexSearcher.getTopReaderContext();
-    Scorer ts = weight.scorer(context, context.reader().getLiveDocs());
+    Scorer ts = weight.scorer(context);
     assertTrue("Didn't skip", ts.advance(3) != DocIdSetIterator.NO_MORE_DOCS);
     // The next doc should be doc 5
     assertTrue("doc should be number 5", ts.docID() == 5);
@@ -199,7 +199,7 @@ public class TestTermScorer extends LuceneTestCase {
     
     Weight weight = indexSearcher.createNormalizedWeight(termQuery, true);
     try {
-      weight.scorer(forbiddenNorms.getContext(), null).nextDoc();
+      weight.scorer(forbiddenNorms.getContext()).nextDoc();
       fail("Should load norms");
     } catch (AssertionError e) {
       // ok
@@ -207,6 +207,6 @@ public class TestTermScorer extends LuceneTestCase {
     
     weight = indexSearcher.createNormalizedWeight(termQuery, false);
     // should not fail this time since norms are not necessary
-    weight.scorer(forbiddenNorms.getContext(), null).nextDoc();
+    weight.scorer(forbiddenNorms.getContext()).nextDoc();
   }
 }
diff --git a/lucene/core/src/test/org/apache/lucene/search/spans/MultiSpansWrapper.java b/lucene/core/src/test/org/apache/lucene/search/spans/MultiSpansWrapper.java
index d11dd35..2197ea1 100644
--- a/lucene/core/src/test/org/apache/lucene/search/spans/MultiSpansWrapper.java
+++ b/lucene/core/src/test/org/apache/lucene/search/spans/MultiSpansWrapper.java
@@ -22,7 +22,6 @@ import org.apache.lucene.index.LeafReader;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.SlowCompositeReaderWrapper;
 import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.util.Bits;
 
 import java.io.IOException;
 
@@ -48,6 +47,6 @@ public class MultiSpansWrapper {
 
     SpanWeight w = spanQuery.createWeight(searcher, false);
 
-    return w.getSpans(lrContext, new Bits.MatchAllBits(lr.numDocs()), requiredPostings);
+    return w.getSpans(lrContext, requiredPostings);
   }
 }
diff --git a/lucene/core/src/test/org/apache/lucene/search/spans/TestNearSpansOrdered.java b/lucene/core/src/test/org/apache/lucene/search/spans/TestNearSpansOrdered.java
index 1001172..2ff4e95 100644
--- a/lucene/core/src/test/org/apache/lucene/search/spans/TestNearSpansOrdered.java
+++ b/lucene/core/src/test/org/apache/lucene/search/spans/TestNearSpansOrdered.java
@@ -191,7 +191,7 @@ public class TestNearSpansOrdered extends LuceneTestCase {
     Weight w = searcher.createNormalizedWeight(q, true);
     IndexReaderContext topReaderContext = searcher.getTopReaderContext();
     LeafReaderContext leave = topReaderContext.leaves().get(0);
-    Scorer s = w.scorer(leave, leave.reader().getLiveDocs());
+    Scorer s = w.scorer(leave);
     assertEquals(1, s.advance(1));
   }
 
diff --git a/lucene/core/src/test/org/apache/lucene/search/spans/TestSpans.java b/lucene/core/src/test/org/apache/lucene/search/spans/TestSpans.java
index e84bc03..9529a45 100644
--- a/lucene/core/src/test/org/apache/lucene/search/spans/TestSpans.java
+++ b/lucene/core/src/test/org/apache/lucene/search/spans/TestSpans.java
@@ -298,7 +298,7 @@ public class TestSpans extends LuceneTestCase {
       try {
         searcher.setSimilarity(sim);
         SpanQuery snq = spanNearOrderedQuery(field, 1, "t1", "t2");
-        spanScorer = searcher.createNormalizedWeight(snq, true).scorer(ctx, ctx.reader().getLiveDocs());
+        spanScorer = searcher.createNormalizedWeight(snq, true).scorer(ctx);
       } finally {
         searcher.setSimilarity(oldSim);
       }
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/DrillSidewaysQuery.java b/lucene/facet/src/java/org/apache/lucene/facet/DrillSidewaysQuery.java
index f33b34f..0aa8428 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/DrillSidewaysQuery.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/DrillSidewaysQuery.java
@@ -113,17 +113,17 @@ class DrillSidewaysQuery extends Query {
       }
 
       @Override
-      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+      public Scorer scorer(LeafReaderContext context) throws IOException {
         // We can only run as a top scorer:
         throw new UnsupportedOperationException();
       }
 
       @Override
-      public BulkScorer bulkScorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {
 
         // TODO: it could be better if we take acceptDocs
         // into account instead of baseScorer?
-        Scorer baseScorer = baseWeight.scorer(context, acceptDocs);
+        Scorer baseScorer = baseWeight.scorer(context);
 
         DrillSidewaysScorer.DocsAndCost[] dims = new DrillSidewaysScorer.DocsAndCost[drillDowns.length];
         int nullCount = 0;
@@ -168,7 +168,7 @@ class DrillSidewaysQuery extends Query {
               dims[dim].disi = disi;
             }
           } else {
-            DocIdSetIterator disi = ((Weight) drillDowns[dim]).scorer(context, null);
+            DocIdSetIterator disi = ((Weight) drillDowns[dim]).scorer(context);
             if (disi == null) {
               nullCount++;
               continue;
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/DrillSidewaysScorer.java b/lucene/facet/src/java/org/apache/lucene/facet/DrillSidewaysScorer.java
index ad2938a..c043175 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/DrillSidewaysScorer.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/DrillSidewaysScorer.java
@@ -26,6 +26,7 @@ import org.apache.lucene.index.PostingsEnum;
 import org.apache.lucene.search.BulkScorer;
 import org.apache.lucene.search.Collector;
 import org.apache.lucene.search.DocIdSetIterator;
+import org.apache.lucene.search.FilterLeafCollector;
 import org.apache.lucene.search.LeafCollector;
 import org.apache.lucene.search.Scorer;
 import org.apache.lucene.search.Weight;
@@ -69,13 +70,26 @@ class DrillSidewaysScorer extends BulkScorer {
   }
 
   @Override
-  public int score(LeafCollector collector, int min, int maxDoc) throws IOException {
+  public int score(LeafCollector originalCollector, Bits acceptDocs, int min, int maxDoc) throws IOException {
     if (min != 0) {
       throw new IllegalArgumentException("min must be 0, got " + min);
     }
     if (maxDoc != Integer.MAX_VALUE) {
       throw new IllegalArgumentException("maxDoc must be Integer.MAX_VALUE");
     }
+    final LeafCollector collector;
+    if (acceptDocs == null) {
+      collector = originalCollector;
+    } else {
+      collector = new FilterLeafCollector(originalCollector) {
+        @Override
+        public void collect(int doc) throws IOException {
+          if (acceptDocs.get(doc)) {
+            super.collect(doc);
+          }
+        }
+      };
+    }
     //if (DEBUG) {
     //  System.out.println("\nscore: reader=" + context.reader());
     //}
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyReader.java b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyReader.java
index 35d2210..be1bb2d 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyReader.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyReader.java
@@ -273,7 +273,7 @@ public class DirectoryTaxonomyReader extends TaxonomyReader {
     // If we're still here, we have a cache miss. We need to fetch the
     // value from disk, and then also put it in the cache:
     int ret = TaxonomyReader.INVALID_ORDINAL;
-    PostingsEnum docs = MultiFields.getTermDocsEnum(indexReader, null, Consts.FULL, new BytesRef(FacetsConfig.pathToString(cp.components, cp.length)), 0);
+    PostingsEnum docs = MultiFields.getTermDocsEnum(indexReader, Consts.FULL, new BytesRef(FacetsConfig.pathToString(cp.components, cp.length)), 0);
     if (docs != null && docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
       ret = docs.docID();
       
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyWriter.java b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyWriter.java
index 77b2389..e241007 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyWriter.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyWriter.java
@@ -389,7 +389,7 @@ public class DirectoryTaxonomyWriter implements TaxonomyWriter {
           TermsEnum termsEnum = terms.iterator();
           if (termsEnum.seekExact(catTerm)) {
             // liveDocs=null because the taxonomy has no deletes
-            docs = termsEnum.postings(null, docs, 0 /* freqs not required */);
+            docs = termsEnum.postings(docs, 0 /* freqs not required */);
             // if the term was found, we know it has exactly one document.
             doc = docs.nextDoc() + ctx.docBase;
             break;
@@ -689,7 +689,7 @@ public class DirectoryTaxonomyWriter implements TaxonomyWriter {
               // is sufficient to call next(), and then doc(), exactly once with no
               // 'validation' checks.
               FacetLabel cp = new FacetLabel(FacetsConfig.stringToPath(t.utf8ToString()));
-              postingsEnum = termsEnum.postings(null, postingsEnum, PostingsEnum.NONE);
+              postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);
               boolean res = cache.put(cp, postingsEnum.nextDoc() + ctx.docBase);
               assert !res : "entries should not have been evicted from the cache";
             } else {
@@ -779,7 +779,7 @@ public class DirectoryTaxonomyWriter implements TaxonomyWriter {
         while (te.next() != null) {
           FacetLabel cp = new FacetLabel(FacetsConfig.stringToPath(te.term().utf8ToString()));
           final int ordinal = addCategory(cp);
-          docs = te.postings(null, docs, PostingsEnum.NONE);
+          docs = te.postings(docs, PostingsEnum.NONE);
           ordinalMap.addMapping(docs.nextDoc() + base, ordinal);
         }
         base += ar.maxDoc(); // no deletions, so we're ok
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/TaxonomyIndexArrays.java b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/TaxonomyIndexArrays.java
index 4215f4c..c798185 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/TaxonomyIndexArrays.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/TaxonomyIndexArrays.java
@@ -129,7 +129,7 @@ class TaxonomyIndexArrays extends ParallelTaxonomyArrays {
     // it's ok to use MultiFields because we only iterate on one posting list.
     // breaking it to loop over the leaves() only complicates code for no
     // apparent gain.
-    PostingsEnum positions = MultiFields.getTermPositionsEnum(reader, null,
+    PostingsEnum positions = MultiFields.getTermPositionsEnum(reader,
         Consts.FIELD_PAYLOADS, Consts.PAYLOAD_PARENT_BYTES_REF,
         PostingsEnum.PAYLOADS);
 
diff --git a/lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermVector.java b/lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermVector.java
index 49f6dd8..c932922 100644
--- a/lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermVector.java
+++ b/lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermVector.java
@@ -148,7 +148,7 @@ public final class TokenStreamFromTermVector extends TokenStream {
       final int termCharsOff = termCharsBuilder.length();
       termCharsBuilder.append(tempCharsRefBuilder.chars(), 0, termCharsLen);
 
-      dpEnum = termsEnum.postings(null, dpEnum, dpEnumFlags);
+      dpEnum = termsEnum.postings(dpEnum, dpEnumFlags);
       assert dpEnum != null; // presumably checked by TokenSources.hasPositions earlier
       dpEnum.nextDoc();
       final int freq = dpEnum.freq();
diff --git a/lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor.java b/lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor.java
index e51f992..766f389 100644
--- a/lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor.java
+++ b/lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor.java
@@ -299,13 +299,16 @@ public class WeightedSpanTermExtractor {
       LeafReaderContext context = getLeafContext();
       SpanWeight w = (SpanWeight) searcher.createNormalizedWeight(q, false);
       Bits acceptDocs = context.reader().getLiveDocs();
-      final Spans spans = w.getSpans(context, acceptDocs, SpanWeight.Postings.POSITIONS);
+      final Spans spans = w.getSpans(context, SpanWeight.Postings.POSITIONS);
       if (spans == null) {
         return;
       }
 
       // collect span positions
       while (spans.nextDoc() != Spans.NO_MORE_DOCS) {
+        if (acceptDocs != null && acceptDocs.get(spans.docID()) == false) {
+          continue;
+        }
         while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {
           spanPositions.add(new PositionSpan(spans.startPosition(), spans.endPosition() - 1));
         }
diff --git a/lucene/highlighter/src/java/org/apache/lucene/search/postingshighlight/PostingsHighlighter.java b/lucene/highlighter/src/java/org/apache/lucene/search/postingshighlight/PostingsHighlighter.java
index f6fb93c..7a98e80 100644
--- a/lucene/highlighter/src/java/org/apache/lucene/search/postingshighlight/PostingsHighlighter.java
+++ b/lucene/highlighter/src/java/org/apache/lucene/search/postingshighlight/PostingsHighlighter.java
@@ -566,7 +566,7 @@ public class PostingsHighlighter {
         if (!termsEnum.seekExact(terms[i])) {
           continue; // term not found
         }
-        de = postings[i] = termsEnum.postings(null, null, PostingsEnum.OFFSETS);
+        de = postings[i] = termsEnum.postings(null, PostingsEnum.OFFSETS);
         assert de != null;
         pDoc = de.advance(doc);
       } else {
diff --git a/lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack.java b/lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack.java
index a754b93..b7cabf6 100644
--- a/lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack.java
+++ b/lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack.java
@@ -104,7 +104,7 @@ public class FieldTermStack {
       if (!termSet.contains(term)) {
         continue;
       }
-      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.POSITIONS);
+      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.POSITIONS);
       dpEnum.nextDoc();
       
       // For weight look here: http://lucene.apache.org/core/3_6_0/api/core/org/apache/lucene/search/DefaultSimilarity.html
diff --git a/lucene/join/src/java/org/apache/lucene/search/join/GlobalOrdinalsQuery.java b/lucene/join/src/java/org/apache/lucene/search/join/GlobalOrdinalsQuery.java
index 19b908f..696b70e 100644
--- a/lucene/join/src/java/org/apache/lucene/search/join/GlobalOrdinalsQuery.java
+++ b/lucene/join/src/java/org/apache/lucene/search/join/GlobalOrdinalsQuery.java
@@ -139,13 +139,13 @@ final class GlobalOrdinalsQuery extends Query {
     }
 
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+    public Scorer scorer(LeafReaderContext context) throws IOException {
       SortedDocValues values = DocValues.getSorted(context.reader(), joinField);
       if (values == null) {
         return null;
       }
 
-      Scorer approximationScorer = approximationWeight.scorer(context, acceptDocs);
+      Scorer approximationScorer = approximationWeight.scorer(context);
       if (approximationScorer == null) {
         return null;
       }
diff --git a/lucene/join/src/java/org/apache/lucene/search/join/GlobalOrdinalsWithScoreQuery.java b/lucene/join/src/java/org/apache/lucene/search/join/GlobalOrdinalsWithScoreQuery.java
index c1bcb64..b0186d8 100644
--- a/lucene/join/src/java/org/apache/lucene/search/join/GlobalOrdinalsWithScoreQuery.java
+++ b/lucene/join/src/java/org/apache/lucene/search/join/GlobalOrdinalsWithScoreQuery.java
@@ -155,13 +155,13 @@ final class GlobalOrdinalsWithScoreQuery extends Query {
     }
 
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+    public Scorer scorer(LeafReaderContext context) throws IOException {
       SortedDocValues values = DocValues.getSorted(context.reader(), joinField);
       if (values == null) {
         return null;
       }
 
-      Scorer approximationScorer = approximationWeight.scorer(context, acceptDocs);
+      Scorer approximationScorer = approximationWeight.scorer(context);
       if (approximationScorer == null) {
         return null;
       } else if (globalOrds != null) {
diff --git a/lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery.java b/lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery.java
index d44b9ed..0b38e06 100644
--- a/lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery.java
+++ b/lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery.java
@@ -133,7 +133,7 @@ class TermsIncludingScoreQuery extends Query {
           PostingsEnum postingsEnum = null;
           for (int i = 0; i < TermsIncludingScoreQuery.this.terms.size(); i++) {
             if (segmentTermsEnum.seekExact(TermsIncludingScoreQuery.this.terms.get(ords[i], spare))) {
-              postingsEnum = segmentTermsEnum.postings(null, postingsEnum, PostingsEnum.NONE);
+              postingsEnum = segmentTermsEnum.postings(postingsEnum, PostingsEnum.NONE);
               if (postingsEnum.advance(doc) == doc) {
                 final float score = TermsIncludingScoreQuery.this.scores[ords[i]];
                 return Explanation.match(score, "Score based on join value " + segmentTermsEnum.term().utf8ToString());
@@ -155,7 +155,7 @@ class TermsIncludingScoreQuery extends Query {
       }
 
       @Override
-      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+      public Scorer scorer(LeafReaderContext context) throws IOException {
         Terms terms = context.reader().terms(field);
         if (terms == null) {
           return null;
@@ -166,9 +166,9 @@ class TermsIncludingScoreQuery extends Query {
 
         TermsEnum segmentTermsEnum = terms.iterator();
         if (multipleValuesPerDocument) {
-          return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);
+          return new MVInOrderScorer(this, segmentTermsEnum, context.reader().maxDoc(), cost);
         } else {
-          return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);
+          return new SVInOrderScorer(this, segmentTermsEnum, context.reader().maxDoc(), cost);
         }
       }
 
@@ -183,21 +183,21 @@ class TermsIncludingScoreQuery extends Query {
 
     int currentDoc = -1;
 
-    SVInOrderScorer(Weight weight, Bits acceptDocs, TermsEnum termsEnum, int maxDoc, long cost) throws IOException {
+    SVInOrderScorer(Weight weight, TermsEnum termsEnum, int maxDoc, long cost) throws IOException {
       super(weight);
       FixedBitSet matchingDocs = new FixedBitSet(maxDoc);
       this.scores = new float[maxDoc];
-      fillDocsAndScores(matchingDocs, acceptDocs, termsEnum);
+      fillDocsAndScores(matchingDocs, termsEnum);
       this.matchingDocsIterator = new BitSetIterator(matchingDocs, cost);
       this.cost = cost;
     }
 
-    protected void fillDocsAndScores(FixedBitSet matchingDocs, Bits acceptDocs, TermsEnum termsEnum) throws IOException {
+    protected void fillDocsAndScores(FixedBitSet matchingDocs, TermsEnum termsEnum) throws IOException {
       BytesRef spare = new BytesRef();
       PostingsEnum postingsEnum = null;
       for (int i = 0; i < terms.size(); i++) {
         if (termsEnum.seekExact(terms.get(ords[i], spare))) {
-          postingsEnum = termsEnum.postings(acceptDocs, postingsEnum, PostingsEnum.NONE);
+          postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);
           float score = TermsIncludingScoreQuery.this.scores[ords[i]];
           for (int doc = postingsEnum.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = postingsEnum.nextDoc()) {
             matchingDocs.set(doc);
@@ -243,17 +243,17 @@ class TermsIncludingScoreQuery extends Query {
   // This scorer deals with the fact that a document can have more than one score from multiple related documents.
   class MVInOrderScorer extends SVInOrderScorer {
 
-    MVInOrderScorer(Weight weight, Bits acceptDocs, TermsEnum termsEnum, int maxDoc, long cost) throws IOException {
-      super(weight, acceptDocs, termsEnum, maxDoc, cost);
+    MVInOrderScorer(Weight weight, TermsEnum termsEnum, int maxDoc, long cost) throws IOException {
+      super(weight, termsEnum, maxDoc, cost);
     }
 
     @Override
-    protected void fillDocsAndScores(FixedBitSet matchingDocs, Bits acceptDocs, TermsEnum termsEnum) throws IOException {
+    protected void fillDocsAndScores(FixedBitSet matchingDocs, TermsEnum termsEnum) throws IOException {
       BytesRef spare = new BytesRef();
       PostingsEnum postingsEnum = null;
       for (int i = 0; i < terms.size(); i++) {
         if (termsEnum.seekExact(terms.get(ords[i], spare))) {
-          postingsEnum = termsEnum.postings(acceptDocs, postingsEnum, PostingsEnum.NONE);
+          postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);
           float score = TermsIncludingScoreQuery.this.scores[ords[i]];
           for (int doc = postingsEnum.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = postingsEnum.nextDoc()) {
             // I prefer this:
diff --git a/lucene/join/src/java/org/apache/lucene/search/join/ToChildBlockJoinQuery.java b/lucene/join/src/java/org/apache/lucene/search/join/ToChildBlockJoinQuery.java
index 6ca8f16..ad09358 100644
--- a/lucene/join/src/java/org/apache/lucene/search/join/ToChildBlockJoinQuery.java
+++ b/lucene/join/src/java/org/apache/lucene/search/join/ToChildBlockJoinQuery.java
@@ -33,7 +33,6 @@ import org.apache.lucene.search.Scorer;
 import org.apache.lucene.search.Weight;
 import org.apache.lucene.util.BitDocIdSet;
 import org.apache.lucene.util.BitSet;
-import org.apache.lucene.util.Bits;
 
 /**
  * Just like {@link ToParentBlockJoinQuery}, except this
@@ -122,9 +121,9 @@ public class ToChildBlockJoinQuery extends Query {
     // NOTE: acceptDocs applies (and is checked) only in the
     // child document space
     @Override
-    public Scorer scorer(LeafReaderContext readerContext, Bits acceptDocs) throws IOException {
+    public Scorer scorer(LeafReaderContext readerContext) throws IOException {
 
-      final Scorer parentScorer = parentWeight.scorer(readerContext, null);
+      final Scorer parentScorer = parentWeight.scorer(readerContext);
 
       if (parentScorer == null) {
         // No matches
@@ -139,12 +138,12 @@ public class ToChildBlockJoinQuery extends Query {
         return null;
       }
 
-      return new ToChildBlockJoinScorer(this, parentScorer, parents.bits(), doScores, acceptDocs);
+      return new ToChildBlockJoinScorer(this, parentScorer, parents.bits(), doScores);
     }
 
     @Override
     public Explanation explain(LeafReaderContext context, int doc) throws IOException {
-      ToChildBlockJoinScorer scorer = (ToChildBlockJoinScorer) scorer(context, context.reader().getLiveDocs());
+      ToChildBlockJoinScorer scorer = (ToChildBlockJoinScorer) scorer(context);
       if (scorer != null && scorer.advance(doc) == doc) {
         int parentDoc = scorer.getParentDoc();
         return Explanation.match(
@@ -161,7 +160,6 @@ public class ToChildBlockJoinQuery extends Query {
     private final Scorer parentScorer;
     private final BitSet parentBits;
     private final boolean doScores;
-    private final Bits acceptDocs;
 
     private float parentScore;
     private int parentFreq = 1;
@@ -169,12 +167,11 @@ public class ToChildBlockJoinQuery extends Query {
     private int childDoc = -1;
     private int parentDoc = 0;
 
-    public ToChildBlockJoinScorer(Weight weight, Scorer parentScorer, BitSet parentBits, boolean doScores, Bits acceptDocs) {
+    public ToChildBlockJoinScorer(Weight weight, Scorer parentScorer, BitSet parentBits, boolean doScores) {
       super(weight);
       this.doScores = doScores;
       this.parentBits = parentBits;
       this.parentScorer = parentScorer;
-      this.acceptDocs = acceptDocs;
     }
 
     @Override
@@ -186,8 +183,6 @@ public class ToChildBlockJoinQuery extends Query {
     public int nextDoc() throws IOException {
       //System.out.println("Q.nextDoc() parentDoc=" + parentDoc + " childDoc=" + childDoc);
 
-      // Loop until we hit a childDoc that's accepted
-      nextChildDoc:
       while (true) {
         if (childDoc+1 == parentDoc) {
           // OK, we are done iterating through all children
@@ -224,20 +219,6 @@ public class ToChildBlockJoinQuery extends Query {
               continue;
             }
 
-            if (acceptDocs != null && !acceptDocs.get(childDoc)) {
-              // find the first child that is accepted
-              while (true) {
-                if (childDoc+1 < parentDoc) {
-                  childDoc++;
-                  if (acceptDocs.get(childDoc))
-                    break;
-                } else {
-                  // no child for this parent doc matches acceptDocs
-                  continue nextChildDoc;
-                }
-              }
-            }
-
             if (childDoc < parentDoc) {
               if (doScores) {
                 parentScore = parentScorer.score();
@@ -252,9 +233,6 @@ public class ToChildBlockJoinQuery extends Query {
         } else {
           assert childDoc < parentDoc: "childDoc=" + childDoc + " parentDoc=" + parentDoc;
           childDoc++;
-          if (acceptDocs != null && !acceptDocs.get(childDoc)) {
-            continue;
-          }
           //System.out.println("  " + childDoc);
           return childDoc;
         }
@@ -323,9 +301,6 @@ public class ToChildBlockJoinQuery extends Query {
       assert !parentBits.get(childTarget);
       childDoc = childTarget;
       //System.out.println("  " + childDoc);
-      if (acceptDocs != null && !acceptDocs.get(childDoc)) {
-        nextDoc();
-      }
       return childDoc;
     }
 
diff --git a/lucene/join/src/java/org/apache/lucene/search/join/ToParentBlockJoinIndexSearcher.java b/lucene/join/src/java/org/apache/lucene/search/join/ToParentBlockJoinIndexSearcher.java
index 3f785e9..9ffaf1a 100644
--- a/lucene/join/src/java/org/apache/lucene/search/join/ToParentBlockJoinIndexSearcher.java
+++ b/lucene/join/src/java/org/apache/lucene/search/join/ToParentBlockJoinIndexSearcher.java
@@ -21,7 +21,6 @@ import java.io.IOException;
 import java.util.List;
 import java.util.concurrent.ExecutorService;
 
-import org.apache.lucene.index.PostingsEnum;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.search.Collector;
@@ -30,6 +29,7 @@ import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.LeafCollector;
 import org.apache.lucene.search.Scorer;
 import org.apache.lucene.search.Weight;
+import org.apache.lucene.util.Bits;
 
 /**
  * An {@link IndexSearcher} to use in conjunction with
@@ -56,12 +56,15 @@ public class ToParentBlockJoinIndexSearcher extends IndexSearcher {
       // we force the use of Scorer (not BulkScorer) to make sure
       // that the scorer passed to LeafCollector.setScorer supports
       // Scorer.getChildren
-      Scorer scorer = weight.scorer(ctx, ctx.reader().getLiveDocs());
+      Scorer scorer = weight.scorer(ctx);
       if (scorer != null) {
         final LeafCollector leafCollector = collector.getLeafCollector(ctx);
         leafCollector.setScorer(scorer);
+        final Bits liveDocs = ctx.reader().getLiveDocs();
         for (int doc = scorer.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = scorer.nextDoc()) {
-          leafCollector.collect(doc);
+          if (liveDocs == null || liveDocs.get(doc)) {
+            leafCollector.collect(doc);
+          }
         }
       }
     }
diff --git a/lucene/join/src/java/org/apache/lucene/search/join/ToParentBlockJoinQuery.java b/lucene/join/src/java/org/apache/lucene/search/join/ToParentBlockJoinQuery.java
index c58870a..c221750 100644
--- a/lucene/join/src/java/org/apache/lucene/search/join/ToParentBlockJoinQuery.java
+++ b/lucene/join/src/java/org/apache/lucene/search/join/ToParentBlockJoinQuery.java
@@ -157,9 +157,9 @@ public class ToParentBlockJoinQuery extends Query {
     // NOTE: acceptDocs applies (and is checked) only in the
     // parent document space
     @Override
-    public Scorer scorer(LeafReaderContext readerContext, Bits acceptDocs) throws IOException {
+    public Scorer scorer(LeafReaderContext readerContext) throws IOException {
 
-      final Scorer childScorer = childWeight.scorer(readerContext, readerContext.reader().getLiveDocs());
+      final Scorer childScorer = childWeight.scorer(readerContext);
       if (childScorer == null) {
         // No matches
         return null;
@@ -180,12 +180,12 @@ public class ToParentBlockJoinQuery extends Query {
         return null;
       }
 
-      return new BlockJoinScorer(this, childScorer, parents.bits(), firstChildDoc, scoreMode, acceptDocs);
+      return new BlockJoinScorer(this, childScorer, parents.bits(), firstChildDoc, scoreMode);
     }
 
     @Override
     public Explanation explain(LeafReaderContext context, int doc) throws IOException {
-      BlockJoinScorer scorer = (BlockJoinScorer) scorer(context, context.reader().getLiveDocs());
+      BlockJoinScorer scorer = (BlockJoinScorer) scorer(context);
       if (scorer != null && scorer.advance(doc) == doc) {
         return scorer.explain(context.docBase);
       }
@@ -197,7 +197,6 @@ public class ToParentBlockJoinQuery extends Query {
     private final Scorer childScorer;
     private final BitSet parentBits;
     private final ScoreMode scoreMode;
-    private final Bits acceptDocs;
     private int parentDoc = -1;
     private int prevParentDoc;
     private float parentScore;
@@ -207,13 +206,12 @@ public class ToParentBlockJoinQuery extends Query {
     private float[] pendingChildScores;
     private int childDocUpto;
 
-    public BlockJoinScorer(Weight weight, Scorer childScorer, BitSet parentBits, int firstChildDoc, ScoreMode scoreMode, Bits acceptDocs) {
+    public BlockJoinScorer(Weight weight, Scorer childScorer, BitSet parentBits, int firstChildDoc, ScoreMode scoreMode) {
       super(weight);
       //System.out.println("Q.init firstChildDoc=" + firstChildDoc);
       this.parentBits = parentBits;
       this.childScorer = childScorer;
       this.scoreMode = scoreMode;
-      this.acceptDocs = acceptDocs;
       nextChildDoc = firstChildDoc;
     }
 
@@ -256,104 +254,84 @@ public class ToParentBlockJoinQuery extends Query {
     @Override
     public int nextDoc() throws IOException {
       //System.out.println("Q.nextDoc() nextChildDoc=" + nextChildDoc);
-      // Loop until we hit a parentDoc that's accepted
-      while (true) {
-        if (nextChildDoc == NO_MORE_DOCS) {
-          //System.out.println("  end");
-          return parentDoc = NO_MORE_DOCS;
-        }
-
-        // Gather all children sharing the same parent as
-        // nextChildDoc
+      if (nextChildDoc == NO_MORE_DOCS) {
+        //System.out.println("  end");
+        return parentDoc = NO_MORE_DOCS;
+      }
 
-        parentDoc = parentBits.nextSetBit(nextChildDoc);
+      // Gather all children sharing the same parent as
+      // nextChildDoc
 
-        // Parent & child docs are supposed to be
-        // orthogonal:
-        if (nextChildDoc == parentDoc) {
-          throw new IllegalStateException("child query must only match non-parent docs, but parent docID=" + nextChildDoc + " matched childScorer=" + childScorer.getClass());
-        }
+      parentDoc = parentBits.nextSetBit(nextChildDoc);
 
-        //System.out.println("  parentDoc=" + parentDoc);
-        assert parentDoc != DocIdSetIterator.NO_MORE_DOCS;
-
-        //System.out.println("  nextChildDoc=" + nextChildDoc);
-        if (acceptDocs != null && !acceptDocs.get(parentDoc)) {
-          // Parent doc not accepted; skip child docs until
-          // we hit a new parent doc:
-          do {
-            nextChildDoc = childScorer.nextDoc();
-          } while (nextChildDoc < parentDoc);
-
-          // Parent & child docs are supposed to be
-          // orthogonal:
-          if (nextChildDoc == parentDoc) {
-            throw new IllegalStateException("child query must only match non-parent docs, but parent docID=" + nextChildDoc + " matched childScorer=" + childScorer.getClass());
-          }
+      // Parent & child docs are supposed to be
+      // orthogonal:
+      if (nextChildDoc == parentDoc) {
+        throw new IllegalStateException("child query must only match non-parent docs, but parent docID=" + nextChildDoc + " matched childScorer=" + childScorer.getClass());
+      }
 
-          continue;
-        }
+      //System.out.println("  parentDoc=" + parentDoc);
+      assert parentDoc != DocIdSetIterator.NO_MORE_DOCS;
 
-        float totalScore = 0;
-        float maxScore = Float.NEGATIVE_INFINITY;
-        float minScore = Float.POSITIVE_INFINITY;
+      float totalScore = 0;
+      float maxScore = Float.NEGATIVE_INFINITY;
+      float minScore = Float.POSITIVE_INFINITY;
 
-        childDocUpto = 0;
-        parentFreq = 0;
-        do {
+      childDocUpto = 0;
+      parentFreq = 0;
+      do {
 
-          //System.out.println("  c=" + nextChildDoc);
-          if (pendingChildDocs != null && pendingChildDocs.length == childDocUpto) {
-            pendingChildDocs = ArrayUtil.grow(pendingChildDocs);
-          }
-          if (pendingChildScores != null && scoreMode != ScoreMode.None && pendingChildScores.length == childDocUpto) {
-            pendingChildScores = ArrayUtil.grow(pendingChildScores);
-          }
-          if (pendingChildDocs != null) {
-            pendingChildDocs[childDocUpto] = nextChildDoc;
-          }
-          if (scoreMode != ScoreMode.None) {
-            // TODO: specialize this into dedicated classes per-scoreMode
-            final float childScore = childScorer.score();
-            final int childFreq = childScorer.freq();
-            if (pendingChildScores != null) {
-              pendingChildScores[childDocUpto] = childScore;
-            }
-            maxScore = Math.max(childScore, maxScore);
-            minScore = Math.min(childFreq, minScore);
-            totalScore += childScore;
-            parentFreq += childFreq;
+        //System.out.println("  c=" + nextChildDoc);
+        if (pendingChildDocs != null && pendingChildDocs.length == childDocUpto) {
+          pendingChildDocs = ArrayUtil.grow(pendingChildDocs);
+        }
+        if (pendingChildScores != null && scoreMode != ScoreMode.None && pendingChildScores.length == childDocUpto) {
+          pendingChildScores = ArrayUtil.grow(pendingChildScores);
+        }
+        if (pendingChildDocs != null) {
+          pendingChildDocs[childDocUpto] = nextChildDoc;
+        }
+        if (scoreMode != ScoreMode.None) {
+          // TODO: specialize this into dedicated classes per-scoreMode
+          final float childScore = childScorer.score();
+          final int childFreq = childScorer.freq();
+          if (pendingChildScores != null) {
+            pendingChildScores[childDocUpto] = childScore;
           }
-          childDocUpto++;
-          nextChildDoc = childScorer.nextDoc();
-        } while (nextChildDoc < parentDoc);
-
-        // Parent & child docs are supposed to be
-        // orthogonal:
-        if (nextChildDoc == parentDoc) {
-          throw new IllegalStateException("child query must only match non-parent docs, but parent docID=" + nextChildDoc + " matched childScorer=" + childScorer.getClass());
+          maxScore = Math.max(childScore, maxScore);
+          minScore = Math.min(childFreq, minScore);
+          totalScore += childScore;
+          parentFreq += childFreq;
         }
+        childDocUpto++;
+        nextChildDoc = childScorer.nextDoc();
+      } while (nextChildDoc < parentDoc);
 
-        switch(scoreMode) {
-        case Avg:
-          parentScore = totalScore / childDocUpto;
-          break;
-        case Max:
-          parentScore = maxScore;
-          break;
-        case Min:
-          parentScore = minScore;
-          break;
-        case Total:
-          parentScore = totalScore;
-          break;
-        case None:
-          break;
-        }
+      // Parent & child docs are supposed to be
+      // orthogonal:
+      if (nextChildDoc == parentDoc) {
+        throw new IllegalStateException("child query must only match non-parent docs, but parent docID=" + nextChildDoc + " matched childScorer=" + childScorer.getClass());
+      }
 
-        //System.out.println("  return parentDoc=" + parentDoc + " childDocUpto=" + childDocUpto);
-        return parentDoc;
+      switch(scoreMode) {
+      case Avg:
+        parentScore = totalScore / childDocUpto;
+        break;
+      case Max:
+        parentScore = maxScore;
+        break;
+      case Min:
+        parentScore = minScore;
+        break;
+      case Total:
+        parentScore = totalScore;
+        break;
+      case None:
+        break;
       }
+
+      //System.out.println("  return parentDoc=" + parentDoc + " childDocUpto=" + childDocUpto);
+      return parentDoc;
     }
 
     @Override
diff --git a/lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoin.java b/lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoin.java
index 8a7e532..6f7b8a0 100644
--- a/lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoin.java
+++ b/lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoin.java
@@ -55,6 +55,7 @@ import org.apache.lucene.search.FieldDoc;
 import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.MatchAllDocsQuery;
+import org.apache.lucene.search.MatchNoDocsQuery;
 import org.apache.lucene.search.MultiTermQuery;
 import org.apache.lucene.search.NumericRangeQuery;
 import org.apache.lucene.search.PrefixQuery;
@@ -444,7 +445,7 @@ public class TestBlockJoin extends LuceneTestCase {
     w.close();
     IndexSearcher s = newSearcher(r);
     
-    ToParentBlockJoinQuery q = new ToParentBlockJoinQuery(new MatchAllDocsQuery(), new BitDocIdSetCachingWrapperFilter(new QueryWrapperFilter(new MatchAllDocsQuery())), ScoreMode.Avg);
+    ToParentBlockJoinQuery q = new ToParentBlockJoinQuery(new MatchNoDocsQuery(), new BitDocIdSetCachingWrapperFilter(new QueryWrapperFilter(new MatchAllDocsQuery())), ScoreMode.Avg);
     QueryUtils.check(random(), q, s);
     s.search(q, 10);
     BooleanQuery.Builder bqB = new BooleanQuery.Builder();
@@ -456,61 +457,6 @@ public class TestBlockJoin extends LuceneTestCase {
     dir.close();
   }
 
-  public void testNestedDocScoringWithDeletes() throws Exception {
-    final Directory dir = newDirectory();
-    final RandomIndexWriter w = new RandomIndexWriter(
-        random(),
-        dir,
-        newIndexWriterConfig(new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.INSTANCE));
-
-    // Cannot assert this since we use NoMergePolicy:
-    w.setDoRandomForceMergeAssert(false);
-
-    List<Document> docs = new ArrayList<>();
-    docs.add(makeJob("java", 2007));
-    docs.add(makeJob("python", 2010));
-    docs.add(makeResume("Lisa", "United Kingdom"));
-    w.addDocuments(docs);
-
-    docs.clear();
-    docs.add(makeJob("c", 1999));
-    docs.add(makeJob("ruby", 2005));
-    docs.add(makeJob("java", 2006));
-    docs.add(makeResume("Frank", "United States"));
-    w.addDocuments(docs);
-
-    w.commit();
-    IndexSearcher s = newSearcher(DirectoryReader.open(dir));
-
-    ToParentBlockJoinQuery q = new ToParentBlockJoinQuery(
-        NumericRangeQuery.newIntRange("year", 1990, 2010, true, true),
-        new BitDocIdSetCachingWrapperFilter(new QueryWrapperFilter(new TermQuery(new Term("docType", "resume")))),
-        ScoreMode.Total
-    );
-
-    TopDocs topDocs = s.search(q, 10);
-    assertEquals(2, topDocs.totalHits);
-    assertEquals(6, topDocs.scoreDocs[0].doc);
-    assertEquals(3.0f, topDocs.scoreDocs[0].score, 0.0f);
-    assertEquals(2, topDocs.scoreDocs[1].doc);
-    assertEquals(2.0f, topDocs.scoreDocs[1].score, 0.0f);
-
-    s.getIndexReader().close();
-    w.deleteDocuments(new Term("skill", "java"));
-    w.close();
-    s = newSearcher(DirectoryReader.open(dir));
-
-    topDocs = s.search(q, 10);
-    assertEquals(2, topDocs.totalHits);
-    assertEquals(6, topDocs.scoreDocs[0].doc);
-    assertEquals(2.0f, topDocs.scoreDocs[0].score, 0.0f);
-    assertEquals(2, topDocs.scoreDocs[1].doc);
-    assertEquals(1.0f, topDocs.scoreDocs[1].score, 0.0f);
-
-    s.getIndexReader().close();
-    dir.close();
-  }
-
   private String[][] getRandomFields(int maxUniqueValues) {
 
     final String[][] fields = new String[TestUtil.nextInt(random(), 2, 4)][];
@@ -699,7 +645,7 @@ public class TestBlockJoin extends LuceneTestCase {
       for(int docIDX=0;docIDX<joinR.maxDoc();docIDX++) {
         System.out.println("  docID=" + docIDX + " doc=" + joinR.document(docIDX) + " deleted?=" + (liveDocs != null && liveDocs.get(docIDX) == false));
       }
-      PostingsEnum parents = MultiFields.getTermDocsEnum(joinR, null, "isParent", new BytesRef("x"));
+      PostingsEnum parents = MultiFields.getTermDocsEnum(joinR, "isParent", new BytesRef("x"));
       System.out.println("parent docIDs:");
       while (parents.nextDoc() != PostingsEnum.NO_MORE_DOCS) {
         System.out.println("  " + parents.docID());
@@ -1207,7 +1153,7 @@ public class TestBlockJoin extends LuceneTestCase {
 
     ToParentBlockJoinQuery q = new ToParentBlockJoinQuery(tq, parentFilter, ScoreMode.Avg);
     Weight weight = s.createNormalizedWeight(q, true);
-    DocIdSetIterator disi = weight.scorer(s.getIndexReader().leaves().get(0), null);
+    DocIdSetIterator disi = weight.scorer(s.getIndexReader().leaves().get(0));
     assertEquals(1, disi.advance(1));
     r.close();
     dir.close();
@@ -1241,7 +1187,7 @@ public class TestBlockJoin extends LuceneTestCase {
 
     ToParentBlockJoinQuery q = new ToParentBlockJoinQuery(tq, parentFilter, ScoreMode.Avg);
     Weight weight = s.createNormalizedWeight(q, true);
-    DocIdSetIterator disi = weight.scorer(s.getIndexReader().leaves().get(0), null);
+    DocIdSetIterator disi = weight.scorer(s.getIndexReader().leaves().get(0));
     assertEquals(2, disi.advance(0));
     r.close();
     dir.close();
@@ -1284,7 +1230,7 @@ public class TestBlockJoin extends LuceneTestCase {
     s.search(childJoinQuery, c);
 
     //Get all child documents within groups
-    @SuppressWarnings({"unchecked","rawtypes"})
+    @SuppressWarnings({"unchecked"})
     TopGroups<Integer>[] getTopGroupsResults = new TopGroups[2];
     getTopGroupsResults[0] = c.getTopGroups(childJoinQuery, null, 0, 10, 0, true);
     getTopGroupsResults[1] = c.getTopGroupsWithAllChildDocs(childJoinQuery, null, 0, 0, true);
diff --git a/lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoinValidation.java b/lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoinValidation.java
index c6f5f9e..1a279f9 100644
--- a/lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoinValidation.java
+++ b/lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoinValidation.java
@@ -131,7 +131,7 @@ public class TestBlockJoinValidation extends LuceneTestCase {
 
     final LeafReaderContext context = indexSearcher.getIndexReader().leaves().get(0);
     Weight weight = indexSearcher.createNormalizedWeight(blockJoinQuery, true);
-    Scorer scorer = weight.scorer(context, context.reader().getLiveDocs());
+    Scorer scorer = weight.scorer(context);
     final Bits parentDocs = parentsFilter.getDocIdSet(context).bits();
 
     int target;
diff --git a/lucene/join/src/test/org/apache/lucene/search/join/TestJoinUtil.java b/lucene/join/src/test/org/apache/lucene/search/join/TestJoinUtil.java
index 3af1083..4821a7c 100644
--- a/lucene/join/src/test/org/apache/lucene/search/join/TestJoinUtil.java
+++ b/lucene/join/src/test/org/apache/lucene/search/join/TestJoinUtil.java
@@ -370,8 +370,8 @@ public class TestJoinUtil extends LuceneTestCase {
           }
 
           @Override
-          public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-            Scorer fieldScorer = fieldWeight.scorer(context, acceptDocs);
+          public Scorer scorer(LeafReaderContext context) throws IOException {
+            Scorer fieldScorer = fieldWeight.scorer(context);
             NumericDocValues price = context.reader().getNumericDocValues(priceField);
             return new FilterScorer(fieldScorer, this) {
               @Override
@@ -1096,7 +1096,7 @@ public class TestJoinUtil extends LuceneTestCase {
           for (BytesRef joinValue : joinValues) {
             TermsEnum termsEnum = terms.iterator();
             if (termsEnum.seekExact(joinValue)) {
-              postingsEnum = termsEnum.postings(slowCompositeReader.getLiveDocs(), postingsEnum, PostingsEnum.NONE);
+              postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);
               JoinScore joinScore = joinValueToJoinScores.get(joinValue);
 
               for (int doc = postingsEnum.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = postingsEnum.nextDoc()) {
@@ -1219,7 +1219,7 @@ public class TestJoinUtil extends LuceneTestCase {
         }
 
         for (RandomDoc otherSideDoc : otherMatchingDocs) {
-          PostingsEnum postingsEnum = MultiFields.getTermDocsEnum(topLevelReader, MultiFields.getLiveDocs(topLevelReader), "id", new BytesRef(otherSideDoc.id), 0);
+          PostingsEnum postingsEnum = MultiFields.getTermDocsEnum(topLevelReader, "id", new BytesRef(otherSideDoc.id), 0);
           assert postingsEnum != null;
           int doc = postingsEnum.nextDoc();
           expectedResult.set(doc);
diff --git a/lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java b/lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java
index 49a4a7e..0e66909 100644
--- a/lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java
+++ b/lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java
@@ -989,12 +989,12 @@ public class MemoryIndex {
       }
 
       @Override
-      public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) {
+      public PostingsEnum postings(PostingsEnum reuse, int flags) {
         if (reuse == null || !(reuse instanceof MemoryPostingsEnum)) {
           reuse = new MemoryPostingsEnum();
         }
         final int ord = info.sortedTerms[termUpto];
-        return ((MemoryPostingsEnum) reuse).reset(liveDocs, info.sliceArray.start[ord], info.sliceArray.end[ord], info.sliceArray.freq[ord]);
+        return ((MemoryPostingsEnum) reuse).reset(info.sliceArray.start[ord], info.sliceArray.end[ord], info.sliceArray.freq[ord]);
       }
 
       @Override
@@ -1016,7 +1016,6 @@ public class MemoryIndex {
       private final SliceReader sliceReader;
       private int posUpto; // for assert
       private boolean hasNext;
-      private Bits liveDocs;
       private int doc = -1;
       private int freq;
       private int pos;
@@ -1030,8 +1029,7 @@ public class MemoryIndex {
         this.payloadBuilder = storePayloads ? new BytesRefBuilder() : null;
       }
 
-      public PostingsEnum reset(Bits liveDocs, int start, int end, int freq) {
-        this.liveDocs = liveDocs;
+      public PostingsEnum reset(int start, int end, int freq) {
         this.sliceReader.reset(start, end);
         posUpto = 0; // for assert
         hasNext = true;
@@ -1049,7 +1047,7 @@ public class MemoryIndex {
       @Override
       public int nextDoc() {
         pos = -1;
-        if (hasNext && (liveDocs == null || liveDocs.get(0))) {
+        if (hasNext) {
           hasNext = false;
           return doc = 0;
         } else {
diff --git a/lucene/memory/src/test/org/apache/lucene/index/memory/TestMemoryIndexAgainstRAMDir.java b/lucene/memory/src/test/org/apache/lucene/index/memory/TestMemoryIndexAgainstRAMDir.java
index c07dd6e..e85e6c1 100644
--- a/lucene/memory/src/test/org/apache/lucene/index/memory/TestMemoryIndexAgainstRAMDir.java
+++ b/lucene/memory/src/test/org/apache/lucene/index/memory/TestMemoryIndexAgainstRAMDir.java
@@ -199,8 +199,8 @@ public class TestMemoryIndexAgainstRAMDir extends BaseTokenStreamTestCase {
           while(iwTermsIter.next() != null) {
             assertNotNull(memTermsIter.next());
             assertEquals(iwTermsIter.term(), memTermsIter.term());
-            PostingsEnum iwDocsAndPos = iwTermsIter.postings(null, null, PostingsEnum.ALL);
-            PostingsEnum memDocsAndPos = memTermsIter.postings(null, null, PostingsEnum.ALL);
+            PostingsEnum iwDocsAndPos = iwTermsIter.postings(null, PostingsEnum.ALL);
+            PostingsEnum memDocsAndPos = memTermsIter.postings(null, PostingsEnum.ALL);
             while(iwDocsAndPos.nextDoc() != PostingsEnum.NO_MORE_DOCS) {
               assertEquals(iwDocsAndPos.docID(), memDocsAndPos.nextDoc());
               assertEquals(iwDocsAndPos.freq(), memDocsAndPos.freq());
@@ -222,8 +222,8 @@ public class TestMemoryIndexAgainstRAMDir extends BaseTokenStreamTestCase {
         } else {
           while(iwTermsIter.next() != null) {
             assertEquals(iwTermsIter.term(), memTermsIter.term());
-            PostingsEnum iwDocsAndPos = iwTermsIter.postings(null, null);
-            PostingsEnum memDocsAndPos = memTermsIter.postings(null, null);
+            PostingsEnum iwDocsAndPos = iwTermsIter.postings(null);
+            PostingsEnum memDocsAndPos = memTermsIter.postings(null);
             while(iwDocsAndPos.nextDoc() != PostingsEnum.NO_MORE_DOCS) {
               assertEquals(iwDocsAndPos.docID(), memDocsAndPos.nextDoc());
               assertEquals(iwDocsAndPos.freq(), memDocsAndPos.freq());
@@ -320,7 +320,7 @@ public class TestMemoryIndexAgainstRAMDir extends BaseTokenStreamTestCase {
     memory.addField("foo", "bar", analyzer);
     LeafReader reader = (LeafReader) memory.createSearcher().getIndexReader();
     TestUtil.checkReader(reader);
-    PostingsEnum disi = TestUtil.docs(random(), reader, "foo", new BytesRef("bar"), null, null, PostingsEnum.NONE);
+    PostingsEnum disi = TestUtil.docs(random(), reader, "foo", new BytesRef("bar"), null, PostingsEnum.NONE);
     int docid = disi.docID();
     assertEquals(-1, docid);
     assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
@@ -328,7 +328,7 @@ public class TestMemoryIndexAgainstRAMDir extends BaseTokenStreamTestCase {
     // now reuse and check again
     TermsEnum te = reader.terms("foo").iterator();
     assertTrue(te.seekExact(new BytesRef("bar")));
-    disi = te.postings(null, disi, PostingsEnum.NONE);
+    disi = te.postings(disi, PostingsEnum.NONE);
     docid = disi.docID();
     assertEquals(-1, docid);
     assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
@@ -367,7 +367,7 @@ public class TestMemoryIndexAgainstRAMDir extends BaseTokenStreamTestCase {
       // now reuse and check again
       TermsEnum te = reader.terms("foo").iterator();
       assertTrue(te.seekExact(new BytesRef("bar")));
-      disi = te.postings(null, disi);
+      disi = te.postings(disi);
       docid = disi.docID();
       assertEquals(-1, docid);
       assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
@@ -534,8 +534,8 @@ public class TestMemoryIndexAgainstRAMDir extends BaseTokenStreamTestCase {
       assertNotNull(memTermEnum.next());
       assertThat(termEnum.totalTermFreq(), equalTo(memTermEnum.totalTermFreq()));
 
-      PostingsEnum docsPosEnum = termEnum.postings(null, null, PostingsEnum.POSITIONS);
-      PostingsEnum memDocsPosEnum = memTermEnum.postings(null, null, PostingsEnum.POSITIONS);
+      PostingsEnum docsPosEnum = termEnum.postings(null, PostingsEnum.POSITIONS);
+      PostingsEnum memDocsPosEnum = memTermEnum.postings(null, PostingsEnum.POSITIONS);
       String currentTerm = termEnum.term().utf8ToString();
 
       assertThat("Token mismatch for field: " + field_name, currentTerm, equalTo(memTermEnum.term().utf8ToString()));
diff --git a/lucene/misc/src/java/org/apache/lucene/index/SortingLeafReader.java b/lucene/misc/src/java/org/apache/lucene/index/SortingLeafReader.java
index 3839ddb..c9c150a 100644
--- a/lucene/misc/src/java/org/apache/lucene/index/SortingLeafReader.java
+++ b/lucene/misc/src/java/org/apache/lucene/index/SortingLeafReader.java
@@ -132,7 +132,7 @@ public class SortingLeafReader extends FilterLeafReader {
     }
 
     @Override
-    public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, final int flags) throws IOException {
+    public PostingsEnum postings( PostingsEnum reuse, final int flags) throws IOException {
 
       if (hasPositions && PostingsEnum.featureRequested(flags, PostingsEnum.POSITIONS)) {
         final PostingsEnum inReuse;
@@ -147,7 +147,7 @@ public class SortingLeafReader extends FilterLeafReader {
           inReuse = reuse;
         }
 
-        final PostingsEnum inDocsAndPositions = in.postings(newToOld(liveDocs), inReuse, flags);
+        final PostingsEnum inDocsAndPositions = in.postings(inReuse, flags);
         // we ignore the fact that offsets may be stored but not asked for,
         // since this code is expected to be used during addIndexes which will
         // ask for everything. if that assumption changes in the future, we can
@@ -168,7 +168,7 @@ public class SortingLeafReader extends FilterLeafReader {
         inReuse = reuse;
       }
 
-      final PostingsEnum inDocs = in.postings(newToOld(liveDocs), inReuse, flags);
+      final PostingsEnum inDocs = in.postings(inReuse, flags);
       final boolean withFreqs = indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS) >=0 && PostingsEnum.featureRequested(flags, PostingsEnum.FREQS);
       return new SortingDocsEnum(docMap.size(), wrapReuse, inDocs, withFreqs, docMap);
     }
diff --git a/lucene/misc/src/java/org/apache/lucene/uninverting/DocTermOrds.java b/lucene/misc/src/java/org/apache/lucene/uninverting/DocTermOrds.java
index 39dbad4..07c5a95 100644
--- a/lucene/misc/src/java/org/apache/lucene/uninverting/DocTermOrds.java
+++ b/lucene/misc/src/java/org/apache/lucene/uninverting/DocTermOrds.java
@@ -346,7 +346,7 @@ public class DocTermOrds implements Accountable {
       final int df = te.docFreq();
       if (df <= maxTermDocFreq) {
 
-        postingsEnum = te.postings(liveDocs, postingsEnum, PostingsEnum.NONE);
+        postingsEnum = te.postings(postingsEnum, PostingsEnum.NONE);
 
         // dF, but takes deletions into account
         int actualDF = 0;
@@ -593,8 +593,8 @@ public class DocTermOrds implements Accountable {
     }
 
     @Override    
-    public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
-      return termsEnum.postings(liveDocs, reuse, flags);
+    public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
+      return termsEnum.postings(reuse, flags);
     }
 
     @Override
diff --git a/lucene/misc/src/java/org/apache/lucene/uninverting/FieldCacheImpl.java b/lucene/misc/src/java/org/apache/lucene/uninverting/FieldCacheImpl.java
index 311478e..bbbe0cb 100644
--- a/lucene/misc/src/java/org/apache/lucene/uninverting/FieldCacheImpl.java
+++ b/lucene/misc/src/java/org/apache/lucene/uninverting/FieldCacheImpl.java
@@ -288,7 +288,7 @@ class FieldCacheImpl implements FieldCache {
             break;
           }
           visitTerm(term);
-          docs = termsEnum.postings(null, docs, PostingsEnum.NONE);
+          docs = termsEnum.postings(docs, PostingsEnum.NONE);
           while (true) {
             final int docID = docs.nextDoc();
             if (docID == DocIdSetIterator.NO_MORE_DOCS) {
@@ -419,7 +419,7 @@ class FieldCacheImpl implements FieldCache {
             res = new FixedBitSet(maxDoc);
           }
 
-          docs = termsEnum.postings(null, docs, PostingsEnum.NONE);
+          docs = termsEnum.postings(docs, PostingsEnum.NONE);
           // TODO: use bulk API
           while (true) {
             final int docID = docs.nextDoc();
@@ -698,7 +698,7 @@ class FieldCacheImpl implements FieldCache {
           }
 
           termOrdToBytesOffset.add(bytes.copyUsingLengthPrefix(term));
-          docs = termsEnum.postings(null, docs, PostingsEnum.NONE);
+          docs = termsEnum.postings(docs, PostingsEnum.NONE);
           while (true) {
             final int docID = docs.nextDoc();
             if (docID == DocIdSetIterator.NO_MORE_DOCS) {
@@ -850,7 +850,7 @@ class FieldCacheImpl implements FieldCache {
             break;
           }
           final long pointer = bytes.copyUsingLengthPrefix(term);
-          docs = termsEnum.postings(null, docs, PostingsEnum.NONE);
+          docs = termsEnum.postings(docs, PostingsEnum.NONE);
           while (true) {
             final int docID = docs.nextDoc();
             if (docID == DocIdSetIterator.NO_MORE_DOCS) {
diff --git a/lucene/misc/src/test/org/apache/lucene/index/SorterTestBase.java b/lucene/misc/src/test/org/apache/lucene/index/SorterTestBase.java
index 06c381e..4f59208 100644
--- a/lucene/misc/src/test/org/apache/lucene/index/SorterTestBase.java
+++ b/lucene/misc/src/test/org/apache/lucene/index/SorterTestBase.java
@@ -235,7 +235,7 @@ public abstract class SorterTestBase extends LuceneTestCase {
   public void testDocsAndPositionsEnum() throws Exception {
     TermsEnum termsEnum = sortedReader.terms(DOC_POSITIONS_FIELD).iterator();
     assertEquals(SeekStatus.FOUND, termsEnum.seekCeil(new BytesRef(DOC_POSITIONS_TERM)));
-    PostingsEnum sortedPositions = termsEnum.postings(null, null, PostingsEnum.ALL);
+    PostingsEnum sortedPositions = termsEnum.postings(null, PostingsEnum.ALL);
     int doc;
     
     // test nextDoc()
@@ -252,7 +252,7 @@ public abstract class SorterTestBase extends LuceneTestCase {
     
     // test advance()
     final PostingsEnum reuse = sortedPositions;
-    sortedPositions = termsEnum.postings(null, reuse, PostingsEnum.ALL);
+    sortedPositions = termsEnum.postings(reuse, PostingsEnum.ALL);
     if (sortedPositions instanceof SortingDocsEnum) {
       assertTrue(((SortingDocsEnum) sortedPositions).reused(reuse)); // make sure reuse worked
     }
@@ -293,40 +293,25 @@ public abstract class SorterTestBase extends LuceneTestCase {
 
   @Test
   public void testDocsEnum() throws Exception {
-    Bits mappedLiveDocs = randomLiveDocs(sortedReader.maxDoc());
     TermsEnum termsEnum = sortedReader.terms(DOCS_ENUM_FIELD).iterator();
     assertEquals(SeekStatus.FOUND, termsEnum.seekCeil(new BytesRef(DOCS_ENUM_TERM)));
-    PostingsEnum docs = termsEnum.postings(mappedLiveDocs, null);
+    PostingsEnum docs = termsEnum.postings(null);
 
     int doc;
     int prev = -1;
     while ((doc = docs.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
-      assertTrue("document " + doc + " marked as deleted", mappedLiveDocs == null || mappedLiveDocs.get(doc));
       assertEquals("incorrect value; doc " + doc, sortedValues[doc].intValue(), Integer.parseInt(sortedReader.document(doc).get(ID_FIELD)));
-      while (++prev < doc) {
-        assertFalse("document " + prev + " not marked as deleted", mappedLiveDocs == null || mappedLiveDocs.get(prev));
-      }
-    }
-    while (++prev < sortedReader.maxDoc()) {
-      assertFalse("document " + prev + " not marked as deleted", mappedLiveDocs == null || mappedLiveDocs.get(prev));
     }
 
     PostingsEnum reuse = docs;
-    docs = termsEnum.postings(mappedLiveDocs, reuse);
+    docs = termsEnum.postings(reuse);
     if (docs instanceof SortingDocsEnum) {
       assertTrue(((SortingDocsEnum) docs).reused(reuse)); // make sure reuse worked
     }
     doc = -1;
     prev = -1;
     while ((doc = docs.advance(doc + 1)) != DocIdSetIterator.NO_MORE_DOCS) {
-      assertTrue("document " + doc + " marked as deleted", mappedLiveDocs == null || mappedLiveDocs.get(doc));
       assertEquals("incorrect value; doc " + doc, sortedValues[doc].intValue(), Integer.parseInt(sortedReader.document(doc).get(ID_FIELD)));
-      while (++prev < doc) {
-        assertFalse("document " + prev + " not marked as deleted", mappedLiveDocs == null || mappedLiveDocs.get(prev));
-      }
-    }
-    while (++prev < sortedReader.maxDoc()) {
-      assertFalse("document " + prev + " not marked as deleted", mappedLiveDocs == null || mappedLiveDocs.get(prev));
     }
   }
   
diff --git a/lucene/queries/src/java/org/apache/lucene/queries/BoostingQuery.java b/lucene/queries/src/java/org/apache/lucene/queries/BoostingQuery.java
index 308d7e7..b482d60 100644
--- a/lucene/queries/src/java/org/apache/lucene/queries/BoostingQuery.java
+++ b/lucene/queries/src/java/org/apache/lucene/queries/BoostingQuery.java
@@ -94,12 +94,12 @@ public class BoostingQuery extends Query {
         }
 
         @Override
-        public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-          final Scorer matchScorer = matchWeight.scorer(context, acceptDocs);
+        public Scorer scorer(LeafReaderContext context) throws IOException {
+          final Scorer matchScorer = matchWeight.scorer(context);
           if (matchScorer == null) {
             return null;
           }
-          final Scorer contextScorer = contextWeight.scorer(context, acceptDocs);
+          final Scorer contextScorer = contextWeight.scorer(context);
           if (contextScorer == null) {
             return matchScorer;
           }
diff --git a/lucene/queries/src/java/org/apache/lucene/queries/CustomScoreQuery.java b/lucene/queries/src/java/org/apache/lucene/queries/CustomScoreQuery.java
index 215fbc8..5962351 100644
--- a/lucene/queries/src/java/org/apache/lucene/queries/CustomScoreQuery.java
+++ b/lucene/queries/src/java/org/apache/lucene/queries/CustomScoreQuery.java
@@ -228,14 +228,14 @@ public class CustomScoreQuery extends Query {
     }
 
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-      Scorer subQueryScorer = subQueryWeight.scorer(context, acceptDocs);
+    public Scorer scorer(LeafReaderContext context) throws IOException {
+      Scorer subQueryScorer = subQueryWeight.scorer(context);
       if (subQueryScorer == null) {
         return null;
       }
       Scorer[] valSrcScorers = new Scorer[valSrcWeights.length];
       for(int i = 0; i < valSrcScorers.length; i++) {
-         valSrcScorers[i] = valSrcWeights[i].scorer(context, acceptDocs);
+         valSrcScorers[i] = valSrcWeights[i].scorer(context);
       }
       return new CustomScorer(CustomScoreQuery.this.getCustomScoreProvider(context), this, queryWeight, subQueryScorer, valSrcScorers);
     }
diff --git a/lucene/queries/src/java/org/apache/lucene/queries/TermsQuery.java b/lucene/queries/src/java/org/apache/lucene/queries/TermsQuery.java
index 02abaa5..ac3455b 100644
--- a/lucene/queries/src/java/org/apache/lucene/queries/TermsQuery.java
+++ b/lucene/queries/src/java/org/apache/lucene/queries/TermsQuery.java
@@ -252,7 +252,7 @@ public class TermsQuery extends Query implements Accountable {
        * On the given leaf context, try to either rewrite to a disjunction if
        * there are few matching terms, or build a bitset containing matching docs.
        */
-      private WeightOrBitSet rewrite(LeafReaderContext context, Bits acceptDocs) throws IOException {
+      private WeightOrBitSet rewrite(LeafReaderContext context) throws IOException {
         final LeafReader reader = context.reader();
 
         // We will first try to collect up to 'threshold' terms into 'matchingTerms'
@@ -282,18 +282,18 @@ public class TermsQuery extends Query implements Accountable {
           }
           if (termsEnum != null && termsEnum.seekExact(term)) {
             if (matchingTerms == null) {
-              docs = termsEnum.postings(acceptDocs, docs, PostingsEnum.NONE);
+              docs = termsEnum.postings(docs, PostingsEnum.NONE);
               builder.or(docs);
             } else if (matchingTerms.size() < threshold) {
               matchingTerms.add(new TermAndState(field, termsEnum));
             } else {
               assert matchingTerms.size() == threshold;
               builder = new BitDocIdSet.Builder(reader.maxDoc());
-              docs = termsEnum.postings(acceptDocs, docs, PostingsEnum.NONE);
+              docs = termsEnum.postings(docs, PostingsEnum.NONE);
               builder.or(docs);
               for (TermAndState t : matchingTerms) {
                 t.termsEnum.seekExact(t.term, t.state);
-                docs = t.termsEnum.postings(acceptDocs, docs, PostingsEnum.NONE);
+                docs = t.termsEnum.postings(docs, PostingsEnum.NONE);
                 builder.or(docs);
               }
               matchingTerms = null;
@@ -329,10 +329,10 @@ public class TermsQuery extends Query implements Accountable {
       }
 
       @Override
-      public BulkScorer bulkScorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-        final WeightOrBitSet weightOrBitSet = rewrite(context, acceptDocs);
+      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {
+        final WeightOrBitSet weightOrBitSet = rewrite(context);
         if (weightOrBitSet.weight != null) {
-          return weightOrBitSet.weight.bulkScorer(context, acceptDocs);
+          return weightOrBitSet.weight.bulkScorer(context);
         } else {
           final Scorer scorer = scorer(weightOrBitSet.bitset);
           if (scorer == null) {
@@ -343,10 +343,10 @@ public class TermsQuery extends Query implements Accountable {
       }
 
       @Override
-      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-        final WeightOrBitSet weightOrBitSet = rewrite(context, acceptDocs);
+      public Scorer scorer(LeafReaderContext context) throws IOException {
+        final WeightOrBitSet weightOrBitSet = rewrite(context);
         if (weightOrBitSet.weight != null) {
-          return weightOrBitSet.weight.scorer(context, acceptDocs);
+          return weightOrBitSet.weight.scorer(context);
         } else {
           return scorer(weightOrBitSet.bitset);
         }
diff --git a/lucene/queries/src/java/org/apache/lucene/queries/function/BoostedQuery.java b/lucene/queries/src/java/org/apache/lucene/queries/function/BoostedQuery.java
index 8b76a3a..e7469cd 100644
--- a/lucene/queries/src/java/org/apache/lucene/queries/function/BoostedQuery.java
+++ b/lucene/queries/src/java/org/apache/lucene/queries/function/BoostedQuery.java
@@ -98,8 +98,8 @@ public class BoostedQuery extends Query {
     }
 
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-      Scorer subQueryScorer = qWeight.scorer(context, acceptDocs);
+    public Scorer scorer(LeafReaderContext context) throws IOException {
+      Scorer subQueryScorer = qWeight.scorer(context);
       if (subQueryScorer == null) {
         return null;
       }
diff --git a/lucene/queries/src/java/org/apache/lucene/queries/function/FunctionQuery.java b/lucene/queries/src/java/org/apache/lucene/queries/function/FunctionQuery.java
index 10a35a1..b04daf4 100644
--- a/lucene/queries/src/java/org/apache/lucene/queries/function/FunctionQuery.java
+++ b/lucene/queries/src/java/org/apache/lucene/queries/function/FunctionQuery.java
@@ -89,13 +89,13 @@ public class FunctionQuery extends Query {
     }
 
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-      return new AllScorer(context, acceptDocs, this, queryWeight);
+    public Scorer scorer(LeafReaderContext context) throws IOException {
+      return new AllScorer(context, this, queryWeight);
     }
 
     @Override
     public Explanation explain(LeafReaderContext context, int doc) throws IOException {
-      return ((AllScorer)scorer(context, context.reader().getLiveDocs())).explain(doc);
+      return ((AllScorer)scorer(context)).explain(doc);
     }
   }
 
@@ -106,15 +106,13 @@ public class FunctionQuery extends Query {
     final float qWeight;
     int doc=-1;
     final FunctionValues vals;
-    final Bits acceptDocs;
 
-    public AllScorer(LeafReaderContext context, Bits acceptDocs, FunctionWeight w, float qWeight) throws IOException {
+    public AllScorer(LeafReaderContext context, FunctionWeight w, float qWeight) throws IOException {
       super(w);
       this.weight = w;
       this.qWeight = qWeight;
       this.reader = context.reader();
       this.maxDoc = reader.maxDoc();
-      this.acceptDocs = acceptDocs;
       vals = func.getValues(weight.context, context);
     }
 
@@ -129,21 +127,16 @@ public class FunctionQuery extends Query {
     // Boost:        foo:myTerm^floatline("myFloatField",1.0,0.0f)
     @Override
     public int nextDoc() throws IOException {
-      for(;;) {
-        ++doc;
-        if (doc>=maxDoc) {
-          return doc=NO_MORE_DOCS;
-        }
-        if (acceptDocs != null && !acceptDocs.get(doc)) continue;
-        return doc;
+      ++doc;
+      if (doc>=maxDoc) {
+        return doc=NO_MORE_DOCS;
       }
+      return doc;
     }
 
     @Override
     public int advance(int target) throws IOException {
-      // this will work even if target==NO_MORE_DOCS
-      doc=target-1;
-      return nextDoc();
+      return slowAdvance(target);
     }
 
     @Override
diff --git a/lucene/queries/src/java/org/apache/lucene/queries/function/valuesource/QueryValueSource.java b/lucene/queries/src/java/org/apache/lucene/queries/function/valuesource/QueryValueSource.java
index f3ceae3..d37d272 100644
--- a/lucene/queries/src/java/org/apache/lucene/queries/function/valuesource/QueryValueSource.java
+++ b/lucene/queries/src/java/org/apache/lucene/queries/function/valuesource/QueryValueSource.java
@@ -80,7 +80,6 @@ public class QueryValueSource extends ValueSource {
 
 class QueryDocValues extends FloatDocValues {
   final LeafReaderContext readerContext;
-  final Bits acceptDocs;
   final Weight weight;
   final float defVal;
   final Map fcontext;
@@ -99,7 +98,6 @@ class QueryDocValues extends FloatDocValues {
     super(vs);
 
     this.readerContext = readerContext;
-    this.acceptDocs = readerContext.reader().getLiveDocs();
     this.defVal = vs.defVal;
     this.q = vs.q;
     this.fcontext = fcontext;
@@ -126,7 +124,7 @@ class QueryDocValues extends FloatDocValues {
     try {
       if (doc < lastDocRequested) {
         if (noMatches) return defVal;
-        scorer = weight.scorer(readerContext, acceptDocs);
+        scorer = weight.scorer(readerContext);
         if (scorer==null) {
           noMatches = true;
           return defVal;
@@ -157,7 +155,7 @@ class QueryDocValues extends FloatDocValues {
     try {
       if (doc < lastDocRequested) {
         if (noMatches) return false;
-        scorer = weight.scorer(readerContext, acceptDocs);
+        scorer = weight.scorer(readerContext);
         scorerDoc = -1;
         if (scorer==null) {
           noMatches = true;
@@ -215,7 +213,7 @@ class QueryDocValues extends FloatDocValues {
             mval.exists = false;
             return;
           }
-          scorer = weight.scorer(readerContext, acceptDocs);
+          scorer = weight.scorer(readerContext);
           scorerDoc = -1;
           if (scorer==null) {
             noMatches = true;
diff --git a/lucene/queries/src/java/org/apache/lucene/queries/function/valuesource/TFValueSource.java b/lucene/queries/src/java/org/apache/lucene/queries/function/valuesource/TFValueSource.java
index 2611ab7..bbae30b 100644
--- a/lucene/queries/src/java/org/apache/lucene/queries/function/valuesource/TFValueSource.java
+++ b/lucene/queries/src/java/org/apache/lucene/queries/function/valuesource/TFValueSource.java
@@ -72,7 +72,7 @@ public class TFValueSource extends TermFreqValueSource {
         if (terms != null) {
           final TermsEnum termsEnum = terms.iterator();
           if (termsEnum.seekExact(indexedBytes)) {
-            docs = termsEnum.postings(null, null);
+            docs = termsEnum.postings(null);
           } else {
             docs = null;
           }
diff --git a/lucene/queries/src/java/org/apache/lucene/queries/function/valuesource/TermFreqValueSource.java b/lucene/queries/src/java/org/apache/lucene/queries/function/valuesource/TermFreqValueSource.java
index 9da21c2..aa95f2b 100644
--- a/lucene/queries/src/java/org/apache/lucene/queries/function/valuesource/TermFreqValueSource.java
+++ b/lucene/queries/src/java/org/apache/lucene/queries/function/valuesource/TermFreqValueSource.java
@@ -65,7 +65,7 @@ public class TermFreqValueSource extends DocFreqValueSource {
         if (terms != null) {
           final TermsEnum termsEnum = terms.iterator();
           if (termsEnum.seekExact(indexedBytes)) {
-            docs = termsEnum.postings(null, null);
+            docs = termsEnum.postings(null);
           } else {
             docs = null;
           }
diff --git a/lucene/sandbox/src/java/org/apache/lucene/bkdtree/BKDPointInBBoxQuery.java b/lucene/sandbox/src/java/org/apache/lucene/bkdtree/BKDPointInBBoxQuery.java
index 587247a..8337cbc 100644
--- a/lucene/sandbox/src/java/org/apache/lucene/bkdtree/BKDPointInBBoxQuery.java
+++ b/lucene/sandbox/src/java/org/apache/lucene/bkdtree/BKDPointInBBoxQuery.java
@@ -101,7 +101,7 @@ public class BKDPointInBBoxQuery extends Query {
 
       @Override
       public Explanation explain(LeafReaderContext context, int doc) throws IOException {
-        final Scorer s = scorer(context, context.reader().getLiveDocs());
+        final Scorer s = scorer(context);
         final boolean exists = s != null && s.advance(doc) == doc;
 
         if (exists) {
@@ -113,7 +113,7 @@ public class BKDPointInBBoxQuery extends Query {
       }
 
       @Override
-      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+      public Scorer scorer(LeafReaderContext context) throws IOException {
         LeafReader reader = context.reader();
         SortedNumericDocValues sdv = reader.getSortedNumericDocValues(field);
         if (sdv == null) {
@@ -127,7 +127,7 @@ public class BKDPointInBBoxQuery extends Query {
         BKDTreeSortedNumericDocValues treeDV = (BKDTreeSortedNumericDocValues) sdv;
         BKDTreeReader tree = treeDV.getBKDTreeReader();
 
-        DocIdSet result = tree.intersect(acceptDocs, minLat, maxLat, minLon, maxLon, treeDV.delegate);
+        DocIdSet result = tree.intersect(minLat, maxLat, minLon, maxLon, treeDV.delegate);
 
         final DocIdSetIterator disi = result.iterator();
 
diff --git a/lucene/sandbox/src/java/org/apache/lucene/bkdtree/BKDPointInPolygonQuery.java b/lucene/sandbox/src/java/org/apache/lucene/bkdtree/BKDPointInPolygonQuery.java
index f7443eb..62fbaa0 100644
--- a/lucene/sandbox/src/java/org/apache/lucene/bkdtree/BKDPointInPolygonQuery.java
+++ b/lucene/sandbox/src/java/org/apache/lucene/bkdtree/BKDPointInPolygonQuery.java
@@ -132,7 +132,7 @@ public class BKDPointInPolygonQuery extends Query {
 
       @Override
       public Explanation explain(LeafReaderContext context, int doc) throws IOException {
-        final Scorer s = scorer(context, context.reader().getLiveDocs());
+        final Scorer s = scorer(context);
         final boolean exists = s != null && s.advance(doc) == doc;
 
         if (exists) {
@@ -144,7 +144,7 @@ public class BKDPointInPolygonQuery extends Query {
       }
 
       @Override
-      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+      public Scorer scorer(LeafReaderContext context) throws IOException {
         LeafReader reader = context.reader();
         SortedNumericDocValues sdv = reader.getSortedNumericDocValues(field);
         if (sdv == null) {
@@ -160,7 +160,7 @@ public class BKDPointInPolygonQuery extends Query {
         
         // TODO: make this more efficient: as we recurse the BKD tree we should check whether the
         // bbox we are recursing into intersects our shape; Apache SIS may have (non-GPL!) code to do this?
-        DocIdSet result = tree.intersect(acceptDocs, minLat, maxLat, minLon, maxLon,
+        DocIdSet result = tree.intersect(minLat, maxLat, minLon, maxLon,
                                          new BKDTreeReader.LatLonFilter() {
                                            @Override
                                            public boolean accept(double lat, double lon) {
diff --git a/lucene/sandbox/src/java/org/apache/lucene/bkdtree/BKDTreeReader.java b/lucene/sandbox/src/java/org/apache/lucene/bkdtree/BKDTreeReader.java
index 5c65761..4defe79 100644
--- a/lucene/sandbox/src/java/org/apache/lucene/bkdtree/BKDTreeReader.java
+++ b/lucene/sandbox/src/java/org/apache/lucene/bkdtree/BKDTreeReader.java
@@ -95,11 +95,11 @@ final class BKDTreeReader implements Accountable {
     }
   }
 
-  public DocIdSet intersect(Bits acceptDocs, double latMin, double latMax, double lonMin, double lonMax, SortedNumericDocValues sndv) throws IOException {
-    return intersect(acceptDocs, latMin, latMax, lonMin, lonMax, null, sndv);
+  public DocIdSet intersect(double latMin, double latMax, double lonMin, double lonMax, SortedNumericDocValues sndv) throws IOException {
+    return intersect(latMin, latMax, lonMin, lonMax, null, sndv);
   }
 
-  public DocIdSet intersect(Bits acceptDocs, double latMin, double latMax, double lonMin, double lonMax, LatLonFilter filter, SortedNumericDocValues sndv) throws IOException {
+  public DocIdSet intersect(double latMin, double latMax, double lonMin, double lonMax, LatLonFilter filter, SortedNumericDocValues sndv) throws IOException {
     if (BKDTreeWriter.validLat(latMin) == false) {
       throw new IllegalArgumentException("invalid latMin: " + latMin);
     }
@@ -128,7 +128,7 @@ final class BKDTreeReader implements Accountable {
                                       filter,
                                       sndv);
 
-    int hitCount = intersect(acceptDocs, state, 1,
+    int hitCount = intersect(state, 1,
                              BKDTreeWriter.encodeLat(-90.0),
                              BKDTreeWriter.encodeLat(Math.nextAfter(90.0, Double.POSITIVE_INFINITY)),
                              BKDTreeWriter.encodeLon(-180.0),
@@ -139,7 +139,7 @@ final class BKDTreeReader implements Accountable {
   }
 
   /** Fast path: this is called when the query rect fully encompasses all cells under this node. */
-  private int addAll(Bits acceptDocs, QueryState state, int nodeID) throws IOException {
+  private int addAll(QueryState state, int nodeID) throws IOException {
 
     //long latRange = (long) cellLatMaxEnc - (long) cellLatMinEnc;
     //long lonRange = (long) cellLonMaxEnc - (long) cellLonMinEnc;
@@ -167,18 +167,9 @@ final class BKDTreeReader implements Accountable {
       //System.out.println("    seek to leafFP=" + fp);
       // How many points are stored in this leaf cell:
       int count = state.in.readVInt();
-      if (acceptDocs != null) {
-        for(int i=0;i<count;i++) {
-          int docID = state.in.readInt();
-          if (acceptDocs.get(docID)) {
-            state.bits.set(docID);
-          }
-        }
-      } else {
-        for(int i=0;i<count;i++) {
-          int docID = state.in.readInt();
-          state.bits.set(docID);
-        }
+      for(int i=0;i<count;i++) {
+        int docID = state.in.readInt();
+        state.bits.set(docID);
       }
 
       //bits.or(allLeafDISI);
@@ -195,14 +186,14 @@ final class BKDTreeReader implements Accountable {
       //System.out.println("  splitValue=" + splitValue);
 
       //System.out.println("  addAll: inner");
-      int count = addAll(acceptDocs, state, 2*nodeID);
-      count += addAll(acceptDocs, state, 2*nodeID+1);
+      int count = addAll(state, 2*nodeID);
+      count += addAll(state, 2*nodeID+1);
       //System.out.println("  addAll: return count=" + count);
       return count;
     }
   }
 
-  private int intersect(Bits acceptDocs, QueryState state,
+  private int intersect(QueryState state,
                         int nodeID,
                         int cellLatMinEnc, int cellLatMaxEnc, int cellLonMinEnc, int cellLonMaxEnc)
     throws IOException {
@@ -223,7 +214,7 @@ final class BKDTreeReader implements Accountable {
           return 0;
         } else if (r == Relation.INSIDE) {
           // This cell is fully inside of the query shape: recursively add all points in this cell without filtering
-          return addAll(acceptDocs, state, nodeID);
+          return addAll(state, nodeID);
         } else {
           // The cell crosses the shape boundary, so we fall through and do full filtering
         }
@@ -231,7 +222,7 @@ final class BKDTreeReader implements Accountable {
     } else if (state.latMinEnc <= cellLatMinEnc && state.latMaxEnc >= cellLatMaxEnc && state.lonMinEnc <= cellLonMinEnc && state.lonMaxEnc >= cellLonMaxEnc) {
       // Optimize the case when the query fully contains this cell: we can
       // recursively add all points without checking if they match the query:
-      return addAll(acceptDocs, state, nodeID);
+      return addAll(state, nodeID);
     }
 
     long latRange = (long) cellLatMaxEnc - (long) cellLatMinEnc;
@@ -273,28 +264,26 @@ final class BKDTreeReader implements Accountable {
 
       for(int i=0;i<count;i++) {
         int docID = state.in.readInt();
-        if (acceptDocs == null || acceptDocs.get(docID)) {
-          state.sndv.setDocument(docID);
-          // How many values this doc has:
-          int docValueCount = state.sndv.count();
-          for(int j=0;j<docValueCount;j++) {
-            long enc = state.sndv.valueAt(j);
-
-            int latEnc = (int) ((enc>>32) & 0xffffffffL);
-            int lonEnc = (int) (enc & 0xffffffffL);
-
-            if (latEnc >= state.latMinEnc &&
-                latEnc < state.latMaxEnc &&
-                lonEnc >= state.lonMinEnc &&
-                lonEnc < state.lonMaxEnc &&
-                (state.latLonFilter == null ||
-                 state.latLonFilter.accept(BKDTreeWriter.decodeLat(latEnc), BKDTreeWriter.decodeLon(lonEnc)))) {
-              state.bits.set(docID);
-              hitCount++;
-
-              // Stop processing values for this doc:
-              break;
-            }
+        state.sndv.setDocument(docID);
+        // How many values this doc has:
+        int docValueCount = state.sndv.count();
+        for(int j=0;j<docValueCount;j++) {
+          long enc = state.sndv.valueAt(j);
+
+          int latEnc = (int) ((enc>>32) & 0xffffffffL);
+          int lonEnc = (int) (enc & 0xffffffffL);
+
+          if (latEnc >= state.latMinEnc &&
+              latEnc < state.latMaxEnc &&
+              lonEnc >= state.lonMinEnc &&
+              lonEnc < state.lonMaxEnc &&
+              (state.latLonFilter == null ||
+               state.latLonFilter.accept(BKDTreeWriter.decodeLat(latEnc), BKDTreeWriter.decodeLon(lonEnc)))) {
+            state.bits.set(docID);
+            hitCount++;
+
+            // Stop processing values for this doc:
+            break;
           }
         }
       }
@@ -330,7 +319,7 @@ final class BKDTreeReader implements Accountable {
         // Left node:
         if (state.latMinEnc < splitValue) {
           //System.out.println("  recurse left");
-          count += intersect(acceptDocs, state,
+          count += intersect(state,
                              2*nodeID,
                              cellLatMinEnc, splitValue, cellLonMinEnc, cellLonMaxEnc);
         }
@@ -338,7 +327,7 @@ final class BKDTreeReader implements Accountable {
         // Right node:
         if (state.latMaxEnc >= splitValue) {
           //System.out.println("  recurse right");
-          count += intersect(acceptDocs, state,
+          count += intersect(state,
                              2*nodeID+1,
                              splitValue, cellLatMaxEnc, cellLonMinEnc, cellLonMaxEnc);
         }
@@ -352,7 +341,7 @@ final class BKDTreeReader implements Accountable {
         // Left node:
         if (state.lonMinEnc < splitValue) {
           // System.out.println("  recurse left");
-          count += intersect(acceptDocs, state,
+          count += intersect(state,
                              2*nodeID,
                              cellLatMinEnc, cellLatMaxEnc, cellLonMinEnc, splitValue);
         }
@@ -360,7 +349,7 @@ final class BKDTreeReader implements Accountable {
         // Right node:
         if (state.lonMaxEnc >= splitValue) {
           // System.out.println("  recurse right");
-          count += intersect(acceptDocs, state,
+          count += intersect(state,
                              2*nodeID+1,
                              cellLatMinEnc, cellLatMaxEnc, splitValue, cellLonMaxEnc);
         }
diff --git a/lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/IDVersionPostingsReader.java b/lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/IDVersionPostingsReader.java
index 0466225..d6a6a61 100644
--- a/lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/IDVersionPostingsReader.java
+++ b/lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/IDVersionPostingsReader.java
@@ -63,7 +63,7 @@ final class IDVersionPostingsReader extends PostingsReaderBase {
   }
 
   @Override
-  public PostingsEnum postings(FieldInfo fieldInfo, BlockTermState termState, Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
+  public PostingsEnum postings(FieldInfo fieldInfo, BlockTermState termState, PostingsEnum reuse, int flags) throws IOException {
     SingleDocsEnum docsEnum;
 
     if (PostingsEnum.featureRequested(flags, PostingsEnum.POSITIONS)) {
@@ -75,7 +75,7 @@ final class IDVersionPostingsReader extends PostingsReaderBase {
         posEnum = new SinglePostingsEnum();
       }
       IDVersionTermState _termState = (IDVersionTermState) termState;
-      posEnum.reset(_termState.docID, _termState.idVersion, liveDocs);
+      posEnum.reset(_termState.docID, _termState.idVersion);
       return posEnum;
     }
 
@@ -84,7 +84,7 @@ final class IDVersionPostingsReader extends PostingsReaderBase {
     } else {
       docsEnum = new SingleDocsEnum();
     }
-    docsEnum.reset(((IDVersionTermState) termState).docID, liveDocs);
+    docsEnum.reset(((IDVersionTermState) termState).docID);
 
     return docsEnum;
   }
diff --git a/lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/IDVersionSegmentTermsEnum.java b/lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/IDVersionSegmentTermsEnum.java
index 3a7e534..138bb59 100644
--- a/lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/IDVersionSegmentTermsEnum.java
+++ b/lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/IDVersionSegmentTermsEnum.java
@@ -995,7 +995,7 @@ public final class IDVersionSegmentTermsEnum extends TermsEnum {
   }
 
   @Override
-  public PostingsEnum postings(Bits skipDocs, PostingsEnum reuse, int flags) throws IOException {
+  public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
     assert !eof;
     //if (DEBUG) {
     //System.out.println("BTTR.docs seg=" + segment);
@@ -1004,7 +1004,7 @@ public final class IDVersionSegmentTermsEnum extends TermsEnum {
     //if (DEBUG) {
     //System.out.println("  state=" + currentFrame.state);
     //}
-    return fr.parent.postingsReader.postings(fr.fieldInfo, currentFrame.state, skipDocs, reuse, flags);
+    return fr.parent.postingsReader.postings(fr.fieldInfo, currentFrame.state, reuse, flags);
   }
 
   @Override
diff --git a/lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/SingleDocsEnum.java b/lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/SingleDocsEnum.java
index caed5cd..5bba79c 100644
--- a/lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/SingleDocsEnum.java
+++ b/lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/SingleDocsEnum.java
@@ -20,25 +20,22 @@ package org.apache.lucene.codecs.idversion;
 import java.io.IOException;
 
 import org.apache.lucene.index.PostingsEnum;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 
 class SingleDocsEnum extends PostingsEnum {
 
   private int doc;
   private int singleDocID;
-  private Bits liveDocs;
 
   /** For reuse */
-  public void reset(int singleDocID, Bits liveDocs) {
+  public void reset(int singleDocID) {
     doc = -1;
-    this.liveDocs = liveDocs;
     this.singleDocID = singleDocID;
   }
 
   @Override
   public int nextDoc() {
-    if (doc == -1 && (liveDocs == null || liveDocs.get(singleDocID))) {
+    if (doc == -1) {
       doc = singleDocID;
     } else {
       doc = NO_MORE_DOCS;
@@ -54,7 +51,7 @@ class SingleDocsEnum extends PostingsEnum {
 
   @Override
   public int advance(int target) {
-    if (doc == -1 && target <= singleDocID && (liveDocs == null || liveDocs.get(singleDocID))) {
+    if (doc == -1 && target <= singleDocID) {
       doc = singleDocID;
     } else {
       doc = NO_MORE_DOCS;
diff --git a/lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/SinglePostingsEnum.java b/lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/SinglePostingsEnum.java
index 63edbe5..04b9480 100644
--- a/lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/SinglePostingsEnum.java
+++ b/lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/SinglePostingsEnum.java
@@ -18,14 +18,12 @@ package org.apache.lucene.codecs.idversion;
  */
 
 import org.apache.lucene.index.PostingsEnum;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 
 class SinglePostingsEnum extends PostingsEnum {
   private int doc;
   private int pos;
   private int singleDocID;
-  private Bits liveDocs;
   private long version;
   private final BytesRef payload;
 
@@ -35,16 +33,15 @@ class SinglePostingsEnum extends PostingsEnum {
   }
 
   /** For reuse */
-  public void reset(int singleDocID, long version, Bits liveDocs) {
+  public void reset(int singleDocID, long version) {
     doc = -1;
-    this.liveDocs = liveDocs;
     this.singleDocID = singleDocID;
     this.version = version;
   }
 
   @Override
   public int nextDoc() {
-    if (doc == -1 && (liveDocs == null || liveDocs.get(singleDocID))) {
+    if (doc == -1) {
       doc = singleDocID;
     } else {
       doc = NO_MORE_DOCS;
@@ -61,7 +58,7 @@ class SinglePostingsEnum extends PostingsEnum {
 
   @Override
   public int advance(int target) {
-    if (doc == -1 && target <= singleDocID && (liveDocs == null || liveDocs.get(singleDocID))) {
+    if (doc == -1 && target <= singleDocID) {
       doc = singleDocID;
       pos = -1;
     } else {
diff --git a/lucene/sandbox/src/java/org/apache/lucene/sandbox/queries/DuplicateFilter.java b/lucene/sandbox/src/java/org/apache/lucene/sandbox/queries/DuplicateFilter.java
index ec553bb..db02d22 100644
--- a/lucene/sandbox/src/java/org/apache/lucene/sandbox/queries/DuplicateFilter.java
+++ b/lucene/sandbox/src/java/org/apache/lucene/sandbox/queries/DuplicateFilter.java
@@ -24,6 +24,7 @@ import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.SlowCompositeReaderWrapper;
 import org.apache.lucene.index.Terms;
 import org.apache.lucene.index.TermsEnum;
+import org.apache.lucene.search.BitsFilteredDocIdSet;
 import org.apache.lucene.search.DocIdSet;
 import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.search.Filter;
@@ -106,7 +107,7 @@ public class DuplicateFilter extends Filter {
         if (currTerm == null) {
           break;
         } else {
-          docs = termsEnum.postings(acceptDocs, docs, PostingsEnum.NONE);
+          docs = termsEnum.postings(docs, PostingsEnum.NONE);
           int doc = docs.nextDoc();
           if (doc != DocIdSetIterator.NO_MORE_DOCS) {
             if (keepMode == KeepMode.KM_USE_FIRST_OCCURRENCE) {
@@ -126,7 +127,7 @@ public class DuplicateFilter extends Filter {
         }
       }
     }
-    return new BitDocIdSet(bits, bits.approximateCardinality());
+    return BitsFilteredDocIdSet.wrap(new BitDocIdSet(bits, bits.approximateCardinality()), acceptDocs);
   }
 
   private DocIdSet fastBits(LeafReader reader, Bits acceptDocs) throws IOException {
@@ -144,7 +145,7 @@ public class DuplicateFilter extends Filter {
         } else {
           if (termsEnum.docFreq() > 1) {
             // unset potential duplicates
-            docs = termsEnum.postings(acceptDocs, docs, PostingsEnum.NONE);
+            docs = termsEnum.postings(docs, PostingsEnum.NONE);
             int doc = docs.nextDoc();
             if (doc != DocIdSetIterator.NO_MORE_DOCS) {
               if (keepMode == KeepMode.KM_USE_FIRST_OCCURRENCE) {
@@ -171,7 +172,7 @@ public class DuplicateFilter extends Filter {
       }
     }
 
-    return new BitDocIdSet(bits);
+    return BitsFilteredDocIdSet.wrap(new BitDocIdSet(bits), acceptDocs);
   }
 
   public String getFieldName() {
diff --git a/lucene/sandbox/src/java/org/apache/lucene/search/TermAutomatonQuery.java b/lucene/sandbox/src/java/org/apache/lucene/search/TermAutomatonQuery.java
index e300994..f1631bd 100644
--- a/lucene/sandbox/src/java/org/apache/lucene/search/TermAutomatonQuery.java
+++ b/lucene/sandbox/src/java/org/apache/lucene/search/TermAutomatonQuery.java
@@ -381,7 +381,7 @@ public class TermAutomatonQuery extends Query {
     }
 
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+    public Scorer scorer(LeafReaderContext context) throws IOException {
 
       // Initialize the enums; null for a given slot means that term didn't appear in this reader
       EnumAndScorer[] enums = new EnumAndScorer[idToTerm.size()];
@@ -395,7 +395,7 @@ public class TermAutomatonQuery extends Query {
 
           TermsEnum termsEnum = context.reader().terms(field).iterator();
           termsEnum.seekExact(term, state);
-          enums[ent.getKey()] = new EnumAndScorer(ent.getKey(), termsEnum.postings(acceptDocs, null, PostingsEnum.POSITIONS));
+          enums[ent.getKey()] = new EnumAndScorer(ent.getKey(), termsEnum.postings(null, PostingsEnum.POSITIONS));
         }
       }
 
diff --git a/lucene/sandbox/src/test/org/apache/lucene/codecs/idversion/TestIDVersionPostingsFormat.java b/lucene/sandbox/src/test/org/apache/lucene/codecs/idversion/TestIDVersionPostingsFormat.java
index de2451a..d85a36e 100644
--- a/lucene/sandbox/src/test/org/apache/lucene/codecs/idversion/TestIDVersionPostingsFormat.java
+++ b/lucene/sandbox/src/test/org/apache/lucene/codecs/idversion/TestIDVersionPostingsFormat.java
@@ -330,9 +330,9 @@ public class TestIDVersionPostingsFormat extends LuceneTestCase {
           if (VERBOSE) {
             System.out.println("  found in seg=" + termsEnums[seg]);
           }
-          postingsEnums[seg] = termsEnums[seg].postings(liveDocs[seg], postingsEnums[seg], 0);
+          postingsEnums[seg] = termsEnums[seg].postings(postingsEnums[seg], 0);
           int docID = postingsEnums[seg].nextDoc();
-          if (docID != PostingsEnum.NO_MORE_DOCS) {
+          if (docID != PostingsEnum.NO_MORE_DOCS && (liveDocs[seg] == null || liveDocs[seg].get(docID))) {
             lastVersion = ((IDVersionSegmentTermsEnum) termsEnums[seg]).getVersion();
             return docBases[seg] + docID;
           }
diff --git a/lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/DuplicateFilterTest.java b/lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/DuplicateFilterTest.java
index 42f151d..18fba7b 100644
--- a/lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/DuplicateFilterTest.java
+++ b/lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/DuplicateFilterTest.java
@@ -155,7 +155,6 @@ public class DuplicateFilterTest extends LuceneTestCase {
       PostingsEnum td = TestUtil.docs(random(), reader,
           KEY_FIELD,
           new BytesRef(url),
-          MultiFields.getLiveDocs(reader),
           null,
           0);
 
@@ -183,7 +182,6 @@ public class DuplicateFilterTest extends LuceneTestCase {
       PostingsEnum td = TestUtil.docs(random(), reader,
           KEY_FIELD,
           new BytesRef(url),
-          MultiFields.getLiveDocs(reader),
           null,
           0);
 
diff --git a/lucene/sandbox/src/test/org/apache/lucene/search/TestDocValuesRangeQuery.java b/lucene/sandbox/src/test/org/apache/lucene/search/TestDocValuesRangeQuery.java
index 5a71d71..b6cf38f 100644
--- a/lucene/sandbox/src/test/org/apache/lucene/search/TestDocValuesRangeQuery.java
+++ b/lucene/sandbox/src/test/org/apache/lucene/search/TestDocValuesRangeQuery.java
@@ -268,12 +268,12 @@ public class TestDocValuesRangeQuery extends LuceneTestCase {
 
     Query q1 = DocValuesRangeQuery.newLongRange("dv1", 0L, 100L, random().nextBoolean(), random().nextBoolean());
     Weight w = searcher.createNormalizedWeight(q1, true);
-    Scorer s = w.scorer(ctx, null);
+    Scorer s = w.scorer(ctx);
     assertNotNull(s.asTwoPhaseIterator());
 
     Query q2 = DocValuesRangeQuery.newBytesRefRange("dv2", toSortableBytes(0L), toSortableBytes(100L), random().nextBoolean(), random().nextBoolean());
     w = searcher.createNormalizedWeight(q2, true);
-    s = w.scorer(ctx, null);
+    s = w.scorer(ctx);
     assertNotNull(s.asTwoPhaseIterator());
 
     reader.close();
diff --git a/lucene/spatial/src/java/org/apache/lucene/spatial/composite/CompositeVerifyQuery.java b/lucene/spatial/src/java/org/apache/lucene/spatial/composite/CompositeVerifyQuery.java
index 23c7c39..0db2c0d 100644
--- a/lucene/spatial/src/java/org/apache/lucene/spatial/composite/CompositeVerifyQuery.java
+++ b/lucene/spatial/src/java/org/apache/lucene/spatial/composite/CompositeVerifyQuery.java
@@ -94,9 +94,9 @@ public class CompositeVerifyQuery extends Query {
     return new ConstantScoreWeight(this) {
 
       @Override
-      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+      public Scorer scorer(LeafReaderContext context) throws IOException {
 
-        final Scorer indexQueryScorer = indexQueryWeight.scorer(context, acceptDocs);//pass acceptDocs through
+        final Scorer indexQueryScorer = indexQueryWeight.scorer(context);
         if (indexQueryScorer == null) {
           return null;
         }
diff --git a/lucene/spatial/src/java/org/apache/lucene/spatial/composite/IntersectsRPTVerifyQuery.java b/lucene/spatial/src/java/org/apache/lucene/spatial/composite/IntersectsRPTVerifyQuery.java
index 394428a..6c2de82 100644
--- a/lucene/spatial/src/java/org/apache/lucene/spatial/composite/IntersectsRPTVerifyQuery.java
+++ b/lucene/spatial/src/java/org/apache/lucene/spatial/composite/IntersectsRPTVerifyQuery.java
@@ -90,10 +90,10 @@ public class IntersectsRPTVerifyQuery extends Query {
 
     return new ConstantScoreWeight(this) {
       @Override
-      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+      public Scorer scorer(LeafReaderContext context) throws IOException {
         // Compute approx & exact
         final IntersectsDifferentiatingFilter.IntersectsDifferentiatingVisitor result =
-            intersectsDiffFilter.compute(context, acceptDocs);
+            intersectsDiffFilter.compute(context, null);
         if (result.approxDocIdSet == null) {
           return null;
         }
diff --git a/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/AbstractPrefixTreeFilter.java b/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/AbstractPrefixTreeFilter.java
index c4dd5cf..d1cdf42 100644
--- a/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/AbstractPrefixTreeFilter.java
+++ b/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/AbstractPrefixTreeFilter.java
@@ -20,11 +20,14 @@ package org.apache.lucene.spatial.prefix;
 import java.io.IOException;
 
 import com.spatial4j.core.shape.Shape;
+
+import org.apache.lucene.index.FilterLeafReader.FilterPostingsEnum;
 import org.apache.lucene.index.LeafReader;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.PostingsEnum;
 import org.apache.lucene.index.Terms;
 import org.apache.lucene.index.TermsEnum;
+import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.search.Filter;
 import org.apache.lucene.spatial.prefix.tree.SpatialPrefixTree;
 import org.apache.lucene.util.BitDocIdSet;
@@ -96,15 +99,51 @@ public abstract class AbstractPrefixTreeFilter extends Filter {
 
     protected void collectDocs(BitSet bitSet) throws IOException {
       assert termsEnum != null;
-      postingsEnum = termsEnum.postings(acceptDocs, postingsEnum, PostingsEnum.NONE);
-      bitSet.or(postingsEnum);
+      postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);
+      bitSet.or(wrap(postingsEnum, acceptDocs));
     }
 
     protected void collectDocs(BitDocIdSet.Builder bitSetBuilder) throws IOException {
       assert termsEnum != null;
-      postingsEnum = termsEnum.postings(acceptDocs, postingsEnum, PostingsEnum.NONE);
-      bitSetBuilder.or(postingsEnum);
+      postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);
+      bitSetBuilder.or(wrap(postingsEnum, acceptDocs));
+    }
+  }
+
+  /** Filter the given {@link PostingsEnum} with the given {@link Bits}. */
+  private static PostingsEnum wrap(PostingsEnum iterator, Bits acceptDocs) {
+    if (iterator == null || acceptDocs == null) {
+      return iterator;
     }
+    return new BitsFilteredPostingsEnum(iterator, acceptDocs);
   }
 
+  /** A {@link PostingsEnum} which is filtered by some random-access bits. */
+  private static class BitsFilteredPostingsEnum extends FilterPostingsEnum {
+
+    private final Bits bits;
+
+    private BitsFilteredPostingsEnum(PostingsEnum in, Bits bits) {
+      super(in);
+      this.bits = bits;
+    }
+
+    private int doNext(int doc) throws IOException {
+      while (doc != NO_MORE_DOCS && bits.get(doc) == false) {
+        doc = in.nextDoc();
+      }
+      return doc;
+    }
+
+    @Override
+    public int nextDoc() throws IOException {
+      return doNext(in.nextDoc());
+    }
+
+    @Override
+    public int advance(int target) throws IOException {
+      return doNext(in.advance(target));
+    }
+
+  }
 }
diff --git a/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/ContainsPrefixTreeFilter.java b/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/ContainsPrefixTreeFilter.java
index 994e690..22bc225 100644
--- a/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/ContainsPrefixTreeFilter.java
+++ b/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/ContainsPrefixTreeFilter.java
@@ -218,9 +218,12 @@ public class ContainsPrefixTreeFilter extends AbstractPrefixTreeFilter {
     private SmallDocSet collectDocs(Bits acceptContains) throws IOException {
       SmallDocSet set = null;
 
-      postingsEnum = termsEnum.postings(acceptContains, postingsEnum, PostingsEnum.NONE);
+      postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);
       int docid;
       while ((docid = postingsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
+        if (acceptContains != null && acceptContains.get(docid) == false) {
+          continue;
+        }
         if (set == null) {
           int size = termsEnum.docFreq();
           if (size <= 0)
diff --git a/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/PrefixTreeFacetCounter.java b/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/PrefixTreeFacetCounter.java
index 05156dd..03e362a 100644
--- a/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/PrefixTreeFacetCounter.java
+++ b/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/PrefixTreeFacetCounter.java
@@ -183,8 +183,11 @@ public class PrefixTreeFacetCounter {
               return termsEnum.docFreq();
             }
             int count = 0;
-            postingsEnum = termsEnum.postings(acceptDocs, postingsEnum, PostingsEnum.NONE);
+            postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);
             while (postingsEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
+              if (acceptDocs != null && acceptDocs.get(postingsEnum.docID()) == false) {
+                continue;
+              }
               count++;
             }
             return count;
@@ -194,8 +197,12 @@ public class PrefixTreeFacetCounter {
             if (acceptDocs == null) {
               return true;
             }
-            postingsEnum = termsEnum.postings(acceptDocs, postingsEnum, PostingsEnum.NONE);
-            return (postingsEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
+            postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);
+            int nextDoc = postingsEnum.nextDoc();
+            while (nextDoc != DocIdSetIterator.NO_MORE_DOCS && acceptDocs.get(nextDoc) == false) {
+              nextDoc = postingsEnum.nextDoc();
+            }
+            return nextDoc != DocIdSetIterator.NO_MORE_DOCS;
           }
 
         }.getDocIdSet();
diff --git a/lucene/spatial/src/java/org/apache/lucene/spatial/util/ShapeFieldCacheProvider.java b/lucene/spatial/src/java/org/apache/lucene/spatial/util/ShapeFieldCacheProvider.java
index 6287f72..a57460d 100644
--- a/lucene/spatial/src/java/org/apache/lucene/spatial/util/ShapeFieldCacheProvider.java
+++ b/lucene/spatial/src/java/org/apache/lucene/spatial/util/ShapeFieldCacheProvider.java
@@ -69,7 +69,7 @@ public abstract class ShapeFieldCacheProvider<T extends Shape> {
       while (term != null) {
         T shape = readShape(term);
         if( shape != null ) {
-          docs = te.postings(null, docs, PostingsEnum.NONE);
+          docs = te.postings(docs, PostingsEnum.NONE);
           Integer docid = docs.nextDoc();
           while (docid != DocIdSetIterator.NO_MORE_DOCS) {
             idx.add( docid, shape );
diff --git a/lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggester.java b/lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggester.java
index ce5edc0..eb48581 100644
--- a/lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggester.java
+++ b/lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggester.java
@@ -270,7 +270,7 @@ public class BlendedInfixSuggester extends AnalyzingInfixSuggester {
 
       if (matchedTokens.contains(docTerm) || (prefixToken != null && docTerm.startsWith(prefixToken))) {
  
-        PostingsEnum docPosEnum = it.postings(null, null, PostingsEnum.OFFSETS);
+        PostingsEnum docPosEnum = it.postings(null, PostingsEnum.OFFSETS);
         docPosEnum.nextDoc();
 
         // use the first occurrence of the term
diff --git a/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionFieldsConsumer.java b/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionFieldsConsumer.java
index 5654bb4..c1bf486 100644
--- a/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionFieldsConsumer.java
+++ b/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionFieldsConsumer.java
@@ -196,7 +196,7 @@ final class CompletionFieldsConsumer extends FieldsConsumer {
      * Writes all postings (surface form, weight, document id) for <code>term</code>
      */
     public void write(BytesRef term, TermsEnum termsEnum) throws IOException {
-      postingsEnum = termsEnum.postings(null, postingsEnum, PostingsEnum.PAYLOADS);
+      postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.PAYLOADS);
       builder.startTerm(term);
       int docFreq = 0;
       while (postingsEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
diff --git a/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionScorer.java b/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionScorer.java
index d1b6679..9b5c987 100644
--- a/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionScorer.java
+++ b/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionScorer.java
@@ -30,17 +30,17 @@ import org.apache.lucene.util.automaton.Automaton;
  * appropriate suggester and collecting the results
  * via a collector.
  *
- * {@link #score(LeafCollector, int, int)} is called
+ * {@link #score(LeafCollector, Bits, int, int)} is called
  * for each leaf reader.
  *
- * {@link #accept(int)} and {@link #score(float, float)}
+ * {@link #accept(int,Bits)} and {@link #score(float, float)}
  * is called for every matched completion (i.e. document)
  *
  * @lucene.experimental
  */
 public class CompletionScorer extends BulkScorer {
   private final NRTSuggester suggester;
-  private final Bits acceptDocs;
+  private final Bits filterDocs;
 
   // values accessed by suggester
   /** weight that created this scorer */
@@ -53,22 +53,22 @@ public class CompletionScorer extends BulkScorer {
    * Creates a scorer for a field-specific <code>suggester</code> scoped by <code>acceptDocs</code>
    */
   protected CompletionScorer(final CompletionWeight weight, final NRTSuggester suggester,
-                             final LeafReader reader, final Bits acceptDocs,
+                             final LeafReader reader, final Bits filterDocs,
                              final boolean filtered, final Automaton automaton) throws IOException {
     this.weight = weight;
     this.suggester = suggester;
     this.reader = reader;
     this.automaton = automaton;
     this.filtered = filtered;
-    this.acceptDocs = acceptDocs;
+    this.filterDocs = filterDocs;
   }
 
   @Override
-  public int score(LeafCollector collector, int min, int max) throws IOException {
+  public int score(LeafCollector collector, Bits acceptDocs, int min, int max) throws IOException {
     if (!(collector instanceof TopSuggestDocsCollector)) {
       throw new IllegalArgumentException("collector is not of type TopSuggestDocsCollector");
     }
-    suggester.lookup(this, ((TopSuggestDocsCollector) collector));
+    suggester.lookup(this, acceptDocs, ((TopSuggestDocsCollector) collector));
     return max;
   }
 
@@ -81,9 +81,12 @@ public class CompletionScorer extends BulkScorer {
    * Returns true if a document with <code>docID</code> is accepted,
    * false if the docID maps to a deleted
    * document or has been filtered out
+   * @param liveDocs the {@link Bits} representing live docs, or possibly
+   *                 {@code null} if all docs are live
    */
-  public final boolean accept(int docID) {
-    return acceptDocs == null || acceptDocs.get(docID);
+  public final boolean accept(int docID, Bits liveDocs) {
+    return (filterDocs == null || filterDocs.get(docID))
+        && (liveDocs == null || liveDocs.get(docID));
   }
 
   /**
diff --git a/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionWeight.java b/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionWeight.java
index 6c0ad30..813b283 100644
--- a/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionWeight.java
+++ b/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionWeight.java
@@ -70,7 +70,7 @@ public class CompletionWeight extends Weight {
   }
 
   @Override
-  public BulkScorer bulkScorer(final LeafReaderContext context, Bits acceptDocs) throws IOException {
+  public BulkScorer bulkScorer(final LeafReaderContext context) throws IOException {
     final LeafReader reader = context.reader();
     final Terms terms;
     final NRTSuggester suggester;
@@ -91,7 +91,7 @@ public class CompletionWeight extends Weight {
     DocIdSet docIdSet = null;
     Filter filter = completionQuery.getFilter();
     if (filter != null) {
-      docIdSet = filter.getDocIdSet(context, acceptDocs);
+      docIdSet = filter.getDocIdSet(context, null);
       if (docIdSet == null || docIdSet.iterator() == null) {
         // filter matches no docs in current leave
         return null;
@@ -99,7 +99,7 @@ public class CompletionWeight extends Weight {
         throw new IllegalArgumentException("DocIDSet does not provide random access interface");
       }
     }
-    Bits acceptDocBits = (docIdSet != null) ? docIdSet.bits() : acceptDocs;
+    Bits acceptDocBits = (docIdSet != null) ? docIdSet.bits() : null;
     return new CompletionScorer(this, suggester, reader, acceptDocBits, filter != null, automaton);
   }
 
@@ -134,7 +134,7 @@ public class CompletionWeight extends Weight {
   }
 
   @Override
-  public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+  public Scorer scorer(LeafReaderContext context) throws IOException {
     throw new UnsupportedOperationException();
   }
 
diff --git a/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/NRTSuggester.java b/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/NRTSuggester.java
index 6bbab8d..2db4134 100644
--- a/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/NRTSuggester.java
+++ b/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/NRTSuggester.java
@@ -28,6 +28,7 @@ import org.apache.lucene.store.ByteArrayDataInput;
 import org.apache.lucene.store.ByteArrayDataOutput;
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.util.Accountable;
+import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.CharsRefBuilder;
 import org.apache.lucene.util.fst.ByteSequenceOutputs;
@@ -44,7 +45,7 @@ import static org.apache.lucene.search.suggest.document.NRTSuggester.PayLoadProc
  * <p>
  * NRTSuggester executes Top N search on a weighted FST specified by a {@link CompletionScorer}
  * <p>
- * See {@link #lookup(CompletionScorer, TopSuggestDocsCollector)} for more implementation
+ * See {@link #lookup(CompletionScorer, Bits, TopSuggestDocsCollector)} for more implementation
  * details.
  * <p>
  * FST Format:
@@ -56,7 +57,7 @@ import static org.apache.lucene.search.suggest.document.NRTSuggester.PayLoadProc
  * NOTE:
  * <ul>
  *   <li>having too many deletions or using a very restrictive filter can make the search inadmissible due to
- *     over-pruning of potential paths. See {@link CompletionScorer#accept(int)}</li>
+ *     over-pruning of potential paths. See {@link CompletionScorer#accept(int, Bits)}</li>
  *   <li>when matched documents are arbitrarily filtered ({@link CompletionScorer#filtered} set to <code>true</code>,
  *     it is assumed that the filter will roughly filter out half the number of documents that match
  *     the provided automaton</li>
@@ -120,12 +121,12 @@ public final class NRTSuggester implements Accountable {
    * The {@link CompletionScorer#automaton} is intersected with the {@link #fst}.
    * {@link CompletionScorer#weight} is used to compute boosts and/or extract context
    * for each matched partial paths. A top N search is executed on {@link #fst} seeded with
-   * the matched partial paths. Upon reaching a completed path, {@link CompletionScorer#accept(int)}
+   * the matched partial paths. Upon reaching a completed path, {@link CompletionScorer#accept(int, Bits)}
    * and {@link CompletionScorer#score(float, float)} is used on the document id, index weight
    * and query boost to filter and score the entry, before being collected via
    * {@link TopSuggestDocsCollector#collect(int, CharSequence, CharSequence, float)}
    */
-  public void lookup(final CompletionScorer scorer, final TopSuggestDocsCollector collector) throws IOException {
+  public void lookup(final CompletionScorer scorer, Bits acceptDocs, final TopSuggestDocsCollector collector) throws IOException {
     final double liveDocsRatio = calculateLiveDocRatio(scorer.reader.numDocs(), scorer.reader.maxDoc());
     if (liveDocsRatio == -1) {
       return;
@@ -143,7 +144,7 @@ public final class NRTSuggester implements Accountable {
       protected boolean acceptResult(Util.FSTPath<Pair<Long, BytesRef>> path) {
         int payloadSepIndex = parseSurfaceForm(path.cost.output2, payloadSep, spare);
         int docID = parseDocID(path.cost.output2, payloadSepIndex);
-        if (!scorer.accept(docID)) {
+        if (!scorer.accept(docID, acceptDocs)) {
           return false;
         }
         try {
diff --git a/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/SuggestIndexSearcher.java b/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/SuggestIndexSearcher.java
index 17b30ce..25566dc 100644
--- a/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/SuggestIndexSearcher.java
+++ b/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/SuggestIndexSearcher.java
@@ -70,10 +70,10 @@ public class SuggestIndexSearcher extends IndexSearcher {
     query = (CompletionQuery) query.rewrite(getIndexReader());
     Weight weight = query.createWeight(this, collector.needsScores());
     for (LeafReaderContext context : getIndexReader().leaves()) {
-      BulkScorer scorer = weight.bulkScorer(context, context.reader().getLiveDocs());
+      BulkScorer scorer = weight.bulkScorer(context);
       if (scorer != null) {
         try {
-          scorer.score(collector.getLeafCollector(context));
+          scorer.score(collector.getLeafCollector(context), context.reader().getLiveDocs());
         } catch (CollectionTerminatedException e) {
           // collection was terminated prematurely
           // continue with the following leaf
diff --git a/lucene/test-framework/src/java/org/apache/lucene/codecs/asserting/AssertingPostingsFormat.java b/lucene/test-framework/src/java/org/apache/lucene/codecs/asserting/AssertingPostingsFormat.java
index a5165a2..03fd23a 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/codecs/asserting/AssertingPostingsFormat.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/codecs/asserting/AssertingPostingsFormat.java
@@ -187,7 +187,7 @@ public final class AssertingPostingsFormat extends PostingsFormat {
             if (hasFreqs) {
               flags = flags | PostingsEnum.FREQS;
             }
-            postingsEnum = termsEnum.postings(null, postingsEnum, flags);
+            postingsEnum = termsEnum.postings(postingsEnum, flags);
           } else {
             flags = PostingsEnum.POSITIONS;
             if (hasPayloads) {
@@ -196,7 +196,7 @@ public final class AssertingPostingsFormat extends PostingsFormat {
             if (hasOffsets) {
               flags = flags | PostingsEnum.OFFSETS;
             }
-            postingsEnum = termsEnum.postings(null, postingsEnum, flags);
+            postingsEnum = termsEnum.postings(postingsEnum, flags);
           }
 
           assert postingsEnum != null : "termsEnum=" + termsEnum + " hasPositions=" + hasPositions;
diff --git a/lucene/test-framework/src/java/org/apache/lucene/codecs/ramonly/RAMOnlyPostingsFormat.java b/lucene/test-framework/src/java/org/apache/lucene/codecs/ramonly/RAMOnlyPostingsFormat.java
index 2d89783..3e6d191 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/codecs/ramonly/RAMOnlyPostingsFormat.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/codecs/ramonly/RAMOnlyPostingsFormat.java
@@ -47,7 +47,6 @@ import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.store.IndexOutput;
 import org.apache.lucene.util.Accountable;
 import org.apache.lucene.util.Accountables;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.IOUtils;
@@ -284,7 +283,7 @@ public final class RAMOnlyPostingsFormat extends PostingsFormat {
             break;
           }
           RAMPostingsWriterImpl postingsWriter = termsConsumer.startTerm(term);
-          postingsEnum = termsEnum.postings(null, postingsEnum, enumFlags);
+          postingsEnum = termsEnum.postings(postingsEnum, enumFlags);
 
           int docFreq = 0;
           long totalTermFreq = 0;
@@ -470,22 +469,20 @@ public final class RAMOnlyPostingsFormat extends PostingsFormat {
     }
 
     @Override
-    public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) {
-      return new RAMDocsEnum(ramField.termToDocs.get(current), liveDocs);
+    public PostingsEnum postings(PostingsEnum reuse, int flags) {
+      return new RAMDocsEnum(ramField.termToDocs.get(current));
     }
 
   }
 
   private static class RAMDocsEnum extends PostingsEnum {
     private final RAMTerm ramTerm;
-    private final Bits liveDocs;
     private RAMDoc current;
     int upto = -1;
     int posUpto = 0;
 
-    public RAMDocsEnum(RAMTerm ramTerm, Bits liveDocs) {
+    public RAMDocsEnum(RAMTerm ramTerm) {
       this.ramTerm = ramTerm;
-      this.liveDocs = liveDocs;
     }
 
     @Override
@@ -496,17 +493,13 @@ public final class RAMOnlyPostingsFormat extends PostingsFormat {
     // TODO: override bulk read, for better perf
     @Override
     public int nextDoc() {
-      while(true) {
-        upto++;
-        if (upto < ramTerm.docs.size()) {
-          current = ramTerm.docs.get(upto);
-          if (liveDocs == null || liveDocs.get(current.docID)) {
-            posUpto = 0;
-            return current.docID;
-          }
-        } else {
-          return NO_MORE_DOCS;
-        }
+      upto++;
+      if (upto < ramTerm.docs.size()) {
+        current = ramTerm.docs.get(upto);
+        posUpto = 0;
+        return current.docID;
+      } else {
+        return NO_MORE_DOCS;
       }
     }
 
diff --git a/lucene/test-framework/src/java/org/apache/lucene/index/AssertingLeafReader.java b/lucene/test-framework/src/java/org/apache/lucene/index/AssertingLeafReader.java
index bf8eee6..bd8141a 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/index/AssertingLeafReader.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/index/AssertingLeafReader.java
@@ -143,7 +143,7 @@ public class AssertingLeafReader extends FilterLeafReader {
     }
 
     @Override
-    public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
+    public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
       assertThread("Terms enums", creationThread);
       assert state == State.POSITIONED: "docs(...) called on unpositioned TermsEnum";
 
@@ -154,7 +154,7 @@ public class AssertingLeafReader extends FilterLeafReader {
       } else {
         actualReuse = null;
       }
-      PostingsEnum docs = super.postings(liveDocs, actualReuse, flags);
+      PostingsEnum docs = super.postings(actualReuse, flags);
       assert docs != null;
       if (docs == actualReuse) {
         // codec reused, reset asserting state
diff --git a/lucene/test-framework/src/java/org/apache/lucene/index/BasePostingsFormatTestCase.java b/lucene/test-framework/src/java/org/apache/lucene/index/BasePostingsFormatTestCase.java
index 0ef23a2..b1bf6b7 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/index/BasePostingsFormatTestCase.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/index/BasePostingsFormatTestCase.java
@@ -176,8 +176,8 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
   }
 
   protected static void checkReuse(TermsEnum termsEnum, int firstFlags, int secondFlags, boolean shouldReuse) throws IOException {
-    PostingsEnum postings1 = termsEnum.postings(null, null, firstFlags);
-    PostingsEnum postings2 = termsEnum.postings(null, postings1, secondFlags);
+    PostingsEnum postings1 = termsEnum.postings(null, firstFlags);
+    PostingsEnum postings2 = termsEnum.postings(postings1, secondFlags);
     if (shouldReuse)
       assertSame("Expected PostingsEnum " + postings1.getClass().getName() + " to be reused", postings1, postings2);
     else
@@ -247,7 +247,7 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
     LeafReader ar = getOnlySegmentReader(ir);
     TermsEnum termsEnum = ar.terms("field").iterator();
     assertTrue(termsEnum.seekExact(new BytesRef("value")));
-    PostingsEnum docsEnum = termsEnum.postings(null, null, PostingsEnum.NONE);
+    PostingsEnum docsEnum = termsEnum.postings(null, PostingsEnum.NONE);
     assertEquals(0, docsEnum.nextDoc());
     assertEquals(1, docsEnum.freq());
     assertEquals(1, docsEnum.nextDoc());
@@ -270,7 +270,7 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
     LeafReader ar = getOnlySegmentReader(ir);
     TermsEnum termsEnum = ar.terms("field").iterator();
     assertTrue(termsEnum.seekExact(new BytesRef("value")));
-    PostingsEnum docsEnum = termsEnum.postings(null, null, PostingsEnum.POSITIONS);
+    PostingsEnum docsEnum = termsEnum.postings(null, PostingsEnum.POSITIONS);
     assertEquals(0, docsEnum.nextDoc());
     assertEquals(1, docsEnum.freq());
     assertEquals(1, docsEnum.nextDoc());
@@ -306,7 +306,7 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
       TermsEnum termsEnum = terms.iterator();
       BytesRef term = termsEnum.next();
       if (term != null) {
-        PostingsEnum postingsEnum = termsEnum.postings(null, null);
+        PostingsEnum postingsEnum = termsEnum.postings(null);
         assertTrue(postingsEnum.nextDoc() == PostingsEnum.NO_MORE_DOCS);
       }
     }
@@ -398,9 +398,9 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
                       // TODO: also sometimes ask for payloads/offsets?
                       boolean noPositions = random().nextBoolean();
                       if (noPositions) {
-                        docs = termsEnum.postings(null, docs, PostingsEnum.FREQS);
+                        docs = termsEnum.postings(docs, PostingsEnum.FREQS);
                       } else {
-                        docs = termsEnum.postings(null, null, PostingsEnum.POSITIONS);
+                        docs = termsEnum.postings(null, PostingsEnum.POSITIONS);
                       }
                       int docFreq = 0;
                       long totalTermFreq = 0;
@@ -447,9 +447,9 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
                         // TODO: also sometimes ask for payloads/offsets?
                         boolean noPositions = random().nextBoolean();
                         if (noPositions) {
-                          docs = termsEnum.postings(null, docs, PostingsEnum.FREQS);
+                          docs = termsEnum.postings(docs, PostingsEnum.FREQS);
                         } else {
-                          docs = termsEnum.postings(null, null, PostingsEnum.POSITIONS);
+                          docs = termsEnum.postings(null, PostingsEnum.POSITIONS);
                         }
 
                         int docFreq = 0;
@@ -579,7 +579,7 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
     // termsenum reuse (FREQS)
     TermsEnum termsEnum = getOnlySegmentReader(reader).terms("foo").iterator();
     termsEnum.seekExact(new BytesRef("bar"));
-    PostingsEnum postings2 = termsEnum.postings(null, postings);
+    PostingsEnum postings2 = termsEnum.postings(postings);
     assertNotNull(postings2);
     assertReused("foo", postings, postings2);
     // and it had better work
@@ -590,13 +590,13 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
     
     // asking for any flags: ok
     for (int flag : new int[] { NONE, FREQS, POSITIONS, PAYLOADS, OFFSETS, ALL }) {
-      postings = termsEnum.postings(null, null, flag);
+      postings = termsEnum.postings(null, flag);
       assertEquals(-1, postings.docID());
       assertEquals(0, postings.nextDoc());
       assertEquals(1, postings.freq());
       assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());
       // reuse that too
-      postings2 = termsEnum.postings(null, postings, flag);
+      postings2 = termsEnum.postings(postings, flag);
       assertNotNull(postings2);
       assertReused("foo", postings, postings2);
       // and it had better work
@@ -637,7 +637,7 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
     // termsenum reuse (FREQS)
     TermsEnum termsEnum = getOnlySegmentReader(reader).terms("foo").iterator();
     termsEnum.seekExact(new BytesRef("bar"));
-    PostingsEnum postings2 = termsEnum.postings(null, postings);
+    PostingsEnum postings2 = termsEnum.postings(postings);
     assertNotNull(postings2);
     assertReused("foo", postings, postings2);
     // and it had better work
@@ -647,14 +647,14 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings2.nextDoc());
     
     // asking for docs only: ok
-    PostingsEnum docsOnly = termsEnum.postings(null, null, PostingsEnum.NONE);
+    PostingsEnum docsOnly = termsEnum.postings(null, PostingsEnum.NONE);
     assertEquals(-1, docsOnly.docID());
     assertEquals(0, docsOnly.nextDoc());
     // we don't define what it is, but if its something else, we should look into it?
     assertTrue(docsOnly.freq() == 1 || docsOnly.freq() == 2);
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly.nextDoc());
     // reuse that too
-    PostingsEnum docsOnly2 = termsEnum.postings(null, docsOnly, PostingsEnum.NONE);
+    PostingsEnum docsOnly2 = termsEnum.postings(docsOnly, PostingsEnum.NONE);
     assertNotNull(docsOnly2);
     assertReused("foo", docsOnly, docsOnly2);
     // and it had better work
@@ -666,7 +666,7 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
     
     // asking for any flags: ok
     for (int flag : new int[] { NONE, FREQS, POSITIONS, PAYLOADS, OFFSETS, ALL }) {
-      postings = termsEnum.postings(null, null, flag);
+      postings = termsEnum.postings(null, flag);
       assertEquals(-1, postings.docID());
       assertEquals(0, postings.nextDoc());
       if (flag != NONE) {
@@ -674,7 +674,7 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
       }
       assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());
       // reuse that too
-      postings2 = termsEnum.postings(null, postings, flag);
+      postings2 = termsEnum.postings(postings, flag);
       assertNotNull(postings2);
       assertReused("foo", postings, postings2);
       // and it had better work
@@ -715,7 +715,7 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
     // termsenum reuse (FREQS)
     TermsEnum termsEnum = getOnlySegmentReader(reader).terms("foo").iterator();
     termsEnum.seekExact(new BytesRef("bar"));
-    PostingsEnum postings2 = termsEnum.postings(null, postings);
+    PostingsEnum postings2 = termsEnum.postings(postings);
     assertNotNull(postings2);
     assertReused("foo", postings, postings2);
     // and it had better work
@@ -725,14 +725,14 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings2.nextDoc());
     
     // asking for docs only: ok
-    PostingsEnum docsOnly = termsEnum.postings(null, null, PostingsEnum.NONE);
+    PostingsEnum docsOnly = termsEnum.postings(null, PostingsEnum.NONE);
     assertEquals(-1, docsOnly.docID());
     assertEquals(0, docsOnly.nextDoc());
     // we don't define what it is, but if its something else, we should look into it?
     assertTrue(docsOnly.freq() == 1 || docsOnly.freq() == 2);
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly.nextDoc());
     // reuse that too
-    PostingsEnum docsOnly2 = termsEnum.postings(null, docsOnly, PostingsEnum.NONE);
+    PostingsEnum docsOnly2 = termsEnum.postings(docsOnly, PostingsEnum.NONE);
     assertNotNull(docsOnly2);
     assertReused("foo", docsOnly, docsOnly2);
     // and it had better work
@@ -758,7 +758,7 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     
     // now reuse the positions
-    PostingsEnum docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.POSITIONS);
+    PostingsEnum docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.POSITIONS);
     assertReused("foo", docsAndPositionsEnum, docsAndPositionsEnum2);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
@@ -790,7 +790,7 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
     assertNull(docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     // reuse
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.PAYLOADS);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.PAYLOADS);
     assertReused("foo", docsAndPositionsEnum, docsAndPositionsEnum2);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
@@ -820,7 +820,7 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
     assertNull(docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     // reuse
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.OFFSETS);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.OFFSETS);
     assertReused("foo", docsAndPositionsEnum, docsAndPositionsEnum2);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
@@ -849,7 +849,7 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
     assertEquals(-1, docsAndPositionsEnum.endOffset());
     assertNull(docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.ALL);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.ALL);
     assertReused("foo", docsAndPositionsEnum, docsAndPositionsEnum2);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
@@ -895,7 +895,7 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
     // termsenum reuse (FREQS)
     TermsEnum termsEnum = getOnlySegmentReader(reader).terms("foo").iterator();
     termsEnum.seekExact(new BytesRef("bar"));
-    PostingsEnum postings2 = termsEnum.postings(null, postings);
+    PostingsEnum postings2 = termsEnum.postings(postings);
     assertNotNull(postings2);
     assertReused("foo", postings, postings2);
     // and it had better work
@@ -905,14 +905,14 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings2.nextDoc());
     
     // asking for docs only: ok
-    PostingsEnum docsOnly = termsEnum.postings(null, null, PostingsEnum.NONE);
+    PostingsEnum docsOnly = termsEnum.postings(null, PostingsEnum.NONE);
     assertEquals(-1, docsOnly.docID());
     assertEquals(0, docsOnly.nextDoc());
     // we don't define what it is, but if its something else, we should look into it?
     assertTrue(docsOnly.freq() == 1 || docsOnly.freq() == 2);
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly.nextDoc());
     // reuse that too
-    PostingsEnum docsOnly2 = termsEnum.postings(null, docsOnly, PostingsEnum.NONE);
+    PostingsEnum docsOnly2 = termsEnum.postings(docsOnly, PostingsEnum.NONE);
     assertNotNull(docsOnly2);
     assertReused("foo", docsOnly, docsOnly2);
     // and it had better work
@@ -940,7 +940,7 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     
     // now reuse the positions
-    PostingsEnum docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.POSITIONS);
+    PostingsEnum docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.POSITIONS);
     assertReused("foo", docsAndPositionsEnum, docsAndPositionsEnum2);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
@@ -976,7 +976,7 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
     assertNull(docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     // reuse
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.PAYLOADS);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.PAYLOADS);
     assertReused("foo", docsAndPositionsEnum, docsAndPositionsEnum2);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
@@ -1008,7 +1008,7 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
     assertNull(docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     // reuse
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.OFFSETS);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.OFFSETS);
     assertReused("foo", docsAndPositionsEnum, docsAndPositionsEnum2);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
@@ -1037,7 +1037,7 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
     assertEquals(7, docsAndPositionsEnum.endOffset());
     assertNull(docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.ALL);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.ALL);
     assertReused("foo", docsAndPositionsEnum, docsAndPositionsEnum2);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
@@ -1080,7 +1080,7 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
     // termsenum reuse (FREQS)
     TermsEnum termsEnum = getOnlySegmentReader(reader).terms("foo").iterator();
     termsEnum.seekExact(new BytesRef("bar"));
-    PostingsEnum postings2 = termsEnum.postings(null, postings);
+    PostingsEnum postings2 = termsEnum.postings(postings);
     assertNotNull(postings2);
     assertReused("foo", postings, postings2);
     // and it had better work
@@ -1090,14 +1090,14 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings2.nextDoc());
     
     // asking for docs only: ok
-    PostingsEnum docsOnly = termsEnum.postings(null, null, PostingsEnum.NONE);
+    PostingsEnum docsOnly = termsEnum.postings(null, PostingsEnum.NONE);
     assertEquals(-1, docsOnly.docID());
     assertEquals(0, docsOnly.nextDoc());
     // we don't define what it is, but if its something else, we should look into it?
     assertTrue(docsOnly.freq() == 1 || docsOnly.freq() == 2);
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly.nextDoc());
     // reuse that too
-    PostingsEnum docsOnly2 = termsEnum.postings(null, docsOnly, PostingsEnum.NONE);
+    PostingsEnum docsOnly2 = termsEnum.postings(docsOnly, PostingsEnum.NONE);
     assertNotNull(docsOnly2);
     assertReused("foo", docsOnly, docsOnly2);
     // and it had better work
@@ -1125,7 +1125,7 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     
     // now reuse the positions
-    PostingsEnum docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.POSITIONS);
+    PostingsEnum docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.POSITIONS);
     assertReused("foo", docsAndPositionsEnum, docsAndPositionsEnum2);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
@@ -1158,7 +1158,7 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
     assertEquals(new BytesRef("pay2"), docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     // reuse
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.PAYLOADS);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.PAYLOADS);
     assertReused("foo", docsAndPositionsEnum, docsAndPositionsEnum2);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
@@ -1190,7 +1190,7 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
     assertTrue(docsAndPositionsEnum.getPayload() == null || new BytesRef("pay2").equals(docsAndPositionsEnum.getPayload()));
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     // reuse
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.OFFSETS);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.OFFSETS);
     assertReused("foo", docsAndPositionsEnum, docsAndPositionsEnum2);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
@@ -1221,7 +1221,7 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
     assertEquals(-1, docsAndPositionsEnum.endOffset());
     assertEquals(new BytesRef("pay2"), docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.ALL);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.ALL);
     assertReused("foo", docsAndPositionsEnum, docsAndPositionsEnum2);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
@@ -1266,7 +1266,7 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
     // termsenum reuse (FREQS)
     TermsEnum termsEnum = getOnlySegmentReader(reader).terms("foo").iterator();
     termsEnum.seekExact(new BytesRef("bar"));
-    PostingsEnum postings2 = termsEnum.postings(null, postings);
+    PostingsEnum postings2 = termsEnum.postings(postings);
     assertNotNull(postings2);
     assertReused("foo", postings, postings2);
     // and it had better work
@@ -1276,14 +1276,14 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings2.nextDoc());
     
     // asking for docs only: ok
-    PostingsEnum docsOnly = termsEnum.postings(null, null, PostingsEnum.NONE);
+    PostingsEnum docsOnly = termsEnum.postings(null, PostingsEnum.NONE);
     assertEquals(-1, docsOnly.docID());
     assertEquals(0, docsOnly.nextDoc());
     // we don't define what it is, but if its something else, we should look into it?
     assertTrue(docsOnly.freq() == 1 || docsOnly.freq() == 2);
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly.nextDoc());
     // reuse that too
-    PostingsEnum docsOnly2 = termsEnum.postings(null, docsOnly, PostingsEnum.NONE);
+    PostingsEnum docsOnly2 = termsEnum.postings(docsOnly, PostingsEnum.NONE);
     assertNotNull(docsOnly2);
     assertReused("foo", docsOnly, docsOnly2);
     // and it had better work
@@ -1313,7 +1313,7 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     
     // now reuse the positions
-    PostingsEnum docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.POSITIONS);
+    PostingsEnum docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.POSITIONS);
     assertReused("foo", docsAndPositionsEnum, docsAndPositionsEnum2);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
@@ -1350,7 +1350,7 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
     assertEquals(new BytesRef("pay2"), docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     // reuse
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.PAYLOADS);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.PAYLOADS);
     assertReused("foo", docsAndPositionsEnum, docsAndPositionsEnum2);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
@@ -1384,7 +1384,7 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
     assertTrue(docsAndPositionsEnum.getPayload() == null || new BytesRef("pay2").equals(docsAndPositionsEnum.getPayload()));
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     // reuse
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.OFFSETS);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.OFFSETS);
     assertReused("foo", docsAndPositionsEnum, docsAndPositionsEnum2);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
@@ -1415,7 +1415,7 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
     assertEquals(7, docsAndPositionsEnum.endOffset());
     assertEquals(new BytesRef("pay2"), docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.ALL);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.ALL);
     assertReused("foo", docsAndPositionsEnum, docsAndPositionsEnum2);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
diff --git a/lucene/test-framework/src/java/org/apache/lucene/index/BaseTermVectorsFormatTestCase.java b/lucene/test-framework/src/java/org/apache/lucene/index/BaseTermVectorsFormatTestCase.java
index e00c67d..9071eab 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/index/BaseTermVectorsFormatTestCase.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/index/BaseTermVectorsFormatTestCase.java
@@ -450,12 +450,8 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
       assertEquals(sortedTerms[i], termsEnum.term());
       assertEquals(1, termsEnum.docFreq());
 
-      final FixedBitSet bits = new FixedBitSet(1);
-      PostingsEnum postingsEnum = termsEnum.postings(bits, random().nextBoolean() ? null : this.docsEnum.get());
-      assertEquals(PostingsEnum.NO_MORE_DOCS, postingsEnum.nextDoc());
-      bits.set(0);
-
-      postingsEnum = termsEnum.postings(random().nextBoolean() ? bits : null, random().nextBoolean() ? null : postingsEnum);
+      PostingsEnum postingsEnum = termsEnum.postings(null);
+      postingsEnum = termsEnum.postings(random().nextBoolean() ? null : postingsEnum);
       assertNotNull(postingsEnum);
       assertEquals(0, postingsEnum.nextDoc());
       assertEquals(0, postingsEnum.docID());
@@ -463,14 +459,8 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
       assertEquals(PostingsEnum.NO_MORE_DOCS, postingsEnum.nextDoc());
       this.docsEnum.set(postingsEnum);
 
-      bits.clear(0);
-      PostingsEnum docsAndPositionsEnum = termsEnum.postings(bits, random().nextBoolean() ? null : this.docsEnum.get(), PostingsEnum.POSITIONS);
-      if (terms.hasPositions()) {
-        assertEquals(PostingsEnum.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
-      }
-      bits.set(0);
-
-      docsAndPositionsEnum = termsEnum.postings(random().nextBoolean() ? bits : null, random().nextBoolean() ? null : docsAndPositionsEnum, PostingsEnum.POSITIONS);
+      PostingsEnum docsAndPositionsEnum = termsEnum.postings(null);
+      docsAndPositionsEnum = termsEnum.postings(random().nextBoolean() ? null : docsAndPositionsEnum, PostingsEnum.POSITIONS);
       if (terms.hasPositions() || terms.hasOffsets()) {
         assertEquals(0, docsAndPositionsEnum.nextDoc());
         final int freq = docsAndPositionsEnum.freq();
@@ -778,14 +768,14 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertEquals(new BytesRef("bar"), termsEnum.next());
     
     // simple use (FREQS)
-    PostingsEnum postings = termsEnum.postings(null, null);
+    PostingsEnum postings = termsEnum.postings(null);
     assertEquals(-1, postings.docID());
     assertEquals(0, postings.nextDoc());
     assertEquals(2, postings.freq());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());
     
     // termsenum reuse (FREQS)
-    PostingsEnum postings2 = termsEnum.postings(null, postings);
+    PostingsEnum postings2 = termsEnum.postings(postings);
     assertNotNull(postings2);
     // and it had better work
     assertEquals(-1, postings2.docID());
@@ -794,14 +784,14 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings2.nextDoc());
     
     // asking for docs only: ok
-    PostingsEnum docsOnly = termsEnum.postings(null, null, PostingsEnum.NONE);
+    PostingsEnum docsOnly = termsEnum.postings(null, PostingsEnum.NONE);
     assertEquals(-1, docsOnly.docID());
     assertEquals(0, docsOnly.nextDoc());
     // we don't define what it is, but if its something else, we should look into it?
     assertTrue(docsOnly.freq() == 1 || docsOnly.freq() == 2);
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly.nextDoc());
     // reuse that too
-    PostingsEnum docsOnly2 = termsEnum.postings(null, docsOnly, PostingsEnum.NONE);
+    PostingsEnum docsOnly2 = termsEnum.postings(docsOnly, PostingsEnum.NONE);
     assertNotNull(docsOnly2);
     // and it had better work
     assertEquals(-1, docsOnly2.docID());
@@ -812,7 +802,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     
     // asking for any flags: ok
     for (int flag : new int[] { NONE, FREQS, POSITIONS, PAYLOADS, OFFSETS, ALL }) {
-      postings = termsEnum.postings(null, null, flag);
+      postings = termsEnum.postings(null, flag);
       assertEquals(-1, postings.docID());
       assertEquals(0, postings.nextDoc());
       if (flag != NONE) {
@@ -820,7 +810,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
       }
       assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());
       // reuse that too
-      postings2 = termsEnum.postings(null, postings, flag);
+      postings2 = termsEnum.postings(postings, flag);
       assertNotNull(postings2);
       // and it had better work
       assertEquals(-1, postings2.docID());
@@ -859,14 +849,14 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertEquals(new BytesRef("bar"), termsEnum.next());
     
     // simple use (FREQS)
-    PostingsEnum postings = termsEnum.postings(null, null);
+    PostingsEnum postings = termsEnum.postings(null);
     assertEquals(-1, postings.docID());
     assertEquals(0, postings.nextDoc());
     assertEquals(2, postings.freq());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());
     
     // termsenum reuse (FREQS)
-    PostingsEnum postings2 = termsEnum.postings(null, postings);
+    PostingsEnum postings2 = termsEnum.postings(postings);
     assertNotNull(postings2);
     // and it had better work
     assertEquals(-1, postings2.docID());
@@ -875,14 +865,14 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings2.nextDoc());
     
     // asking for docs only: ok
-    PostingsEnum docsOnly = termsEnum.postings(null, null, PostingsEnum.NONE);
+    PostingsEnum docsOnly = termsEnum.postings(null, PostingsEnum.NONE);
     assertEquals(-1, docsOnly.docID());
     assertEquals(0, docsOnly.nextDoc());
     // we don't define what it is, but if its something else, we should look into it?
     assertTrue(docsOnly.freq() == 1 || docsOnly.freq() == 2);
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly.nextDoc());
     // reuse that too
-    PostingsEnum docsOnly2 = termsEnum.postings(null, docsOnly, PostingsEnum.NONE);
+    PostingsEnum docsOnly2 = termsEnum.postings(docsOnly, PostingsEnum.NONE);
     assertNotNull(docsOnly2);
     // and it had better work
     assertEquals(-1, docsOnly2.docID());
@@ -892,7 +882,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly2.nextDoc());
     
     // asking for positions, ok
-    PostingsEnum docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.POSITIONS);
+    PostingsEnum docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.POSITIONS);
     assertEquals(-1, docsAndPositionsEnum.docID());
     assertEquals(0, docsAndPositionsEnum.nextDoc());
     assertEquals(2, docsAndPositionsEnum.freq());
@@ -907,7 +897,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     
     // now reuse the positions
-    PostingsEnum docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.POSITIONS);
+    PostingsEnum docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.POSITIONS);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -922,7 +912,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum2.nextDoc());
     
     // payloads, offsets, etc don't cause an error if they aren't there
-    docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.PAYLOADS);
+    docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.PAYLOADS);
     assertNotNull(docsAndPositionsEnum);
     // but make sure they work
     assertEquals(-1, docsAndPositionsEnum.docID());
@@ -938,7 +928,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertNull(docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     // reuse
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.PAYLOADS);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.PAYLOADS);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -952,7 +942,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertNull(docsAndPositionsEnum2.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum2.nextDoc());
     
-    docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.OFFSETS);
+    docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.OFFSETS);
     assertNotNull(docsAndPositionsEnum);
     assertEquals(-1, docsAndPositionsEnum.docID());
     assertEquals(0, docsAndPositionsEnum.nextDoc());
@@ -967,7 +957,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertNull(docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     // reuse
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.OFFSETS);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.OFFSETS);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -981,7 +971,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertNull(docsAndPositionsEnum2.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum2.nextDoc());
     
-    docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.ALL);
+    docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.ALL);
     assertNotNull(docsAndPositionsEnum);
     assertEquals(-1, docsAndPositionsEnum.docID());
     assertEquals(0, docsAndPositionsEnum.nextDoc());
@@ -995,7 +985,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertEquals(-1, docsAndPositionsEnum.endOffset());
     assertNull(docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.ALL);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.ALL);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -1038,14 +1028,14 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertEquals(new BytesRef("bar"), termsEnum.next());
     
     // simple usage (FREQS)
-    PostingsEnum postings = termsEnum.postings(null, null);
+    PostingsEnum postings = termsEnum.postings(null);
     assertEquals(-1, postings.docID());
     assertEquals(0, postings.nextDoc());
     assertEquals(2, postings.freq());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());
     
     // termsenum reuse (FREQS)
-    PostingsEnum postings2 = termsEnum.postings(null, postings);
+    PostingsEnum postings2 = termsEnum.postings(postings);
     assertNotNull(postings2);
     // and it had better work
     assertEquals(-1, postings2.docID());
@@ -1054,14 +1044,14 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings2.nextDoc());
     
     // asking for docs only: ok
-    PostingsEnum docsOnly = termsEnum.postings(null, null, PostingsEnum.NONE);
+    PostingsEnum docsOnly = termsEnum.postings(null, PostingsEnum.NONE);
     assertEquals(-1, docsOnly.docID());
     assertEquals(0, docsOnly.nextDoc());
     // we don't define what it is, but if its something else, we should look into it?
     assertTrue(docsOnly.freq() == 1 || docsOnly.freq() == 2);
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly.nextDoc());
     // reuse that too
-    PostingsEnum docsOnly2 = termsEnum.postings(null, docsOnly, PostingsEnum.NONE);
+    PostingsEnum docsOnly2 = termsEnum.postings(docsOnly, PostingsEnum.NONE);
     assertNotNull(docsOnly2);
     // and it had better work
     assertEquals(-1, docsOnly2.docID());
@@ -1071,7 +1061,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly2.nextDoc());
     
     // asking for positions, ok
-    PostingsEnum docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.POSITIONS);
+    PostingsEnum docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.POSITIONS);
     assertEquals(-1, docsAndPositionsEnum.docID());
     assertEquals(0, docsAndPositionsEnum.nextDoc());
     assertEquals(2, docsAndPositionsEnum.freq());
@@ -1088,7 +1078,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     
     // now reuse the positions
-    PostingsEnum docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.POSITIONS);
+    PostingsEnum docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.POSITIONS);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -1105,7 +1095,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum2.nextDoc());
     
     // payloads don't cause an error if they aren't there
-    docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.PAYLOADS);
+    docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.PAYLOADS);
     assertNotNull(docsAndPositionsEnum);
     // but make sure they work
     assertEquals(-1, docsAndPositionsEnum.docID());
@@ -1123,7 +1113,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertNull(docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     // reuse
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.PAYLOADS);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.PAYLOADS);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -1139,7 +1129,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertNull(docsAndPositionsEnum2.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum2.nextDoc());
     
-    docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.OFFSETS);
+    docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.OFFSETS);
     assertNotNull(docsAndPositionsEnum);
     assertEquals(-1, docsAndPositionsEnum.docID());
     assertEquals(0, docsAndPositionsEnum.nextDoc());
@@ -1154,7 +1144,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertNull(docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     // reuse
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.OFFSETS);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.OFFSETS);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -1168,7 +1158,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertNull(docsAndPositionsEnum2.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum2.nextDoc());
     
-    docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.ALL);
+    docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.ALL);
     assertNotNull(docsAndPositionsEnum);
     assertEquals(-1, docsAndPositionsEnum.docID());
     assertEquals(0, docsAndPositionsEnum.nextDoc());
@@ -1182,7 +1172,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertEquals(7, docsAndPositionsEnum.endOffset());
     assertNull(docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.ALL);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.ALL);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -1224,14 +1214,14 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertEquals(new BytesRef("bar"), termsEnum.next());
     
     // simple usage (FREQS)
-    PostingsEnum postings = termsEnum.postings(null, null);
+    PostingsEnum postings = termsEnum.postings(null);
     assertEquals(-1, postings.docID());
     assertEquals(0, postings.nextDoc());
     assertEquals(2, postings.freq());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());
     
     // termsenum reuse (FREQS)
-    PostingsEnum postings2 = termsEnum.postings(null, postings);
+    PostingsEnum postings2 = termsEnum.postings(postings);
     assertNotNull(postings2);
     // and it had better work
     assertEquals(-1, postings2.docID());
@@ -1240,14 +1230,14 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings2.nextDoc());
     
     // asking for docs only: ok
-    PostingsEnum docsOnly = termsEnum.postings(null, null, PostingsEnum.NONE);
+    PostingsEnum docsOnly = termsEnum.postings(null, PostingsEnum.NONE);
     assertEquals(-1, docsOnly.docID());
     assertEquals(0, docsOnly.nextDoc());
     // we don't define what it is, but if its something else, we should look into it?
     assertTrue(docsOnly.freq() == 1 || docsOnly.freq() == 2);
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly.nextDoc());
     // reuse that too
-    PostingsEnum docsOnly2 = termsEnum.postings(null, docsOnly, PostingsEnum.NONE);
+    PostingsEnum docsOnly2 = termsEnum.postings(docsOnly, PostingsEnum.NONE);
     assertNotNull(docsOnly2);
     // and it had better work
     assertEquals(-1, docsOnly2.docID());
@@ -1257,7 +1247,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly2.nextDoc());
     
     // asking for positions, ok
-    PostingsEnum docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.POSITIONS);
+    PostingsEnum docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.POSITIONS);
     assertEquals(-1, docsAndPositionsEnum.docID());
     assertEquals(0, docsAndPositionsEnum.nextDoc());
     assertEquals(2, docsAndPositionsEnum.freq());
@@ -1274,7 +1264,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     
     // now reuse the positions
-    PostingsEnum docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.POSITIONS);
+    PostingsEnum docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.POSITIONS);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -1291,7 +1281,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum2.nextDoc());
     
     // payloads don't cause an error if they aren't there
-    docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.PAYLOADS);
+    docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.PAYLOADS);
     assertNotNull(docsAndPositionsEnum);
     // but make sure they work
     assertEquals(-1, docsAndPositionsEnum.docID());
@@ -1309,7 +1299,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertNull(docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     // reuse
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.PAYLOADS);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.PAYLOADS);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -1325,7 +1315,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertNull(docsAndPositionsEnum2.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum2.nextDoc());
     
-    docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.OFFSETS);
+    docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.OFFSETS);
     assertNotNull(docsAndPositionsEnum);
     assertEquals(-1, docsAndPositionsEnum.docID());
     assertEquals(0, docsAndPositionsEnum.nextDoc());
@@ -1340,7 +1330,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertNull(docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     // reuse
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.OFFSETS);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.OFFSETS);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -1354,7 +1344,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertNull(docsAndPositionsEnum2.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum2.nextDoc());
     
-    docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.ALL);
+    docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.ALL);
     assertNotNull(docsAndPositionsEnum);
     assertEquals(-1, docsAndPositionsEnum.docID());
     assertEquals(0, docsAndPositionsEnum.nextDoc());
@@ -1368,7 +1358,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertEquals(7, docsAndPositionsEnum.endOffset());
     assertNull(docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.ALL);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.ALL);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -1410,14 +1400,14 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertEquals(new BytesRef("bar"), termsEnum.next());
     
     // sugar method (FREQS)
-    PostingsEnum postings = termsEnum.postings(null, null);
+    PostingsEnum postings = termsEnum.postings(null);
     assertEquals(-1, postings.docID());
     assertEquals(0, postings.nextDoc());
     assertEquals(2, postings.freq());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());
     
     // termsenum reuse (FREQS)
-    PostingsEnum postings2 = termsEnum.postings(null, postings);
+    PostingsEnum postings2 = termsEnum.postings(postings);
     assertNotNull(postings2);
     // and it had better work
     assertEquals(-1, postings2.docID());
@@ -1426,14 +1416,14 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings2.nextDoc());
     
     // asking for docs only: ok
-    PostingsEnum docsOnly = termsEnum.postings(null, null, PostingsEnum.NONE);
+    PostingsEnum docsOnly = termsEnum.postings(null, PostingsEnum.NONE);
     assertEquals(-1, docsOnly.docID());
     assertEquals(0, docsOnly.nextDoc());
     // we don't define what it is, but if its something else, we should look into it?
     assertTrue(docsOnly.freq() == 1 || docsOnly.freq() == 2);
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly.nextDoc());
     // reuse that too
-    PostingsEnum docsOnly2 = termsEnum.postings(null, docsOnly, PostingsEnum.NONE);
+    PostingsEnum docsOnly2 = termsEnum.postings(docsOnly, PostingsEnum.NONE);
     assertNotNull(docsOnly2);
     // and it had better work
     assertEquals(-1, docsOnly2.docID());
@@ -1443,7 +1433,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly2.nextDoc());
     
     // asking for positions, ok
-    PostingsEnum docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.POSITIONS);
+    PostingsEnum docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.POSITIONS);
     assertEquals(-1, docsAndPositionsEnum.docID());
     assertEquals(0, docsAndPositionsEnum.nextDoc());
     assertEquals(2, docsAndPositionsEnum.freq());
@@ -1460,7 +1450,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     
     // now reuse the positions
-    PostingsEnum docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.POSITIONS);
+    PostingsEnum docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.POSITIONS);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -1477,7 +1467,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum2.nextDoc());
     
     // payloads
-    docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.PAYLOADS);
+    docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.PAYLOADS);
     assertNotNull(docsAndPositionsEnum);
     assertEquals(-1, docsAndPositionsEnum.docID());
     assertEquals(0, docsAndPositionsEnum.nextDoc());
@@ -1492,7 +1482,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertEquals(new BytesRef("pay2"), docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     // reuse
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.PAYLOADS);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.PAYLOADS);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -1506,7 +1496,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertEquals(new BytesRef("pay2"), docsAndPositionsEnum2.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum2.nextDoc());
     
-    docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.OFFSETS);
+    docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.OFFSETS);
     assertNotNull(docsAndPositionsEnum);
     assertEquals(-1, docsAndPositionsEnum.docID());
     assertEquals(0, docsAndPositionsEnum.nextDoc());
@@ -1523,7 +1513,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertTrue(docsAndPositionsEnum.getPayload() == null || new BytesRef("pay2").equals(docsAndPositionsEnum.getPayload()));
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     // reuse
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.OFFSETS);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.OFFSETS);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -1539,7 +1529,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertTrue(docsAndPositionsEnum2.getPayload() == null || new BytesRef("pay2").equals(docsAndPositionsEnum2.getPayload()));
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum2.nextDoc());
     
-    docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.ALL);
+    docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.ALL);
     assertNotNull(docsAndPositionsEnum);
     assertEquals(-1, docsAndPositionsEnum.docID());
     assertEquals(0, docsAndPositionsEnum.nextDoc());
@@ -1553,7 +1543,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertEquals(-1, docsAndPositionsEnum.endOffset());
     assertEquals(new BytesRef("pay2"), docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.ALL);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.ALL);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -1596,14 +1586,14 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertEquals(new BytesRef("bar"), termsEnum.next());
     
     // sugar method (FREQS)
-    PostingsEnum postings = termsEnum.postings(null, null);
+    PostingsEnum postings = termsEnum.postings(null);
     assertEquals(-1, postings.docID());
     assertEquals(0, postings.nextDoc());
     assertEquals(2, postings.freq());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());
     
     // termsenum reuse (FREQS)
-    PostingsEnum postings2 = termsEnum.postings(null, postings);
+    PostingsEnum postings2 = termsEnum.postings(postings);
     assertNotNull(postings2);
     // and it had better work
     assertEquals(-1, postings2.docID());
@@ -1612,14 +1602,14 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings2.nextDoc());
     
     // asking for docs only: ok
-    PostingsEnum docsOnly = termsEnum.postings(null, null, PostingsEnum.NONE);
+    PostingsEnum docsOnly = termsEnum.postings(null, PostingsEnum.NONE);
     assertEquals(-1, docsOnly.docID());
     assertEquals(0, docsOnly.nextDoc());
     // we don't define what it is, but if its something else, we should look into it?
     assertTrue(docsOnly.freq() == 1 || docsOnly.freq() == 2);
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly.nextDoc());
     // reuse that too
-    PostingsEnum docsOnly2 = termsEnum.postings(null, docsOnly, PostingsEnum.NONE);
+    PostingsEnum docsOnly2 = termsEnum.postings(docsOnly, PostingsEnum.NONE);
     assertNotNull(docsOnly2);
     // and it had better work
     assertEquals(-1, docsOnly2.docID());
@@ -1629,7 +1619,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly2.nextDoc());
     
     // asking for positions, ok
-    PostingsEnum docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.POSITIONS);
+    PostingsEnum docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.POSITIONS);
     assertEquals(-1, docsAndPositionsEnum.docID());
     assertEquals(0, docsAndPositionsEnum.nextDoc());
     assertEquals(2, docsAndPositionsEnum.freq());
@@ -1648,7 +1638,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     
     // now reuse the positions
-    PostingsEnum docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.POSITIONS);
+    PostingsEnum docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.POSITIONS);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -1667,7 +1657,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum2.nextDoc());
     
     // payloads
-    docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.PAYLOADS);
+    docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.PAYLOADS);
     assertNotNull(docsAndPositionsEnum);
     assertEquals(-1, docsAndPositionsEnum.docID());
     assertEquals(0, docsAndPositionsEnum.nextDoc());
@@ -1684,7 +1674,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertEquals(new BytesRef("pay2"), docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     // reuse
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.PAYLOADS);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.PAYLOADS);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -1700,7 +1690,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertEquals(new BytesRef("pay2"), docsAndPositionsEnum2.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum2.nextDoc());
     
-    docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.OFFSETS);
+    docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.OFFSETS);
     assertNotNull(docsAndPositionsEnum);
     assertEquals(-1, docsAndPositionsEnum.docID());
     assertEquals(0, docsAndPositionsEnum.nextDoc());
@@ -1717,7 +1707,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertTrue(docsAndPositionsEnum.getPayload() == null || new BytesRef("pay2").equals(docsAndPositionsEnum.getPayload()));
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     // reuse
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.OFFSETS);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.OFFSETS);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -1733,7 +1723,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertTrue(docsAndPositionsEnum2.getPayload() == null || new BytesRef("pay2").equals(docsAndPositionsEnum2.getPayload()));
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum2.nextDoc());
     
-    docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.ALL);
+    docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.ALL);
     assertNotNull(docsAndPositionsEnum);
     assertEquals(-1, docsAndPositionsEnum.docID());
     assertEquals(0, docsAndPositionsEnum.nextDoc());
@@ -1747,7 +1737,7 @@ public abstract class BaseTermVectorsFormatTestCase extends BaseIndexFileFormatT
     assertEquals(7, docsAndPositionsEnum.endOffset());
     assertEquals(new BytesRef("pay2"), docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.ALL);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.ALL);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
diff --git a/lucene/test-framework/src/java/org/apache/lucene/index/PerThreadPKLookup.java b/lucene/test-framework/src/java/org/apache/lucene/index/PerThreadPKLookup.java
index e4014e5..d94395d 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/index/PerThreadPKLookup.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/index/PerThreadPKLookup.java
@@ -78,9 +78,10 @@ public class PerThreadPKLookup {
   public int lookup(BytesRef id) throws IOException {
     for(int seg=0;seg<numSegs;seg++) {
       if (termsEnums[seg].seekExact(id)) {
-        postingsEnums[seg] = termsEnums[seg].postings(liveDocs[seg], postingsEnums[seg], 0);
+        postingsEnums[seg] = termsEnums[seg].postings(postingsEnums[seg], 0);
         int docID = postingsEnums[seg].nextDoc();
-        if (docID != PostingsEnum.NO_MORE_DOCS) {
+        if (docID != PostingsEnum.NO_MORE_DOCS
+            && (liveDocs[seg] == null || liveDocs[seg].get(docID))) {
           return docBases[seg] + docID;
         }
         assert hasDeletions;
diff --git a/lucene/test-framework/src/java/org/apache/lucene/index/RandomPostingsTester.java b/lucene/test-framework/src/java/org/apache/lucene/index/RandomPostingsTester.java
index 18f84ce..8e91db2 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/index/RandomPostingsTester.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/index/RandomPostingsTester.java
@@ -40,9 +40,7 @@ import org.apache.lucene.codecs.FieldsProducer;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.FlushInfo;
 import org.apache.lucene.store.IOContext;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.StringHelper;
@@ -99,8 +97,6 @@ public class RandomPostingsTester {
 
   private FieldInfos fieldInfos;
 
-  private FixedBitSet globalLiveDocs;
-
   List<FieldAndTerm> allTerms;
   private int maxDoc;
 
@@ -169,7 +165,7 @@ public class RandomPostingsTester {
 
         // NOTE: sort of silly: we enum all the docs just to
         // get the maxDoc
-        PostingsEnum postingsEnum = getSeedPostings(term, termSeed, false, globalLiveDocs, IndexOptions.DOCS, true);
+        PostingsEnum postingsEnum = getSeedPostings(term, termSeed, IndexOptions.DOCS, true);
         int doc;
         int lastDoc = 0;
         while((doc = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {
@@ -190,14 +186,6 @@ public class RandomPostingsTester {
     // It's the count, not the last docID:
     maxDoc++;
 
-    globalLiveDocs = new FixedBitSet(maxDoc);
-    double liveRatio = random.nextDouble();
-    for(int i=0;i<maxDoc;i++) {
-      if (random.nextDouble() <= liveRatio) {
-        globalLiveDocs.set(i);
-      }
-    }
-
     allTerms = new ArrayList<>();
     for(Map.Entry<String,SortedMap<BytesRef,SeedAndOrd>> fieldEnt : fields.entrySet()) {
       String field = fieldEnt.getKey();
@@ -212,7 +200,7 @@ public class RandomPostingsTester {
     }
   }
 
-  public static SeedPostings getSeedPostings(String term, long seed, boolean withLiveDocs, Bits globalLiveDocs, IndexOptions options, boolean allowPayloads) {
+  public static SeedPostings getSeedPostings(String term, long seed, IndexOptions options, boolean allowPayloads) {
     int minDocFreq, maxDocFreq;
     if (term.startsWith("big_")) {
       minDocFreq = LuceneTestCase.RANDOM_MULTIPLIER * 50000;
@@ -228,7 +216,7 @@ public class RandomPostingsTester {
       maxDocFreq = 3;
     }
 
-    return new SeedPostings(seed, minDocFreq, maxDocFreq, withLiveDocs ? globalLiveDocs : null, options, allowPayloads);
+    return new SeedPostings(seed, minDocFreq, maxDocFreq, options, allowPayloads);
   }
 
   /** Given the same random seed this always enumerates the
@@ -242,9 +230,7 @@ public class RandomPostingsTester {
     private final int maxDocSpacing;
     private final int payloadSize;
     private final boolean fixedPayloads;
-    private final Bits liveDocs;
     private final BytesRef payload;
-    private final IndexOptions options;
     private final boolean doPositions;
     private final boolean allowPayloads;
 
@@ -259,11 +245,10 @@ public class RandomPostingsTester {
     private int posSpacing;
     private int posUpto;
 
-    public SeedPostings(long seed, int minDocFreq, int maxDocFreq, Bits liveDocs, IndexOptions options, boolean allowPayloads) {
+    public SeedPostings(long seed, int minDocFreq, int maxDocFreq, IndexOptions options, boolean allowPayloads) {
       random = new Random(seed);
       docRandom = new Random(random.nextLong());
       docFreq = TestUtil.nextInt(random, minDocFreq, maxDocFreq);
-      this.liveDocs = liveDocs;
       this.allowPayloads = allowPayloads;
 
       // TODO: more realistic to inversely tie this to numDocs:
@@ -279,7 +264,6 @@ public class RandomPostingsTester {
       fixedPayloads = random.nextBoolean();
       byte[] payloadBytes = new byte[payloadSize];
       payload = new BytesRef(payloadBytes);
-      this.options = options;
       doPositions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS.compareTo(options) <= 0;
     }
 
@@ -287,9 +271,7 @@ public class RandomPostingsTester {
     public int nextDoc() {
       while(true) {
         _nextDoc();
-        if (liveDocs == null || docID == NO_MORE_DOCS || liveDocs.get(docID)) {
-          return docID;
-        }
+        return docID;
       }
     }
 
@@ -601,10 +583,7 @@ public class RandomPostingsTester {
     }
 
     @Override
-    public final PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
-      if (liveDocs != null) {
-        throw new IllegalArgumentException("liveDocs must be null");
-      }
+    public final PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
       if (PostingsEnum.featureRequested(flags, PostingsEnum.POSITIONS)) {
         if (maxAllowed.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {
           return null;
@@ -619,7 +598,7 @@ public class RandomPostingsTester {
       if (PostingsEnum.featureRequested(flags, PostingsEnum.FREQS) && maxAllowed.compareTo(IndexOptions.DOCS_AND_FREQS) < 0) {
         return null;
       }
-      return getSeedPostings(current.getKey().utf8ToString(), current.getValue().seed, false, null, maxAllowed, allowPayloads);
+      return getSeedPostings(current.getKey().utf8ToString(), current.getValue().seed, maxAllowed, allowPayloads);
     }
   }
 
@@ -723,28 +702,11 @@ public class RandomPostingsTester {
     // expected term:
     assertEquals(term, termsEnum.term());
 
-    // 50% of the time time pass liveDocs:
-    boolean useLiveDocs = options.contains(Option.LIVE_DOCS) && random.nextBoolean();
-    Bits liveDocs;
-    if (useLiveDocs) {
-      liveDocs = globalLiveDocs;
-      if (LuceneTestCase.VERBOSE) {
-        System.out.println("  use liveDocs: " + globalLiveDocs.length());
-      }
-    } else {
-      liveDocs = null;
-      if (LuceneTestCase.VERBOSE) {
-        System.out.println("  no liveDocs");
-      }
-    }
-
     FieldInfo fieldInfo = currentFieldInfos.fieldInfo(field);
 
     // NOTE: can be empty list if we are using liveDocs:
     SeedPostings expected = getSeedPostings(term.utf8ToString(), 
                                             fields.get(field).get(term).seed,
-                                            useLiveDocs,
-                                            globalLiveDocs,
                                             maxIndexOptions,
                                             true);
     assertEquals(expected.docFreq, termsEnum.docFreq());
@@ -787,7 +749,7 @@ public class RandomPostingsTester {
           System.out.println("  get DocsEnum (but we won't check positions) flags=" + flags);
         }
 
-        threadState.reusePostingsEnum = termsEnum.postings(liveDocs, prevPostingsEnum, flags);
+        threadState.reusePostingsEnum = termsEnum.postings(prevPostingsEnum, flags);
         postingsEnum = threadState.reusePostingsEnum;
       } else {
         if (LuceneTestCase.VERBOSE) {
@@ -796,7 +758,7 @@ public class RandomPostingsTester {
         if (options.contains(Option.REUSE_ENUMS) && random.nextInt(10) < 9) {
           prevPostingsEnum = threadState.reusePostingsEnum;
         }
-        threadState.reusePostingsEnum = termsEnum.postings(liveDocs, prevPostingsEnum, doCheckFreqs ? PostingsEnum.FREQS : PostingsEnum.NONE);
+        threadState.reusePostingsEnum = termsEnum.postings(prevPostingsEnum, doCheckFreqs ? PostingsEnum.FREQS : PostingsEnum.NONE);
         postingsEnum = threadState.reusePostingsEnum;
       }
     } else {
@@ -816,7 +778,7 @@ public class RandomPostingsTester {
         System.out.println("  get DocsEnum flags=" + flags);
       }
 
-      threadState.reusePostingsEnum = termsEnum.postings(liveDocs, prevPostingsEnum, flags);
+      threadState.reusePostingsEnum = termsEnum.postings(prevPostingsEnum, flags);
       postingsEnum = threadState.reusePostingsEnum;
     }
 
diff --git a/lucene/test-framework/src/java/org/apache/lucene/search/AssertingBulkScorer.java b/lucene/test-framework/src/java/org/apache/lucene/search/AssertingBulkScorer.java
index 71f18ed..07cdd9d 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/search/AssertingBulkScorer.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/search/AssertingBulkScorer.java
@@ -21,6 +21,7 @@ import java.io.IOException;
 import java.util.Random;
 
 import org.apache.lucene.index.PostingsEnum;
+import org.apache.lucene.util.Bits;
 
 import com.carrotsearch.randomizedtesting.generators.RandomInts;
 
@@ -55,28 +56,28 @@ final class AssertingBulkScorer extends BulkScorer {
   }
 
   @Override
-  public void score(LeafCollector collector) throws IOException {
+  public void score(LeafCollector collector, Bits acceptDocs) throws IOException {
     assert max == 0;
     collector = new AssertingLeafCollector(random, collector, 0, PostingsEnum.NO_MORE_DOCS);
     if (random.nextBoolean()) {
       try {
-        final int next = score(collector, 0, PostingsEnum.NO_MORE_DOCS);
+        final int next = score(collector, acceptDocs, 0, PostingsEnum.NO_MORE_DOCS);
         assert next == DocIdSetIterator.NO_MORE_DOCS;
       } catch (UnsupportedOperationException e) {
-        in.score(collector);
+        in.score(collector, acceptDocs);
       }
     } else {
-      in.score(collector);
+      in.score(collector, acceptDocs);
     }
   }
 
   @Override
-  public int score(LeafCollector collector, int min, final int max) throws IOException {
+  public int score(LeafCollector collector, Bits acceptDocs, int min, final int max) throws IOException {
     assert min >= this.max: "Scoring backward: min=" + min + " while previous max was max=" + this.max;
     assert min <= max : "max must be greater than min, got min=" + min + ", and max=" + max;
     this.max = max;
     collector = new AssertingLeafCollector(random, collector, min, max);
-    final int next = in.score(collector, min, max);
+    final int next = in.score(collector, acceptDocs, min, max);
     assert next >= max;
     if (max >= maxDoc || next >= maxDoc) {
       assert next == DocIdSetIterator.NO_MORE_DOCS;
diff --git a/lucene/test-framework/src/java/org/apache/lucene/search/AssertingScorer.java b/lucene/test-framework/src/java/org/apache/lucene/search/AssertingScorer.java
index 96d2065..2bc61ef 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/search/AssertingScorer.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/search/AssertingScorer.java
@@ -39,13 +39,14 @@ public class AssertingScorer extends Scorer {
   final boolean needsScores;
 
   IteratorState state = IteratorState.START;
-  int doc = -1;
+  int doc;
 
   private AssertingScorer(Random random, Scorer in, boolean needsScores) {
     super(in.weight);
     this.random = random;
     this.in = in;
     this.needsScores = needsScores;
+    this.doc = in.docID();
   }
 
   public Scorer getIn() {
@@ -90,7 +91,6 @@ public class AssertingScorer extends Scorer {
 
   @Override
   public int docID() {
-    assert state != IteratorState.APPROXIMATING : "calling docId() on the Scorer while the match has not been confirmed";
     return in.docID();
   }
 
@@ -159,7 +159,7 @@ public class AssertingScorer extends Scorer {
           state = IteratorState.APPROXIMATING;
         }
         assert inApproximation.docID() == nextDoc;
-        return nextDoc;
+        return doc = nextDoc;
       }
 
       @Override
@@ -174,7 +174,7 @@ public class AssertingScorer extends Scorer {
           state = IteratorState.APPROXIMATING;
         }
         assert inApproximation.docID() == advanced;
-        return advanced;
+        return doc = advanced;
       }
 
       @Override
diff --git a/lucene/test-framework/src/java/org/apache/lucene/search/AssertingWeight.java b/lucene/test-framework/src/java/org/apache/lucene/search/AssertingWeight.java
index 71036d8..4616166 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/search/AssertingWeight.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/search/AssertingWeight.java
@@ -23,7 +23,6 @@ import java.util.Set;
 
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.Term;
-import org.apache.lucene.util.Bits;
 
 class AssertingWeight extends Weight {
 
@@ -59,15 +58,15 @@ class AssertingWeight extends Weight {
   }
 
   @Override
-  public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-    final Scorer inScorer = in.scorer(context, acceptDocs);
+  public Scorer scorer(LeafReaderContext context) throws IOException {
+    final Scorer inScorer = in.scorer(context);
     assert inScorer == null || inScorer.docID() == -1;
     return AssertingScorer.wrap(new Random(random.nextLong()), inScorer, needsScores);
   }
 
   @Override
-  public BulkScorer bulkScorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-    BulkScorer inScorer = in.bulkScorer(context, acceptDocs);
+  public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {
+    BulkScorer inScorer = in.bulkScorer(context);
     if (inScorer == null) {
       return null;
     }
diff --git a/lucene/test-framework/src/java/org/apache/lucene/search/BulkScorerWrapperScorer.java b/lucene/test-framework/src/java/org/apache/lucene/search/BulkScorerWrapperScorer.java
index e682d9d..7263402 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/search/BulkScorerWrapperScorer.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/search/BulkScorerWrapperScorer.java
@@ -63,7 +63,7 @@ public class BulkScorerWrapperScorer extends Scorer {
           scores[bufferLength] = scorer.score();
           bufferLength += 1;
         }
-      }, min, max);
+      }, null, min, max);
     }
     i = -1;
   }
diff --git a/lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils.java b/lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils.java
index 707dd4f..aa93e70 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils.java
@@ -341,7 +341,7 @@ public class QueryUtils {
               if (scorer == null) {
                 Weight w = s.createNormalizedWeight(q, true);
                 LeafReaderContext context = readerContextArray.get(leafPtr);
-                scorer = w.scorer(context, context.reader().getLiveDocs());
+                scorer = w.scorer(context);
               }
               
               int op = order[(opidx[0]++) % order.length];
@@ -405,9 +405,16 @@ public class QueryUtils {
               indexSearcher.setSimilarity(s.getSimilarity(true));
               Weight w = indexSearcher.createNormalizedWeight(q, true);
               LeafReaderContext ctx = (LeafReaderContext)indexSearcher.getTopReaderContext();
-              Scorer scorer = w.scorer(ctx, ctx.reader().getLiveDocs());
+              Scorer scorer = w.scorer(ctx);
               if (scorer != null) {
-                boolean more = scorer.advance(lastDoc[0] + 1) != DocIdSetIterator.NO_MORE_DOCS;
+                boolean more = false;
+                final Bits liveDocs = context.reader().getLiveDocs();
+                for (int d = scorer.advance(lastDoc[0] + 1); d != DocIdSetIterator.NO_MORE_DOCS; d = scorer.nextDoc()) {
+                  if (liveDocs == null || liveDocs.get(d)) {
+                    more = true;
+                    break;
+                  }
+                }
                 Assert.assertFalse("query's last doc was "+ lastDoc[0] +" but advance("+(lastDoc[0]+1)+") got to "+scorer.docID(),more);
               }
               leafPtr++;
@@ -427,9 +434,16 @@ public class QueryUtils {
           indexSearcher.setSimilarity(s.getSimilarity(true));
           Weight w = indexSearcher.createNormalizedWeight(q, true);
           LeafReaderContext ctx = previousReader.getContext();
-          Scorer scorer = w.scorer(ctx, ctx.reader().getLiveDocs());
+          Scorer scorer = w.scorer(ctx);
           if (scorer != null) {
-            boolean more = scorer.advance(lastDoc[0] + 1) != DocIdSetIterator.NO_MORE_DOCS;
+            boolean more = false;
+            final Bits liveDocs = lastReader[0].getLiveDocs();
+            for (int d = scorer.advance(lastDoc[0] + 1); d != DocIdSetIterator.NO_MORE_DOCS; d = scorer.nextDoc()) {
+              if (liveDocs == null || liveDocs.get(d)) {
+                more = true;
+                break;
+              }
+            }
             Assert.assertFalse("query's last doc was "+ lastDoc[0] +" but advance("+(lastDoc[0]+1)+") got to "+scorer.docID(),more);
           }
         }
@@ -446,7 +460,6 @@ public class QueryUtils {
     s.search(q,new SimpleCollector() {
       private Scorer scorer;
       private int leafPtr;
-      private Bits liveDocs;
       @Override
       public void setScorer(Scorer scorer) {
         this.scorer = scorer;
@@ -458,7 +471,7 @@ public class QueryUtils {
           long startMS = System.currentTimeMillis();
           for (int i=lastDoc[0]+1; i<=doc; i++) {
             Weight w = s.createNormalizedWeight(q, true);
-            Scorer scorer = w.scorer(context.get(leafPtr), liveDocs);
+            Scorer scorer = w.scorer(context.get(leafPtr));
             Assert.assertTrue("query collected "+doc+" but advance("+i+") says no more docs!",scorer.advance(i) != DocIdSetIterator.NO_MORE_DOCS);
             Assert.assertEquals("query collected "+doc+" but advance("+i+") got to "+scorer.docID(),doc,scorer.docID());
             float advanceScore = scorer.score();
@@ -491,9 +504,16 @@ public class QueryUtils {
           IndexSearcher indexSearcher = LuceneTestCase.newSearcher(previousReader);
           indexSearcher.setSimilarity(s.getSimilarity(true));
           Weight w = indexSearcher.createNormalizedWeight(q, true);
-          Scorer scorer = w.scorer((LeafReaderContext)indexSearcher.getTopReaderContext(), previousReader.getLiveDocs());
+          Scorer scorer = w.scorer((LeafReaderContext)indexSearcher.getTopReaderContext());
           if (scorer != null) {
-            boolean more = scorer.advance(lastDoc[0] + 1) != DocIdSetIterator.NO_MORE_DOCS;
+            boolean more = false;
+            final Bits liveDocs = context.reader().getLiveDocs();
+            for (int d = scorer.advance(lastDoc[0] + 1); d != DocIdSetIterator.NO_MORE_DOCS; d = scorer.nextDoc()) {
+              if (liveDocs == null || liveDocs.get(d)) {
+                more = true;
+                break;
+              }
+            }
             Assert.assertFalse("query's last doc was "+ lastDoc[0] +" but advance("+(lastDoc[0]+1)+") got to "+scorer.docID(),more);
           }
           leafPtr++;
@@ -501,7 +521,6 @@ public class QueryUtils {
 
         lastReader[0] = context.reader();
         lastDoc[0] = -1;
-        liveDocs = context.reader().getLiveDocs();
       }
     });
 
@@ -512,9 +531,16 @@ public class QueryUtils {
       IndexSearcher indexSearcher = LuceneTestCase.newSearcher(previousReader);
       indexSearcher.setSimilarity(s.getSimilarity(true));
       Weight w = indexSearcher.createNormalizedWeight(q, true);
-      Scorer scorer = w.scorer((LeafReaderContext)indexSearcher.getTopReaderContext(), previousReader.getLiveDocs());
+      Scorer scorer = w.scorer((LeafReaderContext)indexSearcher.getTopReaderContext());
       if (scorer != null) {
-        boolean more = scorer.advance(lastDoc[0] + 1) != DocIdSetIterator.NO_MORE_DOCS;
+        boolean more = false;
+        final Bits liveDocs = lastReader[0].getLiveDocs();
+        for (int d = scorer.advance(lastDoc[0] + 1); d != DocIdSetIterator.NO_MORE_DOCS; d = scorer.nextDoc()) {
+          if (liveDocs == null || liveDocs.get(d)) {
+            more = true;
+            break;
+          }
+        }
         Assert.assertFalse("query's last doc was "+ lastDoc[0] +" but advance("+(lastDoc[0]+1)+") got to "+scorer.docID(),more);
       }
     }
@@ -524,8 +550,8 @@ public class QueryUtils {
   public static void checkBulkScorerSkipTo(Random r, Query query, IndexSearcher searcher) throws IOException {
     Weight weight = searcher.createNormalizedWeight(query, true);
     for (LeafReaderContext context : searcher.getIndexReader().leaves()) {
-      final Scorer scorer = weight.scorer(context, context.reader().getLiveDocs());
-      final BulkScorer bulkScorer = weight.bulkScorer(context, context.reader().getLiveDocs());
+      final Scorer scorer = weight.scorer(context);
+      final BulkScorer bulkScorer = weight.bulkScorer(context);
       if (scorer == null && bulkScorer == null) {
         continue;
       } else if (bulkScorer == null) {
@@ -554,7 +580,7 @@ public class QueryUtils {
             Assert.assertEquals(scorer.score(), scorer2.score(), 0.01f);
             scorer.nextDoc();
           }
-        }, min, max);
+        }, null, min, max);
         assert max <= next;
         assert next <= scorer.docID();
         upTo = max;
@@ -569,7 +595,7 @@ public class QueryUtils {
               // no more matches
               assert false;
             }
-          }, upTo, DocIdSetIterator.NO_MORE_DOCS);
+          }, null, upTo, DocIdSetIterator.NO_MORE_DOCS);
           break;
         }
       }
diff --git a/lucene/test-framework/src/java/org/apache/lucene/search/RandomApproximationQuery.java b/lucene/test-framework/src/java/org/apache/lucene/search/RandomApproximationQuery.java
index 270ae4f..02616b8 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/search/RandomApproximationQuery.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/search/RandomApproximationQuery.java
@@ -113,8 +113,8 @@ public class RandomApproximationQuery extends Query {
     }
 
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-      final Scorer scorer = weight.scorer(context, acceptDocs);
+    public Scorer scorer(LeafReaderContext context) throws IOException {
+      final Scorer scorer = weight.scorer(context);
       if (scorer == null) {
         return null;
       }
diff --git a/lucene/test-framework/src/java/org/apache/lucene/search/ScorerIndexSearcher.java b/lucene/test-framework/src/java/org/apache/lucene/search/ScorerIndexSearcher.java
index dd650a5..e1dc032 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/search/ScorerIndexSearcher.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/search/ScorerIndexSearcher.java
@@ -23,6 +23,7 @@ import java.util.concurrent.ExecutorService;
 
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.util.Bits;
 
 /**
  * An {@link IndexSearcher} that always uses the {@link Scorer} API, never {@link BulkScorer}.
@@ -48,12 +49,15 @@ public class ScorerIndexSearcher extends IndexSearcher {
       // we force the use of Scorer (not BulkScorer) to make sure
       // that the scorer passed to LeafCollector.setScorer supports
       // Scorer.getChildren
-      Scorer scorer = weight.scorer(ctx, ctx.reader().getLiveDocs());
+      Scorer scorer = weight.scorer(ctx);
       if (scorer != null) {
         final LeafCollector leafCollector = collector.getLeafCollector(ctx);
         leafCollector.setScorer(scorer);
+        final Bits liveDocs = ctx.reader().getLiveDocs();
         for (int doc = scorer.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = scorer.nextDoc()) {
-          leafCollector.collect(doc);
+          if (liveDocs == null || liveDocs.get(doc)) {
+            leafCollector.collect(doc);
+          }
         }
       }
     }
diff --git a/lucene/test-framework/src/java/org/apache/lucene/search/SearchEquivalenceTestBase.java b/lucene/test-framework/src/java/org/apache/lucene/search/SearchEquivalenceTestBase.java
index 0e4a331..274c7cb 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/search/SearchEquivalenceTestBase.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/search/SearchEquivalenceTestBase.java
@@ -190,7 +190,7 @@ public abstract class SearchEquivalenceTestBase extends LuceneTestCase {
       return new DocIdSet() {
         @Override
         public DocIdSetIterator iterator() throws IOException {
-          return weight.scorer(privateContext, acceptDocs);
+          return weight.scorer(privateContext);
         }
 
         @Override
diff --git a/lucene/test-framework/src/java/org/apache/lucene/search/spans/AssertingSpanWeight.java b/lucene/test-framework/src/java/org/apache/lucene/search/spans/AssertingSpanWeight.java
index 61c9f9d..c180b3e 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/search/spans/AssertingSpanWeight.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/search/spans/AssertingSpanWeight.java
@@ -23,7 +23,6 @@ import org.apache.lucene.index.TermContext;
 import org.apache.lucene.search.Explanation;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Scorer;
-import org.apache.lucene.util.Bits;
 
 import java.io.IOException;
 import java.util.Map;
@@ -52,8 +51,8 @@ public class AssertingSpanWeight extends SpanWeight {
   }
 
   @Override
-  public Spans getSpans(LeafReaderContext context, Bits liveDocs, Postings requiredPostings) throws IOException {
-    Spans spans = in.getSpans(context, liveDocs, requiredPostings);
+  public Spans getSpans(LeafReaderContext context, Postings requiredPostings) throws IOException {
+    Spans spans = in.getSpans(context, requiredPostings);
     if (spans == null)
       return null;
     return new AssertingSpans(spans);
@@ -75,8 +74,8 @@ public class AssertingSpanWeight extends SpanWeight {
   }
 
   @Override
-  public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-    return in.scorer(context, acceptDocs);
+  public Scorer scorer(LeafReaderContext context) throws IOException {
+    return in.scorer(context);
   }
 
   @Override
diff --git a/lucene/test-framework/src/java/org/apache/lucene/util/LuceneTestCase.java b/lucene/test-framework/src/java/org/apache/lucene/util/LuceneTestCase.java
index 5463dce..2db1d6e 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/util/LuceneTestCase.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/util/LuceneTestCase.java
@@ -2025,7 +2025,6 @@ public abstract class LuceneTestCase extends Assert {
    */
   public void assertTermsEnumEquals(String info, IndexReader leftReader, TermsEnum leftTermsEnum, TermsEnum rightTermsEnum, boolean deep) throws IOException {
     BytesRef term;
-    Bits randomBits = new RandomBits(leftReader.maxDoc(), random().nextDouble(), random());
     PostingsEnum leftPositions = null;
     PostingsEnum rightPositions = null;
     PostingsEnum leftDocs = null;
@@ -2035,52 +2034,36 @@ public abstract class LuceneTestCase extends Assert {
       assertEquals(info, term, rightTermsEnum.next());
       assertTermStatsEquals(info, leftTermsEnum, rightTermsEnum);
       if (deep) {
-        assertDocsAndPositionsEnumEquals(info, leftPositions = leftTermsEnum.postings(null, leftPositions, PostingsEnum.ALL),
-                                   rightPositions = rightTermsEnum.postings(null, rightPositions, PostingsEnum.ALL));
-        assertDocsAndPositionsEnumEquals(info, leftPositions = leftTermsEnum.postings(randomBits, leftPositions, PostingsEnum.ALL),
-                                   rightPositions = rightTermsEnum.postings(randomBits, rightPositions, PostingsEnum.ALL));
+        assertDocsAndPositionsEnumEquals(info, leftPositions = leftTermsEnum.postings(leftPositions, PostingsEnum.ALL),
+                                   rightPositions = rightTermsEnum.postings(rightPositions, PostingsEnum.ALL));
 
         assertPositionsSkippingEquals(info, leftReader, leftTermsEnum.docFreq(), 
-                                leftPositions = leftTermsEnum.postings(null, leftPositions, PostingsEnum.ALL),
-                                rightPositions = rightTermsEnum.postings(null, rightPositions, PostingsEnum.ALL));
-        assertPositionsSkippingEquals(info, leftReader, leftTermsEnum.docFreq(), 
-                                leftPositions = leftTermsEnum.postings(randomBits, leftPositions, PostingsEnum.ALL),
-            rightPositions = rightTermsEnum.postings(randomBits, rightPositions, PostingsEnum.ALL));
+                                leftPositions = leftTermsEnum.postings(leftPositions, PostingsEnum.ALL),
+                                rightPositions = rightTermsEnum.postings(rightPositions, PostingsEnum.ALL));
+
 
         // with freqs:
-        assertDocsEnumEquals(info, leftDocs = leftTermsEnum.postings(null, leftDocs),
-            rightDocs = rightTermsEnum.postings(null, rightDocs),
-            true);
-        assertDocsEnumEquals(info, leftDocs = leftTermsEnum.postings(randomBits, leftDocs),
-            rightDocs = rightTermsEnum.postings(randomBits, rightDocs),
+        assertDocsEnumEquals(info, leftDocs = leftTermsEnum.postings(leftDocs),
+            rightDocs = rightTermsEnum.postings(rightDocs),
             true);
 
+
         // w/o freqs:
-        assertDocsEnumEquals(info, leftDocs = leftTermsEnum.postings(null, leftDocs, PostingsEnum.NONE),
-            rightDocs = rightTermsEnum.postings(null, rightDocs, PostingsEnum.NONE),
-            false);
-        assertDocsEnumEquals(info, leftDocs = leftTermsEnum.postings(randomBits, leftDocs, PostingsEnum.NONE),
-            rightDocs = rightTermsEnum.postings(randomBits, rightDocs, PostingsEnum.NONE),
+        assertDocsEnumEquals(info, leftDocs = leftTermsEnum.postings(leftDocs, PostingsEnum.NONE),
+            rightDocs = rightTermsEnum.postings(rightDocs, PostingsEnum.NONE),
             false);
+
         
         // with freqs:
         assertDocsSkippingEquals(info, leftReader, leftTermsEnum.docFreq(), 
-            leftDocs = leftTermsEnum.postings(null, leftDocs),
-            rightDocs = rightTermsEnum.postings(null, rightDocs),
-            true);
-        assertDocsSkippingEquals(info, leftReader, leftTermsEnum.docFreq(), 
-            leftDocs = leftTermsEnum.postings(randomBits, leftDocs),
-            rightDocs = rightTermsEnum.postings(randomBits, rightDocs),
+            leftDocs = leftTermsEnum.postings(leftDocs),
+            rightDocs = rightTermsEnum.postings(rightDocs),
             true);
 
         // w/o freqs:
         assertDocsSkippingEquals(info, leftReader, leftTermsEnum.docFreq(), 
-            leftDocs = leftTermsEnum.postings(null, leftDocs, PostingsEnum.NONE),
-            rightDocs = rightTermsEnum.postings(null, rightDocs, PostingsEnum.NONE),
-            false);
-        assertDocsSkippingEquals(info, leftReader, leftTermsEnum.docFreq(), 
-            leftDocs = leftTermsEnum.postings(randomBits, leftDocs, PostingsEnum.NONE),
-            rightDocs = rightTermsEnum.postings(randomBits, rightDocs, PostingsEnum.NONE),
+            leftDocs = leftTermsEnum.postings(leftDocs, PostingsEnum.NONE),
+            rightDocs = rightTermsEnum.postings(rightDocs, PostingsEnum.NONE),
             false);
       }
     }
diff --git a/lucene/test-framework/src/java/org/apache/lucene/util/TestUtil.java b/lucene/test-framework/src/java/org/apache/lucene/util/TestUtil.java
index e6914c9..c7f2744 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/util/TestUtil.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/util/TestUtil.java
@@ -1081,7 +1081,7 @@ public final class TestUtil {
   // Returns a DocsEnum, but randomly sometimes uses a
   // DocsAndFreqsEnum, DocsAndPositionsEnum.  Returns null
   // if field/term doesn't exist:
-  public static PostingsEnum docs(Random random, IndexReader r, String field, BytesRef term, Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
+  public static PostingsEnum docs(Random random, IndexReader r, String field, BytesRef term, PostingsEnum reuse, int flags) throws IOException {
     final Terms terms = MultiFields.getTerms(r, field);
     if (terms == null) {
       return null;
@@ -1090,11 +1090,11 @@ public final class TestUtil {
     if (!termsEnum.seekExact(term)) {
       return null;
     }
-    return docs(random, termsEnum, liveDocs, reuse, flags);
+    return docs(random, termsEnum, reuse, flags);
   }
 
   // Returns a PostingsEnum with random features available
-  public static PostingsEnum docs(Random random, TermsEnum termsEnum, Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
+  public static PostingsEnum docs(Random random, TermsEnum termsEnum, PostingsEnum reuse, int flags) throws IOException {
     // TODO: simplify this method? it would be easier to randomly either use the flags passed, or do the random selection,
     // FREQS should be part fo the random selection instead of outside on its own?
     if (random.nextBoolean()) {
@@ -1106,11 +1106,11 @@ public final class TestUtil {
           case 2: posFlags = PostingsEnum.PAYLOADS; break;
           default: posFlags = PostingsEnum.ALL; break;
         }
-        return termsEnum.postings(liveDocs, null, posFlags);
+        return termsEnum.postings(null, posFlags);
       }
       flags |= PostingsEnum.FREQS;
     }
-    return termsEnum.postings(liveDocs, reuse, flags);
+    return termsEnum.postings(reuse, flags);
   }
   
   public static CharSequence stringToCharSequence(String string, Random random) {
diff --git a/lucene/test-framework/src/test/org/apache/lucene/analysis/TestMockAnalyzer.java b/lucene/test-framework/src/test/org/apache/lucene/analysis/TestMockAnalyzer.java
index 5d3b756..40b69df 100644
--- a/lucene/test-framework/src/test/org/apache/lucene/analysis/TestMockAnalyzer.java
+++ b/lucene/test-framework/src/test/org/apache/lucene/analysis/TestMockAnalyzer.java
@@ -321,7 +321,7 @@ public class TestMockAnalyzer extends BaseTokenStreamTestCase {
     final Terms terms = fields.terms("f");
     final TermsEnum te = terms.iterator();
     assertEquals(new BytesRef("a"), te.next());
-    final PostingsEnum dpe = te.postings(null, null, PostingsEnum.ALL);
+    final PostingsEnum dpe = te.postings(null, PostingsEnum.ALL);
     assertEquals(0, dpe.nextDoc());
     assertEquals(2, dpe.freq());
     assertEquals(0, dpe.nextPosition());
diff --git a/solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler.java b/solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler.java
index c54f41a..197f709 100644
--- a/solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler.java
+++ b/solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler.java
@@ -54,6 +54,7 @@ import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.search.similarities.Similarity;
 import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.CharsRefBuilder;
 import org.apache.lucene.util.PriorityQueue;
@@ -417,8 +418,12 @@ public class LukeRequestHandler extends RequestHandlerBase
       if (text == null) { // Ran off the end of the terms enum without finding any live docs with that field in them.
         return null;
       }
-      postingsEnum = termsEnum.postings(reader.getLiveDocs(), postingsEnum, PostingsEnum.NONE);
+      postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);
+      final Bits liveDocs = reader.getLiveDocs();
       if (postingsEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
+        if (liveDocs != null && liveDocs.get(postingsEnum.docID())) {
+          continue;
+        }
         return reader.document(postingsEnum.docID());
       }
     }
diff --git a/solr/core/src/java/org/apache/solr/handler/component/QueryElevationComponent.java b/solr/core/src/java/org/apache/solr/handler/component/QueryElevationComponent.java
index a541f9d..b94e4b3 100644
--- a/solr/core/src/java/org/apache/solr/handler/component/QueryElevationComponent.java
+++ b/solr/core/src/java/org/apache/solr/handler/component/QueryElevationComponent.java
@@ -575,8 +575,11 @@ public class QueryElevationComponent extends SearchComponent implements SolrCore
         while(it.hasNext()) {
           BytesRef ref = it.next();
           if(termsEnum.seekExact(ref)) {
-            postingsEnum = termsEnum.postings(liveDocs, postingsEnum);
+            postingsEnum = termsEnum.postings(postingsEnum);
             int doc = postingsEnum.nextDoc();
+            while (doc != PostingsEnum.NO_MORE_DOCS && liveDocs != null && liveDocs.get(doc) == false) {
+              doc = postingsEnum.nextDoc();
+            }
             if(doc != PostingsEnum.NO_MORE_DOCS) {
               //Found the document.
               int p = boosted.get(ref);
@@ -692,8 +695,11 @@ public class QueryElevationComponent extends SearchComponent implements SolrCore
         for (String id : elevations.ids) {
           term.copyChars(id);
           if (seen.contains(id) == false  && termsEnum.seekExact(term.get())) {
-            postingsEnum = termsEnum.postings(liveDocs, postingsEnum, PostingsEnum.NONE);
+            postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);
             int docId = postingsEnum.nextDoc();
+            while (docId != DocIdSetIterator.NO_MORE_DOCS && liveDocs != null && liveDocs.get(docId) == false) {
+              docId = postingsEnum.nextDoc();
+            }
             if (docId == DocIdSetIterator.NO_MORE_DOCS ) continue;  // must have been deleted
             termValues[ordSet.put(docId)] = term.toBytesRef();
             seen.add(id);
diff --git a/solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent.java b/solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent.java
index ab838c2..a59507b 100644
--- a/solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent.java
+++ b/solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent.java
@@ -357,7 +357,7 @@ public class TermVectorComponent extends SearchComponent implements SolrCoreAwar
       //payloads require offsets
       dpEnumFlags |= (fieldOptions.offsets || fieldOptions.payloads) ? PostingsEnum.OFFSETS : 0;
       dpEnumFlags |= fieldOptions.payloads ? PostingsEnum.PAYLOADS : 0;
-      dpEnum = termsEnum.postings(null, dpEnum, dpEnumFlags);
+      dpEnum = termsEnum.postings(dpEnum, dpEnumFlags);
 
       boolean atNextDoc = false;
       if (dpEnum != null) {
diff --git a/solr/core/src/java/org/apache/solr/request/SimpleFacets.java b/solr/core/src/java/org/apache/solr/request/SimpleFacets.java
index 61372f6..391c429 100644
--- a/solr/core/src/java/org/apache/solr/request/SimpleFacets.java
+++ b/solr/core/src/java/org/apache/solr/request/SimpleFacets.java
@@ -821,7 +821,7 @@ public class SimpleFacets {
               // TODO: specialize when base docset is a bitset or hash set (skipDocs)?  or does it matter for this?
               // TODO: do this per-segment for better efficiency (MultiDocsEnum just uses base class impl)
               // TODO: would passing deleted docs lead to better efficiency over checking the fastForRandomSet?
-              postingsEnum = termsEnum.postings(null, postingsEnum, PostingsEnum.NONE);
+              postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);
               c = 0;
 
               if (postingsEnum instanceof MultiPostingsEnum) {
diff --git a/solr/core/src/java/org/apache/solr/schema/LatLonType.java b/solr/core/src/java/org/apache/solr/schema/LatLonType.java
index 33c9a4a..ec157df 100644
--- a/solr/core/src/java/org/apache/solr/schema/LatLonType.java
+++ b/solr/core/src/java/org/apache/solr/schema/LatLonType.java
@@ -340,13 +340,13 @@ class SpatialDistanceQuery extends ExtendedQueryBase implements PostFilter {
     }
 
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-      return new SpatialScorer(context, acceptDocs, this, queryWeight);
+    public Scorer scorer(LeafReaderContext context) throws IOException {
+      return new SpatialScorer(context, this, queryWeight);
     }
 
     @Override
     public Explanation explain(LeafReaderContext context, int doc) throws IOException {
-      return ((SpatialScorer)scorer(context, context.reader().getLiveDocs())).explain(doc);
+      return ((SpatialScorer)scorer(context)).explain(doc);
     }
   }
 
@@ -358,7 +358,6 @@ class SpatialDistanceQuery extends ExtendedQueryBase implements PostFilter {
     int doc=-1;
     final FunctionValues latVals;
     final FunctionValues lonVals;
-    final Bits acceptDocs;
 
 
     final double lonMin, lonMax, lon2Min, lon2Max, latMin, latMax;
@@ -374,13 +373,12 @@ class SpatialDistanceQuery extends ExtendedQueryBase implements PostFilter {
     int lastDistDoc;
     double lastDist;
 
-    public SpatialScorer(LeafReaderContext readerContext, Bits acceptDocs, SpatialWeight w, float qWeight) throws IOException {
+    public SpatialScorer(LeafReaderContext readerContext, SpatialWeight w, float qWeight) throws IOException {
       super(w);
       this.weight = w;
       this.qWeight = qWeight;
       this.reader = readerContext.reader();
       this.maxDoc = reader.maxDoc();
-      this.acceptDocs = acceptDocs;
       latVals = latSource.getValues(weight.latContext, readerContext);
       lonVals = lonSource.getValues(weight.lonContext, readerContext);
 
@@ -458,7 +456,6 @@ class SpatialDistanceQuery extends ExtendedQueryBase implements PostFilter {
         if (doc>=maxDoc) {
           return doc=NO_MORE_DOCS;
         }
-        if (acceptDocs != null && !acceptDocs.get(doc)) continue;
         if (!match()) continue;
         return doc;
       }
@@ -538,7 +535,7 @@ class SpatialDistanceQuery extends ExtendedQueryBase implements PostFilter {
     protected void doSetNextReader(LeafReaderContext context) throws IOException {
       super.doSetNextReader(context);
       maxdoc = context.reader().maxDoc();
-      spatialScorer = new SpatialScorer(context, null, weight, 1.0f);
+      spatialScorer = new SpatialScorer(context, weight, 1.0f);
     }
   }
 
diff --git a/solr/core/src/java/org/apache/solr/search/BitsFilteredPostingsEnum.java b/solr/core/src/java/org/apache/solr/search/BitsFilteredPostingsEnum.java
new file mode 100644
index 0000000..f93709b
--- /dev/null
+++ b/solr/core/src/java/org/apache/solr/search/BitsFilteredPostingsEnum.java
@@ -0,0 +1,58 @@
+package org.apache.solr.search;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.index.FilterLeafReader.FilterPostingsEnum;
+import org.apache.lucene.index.PostingsEnum;
+import org.apache.lucene.util.Bits;
+
+public class BitsFilteredPostingsEnum extends FilterPostingsEnum {
+
+  public static PostingsEnum wrap(PostingsEnum in, Bits acceptDocs) {
+    if (in == null || acceptDocs == null) {
+      return in;
+    }
+    return new BitsFilteredPostingsEnum(in, acceptDocs);
+  }
+
+  private final Bits acceptDocs;
+
+  private BitsFilteredPostingsEnum(PostingsEnum in, Bits acceptDocs) {
+    super(in);
+    this.acceptDocs = acceptDocs;
+  }
+
+  private int doNext(int doc) throws IOException {
+    while (doc != NO_MORE_DOCS && acceptDocs.get(doc) == false) {
+      doc = super.nextDoc();
+    }
+    return doc;
+  }
+
+  @Override
+  public int nextDoc() throws IOException {
+    return doNext(super.nextDoc());
+  }
+
+  @Override
+  public int advance(int target) throws IOException {
+    return doNext(super.advance(target));
+  }
+}
diff --git a/solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java b/solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java
index 957fd72..e3819e3 100644
--- a/solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java
+++ b/solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java
@@ -277,7 +277,7 @@ class JoinQuery extends Query {
 
 
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+    public Scorer scorer(LeafReaderContext context) throws IOException {
       if (filter == null) {
         boolean debug = rb != null && rb.isDebug();
         long start = debug ? System.currentTimeMillis() : 0;
@@ -309,7 +309,7 @@ class JoinQuery extends Query {
       }
 
       // Although this set only includes live docs, other filters can be pushed down to queries.
-      DocIdSet readerSet = filter.getDocIdSet(context, acceptDocs);
+      DocIdSet readerSet = filter.getDocIdSet(context, null);
       if (readerSet == null) {
         return null;
       }
@@ -409,7 +409,7 @@ class JoinQuery extends Query {
         if (freq < minDocFreqFrom) {
           fromTermDirectCount++;
           // OK to skip liveDocs, since we check for intersection with docs matching query
-          fromDeState.postingsEnum = fromDeState.termsEnum.postings(null, fromDeState.postingsEnum, PostingsEnum.NONE);
+          fromDeState.postingsEnum = fromDeState.termsEnum.postings(fromDeState.postingsEnum, PostingsEnum.NONE);
           PostingsEnum postingsEnum = fromDeState.postingsEnum;
 
           if (postingsEnum instanceof MultiPostingsEnum) {
@@ -474,7 +474,8 @@ class JoinQuery extends Query {
               toTermDirectCount++;
 
               // need to use liveDocs here so we don't map to any deleted ones
-              toDeState.postingsEnum = toDeState.termsEnum.postings(toDeState.liveDocs, toDeState.postingsEnum, PostingsEnum.NONE);
+              toDeState.postingsEnum = toDeState.termsEnum.postings(toDeState.postingsEnum, PostingsEnum.NONE);
+              toDeState.postingsEnum = BitsFilteredPostingsEnum.wrap(toDeState.postingsEnum, toDeState.liveDocs);
               PostingsEnum postingsEnum = toDeState.postingsEnum;
 
               if (postingsEnum instanceof MultiPostingsEnum) {
diff --git a/solr/core/src/java/org/apache/solr/search/ReRankQParserPlugin.java b/solr/core/src/java/org/apache/solr/search/ReRankQParserPlugin.java
index dedf026..f5fb64d 100644
--- a/solr/core/src/java/org/apache/solr/search/ReRankQParserPlugin.java
+++ b/solr/core/src/java/org/apache/solr/search/ReRankQParserPlugin.java
@@ -204,8 +204,8 @@ public class ReRankQParserPlugin extends QParserPlugin {
       return mainWeight.getValueForNormalization();
     }
 
-    public Scorer scorer(LeafReaderContext context, Bits bits) throws IOException {
-      return mainWeight.scorer(context, bits);
+    public Scorer scorer(LeafReaderContext context) throws IOException {
+      return mainWeight.scorer(context);
     }
 
     public void normalize(float norm, float topLevelBoost) {
diff --git a/solr/core/src/java/org/apache/solr/search/SolrConstantScoreQuery.java b/solr/core/src/java/org/apache/solr/search/SolrConstantScoreQuery.java
index 1f620ae..f409f74 100644
--- a/solr/core/src/java/org/apache/solr/search/SolrConstantScoreQuery.java
+++ b/solr/core/src/java/org/apache/solr/search/SolrConstantScoreQuery.java
@@ -103,8 +103,8 @@ public class SolrConstantScoreQuery extends ConstantScoreQuery implements Extend
     }
 
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-      DocIdSet docIdSet = filter instanceof SolrFilter ? ((SolrFilter)filter).getDocIdSet(this.context, context, acceptDocs) : filter.getDocIdSet(context, acceptDocs);
+    public Scorer scorer(LeafReaderContext context) throws IOException {
+      DocIdSet docIdSet = filter instanceof SolrFilter ? ((SolrFilter)filter).getDocIdSet(this.context, context, null) : filter.getDocIdSet(context, null);
       if (docIdSet == null) {
         return null;
       }
diff --git a/solr/core/src/java/org/apache/solr/search/SolrIndexSearcher.java b/solr/core/src/java/org/apache/solr/search/SolrIndexSearcher.java
index 9e91797..bbe2e6d 100644
--- a/solr/core/src/java/org/apache/solr/search/SolrIndexSearcher.java
+++ b/solr/core/src/java/org/apache/solr/search/SolrIndexSearcher.java
@@ -807,7 +807,8 @@ public class SolrIndexSearcher extends IndexSearcher implements Closeable,SolrIn
     if (!termsEnum.seekExact(termBytes)) {
       return -1;
     }
-    PostingsEnum docs = termsEnum.postings(leafReader.getLiveDocs(), null, PostingsEnum.NONE);
+    PostingsEnum docs = termsEnum.postings(null, PostingsEnum.NONE);
+    docs = BitsFilteredPostingsEnum.wrap(docs, leafReader.getLiveDocs());
     int id = docs.nextDoc();
     return id == DocIdSetIterator.NO_MORE_DOCS ? -1 : id;
   }
@@ -828,7 +829,8 @@ public class SolrIndexSearcher extends IndexSearcher implements Closeable,SolrIn
       
       TermsEnum te = terms.iterator();
       if (te.seekExact(idBytes)) {
-        PostingsEnum docs = te.postings(reader.getLiveDocs(), null, PostingsEnum.NONE);
+        PostingsEnum docs = te.postings(null, PostingsEnum.NONE);
+        docs = BitsFilteredPostingsEnum.wrap(docs, reader.getLiveDocs());
         int id = docs.nextDoc();
         if (id == DocIdSetIterator.NO_MORE_DOCS) continue;
         assert docs.nextDoc() == DocIdSetIterator.NO_MORE_DOCS;
@@ -1200,7 +1202,8 @@ public class SolrIndexSearcher extends IndexSearcher implements Closeable,SolrIn
     int bitsSet = 0;
     FixedBitSet fbs = null;
 
-    PostingsEnum postingsEnum = deState.termsEnum.postings(deState.liveDocs, deState.postingsEnum, PostingsEnum.NONE);
+    PostingsEnum postingsEnum = deState.termsEnum.postings(deState.postingsEnum, PostingsEnum.NONE);
+    postingsEnum = BitsFilteredPostingsEnum.wrap(postingsEnum, deState.liveDocs);
     if (deState.postingsEnum == null) {
       deState.postingsEnum = postingsEnum;
     }
@@ -2526,7 +2529,7 @@ class FilterImpl extends Filter {
         iterators.add(iter);
       }
       for (Weight w : weights) {
-        Scorer scorer = w.scorer(context, context.reader().getLiveDocs());
+        Scorer scorer = w.scorer(context);
         if (scorer == null) return null;
         iterators.add(scorer);
       }
diff --git a/solr/core/src/java/org/apache/solr/search/facet/FacetField.java b/solr/core/src/java/org/apache/solr/search/facet/FacetField.java
index 7870d41..4339f34 100644
--- a/solr/core/src/java/org/apache/solr/search/facet/FacetField.java
+++ b/solr/core/src/java/org/apache/solr/search/facet/FacetField.java
@@ -744,7 +744,7 @@ class FacetFieldProcessorStream extends FacetFieldProcessor implements Closeable
             }
           }
           // iterate over TermDocs to calculate the intersection
-          postingsEnum = termsEnum.postings(null, postingsEnum, PostingsEnum.NONE);
+          postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);
 
           if (postingsEnum instanceof MultiPostingsEnum) {
             MultiPostingsEnum.EnumWithSlice[] subs = ((MultiPostingsEnum) postingsEnum).getSubs();
diff --git a/solr/core/src/java/org/apache/solr/search/function/FileFloatSource.java b/solr/core/src/java/org/apache/solr/search/function/FileFloatSource.java
index 62df383..0f556ba 100644
--- a/solr/core/src/java/org/apache/solr/search/function/FileFloatSource.java
+++ b/solr/core/src/java/org/apache/solr/search/function/FileFloatSource.java
@@ -305,7 +305,7 @@ public class FileFloatSource extends ValueSource {
           continue;
         }
 
-        postingsEnum = termsEnum.postings(null, postingsEnum, PostingsEnum.NONE);
+        postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);
         int doc;
         while ((doc = postingsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
           vals[doc] = fval;
diff --git a/solr/core/src/java/org/apache/solr/search/join/IgnoreAcceptDocsQuery.java b/solr/core/src/java/org/apache/solr/search/join/IgnoreAcceptDocsQuery.java
index 25181b0..a0625a5 100644
--- a/solr/core/src/java/org/apache/solr/search/join/IgnoreAcceptDocsQuery.java
+++ b/solr/core/src/java/org/apache/solr/search/join/IgnoreAcceptDocsQuery.java
@@ -23,8 +23,10 @@ import java.util.Set;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.Term;
+import org.apache.lucene.search.BulkScorer;
 import org.apache.lucene.search.Explanation;
 import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.LeafCollector;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.Scorer;
 import org.apache.lucene.search.Weight;
@@ -82,8 +84,26 @@ public class IgnoreAcceptDocsQuery extends Query {
     }
 
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-      return w.scorer(context, null);
+    public Scorer scorer(LeafReaderContext context) throws IOException {
+      return w.scorer(context);
+    }
+
+    @Override
+    public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {
+      final BulkScorer in = w.bulkScorer(context);
+      return new BulkScorer() {
+
+        @Override
+        public int score(LeafCollector collector, Bits acceptDocs, int min, int max) throws IOException {
+          return in.score(collector, null, min, max);
+        }
+
+        @Override
+        public long cost() {
+          return in.cost();
+        }
+        
+      };
     }
   }
 
diff --git a/solr/core/src/java/org/apache/solr/update/DeleteByQueryWrapper.java b/solr/core/src/java/org/apache/solr/update/DeleteByQueryWrapper.java
index a131fbb..15a2905 100644
--- a/solr/core/src/java/org/apache/solr/update/DeleteByQueryWrapper.java
+++ b/solr/core/src/java/org/apache/solr/update/DeleteByQueryWrapper.java
@@ -86,8 +86,8 @@ final class DeleteByQueryWrapper extends Query {
       public void normalize(float norm, float topLevelBoost) { inner.normalize(norm, topLevelBoost); }
 
       @Override
-      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-        return inner.scorer(privateContext.getIndexReader().leaves().get(0), acceptDocs);
+      public Scorer scorer(LeafReaderContext context) throws IOException {
+        return inner.scorer(privateContext.getIndexReader().leaves().get(0));
       }
     };
   }
diff --git a/solr/core/src/java/org/apache/solr/update/SolrIndexSplitter.java b/solr/core/src/java/org/apache/solr/update/SolrIndexSplitter.java
index 9ce927b..fd03f42 100644
--- a/solr/core/src/java/org/apache/solr/update/SolrIndexSplitter.java
+++ b/solr/core/src/java/org/apache/solr/update/SolrIndexSplitter.java
@@ -42,6 +42,7 @@ import org.apache.solr.common.cloud.DocRouter;
 import org.apache.solr.common.cloud.HashBasedRouter;
 import org.apache.solr.core.SolrCore;
 import org.apache.solr.schema.SchemaField;
+import org.apache.solr.search.BitsFilteredPostingsEnum;
 import org.apache.solr.search.SolrIndexSearcher;
 import org.apache.solr.util.RefCounted;
 import org.slf4j.Logger;
@@ -201,7 +202,8 @@ public class SolrIndexSplitter {
         hash = hashRouter.sliceHash(idString, null, null, null);
       }
 
-      postingsEnum = termsEnum.postings(liveDocs, postingsEnum, PostingsEnum.NONE);
+      postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);
+      postingsEnum = BitsFilteredPostingsEnum.wrap(postingsEnum, liveDocs);
       for (;;) {
         int doc = postingsEnum.nextDoc();
         if (doc == DocIdSetIterator.NO_MORE_DOCS) break;
diff --git a/solr/core/src/test/org/apache/solr/search/TestRTGBase.java b/solr/core/src/test/org/apache/solr/search/TestRTGBase.java
index 4698732..ef6eb1d 100644
--- a/solr/core/src/test/org/apache/solr/search/TestRTGBase.java
+++ b/solr/core/src/test/org/apache/solr/search/TestRTGBase.java
@@ -132,7 +132,8 @@ public class TestRTGBase extends SolrTestCaseJ4 {
     if (!termsEnum.seekExact(termBytes)) {
       return -1;
     }
-    PostingsEnum docs = termsEnum.postings(MultiFields.getLiveDocs(r), null, PostingsEnum.NONE);
+    PostingsEnum docs = termsEnum.postings(null, PostingsEnum.NONE);
+    docs = BitsFilteredPostingsEnum.wrap(docs, MultiFields.getLiveDocs(r));
     int id = docs.nextDoc();
     if (id != DocIdSetIterator.NO_MORE_DOCS) {
       int next = docs.nextDoc();

