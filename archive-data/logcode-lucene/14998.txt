GitDiffStart: 4f2fc58301b6f7c499271bf73a5a56d8a0acb301 | Thu Aug 18 02:36:32 2011 +0000
diff --git a/dev-tools/idea/lucene/contrib/spatial/spatial.iml b/dev-tools/idea/lucene/contrib/spatial/spatial.iml
index fe1c2ec..6838f0c 100644
--- a/dev-tools/idea/lucene/contrib/spatial/spatial.iml
+++ b/dev-tools/idea/lucene/contrib/spatial/spatial.iml
@@ -14,6 +14,7 @@
     <orderEntry type="module" module-name="queries-contrib" />
     <orderEntry type="module" module-name="misc" />
     <orderEntry type="module" module-name="lucene" />
+    <orderEntry type="module" module-name="queries" />
   </component>
 </module>
 
diff --git a/dev-tools/maven/lucene/contrib/spatial/pom.xml.template b/dev-tools/maven/lucene/contrib/spatial/pom.xml.template
index a7201c7..1fd90b4 100644
--- a/dev-tools/maven/lucene/contrib/spatial/pom.xml.template
+++ b/dev-tools/maven/lucene/contrib/spatial/pom.xml.template
@@ -53,6 +53,11 @@
       <version>${project.version}</version>
     </dependency>
     <dependency>
+      <groupId>${project.groupId}</groupId>
+      <artifactId>lucene-queries</artifactId>
+      <version>${project.version}</version>
+    </dependency>
+    <dependency>
       <groupId>junit</groupId>
       <artifactId>junit</artifactId>
       <scope>test</scope>
diff --git a/lucene/contrib/queries/src/java/org/apache/lucene/search/BooleanFilter.java b/lucene/contrib/queries/src/java/org/apache/lucene/search/BooleanFilter.java
deleted file mode 100644
index 51c3d6e..0000000
--- a/lucene/contrib/queries/src/java/org/apache/lucene/search/BooleanFilter.java
+++ /dev/null
@@ -1,184 +0,0 @@
-package org.apache.lucene.search;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.List;
-
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.IndexReader.AtomicReaderContext;
-import org.apache.lucene.search.BooleanClause.Occur;
-import org.apache.lucene.util.OpenBitSet;
-import org.apache.lucene.util.OpenBitSetDISI;
-
-/**
- * A container Filter that allows Boolean composition of Filters.
- * Filters are allocated into one of three logical constructs;
- * SHOULD, MUST NOT, MUST
- * The results Filter BitSet is constructed as follows:
- * SHOULD Filters are OR'd together
- * The resulting Filter is NOT'd with the NOT Filters
- * The resulting Filter is AND'd with the MUST Filters
- */
-
-public class BooleanFilter extends Filter {
-
-  List<Filter> shouldFilters = null;
-  List<Filter> notFilters = null;
-  List<Filter> mustFilters = null;
-
-  /**
-   * Returns the a DocIdSetIterator representing the Boolean composition
-   * of the filters that have been added.
-   */
-  @Override
-  public DocIdSet getDocIdSet(AtomicReaderContext context) throws IOException {
-    OpenBitSetDISI res = null;
-    final IndexReader reader = context.reader;
-    if (shouldFilters != null) {
-      for (int i = 0; i < shouldFilters.size(); i++) {
-        if (res == null) {
-          res = new OpenBitSetDISI(getDISI(shouldFilters, i, context), reader.maxDoc());
-        } else { 
-          DocIdSet dis = shouldFilters.get(i).getDocIdSet(context);
-          if(dis instanceof OpenBitSet) {
-            // optimized case for OpenBitSets
-            res.or((OpenBitSet) dis);
-          } else {
-            res.inPlaceOr(getDISI(shouldFilters, i, context));
-          }
-        }
-      }
-    }
-    
-    if (notFilters != null) {
-      for (int i = 0; i < notFilters.size(); i++) {
-        if (res == null) {
-          res = new OpenBitSetDISI(getDISI(notFilters, i, context), reader.maxDoc());
-          res.flip(0, reader.maxDoc()); // NOTE: may set bits on deleted docs
-        } else {
-          DocIdSet dis = notFilters.get(i).getDocIdSet(context);
-          if(dis instanceof OpenBitSet) {
-            // optimized case for OpenBitSets
-            res.andNot((OpenBitSet) dis);
-          } else {
-            res.inPlaceNot(getDISI(notFilters, i, context));
-          }
-        }
-      }
-    }
-    
-    if (mustFilters != null) {
-      for (int i = 0; i < mustFilters.size(); i++) {
-        if (res == null) {
-          res = new OpenBitSetDISI(getDISI(mustFilters, i, context), reader.maxDoc());
-        } else {
-          DocIdSet dis = mustFilters.get(i).getDocIdSet(context);
-          if(dis instanceof OpenBitSet) {
-            // optimized case for OpenBitSets
-            res.and((OpenBitSet) dis);
-          } else {
-            res.inPlaceAnd(getDISI(mustFilters, i, context));
-          }
-        }
-      }
-    }
-
-    return res != null ? res : DocIdSet.EMPTY_DOCIDSET;
-  }
-
-  /**
-  * Adds a new FilterClause to the Boolean Filter container
-  * @param filterClause A FilterClause object containing a Filter and an Occur parameter
-  */
-  public void add(FilterClause filterClause) {
-    if (filterClause.getOccur().equals(Occur.MUST)) {
-      if (mustFilters == null) {
-        mustFilters = new ArrayList<Filter>();
-      }
-      mustFilters.add(filterClause.getFilter());
-    } else if (filterClause.getOccur().equals(Occur.SHOULD)) {
-      if (shouldFilters == null) {
-        shouldFilters = new ArrayList<Filter>();
-      }
-      shouldFilters.add(filterClause.getFilter());
-    } else if (filterClause.getOccur().equals(Occur.MUST_NOT)) {
-      if (notFilters == null) {
-        notFilters = new ArrayList<Filter>();
-      }
-      notFilters.add(filterClause.getFilter());
-    }
-  }
-
-  private DocIdSetIterator getDISI(List<Filter> filters, int index, AtomicReaderContext context)
-      throws IOException {
-    return filters.get(index).getDocIdSet(context).iterator();
-  }
-  
-  @Override
-  public boolean equals(Object obj) {
-    if (this == obj) {
-      return true;
-    }
-
-    if ((obj == null) || (obj.getClass() != this.getClass())) {
-      return false;
-    }
-
-    BooleanFilter other = (BooleanFilter)obj;
-    return equalFilters(notFilters, other.notFilters)
-        && equalFilters(mustFilters, other.mustFilters)
-        && equalFilters(shouldFilters, other.shouldFilters);
-  }
-
-  private boolean equalFilters(List<Filter> filters1, List<Filter> filters2) {
-    return (filters1 == filters2) || ((filters1 != null) && filters1.equals(filters2));
-  }
-
-  @Override
-  public int hashCode() {
-    int hash = 7;
-    hash = 31 * hash + (null == mustFilters ? 0 : mustFilters.hashCode());
-    hash = 31 * hash + (null == notFilters ? 0 : notFilters.hashCode());
-    hash = 31 * hash + (null == shouldFilters ? 0 : shouldFilters.hashCode());
-    return hash;
-  }
-  
-  /** Prints a user-readable version of this query. */
-  @Override
-  public String toString() {
-    StringBuilder buffer = new StringBuilder();
-    buffer.append("BooleanFilter(");
-    appendFilters(shouldFilters, "", buffer);
-    appendFilters(mustFilters, "+", buffer);
-    appendFilters(notFilters, "-", buffer);
-    buffer.append(")");
-    return buffer.toString();
-  }
-  
-  private void appendFilters(List<Filter> filters, String occurString, StringBuilder buffer) {
-    if (filters != null) {
-      for (Filter filter : filters) {
-        buffer.append(' ');
-        buffer.append(occurString);
-        buffer.append(filter.toString());
-      }
-    }
-  }    
-}
diff --git a/lucene/contrib/queries/src/java/org/apache/lucene/search/BoostingQuery.java b/lucene/contrib/queries/src/java/org/apache/lucene/search/BoostingQuery.java
deleted file mode 100644
index f2fa951..0000000
--- a/lucene/contrib/queries/src/java/org/apache/lucene/search/BoostingQuery.java
+++ /dev/null
@@ -1,135 +0,0 @@
-package org.apache.lucene.search;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.IndexSearcher;
-
-/**
- * The BoostingQuery class can be used to effectively demote results that match a given query. 
- * Unlike the "NOT" clause, this still selects documents that contain undesirable terms, 
- * but reduces their overall score:
- *
- *     Query balancedQuery = new BoostingQuery(positiveQuery, negativeQuery, 0.01f);
- * In this scenario the positiveQuery contains the mandatory, desirable criteria which is used to 
- * select all matching documents, and the negativeQuery contains the undesirable elements which 
- * are simply used to lessen the scores. Documents that match the negativeQuery have their score 
- * multiplied by the supplied "boost" parameter, so this should be less than 1 to achieve a 
- * demoting effect
- * 
- * This code was originally made available here: [WWW] http://marc.theaimsgroup.com/?l=lucene-user&m=108058407130459&w=2
- * and is documented here: http://wiki.apache.org/lucene-java/CommunityContributions
- */
-public class BoostingQuery extends Query {
-    private float boost;                            // the amount to boost by
-    private Query match;                            // query to match
-    private Query context;                          // boost when matches too
-
-    public BoostingQuery(Query match, Query context, float boost) {
-      this.match = match;
-      this.context = (Query) context.clone();        // clone before boost
-      this.boost = boost;
-      this.context.setBoost(0.0f);                      // ignore context-only matches
-    }
-
-    @Override
-    public Query rewrite(IndexReader reader) throws IOException {
-      BooleanQuery result = new BooleanQuery() {
-        @Override
-        public Weight createWeight(IndexSearcher searcher) throws IOException {
-          return new BooleanWeight(searcher, false) {
-
-            @Override
-            public float coord(int overlap, int max) {
-              switch (overlap) {
-
-              case 1:                               // matched only one clause
-                return 1.0f;                        // use the score as-is
-
-              case 2:                               // matched both clauses
-                return boost;                       // multiply by boost
-
-              default:
-                return 0.0f;
-                
-              }
-            }
-          };
-        }
-      };
-
-      result.add(match, BooleanClause.Occur.MUST);
-      result.add(context, BooleanClause.Occur.SHOULD);
-
-      return result;
-    }
-
-    @Override
-    public int hashCode() {
-      final int prime = 31;
-      int result = 1;
-      result = prime * result + Float.floatToIntBits(boost);
-      result = prime * result + ((context == null) ? 0 : context.hashCode());
-      result = prime * result + ((match == null) ? 0 : match.hashCode());
-      return result;
-    }
-
-    @Override
-    public boolean equals(Object obj) {
-      if (this == obj) {
-        return true;
-      }
-      if (obj == null) {
-        return false;
-      }
-      if (getClass() != obj.getClass()) {
-        return false;
-      }
-
-      BoostingQuery other = (BoostingQuery) obj;
-      if (Float.floatToIntBits(boost) != Float.floatToIntBits(other.boost)) {
-        return false;
-      }
-      
-      if (context == null) {
-        if (other.context != null) {
-          return false;
-        }
-      } else if (!context.equals(other.context)) {
-        return false;
-      }
-      
-      if (match == null) {
-        if (other.match != null) {
-          return false;
-        }
-      } else if (!match.equals(other.match)) {
-        return false;
-      }
-      return true;
-    }
-
-    @Override
-    public String toString(String field) {
-      return match.toString(field) + "/" + context.toString(field);
-    }
-  }
diff --git a/lucene/contrib/queries/src/java/org/apache/lucene/search/ChainedFilter.java b/lucene/contrib/queries/src/java/org/apache/lucene/search/ChainedFilter.java
deleted file mode 100644
index 18ef1fb..0000000
--- a/lucene/contrib/queries/src/java/org/apache/lucene/search/ChainedFilter.java
+++ /dev/null
@@ -1,246 +0,0 @@
-package org.apache.lucene.search;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.IndexReader.AtomicReaderContext;
-import org.apache.lucene.util.OpenBitSet;
-import org.apache.lucene.util.OpenBitSetDISI;
-
-import java.io.IOException;
-
-/**
- * <p>
- * Allows multiple {@link Filter}s to be chained.
- * Logical operations such as <b>NOT</b> and <b>XOR</b>
- * are applied between filters. One operation can be used
- * for all filters, or a specific operation can be declared
- * for each filter.
- * </p>
- * <p>
- * Order in which filters are called depends on
- * the position of the filter in the chain. It's probably
- * more efficient to place the most restrictive filters
- * /least computationally-intensive filters first.
- * </p>
- */
-public class ChainedFilter extends Filter {
-
-  public static final int OR = 0;
-  public static final int AND = 1;
-  public static final int ANDNOT = 2;
-  public static final int XOR = 3;
-  /**
-   * Logical operation when none is declared. Defaults to OR.
-   */
-  public static int DEFAULT = OR;
-
-  /**
-   * The filter chain
-   */
-  private Filter[] chain = null;
-
-  private int[] logicArray;
-
-  private int logic = -1;
-
-  /**
-   * Ctor.
-   *
-   * @param chain The chain of filters
-   */
-  public ChainedFilter(Filter[] chain) {
-    this.chain = chain;
-  }
-
-  /**
-   * Ctor.
-   *
-   * @param chain The chain of filters
-   * @param logicArray Logical operations to apply between filters
-   */
-  public ChainedFilter(Filter[] chain, int[] logicArray) {
-    this.chain = chain;
-    this.logicArray = logicArray;
-  }
-
-  /**
-   * Ctor.
-   *
-   * @param chain The chain of filters
-   * @param logic Logical operation to apply to ALL filters
-   */
-  public ChainedFilter(Filter[] chain, int logic) {
-    this.chain = chain;
-    this.logic = logic;
-  }
-
-  /**
-   * {@link Filter#getDocIdSet}.
-   */
-  @Override
-  public DocIdSet getDocIdSet(AtomicReaderContext context) throws IOException {
-    int[] index = new int[1]; // use array as reference to modifiable int;
-    index[0] = 0;             // an object attribute would not be thread safe.
-    if (logic != -1) {
-      return getDocIdSet(context, logic, index);
-    } else if (logicArray != null) {
-      return getDocIdSet(context, logicArray, index);
-    }
-
-    return getDocIdSet(context, DEFAULT, index);
-  }
-
-  private DocIdSetIterator getDISI(Filter filter, AtomicReaderContext context)
-      throws IOException {
-    DocIdSet docIdSet = filter.getDocIdSet(context);
-    if (docIdSet == null) {
-      return DocIdSet.EMPTY_DOCIDSET.iterator();
-    } else {
-      DocIdSetIterator iter = docIdSet.iterator();
-      if (iter == null) {
-        return DocIdSet.EMPTY_DOCIDSET.iterator();
-      } else {
-        return iter;
-      }
-    }
-  }
-
-  private OpenBitSetDISI initialResult(AtomicReaderContext context, int logic, int[] index)
-      throws IOException {
-    IndexReader reader = context.reader;
-    OpenBitSetDISI result;
-    /**
-     * First AND operation takes place against a completely false
-     * bitset and will always return zero results.
-     */
-    if (logic == AND) {
-      result = new OpenBitSetDISI(getDISI(chain[index[0]], context), reader.maxDoc());
-      ++index[0];
-    } else if (logic == ANDNOT) {
-      result = new OpenBitSetDISI(getDISI(chain[index[0]], context), reader.maxDoc());
-      result.flip(0, reader.maxDoc()); // NOTE: may set bits for deleted docs.
-      ++index[0];
-    } else {
-      result = new OpenBitSetDISI(reader.maxDoc());
-    }
-    return result;
-  }
-
-  /**
-   * Delegates to each filter in the chain.
-   *
-   * @param context AtomicReaderContext
-   * @param logic Logical operation
-   * @return DocIdSet
-   */
-  private DocIdSet getDocIdSet(AtomicReaderContext context, int logic, int[] index)
-      throws IOException {
-    OpenBitSetDISI result = initialResult(context, logic, index);
-    for (; index[0] < chain.length; index[0]++) {
-      doChain(result, logic, chain[index[0]].getDocIdSet(context));
-    }
-    return result;
-  }
-
-  /**
-   * Delegates to each filter in the chain.
-   *
-   * @param context AtomicReaderContext
-   * @param logic Logical operation
-   * @return DocIdSet
-   */
-  private DocIdSet getDocIdSet(AtomicReaderContext context, int[] logic, int[] index)
-      throws IOException {
-    if (logic.length != chain.length) {
-      throw new IllegalArgumentException("Invalid number of elements in logic array");
-    }
-
-    OpenBitSetDISI result = initialResult(context, logic[0], index);
-    for (; index[0] < chain.length; index[0]++) {
-      doChain(result, logic[index[0]], chain[index[0]].getDocIdSet(context));
-    }
-    return result;
-  }
-
-  @Override
-  public String toString() {
-    StringBuilder sb = new StringBuilder();
-    sb.append("ChainedFilter: [");
-    for (Filter aChain : chain) {
-      sb.append(aChain);
-      sb.append(' ');
-    }
-    sb.append(']');
-    return sb.toString();
-  }
-
-  private void doChain(OpenBitSetDISI result, int logic, DocIdSet dis)
-      throws IOException {
-
-    if (dis instanceof OpenBitSet) {
-      // optimized case for OpenBitSets
-      switch (logic) {
-        case OR:
-          result.or((OpenBitSet) dis);
-          break;
-        case AND:
-          result.and((OpenBitSet) dis);
-          break;
-        case ANDNOT:
-          result.andNot((OpenBitSet) dis);
-          break;
-        case XOR:
-          result.xor((OpenBitSet) dis);
-          break;
-        default:
-          doChain(result, DEFAULT, dis);
-          break;
-      }
-    } else {
-      DocIdSetIterator disi;
-      if (dis == null) {
-        disi = DocIdSet.EMPTY_DOCIDSET.iterator();
-      } else {
-        disi = dis.iterator();
-        if (disi == null) {
-          disi = DocIdSet.EMPTY_DOCIDSET.iterator();
-        }
-      }
-
-      switch (logic) {
-        case OR:
-          result.inPlaceOr(disi);
-          break;
-        case AND:
-          result.inPlaceAnd(disi);
-          break;
-        case ANDNOT:
-          result.inPlaceNot(disi);
-          break;
-        case XOR:
-          result.inPlaceXor(disi);
-          break;
-        default:
-          doChain(result, DEFAULT, dis);
-          break;
-      }
-    }
-  }
-
-}
diff --git a/lucene/contrib/queries/src/java/org/apache/lucene/search/DuplicateFilter.java b/lucene/contrib/queries/src/java/org/apache/lucene/search/DuplicateFilter.java
deleted file mode 100644
index 409fdb5..0000000
--- a/lucene/contrib/queries/src/java/org/apache/lucene/search/DuplicateFilter.java
+++ /dev/null
@@ -1,212 +0,0 @@
-package org.apache.lucene.search;
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.index.*;
-import org.apache.lucene.index.IndexReader.AtomicReaderContext;
-import org.apache.lucene.util.Bits;
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.FixedBitSet;
-
-import java.io.IOException;
-
-public class DuplicateFilter extends Filter {
-  // TODO: make duplicate filter aware of ReaderContext such that we can
-  // filter duplicates across segments
-
-  /**
-   * KeepMode determines which document id to consider as the master, all others being
-   * identified as duplicates. Selecting the "first occurrence" can potentially save on IO.
-   */
-  public enum KeepMode {
-    KM_USE_FIRST_OCCURRENCE, KM_USE_LAST_OCCURRENCE
-  }
-
-  private KeepMode keepMode;
-
-  /**
-   * "Full" processing mode starts by setting all bits to false and only setting bits
-   * for documents that contain the given field and are identified as none-duplicates.
-   * <p/>
-   * "Fast" processing sets all bits to true then unsets all duplicate docs found for the
-   * given field. This approach avoids the need to read TermDocs for terms that are seen
-   * to have a document frequency of exactly "1" (i.e. no duplicates). While a potentially
-   * faster approach , the downside is that bitsets produced will include bits set for
-   * documents that do not actually contain the field given.
-   */
-
-  public enum ProcessingMode {
-    PM_FULL_VALIDATION, PM_FAST_INVALIDATION
-  }
-
-  private ProcessingMode processingMode;
-
-  private String fieldName;
-
-  public DuplicateFilter(String fieldName) {
-    this(fieldName, KeepMode.KM_USE_LAST_OCCURRENCE, ProcessingMode.PM_FULL_VALIDATION);
-  }
-
-  public DuplicateFilter(String fieldName, KeepMode keepMode, ProcessingMode processingMode) {
-    this.fieldName = fieldName;
-    this.keepMode = keepMode;
-    this.processingMode = processingMode;
-  }
-
-  @Override
-  public DocIdSet getDocIdSet(AtomicReaderContext context) throws IOException {
-    if (processingMode == ProcessingMode.PM_FAST_INVALIDATION) {
-      return fastBits(context.reader);
-    } else {
-      return correctBits(context.reader);
-    }
-  }
-
-  private FixedBitSet correctBits(IndexReader reader) throws IOException {
-    FixedBitSet bits = new FixedBitSet(reader.maxDoc()); //assume all are INvalid
-    final Bits liveDocs = MultiFields.getLiveDocs(reader);
-    Terms terms = reader.fields().terms(fieldName);
-
-    if (terms == null) {
-      return bits;
-    }
-
-    TermsEnum termsEnum = terms.iterator();
-    DocsEnum docs = null;
-    while (true) {
-      BytesRef currTerm = termsEnum.next();
-      if (currTerm == null) {
-        break;
-      } else {
-        docs = termsEnum.docs(liveDocs, docs);
-        int doc = docs.nextDoc();
-        if (doc != DocsEnum.NO_MORE_DOCS) {
-          if (keepMode == KeepMode.KM_USE_FIRST_OCCURRENCE) {
-            bits.set(doc);
-          } else {
-            int lastDoc = doc;
-            while (true) {
-              lastDoc = doc;
-              doc = docs.nextDoc();
-              if (doc == DocsEnum.NO_MORE_DOCS) {
-                break;
-              }
-            }
-            bits.set(lastDoc);
-          }
-        }
-      }
-    }
-    return bits;
-  }
-
-  private FixedBitSet fastBits(IndexReader reader) throws IOException {
-    FixedBitSet bits = new FixedBitSet(reader.maxDoc());
-    bits.set(0, reader.maxDoc()); //assume all are valid
-    final Bits liveDocs = MultiFields.getLiveDocs(reader);
-    Terms terms = reader.fields().terms(fieldName);
-
-    if (terms == null) {
-      return bits;
-    }
-
-    TermsEnum termsEnum = terms.iterator();
-    DocsEnum docs = null;
-    while (true) {
-      BytesRef currTerm = termsEnum.next();
-      if (currTerm == null) {
-        break;
-      } else {
-        if (termsEnum.docFreq() > 1) {
-          // unset potential duplicates
-          docs = termsEnum.docs(liveDocs, docs);
-          int doc = docs.nextDoc();
-          if (doc != DocsEnum.NO_MORE_DOCS) {
-            if (keepMode == KeepMode.KM_USE_FIRST_OCCURRENCE) {
-              doc = docs.nextDoc();
-            }
-          }
-
-          int lastDoc = -1;
-          while (true) {
-            lastDoc = doc;
-            bits.clear(lastDoc);
-            doc = docs.nextDoc();
-            if (doc == DocsEnum.NO_MORE_DOCS) {
-              break;
-            }
-          }
-
-          if (keepMode == KeepMode.KM_USE_LAST_OCCURRENCE) {
-            // restore the last bit
-            bits.set(lastDoc);
-          }
-        }
-      }
-    }
-
-    return bits;
-  }
-
-  public String getFieldName() {
-    return fieldName;
-  }
-
-  public void setFieldName(String fieldName) {
-    this.fieldName = fieldName;
-  }
-
-  public KeepMode getKeepMode() {
-    return keepMode;
-  }
-
-  public void setKeepMode(KeepMode keepMode) {
-    this.keepMode = keepMode;
-  }
-
-  @Override
-  public boolean equals(Object obj) {
-    if (this == obj) {
-      return true;
-    }
-    if ((obj == null) || (obj.getClass() != this.getClass())) {
-      return false;
-    }
-
-    DuplicateFilter other = (DuplicateFilter) obj;
-    return keepMode == other.keepMode &&
-        processingMode == other.processingMode &&
-        fieldName != null && fieldName.equals(other.fieldName);
-  }
-
-  @Override
-  public int hashCode() {
-    int hash = 217;
-    hash = 31 * hash + keepMode.hashCode();
-    hash = 31 * hash + processingMode.hashCode();
-    hash = 31 * hash + fieldName.hashCode();
-    return hash;
-  }
-
-  public ProcessingMode getProcessingMode() {
-    return processingMode;
-  }
-
-  public void setProcessingMode(ProcessingMode processingMode) {
-    this.processingMode = processingMode;
-  }
-}
diff --git a/lucene/contrib/queries/src/java/org/apache/lucene/search/FilterClause.java b/lucene/contrib/queries/src/java/org/apache/lucene/search/FilterClause.java
deleted file mode 100644
index 81537b6..0000000
--- a/lucene/contrib/queries/src/java/org/apache/lucene/search/FilterClause.java
+++ /dev/null
@@ -1,60 +0,0 @@
-package org.apache.lucene.search;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.search.BooleanClause.Occur;
-
-/**
- * A Filter that wrapped with an indication of how that filter
- * is used when composed with another filter.
- * (Follows the boolean logic in BooleanClause for composition 
- * of queries.)
- */
-public class FilterClause {
-
-	private final Occur occur;
-	private final Filter filter;
-
-	/**
-	 * Create a new FilterClause
-	 * @param filter A Filter object containing a BitSet
-	 * @param occur A parameter implementation indicating SHOULD, MUST or MUST NOT
-	 */
-	
-	public FilterClause(Filter filter, Occur occur) {
-		this.occur = occur;
-		this.filter = filter;
-	}
-
-	/**
-	 * Returns this FilterClause's filter
-	 * @return A Filter object
-	 */
-	public Filter getFilter() {
-		return filter;
-	}
-
-	/**
-	 * Returns this FilterClause's occur parameter
-	 * @return An Occur object
-	 */
-	public Occur getOccur() {
-		return occur;
-	}
-
-}
diff --git a/lucene/contrib/queries/src/java/org/apache/lucene/search/TermsFilter.java b/lucene/contrib/queries/src/java/org/apache/lucene/search/TermsFilter.java
deleted file mode 100644
index ca51843..0000000
--- a/lucene/contrib/queries/src/java/org/apache/lucene/search/TermsFilter.java
+++ /dev/null
@@ -1,113 +0,0 @@
-package org.apache.lucene.search;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.index.*;
-import org.apache.lucene.index.IndexReader.AtomicReaderContext;
-import org.apache.lucene.util.Bits;
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.FixedBitSet;
-
-import java.io.IOException;
-import java.util.Set;
-import java.util.TreeSet;
-
-/**
- * Constructs a filter for docs matching any of the terms added to this class.
- * Unlike a RangeFilter this can be used for filtering on multiple terms that are not necessarily in
- * a sequence. An example might be a collection of primary keys from a database query result or perhaps
- * a choice of "category" labels picked by the end user. As a filter, this is much faster than the
- * equivalent query (a BooleanQuery with many "should" TermQueries)
- */
-public class TermsFilter extends Filter {
-
-  private final Set<Term> terms = new TreeSet<Term>();
-
-  /**
-   * Adds a term to the list of acceptable terms
-   *
-   * @param term
-   */
-  public void addTerm(Term term) {
-    terms.add(term);
-  }
-
-/* (non-Javadoc)
-   * @see org.apache.lucene.search.Filter#getDocIdSet(org.apache.lucene.index.IndexReader)
-   */
-
-  @Override
-  public DocIdSet getDocIdSet(AtomicReaderContext context) throws IOException {
-    IndexReader reader = context.reader;
-    FixedBitSet result = new FixedBitSet(reader.maxDoc());
-    Fields fields = reader.fields();
-
-    if (fields == null) {
-      return result;
-    }
-
-    BytesRef br = new BytesRef();
-    Bits liveDocs = reader.getLiveDocs();
-    String lastField = null;
-    Terms termsC = null;
-    TermsEnum termsEnum = null;
-    DocsEnum docs = null;
-    for (Term term : terms) {
-      if (!term.field().equals(lastField)) {
-        termsC = fields.terms(term.field());
-        termsEnum = termsC.iterator();
-        lastField = term.field();
-      }
-
-      if (terms != null) { // TODO this check doesn't make sense, decide which variable its supposed to be for
-        br.copy(term.bytes());
-        if (termsEnum.seekCeil(br) == TermsEnum.SeekStatus.FOUND) {
-          docs = termsEnum.docs(liveDocs, docs);
-          while (docs.nextDoc() != DocsEnum.NO_MORE_DOCS) {
-            result.set(docs.docID());
-          }
-        }
-      }
-    }
-    return result;
-  }
-
-  @Override
-  public boolean equals(Object obj) {
-    if (this == obj) {
-      return true;
-    }
-    if ((obj == null) || (obj.getClass() != this.getClass())) {
-      return false;
-    }
-
-    TermsFilter test = (TermsFilter) obj;
-    return (terms == test.terms ||
-        (terms != null && terms.equals(test.terms)));
-  }
-
-  @Override
-  public int hashCode() {
-    int hash = 9;
-    for (Term term : terms) {
-      hash = 31 * hash + term.hashCode();
-    }
-    return hash;
-  }
-
-}
diff --git a/lucene/contrib/queries/src/test/org/apache/lucene/search/BooleanFilterTest.java b/lucene/contrib/queries/src/test/org/apache/lucene/search/BooleanFilterTest.java
deleted file mode 100644
index 0f4dd19..0000000
--- a/lucene/contrib/queries/src/test/org/apache/lucene/search/BooleanFilterTest.java
+++ /dev/null
@@ -1,161 +0,0 @@
-package org.apache.lucene.search;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.MockAnalyzer;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.IndexReader.AtomicReaderContext;
-import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.SlowMultiReaderWrapper;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.LuceneTestCase;
-
-import java.io.IOException;
-
-public class BooleanFilterTest extends LuceneTestCase {
-  private Directory directory;
-  private IndexReader reader;
-
-  @Override
-  public void setUp() throws Exception {
-    super.setUp();
-    directory = newDirectory();
-    RandomIndexWriter writer = new RandomIndexWriter(random, directory, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false));
-
-    //Add series of docs with filterable fields : acces rights, prices, dates and "in-stock" flags
-    addDoc(writer, "admin guest", "010", "20040101", "Y");
-    addDoc(writer, "guest", "020", "20040101", "Y");
-    addDoc(writer, "guest", "020", "20050101", "Y");
-    addDoc(writer, "admin", "020", "20050101", "Maybe");
-    addDoc(writer, "admin guest", "030", "20050101", "N");
-    reader = new SlowMultiReaderWrapper(writer.getReader());
-    writer.close();
-  }
-
-  @Override
-  public void tearDown() throws Exception {
-    reader.close();
-    directory.close();
-    super.tearDown();
-  }
-
-  private void addDoc(RandomIndexWriter writer, String accessRights, String price, String date, String inStock) throws IOException {
-    Document doc = new Document();
-    doc.add(newField("accessRights", accessRights, Field.Store.YES, Field.Index.ANALYZED));
-    doc.add(newField("price", price, Field.Store.YES, Field.Index.ANALYZED));
-    doc.add(newField("date", date, Field.Store.YES, Field.Index.ANALYZED));
-    doc.add(newField("inStock", inStock, Field.Store.YES, Field.Index.ANALYZED));
-    writer.addDocument(doc);
-  }
-
-  private Filter getRangeFilter(String field, String lowerPrice, String upperPrice) {
-    Filter f = TermRangeFilter.newStringRange(field, lowerPrice, upperPrice, true, true);
-    return f;
-  }
-
-  private Filter getTermsFilter(String field, String text) {
-    TermsFilter tf = new TermsFilter();
-    tf.addTerm(new Term(field, text));
-
-    return tf;
-  }
-
-  private void tstFilterCard(String mes, int expected, Filter filt)
-      throws Throwable {
-    DocIdSetIterator disi = filt.getDocIdSet(new AtomicReaderContext(reader)).iterator();
-    int actual = 0;
-    while (disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
-      actual++;
-    }
-    assertEquals(mes, expected, actual);
-  }
-
-
-  public void testShould() throws Throwable {
-    BooleanFilter booleanFilter = new BooleanFilter();
-    booleanFilter.add(new FilterClause(getTermsFilter("price", "030"), BooleanClause.Occur.SHOULD));
-    tstFilterCard("Should retrieves only 1 doc", 1, booleanFilter);
-  }
-
-  public void testShoulds() throws Throwable {
-    BooleanFilter booleanFilter = new BooleanFilter();
-    booleanFilter.add(new FilterClause(getRangeFilter("price", "010", "020"), BooleanClause.Occur.SHOULD));
-    booleanFilter.add(new FilterClause(getRangeFilter("price", "020", "030"), BooleanClause.Occur.SHOULD));
-    tstFilterCard("Shoulds are Ored together", 5, booleanFilter);
-  }
-
-  public void testShouldsAndMustNot() throws Throwable {
-    BooleanFilter booleanFilter = new BooleanFilter();
-    booleanFilter.add(new FilterClause(getRangeFilter("price", "010", "020"), BooleanClause.Occur.SHOULD));
-    booleanFilter.add(new FilterClause(getRangeFilter("price", "020", "030"), BooleanClause.Occur.SHOULD));
-    booleanFilter.add(new FilterClause(getTermsFilter("inStock", "N"), BooleanClause.Occur.MUST_NOT));
-    tstFilterCard("Shoulds Ored but AndNot", 4, booleanFilter);
-
-    booleanFilter.add(new FilterClause(getTermsFilter("inStock", "Maybe"), BooleanClause.Occur.MUST_NOT));
-    tstFilterCard("Shoulds Ored but AndNots", 3, booleanFilter);
-  }
-
-  public void testShouldsAndMust() throws Throwable {
-    BooleanFilter booleanFilter = new BooleanFilter();
-    booleanFilter.add(new FilterClause(getRangeFilter("price", "010", "020"), BooleanClause.Occur.SHOULD));
-    booleanFilter.add(new FilterClause(getRangeFilter("price", "020", "030"), BooleanClause.Occur.SHOULD));
-    booleanFilter.add(new FilterClause(getTermsFilter("accessRights", "admin"), BooleanClause.Occur.MUST));
-    tstFilterCard("Shoulds Ored but MUST", 3, booleanFilter);
-  }
-
-  public void testShouldsAndMusts() throws Throwable {
-    BooleanFilter booleanFilter = new BooleanFilter();
-    booleanFilter.add(new FilterClause(getRangeFilter("price", "010", "020"), BooleanClause.Occur.SHOULD));
-    booleanFilter.add(new FilterClause(getRangeFilter("price", "020", "030"), BooleanClause.Occur.SHOULD));
-    booleanFilter.add(new FilterClause(getTermsFilter("accessRights", "admin"), BooleanClause.Occur.MUST));
-    booleanFilter.add(new FilterClause(getRangeFilter("date", "20040101", "20041231"), BooleanClause.Occur.MUST));
-    tstFilterCard("Shoulds Ored but MUSTs ANDED", 1, booleanFilter);
-  }
-
-  public void testShouldsAndMustsAndMustNot() throws Throwable {
-    BooleanFilter booleanFilter = new BooleanFilter();
-    booleanFilter.add(new FilterClause(getRangeFilter("price", "030", "040"), BooleanClause.Occur.SHOULD));
-    booleanFilter.add(new FilterClause(getTermsFilter("accessRights", "admin"), BooleanClause.Occur.MUST));
-    booleanFilter.add(new FilterClause(getRangeFilter("date", "20050101", "20051231"), BooleanClause.Occur.MUST));
-    booleanFilter.add(new FilterClause(getTermsFilter("inStock", "N"), BooleanClause.Occur.MUST_NOT));
-    tstFilterCard("Shoulds Ored but MUSTs ANDED and MustNot", 0, booleanFilter);
-  }
-
-  public void testJustMust() throws Throwable {
-    BooleanFilter booleanFilter = new BooleanFilter();
-    booleanFilter.add(new FilterClause(getTermsFilter("accessRights", "admin"), BooleanClause.Occur.MUST));
-    tstFilterCard("MUST", 3, booleanFilter);
-  }
-
-  public void testJustMustNot() throws Throwable {
-    BooleanFilter booleanFilter = new BooleanFilter();
-    booleanFilter.add(new FilterClause(getTermsFilter("inStock", "N"), BooleanClause.Occur.MUST_NOT));
-    tstFilterCard("MUST_NOT", 4, booleanFilter);
-  }
-
-  public void testMustAndMustNot() throws Throwable {
-    BooleanFilter booleanFilter = new BooleanFilter();
-    booleanFilter.add(new FilterClause(getTermsFilter("inStock", "N"), BooleanClause.Occur.MUST));
-    booleanFilter.add(new FilterClause(getTermsFilter("price", "030"), BooleanClause.Occur.MUST_NOT));
-    tstFilterCard("MUST_NOT wins over MUST for same docs", 0, booleanFilter);
-  }
-}
diff --git a/lucene/contrib/queries/src/test/org/apache/lucene/search/BoostingQueryTest.java b/lucene/contrib/queries/src/test/org/apache/lucene/search/BoostingQueryTest.java
deleted file mode 100644
index 66e9282..0000000
--- a/lucene/contrib/queries/src/test/org/apache/lucene/search/BoostingQueryTest.java
+++ /dev/null
@@ -1,32 +0,0 @@
-package org.apache.lucene.search;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.index.Term;
-import org.apache.lucene.util.LuceneTestCase;
-
-public class BoostingQueryTest extends LuceneTestCase {
-  public void testBoostingQueryEquals() {
-    TermQuery q1 = new TermQuery(new Term("subject:", "java"));
-    TermQuery q2 = new TermQuery(new Term("subject:", "java"));
-    assertEquals("Two TermQueries with same attributes should be equal", q1, q2);
-    BoostingQuery bq1 = new BoostingQuery(q1, q2, 0.1f);
-    BoostingQuery bq2 = new BoostingQuery(q1, q2, 0.1f);
-    assertEquals("BoostingQuery with same attributes is not equal", bq1, bq2);
-  }
-}
diff --git a/lucene/contrib/queries/src/test/org/apache/lucene/search/ChainedFilterTest.java b/lucene/contrib/queries/src/test/org/apache/lucene/search/ChainedFilterTest.java
deleted file mode 100644
index 27e091b..0000000
--- a/lucene/contrib/queries/src/test/org/apache/lucene/search/ChainedFilterTest.java
+++ /dev/null
@@ -1,219 +0,0 @@
-package org.apache.lucene.search;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.util.Calendar;
-import java.util.GregorianCalendar;
-
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.CachingWrapperFilter;
-import org.apache.lucene.search.Filter;
-import org.apache.lucene.search.MatchAllDocsQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.QueryWrapperFilter;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.TermQuery;
-import org.apache.lucene.search.TermRangeFilter;
-import org.apache.lucene.search.TopDocs;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.LuceneTestCase;
-
-public class ChainedFilterTest extends LuceneTestCase {
-  public static final int MAX = 500;
-
-  private Directory directory;
-  private IndexSearcher searcher;
-  private IndexReader reader;
-  private Query query;
-  // private DateFilter dateFilter;   DateFilter was deprecated and removed
-  private TermRangeFilter dateFilter;
-  private QueryWrapperFilter bobFilter;
-  private QueryWrapperFilter sueFilter;
-
-  @Override
-  public void setUp() throws Exception {
-    super.setUp();
-    directory = newDirectory();
-    RandomIndexWriter writer = new RandomIndexWriter(random, directory);
-    Calendar cal = new GregorianCalendar();
-    cal.clear();
-    cal.setTimeInMillis(1041397200000L); // 2003 January 01
-
-    for (int i = 0; i < MAX; i++) {
-      Document doc = new Document();
-      doc.add(newField("key", "" + (i + 1), Field.Store.YES, Field.Index.NOT_ANALYZED));
-      doc.add(newField("owner", (i < MAX / 2) ? "bob" : "sue", Field.Store.YES, Field.Index.NOT_ANALYZED));
-      doc.add(newField("date", cal.getTime().toString(), Field.Store.YES, Field.Index.NOT_ANALYZED));
-      writer.addDocument(doc);
-
-      cal.add(Calendar.DATE, 1);
-    }
-    reader = writer.getReader();
-    writer.close();
-
-    searcher = newSearcher(reader);
-
-    // query for everything to make life easier
-    BooleanQuery bq = new BooleanQuery();
-    bq.add(new TermQuery(new Term("owner", "bob")), BooleanClause.Occur.SHOULD);
-    bq.add(new TermQuery(new Term("owner", "sue")), BooleanClause.Occur.SHOULD);
-    query = bq;
-
-    // date filter matches everything too
-    //Date pastTheEnd = parseDate("2099 Jan 1");
-    // dateFilter = DateFilter.Before("date", pastTheEnd);
-    // just treat dates as strings and select the whole range for now...
-    dateFilter = TermRangeFilter.newStringRange("date","","ZZZZ",true,true);
-
-    bobFilter = new QueryWrapperFilter(
-        new TermQuery(new Term("owner", "bob")));
-    sueFilter = new QueryWrapperFilter(
-        new TermQuery(new Term("owner", "sue")));
-  }
-
-  @Override
-  public void tearDown() throws Exception {
-    searcher.close();
-    reader.close();
-    directory.close();
-    super.tearDown();
-  }
-
-  private ChainedFilter getChainedFilter(Filter[] chain, int[] logic) {
-    if (logic == null) {
-      return new ChainedFilter(chain);
-    } else {
-      return new ChainedFilter(chain, logic);
-    }
-  }
-
-  private ChainedFilter getChainedFilter(Filter[] chain, int logic) {
-    return new ChainedFilter(chain, logic);
-  }
-
-  
-  public void testSingleFilter() throws Exception {
-    ChainedFilter chain = getChainedFilter(new Filter[] {dateFilter}, null);
-
-    int numHits = searcher.search(query, chain, 1000).totalHits;
-    assertEquals(MAX, numHits);
-
-    chain = new ChainedFilter(new Filter[] {bobFilter});
-    numHits = searcher.search(query, chain, 1000).totalHits;
-    assertEquals(MAX / 2, numHits);
-    
-    chain = getChainedFilter(new Filter[] {bobFilter}, new int[] {ChainedFilter.AND});
-    TopDocs hits = searcher.search(query, chain, 1000);
-    numHits = hits.totalHits;
-    assertEquals(MAX / 2, numHits);
-    assertEquals("bob", searcher.doc(hits.scoreDocs[0].doc).get("owner"));
-    
-    chain = getChainedFilter(new Filter[] {bobFilter}, new int[] {ChainedFilter.ANDNOT});
-    hits = searcher.search(query, chain, 1000);
-    numHits = hits.totalHits;
-    assertEquals(MAX / 2, numHits);
-    assertEquals("sue", searcher.doc(hits.scoreDocs[0].doc).get("owner"));
-  }
-
-  public void testOR() throws Exception {
-    ChainedFilter chain = getChainedFilter(
-      new Filter[] {sueFilter, bobFilter}, null);
-
-    int numHits = searcher.search(query, chain, 1000).totalHits;
-    assertEquals("OR matches all", MAX, numHits);
-  }
-
-  public void testAND() throws Exception {
-    ChainedFilter chain = getChainedFilter(
-      new Filter[] {dateFilter, bobFilter}, ChainedFilter.AND);
-
-    TopDocs hits = searcher.search(query, chain, 1000);
-    assertEquals("AND matches just bob", MAX / 2, hits.totalHits);
-    assertEquals("bob", searcher.doc(hits.scoreDocs[0].doc).get("owner"));
-  }
-
-  public void testXOR() throws Exception {
-    ChainedFilter chain = getChainedFilter(
-      new Filter[]{dateFilter, bobFilter}, ChainedFilter.XOR);
-
-    TopDocs hits = searcher.search(query, chain, 1000);
-    assertEquals("XOR matches sue", MAX / 2, hits.totalHits);
-    assertEquals("sue", searcher.doc(hits.scoreDocs[0].doc).get("owner"));
-  }
-
-  public void testANDNOT() throws Exception {
-    ChainedFilter chain = getChainedFilter(
-      new Filter[]{dateFilter, sueFilter},
-        new int[] {ChainedFilter.AND, ChainedFilter.ANDNOT});
-
-    TopDocs hits = searcher.search(query, chain, 1000);
-    assertEquals("ANDNOT matches just bob",
-        MAX / 2, hits.totalHits);
-    assertEquals("bob", searcher.doc(hits.scoreDocs[0].doc).get("owner"));
-    
-    chain = getChainedFilter(
-        new Filter[]{bobFilter, bobFilter},
-          new int[] {ChainedFilter.ANDNOT, ChainedFilter.ANDNOT});
-
-      hits = searcher.search(query, chain, 1000);
-      assertEquals("ANDNOT bob ANDNOT bob matches all sues",
-          MAX / 2, hits.totalHits);
-      assertEquals("sue", searcher.doc(hits.scoreDocs[0].doc).get("owner"));
-  }
-
-  /*
-  private Date parseDate(String s) throws ParseException {
-    return new SimpleDateFormat("yyyy MMM dd", Locale.US).parse(s);
-  }
-  */
-  
-  public void testWithCachingFilter() throws Exception {
-    Directory dir = newDirectory();
-    RandomIndexWriter writer = new RandomIndexWriter(random, dir);
-    IndexReader reader = writer.getReader();
-    writer.close();
-  
-    IndexSearcher searcher = newSearcher(reader);
-  
-    Query query = new TermQuery(new Term("none", "none"));
-  
-    QueryWrapperFilter queryFilter = new QueryWrapperFilter(query);
-    CachingWrapperFilter cachingFilter = new CachingWrapperFilter(queryFilter);
-  
-    searcher.search(query, cachingFilter, 1);
-  
-    CachingWrapperFilter cachingFilter2 = new CachingWrapperFilter(queryFilter);
-    Filter[] chain = new Filter[2];
-    chain[0] = cachingFilter;
-    chain[1] = cachingFilter2;
-    ChainedFilter cf = new ChainedFilter(chain);
-  
-    // throws java.lang.ClassCastException: org.apache.lucene.util.OpenBitSet cannot be cast to java.util.BitSet
-    searcher.search(new MatchAllDocsQuery(), cf, 1);
-    searcher.close();
-    reader.close();
-    dir.close();
-  }
-
-}
diff --git a/lucene/contrib/queries/src/test/org/apache/lucene/search/DuplicateFilterTest.java b/lucene/contrib/queries/src/test/org/apache/lucene/search/DuplicateFilterTest.java
deleted file mode 100644
index ea38185..0000000
--- a/lucene/contrib/queries/src/test/org/apache/lucene/search/DuplicateFilterTest.java
+++ /dev/null
@@ -1,166 +0,0 @@
-package org.apache.lucene.search;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.MockAnalyzer;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.index.*;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.LuceneTestCase;
-
-import java.io.IOException;
-import java.util.HashSet;
-
-public class DuplicateFilterTest extends LuceneTestCase {
-  private static final String KEY_FIELD = "url";
-  private Directory directory;
-  private IndexReader reader;
-  TermQuery tq = new TermQuery(new Term("text", "lucene"));
-  private IndexSearcher searcher;
-
-  @Override
-  public void setUp() throws Exception {
-    super.setUp();
-    directory = newDirectory();
-    RandomIndexWriter writer = new RandomIndexWriter(random, directory, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));
-
-    //Add series of docs with filterable fields : url, text and dates  flags
-    addDoc(writer, "http://lucene.apache.org", "lucene 1.4.3 available", "20040101");
-    addDoc(writer, "http://lucene.apache.org", "New release pending", "20040102");
-    addDoc(writer, "http://lucene.apache.org", "Lucene 1.9 out now", "20050101");
-    addDoc(writer, "http://www.bar.com", "Local man bites dog", "20040101");
-    addDoc(writer, "http://www.bar.com", "Dog bites local man", "20040102");
-    addDoc(writer, "http://www.bar.com", "Dog uses Lucene", "20050101");
-    addDoc(writer, "http://lucene.apache.org", "Lucene 2.0 out", "20050101");
-    addDoc(writer, "http://lucene.apache.org", "Oops. Lucene 2.1 out", "20050102");
-
-    // Until we fix LUCENE-2348, the index must
-    // have only 1 segment:
-    writer.optimize();
-
-    reader = writer.getReader();
-    writer.close();
-    searcher = newSearcher(reader);
-
-  }
-
-  @Override
-  public void tearDown() throws Exception {
-    reader.close();
-    searcher.close();
-    directory.close();
-    super.tearDown();
-  }
-
-  private void addDoc(RandomIndexWriter writer, String url, String text, String date) throws IOException {
-    Document doc = new Document();
-    doc.add(newField(KEY_FIELD, url, Field.Store.YES, Field.Index.NOT_ANALYZED));
-    doc.add(newField("text", text, Field.Store.YES, Field.Index.ANALYZED));
-    doc.add(newField("date", date, Field.Store.YES, Field.Index.ANALYZED));
-    writer.addDocument(doc);
-  }
-
-  public void testDefaultFilter() throws Throwable {
-    DuplicateFilter df = new DuplicateFilter(KEY_FIELD);
-    HashSet<String> results = new HashSet<String>();
-    ScoreDoc[] hits = searcher.search(tq, df, 1000).scoreDocs;
-
-    for (ScoreDoc hit : hits) {
-      Document d = searcher.doc(hit.doc);
-      String url = d.get(KEY_FIELD);
-      assertFalse("No duplicate urls should be returned", results.contains(url));
-      results.add(url);
-    }
-  }
-
-  public void testNoFilter() throws Throwable {
-    HashSet<String> results = new HashSet<String>();
-    ScoreDoc[] hits = searcher.search(tq, null, 1000).scoreDocs;
-    assertTrue("Default searching should have found some matches", hits.length > 0);
-    boolean dupsFound = false;
-
-    for (ScoreDoc hit : hits) {
-      Document d = searcher.doc(hit.doc);
-      String url = d.get(KEY_FIELD);
-      if (!dupsFound)
-        dupsFound = results.contains(url);
-      results.add(url);
-    }
-    assertTrue("Default searching should have found duplicate urls", dupsFound);
-  }
-
-  public void testFastFilter() throws Throwable {
-    DuplicateFilter df = new DuplicateFilter(KEY_FIELD);
-    df.setProcessingMode(DuplicateFilter.ProcessingMode.PM_FAST_INVALIDATION);
-    HashSet<String> results = new HashSet<String>();
-    ScoreDoc[] hits = searcher.search(tq, df, 1000).scoreDocs;
-    assertTrue("Filtered searching should have found some matches", hits.length > 0);
-
-    for (ScoreDoc hit : hits) {
-      Document d = searcher.doc(hit.doc);
-      String url = d.get(KEY_FIELD);
-      assertFalse("No duplicate urls should be returned", results.contains(url));
-      results.add(url);
-    }
-    assertEquals("Two urls found", 2, results.size());
-  }
-
-  public void testKeepsLastFilter() throws Throwable {
-    DuplicateFilter df = new DuplicateFilter(KEY_FIELD);
-    df.setKeepMode(DuplicateFilter.KeepMode.KM_USE_LAST_OCCURRENCE);
-    ScoreDoc[] hits = searcher.search(tq, df, 1000).scoreDocs;
-    assertTrue("Filtered searching should have found some matches", hits.length > 0);
-    for (ScoreDoc hit : hits) {
-      Document d = searcher.doc(hit.doc);
-      String url = d.get(KEY_FIELD);
-      DocsEnum td = MultiFields.getTermDocsEnum(reader,
-          MultiFields.getLiveDocs(reader),
-          KEY_FIELD,
-          new BytesRef(url));
-      int lastDoc = 0;
-      while (td.nextDoc() != DocsEnum.NO_MORE_DOCS) {
-        lastDoc = td.docID();
-      }
-      assertEquals("Duplicate urls should return last doc", lastDoc, hit.doc);
-    }
-  }
-
-
-  public void testKeepsFirstFilter() throws Throwable {
-    DuplicateFilter df = new DuplicateFilter(KEY_FIELD);
-    df.setKeepMode(DuplicateFilter.KeepMode.KM_USE_FIRST_OCCURRENCE);
-    ScoreDoc[] hits = searcher.search(tq, df, 1000).scoreDocs;
-    assertTrue("Filtered searching should have found some matches", hits.length > 0);
-    for (ScoreDoc hit : hits) {
-      Document d = searcher.doc(hit.doc);
-      String url = d.get(KEY_FIELD);
-      DocsEnum td = MultiFields.getTermDocsEnum(reader,
-          MultiFields.getLiveDocs(reader),
-          KEY_FIELD,
-          new BytesRef(url));
-      int lastDoc = 0;
-      td.nextDoc();
-      lastDoc = td.docID();
-      assertEquals("Duplicate urls should return first doc", lastDoc, hit.doc);
-    }
-  }
-
-
-}
diff --git a/lucene/contrib/queries/src/test/org/apache/lucene/search/TermsFilterTest.java b/lucene/contrib/queries/src/test/org/apache/lucene/search/TermsFilterTest.java
deleted file mode 100644
index f87ea6c..0000000
--- a/lucene/contrib/queries/src/test/org/apache/lucene/search/TermsFilterTest.java
+++ /dev/null
@@ -1,88 +0,0 @@
-package org.apache.lucene.search;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.IndexReader.AtomicReaderContext;
-import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.SlowMultiReaderWrapper;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.FixedBitSet;
-import org.apache.lucene.util.LuceneTestCase;
-
-import java.util.HashSet;
-
-public class TermsFilterTest extends LuceneTestCase {
-
-  public void testCachability() throws Exception {
-    TermsFilter a = new TermsFilter();
-    a.addTerm(new Term("field1", "a"));
-    a.addTerm(new Term("field1", "b"));
-    HashSet<Filter> cachedFilters = new HashSet<Filter>();
-    cachedFilters.add(a);
-    TermsFilter b = new TermsFilter();
-    b.addTerm(new Term("field1", "a"));
-    b.addTerm(new Term("field1", "b"));
-
-    assertTrue("Must be cached", cachedFilters.contains(b));
-    b.addTerm(new Term("field1", "a")); //duplicate term
-    assertTrue("Must be cached", cachedFilters.contains(b));
-    b.addTerm(new Term("field1", "c"));
-    assertFalse("Must not be cached", cachedFilters.contains(b));
-  }
-
-  public void testMissingTerms() throws Exception {
-    String fieldName = "field1";
-    Directory rd = newDirectory();
-    RandomIndexWriter w = new RandomIndexWriter(random, rd);
-    for (int i = 0; i < 100; i++) {
-      Document doc = new Document();
-      int term = i * 10; //terms are units of 10;
-      doc.add(newField(fieldName, "" + term, Field.Store.YES, Field.Index.NOT_ANALYZED));
-      w.addDocument(doc);
-    }
-    IndexReader reader = new SlowMultiReaderWrapper(w.getReader());
-    assertTrue(reader.getTopReaderContext().isAtomic);
-    AtomicReaderContext context = (AtomicReaderContext) reader.getTopReaderContext();
-    assertTrue(context.isAtomic);
-    w.close();
-
-    TermsFilter tf = new TermsFilter();
-    tf.addTerm(new Term(fieldName, "19"));
-    FixedBitSet bits = (FixedBitSet) tf.getDocIdSet(context);
-    assertEquals("Must match nothing", 0, bits.cardinality());
-
-    tf.addTerm(new Term(fieldName, "20"));
-    bits = (FixedBitSet) tf.getDocIdSet(context);
-    assertEquals("Must match 1", 1, bits.cardinality());
-
-    tf.addTerm(new Term(fieldName, "10"));
-    bits = (FixedBitSet) tf.getDocIdSet(context);
-    assertEquals("Must match 2", 2, bits.cardinality());
-
-    tf.addTerm(new Term(fieldName, "00"));
-    bits = (FixedBitSet) tf.getDocIdSet(context);
-    assertEquals("Must match 2", 2, bits.cardinality());
-
-    reader.close();
-    rd.close();
-  }
-}
diff --git a/lucene/contrib/spatial/build.xml b/lucene/contrib/spatial/build.xml
index 5980200..466146d 100644
--- a/lucene/contrib/spatial/build.xml
+++ b/lucene/contrib/spatial/build.xml
@@ -27,8 +27,9 @@
 
   <path id="classpath">
     <pathelement path="${queries-contrib.jar}"/>
+    <pathelement path="${queries.jar}"/>
     <path refid="base.classpath"/>
   </path>
 
-  <target name="compile-core" depends="jar-queries-contrib, common.compile-core" />
+  <target name="compile-core" depends="jar-queries-contrib, jar-queries, common.compile-core" />
 </project>
diff --git a/lucene/contrib/spatial/src/java/org/apache/lucene/spatial/tier/DistanceQueryBuilder.java b/lucene/contrib/spatial/src/java/org/apache/lucene/spatial/tier/DistanceQueryBuilder.java
index 418a4f7..c985f9c 100644
--- a/lucene/contrib/spatial/src/java/org/apache/lucene/spatial/tier/DistanceQueryBuilder.java
+++ b/lucene/contrib/spatial/src/java/org/apache/lucene/spatial/tier/DistanceQueryBuilder.java
@@ -18,7 +18,7 @@
 package org.apache.lucene.spatial.tier;
 
 import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.ChainedFilter;
+import org.apache.lucene.queries.ChainedFilter;
 import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.QueryWrapperFilter;
diff --git a/lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/BooleanFilterBuilder.java b/lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/BooleanFilterBuilder.java
index eabcffd..334d2e1 100644
--- a/lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/BooleanFilterBuilder.java
+++ b/lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/BooleanFilterBuilder.java
@@ -4,9 +4,9 @@
 package org.apache.lucene.xmlparser.builders;
 
 import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanFilter;
+import org.apache.lucene.queries.BooleanFilter;
 import org.apache.lucene.search.Filter;
-import org.apache.lucene.search.FilterClause;
+import org.apache.lucene.queries.FilterClause;
 import org.apache.lucene.xmlparser.DOMUtils;
 import org.apache.lucene.xmlparser.FilterBuilder;
 import org.apache.lucene.xmlparser.ParserException;
diff --git a/lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/BoostingQueryBuilder.java b/lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/BoostingQueryBuilder.java
index 0d57a7d..e6993f6 100644
--- a/lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/BoostingQueryBuilder.java
+++ b/lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/BoostingQueryBuilder.java
@@ -1,6 +1,6 @@
 package org.apache.lucene.xmlparser.builders;
 
-import org.apache.lucene.search.BoostingQuery;
+import org.apache.lucene.queries.BoostingQuery;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.xmlparser.DOMUtils;
 import org.apache.lucene.xmlparser.ParserException;
diff --git a/lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/DuplicateFilterBuilder.java b/lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/DuplicateFilterBuilder.java
index 921fdbe..e244235 100644
--- a/lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/DuplicateFilterBuilder.java
+++ b/lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/DuplicateFilterBuilder.java
@@ -3,7 +3,7 @@
  */
 package org.apache.lucene.xmlparser.builders;
 
-import org.apache.lucene.search.DuplicateFilter;
+import org.apache.lucene.queries.DuplicateFilter;
 import org.apache.lucene.search.Filter;
 import org.apache.lucene.xmlparser.DOMUtils;
 import org.apache.lucene.xmlparser.FilterBuilder;
diff --git a/lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/TermsFilterBuilder.java b/lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/TermsFilterBuilder.java
index b9c502d..f1dec27 100644
--- a/lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/TermsFilterBuilder.java
+++ b/lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/TermsFilterBuilder.java
@@ -5,7 +5,7 @@ import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.tokenattributes.TermToBytesRefAttribute;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.Filter;
-import org.apache.lucene.search.TermsFilter;
+import org.apache.lucene.queries.TermsFilter;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.xmlparser.DOMUtils;
 import org.apache.lucene.xmlparser.FilterBuilder;
diff --git a/modules/queries/src/java/org/apache/lucene/queries/BooleanFilter.java b/modules/queries/src/java/org/apache/lucene/queries/BooleanFilter.java
new file mode 100644
index 0000000..976351d
--- /dev/null
+++ b/modules/queries/src/java/org/apache/lucene/queries/BooleanFilter.java
@@ -0,0 +1,187 @@
+package org.apache.lucene.queries;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.List;
+
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.IndexReader.AtomicReaderContext;
+import org.apache.lucene.search.BooleanClause.Occur;
+import org.apache.lucene.search.DocIdSet;
+import org.apache.lucene.search.DocIdSetIterator;
+import org.apache.lucene.search.Filter;
+import org.apache.lucene.util.OpenBitSet;
+import org.apache.lucene.util.OpenBitSetDISI;
+
+/**
+ * A container Filter that allows Boolean composition of Filters.
+ * Filters are allocated into one of three logical constructs;
+ * SHOULD, MUST NOT, MUST
+ * The results Filter BitSet is constructed as follows:
+ * SHOULD Filters are OR'd together
+ * The resulting Filter is NOT'd with the NOT Filters
+ * The resulting Filter is AND'd with the MUST Filters
+ */
+
+public class BooleanFilter extends Filter {
+
+  List<Filter> shouldFilters = null;
+  List<Filter> notFilters = null;
+  List<Filter> mustFilters = null;
+
+  /**
+   * Returns the a DocIdSetIterator representing the Boolean composition
+   * of the filters that have been added.
+   */
+  @Override
+  public DocIdSet getDocIdSet(AtomicReaderContext context) throws IOException {
+    OpenBitSetDISI res = null;
+    final IndexReader reader = context.reader;
+    if (shouldFilters != null) {
+      for (int i = 0; i < shouldFilters.size(); i++) {
+        if (res == null) {
+          res = new OpenBitSetDISI(getDISI(shouldFilters, i, context), reader.maxDoc());
+        } else { 
+          DocIdSet dis = shouldFilters.get(i).getDocIdSet(context);
+          if(dis instanceof OpenBitSet) {
+            // optimized case for OpenBitSets
+            res.or((OpenBitSet) dis);
+          } else {
+            res.inPlaceOr(getDISI(shouldFilters, i, context));
+          }
+        }
+      }
+    }
+    
+    if (notFilters != null) {
+      for (int i = 0; i < notFilters.size(); i++) {
+        if (res == null) {
+          res = new OpenBitSetDISI(getDISI(notFilters, i, context), reader.maxDoc());
+          res.flip(0, reader.maxDoc()); // NOTE: may set bits on deleted docs
+        } else {
+          DocIdSet dis = notFilters.get(i).getDocIdSet(context);
+          if(dis instanceof OpenBitSet) {
+            // optimized case for OpenBitSets
+            res.andNot((OpenBitSet) dis);
+          } else {
+            res.inPlaceNot(getDISI(notFilters, i, context));
+          }
+        }
+      }
+    }
+    
+    if (mustFilters != null) {
+      for (int i = 0; i < mustFilters.size(); i++) {
+        if (res == null) {
+          res = new OpenBitSetDISI(getDISI(mustFilters, i, context), reader.maxDoc());
+        } else {
+          DocIdSet dis = mustFilters.get(i).getDocIdSet(context);
+          if(dis instanceof OpenBitSet) {
+            // optimized case for OpenBitSets
+            res.and((OpenBitSet) dis);
+          } else {
+            res.inPlaceAnd(getDISI(mustFilters, i, context));
+          }
+        }
+      }
+    }
+
+    return res != null ? res : DocIdSet.EMPTY_DOCIDSET;
+  }
+
+  /**
+  * Adds a new FilterClause to the Boolean Filter container
+  * @param filterClause A FilterClause object containing a Filter and an Occur parameter
+  */
+  public void add(FilterClause filterClause) {
+    if (filterClause.getOccur().equals(Occur.MUST)) {
+      if (mustFilters == null) {
+        mustFilters = new ArrayList<Filter>();
+      }
+      mustFilters.add(filterClause.getFilter());
+    } else if (filterClause.getOccur().equals(Occur.SHOULD)) {
+      if (shouldFilters == null) {
+        shouldFilters = new ArrayList<Filter>();
+      }
+      shouldFilters.add(filterClause.getFilter());
+    } else if (filterClause.getOccur().equals(Occur.MUST_NOT)) {
+      if (notFilters == null) {
+        notFilters = new ArrayList<Filter>();
+      }
+      notFilters.add(filterClause.getFilter());
+    }
+  }
+
+  private DocIdSetIterator getDISI(List<Filter> filters, int index, AtomicReaderContext context)
+      throws IOException {
+    return filters.get(index).getDocIdSet(context).iterator();
+  }
+  
+  @Override
+  public boolean equals(Object obj) {
+    if (this == obj) {
+      return true;
+    }
+
+    if ((obj == null) || (obj.getClass() != this.getClass())) {
+      return false;
+    }
+
+    BooleanFilter other = (BooleanFilter)obj;
+    return equalFilters(notFilters, other.notFilters)
+        && equalFilters(mustFilters, other.mustFilters)
+        && equalFilters(shouldFilters, other.shouldFilters);
+  }
+
+  private boolean equalFilters(List<Filter> filters1, List<Filter> filters2) {
+    return (filters1 == filters2) || ((filters1 != null) && filters1.equals(filters2));
+  }
+
+  @Override
+  public int hashCode() {
+    int hash = 7;
+    hash = 31 * hash + (null == mustFilters ? 0 : mustFilters.hashCode());
+    hash = 31 * hash + (null == notFilters ? 0 : notFilters.hashCode());
+    hash = 31 * hash + (null == shouldFilters ? 0 : shouldFilters.hashCode());
+    return hash;
+  }
+  
+  /** Prints a user-readable version of this query. */
+  @Override
+  public String toString() {
+    StringBuilder buffer = new StringBuilder();
+    buffer.append("BooleanFilter(");
+    appendFilters(shouldFilters, "", buffer);
+    appendFilters(mustFilters, "+", buffer);
+    appendFilters(notFilters, "-", buffer);
+    buffer.append(")");
+    return buffer.toString();
+  }
+  
+  private void appendFilters(List<Filter> filters, String occurString, StringBuilder buffer) {
+    if (filters != null) {
+      for (Filter filter : filters) {
+        buffer.append(' ');
+        buffer.append(occurString);
+        buffer.append(filter.toString());
+      }
+    }
+  }    
+}
diff --git a/modules/queries/src/java/org/apache/lucene/queries/BoostingQuery.java b/modules/queries/src/java/org/apache/lucene/queries/BoostingQuery.java
new file mode 100644
index 0000000..143231c
--- /dev/null
+++ b/modules/queries/src/java/org/apache/lucene/queries/BoostingQuery.java
@@ -0,0 +1,133 @@
+package org.apache.lucene.queries;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.search.*;
+
+/**
+ * The BoostingQuery class can be used to effectively demote results that match a given query. 
+ * Unlike the "NOT" clause, this still selects documents that contain undesirable terms, 
+ * but reduces their overall score:
+ *
+ *     Query balancedQuery = new BoostingQuery(positiveQuery, negativeQuery, 0.01f);
+ * In this scenario the positiveQuery contains the mandatory, desirable criteria which is used to 
+ * select all matching documents, and the negativeQuery contains the undesirable elements which 
+ * are simply used to lessen the scores. Documents that match the negativeQuery have their score 
+ * multiplied by the supplied "boost" parameter, so this should be less than 1 to achieve a 
+ * demoting effect
+ * 
+ * This code was originally made available here: [WWW] http://marc.theaimsgroup.com/?l=lucene-user&m=108058407130459&w=2
+ * and is documented here: http://wiki.apache.org/lucene-java/CommunityContributions
+ */
+public class BoostingQuery extends Query {
+    private float boost;                            // the amount to boost by
+    private Query match;                            // query to match
+    private Query context;                          // boost when matches too
+
+    public BoostingQuery(Query match, Query context, float boost) {
+      this.match = match;
+      this.context = (Query) context.clone();        // clone before boost
+      this.boost = boost;
+      this.context.setBoost(0.0f);                      // ignore context-only matches
+    }
+
+    @Override
+    public Query rewrite(IndexReader reader) throws IOException {
+      BooleanQuery result = new BooleanQuery() {
+        @Override
+        public Weight createWeight(IndexSearcher searcher) throws IOException {
+          return new BooleanWeight(searcher, false) {
+
+            @Override
+            public float coord(int overlap, int max) {
+              switch (overlap) {
+
+              case 1:                               // matched only one clause
+                return 1.0f;                        // use the score as-is
+
+              case 2:                               // matched both clauses
+                return boost;                       // multiply by boost
+
+              default:
+                return 0.0f;
+                
+              }
+            }
+          };
+        }
+      };
+
+      result.add(match, BooleanClause.Occur.MUST);
+      result.add(context, BooleanClause.Occur.SHOULD);
+
+      return result;
+    }
+
+    @Override
+    public int hashCode() {
+      final int prime = 31;
+      int result = 1;
+      result = prime * result + Float.floatToIntBits(boost);
+      result = prime * result + ((context == null) ? 0 : context.hashCode());
+      result = prime * result + ((match == null) ? 0 : match.hashCode());
+      return result;
+    }
+
+    @Override
+    public boolean equals(Object obj) {
+      if (this == obj) {
+        return true;
+      }
+      if (obj == null) {
+        return false;
+      }
+      if (getClass() != obj.getClass()) {
+        return false;
+      }
+
+      BoostingQuery other = (BoostingQuery) obj;
+      if (Float.floatToIntBits(boost) != Float.floatToIntBits(other.boost)) {
+        return false;
+      }
+      
+      if (context == null) {
+        if (other.context != null) {
+          return false;
+        }
+      } else if (!context.equals(other.context)) {
+        return false;
+      }
+      
+      if (match == null) {
+        if (other.match != null) {
+          return false;
+        }
+      } else if (!match.equals(other.match)) {
+        return false;
+      }
+      return true;
+    }
+
+    @Override
+    public String toString(String field) {
+      return match.toString(field) + "/" + context.toString(field);
+    }
+  }
diff --git a/modules/queries/src/java/org/apache/lucene/queries/ChainedFilter.java b/modules/queries/src/java/org/apache/lucene/queries/ChainedFilter.java
new file mode 100644
index 0000000..2352e13
--- /dev/null
+++ b/modules/queries/src/java/org/apache/lucene/queries/ChainedFilter.java
@@ -0,0 +1,249 @@
+package org.apache.lucene.queries;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.IndexReader.AtomicReaderContext;
+import org.apache.lucene.search.DocIdSet;
+import org.apache.lucene.search.DocIdSetIterator;
+import org.apache.lucene.search.Filter;
+import org.apache.lucene.util.OpenBitSet;
+import org.apache.lucene.util.OpenBitSetDISI;
+
+import java.io.IOException;
+
+/**
+ * <p>
+ * Allows multiple {@link Filter}s to be chained.
+ * Logical operations such as <b>NOT</b> and <b>XOR</b>
+ * are applied between filters. One operation can be used
+ * for all filters, or a specific operation can be declared
+ * for each filter.
+ * </p>
+ * <p>
+ * Order in which filters are called depends on
+ * the position of the filter in the chain. It's probably
+ * more efficient to place the most restrictive filters
+ * /least computationally-intensive filters first.
+ * </p>
+ */
+public class ChainedFilter extends Filter {
+
+  public static final int OR = 0;
+  public static final int AND = 1;
+  public static final int ANDNOT = 2;
+  public static final int XOR = 3;
+  /**
+   * Logical operation when none is declared. Defaults to OR.
+   */
+  public static int DEFAULT = OR;
+
+  /**
+   * The filter chain
+   */
+  private Filter[] chain = null;
+
+  private int[] logicArray;
+
+  private int logic = -1;
+
+  /**
+   * Ctor.
+   *
+   * @param chain The chain of filters
+   */
+  public ChainedFilter(Filter[] chain) {
+    this.chain = chain;
+  }
+
+  /**
+   * Ctor.
+   *
+   * @param chain The chain of filters
+   * @param logicArray Logical operations to apply between filters
+   */
+  public ChainedFilter(Filter[] chain, int[] logicArray) {
+    this.chain = chain;
+    this.logicArray = logicArray;
+  }
+
+  /**
+   * Ctor.
+   *
+   * @param chain The chain of filters
+   * @param logic Logical operation to apply to ALL filters
+   */
+  public ChainedFilter(Filter[] chain, int logic) {
+    this.chain = chain;
+    this.logic = logic;
+  }
+
+  /**
+   * {@link Filter#getDocIdSet}.
+   */
+  @Override
+  public DocIdSet getDocIdSet(AtomicReaderContext context) throws IOException {
+    int[] index = new int[1]; // use array as reference to modifiable int;
+    index[0] = 0;             // an object attribute would not be thread safe.
+    if (logic != -1) {
+      return getDocIdSet(context, logic, index);
+    } else if (logicArray != null) {
+      return getDocIdSet(context, logicArray, index);
+    }
+
+    return getDocIdSet(context, DEFAULT, index);
+  }
+
+  private DocIdSetIterator getDISI(Filter filter, AtomicReaderContext context)
+      throws IOException {
+    DocIdSet docIdSet = filter.getDocIdSet(context);
+    if (docIdSet == null) {
+      return DocIdSet.EMPTY_DOCIDSET.iterator();
+    } else {
+      DocIdSetIterator iter = docIdSet.iterator();
+      if (iter == null) {
+        return DocIdSet.EMPTY_DOCIDSET.iterator();
+      } else {
+        return iter;
+      }
+    }
+  }
+
+  private OpenBitSetDISI initialResult(AtomicReaderContext context, int logic, int[] index)
+      throws IOException {
+    IndexReader reader = context.reader;
+    OpenBitSetDISI result;
+    /**
+     * First AND operation takes place against a completely false
+     * bitset and will always return zero results.
+     */
+    if (logic == AND) {
+      result = new OpenBitSetDISI(getDISI(chain[index[0]], context), reader.maxDoc());
+      ++index[0];
+    } else if (logic == ANDNOT) {
+      result = new OpenBitSetDISI(getDISI(chain[index[0]], context), reader.maxDoc());
+      result.flip(0, reader.maxDoc()); // NOTE: may set bits for deleted docs.
+      ++index[0];
+    } else {
+      result = new OpenBitSetDISI(reader.maxDoc());
+    }
+    return result;
+  }
+
+  /**
+   * Delegates to each filter in the chain.
+   *
+   * @param context AtomicReaderContext
+   * @param logic Logical operation
+   * @return DocIdSet
+   */
+  private DocIdSet getDocIdSet(AtomicReaderContext context, int logic, int[] index)
+      throws IOException {
+    OpenBitSetDISI result = initialResult(context, logic, index);
+    for (; index[0] < chain.length; index[0]++) {
+      doChain(result, logic, chain[index[0]].getDocIdSet(context));
+    }
+    return result;
+  }
+
+  /**
+   * Delegates to each filter in the chain.
+   *
+   * @param context AtomicReaderContext
+   * @param logic Logical operation
+   * @return DocIdSet
+   */
+  private DocIdSet getDocIdSet(AtomicReaderContext context, int[] logic, int[] index)
+      throws IOException {
+    if (logic.length != chain.length) {
+      throw new IllegalArgumentException("Invalid number of elements in logic array");
+    }
+
+    OpenBitSetDISI result = initialResult(context, logic[0], index);
+    for (; index[0] < chain.length; index[0]++) {
+      doChain(result, logic[index[0]], chain[index[0]].getDocIdSet(context));
+    }
+    return result;
+  }
+
+  @Override
+  public String toString() {
+    StringBuilder sb = new StringBuilder();
+    sb.append("ChainedFilter: [");
+    for (Filter aChain : chain) {
+      sb.append(aChain);
+      sb.append(' ');
+    }
+    sb.append(']');
+    return sb.toString();
+  }
+
+  private void doChain(OpenBitSetDISI result, int logic, DocIdSet dis)
+      throws IOException {
+
+    if (dis instanceof OpenBitSet) {
+      // optimized case for OpenBitSets
+      switch (logic) {
+        case OR:
+          result.or((OpenBitSet) dis);
+          break;
+        case AND:
+          result.and((OpenBitSet) dis);
+          break;
+        case ANDNOT:
+          result.andNot((OpenBitSet) dis);
+          break;
+        case XOR:
+          result.xor((OpenBitSet) dis);
+          break;
+        default:
+          doChain(result, DEFAULT, dis);
+          break;
+      }
+    } else {
+      DocIdSetIterator disi;
+      if (dis == null) {
+        disi = DocIdSet.EMPTY_DOCIDSET.iterator();
+      } else {
+        disi = dis.iterator();
+        if (disi == null) {
+          disi = DocIdSet.EMPTY_DOCIDSET.iterator();
+        }
+      }
+
+      switch (logic) {
+        case OR:
+          result.inPlaceOr(disi);
+          break;
+        case AND:
+          result.inPlaceAnd(disi);
+          break;
+        case ANDNOT:
+          result.inPlaceNot(disi);
+          break;
+        case XOR:
+          result.inPlaceXor(disi);
+          break;
+        default:
+          doChain(result, DEFAULT, dis);
+          break;
+      }
+    }
+  }
+
+}
diff --git a/modules/queries/src/java/org/apache/lucene/queries/DuplicateFilter.java b/modules/queries/src/java/org/apache/lucene/queries/DuplicateFilter.java
new file mode 100644
index 0000000..33305ef
--- /dev/null
+++ b/modules/queries/src/java/org/apache/lucene/queries/DuplicateFilter.java
@@ -0,0 +1,214 @@
+package org.apache.lucene.queries;
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.index.*;
+import org.apache.lucene.index.IndexReader.AtomicReaderContext;
+import org.apache.lucene.search.DocIdSet;
+import org.apache.lucene.search.Filter;
+import org.apache.lucene.util.Bits;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.FixedBitSet;
+
+import java.io.IOException;
+
+public class DuplicateFilter extends Filter {
+  // TODO: make duplicate filter aware of ReaderContext such that we can
+  // filter duplicates across segments
+
+  /**
+   * KeepMode determines which document id to consider as the master, all others being
+   * identified as duplicates. Selecting the "first occurrence" can potentially save on IO.
+   */
+  public enum KeepMode {
+    KM_USE_FIRST_OCCURRENCE, KM_USE_LAST_OCCURRENCE
+  }
+
+  private KeepMode keepMode;
+
+  /**
+   * "Full" processing mode starts by setting all bits to false and only setting bits
+   * for documents that contain the given field and are identified as none-duplicates.
+   * <p/>
+   * "Fast" processing sets all bits to true then unsets all duplicate docs found for the
+   * given field. This approach avoids the need to read TermDocs for terms that are seen
+   * to have a document frequency of exactly "1" (i.e. no duplicates). While a potentially
+   * faster approach , the downside is that bitsets produced will include bits set for
+   * documents that do not actually contain the field given.
+   */
+
+  public enum ProcessingMode {
+    PM_FULL_VALIDATION, PM_FAST_INVALIDATION
+  }
+
+  private ProcessingMode processingMode;
+
+  private String fieldName;
+
+  public DuplicateFilter(String fieldName) {
+    this(fieldName, KeepMode.KM_USE_LAST_OCCURRENCE, ProcessingMode.PM_FULL_VALIDATION);
+  }
+
+  public DuplicateFilter(String fieldName, KeepMode keepMode, ProcessingMode processingMode) {
+    this.fieldName = fieldName;
+    this.keepMode = keepMode;
+    this.processingMode = processingMode;
+  }
+
+  @Override
+  public DocIdSet getDocIdSet(AtomicReaderContext context) throws IOException {
+    if (processingMode == ProcessingMode.PM_FAST_INVALIDATION) {
+      return fastBits(context.reader);
+    } else {
+      return correctBits(context.reader);
+    }
+  }
+
+  private FixedBitSet correctBits(IndexReader reader) throws IOException {
+    FixedBitSet bits = new FixedBitSet(reader.maxDoc()); //assume all are INvalid
+    final Bits liveDocs = MultiFields.getLiveDocs(reader);
+    Terms terms = reader.fields().terms(fieldName);
+
+    if (terms == null) {
+      return bits;
+    }
+
+    TermsEnum termsEnum = terms.iterator();
+    DocsEnum docs = null;
+    while (true) {
+      BytesRef currTerm = termsEnum.next();
+      if (currTerm == null) {
+        break;
+      } else {
+        docs = termsEnum.docs(liveDocs, docs);
+        int doc = docs.nextDoc();
+        if (doc != DocsEnum.NO_MORE_DOCS) {
+          if (keepMode == KeepMode.KM_USE_FIRST_OCCURRENCE) {
+            bits.set(doc);
+          } else {
+            int lastDoc = doc;
+            while (true) {
+              lastDoc = doc;
+              doc = docs.nextDoc();
+              if (doc == DocsEnum.NO_MORE_DOCS) {
+                break;
+              }
+            }
+            bits.set(lastDoc);
+          }
+        }
+      }
+    }
+    return bits;
+  }
+
+  private FixedBitSet fastBits(IndexReader reader) throws IOException {
+    FixedBitSet bits = new FixedBitSet(reader.maxDoc());
+    bits.set(0, reader.maxDoc()); //assume all are valid
+    final Bits liveDocs = MultiFields.getLiveDocs(reader);
+    Terms terms = reader.fields().terms(fieldName);
+
+    if (terms == null) {
+      return bits;
+    }
+
+    TermsEnum termsEnum = terms.iterator();
+    DocsEnum docs = null;
+    while (true) {
+      BytesRef currTerm = termsEnum.next();
+      if (currTerm == null) {
+        break;
+      } else {
+        if (termsEnum.docFreq() > 1) {
+          // unset potential duplicates
+          docs = termsEnum.docs(liveDocs, docs);
+          int doc = docs.nextDoc();
+          if (doc != DocsEnum.NO_MORE_DOCS) {
+            if (keepMode == KeepMode.KM_USE_FIRST_OCCURRENCE) {
+              doc = docs.nextDoc();
+            }
+          }
+
+          int lastDoc = -1;
+          while (true) {
+            lastDoc = doc;
+            bits.clear(lastDoc);
+            doc = docs.nextDoc();
+            if (doc == DocsEnum.NO_MORE_DOCS) {
+              break;
+            }
+          }
+
+          if (keepMode == KeepMode.KM_USE_LAST_OCCURRENCE) {
+            // restore the last bit
+            bits.set(lastDoc);
+          }
+        }
+      }
+    }
+
+    return bits;
+  }
+
+  public String getFieldName() {
+    return fieldName;
+  }
+
+  public void setFieldName(String fieldName) {
+    this.fieldName = fieldName;
+  }
+
+  public KeepMode getKeepMode() {
+    return keepMode;
+  }
+
+  public void setKeepMode(KeepMode keepMode) {
+    this.keepMode = keepMode;
+  }
+
+  @Override
+  public boolean equals(Object obj) {
+    if (this == obj) {
+      return true;
+    }
+    if ((obj == null) || (obj.getClass() != this.getClass())) {
+      return false;
+    }
+
+    DuplicateFilter other = (DuplicateFilter) obj;
+    return keepMode == other.keepMode &&
+        processingMode == other.processingMode &&
+        fieldName != null && fieldName.equals(other.fieldName);
+  }
+
+  @Override
+  public int hashCode() {
+    int hash = 217;
+    hash = 31 * hash + keepMode.hashCode();
+    hash = 31 * hash + processingMode.hashCode();
+    hash = 31 * hash + fieldName.hashCode();
+    return hash;
+  }
+
+  public ProcessingMode getProcessingMode() {
+    return processingMode;
+  }
+
+  public void setProcessingMode(ProcessingMode processingMode) {
+    this.processingMode = processingMode;
+  }
+}
diff --git a/modules/queries/src/java/org/apache/lucene/queries/FilterClause.java b/modules/queries/src/java/org/apache/lucene/queries/FilterClause.java
new file mode 100644
index 0000000..09fa803
--- /dev/null
+++ b/modules/queries/src/java/org/apache/lucene/queries/FilterClause.java
@@ -0,0 +1,61 @@
+package org.apache.lucene.queries;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.search.BooleanClause.Occur;
+import org.apache.lucene.search.Filter;
+
+/**
+ * A Filter that wrapped with an indication of how that filter
+ * is used when composed with another filter.
+ * (Follows the boolean logic in BooleanClause for composition 
+ * of queries.)
+ */
+public class FilterClause {
+
+	private final Occur occur;
+	private final Filter filter;
+
+	/**
+	 * Create a new FilterClause
+	 * @param filter A Filter object containing a BitSet
+	 * @param occur A parameter implementation indicating SHOULD, MUST or MUST NOT
+	 */
+	
+	public FilterClause(Filter filter, Occur occur) {
+		this.occur = occur;
+		this.filter = filter;
+	}
+
+	/**
+	 * Returns this FilterClause's filter
+	 * @return A Filter object
+	 */
+	public Filter getFilter() {
+		return filter;
+	}
+
+	/**
+	 * Returns this FilterClause's occur parameter
+	 * @return An Occur object
+	 */
+	public Occur getOccur() {
+		return occur;
+	}
+
+}
diff --git a/modules/queries/src/java/org/apache/lucene/queries/TermsFilter.java b/modules/queries/src/java/org/apache/lucene/queries/TermsFilter.java
new file mode 100644
index 0000000..cb27f23
--- /dev/null
+++ b/modules/queries/src/java/org/apache/lucene/queries/TermsFilter.java
@@ -0,0 +1,115 @@
+package org.apache.lucene.queries;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.index.*;
+import org.apache.lucene.index.IndexReader.AtomicReaderContext;
+import org.apache.lucene.search.DocIdSet;
+import org.apache.lucene.search.Filter;
+import org.apache.lucene.util.Bits;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.FixedBitSet;
+
+import java.io.IOException;
+import java.util.Set;
+import java.util.TreeSet;
+
+/**
+ * Constructs a filter for docs matching any of the terms added to this class.
+ * Unlike a RangeFilter this can be used for filtering on multiple terms that are not necessarily in
+ * a sequence. An example might be a collection of primary keys from a database query result or perhaps
+ * a choice of "category" labels picked by the end user. As a filter, this is much faster than the
+ * equivalent query (a BooleanQuery with many "should" TermQueries)
+ */
+public class TermsFilter extends Filter {
+
+  private final Set<Term> terms = new TreeSet<Term>();
+
+  /**
+   * Adds a term to the list of acceptable terms
+   *
+   * @param term
+   */
+  public void addTerm(Term term) {
+    terms.add(term);
+  }
+
+/* (non-Javadoc)
+   * @see org.apache.lucene.search.Filter#getDocIdSet(org.apache.lucene.index.IndexReader)
+   */
+
+  @Override
+  public DocIdSet getDocIdSet(AtomicReaderContext context) throws IOException {
+    IndexReader reader = context.reader;
+    FixedBitSet result = new FixedBitSet(reader.maxDoc());
+    Fields fields = reader.fields();
+
+    if (fields == null) {
+      return result;
+    }
+
+    BytesRef br = new BytesRef();
+    Bits liveDocs = reader.getLiveDocs();
+    String lastField = null;
+    Terms termsC = null;
+    TermsEnum termsEnum = null;
+    DocsEnum docs = null;
+    for (Term term : terms) {
+      if (!term.field().equals(lastField)) {
+        termsC = fields.terms(term.field());
+        termsEnum = termsC.iterator();
+        lastField = term.field();
+      }
+
+      if (terms != null) { // TODO this check doesn't make sense, decide which variable its supposed to be for
+        br.copy(term.bytes());
+        if (termsEnum.seekCeil(br) == TermsEnum.SeekStatus.FOUND) {
+          docs = termsEnum.docs(liveDocs, docs);
+          while (docs.nextDoc() != DocsEnum.NO_MORE_DOCS) {
+            result.set(docs.docID());
+          }
+        }
+      }
+    }
+    return result;
+  }
+
+  @Override
+  public boolean equals(Object obj) {
+    if (this == obj) {
+      return true;
+    }
+    if ((obj == null) || (obj.getClass() != this.getClass())) {
+      return false;
+    }
+
+    TermsFilter test = (TermsFilter) obj;
+    return (terms == test.terms ||
+        (terms != null && terms.equals(test.terms)));
+  }
+
+  @Override
+  public int hashCode() {
+    int hash = 9;
+    for (Term term : terms) {
+      hash = 31 * hash + term.hashCode();
+    }
+    return hash;
+  }
+
+}
diff --git a/modules/queries/src/test/org/apache/lucene/queries/BooleanFilterTest.java b/modules/queries/src/test/org/apache/lucene/queries/BooleanFilterTest.java
new file mode 100644
index 0000000..df4f307
--- /dev/null
+++ b/modules/queries/src/test/org/apache/lucene/queries/BooleanFilterTest.java
@@ -0,0 +1,165 @@
+package org.apache.lucene.queries;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.MockAnalyzer;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.IndexReader.AtomicReaderContext;
+import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.index.SlowMultiReaderWrapper;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.BooleanClause;
+import org.apache.lucene.search.DocIdSetIterator;
+import org.apache.lucene.search.Filter;
+import org.apache.lucene.search.TermRangeFilter;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.LuceneTestCase;
+
+import java.io.IOException;
+
+public class BooleanFilterTest extends LuceneTestCase {
+  private Directory directory;
+  private IndexReader reader;
+
+  @Override
+  public void setUp() throws Exception {
+    super.setUp();
+    directory = newDirectory();
+    RandomIndexWriter writer = new RandomIndexWriter(random, directory, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false));
+
+    //Add series of docs with filterable fields : acces rights, prices, dates and "in-stock" flags
+    addDoc(writer, "admin guest", "010", "20040101", "Y");
+    addDoc(writer, "guest", "020", "20040101", "Y");
+    addDoc(writer, "guest", "020", "20050101", "Y");
+    addDoc(writer, "admin", "020", "20050101", "Maybe");
+    addDoc(writer, "admin guest", "030", "20050101", "N");
+    reader = new SlowMultiReaderWrapper(writer.getReader());
+    writer.close();
+  }
+
+  @Override
+  public void tearDown() throws Exception {
+    reader.close();
+    directory.close();
+    super.tearDown();
+  }
+
+  private void addDoc(RandomIndexWriter writer, String accessRights, String price, String date, String inStock) throws IOException {
+    Document doc = new Document();
+    doc.add(newField("accessRights", accessRights, Field.Store.YES, Field.Index.ANALYZED));
+    doc.add(newField("price", price, Field.Store.YES, Field.Index.ANALYZED));
+    doc.add(newField("date", date, Field.Store.YES, Field.Index.ANALYZED));
+    doc.add(newField("inStock", inStock, Field.Store.YES, Field.Index.ANALYZED));
+    writer.addDocument(doc);
+  }
+
+  private Filter getRangeFilter(String field, String lowerPrice, String upperPrice) {
+    Filter f = TermRangeFilter.newStringRange(field, lowerPrice, upperPrice, true, true);
+    return f;
+  }
+
+  private Filter getTermsFilter(String field, String text) {
+    TermsFilter tf = new TermsFilter();
+    tf.addTerm(new Term(field, text));
+
+    return tf;
+  }
+
+  private void tstFilterCard(String mes, int expected, Filter filt)
+      throws Throwable {
+    DocIdSetIterator disi = filt.getDocIdSet(new AtomicReaderContext(reader)).iterator();
+    int actual = 0;
+    while (disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
+      actual++;
+    }
+    assertEquals(mes, expected, actual);
+  }
+
+
+  public void testShould() throws Throwable {
+    BooleanFilter booleanFilter = new BooleanFilter();
+    booleanFilter.add(new FilterClause(getTermsFilter("price", "030"), BooleanClause.Occur.SHOULD));
+    tstFilterCard("Should retrieves only 1 doc", 1, booleanFilter);
+  }
+
+  public void testShoulds() throws Throwable {
+    BooleanFilter booleanFilter = new BooleanFilter();
+    booleanFilter.add(new FilterClause(getRangeFilter("price", "010", "020"), BooleanClause.Occur.SHOULD));
+    booleanFilter.add(new FilterClause(getRangeFilter("price", "020", "030"), BooleanClause.Occur.SHOULD));
+    tstFilterCard("Shoulds are Ored together", 5, booleanFilter);
+  }
+
+  public void testShouldsAndMustNot() throws Throwable {
+    BooleanFilter booleanFilter = new BooleanFilter();
+    booleanFilter.add(new FilterClause(getRangeFilter("price", "010", "020"), BooleanClause.Occur.SHOULD));
+    booleanFilter.add(new FilterClause(getRangeFilter("price", "020", "030"), BooleanClause.Occur.SHOULD));
+    booleanFilter.add(new FilterClause(getTermsFilter("inStock", "N"), BooleanClause.Occur.MUST_NOT));
+    tstFilterCard("Shoulds Ored but AndNot", 4, booleanFilter);
+
+    booleanFilter.add(new FilterClause(getTermsFilter("inStock", "Maybe"), BooleanClause.Occur.MUST_NOT));
+    tstFilterCard("Shoulds Ored but AndNots", 3, booleanFilter);
+  }
+
+  public void testShouldsAndMust() throws Throwable {
+    BooleanFilter booleanFilter = new BooleanFilter();
+    booleanFilter.add(new FilterClause(getRangeFilter("price", "010", "020"), BooleanClause.Occur.SHOULD));
+    booleanFilter.add(new FilterClause(getRangeFilter("price", "020", "030"), BooleanClause.Occur.SHOULD));
+    booleanFilter.add(new FilterClause(getTermsFilter("accessRights", "admin"), BooleanClause.Occur.MUST));
+    tstFilterCard("Shoulds Ored but MUST", 3, booleanFilter);
+  }
+
+  public void testShouldsAndMusts() throws Throwable {
+    BooleanFilter booleanFilter = new BooleanFilter();
+    booleanFilter.add(new FilterClause(getRangeFilter("price", "010", "020"), BooleanClause.Occur.SHOULD));
+    booleanFilter.add(new FilterClause(getRangeFilter("price", "020", "030"), BooleanClause.Occur.SHOULD));
+    booleanFilter.add(new FilterClause(getTermsFilter("accessRights", "admin"), BooleanClause.Occur.MUST));
+    booleanFilter.add(new FilterClause(getRangeFilter("date", "20040101", "20041231"), BooleanClause.Occur.MUST));
+    tstFilterCard("Shoulds Ored but MUSTs ANDED", 1, booleanFilter);
+  }
+
+  public void testShouldsAndMustsAndMustNot() throws Throwable {
+    BooleanFilter booleanFilter = new BooleanFilter();
+    booleanFilter.add(new FilterClause(getRangeFilter("price", "030", "040"), BooleanClause.Occur.SHOULD));
+    booleanFilter.add(new FilterClause(getTermsFilter("accessRights", "admin"), BooleanClause.Occur.MUST));
+    booleanFilter.add(new FilterClause(getRangeFilter("date", "20050101", "20051231"), BooleanClause.Occur.MUST));
+    booleanFilter.add(new FilterClause(getTermsFilter("inStock", "N"), BooleanClause.Occur.MUST_NOT));
+    tstFilterCard("Shoulds Ored but MUSTs ANDED and MustNot", 0, booleanFilter);
+  }
+
+  public void testJustMust() throws Throwable {
+    BooleanFilter booleanFilter = new BooleanFilter();
+    booleanFilter.add(new FilterClause(getTermsFilter("accessRights", "admin"), BooleanClause.Occur.MUST));
+    tstFilterCard("MUST", 3, booleanFilter);
+  }
+
+  public void testJustMustNot() throws Throwable {
+    BooleanFilter booleanFilter = new BooleanFilter();
+    booleanFilter.add(new FilterClause(getTermsFilter("inStock", "N"), BooleanClause.Occur.MUST_NOT));
+    tstFilterCard("MUST_NOT", 4, booleanFilter);
+  }
+
+  public void testMustAndMustNot() throws Throwable {
+    BooleanFilter booleanFilter = new BooleanFilter();
+    booleanFilter.add(new FilterClause(getTermsFilter("inStock", "N"), BooleanClause.Occur.MUST));
+    booleanFilter.add(new FilterClause(getTermsFilter("price", "030"), BooleanClause.Occur.MUST_NOT));
+    tstFilterCard("MUST_NOT wins over MUST for same docs", 0, booleanFilter);
+  }
+}
diff --git a/modules/queries/src/test/org/apache/lucene/queries/BoostingQueryTest.java b/modules/queries/src/test/org/apache/lucene/queries/BoostingQueryTest.java
new file mode 100644
index 0000000..ef4e9ed
--- /dev/null
+++ b/modules/queries/src/test/org/apache/lucene/queries/BoostingQueryTest.java
@@ -0,0 +1,33 @@
+package org.apache.lucene.queries;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.TermQuery;
+import org.apache.lucene.util.LuceneTestCase;
+
+public class BoostingQueryTest extends LuceneTestCase {
+  public void testBoostingQueryEquals() {
+    TermQuery q1 = new TermQuery(new Term("subject:", "java"));
+    TermQuery q2 = new TermQuery(new Term("subject:", "java"));
+    assertEquals("Two TermQueries with same attributes should be equal", q1, q2);
+    BoostingQuery bq1 = new BoostingQuery(q1, q2, 0.1f);
+    BoostingQuery bq2 = new BoostingQuery(q1, q2, 0.1f);
+    assertEquals("BoostingQuery with same attributes is not equal", bq1, bq2);
+  }
+}
diff --git a/modules/queries/src/test/org/apache/lucene/queries/ChainedFilterTest.java b/modules/queries/src/test/org/apache/lucene/queries/ChainedFilterTest.java
new file mode 100644
index 0000000..d781b2e
--- /dev/null
+++ b/modules/queries/src/test/org/apache/lucene/queries/ChainedFilterTest.java
@@ -0,0 +1,219 @@
+package org.apache.lucene.queries;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.util.Calendar;
+import java.util.GregorianCalendar;
+
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.BooleanClause;
+import org.apache.lucene.search.BooleanQuery;
+import org.apache.lucene.search.CachingWrapperFilter;
+import org.apache.lucene.search.Filter;
+import org.apache.lucene.search.MatchAllDocsQuery;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.QueryWrapperFilter;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.TermQuery;
+import org.apache.lucene.search.TermRangeFilter;
+import org.apache.lucene.search.TopDocs;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.LuceneTestCase;
+
+public class ChainedFilterTest extends LuceneTestCase {
+  public static final int MAX = 500;
+
+  private Directory directory;
+  private IndexSearcher searcher;
+  private IndexReader reader;
+  private Query query;
+  // private DateFilter dateFilter;   DateFilter was deprecated and removed
+  private TermRangeFilter dateFilter;
+  private QueryWrapperFilter bobFilter;
+  private QueryWrapperFilter sueFilter;
+
+  @Override
+  public void setUp() throws Exception {
+    super.setUp();
+    directory = newDirectory();
+    RandomIndexWriter writer = new RandomIndexWriter(random, directory);
+    Calendar cal = new GregorianCalendar();
+    cal.clear();
+    cal.setTimeInMillis(1041397200000L); // 2003 January 01
+
+    for (int i = 0; i < MAX; i++) {
+      Document doc = new Document();
+      doc.add(newField("key", "" + (i + 1), Field.Store.YES, Field.Index.NOT_ANALYZED));
+      doc.add(newField("owner", (i < MAX / 2) ? "bob" : "sue", Field.Store.YES, Field.Index.NOT_ANALYZED));
+      doc.add(newField("date", cal.getTime().toString(), Field.Store.YES, Field.Index.NOT_ANALYZED));
+      writer.addDocument(doc);
+
+      cal.add(Calendar.DATE, 1);
+    }
+    reader = writer.getReader();
+    writer.close();
+
+    searcher = newSearcher(reader);
+
+    // query for everything to make life easier
+    BooleanQuery bq = new BooleanQuery();
+    bq.add(new TermQuery(new Term("owner", "bob")), BooleanClause.Occur.SHOULD);
+    bq.add(new TermQuery(new Term("owner", "sue")), BooleanClause.Occur.SHOULD);
+    query = bq;
+
+    // date filter matches everything too
+    //Date pastTheEnd = parseDate("2099 Jan 1");
+    // dateFilter = DateFilter.Before("date", pastTheEnd);
+    // just treat dates as strings and select the whole range for now...
+    dateFilter = TermRangeFilter.newStringRange("date","","ZZZZ",true,true);
+
+    bobFilter = new QueryWrapperFilter(
+        new TermQuery(new Term("owner", "bob")));
+    sueFilter = new QueryWrapperFilter(
+        new TermQuery(new Term("owner", "sue")));
+  }
+
+  @Override
+  public void tearDown() throws Exception {
+    searcher.close();
+    reader.close();
+    directory.close();
+    super.tearDown();
+  }
+
+  private ChainedFilter getChainedFilter(Filter[] chain, int[] logic) {
+    if (logic == null) {
+      return new ChainedFilter(chain);
+    } else {
+      return new ChainedFilter(chain, logic);
+    }
+  }
+
+  private ChainedFilter getChainedFilter(Filter[] chain, int logic) {
+    return new ChainedFilter(chain, logic);
+  }
+
+  
+  public void testSingleFilter() throws Exception {
+    ChainedFilter chain = getChainedFilter(new Filter[] {dateFilter}, null);
+
+    int numHits = searcher.search(query, chain, 1000).totalHits;
+    assertEquals(MAX, numHits);
+
+    chain = new ChainedFilter(new Filter[] {bobFilter});
+    numHits = searcher.search(query, chain, 1000).totalHits;
+    assertEquals(MAX / 2, numHits);
+    
+    chain = getChainedFilter(new Filter[] {bobFilter}, new int[] {ChainedFilter.AND});
+    TopDocs hits = searcher.search(query, chain, 1000);
+    numHits = hits.totalHits;
+    assertEquals(MAX / 2, numHits);
+    assertEquals("bob", searcher.doc(hits.scoreDocs[0].doc).get("owner"));
+    
+    chain = getChainedFilter(new Filter[] {bobFilter}, new int[] {ChainedFilter.ANDNOT});
+    hits = searcher.search(query, chain, 1000);
+    numHits = hits.totalHits;
+    assertEquals(MAX / 2, numHits);
+    assertEquals("sue", searcher.doc(hits.scoreDocs[0].doc).get("owner"));
+  }
+
+  public void testOR() throws Exception {
+    ChainedFilter chain = getChainedFilter(
+      new Filter[] {sueFilter, bobFilter}, null);
+
+    int numHits = searcher.search(query, chain, 1000).totalHits;
+    assertEquals("OR matches all", MAX, numHits);
+  }
+
+  public void testAND() throws Exception {
+    ChainedFilter chain = getChainedFilter(
+      new Filter[] {dateFilter, bobFilter}, ChainedFilter.AND);
+
+    TopDocs hits = searcher.search(query, chain, 1000);
+    assertEquals("AND matches just bob", MAX / 2, hits.totalHits);
+    assertEquals("bob", searcher.doc(hits.scoreDocs[0].doc).get("owner"));
+  }
+
+  public void testXOR() throws Exception {
+    ChainedFilter chain = getChainedFilter(
+      new Filter[]{dateFilter, bobFilter}, ChainedFilter.XOR);
+
+    TopDocs hits = searcher.search(query, chain, 1000);
+    assertEquals("XOR matches sue", MAX / 2, hits.totalHits);
+    assertEquals("sue", searcher.doc(hits.scoreDocs[0].doc).get("owner"));
+  }
+
+  public void testANDNOT() throws Exception {
+    ChainedFilter chain = getChainedFilter(
+      new Filter[]{dateFilter, sueFilter},
+        new int[] {ChainedFilter.AND, ChainedFilter.ANDNOT});
+
+    TopDocs hits = searcher.search(query, chain, 1000);
+    assertEquals("ANDNOT matches just bob",
+        MAX / 2, hits.totalHits);
+    assertEquals("bob", searcher.doc(hits.scoreDocs[0].doc).get("owner"));
+    
+    chain = getChainedFilter(
+        new Filter[]{bobFilter, bobFilter},
+          new int[] {ChainedFilter.ANDNOT, ChainedFilter.ANDNOT});
+
+      hits = searcher.search(query, chain, 1000);
+      assertEquals("ANDNOT bob ANDNOT bob matches all sues",
+          MAX / 2, hits.totalHits);
+      assertEquals("sue", searcher.doc(hits.scoreDocs[0].doc).get("owner"));
+  }
+
+  /*
+  private Date parseDate(String s) throws ParseException {
+    return new SimpleDateFormat("yyyy MMM dd", Locale.US).parse(s);
+  }
+  */
+  
+  public void testWithCachingFilter() throws Exception {
+    Directory dir = newDirectory();
+    RandomIndexWriter writer = new RandomIndexWriter(random, dir);
+    IndexReader reader = writer.getReader();
+    writer.close();
+  
+    IndexSearcher searcher = newSearcher(reader);
+  
+    Query query = new TermQuery(new Term("none", "none"));
+  
+    QueryWrapperFilter queryFilter = new QueryWrapperFilter(query);
+    CachingWrapperFilter cachingFilter = new CachingWrapperFilter(queryFilter);
+  
+    searcher.search(query, cachingFilter, 1);
+  
+    CachingWrapperFilter cachingFilter2 = new CachingWrapperFilter(queryFilter);
+    Filter[] chain = new Filter[2];
+    chain[0] = cachingFilter;
+    chain[1] = cachingFilter2;
+    ChainedFilter cf = new ChainedFilter(chain);
+  
+    // throws java.lang.ClassCastException: org.apache.lucene.util.OpenBitSet cannot be cast to java.util.BitSet
+    searcher.search(new MatchAllDocsQuery(), cf, 1);
+    searcher.close();
+    reader.close();
+    dir.close();
+  }
+
+}
diff --git a/modules/queries/src/test/org/apache/lucene/queries/DuplicateFilterTest.java b/modules/queries/src/test/org/apache/lucene/queries/DuplicateFilterTest.java
new file mode 100644
index 0000000..5e31593
--- /dev/null
+++ b/modules/queries/src/test/org/apache/lucene/queries/DuplicateFilterTest.java
@@ -0,0 +1,169 @@
+package org.apache.lucene.queries;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.MockAnalyzer;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.index.*;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.ScoreDoc;
+import org.apache.lucene.search.TermQuery;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.LuceneTestCase;
+
+import java.io.IOException;
+import java.util.HashSet;
+
+public class DuplicateFilterTest extends LuceneTestCase {
+  private static final String KEY_FIELD = "url";
+  private Directory directory;
+  private IndexReader reader;
+  TermQuery tq = new TermQuery(new Term("text", "lucene"));
+  private IndexSearcher searcher;
+
+  @Override
+  public void setUp() throws Exception {
+    super.setUp();
+    directory = newDirectory();
+    RandomIndexWriter writer = new RandomIndexWriter(random, directory, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));
+
+    //Add series of docs with filterable fields : url, text and dates  flags
+    addDoc(writer, "http://lucene.apache.org", "lucene 1.4.3 available", "20040101");
+    addDoc(writer, "http://lucene.apache.org", "New release pending", "20040102");
+    addDoc(writer, "http://lucene.apache.org", "Lucene 1.9 out now", "20050101");
+    addDoc(writer, "http://www.bar.com", "Local man bites dog", "20040101");
+    addDoc(writer, "http://www.bar.com", "Dog bites local man", "20040102");
+    addDoc(writer, "http://www.bar.com", "Dog uses Lucene", "20050101");
+    addDoc(writer, "http://lucene.apache.org", "Lucene 2.0 out", "20050101");
+    addDoc(writer, "http://lucene.apache.org", "Oops. Lucene 2.1 out", "20050102");
+
+    // Until we fix LUCENE-2348, the index must
+    // have only 1 segment:
+    writer.optimize();
+
+    reader = writer.getReader();
+    writer.close();
+    searcher = newSearcher(reader);
+
+  }
+
+  @Override
+  public void tearDown() throws Exception {
+    reader.close();
+    searcher.close();
+    directory.close();
+    super.tearDown();
+  }
+
+  private void addDoc(RandomIndexWriter writer, String url, String text, String date) throws IOException {
+    Document doc = new Document();
+    doc.add(newField(KEY_FIELD, url, Field.Store.YES, Field.Index.NOT_ANALYZED));
+    doc.add(newField("text", text, Field.Store.YES, Field.Index.ANALYZED));
+    doc.add(newField("date", date, Field.Store.YES, Field.Index.ANALYZED));
+    writer.addDocument(doc);
+  }
+
+  public void testDefaultFilter() throws Throwable {
+    DuplicateFilter df = new DuplicateFilter(KEY_FIELD);
+    HashSet<String> results = new HashSet<String>();
+    ScoreDoc[] hits = searcher.search(tq, df, 1000).scoreDocs;
+
+    for (ScoreDoc hit : hits) {
+      Document d = searcher.doc(hit.doc);
+      String url = d.get(KEY_FIELD);
+      assertFalse("No duplicate urls should be returned", results.contains(url));
+      results.add(url);
+    }
+  }
+
+  public void testNoFilter() throws Throwable {
+    HashSet<String> results = new HashSet<String>();
+    ScoreDoc[] hits = searcher.search(tq, null, 1000).scoreDocs;
+    assertTrue("Default searching should have found some matches", hits.length > 0);
+    boolean dupsFound = false;
+
+    for (ScoreDoc hit : hits) {
+      Document d = searcher.doc(hit.doc);
+      String url = d.get(KEY_FIELD);
+      if (!dupsFound)
+        dupsFound = results.contains(url);
+      results.add(url);
+    }
+    assertTrue("Default searching should have found duplicate urls", dupsFound);
+  }
+
+  public void testFastFilter() throws Throwable {
+    DuplicateFilter df = new DuplicateFilter(KEY_FIELD);
+    df.setProcessingMode(DuplicateFilter.ProcessingMode.PM_FAST_INVALIDATION);
+    HashSet<String> results = new HashSet<String>();
+    ScoreDoc[] hits = searcher.search(tq, df, 1000).scoreDocs;
+    assertTrue("Filtered searching should have found some matches", hits.length > 0);
+
+    for (ScoreDoc hit : hits) {
+      Document d = searcher.doc(hit.doc);
+      String url = d.get(KEY_FIELD);
+      assertFalse("No duplicate urls should be returned", results.contains(url));
+      results.add(url);
+    }
+    assertEquals("Two urls found", 2, results.size());
+  }
+
+  public void testKeepsLastFilter() throws Throwable {
+    DuplicateFilter df = new DuplicateFilter(KEY_FIELD);
+    df.setKeepMode(DuplicateFilter.KeepMode.KM_USE_LAST_OCCURRENCE);
+    ScoreDoc[] hits = searcher.search(tq, df, 1000).scoreDocs;
+    assertTrue("Filtered searching should have found some matches", hits.length > 0);
+    for (ScoreDoc hit : hits) {
+      Document d = searcher.doc(hit.doc);
+      String url = d.get(KEY_FIELD);
+      DocsEnum td = MultiFields.getTermDocsEnum(reader,
+          MultiFields.getLiveDocs(reader),
+          KEY_FIELD,
+          new BytesRef(url));
+      int lastDoc = 0;
+      while (td.nextDoc() != DocsEnum.NO_MORE_DOCS) {
+        lastDoc = td.docID();
+      }
+      assertEquals("Duplicate urls should return last doc", lastDoc, hit.doc);
+    }
+  }
+
+
+  public void testKeepsFirstFilter() throws Throwable {
+    DuplicateFilter df = new DuplicateFilter(KEY_FIELD);
+    df.setKeepMode(DuplicateFilter.KeepMode.KM_USE_FIRST_OCCURRENCE);
+    ScoreDoc[] hits = searcher.search(tq, df, 1000).scoreDocs;
+    assertTrue("Filtered searching should have found some matches", hits.length > 0);
+    for (ScoreDoc hit : hits) {
+      Document d = searcher.doc(hit.doc);
+      String url = d.get(KEY_FIELD);
+      DocsEnum td = MultiFields.getTermDocsEnum(reader,
+          MultiFields.getLiveDocs(reader),
+          KEY_FIELD,
+          new BytesRef(url));
+      int lastDoc = 0;
+      td.nextDoc();
+      lastDoc = td.docID();
+      assertEquals("Duplicate urls should return first doc", lastDoc, hit.doc);
+    }
+  }
+
+
+}
diff --git a/modules/queries/src/test/org/apache/lucene/queries/TermsFilterTest.java b/modules/queries/src/test/org/apache/lucene/queries/TermsFilterTest.java
new file mode 100644
index 0000000..db62adb
--- /dev/null
+++ b/modules/queries/src/test/org/apache/lucene/queries/TermsFilterTest.java
@@ -0,0 +1,89 @@
+package org.apache.lucene.queries;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.IndexReader.AtomicReaderContext;
+import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.index.SlowMultiReaderWrapper;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.Filter;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.FixedBitSet;
+import org.apache.lucene.util.LuceneTestCase;
+
+import java.util.HashSet;
+
+public class TermsFilterTest extends LuceneTestCase {
+
+  public void testCachability() throws Exception {
+    TermsFilter a = new TermsFilter();
+    a.addTerm(new Term("field1", "a"));
+    a.addTerm(new Term("field1", "b"));
+    HashSet<Filter> cachedFilters = new HashSet<Filter>();
+    cachedFilters.add(a);
+    TermsFilter b = new TermsFilter();
+    b.addTerm(new Term("field1", "a"));
+    b.addTerm(new Term("field1", "b"));
+
+    assertTrue("Must be cached", cachedFilters.contains(b));
+    b.addTerm(new Term("field1", "a")); //duplicate term
+    assertTrue("Must be cached", cachedFilters.contains(b));
+    b.addTerm(new Term("field1", "c"));
+    assertFalse("Must not be cached", cachedFilters.contains(b));
+  }
+
+  public void testMissingTerms() throws Exception {
+    String fieldName = "field1";
+    Directory rd = newDirectory();
+    RandomIndexWriter w = new RandomIndexWriter(random, rd);
+    for (int i = 0; i < 100; i++) {
+      Document doc = new Document();
+      int term = i * 10; //terms are units of 10;
+      doc.add(newField(fieldName, "" + term, Field.Store.YES, Field.Index.NOT_ANALYZED));
+      w.addDocument(doc);
+    }
+    IndexReader reader = new SlowMultiReaderWrapper(w.getReader());
+    assertTrue(reader.getTopReaderContext().isAtomic);
+    AtomicReaderContext context = (AtomicReaderContext) reader.getTopReaderContext();
+    assertTrue(context.isAtomic);
+    w.close();
+
+    TermsFilter tf = new TermsFilter();
+    tf.addTerm(new Term(fieldName, "19"));
+    FixedBitSet bits = (FixedBitSet) tf.getDocIdSet(context);
+    assertEquals("Must match nothing", 0, bits.cardinality());
+
+    tf.addTerm(new Term(fieldName, "20"));
+    bits = (FixedBitSet) tf.getDocIdSet(context);
+    assertEquals("Must match 1", 1, bits.cardinality());
+
+    tf.addTerm(new Term(fieldName, "10"));
+    bits = (FixedBitSet) tf.getDocIdSet(context);
+    assertEquals("Must match 2", 2, bits.cardinality());
+
+    tf.addTerm(new Term(fieldName, "00"));
+    bits = (FixedBitSet) tf.getDocIdSet(context);
+    assertEquals("Must match 2", 2, bits.cardinality());
+
+    reader.close();
+    rd.close();
+  }
+}

