GitDiffStart: bf773c01f5f52de5a0a8a7d4dd53b32e17d0ab5d | Fri Aug 8 09:37:21 2014 +0000
diff --git a/lucene/classification/src/java/org/apache/lucene/classification/utils/DocToDoubleVectorUtils.java b/lucene/classification/src/java/org/apache/lucene/classification/utils/DocToDoubleVectorUtils.java
new file mode 100644
index 0000000..48043be
--- /dev/null
+++ b/lucene/classification/src/java/org/apache/lucene/classification/utils/DocToDoubleVectorUtils.java
@@ -0,0 +1,84 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.lucene.classification.utils;
+
+import org.apache.lucene.index.Terms;
+import org.apache.lucene.index.TermsEnum;
+import org.apache.lucene.util.BytesRef;
+
+import java.io.IOException;
+
+/**
+ * utility class for converting Lucene {@link org.apache.lucene.document.Document}s to <code>Double</code> vectors.
+ */
+public class DocToDoubleVectorUtils {
+
+  /**
+   * create a sparse <code>Double</code> vector given doc and field term vectors using local frequency of the terms in the doc
+   * @param docTerms term vectors for a given document
+   * @param fieldTerms field term vectors
+   * @return a sparse vector of <code>Double</code>s as an array
+   * @throws IOException
+   */
+  public static Double[] toSparseLocalFreqDoubleArray(Terms docTerms, Terms fieldTerms) throws IOException {
+    TermsEnum fieldTermsEnum = fieldTerms.iterator(null);
+    Double[] freqVector = null;
+    if (docTerms != null) {
+      freqVector = new Double[(int) fieldTerms.size()];
+      int i = 0;
+      TermsEnum docTermsEnum = docTerms.iterator(null);
+      BytesRef term;
+      while ((term = fieldTermsEnum.next()) != null) {
+        TermsEnum.SeekStatus seekStatus = docTermsEnum.seekCeil(term);
+        if (seekStatus.equals(TermsEnum.SeekStatus.END)) {
+          docTermsEnum = docTerms.iterator(null);
+        }
+        if (seekStatus.equals(TermsEnum.SeekStatus.FOUND)) {
+          long termFreqLocal = docTermsEnum.totalTermFreq(); // the total number of occurrences of this term in the given document
+          freqVector[i] = Long.valueOf(termFreqLocal).doubleValue();
+        }
+        else {
+          freqVector[i] = 0d;
+        }
+        i++;
+      }
+    }
+    return freqVector;
+  }
+
+  /**
+   * create a dense <code>Double</code> vector given doc and field term vectors using local frequency of the terms in the doc
+   * @param docTerms term vectors for a given document
+   * @return a dense vector of <code>Double</code>s as an array
+   * @throws IOException
+   */
+  public static Double[] toDenseLocalFreqDoubleArray(Terms docTerms) throws IOException {
+    Double[] freqVector = null;
+    if (docTerms != null) {
+        freqVector = new Double[(int) docTerms.size()];
+        int i = 0;
+        TermsEnum docTermsEnum = docTerms.iterator(null);
+
+        while (docTermsEnum.next() != null) {
+            long termFreqLocal = docTermsEnum.totalTermFreq(); // the total number of occurrences of this term in the given document
+            freqVector[i] = Long.valueOf(termFreqLocal).doubleValue();
+            i++;
+        }
+    }
+    return freqVector;
+}
+}
diff --git a/lucene/classification/src/test/org/apache/lucene/classification/utils/DocToDoubleVectorUtilsTest.java b/lucene/classification/src/test/org/apache/lucene/classification/utils/DocToDoubleVectorUtilsTest.java
new file mode 100644
index 0000000..b132a12
--- /dev/null
+++ b/lucene/classification/src/test/org/apache/lucene/classification/utils/DocToDoubleVectorUtilsTest.java
@@ -0,0 +1,105 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.lucene.classification.utils;
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.MockAnalyzer;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.document.FieldType;
+import org.apache.lucene.document.TextField;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.MultiFields;
+import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.index.Terms;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.MatchAllDocsQuery;
+import org.apache.lucene.search.ScoreDoc;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.LuceneTestCase;
+import org.junit.After;
+import org.junit.Before;
+import org.junit.Test;
+
+/**
+ * Testcase for {@link org.apache.lucene.classification.utils.DocToDoubleVectorUtils}
+ */
+public class DocToDoubleVectorUtilsTest extends LuceneTestCase {
+
+  private IndexReader index;
+  private Directory dir;
+
+  @Override
+  @Before
+  public void setUp() throws Exception {
+    super.setUp();
+    dir = newDirectory();
+    RandomIndexWriter indexWriter = new RandomIndexWriter(random(), dir);
+
+    FieldType ft = new FieldType(TextField.TYPE_STORED);
+    ft.setStoreTermVectors(true);
+    ft.setStoreTermVectorOffsets(true);
+    ft.setStoreTermVectorPositions(true);
+
+    Analyzer analyzer = new MockAnalyzer(random());
+
+    Document doc;
+    for (int i = 0; i < 10; i++) {
+      doc = new Document();
+      doc.add(new Field("id", Integer.toString(i), ft));
+      doc.add(new Field("text", random().nextInt(10) + " " + random().nextInt(10) + " " + random().nextInt(10), ft));
+      indexWriter.addDocument(doc, analyzer);
+    }
+
+    indexWriter.commit();
+
+    index = indexWriter.getReader();
+
+    indexWriter.close();
+  }
+
+  @Override
+  @After
+  public void tearDown() throws Exception {
+    index.close();
+    dir.close();
+    super.tearDown();
+  }
+
+  @Test
+  public void testDenseFreqDoubleArrayConversion() throws Exception {
+    IndexSearcher indexSearcher = new IndexSearcher(index);
+    for (ScoreDoc scoreDoc : indexSearcher.search(new MatchAllDocsQuery(), Integer.MAX_VALUE).scoreDocs) {
+      Terms docTerms = index.getTermVector(scoreDoc.doc, "text");
+      Double[] vector = DocToDoubleVectorUtils.toDenseLocalFreqDoubleArray(docTerms);
+      assertNotNull(vector);
+      assertTrue(vector.length > 0);
+    }
+  }
+
+  @Test
+  public void testSparseFreqDoubleArrayConversion() throws Exception {
+    Terms fieldTerms = MultiFields.getTerms(index, "text");
+    IndexSearcher indexSearcher = new IndexSearcher(index);
+    for (ScoreDoc scoreDoc : indexSearcher.search(new MatchAllDocsQuery(), Integer.MAX_VALUE).scoreDocs) {
+      Terms docTerms = index.getTermVector(scoreDoc.doc, "text");
+      Double[] vector = DocToDoubleVectorUtils.toSparseLocalFreqDoubleArray(docTerms, fieldTerms);
+      assertNotNull(vector);
+      assertTrue(vector.length > 0);
+    }
+  }
+}

