GitDiffStart: a1461ad9b12fe4d9a62fc7a4aff2c7361584dedc | Mon Dec 9 22:53:38 2013 +0000
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLCharacterEntities.jflex b/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLCharacterEntities.jflex
index a32e148..c717b03 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLCharacterEntities.jflex
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLCharacterEntities.jflex
@@ -73,7 +73,7 @@ CharacterEntities = ( "AElig" | "Aacute" | "Acirc" | "Agrave" | "Alpha"
     upperCaseVariantsAccepted.put("amp", "AMP");
   }
   private static final CharArrayMap<Character> entityValues
-      = new CharArrayMap<Character>(Version.LUCENE_40, 253, false);
+      = new CharArrayMap<Character>(Version.LUCENE_CURRENT, 253, false);
   static {
     String[] entities = {
       "AElig", "\u00C6", "Aacute", "\u00C1", "Acirc", "\u00C2",
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.java
index 4163a8f..f39f4ff 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.java
@@ -30673,7 +30673,7 @@ public final class HTMLStripCharFilter extends BaseCharFilter {
     upperCaseVariantsAccepted.put("amp", "AMP");
   }
   private static final CharArrayMap<Character> entityValues
-      = new CharArrayMap<Character>(Version.LUCENE_40, 253, false);
+      = new CharArrayMap<Character>(Version.LUCENE_CURRENT, 253, false);
   static {
     String[] entities = {
       "AElig", "\u00C6", "Aacute", "\u00C1", "Acirc", "\u00C2",
@@ -30812,7 +30812,7 @@ public final class HTMLStripCharFilter extends BaseCharFilter {
           escapeSTYLE = true;
         } else {
           if (null == this.escapedTags) {
-            this.escapedTags = new CharArraySet(Version.LUCENE_40, 16, true);
+            this.escapedTags = new CharArraySet(Version.LUCENE_CURRENT, 16, true);
           }
           this.escapedTags.add(tag);
         }
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.jflex b/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.jflex
index 2a19332..cbef3f4 100755
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.jflex
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.jflex
@@ -197,7 +197,7 @@ InlineElment = ( [aAbBiIqQsSuU]                   |
           escapeSTYLE = true;
         } else {
           if (null == this.escapedTags) {
-            this.escapedTags = new CharArraySet(Version.LUCENE_40, 16, true);
+            this.escapedTags = new CharArraySet(Version.LUCENE_CURRENT, 16, true);
           }
           this.escapedTags.add(tag);
         }
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/htmlentity.py b/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/htmlentity.py
index ff9ee6b..8a080b9 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/htmlentity.py
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/htmlentity.py
@@ -61,7 +61,7 @@ def main():
   print '    upperCaseVariantsAccepted.put("amp", "AMP");'
   print '  }'
   print '  private static final CharArrayMap<Character> entityValues'
-  print '      = new CharArrayMap<Character>(Version.LUCENE_40, %i, false);' % len(keys)
+  print '      = new CharArrayMap<Character>(Version.LUCENE_CURRENT, %i, false);' % len(keys)
   print '  static {'
   print '    String[] entities = {'
   output_line = '     '
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/el/GreekStemmer.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/el/GreekStemmer.java
index 815474f..3db58dd 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/el/GreekStemmer.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/el/GreekStemmer.java
@@ -196,7 +196,7 @@ public class GreekStemmer {
     return len;
   }
   
-  private static final CharArraySet exc4 = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc4 = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("θ", "δ", "ελ", "γαλ", "ν", "?", "ιδ", "?α?"),
       false);
   
@@ -222,7 +222,7 @@ public class GreekStemmer {
     return len;
   }
 
-  private static final CharArraySet exc6 = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc6 = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("αλ", "αδ", "ενδ", "αμαν", "αμμο?αλ", "ηθ", "ανηθ",
           "αν?ιδ", "???", "β??μ", "γε?", "εξ?δ", "καλ?", "καλλιν", "κα?αδ",
           "μο?λ", "μ?αν", "μ?αγια?", "μ?ολ", "μ?ο?", "νι?", "ξικ", "??νομηλ",
@@ -247,7 +247,7 @@ public class GreekStemmer {
     return len;
   }
   
-  private static final CharArraySet exc7 = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc7 = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("ανα?", "α?οθ", "α?οκ", "α?ο??", "βο?β", "ξεθ", "ο?λ",
           "?εθ", "?ικ?", "?ο?", "?ι?", "?"), 
       false);
@@ -274,11 +274,11 @@ public class GreekStemmer {
     return len;
   }
 
-  private static final CharArraySet exc8a = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc8a = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("??", "??"),
       false);
 
-  private static final CharArraySet exc8b = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc8b = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("βε?ε?", "βο?λκ", "β?α?μ", "γ", "δ?αδο?μ", "θ", "καλ?ο?ζ",
           "κα??ελ", "κο?μο?", "λαο?λ", "μ?αμεθ", "μ", "μο??ο?λμ", "ν", "ο?λ",
           "?", "?ελεκ", "?λ", "?ολι?", "?ο??ολ", "?α?ακα??", "?ο?λ?",
@@ -337,7 +337,7 @@ public class GreekStemmer {
     return len;
   }
   
-  private static final CharArraySet exc9 = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc9 = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("αβα?", "βεν", "ενα?", "αβ?", "αδ", "αθ", "αν", "α?λ",
           "βα?ον", "ν??", "?κ", "κο?", "μ?ο?", "νι?", "?αγ", "?α?ακαλ", "?ε??",
           "?κελ", "????", "?οκ", "?", "δ", "εμ", "θα??", "θ"), 
@@ -425,11 +425,11 @@ public class GreekStemmer {
     return len;
   }
 
-  private static final CharArraySet exc12a = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc12a = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("?", "α?", "??μ?", "α??μ?", "ακα?α?", "αμε?αμ?"),
       false);
 
-  private static final CharArraySet exc12b = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc12b = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("αλ", "α?", "εκ?ελ", "ζ", "μ", "ξ", "?α?ακαλ", "α?", "??ο", "νι?"),
       false);
   
@@ -449,7 +449,7 @@ public class GreekStemmer {
     return len;
   }
   
-  private static final CharArraySet exc13 = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc13 = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("διαθ", "θ", "?α?ακα?αθ", "??ο?θ", "??νθ"),
       false);
   
@@ -483,7 +483,7 @@ public class GreekStemmer {
     return len;
   }
   
-  private static final CharArraySet exc14 = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc14 = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("?α?μακ", "?αδ", "αγκ", "ανα??", "β?ομ", "εκλι?", "λαμ?ιδ",
           "λε?", "μ", "?α?", "?", "λ", "μεδ", "με?αζ", "??ο?ειν", "αμ", "αιθ",
           "ανηκ", "δε??οζ", "ενδια?ε?", "δε", "δε??ε?ε?", "καθα?ε?", "?λε",
@@ -521,7 +521,7 @@ public class GreekStemmer {
    return len;
   }
   
-  private static final CharArraySet exc15a = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc15a = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("αβα??", "?ολ??", "αδη?", "?αμ?", "?", "α??", "α?", "αμαλ",
           "αμαλλι", "αν???", "α?ε?", "α??α?", "α?α?", "δε?βεν", "δ?ο?ο?",
           "ξε?", "νεο?", "νομο?", "ολο?", "ομο?", "??ο??", "??ο???ο?", "??μ?",
@@ -530,7 +530,7 @@ public class GreekStemmer {
           "ο?λαμ", "ο??", "?", "??", "μ"), 
       false);
   
-  private static final CharArraySet exc15b = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc15b = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("?ο?", "να?λο?"),
       false);
   
@@ -567,7 +567,7 @@ public class GreekStemmer {
     return len;
   }
   
-  private static final CharArraySet exc16 = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc16 = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("ν", "?ε??ον", "δ?δεκαν", "ε?ημον", "μεγαλον", "ε??αν"),
       false);
   
@@ -587,7 +587,7 @@ public class GreekStemmer {
     return len;
   }
   
-  private static final CharArraySet exc17 = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc17 = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("α?β", "?β", "α??", "??", "α?λ", "αειμν", "δ????", "ε???", "κοινο??", "?αλιμ?"),
       false);
   
@@ -601,7 +601,7 @@ public class GreekStemmer {
     return len;
   }
   
-  private static final CharArraySet exc18 = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc18 = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("ν", "?", "??ι", "???αβομο???", "κακομο???", "εξ?ν"),
       false);
   
@@ -625,7 +625,7 @@ public class GreekStemmer {
     return len;
   }
   
-  private static final CharArraySet exc19 = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc19 = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("?α?α?ο??", "?", "?", "??ιο?λ", "αζ", "αλλο?ο??", "α?ο??"),
       false);
   
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/en/KStemmer.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/en/KStemmer.java
index a0d5bc6..8f87d91 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/en/KStemmer.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/en/KStemmer.java
@@ -280,10 +280,7 @@ public class KStemmer {
     DictEntry defaultEntry;
     DictEntry entry;
 
-    CharArrayMap<DictEntry> d = new CharArrayMap<DictEntry>(
-        Version.LUCENE_50, 1000, false);
-    
-    d = new CharArrayMap<DictEntry>(Version.LUCENE_50, 1000, false);
+    CharArrayMap<DictEntry> d = new CharArrayMap<DictEntry>(Version.LUCENE_CURRENT, 1000, false);
     for (int i = 0; i < exceptionWords.length; i++) {
       if (!d.containsKey(exceptionWords[i])) {
         entry = new DictEntry(exceptionWords[i], true);
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/HunspellStemmer.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/HunspellStemmer.java
index b0ded28..ae29482 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/HunspellStemmer.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/HunspellStemmer.java
@@ -34,7 +34,7 @@ public class HunspellStemmer {
   private final int recursionCap;
   private final HunspellDictionary dictionary;
   private final StringBuilder segment = new StringBuilder();
-  private CharacterUtils charUtils = CharacterUtils.getInstance(Version.LUCENE_40);
+  private CharacterUtils charUtils = CharacterUtils.getInstance(Version.LUCENE_CURRENT);
 
   /**
    * Constructs a new HunspellStemmer which will use the provided HunspellDictionary to create its stems. Uses the 
@@ -324,7 +324,8 @@ public class HunspellStemmer {
     InputStream affixInputStream = new FileInputStream(args[offset++]);
     InputStream dicInputStream = new FileInputStream(args[offset++]);
 
-    HunspellDictionary dictionary = new HunspellDictionary(affixInputStream, dicInputStream, Version.LUCENE_40, ignoreCase);
+    // :Post-Release-Update-Version.LUCENE_XY:
+    HunspellDictionary dictionary = new HunspellDictionary(affixInputStream, dicInputStream, Version.LUCENE_50, ignoreCase);
 
     affixInputStream.close();
     dicInputStream.close();
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/RemoveDuplicatesTokenFilter.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/RemoveDuplicatesTokenFilter.java
index ac77981..e3c7a03 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/RemoveDuplicatesTokenFilter.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/RemoveDuplicatesTokenFilter.java
@@ -35,7 +35,7 @@ public final class RemoveDuplicatesTokenFilter extends TokenFilter {
   private final PositionIncrementAttribute posIncAttribute =  addAttribute(PositionIncrementAttribute.class);
   
   // use a fixed version, as we don't care about case sensitivity.
-  private final CharArraySet previous = new CharArraySet(Version.LUCENE_50, 8, false);
+  private final CharArraySet previous = new CharArraySet(Version.LUCENE_CURRENT, 8, false);
 
   /**
    * Creates a new RemoveDuplicatesTokenFilter
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/pt/RSLPStemmerBase.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/pt/RSLPStemmerBase.java
index 24cfed7..0915d53 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/pt/RSLPStemmerBase.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/pt/RSLPStemmerBase.java
@@ -134,7 +134,7 @@ public abstract class RSLPStemmerBase {
         if (!exceptions[i].endsWith(suffix))
           throw new RuntimeException("useless exception '" + exceptions[i] + "' does not end with '" + suffix + "'");
       }
-      this.exceptions = new CharArraySet(Version.LUCENE_50,
+      this.exceptions = new CharArraySet(Version.LUCENE_CURRENT,
            Arrays.asList(exceptions), false);
     }
 
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilterFactory.java
index 6aa504b..8c1de5a 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilterFactory.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilterFactory.java
@@ -133,8 +133,8 @@ public class SynonymFilterFactory extends TokenFilterFactory implements Resource
       analyzer = new Analyzer() {
         @Override
         protected TokenStreamComponents createComponents(String fieldName, Reader reader) {
-          Tokenizer tokenizer = factory == null ? new WhitespaceTokenizer(Version.LUCENE_50, reader) : factory.create(reader);
-          TokenStream stream = ignoreCase ? new LowerCaseFilter(Version.LUCENE_50, tokenizer) : tokenizer;
+          Tokenizer tokenizer = factory == null ? new WhitespaceTokenizer(Version.LUCENE_CURRENT, reader) : factory.create(reader);
+          TokenStream stream = ignoreCase ? new LowerCaseFilter(Version.LUCENE_CURRENT, tokenizer) : tokenizer;
           return new TokenStreamComponents(tokenizer, stream);
         }
       };
@@ -201,7 +201,7 @@ public class SynonymFilterFactory extends TokenFilterFactory implements Resource
   private Analyzer loadAnalyzer(ResourceLoader loader, String cname) throws IOException {
     Class<? extends Analyzer> clazz = loader.findClass(cname, Analyzer.class);
     try {
-      Analyzer analyzer = clazz.getConstructor(Version.class).newInstance(Version.LUCENE_50);
+      Analyzer analyzer = clazz.getConstructor(Version.class).newInstance(Version.LUCENE_CURRENT);
       if (analyzer instanceof ResourceLoaderAware) {
         ((ResourceLoaderAware) analyzer).inform(loader);
       }
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopAnalyzer.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopAnalyzer.java
index e27adbb..0656c28 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopAnalyzer.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopAnalyzer.java
@@ -60,7 +60,7 @@ public class TestStopAnalyzer extends BaseTokenStreamTestCase {
 
   public void testStopList() throws IOException {
     CharArraySet stopWordsSet = new CharArraySet(TEST_VERSION_CURRENT, asSet("good", "test", "analyzer"), false);
-    StopAnalyzer newStop = new StopAnalyzer(Version.LUCENE_40, stopWordsSet);
+    StopAnalyzer newStop = new StopAnalyzer(TEST_VERSION_CURRENT, stopWordsSet);
     try (TokenStream stream = newStop.tokenStream("test", "This is a good test of the english stop analyzer")) {
       assertNotNull(stream);
       CharTermAttribute termAtt = stream.getAttribute(CharTermAttribute.class);
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopFilter.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopFilter.java
index 383fd70..b363b00 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopFilter.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopFilter.java
@@ -94,7 +94,7 @@ public class TestStopFilter extends BaseTokenStreamTestCase {
   // LUCENE-3849: make sure after .end() we see the "ending" posInc
   public void testEndStopword() throws Exception {
     CharArraySet stopSet = StopFilter.makeStopSet(TEST_VERSION_CURRENT, "of");
-    StopFilter stpf = new StopFilter(Version.LUCENE_40, new MockTokenizer(new StringReader("test of"), MockTokenizer.WHITESPACE, false), stopSet);
+    StopFilter stpf = new StopFilter(TEST_VERSION_CURRENT, new MockTokenizer(new StringReader("test of"), MockTokenizer.WHITESPACE, false), stopSet);
     assertTokenStreamContents(stpf, new String[] { "test" },
                               new int[] {0},
                               new int[] {4},
diff --git a/lucene/analysis/icu/src/java/overview.html b/lucene/analysis/icu/src/java/overview.html
index 0c123bf..5411a4f 100644
--- a/lucene/analysis/icu/src/java/overview.html
+++ b/lucene/analysis/icu/src/java/overview.html
@@ -14,6 +14,7 @@
  See the License for the specific language governing permissions and
  limitations under the License.
 -->
+<!-- :Post-Release-Update-Version.LUCENE_XY: - several mentions in this file -->
 <html>
   <head>
     <META http-equiv="Content-Type" content="text/html; charset=UTF-8">
@@ -114,9 +115,9 @@ algorithm.
 <h3>Farsi Range Queries</h3>
 <pre class="prettyprint">
   Collator collator = Collator.getInstance(new ULocale("ar"));
-  ICUCollationKeyAnalyzer analyzer = new ICUCollationKeyAnalyzer(Version.LUCENE_40, collator);
+  ICUCollationKeyAnalyzer analyzer = new ICUCollationKeyAnalyzer(Version.LUCENE_50, collator);
   RAMDirectory ramDir = new RAMDirectory();
-  IndexWriter writer = new IndexWriter(ramDir, new IndexWriterConfig(Version.LUCENE_40, analyzer));
+  IndexWriter writer = new IndexWriter(ramDir, new IndexWriterConfig(Version.LUCENE_50, analyzer));
   Document doc = new Document();
   doc.add(new Field("content", "\u0633\u0627\u0628", 
                     Field.Store.YES, Field.Index.ANALYZED));
@@ -124,7 +125,7 @@ algorithm.
   writer.close();
   IndexSearcher is = new IndexSearcher(ramDir, true);
 
-  QueryParser aqp = new QueryParser(Version.LUCENE_40, "content", analyzer);
+  QueryParser aqp = new QueryParser(Version.LUCENE_50, "content", analyzer);
   aqp.setAnalyzeRangeTerms(true);
     
   // Unicode order would include U+0633 in [ U+062F - U+0698 ], but Farsi
@@ -140,9 +141,9 @@ algorithm.
 <h3>Danish Sorting</h3>
 <pre class="prettyprint">
   Analyzer analyzer 
-    = new ICUCollationKeyAnalyzer(Version.LUCENE_40, Collator.getInstance(new ULocale("da", "dk")));
+    = new ICUCollationKeyAnalyzer(Version.LUCENE_50, Collator.getInstance(new ULocale("da", "dk")));
   RAMDirectory indexStore = new RAMDirectory();
-  IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(Version.LUCENE_40, analyzer));
+  IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(Version.LUCENE_50, analyzer));
   String[] tracer = new String[] { "A", "B", "C", "D", "E" };
   String[] data = new String[] { "HAT", "HUT", "H\u00C5T", "H\u00D8T", "HOT" };
   String[] sortedTracerOrder = new String[] { "A", "E", "B", "D", "C" };
@@ -168,15 +169,15 @@ algorithm.
 <pre class="prettyprint">
   Collator collator = Collator.getInstance(new ULocale("tr", "TR"));
   collator.setStrength(Collator.PRIMARY);
-  Analyzer analyzer = new ICUCollationKeyAnalyzer(Version.LUCENE_40, collator);
+  Analyzer analyzer = new ICUCollationKeyAnalyzer(Version.LUCENE_50, collator);
   RAMDirectory ramDir = new RAMDirectory();
-  IndexWriter writer = new IndexWriter(ramDir, new IndexWriterConfig(Version.LUCENE_40, analyzer));
+  IndexWriter writer = new IndexWriter(ramDir, new IndexWriterConfig(Version.LUCENE_50, analyzer));
   Document doc = new Document();
   doc.add(new Field("contents", "DIGY", Field.Store.NO, Field.Index.ANALYZED));
   writer.addDocument(doc);
   writer.close();
   IndexSearcher is = new IndexSearcher(ramDir, true);
-  QueryParser parser = new QueryParser(Version.LUCENE_40, "contents", analyzer);
+  QueryParser parser = new QueryParser(Version.LUCENE_50, "contents", analyzer);
   Query query = parser.parse("d\u0131gy");   // U+0131: dotless i
   ScoreDoc[] result = is.search(query, null, 1000).scoreDocs;
   assertEquals("The index Term should be included.", 1, result.length);
diff --git a/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/CreateIndexTask.java b/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/CreateIndexTask.java
index 24087aa..9d0ee64 100644
--- a/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/CreateIndexTask.java
+++ b/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/CreateIndexTask.java
@@ -97,7 +97,8 @@ public class CreateIndexTask extends PerfTask {
   }
   
   public static IndexWriterConfig createWriterConfig(Config config, PerfRunData runData, OpenMode mode, IndexCommit commit) {
-    Version version = Version.valueOf(config.get("writer.version", Version.LUCENE_40.toString()));
+    // :Post-Release-Update-Version.LUCENE_XY:
+    Version version = Version.valueOf(config.get("writer.version", Version.LUCENE_50.toString()));
     IndexWriterConfig iwConf = new IndexWriterConfig(version, runData.getAnalyzer());
     iwConf.setOpenMode(mode);
     IndexDeletionPolicy indexDeletionPolicy = getIndexDeletionPolicy(config);
diff --git a/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/tasks/CreateIndexTaskTest.java b/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/tasks/CreateIndexTaskTest.java
index 3f1d0cc..4c1c8fd 100644
--- a/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/tasks/CreateIndexTaskTest.java
+++ b/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/tasks/CreateIndexTaskTest.java
@@ -37,7 +37,8 @@ public class CreateIndexTaskTest extends BenchmarkTestCase {
 
   private PerfRunData createPerfRunData(String infoStreamValue) throws Exception {
     Properties props = new Properties();
-    props.setProperty("writer.version", Version.LUCENE_40.toString());
+    // :Post-Release-Update-Version.LUCENE_XY:
+    props.setProperty("writer.version", Version.LUCENE_50.toString());
     props.setProperty("print.props", "false"); // don't print anything
     props.setProperty("directory", "RAMDirectory");
     if (infoStreamValue != null) {
diff --git a/lucene/classification/src/java/org/apache/lucene/classification/utils/DatasetSplitter.java b/lucene/classification/src/java/org/apache/lucene/classification/utils/DatasetSplitter.java
index 401da81..5dbea2e 100644
--- a/lucene/classification/src/java/org/apache/lucene/classification/utils/DatasetSplitter.java
+++ b/lucene/classification/src/java/org/apache/lucene/classification/utils/DatasetSplitter.java
@@ -69,6 +69,7 @@ public class DatasetSplitter {
                     Analyzer analyzer, String... fieldNames) throws IOException {
 
     // create IWs for train / test / cv IDXs
+    // :Post-Release-Update-Version.LUCENE_XY:
     IndexWriter testWriter = new IndexWriter(testIndex, new IndexWriterConfig(Version.LUCENE_50, analyzer));
     IndexWriter cvWriter = new IndexWriter(crossValidationIndex, new IndexWriterConfig(Version.LUCENE_50, analyzer));
     IndexWriter trainingWriter = new IndexWriter(trainingIndex, new IndexWriterConfig(Version.LUCENE_50, analyzer));
diff --git a/lucene/core/src/java/org/apache/lucene/store/NRTCachingDirectory.java b/lucene/core/src/java/org/apache/lucene/store/NRTCachingDirectory.java
index 0d54d57..c4c0924 100644
--- a/lucene/core/src/java/org/apache/lucene/store/NRTCachingDirectory.java
+++ b/lucene/core/src/java/org/apache/lucene/store/NRTCachingDirectory.java
@@ -50,7 +50,7 @@ import org.apache.lucene.util.IOUtils;
  * <pre class="prettyprint">
  *   Directory fsDir = FSDirectory.open(new File("/path/to/index"));
  *   NRTCachingDirectory cachedFSDir = new NRTCachingDirectory(fsDir, 5.0, 60.0);
- *   IndexWriterConfig conf = new IndexWriterConfig(Version.LUCENE_32, analyzer);
+ *   IndexWriterConfig conf = new IndexWriterConfig(Version.LUCENE_50, analyzer);
  *   IndexWriter writer = new IndexWriter(cachedFSDir, conf);
  * </pre>
  *
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery.java b/lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery.java
index e78649a..d43c9b3 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery.java
@@ -217,7 +217,7 @@ public class TestPhraseQuery extends LuceneTestCase {
     Directory directory = newDirectory();
     Analyzer stopAnalyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET);
     RandomIndexWriter writer = new RandomIndexWriter(random(), directory, 
-        newIndexWriterConfig( Version.LUCENE_40, stopAnalyzer));
+        newIndexWriterConfig(TEST_VERSION_CURRENT, stopAnalyzer));
     Document doc = new Document();
     doc.add(newTextField("field", "the stop words are here", Field.Store.YES));
     writer.addDocument(doc);
diff --git a/lucene/demo/src/java/org/apache/lucene/demo/IndexFiles.java b/lucene/demo/src/java/org/apache/lucene/demo/IndexFiles.java
index a4abadc..5f1e48d 100644
--- a/lucene/demo/src/java/org/apache/lucene/demo/IndexFiles.java
+++ b/lucene/demo/src/java/org/apache/lucene/demo/IndexFiles.java
@@ -86,8 +86,9 @@ public class IndexFiles {
       System.out.println("Indexing to directory '" + indexPath + "'...");
 
       Directory dir = FSDirectory.open(new File(indexPath));
-      Analyzer analyzer = new StandardAnalyzer(Version.LUCENE_40);
-      IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_40, analyzer);
+      // :Post-Release-Update-Version.LUCENE_XY:
+      Analyzer analyzer = new StandardAnalyzer(Version.LUCENE_50);
+      IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_50, analyzer);
 
       if (create) {
         // Create a new index in the directory, removing any
diff --git a/lucene/demo/src/java/org/apache/lucene/demo/SearchFiles.java b/lucene/demo/src/java/org/apache/lucene/demo/SearchFiles.java
index 7bb22f6..621ecf4 100644
--- a/lucene/demo/src/java/org/apache/lucene/demo/SearchFiles.java
+++ b/lucene/demo/src/java/org/apache/lucene/demo/SearchFiles.java
@@ -90,7 +90,8 @@ public class SearchFiles {
     
     IndexReader reader = DirectoryReader.open(FSDirectory.open(new File(index)));
     IndexSearcher searcher = new IndexSearcher(reader);
-    Analyzer analyzer = new StandardAnalyzer(Version.LUCENE_40);
+    // :Post-Release-Update-Version.LUCENE_XY:
+    Analyzer analyzer = new StandardAnalyzer(Version.LUCENE_50);
 
     BufferedReader in = null;
     if (queries != null) {
@@ -98,7 +99,8 @@ public class SearchFiles {
     } else {
       in = new BufferedReader(new InputStreamReader(System.in, "UTF-8"));
     }
-    QueryParser parser = new QueryParser(Version.LUCENE_40, field, analyzer);
+    // :Post-Release-Update-Version.LUCENE_XY:
+    QueryParser parser = new QueryParser(Version.LUCENE_50, field, analyzer);
     while (true) {
       if (queries == null && queryString == null) {                        // prompt the user
         System.out.println("Enter query: ");
diff --git a/lucene/demo/src/java/org/apache/lucene/demo/facet/FacetExamples.java b/lucene/demo/src/java/org/apache/lucene/demo/facet/FacetExamples.java
index 2311396..2e4844c 100644
--- a/lucene/demo/src/java/org/apache/lucene/demo/facet/FacetExamples.java
+++ b/lucene/demo/src/java/org/apache/lucene/demo/facet/FacetExamples.java
@@ -25,7 +25,8 @@ import org.apache.lucene.util.Version;
  * @lucene.experimental
  */
 public interface FacetExamples {
-  
+
+  // :Post-Release-Update-Version.LUCENE_XY:
   /** The Lucene {@link Version} used by the example code. */
   public static final Version EXAMPLES_VER = Version.LUCENE_50;
 
diff --git a/lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo.java b/lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo.java
index acef8a5..bda9d3f 100644
--- a/lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo.java
+++ b/lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo.java
@@ -133,7 +133,7 @@ public class FormBasedXmlQueryDemo extends HttpServlet {
   private void openExampleIndex() throws IOException {
     //Create a RAM-based index from our test data file
     RAMDirectory rd = new RAMDirectory();
-    IndexWriterConfig iwConfig = new IndexWriterConfig(Version.LUCENE_40, analyzer);
+    IndexWriterConfig iwConfig = new IndexWriterConfig(Version.LUCENE_CURRENT, analyzer);
     IndexWriter writer = new IndexWriter(rd, iwConfig);
     InputStream dataIn = getServletContext().getResourceAsStream("/WEB-INF/data.tsv");
     BufferedReader br = new BufferedReader(new InputStreamReader(dataIn, IOUtils.CHARSET_UTF_8));
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyWriter.java b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyWriter.java
index a269f5c..3937565 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyWriter.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyWriter.java
@@ -299,7 +299,8 @@ public class DirectoryTaxonomyWriter implements TaxonomyWriter {
   protected IndexWriterConfig createIndexWriterConfig(OpenMode openMode) {
     // TODO: should we use a more optimized Codec, e.g. Pulsing (or write custom)?
     // The taxonomy has a unique structure, where each term is associated with one document
- 
+
+    // :Post-Release-Update-Version.LUCENE_XY:
     // Make sure we use a MergePolicy which always merges adjacent segments and thus
     // keeps the doc IDs ordered as well (this is crucial for the taxonomy index).
     return new IndexWriterConfig(Version.LUCENE_50, null).setOpenMode(openMode).setMergePolicy(
diff --git a/lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/TestParser.java b/lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/TestParser.java
index 9f5b6fe..eaa71db 100644
--- a/lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/TestParser.java
+++ b/lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/TestParser.java
@@ -65,7 +65,7 @@ public class TestParser extends LuceneTestCase {
     BufferedReader d = new BufferedReader(new InputStreamReader(
         TestParser.class.getResourceAsStream("reuters21578.txt"), "US-ASCII"));
     dir = newDirectory();
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(Version.LUCENE_40, analyzer));
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));
     String line = d.readLine();
     while (line != null) {
       int endOfDate = line.indexOf('\t');
diff --git a/lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/FreeTextSuggester.java b/lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/FreeTextSuggester.java
index 797acae..e901ef7 100644
--- a/lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/FreeTextSuggester.java
+++ b/lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/FreeTextSuggester.java
@@ -301,7 +301,7 @@ public class FreeTextSuggester extends Lookup {
 
     Directory dir = FSDirectory.open(tempIndexPath);
 
-    IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_46, indexAnalyzer);
+    IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_CURRENT, indexAnalyzer);
     iwc.setOpenMode(IndexWriterConfig.OpenMode.CREATE);
     iwc.setRAMBufferSizeMB(ramBufferSizeMB);
     IndexWriter writer = new IndexWriter(dir, iwc);
diff --git a/lucene/test-framework/src/java/org/apache/lucene/util/LuceneTestCase.java b/lucene/test-framework/src/java/org/apache/lucene/util/LuceneTestCase.java
index eb12f54..862a9f4 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/util/LuceneTestCase.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/util/LuceneTestCase.java
@@ -228,6 +228,7 @@ public abstract class LuceneTestCase extends Assert {
   // for all suites ever since.
   // -----------------------------------------------------------------
 
+  // :Post-Release-Update-Version.LUCENE_XY:
   /** 
    * Use this constant when creating Analyzers and any other version-dependent stuff.
    * <p><b>NOTE:</b> Change this when development starts for new Lucene version:
diff --git a/solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField.java b/solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField.java
index 7c33a3d..c1b2ce7 100644
--- a/solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField.java
+++ b/solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField.java
@@ -187,8 +187,7 @@ public class ICUCollationField extends FieldType {
       rbc.setVariableTop(variableTop);
     }
 
-    // we use 4.0 because it ensures we just encode the pure byte[] keys.
-    analyzer = new ICUCollationKeyAnalyzer(Version.LUCENE_40, collator);
+    analyzer = new ICUCollationKeyAnalyzer(Version.LUCENE_CURRENT, collator);
   }
   
   /**
diff --git a/solr/core/src/java/org/apache/solr/schema/CollationField.java b/solr/core/src/java/org/apache/solr/schema/CollationField.java
index 5b46159..891e673 100644
--- a/solr/core/src/java/org/apache/solr/schema/CollationField.java
+++ b/solr/core/src/java/org/apache/solr/schema/CollationField.java
@@ -147,8 +147,7 @@ public class CollationField extends FieldType {
       else
         throw new SolrException(ErrorCode.SERVER_ERROR, "Invalid decomposition: " + decomposition);
     }
-    // we use 4.0 because it ensures we just encode the pure byte[] keys.
-    analyzer = new CollationKeyAnalyzer(Version.LUCENE_40, collator);
+    analyzer = new CollationKeyAnalyzer(Version.LUCENE_CURRENT, collator);
   }
   
   /**
diff --git a/solr/core/src/test/org/apache/solr/core/SolrCoreCheckLockOnStartupTest.java b/solr/core/src/test/org/apache/solr/core/SolrCoreCheckLockOnStartupTest.java
index e07b5ed..9051bf2 100644
--- a/solr/core/src/test/org/apache/solr/core/SolrCoreCheckLockOnStartupTest.java
+++ b/solr/core/src/test/org/apache/solr/core/SolrCoreCheckLockOnStartupTest.java
@@ -43,7 +43,7 @@ public class SolrCoreCheckLockOnStartupTest extends SolrTestCaseJ4 {
     //explicitly creates the temp dataDir so we know where the index will be located
     createTempDir();
 
-    IndexWriterConfig indexWriterConfig = new IndexWriterConfig(Version.LUCENE_40, null);
+    IndexWriterConfig indexWriterConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, null);
     Directory directory = newFSDirectory(new File(dataDir, "index"));
     //creates a new index on the known location
     new IndexWriter(
@@ -58,7 +58,7 @@ public class SolrCoreCheckLockOnStartupTest extends SolrTestCaseJ4 {
 
     Directory directory = newFSDirectory(new File(dataDir, "index"), new SimpleFSLockFactory());
     //creates a new IndexWriter without releasing the lock yet
-    IndexWriter indexWriter = new IndexWriter(directory, new IndexWriterConfig(Version.LUCENE_40, null));
+    IndexWriter indexWriter = new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, null));
 
     ignoreException("locked");
     try {
@@ -84,7 +84,7 @@ public class SolrCoreCheckLockOnStartupTest extends SolrTestCaseJ4 {
     log.info("Acquiring lock on {}", indexDir.getAbsolutePath());
     Directory directory = newFSDirectory(indexDir, new NativeFSLockFactory());
     //creates a new IndexWriter without releasing the lock yet
-    IndexWriter indexWriter = new IndexWriter(directory, new IndexWriterConfig(Version.LUCENE_40, null));
+    IndexWriter indexWriter = new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, null));
 
     ignoreException("locked");
     try {
diff --git a/solr/core/src/test/org/apache/solr/core/TestArbitraryIndexDir.java b/solr/core/src/test/org/apache/solr/core/TestArbitraryIndexDir.java
index d16456e..567b1be 100644
--- a/solr/core/src/test/org/apache/solr/core/TestArbitraryIndexDir.java
+++ b/solr/core/src/test/org/apache/solr/core/TestArbitraryIndexDir.java
@@ -118,7 +118,7 @@ public class TestArbitraryIndexDir extends AbstractSolrTestCase{
     Directory dir = newFSDirectory(newDir);
     IndexWriter iw = new IndexWriter(
         dir,
-        new IndexWriterConfig(Version.LUCENE_40, new StandardAnalyzer(Version.LUCENE_40))
+        new IndexWriterConfig(TEST_VERSION_CURRENT, new StandardAnalyzer(TEST_VERSION_CURRENT))
     );
     Document doc = new Document();
     doc.add(new TextField("id", "2", Field.Store.YES));
diff --git a/solr/core/src/test/org/apache/solr/search/TestStressLucene.java b/solr/core/src/test/org/apache/solr/search/TestStressLucene.java
index 38809f5..f27e363 100644
--- a/solr/core/src/test/org/apache/solr/search/TestStressLucene.java
+++ b/solr/core/src/test/org/apache/solr/search/TestStressLucene.java
@@ -101,7 +101,7 @@ public class TestStressLucene extends TestRTGBase {
 
 
     // RAMDirectory dir = new RAMDirectory();
-    // final IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(Version.LUCENE_40, new WhitespaceAnalyzer(Version.LUCENE_40)));
+    // final IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));
 
     Directory dir = newDirectory();
 
diff --git a/solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter.java b/solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter.java
index 15ec62f..69d70ab 100644
--- a/solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter.java
+++ b/solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter.java
@@ -25,7 +25,7 @@ import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
 import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;
 import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
 import org.apache.lucene.analysis.tokenattributes.TypeAttribute;
-import org.apache.lucene.util.Version;
+import org.apache.lucene.util.LuceneTestCase;
 
 import java.util.Collection;
 import java.util.HashSet;
@@ -41,7 +41,7 @@ class SimpleQueryConverter extends SpellingQueryConverter {
   @Override
   public Collection<Token> convert(String origQuery) {
     Collection<Token> result = new HashSet<Token>();
-    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(Version.LUCENE_40);
+    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(LuceneTestCase.TEST_VERSION_CURRENT);
     
     try (TokenStream ts = analyzer.tokenStream("", origQuery)) {
       // TODO: support custom attributes

