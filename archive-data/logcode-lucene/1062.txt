GitDiffStart: 160940688f8c7e808ddf31d784fe8a46a3e49f2b | Wed May 11 21:19:01 2016 +0200
diff --git a/solr/core/src/java/org/apache/solr/client/solrj/embedded/SSLConfig.java b/solr/core/src/java/org/apache/solr/client/solrj/embedded/SSLConfig.java
index 60f383c..62c9024 100644
--- a/solr/core/src/java/org/apache/solr/client/solrj/embedded/SSLConfig.java
+++ b/solr/core/src/java/org/apache/solr/client/solrj/embedded/SSLConfig.java
@@ -20,7 +20,7 @@ import org.eclipse.jetty.util.ssl.SslContextFactory;
 
 /** 
  * Encapsulates settings related to SSL Configuration for an embedded Jetty Server.
- * NOTE: all other settings are ignogred if {@link #isSSLMode} is false.
+ * NOTE: all other settings are ignored if {@link #isSSLMode} is false.
  * @see #setUseSSL
  */
 public class SSLConfig {
diff --git a/solr/core/src/java/org/apache/solr/cloud/Assign.java b/solr/core/src/java/org/apache/solr/cloud/Assign.java
index d313a47..b68dfe1 100644
--- a/solr/core/src/java/org/apache/solr/cloud/Assign.java
+++ b/solr/core/src/java/org/apache/solr/cloud/Assign.java
@@ -157,7 +157,7 @@ public class Assign {
     if (createNodeList == null) { // We only care if we haven't been told to put new replicas on specific nodes.
       int availableSlots = 0;
       for (Map.Entry<String, ReplicaCount> ent : nodeNameVsShardCount.entrySet()) {
-        //ADDREPLICA can put more than maxShardsPerNode on an instnace, so this test is necessary.
+        //ADDREPLICA can put more than maxShardsPerNode on an instance, so this test is necessary.
         if (maxShardsPerNode > ent.getValue().thisCollectionNodes) {
           availableSlots += (maxShardsPerNode - ent.getValue().thisCollectionNodes);
         }
diff --git a/solr/core/src/java/org/apache/solr/cloud/Overseer.java b/solr/core/src/java/org/apache/solr/cloud/Overseer.java
index f25cab7..c5e51f9 100644
--- a/solr/core/src/java/org/apache/solr/cloud/Overseer.java
+++ b/solr/core/src/java/org/apache/solr/cloud/Overseer.java
@@ -659,7 +659,7 @@ public class Overseer implements Closeable {
       }
     }
 
-    // Go through the list of presently-hosted proeprties and remove any that have too many replicas that host the property
+    // Go through the list of presently-hosted properties and remove any that have too many replicas that host the property
     private void removeOverallocatedReplicas() {
       tmpMaxPropPerNode = origMaxPropPerNode; // A bit clumsy, but don't want to duplicate code.
       tmpModulo = origModulo;
diff --git a/solr/core/src/java/org/apache/solr/core/Config.java b/solr/core/src/java/org/apache/solr/core/Config.java
index a998c6f..9244409 100644
--- a/solr/core/src/java/org/apache/solr/core/Config.java
+++ b/solr/core/src/java/org/apache/solr/core/Config.java
@@ -103,7 +103,7 @@ public class Config {
    * @param loader the resource loader used to obtain an input stream if 'is' is null
    * @param name the resource name used if the input stream 'is' is null
    * @param is the resource as a SAX InputSource
-   * @param prefix an optional prefix that will be preprended to all non-absolute xpath expressions
+   * @param prefix an optional prefix that will be prepended to all non-absolute xpath expressions
    */
   public Config(SolrResourceLoader loader, String name, InputSource is, String prefix, boolean substituteProps) throws ParserConfigurationException, IOException, SAXException
   {
diff --git a/solr/core/src/java/org/apache/solr/core/CoreContainer.java b/solr/core/src/java/org/apache/solr/core/CoreContainer.java
index e1ea6fb..f933fab 100644
--- a/solr/core/src/java/org/apache/solr/core/CoreContainer.java
+++ b/solr/core/src/java/org/apache/solr/core/CoreContainer.java
@@ -1082,7 +1082,7 @@ public class CoreContainer {
     CoreDescriptor desc = solrCores.getDynamicDescriptor(name);
     if (desc == null) { //Nope, no transient core with this name
 
-      // if there was an error initalizing this core, throw a 500
+      // if there was an error initializing this core, throw a 500
       // error with the details for clients attempting to access it.
       CoreLoadFailure loadFailure = getCoreInitFailures().get(name);
       if (null != loadFailure) {
diff --git a/solr/core/src/java/org/apache/solr/core/InitParams.java b/solr/core/src/java/org/apache/solr/core/InitParams.java
index d79dfea..031c7b7 100644
--- a/solr/core/src/java/org/apache/solr/core/InitParams.java
+++ b/solr/core/src/java/org/apache/solr/core/InitParams.java
@@ -94,7 +94,7 @@ public class InitParams {
       //if this is a component implicitly defined in code it should be overridden by initPrams
       merge(defaults, (NamedList) info.initArgs.get(DEFAULTS), info.initArgs, DEFAULTS, false);
     } else {
-      //if the args is initialized from solrconfig.xml inside the requesthHandler it should be taking precedence over  initParams
+      //if the args is initialized from solrconfig.xml inside the requestHandler it should be taking precedence over  initParams
       merge((NamedList) info.initArgs.get(DEFAULTS), defaults, info.initArgs, DEFAULTS, false);
     }
     merge((NamedList) info.initArgs.get(INVARIANTS), invariants, info.initArgs, INVARIANTS, false);
@@ -103,7 +103,7 @@ public class InitParams {
     if (pluginInfo.initArgs != null) {
       for (int i = 0; i < pluginInfo.initArgs.size(); i++) {
         String name = pluginInfo.initArgs.getName(i);
-        if (KNOWN_KEYS.contains(name)) continue;//aready taken care of
+        if (KNOWN_KEYS.contains(name)) continue;//already taken care of
         Object val = info.initArgs.get(name);
         if (val != null) continue; //this is explicitly specified in the reqhandler , ignore
         info.initArgs.add(name, pluginInfo.initArgs.getVal(i));
diff --git a/solr/core/src/java/org/apache/solr/core/SolrConfig.java b/solr/core/src/java/org/apache/solr/core/SolrConfig.java
index 0b4bac3..a5f5458 100644
--- a/solr/core/src/java/org/apache/solr/core/SolrConfig.java
+++ b/solr/core/src/java/org/apache/solr/core/SolrConfig.java
@@ -97,7 +97,7 @@ public class SolrConfig extends Config implements MapSerializable {
     REQUIRE_NAME_IN_OVERLAY,
     REQUIRE_CLASS,
     LAZY,
-    // EnumSet.of and/or EnumSet.copyOf(Collection) are anoying
+    // EnumSet.of and/or EnumSet.copyOf(Collection) are annoying
     // because of type determination
     NOOP
   }
@@ -204,7 +204,7 @@ public class SolrConfig extends Config implements MapSerializable {
         true
     );
     assertWarnOrFail("Solr no longer supports forceful unlocking via the 'unlockOnStartup' option.  "+
-                     "This is no longer neccessary for the default lockType except in situations where "+
+                     "This is no longer necessary for the default lockType except in situations where "+
                      "it would be dangerous and should not be done.  For other lockTypes and/or "+
                      "directoryFactory options it may also be dangerous and users must resolve "+
                      "problematic locks manually.",
@@ -317,7 +317,7 @@ public class SolrConfig extends Config implements MapSerializable {
       .add(new SolrPluginInfo(SearchComponent.class, "searchComponent", REQUIRE_NAME, REQUIRE_CLASS, MULTI_OK))
       .add(new SolrPluginInfo(UpdateRequestProcessorFactory.class, "updateProcessor", REQUIRE_NAME, REQUIRE_CLASS, MULTI_OK))
           // TODO: WTF is up with queryConverter???
-          // it aparently *only* works as a singleton? - SOLR-4304
+          // it apparently *only* works as a singleton? - SOLR-4304
           // and even then -- only if there is a single SpellCheckComponent
           // because of queryConverter.setIndexAnalyzer
       .add(new SolrPluginInfo(QueryConverter.class, "queryConverter", REQUIRE_NAME, REQUIRE_CLASS))
diff --git a/solr/core/src/java/org/apache/solr/core/package-info.java b/solr/core/src/java/org/apache/solr/core/package-info.java
index 6fd201f..0dbb8c2 100644
--- a/solr/core/src/java/org/apache/solr/core/package-info.java
+++ b/solr/core/src/java/org/apache/solr/core/package-info.java
@@ -16,7 +16,7 @@
  */
  
 /** 
- * Core classes implementin Solr internals and the management of {@link org.apache.solr.core.SolrCore}s
+ * Core classes implementing Solr internals and the management of {@link org.apache.solr.core.SolrCore}s
  */
 package org.apache.solr.core;
 
diff --git a/solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase.java b/solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase.java
index d7cfc45..0770bd4 100644
--- a/solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase.java
+++ b/solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase.java
@@ -222,7 +222,7 @@ public abstract class AnalysisRequestHandlerBase extends RequestHandlerBase {
     final FieldType fieldType = context.getFieldType();
     final AttributeSource[] tokens = tokenList.toArray(new AttributeSource[tokenList.size()]);
     
-    // sort the tokens by absoulte position
+    // sort the tokens by absolute position
     ArrayUtil.timSort(tokens, new Comparator<AttributeSource>() {
       @Override
       public int compare(AttributeSource a, AttributeSource b) {
@@ -481,7 +481,7 @@ public abstract class AnalysisRequestHandlerBase extends RequestHandlerBase {
     /**
      * Constructs a new AnalysisContext with a given field tpe, analyzer and
      * termsToMatch. During the analysis processs, The produced tokens will be 
-     * compaired to the termes in the {@code termsToMatch} set. When found, 
+     * compared to the terms in the {@code termsToMatch} set. When found, 
      * these tokens will be marked as a match.
      *
      * @param fieldName    The name of the field the analysis is performed on 
diff --git a/solr/core/src/java/org/apache/solr/handler/NestedRequestHandler.java b/solr/core/src/java/org/apache/solr/handler/NestedRequestHandler.java
index 947a339..7495ed0 100644
--- a/solr/core/src/java/org/apache/solr/handler/NestedRequestHandler.java
+++ b/solr/core/src/java/org/apache/solr/handler/NestedRequestHandler.java
@@ -22,7 +22,7 @@ import org.apache.solr.request.SolrRequestHandler;
 /**An interface for RequestHandlers need to handle all paths under its registered path
  */
 public interface NestedRequestHandler {
-  /** Return a Requestandler to handle a subpath from the path this handler is registered.
+  /** Return a RequestHandler to handle a subpath from the path this handler is registered.
    */
   SolrRequestHandler getSubHandler(String subPath);
 }
diff --git a/solr/core/src/java/org/apache/solr/handler/ReplicationHandler.java b/solr/core/src/java/org/apache/solr/handler/ReplicationHandler.java
index 4dbcef2..3785db7 100644
--- a/solr/core/src/java/org/apache/solr/handler/ReplicationHandler.java
+++ b/solr/core/src/java/org/apache/solr/handler/ReplicationHandler.java
@@ -145,7 +145,7 @@ public class ReplicationHandler extends RequestHandlerBase implements SolrCoreAw
           try {
             version = Long.parseLong(commitTime);
           } catch (NumberFormatException e) {
-            LOG.warn("Version in commitData was not formated correctly: " + commitTime, e);
+            LOG.warn("Version in commitData was not formatted correctly: " + commitTime, e);
           }
         }
       } catch (IOException e) {
diff --git a/solr/core/src/java/org/apache/solr/handler/SQLHandler.java b/solr/core/src/java/org/apache/solr/handler/SQLHandler.java
index bc46a78..4031858 100644
--- a/solr/core/src/java/org/apache/solr/handler/SQLHandler.java
+++ b/solr/core/src/java/org/apache/solr/handler/SQLHandler.java
@@ -504,7 +504,7 @@ public class SQLHandler extends RequestHandlerBase implements SolrCoreAware , Pe
     Bucket[] buckets = getBuckets(sqlVisitor.groupBy, fieldSet);
     Metric[] metrics = getMetrics(sqlVisitor.fields, fieldSet);
     if(metrics.length == 0) {
-      throw new IOException("Group by queries must include atleast one aggregate function.");
+      throw new IOException("Group by queries must include at least one aggregate function.");
     }
 
     TableSpec tableSpec = new TableSpec(sqlVisitor.table, defaultZkhost);
diff --git a/solr/core/src/java/org/apache/solr/handler/StandardRequestHandler.java b/solr/core/src/java/org/apache/solr/handler/StandardRequestHandler.java
index 53a8397..d5eae08 100644
--- a/solr/core/src/java/org/apache/solr/handler/StandardRequestHandler.java
+++ b/solr/core/src/java/org/apache/solr/handler/StandardRequestHandler.java
@@ -25,7 +25,7 @@ import java.net.URL;
  *
  *
  * All of the following options may be configured for this handler
- * in the solrconfig as defaults, and may be overriden as request parameters.
+ * in the solrconfig as defaults, and may be overridden as request parameters.
  * (TODO: complete documentation of request parameters here, rather than only
  * on the wiki).
  *
diff --git a/solr/core/src/java/org/apache/solr/handler/component/StatsField.java b/solr/core/src/java/org/apache/solr/handler/component/StatsField.java
index 6f15174..4c2a2b6 100644
--- a/solr/core/src/java/org/apache/solr/handler/component/StatsField.java
+++ b/solr/core/src/java/org/apache/solr/handler/component/StatsField.java
@@ -138,7 +138,7 @@ public class StatsField {
      *        order to compute <i>this</i> stat over the entire distributed result set.
      * @param selfDep indicates that when computing this stat across a distributed result 
      *        set, each shard must compute this stat <i>in addition to</i> any other 
-     *        distributed dependences.
+     *        distributed dependencies.
      * @see #getDistribDeps
      */
     Stat(boolean selfDep, Stat... deps) {
diff --git a/solr/core/src/java/org/apache/solr/handler/component/StatsValuesFactory.java b/solr/core/src/java/org/apache/solr/handler/component/StatsValuesFactory.java
index d49a108..c96a2eb 100644
--- a/solr/core/src/java/org/apache/solr/handler/component/StatsValuesFactory.java
+++ b/solr/core/src/java/org/apache/solr/handler/component/StatsValuesFactory.java
@@ -547,7 +547,7 @@ class NumericStatsValues extends AbstractStatsValues<Number> {
       if (null != min) {
         double minD = min.doubleValue();
         if (null == this.min || minD < this.minD) {
-          // Double for result & cached primitive doulbe to minimize unboxing in future comparisons
+          // Double for result & cached primitive double to minimize unboxing in future comparisons
           this.min = this.minD = minD;
         }
       }
@@ -556,7 +556,7 @@ class NumericStatsValues extends AbstractStatsValues<Number> {
       if (null != max) {
         double maxD = max.doubleValue();
         if (null == this.max || this.maxD < maxD) {
-          // Double for result & cached primitive doulbe to minimize unboxing in future comparisons
+          // Double for result & cached primitive double to minimize unboxing in future comparisons
           this.max = this.maxD = maxD;
         }
       }
diff --git a/solr/core/src/java/org/apache/solr/highlight/SolrHighlighter.java b/solr/core/src/java/org/apache/solr/highlight/SolrHighlighter.java
index a32be42..e9ebf0c 100644
--- a/solr/core/src/java/org/apache/solr/highlight/SolrHighlighter.java
+++ b/solr/core/src/java/org/apache/solr/highlight/SolrHighlighter.java
@@ -44,7 +44,7 @@ public abstract class SolrHighlighter
 
   /**
    * Return a String array of the fields to be highlighted.
-   * Falls back to the programatic defaults, or the default search field if the list of fields
+   * Falls back to the programmatic defaults, or the default search field if the list of fields
    * is not specified in either the handler configuration or the request.
    * @param query The current Query
    * @param request The current SolrQueryRequest
diff --git a/solr/core/src/java/org/apache/solr/highlight/package-info.java b/solr/core/src/java/org/apache/solr/highlight/package-info.java
index fda2083..2177c7f 100644
--- a/solr/core/src/java/org/apache/solr/highlight/package-info.java
+++ b/solr/core/src/java/org/apache/solr/highlight/package-info.java
@@ -16,7 +16,7 @@
  */
  
 /** 
- * {@link org.apache.solr.highlight.SolrHighlighter} API and related implementaions and utilities
+ * {@link org.apache.solr.highlight.SolrHighlighter} API and related implementations and utilities
  * <p>
  * See {@link org.apache.lucene.search.highlight} for addition information.
  */
diff --git a/solr/core/src/java/org/apache/solr/internal/csv/CSVParser.java b/solr/core/src/java/org/apache/solr/internal/csv/CSVParser.java
index ad1aef7..7bd918f 100644
--- a/solr/core/src/java/org/apache/solr/internal/csv/CSVParser.java
+++ b/solr/core/src/java/org/apache/solr/internal/csv/CSVParser.java
@@ -268,7 +268,7 @@ public class CSVParser {
     int lastChar = in.readAgain();
     
     //  read the next char and set eol
-    /* note: unfourtunately isEndOfLine may consumes a character silently.
+    /* note: unfortunately isEndOfLine may consumes a character silently.
      *       this has no effect outside of the method. so a simple workaround
      *       is to call 'readAgain' on the stream...
      *       uh: might using objects instead of base-types (jdk1.5 autoboxing!)
diff --git a/solr/core/src/java/org/apache/solr/internal/csv/ExtendedBufferedReader.java b/solr/core/src/java/org/apache/solr/internal/csv/ExtendedBufferedReader.java
index 48f373a..90bc90a 100644
--- a/solr/core/src/java/org/apache/solr/internal/csv/ExtendedBufferedReader.java
+++ b/solr/core/src/java/org/apache/solr/internal/csv/ExtendedBufferedReader.java
@@ -106,7 +106,7 @@ class ExtendedBufferedReader extends BufferedReader  {
    * Non-blocking reading of len chars into buffer buf starting
    * at bufferposition off.
    * 
-   * performs an iteratative read on the underlying stream
+   * performs an iterative read on the underlying stream
    * as long as the following conditions hold:
    *   - less than len chars have been read
    *   - end of stream has not been reached
diff --git a/solr/core/src/java/org/apache/solr/logging/LoggerInfo.java b/solr/core/src/java/org/apache/solr/logging/LoggerInfo.java
index 8692ea5..0a55276 100644
--- a/solr/core/src/java/org/apache/solr/logging/LoggerInfo.java
+++ b/solr/core/src/java/org/apache/solr/logging/LoggerInfo.java
@@ -21,7 +21,7 @@ import org.apache.solr.common.util.SimpleOrderedMap;
 import static org.apache.solr.common.params.CommonParams.NAME;
 
 /**
- * Wrapper class for Logger implementaions
+ * Wrapper class for Logger implementations
  */
 public abstract class LoggerInfo implements Comparable<LoggerInfo> {
   public static final String ROOT_NAME = "root";
diff --git a/solr/core/src/java/org/apache/solr/response/BinaryQueryResponseWriter.java b/solr/core/src/java/org/apache/solr/response/BinaryQueryResponseWriter.java
index 85235e6..8ae901b 100644
--- a/solr/core/src/java/org/apache/solr/response/BinaryQueryResponseWriter.java
+++ b/solr/core/src/java/org/apache/solr/response/BinaryQueryResponseWriter.java
@@ -31,7 +31,7 @@ import org.apache.solr.request.SolrQueryRequest;
  */
 public interface BinaryQueryResponseWriter extends QueryResponseWriter{
 
-    /**Use it to write the reponse in a binary format
+    /**Use it to write the response in a binary format
      */
     public void write(OutputStream out, SolrQueryRequest request, SolrQueryResponse response) throws IOException;
 }
diff --git a/solr/core/src/java/org/apache/solr/response/QueryResponseWriter.java b/solr/core/src/java/org/apache/solr/response/QueryResponseWriter.java
index c3fdf4a..8f460dd 100644
--- a/solr/core/src/java/org/apache/solr/response/QueryResponseWriter.java
+++ b/solr/core/src/java/org/apache/solr/response/QueryResponseWriter.java
@@ -50,7 +50,7 @@ public interface QueryResponseWriter extends NamedListInitializedPlugin {
    * Write a SolrQueryResponse, this method must be thread save.
    *
    * <p>
-   * Information about the request (in particular: formating options) may be 
+   * Information about the request (in particular: formatting options) may be 
    * obtained from <code>req</code> but the dominant source of information 
    * should be <code>rsp</code>.
    * <p>
diff --git a/solr/core/src/java/org/apache/solr/response/QueryResponseWriterUtil.java b/solr/core/src/java/org/apache/solr/response/QueryResponseWriterUtil.java
index 6487537..ed47e84 100644
--- a/solr/core/src/java/org/apache/solr/response/QueryResponseWriterUtil.java
+++ b/solr/core/src/java/org/apache/solr/response/QueryResponseWriterUtil.java
@@ -36,7 +36,7 @@ public final class QueryResponseWriterUtil {
   /**
    * Writes the response writer's result to the given output stream.
    * This method inspects the specified writer to determine if it is a 
-   * {@link BinaryQueryResponseWriter} or not to delegate to the approprate method.
+   * {@link BinaryQueryResponseWriter} or not to delegate to the appropriate method.
    * @see BinaryQueryResponseWriter#write(OutputStream,SolrQueryRequest,SolrQueryResponse)
    * @see BinaryQueryResponseWriter#write(Writer,SolrQueryRequest,SolrQueryResponse)
    */
diff --git a/solr/core/src/java/org/apache/solr/response/ResultContext.java b/solr/core/src/java/org/apache/solr/response/ResultContext.java
index b8cd6b2..56811a7 100644
--- a/solr/core/src/java/org/apache/solr/response/ResultContext.java
+++ b/solr/core/src/java/org/apache/solr/response/ResultContext.java
@@ -41,7 +41,7 @@ public abstract class ResultContext {
 
   public abstract Query getQuery();
 
-  // TODO: any reason to allow for retrievial of any filters as well?
+  // TODO: any reason to allow for retrieval of any filters as well?
 
   /** Note: do not use the request to get the searcher!  A cross-core request may have a different
    *  searcher (for the other core) than the original request.
diff --git a/solr/core/src/java/org/apache/solr/response/package-info.java b/solr/core/src/java/org/apache/solr/response/package-info.java
index 6b4bd2c..c1b6148 100644
--- a/solr/core/src/java/org/apache/solr/response/package-info.java
+++ b/solr/core/src/java/org/apache/solr/response/package-info.java
@@ -16,7 +16,7 @@
  */
  
 /** 
- * API and implementations of {@link org.apache.solr.response.QueryResponseWriter} for formating Solr request responses
+ * API and implementations of {@link org.apache.solr.response.QueryResponseWriter} for formatting Solr request responses
  */
 package org.apache.solr.response;
 
diff --git a/solr/core/src/java/org/apache/solr/rest/RestManager.java b/solr/core/src/java/org/apache/solr/rest/RestManager.java
index 1c095cb..2e1c9bc 100644
--- a/solr/core/src/java/org/apache/solr/rest/RestManager.java
+++ b/solr/core/src/java/org/apache/solr/rest/RestManager.java
@@ -128,7 +128,7 @@ public class RestManager {
     }
 
     /**
-     * Returns the set of non-registerable endpoints.
+     * Returns the set of non-registrable endpoints.
      */
     public Set<String> getReservedEndpoints() {
       return Collections.unmodifiableSet(reservedEndpoints);
diff --git a/solr/core/src/java/org/apache/solr/schema/CurrencyField.java b/solr/core/src/java/org/apache/solr/schema/CurrencyField.java
index b1047e3..5a0bb1a 100644
--- a/solr/core/src/java/org/apache/solr/schema/CurrencyField.java
+++ b/solr/core/src/java/org/apache/solr/schema/CurrencyField.java
@@ -556,7 +556,7 @@ public class CurrencyField extends FieldType implements SchemaAware, ResourceLoa
         @Override
         public long longVal(int doc) {
           long amount = amounts.longVal(doc);
-          // bail fast using whatever ammounts defaults to if no value
+          // bail fast using whatever amounts defaults to if no value
           // (if we don't do this early, currencyOrd may be < 0, 
           // causing index bounds exception
           if ( ! exists(doc) ) {
diff --git a/solr/core/src/java/org/apache/solr/schema/ExchangeRateProvider.java b/solr/core/src/java/org/apache/solr/schema/ExchangeRateProvider.java
index 3ffe515..34c12e3 100644
--- a/solr/core/src/java/org/apache/solr/schema/ExchangeRateProvider.java
+++ b/solr/core/src/java/org/apache/solr/schema/ExchangeRateProvider.java
@@ -26,7 +26,7 @@ import org.apache.solr.common.SolrException;
  */
 public interface ExchangeRateProvider {
   /**
-   * Get the exchange rate betwen the two given currencies
+   * Get the exchange rate between the two given currencies
    * @return the exchange rate as a double
    * @throws SolrException if the rate is not defined in the provider
    */
diff --git a/solr/core/src/java/org/apache/solr/schema/TrieDoubleField.java b/solr/core/src/java/org/apache/solr/schema/TrieDoubleField.java
index b055f1a..edaa0c4 100644
--- a/solr/core/src/java/org/apache/solr/schema/TrieDoubleField.java
+++ b/solr/core/src/java/org/apache/solr/schema/TrieDoubleField.java
@@ -103,7 +103,7 @@ public class TrieDoubleField extends TrieField implements DoubleValueFieldType {
               
               @Override
               public void fillValue(int doc) {
-                // micro optimized (eliminate at least one redudnent ord check) 
+                // micro optimized (eliminate at least one redundant ord check) 
                 //mval.exists = exists(doc);
                 //mval.value = mval.exists ? doubleVal(doc) : 0.0D;
                 BytesRef bytes = view.get(doc);
diff --git a/solr/core/src/java/org/apache/solr/schema/TrieField.java b/solr/core/src/java/org/apache/solr/schema/TrieField.java
index bed087e..3483909 100644
--- a/solr/core/src/java/org/apache/solr/schema/TrieField.java
+++ b/solr/core/src/java/org/apache/solr/schema/TrieField.java
@@ -309,7 +309,7 @@ public class TrieField extends PrimitiveFieldType {
    * field is not supported for this field type
    *
    * @param choice the selector Type to use, will never be null
-   * @param field the field to use, garunteed to be multivalued.
+   * @param field the field to use, guaranteed to be multivalued.
    * @see #getSingleValueSource(MultiValueSelector,SchemaField,QParser) 
    */
   protected ValueSource getSingleValueSource(SortedSetSelector.Type choice, SchemaField field) {
diff --git a/solr/core/src/java/org/apache/solr/schema/TrieFloatField.java b/solr/core/src/java/org/apache/solr/schema/TrieFloatField.java
index 38210a3..8d1739e 100644
--- a/solr/core/src/java/org/apache/solr/schema/TrieFloatField.java
+++ b/solr/core/src/java/org/apache/solr/schema/TrieFloatField.java
@@ -103,7 +103,7 @@ public class TrieFloatField extends TrieField implements FloatValueFieldType {
               
               @Override
               public void fillValue(int doc) {
-                // micro optimized (eliminate at least one redudnent ord check) 
+                // micro optimized (eliminate at least one redundant ord check) 
                 //mval.exists = exists(doc);
                 //mval.value = mval.exists ? floatVal(doc) : 0.0F;
                 //
diff --git a/solr/core/src/java/org/apache/solr/schema/TrieIntField.java b/solr/core/src/java/org/apache/solr/schema/TrieIntField.java
index 2a953b3..07d9c74 100644
--- a/solr/core/src/java/org/apache/solr/schema/TrieIntField.java
+++ b/solr/core/src/java/org/apache/solr/schema/TrieIntField.java
@@ -101,7 +101,7 @@ public class TrieIntField extends TrieField implements IntValueFieldType {
               
               @Override
               public void fillValue(int doc) {
-                // micro optimized (eliminate at least one redudnent ord check) 
+                // micro optimized (eliminate at least one redundant ord check) 
                 //mval.exists = exists(doc);
                 //mval.value = mval.exists ? intVal(doc) : 0;
                 //
diff --git a/solr/core/src/java/org/apache/solr/schema/TrieLongField.java b/solr/core/src/java/org/apache/solr/schema/TrieLongField.java
index 54239bd..28345af 100644
--- a/solr/core/src/java/org/apache/solr/schema/TrieLongField.java
+++ b/solr/core/src/java/org/apache/solr/schema/TrieLongField.java
@@ -101,7 +101,7 @@ public class TrieLongField extends TrieField implements LongValueFieldType {
               
               @Override
               public void fillValue(int doc) {
-                // micro optimized (eliminate at least one redudnent ord check) 
+                // micro optimized (eliminate at least one redundant ord check) 
                 //mval.exists = exists(doc);
                 //mval.value = mval.exists ? longVal(doc) : 0;
                 //
diff --git a/solr/core/src/java/org/apache/solr/schema/UUIDField.java b/solr/core/src/java/org/apache/solr/schema/UUIDField.java
index e83359c..d40e5a5 100644
--- a/solr/core/src/java/org/apache/solr/schema/UUIDField.java
+++ b/solr/core/src/java/org/apache/solr/schema/UUIDField.java
@@ -38,7 +38,7 @@ import org.apache.solr.update.processor.UUIDUpdateProcessorFactory; // jdoc
  * configured as the unique key field) since the result will be that each 
  * replica of each document will get a unique UUID value.  
  * Using {@link UUIDUpdateProcessorFactory} to generate UUID values when 
- * documents are added is recomended instead.
+ * documents are added is recommended instead.
  * </p>
  * 
  * @see UUID#toString
diff --git a/solr/core/src/java/org/apache/solr/search/CollapsingQParserPlugin.java b/solr/core/src/java/org/apache/solr/search/CollapsingQParserPlugin.java
index f4a0fbf..9a22221 100644
--- a/solr/core/src/java/org/apache/solr/search/CollapsingQParserPlugin.java
+++ b/solr/core/src/java/org/apache/solr/search/CollapsingQParserPlugin.java
@@ -2530,7 +2530,7 @@ public class CollapsingQParserPlugin extends QParserPlugin {
       }
     }
     
-    // LUCENE-6808 workarround
+    // LUCENE-6808 workaround
     private static Object cloneIfBytesRef(Object val) {
       if (val instanceof BytesRef) {
         return BytesRef.deepCopyOf((BytesRef) val);
@@ -2631,7 +2631,7 @@ public class CollapsingQParserPlugin extends QParserPlugin {
       }
 
       if (0 <= lastCompare) {
-        // we're either not competitive, or we're completley tied with another doc that's already group head
+        // we're either not competitive, or we're completely tied with another doc that's already group head
         // that's already been selected
         return false;
       } // else...
diff --git a/solr/core/src/java/org/apache/solr/search/CursorMark.java b/solr/core/src/java/org/apache/solr/search/CursorMark.java
index 6330286..38fced5 100644
--- a/solr/core/src/java/org/apache/solr/search/CursorMark.java
+++ b/solr/core/src/java/org/apache/solr/search/CursorMark.java
@@ -56,7 +56,7 @@ public final class CursorMark {
    * The raw, unmarshalled, sort values (that corrispond with the SortField's in the 
    * SortSpec) for knowing which docs this cursor should "search after".  If this 
    * list is null, then we have no specific values to "search after" and we 
-   * should start from the very begining of the sorted list of documents matching 
+   * should start from the very beginning of the sorted list of documents matching 
    * the query.
    */
   private List<Object> values = null;
diff --git a/solr/core/src/java/org/apache/solr/search/DocSet.java b/solr/core/src/java/org/apache/solr/search/DocSet.java
index 91d8e10..dd8f024 100644
--- a/solr/core/src/java/org/apache/solr/search/DocSet.java
+++ b/solr/core/src/java/org/apache/solr/search/DocSet.java
@@ -48,7 +48,7 @@ public interface DocSet extends Closeable, Accountable /* extends Collection<Int
    *
    * <p>
    * This method may be faster then <code>add(doc)</code> in some
-   * implementaions provided the caller is certain of the precondition.
+   * implementations provided the caller is certain of the precondition.
    * </p>
    *
    * @see #add
diff --git a/solr/core/src/java/org/apache/solr/search/DocSetBase.java b/solr/core/src/java/org/apache/solr/search/DocSetBase.java
index 3c59af6..fa83981 100644
--- a/solr/core/src/java/org/apache/solr/search/DocSetBase.java
+++ b/solr/core/src/java/org/apache/solr/search/DocSetBase.java
@@ -27,7 +27,7 @@ import org.apache.lucene.util.BitDocIdSet;
 import org.apache.lucene.util.FixedBitSet;
 import org.apache.solr.common.SolrException;
 
-/** A base class that may be usefull for implementing DocSets */
+/** A base class that may be useful for implementing DocSets */
 abstract class DocSetBase implements DocSet {
 
   public static FixedBitSet toBitSet(DocSet set) {
diff --git a/solr/core/src/java/org/apache/solr/search/LFUCache.java b/solr/core/src/java/org/apache/solr/search/LFUCache.java
index 9bf544b..2b593c6 100644
--- a/solr/core/src/java/org/apache/solr/search/LFUCache.java
+++ b/solr/core/src/java/org/apache/solr/search/LFUCache.java
@@ -272,11 +272,11 @@ public class LFUCache<K, V> implements SolrCache<K, V> {
     long cevictions = 0;
 
     // NOTE: It is safe to iterate on a CopyOnWriteArrayList
-    for (ConcurrentLFUCache.Stats statistiscs : statsList) {
-      clookups += statistiscs.getCumulativeLookups();
-      chits += statistiscs.getCumulativeHits();
-      cinserts += statistiscs.getCumulativePuts();
-      cevictions += statistiscs.getCumulativeEvictions();
+    for (ConcurrentLFUCache.Stats statistics : statsList) {
+      clookups += statistics.getCumulativeLookups();
+      chits += statistics.getCumulativeHits();
+      cinserts += statistics.getCumulativePuts();
+      cevictions += statistics.getCumulativeEvictions();
     }
     lst.add("cumulative_lookups", clookups);
     lst.add("cumulative_hits", chits);
diff --git a/solr/core/src/java/org/apache/solr/search/QueryResultKey.java b/solr/core/src/java/org/apache/solr/search/QueryResultKey.java
index d42ba45..bcf8104 100644
--- a/solr/core/src/java/org/apache/solr/search/QueryResultKey.java
+++ b/solr/core/src/java/org/apache/solr/search/QueryResultKey.java
@@ -99,7 +99,7 @@ public final class QueryResultKey {
    * already been found to have equal hashCodes, since the unordered comparison aspects 
    * of the logic are not cheap.
    * 
-   * @return true if the lists of equivilent other then the ordering
+   * @return true if the lists of equivalent other then the ordering
    */
   private static boolean unorderedCompare(List<Query> fqList1, List<Query> fqList2) {
     // Do fast version first, expecting that filters are usually in the same order
@@ -128,7 +128,7 @@ public final class QueryResultKey {
    * This method should only be called on lists which are the same size, and where 
    * all items with an index less then the specified start index are the same.
    *
-   * @return true if the list items after start are equivilent other then the ordering
+   * @return true if the list items after start are equivalent other then the ordering
    */
   private static boolean unorderedCompare(List<Query> fqList1, List<Query> fqList2, int start) {
     assert null != fqList1;
@@ -137,8 +137,8 @@ public final class QueryResultKey {
     final int sz = fqList1.size();
     assert fqList2.size() == sz;
 
-    // SOLR-5618: if we had a garuntee that the lists never contained any duplicates,
-    // this logic could be a lot simplier 
+    // SOLR-5618: if we had a guarantee that the lists never contained any duplicates,
+    // this logic could be a lot simpler 
     //
     // (And of course: if the SolrIndexSearcher / QueryCommmand was ever changed to
     // sort the filter query list, then this whole method could be eliminated).
diff --git a/solr/core/src/java/org/apache/solr/search/SolrIndexSearcher.java b/solr/core/src/java/org/apache/solr/search/SolrIndexSearcher.java
index 6ff5469..23a6db3 100644
--- a/solr/core/src/java/org/apache/solr/search/SolrIndexSearcher.java
+++ b/solr/core/src/java/org/apache/solr/search/SolrIndexSearcher.java
@@ -222,7 +222,7 @@ public class SolrIndexSearcher extends IndexSearcher implements Closeable, SolrI
   /**
    * Builds the necessary collector chain (via delegate wrapping) and executes the query against it. This method takes
    * into consideration both the explicitly provided collector and postFilter as well as any needed collector wrappers
-   * for dealing with options specified in the QueryCOmmand.
+   * for dealing with options specified in the QueryCommand.
    */
   private void buildAndRunCollectorChain(QueryResult qr, Query query, Collector collector, QueryCommand cmd,
       DelegatingCollector postFilter) throws IOException {
diff --git a/solr/core/src/java/org/apache/solr/search/SolrReturnFields.java b/solr/core/src/java/org/apache/solr/search/SolrReturnFields.java
index 34ef79e..a700d7b 100644
--- a/solr/core/src/java/org/apache/solr/search/SolrReturnFields.java
+++ b/solr/core/src/java/org/apache/solr/search/SolrReturnFields.java
@@ -134,7 +134,7 @@ public class SolrReturnFields extends ReturnFields {
       // TODO??? need to fill up the fields with matching field names in the index
       // and add them to okFieldNames?
       // maybe just get all fields?
-      // this would disable field selection optimization... i think thatis OK
+      // this would disable field selection optimization... i think that is OK
       fields.clear(); // this will get all fields, and use wantsField to limit
     }
 
diff --git a/solr/core/src/java/org/apache/solr/search/SortedIntDocSet.java b/solr/core/src/java/org/apache/solr/search/SortedIntDocSet.java
index 514d512..0cb5d08 100644
--- a/solr/core/src/java/org/apache/solr/search/SortedIntDocSet.java
+++ b/solr/core/src/java/org/apache/solr/search/SortedIntDocSet.java
@@ -105,7 +105,7 @@ public class SortedIntDocSet extends DocSetBase {
     // FUTURE: try partitioning like a sort algorithm.  Pick the midpoint of the big
     // array, find where that should be in the small array, and then recurse with
     // the top and bottom half of both arrays until they are small enough to use
-    // a fallback insersection method.
+    // a fallback intersection method.
     // NOTE: I tried this and it worked, but it was actually slower than this current
     // highly optimized approach.
 
@@ -248,7 +248,7 @@ public class SortedIntDocSet extends DocSetBase {
     int i=0,j=0;
     int doca=a[i],docb=b[j];
     for(;;) {
-      // switch on the sign bit somehow?  Hopefull JVM is smart enough to just test once.
+      // switch on the sign bit somehow? Hopefully JVM is smart enough to just test once.
 
       // Since set a is less dense then set b, doca is likely to be greater than docb so
       // check that case first.  This resulted in a 13% speedup.
diff --git a/solr/core/src/java/org/apache/solr/search/ValueSourceParser.java b/solr/core/src/java/org/apache/solr/search/ValueSourceParser.java
index aa94a2e..4a1a4b1 100644
--- a/solr/core/src/java/org/apache/solr/search/ValueSourceParser.java
+++ b/solr/core/src/java/org/apache/solr/search/ValueSourceParser.java
@@ -94,14 +94,14 @@ public abstract class ValueSourceParser implements NamedListInitializedPlugin {
   /* standard functions */
   public static Map<String, ValueSourceParser> standardValueSourceParsers = new HashMap<>();
 
-  /** Adds a new parser for the name and returns any existing one that was overriden.
+  /** Adds a new parser for the name and returns any existing one that was overridden.
    *  This is not thread safe.
    */
   public static ValueSourceParser addParser(String name, ValueSourceParser p) {
     return standardValueSourceParsers.put(name, p);
   }
 
-  /** Adds a new parser for the name and returns any existing one that was overriden.
+  /** Adds a new parser for the name and returns any existing one that was overridden.
    *  This is not thread safe.
    */
   public static ValueSourceParser addParser(NamedParser p) {
@@ -419,7 +419,7 @@ public abstract class ValueSourceParser implements NamedListInitializedPlugin {
           FieldType.MultiValueSelector selector = FieldType.MultiValueSelector.lookup(s);
           if (null == selector) {
             throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,
-                                    "Multi-Valued field selector '"+s+"' not spported");
+                                    "Multi-Valued field selector '"+s+"' not supported");
           }
           return f.getType().getSingleValueSource(selector, f, fp);
         }
diff --git a/solr/core/src/java/org/apache/solr/search/function/FileFloatSource.java b/solr/core/src/java/org/apache/solr/search/function/FileFloatSource.java
index 7382fdc..7999541 100644
--- a/solr/core/src/java/org/apache/solr/search/function/FileFloatSource.java
+++ b/solr/core/src/java/org/apache/solr/search/function/FileFloatSource.java
@@ -203,7 +203,7 @@ public class FileFloatSource extends ValueSource {
     
     public void resetCache(){
       synchronized(readerCache){
-        // Map.clear() is optional and can throw UnsipportedOperationException,
+        // Map.clear() is optional and can throw UnsupportedOperationException,
         // but readerCache is WeakHashMap and it supports clear().
         readerCache.clear();
       }
diff --git a/solr/core/src/java/org/apache/solr/search/grouping/distributed/requestfactory/TopGroupsShardRequestFactory.java b/solr/core/src/java/org/apache/solr/search/grouping/distributed/requestfactory/TopGroupsShardRequestFactory.java
index bdca03f..ca73a30 100644
--- a/solr/core/src/java/org/apache/solr/search/grouping/distributed/requestfactory/TopGroupsShardRequestFactory.java
+++ b/solr/core/src/java/org/apache/solr/search/grouping/distributed/requestfactory/TopGroupsShardRequestFactory.java
@@ -105,7 +105,7 @@ public class TopGroupsShardRequestFactory implements ShardRequestFactory {
       sreq.params.set(CommonParams.START, "0");
     }
     if (rb.shards_rows > -1) {
-      // if the client set shards.rows set this explicity
+      // if the client set shards.rows set this explicitly
       sreq.params.set(CommonParams.ROWS, rb.shards_rows);
     } else {
       sreq.params.set(CommonParams.ROWS, rb.getSortSpec().getOffset() + rb.getSortSpec().getCount());
diff --git a/solr/core/src/java/org/apache/solr/security/AuthenticationPlugin.java b/solr/core/src/java/org/apache/solr/security/AuthenticationPlugin.java
index 47daec1..105f307 100644
--- a/solr/core/src/java/org/apache/solr/security/AuthenticationPlugin.java
+++ b/solr/core/src/java/org/apache/solr/security/AuthenticationPlugin.java
@@ -65,8 +65,7 @@ public abstract class AuthenticationPlugin implements Closeable {
    * @param request the http request
    * @param response the http response
    * @param filterChain the servlet filter chain
-   * @throws Exception any exception thrown during the authentication, e.g. 
-   * PriviledgedAccessException
+   * @throws Exception any exception thrown during the authentication, e.g. PrivilegedActionException
    */
   public abstract void doAuthenticate(ServletRequest request, ServletResponse response,
       FilterChain filterChain) throws Exception;
diff --git a/solr/core/src/java/org/apache/solr/spelling/IndexBasedSpellChecker.java b/solr/core/src/java/org/apache/solr/spelling/IndexBasedSpellChecker.java
index 0160143..aa6e049 100644
--- a/solr/core/src/java/org/apache/solr/spelling/IndexBasedSpellChecker.java
+++ b/solr/core/src/java/org/apache/solr/spelling/IndexBasedSpellChecker.java
@@ -30,7 +30,7 @@ import java.io.IOException;
 
 /**
  * <p>
- * A spell checker implementation that loads words from Solr as well as arbitary Lucene indices.
+ * A spell checker implementation that loads words from Solr as well as arbitrary Lucene indices.
  * </p>
  * 
  * <p>
diff --git a/solr/core/src/java/org/apache/solr/update/CdcrUpdateLog.java b/solr/core/src/java/org/apache/solr/update/CdcrUpdateLog.java
index 595791d..3afc66c 100644
--- a/solr/core/src/java/org/apache/solr/update/CdcrUpdateLog.java
+++ b/solr/core/src/java/org/apache/solr/update/CdcrUpdateLog.java
@@ -595,7 +595,7 @@ public class CdcrUpdateLog extends UpdateLog {
      */
     public void forwardSeek(CdcrLogReader subReader) {
       // If a subreader has a null tlog reader, does nothing
-      // This can happend if a subreader is instantiated from a non-initialised parent reader, or if the subreader
+      // This can happened if a subreader is instantiated from a non-initialised parent reader, or if the subreader
       // has been closed.
       if (subReader.tlogReader == null) {
         return;
diff --git a/solr/core/src/java/org/apache/solr/update/UpdateShardHandler.java b/solr/core/src/java/org/apache/solr/update/UpdateShardHandler.java
index 4fe869c..5cc77d2 100644
--- a/solr/core/src/java/org/apache/solr/update/UpdateShardHandler.java
+++ b/solr/core/src/java/org/apache/solr/update/UpdateShardHandler.java
@@ -85,7 +85,7 @@ public class UpdateShardHandler {
 
   /**
    * In general, RecoveryStrategy threads do not do disk IO, but they open and close SolrCores
-   * in async threads, amoung other things, and can trigger disk IO, so we use this alternate 
+   * in async threads, among other things, and can trigger disk IO, so we use this alternate 
    * executor rather than the 'updateExecutor', which is interrupted on shutdown.
    * 
    * @return executor for {@link RecoveryStrategy} thread which will not be interrupted on close.
@@ -96,7 +96,7 @@ public class UpdateShardHandler {
 
   public void close() {
     try {
-      // we interrupt on purpose here, but this exectuor should not run threads that do disk IO!
+      // we interrupt on purpose here, but this executor should not run threads that do disk IO!
       ExecutorUtil.shutdownWithInterruptAndAwaitTermination(updateExecutor);
       ExecutorUtil.shutdownAndAwaitTermination(recoveryExecutor);
     } catch (Exception e) {
diff --git a/solr/core/src/java/org/apache/solr/update/processor/AllValuesOrNoneFieldMutatingUpdateProcessor.java b/solr/core/src/java/org/apache/solr/update/processor/AllValuesOrNoneFieldMutatingUpdateProcessor.java
index 5169435..52726ea 100644
--- a/solr/core/src/java/org/apache/solr/update/processor/AllValuesOrNoneFieldMutatingUpdateProcessor.java
+++ b/solr/core/src/java/org/apache/solr/update/processor/AllValuesOrNoneFieldMutatingUpdateProcessor.java
@@ -83,7 +83,7 @@ public abstract class AllValuesOrNoneFieldMutatingUpdateProcessor extends FieldM
     for (final Object srcVal : vals) {
       final Object destVal = mutateValue(srcVal);
       if (SKIP_FIELD_VALUE_LIST_SINGLETON == destVal) {
-        log.debug("field '{}' {} value '{}' is not mutatable, so no values will be mutated",
+        log.debug("field '{}' {} value '{}' is not mutable, so no values will be mutated",
                   new Object[] { srcField.getName(), srcVal.getClass().getSimpleName(), srcVal });
         return srcField;
       }
diff --git a/solr/core/src/java/org/apache/solr/update/processor/ClassificationUpdateProcessor.java b/solr/core/src/java/org/apache/solr/update/processor/ClassificationUpdateProcessor.java
index b752565..9344fb9 100644
--- a/solr/core/src/java/org/apache/solr/update/processor/ClassificationUpdateProcessor.java
+++ b/solr/core/src/java/org/apache/solr/update/processor/ClassificationUpdateProcessor.java
@@ -80,7 +80,7 @@ class ClassificationUpdateProcessor
   }
 
   /**
-   * @param cmd the update command in input conaining the Document to classify
+   * @param cmd the update command in input containing the Document to classify
    * @throws IOException If there is a low-level I/O error
    */
   @Override
diff --git a/solr/core/src/java/org/apache/solr/update/processor/ClassificationUpdateProcessorFactory.java b/solr/core/src/java/org/apache/solr/update/processor/ClassificationUpdateProcessorFactory.java
index 79b3240..a70f21d 100644
--- a/solr/core/src/java/org/apache/solr/update/processor/ClassificationUpdateProcessorFactory.java
+++ b/solr/core/src/java/org/apache/solr/update/processor/ClassificationUpdateProcessorFactory.java
@@ -55,7 +55,7 @@ public class ClassificationUpdateProcessorFactory extends UpdateRequestProcessor
 
   private int minDf; // knn specific - the minimum Document Frequency for considering a term
 
-  private int k; // knn specific - thw window of top results to evaluate, when assgning the class
+  private int k; // knn specific - thw window of top results to evaluate, when assigning the class
 
   @Override
   public void init(final NamedList args) {
diff --git a/solr/core/src/java/org/apache/solr/update/processor/ConcatFieldUpdateProcessorFactory.java b/solr/core/src/java/org/apache/solr/update/processor/ConcatFieldUpdateProcessorFactory.java
index 34b92b0..9f8e88a 100644
--- a/solr/core/src/java/org/apache/solr/update/processor/ConcatFieldUpdateProcessorFactory.java
+++ b/solr/core/src/java/org/apache/solr/update/processor/ConcatFieldUpdateProcessorFactory.java
@@ -44,7 +44,7 @@ import org.apache.commons.lang.StringUtils;
  * For example, in the configuration below, any "single valued" string and 
  * text field which is found to contain multiple values <i>except</i> for 
  * the <code>primary_author</code> field will be concatenated using the 
- * string "<code>; </code>" as a delimeter.  For the 
+ * string "<code>; </code>" as a delimiter.  For the 
  * <code>primary_author</code> field, the multiple values will be left 
  * alone for <code>FirstFieldValueUpdateProcessorFactory</code> to deal with.
  * </p>
diff --git a/solr/core/src/java/org/apache/solr/update/processor/DocBasedVersionConstraintsProcessorFactory.java b/solr/core/src/java/org/apache/solr/update/processor/DocBasedVersionConstraintsProcessorFactory.java
index 4ecf371..c21ea76 100644
--- a/solr/core/src/java/org/apache/solr/update/processor/DocBasedVersionConstraintsProcessorFactory.java
+++ b/solr/core/src/java/org/apache/solr/update/processor/DocBasedVersionConstraintsProcessorFactory.java
@@ -229,7 +229,7 @@ public class DocBasedVersionConstraintsProcessorFactory extends UpdateRequestPro
     private Object convertFieldValueUsingType(SchemaField sf, final Object rawValue) {
       if (rawValue instanceof CharSequence) {
         // in theory, the FieldType might still be CharSequence based,
-        // but in that case trust it to do an identiy conversion...
+        // but in that case trust it to do an identity conversion...
         FieldType fieldType = userVersionField.getType();
         BytesRefBuilder term = new BytesRefBuilder();
         fieldType.readableToIndexed((CharSequence)rawValue, term);
@@ -468,7 +468,7 @@ public class DocBasedVersionConstraintsProcessorFactory extends UpdateRequestPro
         //   - deleteVersionParam to do a version check
         //   - some new boolean param to determine if a stub document gets added in place?
         try {
-          // drop the delete, and instead propogate an AddDoc that
+          // drop the delete, and instead propagate an AddDoc that
           // replaces the doc with a new "empty" one that records the deleted version
 
           SolrInputDocument newDoc = new SolrInputDocument();
diff --git a/solr/core/src/java/org/apache/solr/update/processor/DocExpirationUpdateProcessorFactory.java b/solr/core/src/java/org/apache/solr/update/processor/DocExpirationUpdateProcessorFactory.java
index b8a4b57..ffef1f3 100644
--- a/solr/core/src/java/org/apache/solr/update/processor/DocExpirationUpdateProcessorFactory.java
+++ b/solr/core/src/java/org/apache/solr/update/processor/DocExpirationUpdateProcessorFactory.java
@@ -247,7 +247,7 @@ public final class DocExpirationUpdateProcessorFactory
       } catch (SolrException e) {
         throw confErr(DEL_CHAIN_NAME_CONF + " does not exist: " + deleteChainName, e);
       }
-      // schedule recuring deletion
+      // schedule recurring deletion
       initDeleteExpiredDocsScheduler(core);
     }
   }
@@ -331,9 +331,9 @@ public final class DocExpirationUpdateProcessorFactory
           final DateMathParser dmp = new DateMathParser();
           // TODO: should we try to accept things like "1DAY" as well as "+1DAY" ?
           // How? 
-          // 'startsWith("+")' is a bad idea because it would cause porblems with
+          // 'startsWith("+")' is a bad idea because it would cause problems with
           // things like "/DAY+1YEAR"
-          // Maybe catch ParseException and rety with "+" prepended?
+          // Maybe catch ParseException and retry with "+" prepended?
           doc.addField(expireField, dmp.parseMath(math));
         } catch (ParseException pe) {
           throw new SolrException(BAD_REQUEST, "Can't parse ttl as date math: " + math, pe);
@@ -419,11 +419,11 @@ public final class DocExpirationUpdateProcessorFactory
         } catch (IOException ioe) {
           log.error("IOException in periodic deletion of expired docs: " +
                     ioe.getMessage(), ioe);
-          // DO NOT RETHROW: ScheduledExecutor will supress subsequent executions
+          // DO NOT RETHROW: ScheduledExecutor will suppress subsequent executions
         } catch (RuntimeException re) {
           log.error("Runtime error in periodic deletion of expired docs: " + 
                     re.getMessage(), re);
-          // DO NOT RETHROW: ScheduledExecutor will supress subsequent executions
+          // DO NOT RETHROW: ScheduledExecutor will suppress subsequent executions
         } finally {
           SolrRequestInfo.clearRequestInfo();
         }
@@ -436,12 +436,12 @@ public final class DocExpirationUpdateProcessorFactory
   /**
    * <p>
    * Helper method that returns true if the Runnable managed by this factory 
-   * should be responseible of doing periodica deletes.
+   * should be responsible of doing periodical deletes.
    * </p>
    * <p>
-   * In simple standalone instalations this method always returns true, 
+   * In simple standalone installations this method always returns true, 
    * but in cloud mode it will be true if and only if we are currently the leader 
-   * of the (active) slice with the first name (lexigraphically).
+   * of the (active) slice with the first name (lexicographically).
    * </p>
    * <p>
    * If this method returns false, it may have also logged a message letting the user 
diff --git a/solr/core/src/java/org/apache/solr/update/processor/RunUpdateProcessorFactory.java b/solr/core/src/java/org/apache/solr/update/processor/RunUpdateProcessorFactory.java
index 0e40195..c301b17 100644
--- a/solr/core/src/java/org/apache/solr/update/processor/RunUpdateProcessorFactory.java
+++ b/solr/core/src/java/org/apache/solr/update/processor/RunUpdateProcessorFactory.java
@@ -26,7 +26,7 @@ import org.apache.solr.update.*;
 
 /**
  * Executes the update commands using the underlying UpdateHandler.
- * Allmost all processor chains should end with an instance of 
+ * Almost all processor chains should end with an instance of 
  * <code>RunUpdateProcessorFactory</code> unless the user is explicitly 
  * executing the update commands in an alternative custom 
  * <code>UpdateRequestProcessorFactory</code>
diff --git a/solr/core/src/java/org/apache/solr/update/processor/TolerantUpdateProcessor.java b/solr/core/src/java/org/apache/solr/update/processor/TolerantUpdateProcessor.java
index f9437f5..bf629cc 100644
--- a/solr/core/src/java/org/apache/solr/update/processor/TolerantUpdateProcessor.java
+++ b/solr/core/src/java/org/apache/solr/update/processor/TolerantUpdateProcessor.java
@@ -202,8 +202,8 @@ public class TolerantUpdateProcessor extends UpdateRequestProcessor {
     try {
       super.processMergeIndexes(cmd);
     } catch (Throwable t) {
-      // we're not tolerante of errors from this type of command, but we
-      // do need to track it so we can annotate it with any other errors we were allready tolerant of
+      // we're not tolerant of errors from this type of command, but we
+      // do need to track it so we can annotate it with any other errors we were already tolerant of
       firstErrTracker.caught(t);
       throw t;
     }
@@ -214,8 +214,8 @@ public class TolerantUpdateProcessor extends UpdateRequestProcessor {
     try {
       super.processCommit(cmd);
     } catch (Throwable t) {
-      // we're not tolerante of errors from this type of command, but we
-      // do need to track it so we can annotate it with any other errors we were allready tolerant of
+      // we're not tolerant of errors from this type of command, but we
+      // do need to track it so we can annotate it with any other errors we were already tolerant of
       firstErrTracker.caught(t);
       throw t;
     }
@@ -226,8 +226,8 @@ public class TolerantUpdateProcessor extends UpdateRequestProcessor {
     try {
       super.processRollback(cmd);
     } catch (Throwable t) {
-      // we're not tolerante of errors from this type of command, but we
-      // do need to track it so we can annotate it with any other errors we were allready tolerant of
+      // we're not tolerant of errors from this type of command, but we
+      // do need to track it so we can annotate it with any other errors we were already tolerant of
       firstErrTracker.caught(t);
       throw t;
     }
@@ -298,7 +298,7 @@ public class TolerantUpdateProcessor extends UpdateRequestProcessor {
     // decide if we have hit a situation where we know an error needs to be thrown.
     
     if ((DistribPhase.TOLEADER.equals(distribPhase) ? 0 : maxErrors) < knownErrors.size()) {
-      // NOTE: even if maxErrors wasn't exceeeded, we need to throw an error when we have any errors if we're
+      // NOTE: even if maxErrors wasn't exceeded, we need to throw an error when we have any errors if we're
       // a leader that was forwarded to by another node so that the forwarding node knows we encountered some
       // problems and can aggregate the results
 
@@ -361,7 +361,7 @@ public class TolerantUpdateProcessor extends UpdateRequestProcessor {
      *
      * This method will keep a record that this update processor has already thrown the exception, and do 
      * nothing on future calls, so subsequent update processor methods can update the metadata but won't 
-     * inadvertantly re-throw this (or any other) cascading exception by mistake.
+     * inadvertently re-throw this (or any other) cascading exception by mistake.
      */
     public void throwFirst() throws SolrException {
       assert null != first : "caught was never called?";
diff --git a/solr/core/src/java/org/apache/solr/update/processor/UpdateRequestProcessorChain.java b/solr/core/src/java/org/apache/solr/update/processor/UpdateRequestProcessorChain.java
index 4629425..6c5567f 100644
--- a/solr/core/src/java/org/apache/solr/update/processor/UpdateRequestProcessorChain.java
+++ b/solr/core/src/java/org/apache/solr/update/processor/UpdateRequestProcessorChain.java
@@ -76,7 +76,7 @@ import java.util.Objects;
  * </ul>
  *
  * <p>
- * Allmost all processor chains should end with an instance of 
+ * Almost all processor chains should end with an instance of 
  * <code>RunUpdateProcessorFactory</code> unless the user is explicitly 
  * executing the update commands in an alternative custom 
  * <code>UpdateRequestProcessorFactory</code>.  If a chain includes 
diff --git a/solr/core/src/java/org/apache/solr/util/DateMathParser.java b/solr/core/src/java/org/apache/solr/util/DateMathParser.java
index 489a5aa..9ffdf73 100644
--- a/solr/core/src/java/org/apache/solr/util/DateMathParser.java
+++ b/solr/core/src/java/org/apache/solr/util/DateMathParser.java
@@ -114,7 +114,7 @@ public class DateMathParser  {
       .parseCaseInsensitive().parseLenient().appendInstant().toFormatter(Locale.ROOT);
 
   /**
-   * A mapping from (uppercased) String labels idenyifying time units,
+   * A mapping from (uppercased) String labels identifying time units,
    * to the corresponding Calendar constant used to set/add/roll that unit
    * of measurement.
    *
@@ -134,7 +134,7 @@ public class DateMathParser  {
 
     // NOTE: consciously choosing not to support WEEK at this time,
     // because of complexity in rounding down to the nearest week
-    // arround a month/year boundry.
+    // around a month/year boundary.
     // (Not to mention: it's not clear what people would *expect*)
     // 
     // If we consider adding some time of "week" support, then
diff --git a/solr/core/src/java/org/apache/solr/util/PivotListEntry.java b/solr/core/src/java/org/apache/solr/util/PivotListEntry.java
index 9f580c0..f81e039 100644
--- a/solr/core/src/java/org/apache/solr/util/PivotListEntry.java
+++ b/solr/core/src/java/org/apache/solr/util/PivotListEntry.java
@@ -80,7 +80,7 @@ public enum PivotListEntry {
       assert this.minIndex < pivotList.size();
       return pivotList.getVal(this.minIndex);
     }
-    // otherweise...
+    // otherwise...
     // scan starting at the min/optional index
     return pivotList.get(this.getName(), this.minIndex);
   }
diff --git a/solr/core/src/java/org/apache/solr/util/VersionedFile.java b/solr/core/src/java/org/apache/solr/util/VersionedFile.java
index 45aaef9..739858a 100644
--- a/solr/core/src/java/org/apache/solr/util/VersionedFile.java
+++ b/solr/core/src/java/org/apache/solr/util/VersionedFile.java
@@ -81,7 +81,7 @@ public class VersionedFile
       is = new FileInputStream(f);
     }
 
-    // delete old files only after we have successfuly opened the newest
+    // delete old files only after we have successfully opened the newest
     if (oldFiles != null) {
       delete(oldFiles);
     }
@@ -99,7 +99,7 @@ public class VersionedFile
           try {
             Files.deleteIfExists(df.toPath());
           } catch (IOException cause) {
-            // TODO: should this class care if a file couldnt be deleted?
+            // TODO: should this class care if a file couldn't be deleted?
             // this just emulates previous behavior, where only SecurityException would be handled.
           }
           // deleteList.remove(df);
diff --git a/solr/core/src/test/org/apache/solr/cloud/DistribCursorPagingTest.java b/solr/core/src/test/org/apache/solr/cloud/DistribCursorPagingTest.java
index f5a3132..d7875d8 100644
--- a/solr/core/src/test/org/apache/solr/cloud/DistribCursorPagingTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/DistribCursorPagingTest.java
@@ -104,7 +104,7 @@ public class DistribCursorPagingTest extends AbstractFullDistribZkTestBase {
   }
 
   private void doBadInputTest() throws Exception {
-    // sometimes seed some data, othertimes use an empty index
+    // sometimes seed some data, other times use an empty index
     if (random().nextBoolean()) {
       indexDoc(sdoc("id", "42", "str", "z", "float", "99.99", "int", "42"));
       indexDoc(sdoc("id", "66", "str", "x", "float", "22.00", "int", "-66"));
@@ -697,15 +697,15 @@ public class DistribCursorPagingTest extends AbstractFullDistribZkTestBase {
    * Given a set of params, executes a cursor query using {@link CursorMarkParams#CURSOR_MARK_START} 
    * and then continuously walks the results using {@link CursorMarkParams#CURSOR_MARK_START} as long 
    * as a non-0 number of docs ar returned.  This method records the the set of all id's
-   * (must be postive ints) encountered and throws an assertion failure if any id is 
+   * (must be positive ints) encountered and throws an assertion failure if any id is 
    * encountered more then once, or if the set grows above maxSize
    * </p>
    *
    * <p>
-   * Note that this method explicily uses the "cloudClient" for executing the queries, 
+   * Note that this method explicitly uses the "cloudClient" for executing the queries, 
    * instead of relying on the test infrastructure to execute the queries redundently
-   * aainst both the cloud client as well as a control client.  This is because term stat 
-   * differences in a sharded setup can result in differnent scores for documents compared 
+   * against both the cloud client as well as a control client.  This is because term stat 
+   * differences in a sharded setup can result in different scores for documents compared 
    * to the control index -- which can affect the sorting in some cases and cause false 
    * negatives in the response comparisons (even if we don't include "score" in the "fl")
    * </p>
diff --git a/solr/core/src/test/org/apache/solr/cloud/DistribDocExpirationUpdateProcessorTest.java b/solr/core/src/test/org/apache/solr/cloud/DistribDocExpirationUpdateProcessorTest.java
index eaf2460..e1d9922 100644
--- a/solr/core/src/test/org/apache/solr/cloud/DistribDocExpirationUpdateProcessorTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/DistribDocExpirationUpdateProcessorTest.java
@@ -125,7 +125,7 @@ public class DistribDocExpirationUpdateProcessorTest extends AbstractFullDistrib
     // TODO: above logic verifies that deleteByQuery happens on all nodes, and ...
     // doesn't affect searcher re-open on shards w/o expired docs ... can we also verify 
     // that *only* one node is sending the deletes ?
-    // (ie: no flood of redundent deletes?)
+    // (ie: no flood of redundant deletes?)
 
   }
 
@@ -168,7 +168,7 @@ public class DistribDocExpirationUpdateProcessorTest extends AbstractFullDistrib
   /**
    * Executes a query over and over against the cloudClient every 5 seconds 
    * until the numFound is 0 or the maxTimeLimitSeconds is exceeded. 
-   * Query is garunteed to be executed at least once.
+   * Query is guaranteed to be executed at least once.
    */
   private void waitForNoResults(int maxTimeLimitSeconds,
                                 SolrParams params)
diff --git a/solr/core/src/test/org/apache/solr/cloud/RemoteQueryErrorTest.java b/solr/core/src/test/org/apache/solr/cloud/RemoteQueryErrorTest.java
index 73d9396..24f9696 100644
--- a/solr/core/src/test/org/apache/solr/cloud/RemoteQueryErrorTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/RemoteQueryErrorTest.java
@@ -60,7 +60,7 @@ public class RemoteQueryErrorTest extends AbstractFullDistribZkTestBase {
       try {
         SolrInputDocument emptyDoc = new SolrInputDocument();
         solrClient.add(emptyDoc);
-        fail("Expected unique key exceptoin");
+        fail("Expected unique key exception");
       } catch (SolrException ex) {
         assertThat(ex.getMessage(), containsString("Document is missing mandatory uniqueKey field: id"));
       } catch(Exception ex) {
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestCloudPivotFacet.java b/solr/core/src/test/org/apache/solr/cloud/TestCloudPivotFacet.java
index dc7e0b0..a29e357 100644
--- a/solr/core/src/test/org/apache/solr/cloud/TestCloudPivotFacet.java
+++ b/solr/core/src/test/org/apache/solr/cloud/TestCloudPivotFacet.java
@@ -516,7 +516,7 @@ public class TestCloudPivotFacet extends AbstractFullDistribZkTestBase {
     // randomly decide which stat tag to use
 
     // if this is 0, or stats aren't enabled, we'll be asking for a tag that doesn't exist
-    // ...which should be fine (just like excluding a taged fq that doesn't exist)
+    // ...which should be fine (just like excluding a tagged fq that doesn't exist)
     final int statTag = TestUtil.nextInt(random(), -1, 4);
       
     if (0 <= statTag) {
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestMiniSolrCloudClusterSSL.java b/solr/core/src/test/org/apache/solr/cloud/TestMiniSolrCloudClusterSSL.java
index a041348..e069cb8 100644
--- a/solr/core/src/test/org/apache/solr/cloud/TestMiniSolrCloudClusterSSL.java
+++ b/solr/core/src/test/org/apache/solr/cloud/TestMiniSolrCloudClusterSSL.java
@@ -241,7 +241,7 @@ public class TestMiniSolrCloudClusterSSL extends SolrTestCaseJ4 {
       }
       
       // sanity check the HttpClient used under the hood by our the cluster's CloudSolrClient
-      // ensure it has the neccessary protocols/credentials for each jetty server
+      // ensure it has the necessary protocols/credentials for each jetty server
       //
       // NOTE: we're not responsible for closing the cloud client
       final HttpClient cloudClient = cluster.getSolrClient().getLbClient().getHttpClient();
@@ -265,7 +265,7 @@ public class TestMiniSolrCloudClusterSSL extends SolrTestCaseJ4 {
         // verify simple HTTP(S) client can't do HEAD request for URL with wrong protocol
         try (CloseableHttpClient client = getSslAwareClientWithNoClientCerts()) {
           final String wrongUrl = wrongBaseURL + "/admin/cores";
-          // vastly diff exception details betwen plain http vs https, not worried about details here
+          // vastly diff exception details between plain http vs https, not worried about details here
           expectThrows(IOException.class, () -> {
               doHeadRequest(client, wrongUrl);
             });
@@ -335,7 +335,7 @@ public class TestMiniSolrCloudClusterSSL extends SolrTestCaseJ4 {
    */
   public static HttpSolrClient getRandomizedHttpSolrClient(String url) {
     // NOTE: at the moment, SolrTestCaseJ4 already returns "new HttpSolrClient" most of the time,
-    // so this method may seem redundent -- but the point here is to sanity check 2 things:
+    // so this method may seem redundant -- but the point here is to sanity check 2 things:
     // 1) a direct test that "new HttpSolrClient" works given the current JVM/sysprop defaults
     // 2) a sanity check that whatever getHttpSolrClient(String) returns will work regardless of
     //    current test configuration.
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestRandomRequestDistribution.java b/solr/core/src/test/org/apache/solr/cloud/TestRandomRequestDistribution.java
index 264d429..1c1c5c1 100644
--- a/solr/core/src/test/org/apache/solr/cloud/TestRandomRequestDistribution.java
+++ b/solr/core/src/test/org/apache/solr/cloud/TestRandomRequestDistribution.java
@@ -194,7 +194,7 @@ public class TestRandomRequestDistribution extends AbstractFullDistribZkTestBase
       // To make sure that's true we keep querying the down replica
       // If queries are getting processed by the down replica then the cluster state hasn't updated for that replica
       // locally
-      // So we keep trying till it has updated and then verify if ALL queries go to the active reploca
+      // So we keep trying till it has updated and then verify if ALL queries go to the active replica
       long count = 0;
       while (true) {
         count++;
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestStressLiveNodes.java b/solr/core/src/test/org/apache/solr/cloud/TestStressLiveNodes.java
index 3bf6b70..80b717e 100644
--- a/solr/core/src/test/org/apache/solr/cloud/TestStressLiveNodes.java
+++ b/solr/core/src/test/org/apache/solr/cloud/TestStressLiveNodes.java
@@ -150,17 +150,17 @@ public class TestStressLiveNodes extends SolrCloudTestCase {
                    actualLiveNodes, cachedLiveNodes);
       
       
-      // start spining up some threads to add some live_node children in parallel
+      // start spinning up some threads to add some live_node children in parallel
 
       // we don't need a lot of threads or nodes (we don't want to swamp the CPUs
-      // just bursts of conccurent adds) but we do want to randomize it a bit so we increase the
+      // just bursts of concurrent adds) but we do want to randomize it a bit so we increase the
       // odds of concurrent watchers firing regardless of the num CPUs or load on the machine running
       // the test (but we deliberately don't look at availableProcessors() since we want randomization
       // consistency across all machines for a given seed)
       final int numThreads = TestUtil.nextInt(random(), 2, 5);
       
       // use same num for all thrashers, to increase likely hood of them all competing
-      // (diff random number would mean heavy concurency only for ~ the first N=lowest num requetss)
+      // (diff random number would mean heavy concurrency only for ~ the first N=lowest num requests)
       //
       // this does not need to be a large number -- in fact, the higher it is, the more
       // likely we are to see a mistake in early watcher triggers get "corrected" by a later one
@@ -221,7 +221,7 @@ public class TestStressLiveNodes extends SolrCloudTestCase {
     private boolean running = false;;
     private int numAdded = 0;
     
-    /** ID should ideally be unique amonst any other instances */
+    /** ID should ideally be unique amongst any other instances */
     public LiveNodeTrasher(String id, int numNodesToAdd) {
       this.id = id;
       this.numNodesToAdd = numNodesToAdd;
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestTolerantUpdateProcessorCloud.java b/solr/core/src/test/org/apache/solr/cloud/TestTolerantUpdateProcessorCloud.java
index ca15a69..b599244 100644
--- a/solr/core/src/test/org/apache/solr/cloud/TestTolerantUpdateProcessorCloud.java
+++ b/solr/core/src/test/org/apache/solr/cloud/TestTolerantUpdateProcessorCloud.java
@@ -263,17 +263,17 @@ public class TestTolerantUpdateProcessorCloud extends SolrCloudTestCase {
         assertEquals("not the expected DBQ failure: " + e.getMessage(), 400, e.code());
       }
       
-      // verify oportunistic concurrency deletions fail as we expect when docs are / aren't present
+      // verify opportunistic concurrency deletions fail as we expect when docs are / aren't present
       for (UpdateRequest r : new UpdateRequest[] {
           update(params("commit", "true")).deleteById(S_ONE_PRE + "1", -1L),
           update(params("commit", "true")).deleteById(S_TWO_PRE + "2", -1L),
           update(params("commit", "true")).deleteById("id_not_exists",  1L)    }) {
         try {
           UpdateResponse rsp = r.process(c);
-          fail("sanity check for oportunistic concurrency delete didn't fail: "
+          fail("sanity check for opportunistic concurrency delete didn't fail: "
                + r.toString() + " => " + rsp.toString());
         } catch (SolrException e) {
-          assertEquals("not the expected oportunistic concurrency failure code: "
+          assertEquals("not the expected opportunistic concurrency failure code: "
                        + r.toString() + " => " + e.getMessage(), 409, e.code());
         }
       }
@@ -316,29 +316,29 @@ public class TestTolerantUpdateProcessorCloud extends SolrCloudTestCase {
                  doc(f("id", docId2), f("foo_i", "1976"))).process(client);
     assertEquals(0, rsp.getStatus());
 
-    // attempt to delete individual doc id(s) that should fail because of oportunistic concurrency constraints
+    // attempt to delete individual doc id(s) that should fail because of opportunistic concurrency constraints
     for (String id : new String[] { docId1, docId2 }) {
       rsp = update(params("update.chain", "tolerant-chain-max-errors-10",
                           "commit", "true")).deleteById(id, -1L).process(client);
       assertEquals(0, rsp.getStatus());
-      assertUpdateTolerantErrors("failed oportunistic concurrent delId="+id, rsp,
+      assertUpdateTolerantErrors("failed opportunistic concurrent delId="+id, rsp,
                                  delIErr(id));
     }
     
-    // multiple failed deletes from the same shard (via oportunistic concurrent w/ bogus ids)
+    // multiple failed deletes from the same shard (via opportunistic concurrent w/ bogus ids)
     rsp = update(params("update.chain", "tolerant-chain-max-errors-10",
                         "commit", "true")
                  ).deleteById(S_ONE_PRE + "X", +1L).deleteById(S_ONE_PRE + "Y", +1L).process(client);
     assertEquals(0, rsp.getStatus());
-    assertUpdateTolerantErrors("failed oportunistic concurrent delete by id for 2 bogus docs", rsp,
+    assertUpdateTolerantErrors("failed opportunistic concurrent delete by id for 2 bogus docs", rsp,
                                delIErr(S_ONE_PRE + "X"), delIErr(S_ONE_PRE + "Y"));
     assertQueryDocIds(client, true, docId1, docId2);
     
-    // multiple failed deletes from the diff shards due to oportunistic concurrency constraints
+    // multiple failed deletes from the diff shards due to opportunistic concurrency constraints
     rsp = update(params("update.chain", "tolerant-chain-max-errors-10",
                         "commit", "true")).deleteById(docId2, -1L).deleteById(docId1, -1L).process(client);
     assertEquals(0, rsp.getStatus());
-    assertUpdateTolerantErrors("failed oportunistic concurrent delete by id for 2 docs", rsp,
+    assertUpdateTolerantErrors("failed opportunistic concurrent delete by id for 2 docs", rsp,
                                delIErr(docId1), delIErr(docId2));
     assertQueryDocIds(client, true, docId1, docId2);
 
@@ -346,7 +346,7 @@ public class TestTolerantUpdateProcessorCloud extends SolrCloudTestCase {
     rsp = update(params("update.chain", "tolerant-chain-max-errors-10",
                         "commit", "true")).deleteByQuery("bogus_field:foo").process(client);
     assertEquals(0, rsp.getStatus());
-    assertUpdateTolerantErrors("failed oportunistic concurrent delete by query", rsp,
+    assertUpdateTolerantErrors("failed opportunistic concurrent delete by query", rsp,
                                delQErr("bogus_field:foo"));
     assertQueryDocIds(client, true, docId1, docId2);
 
@@ -355,7 +355,7 @@ public class TestTolerantUpdateProcessorCloud extends SolrCloudTestCase {
                         "commit", "true")
                  ).deleteByQuery("bogus_field:foo").deleteByQuery("foo_i:23").process(client);
     assertEquals(0, rsp.getStatus());
-    assertUpdateTolerantErrors("failed oportunistic concurrent delete by query", rsp,
+    assertUpdateTolerantErrors("failed opportunistic concurrent delete by query", rsp,
                                delQErr("bogus_field:foo"));
     assertQueryDocIds(client, true, docId1, docId2);
     
@@ -364,7 +364,7 @@ public class TestTolerantUpdateProcessorCloud extends SolrCloudTestCase {
                         "commit", "true")
                  ).deleteById(docId1, -1L).deleteById("bogus", -1L).process(client);
     assertEquals(0, rsp.getStatus());
-    assertUpdateTolerantErrors("failed oportunistic concurrent delete by id: exists", rsp,
+    assertUpdateTolerantErrors("failed opportunistic concurrent delete by id: exists", rsp,
                                delIErr(docId1));
     assertQueryDocIds(client, true, docId1, docId2);
     
@@ -373,7 +373,7 @@ public class TestTolerantUpdateProcessorCloud extends SolrCloudTestCase {
                         "commit", "true")
                  ).deleteById(docId1, +1L).deleteById("bogusId", +1L).process(client);
     assertEquals(0, rsp.getStatus());
-    assertUpdateTolerantErrors("failed oportunistic concurrent delete by id: bogus", rsp,
+    assertUpdateTolerantErrors("failed opportunistic concurrent delete by id: bogus", rsp,
                                delIErr("bogusId"));
     assertQueryDocIds(client, false, docId1);
     assertQueryDocIds(client, true, docId2);
@@ -384,7 +384,7 @@ public class TestTolerantUpdateProcessorCloud extends SolrCloudTestCase {
                         "commit", "true")
                  ).deleteByQuery("bogus_field:foo").deleteByQuery("foo_i:1976").process(client);
     assertEquals(0, rsp.getStatus());
-    assertUpdateTolerantErrors("failed oportunistic concurrent delete by query", rsp,
+    assertUpdateTolerantErrors("failed opportunistic concurrent delete by query", rsp,
                                delQErr("bogus_field:foo"));
     assertQueryDocIds(client, false, docId2);
 
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestTolerantUpdateProcessorRandomCloud.java b/solr/core/src/test/org/apache/solr/cloud/TestTolerantUpdateProcessorRandomCloud.java
index 81d8881..89f8aeb 100644
--- a/solr/core/src/test/org/apache/solr/cloud/TestTolerantUpdateProcessorRandomCloud.java
+++ b/solr/core/src/test/org/apache/solr/cloud/TestTolerantUpdateProcessorRandomCloud.java
@@ -278,10 +278,10 @@ public class TestTolerantUpdateProcessorRandomCloud extends SolrCloudTestCase {
         Thread.sleep(200);
       }
 
-      // check the index contents against our expecationts
+      // check the index contents against our expectations
       final BitSet actualDocIds = allDocs(CLOUD_CLIENT, maxDocId);
       if ( expectedDocIds.cardinality() != actualDocIds.cardinality() ) {
-        log.error("cardinality missmatch: expected {} BUT actual {}",
+        log.error("cardinality mismatch: expected {} BUT actual {}",
                   expectedDocIds.cardinality(),
                   actualDocIds.cardinality());
       }
@@ -325,7 +325,7 @@ public class TestTolerantUpdateProcessorRandomCloud extends SolrCloudTestCase {
     
     assertEquals("wrong nextBit at end of all iters", -1,
                  randomUnsetBit(random(), bits, max));
-    assertEquals("wrong nextBit at redundent end of all iters", -1,
+    assertEquals("wrong nextBit at redundant end of all iters", -1,
                  randomUnsetBit(random(), bits, max));
   }
   
diff --git a/solr/core/src/test/org/apache/solr/cloud/overseer/ZkStateWriterTest.java b/solr/core/src/test/org/apache/solr/cloud/overseer/ZkStateWriterTest.java
index f5648bf..deca8b0 100644
--- a/solr/core/src/test/org/apache/solr/cloud/overseer/ZkStateWriterTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/overseer/ZkStateWriterTest.java
@@ -260,14 +260,14 @@ public class ZkStateWriterTest extends SolrTestCaseJ4 {
 
       try {
         writer.enqueueUpdate(reader.getClusterState(), c2, null);
-        fail("enqueueUpdate after BadVersionException should not have suceeded");
+        fail("enqueueUpdate after BadVersionException should not have succeeded");
       } catch (IllegalStateException e) {
         // expected
       }
 
       try {
         writer.writePendingUpdates();
-        fail("writePendingUpdates after BadVersionException should not have suceeded");
+        fail("writePendingUpdates after BadVersionException should not have succeeded");
       } catch (IllegalStateException e) {
         // expected
       }
@@ -344,14 +344,14 @@ public class ZkStateWriterTest extends SolrTestCaseJ4 {
 
       try {
         writer.enqueueUpdate(reader.getClusterState(), c2, null);
-        fail("enqueueUpdate after BadVersionException should not have suceeded");
+        fail("enqueueUpdate after BadVersionException should not have succeeded");
       } catch (IllegalStateException e) {
         // expected
       }
 
       try {
         writer.writePendingUpdates();
-        fail("writePendingUpdates after BadVersionException should not have suceeded");
+        fail("writePendingUpdates after BadVersionException should not have succeeded");
       } catch (IllegalStateException e) {
         // expected
       }
diff --git a/solr/core/src/test/org/apache/solr/core/CountUsageValueSourceParser.java b/solr/core/src/test/org/apache/solr/core/CountUsageValueSourceParser.java
index c7c1a50..e638039 100644
--- a/solr/core/src/test/org/apache/solr/core/CountUsageValueSourceParser.java
+++ b/solr/core/src/test/org/apache/solr/core/CountUsageValueSourceParser.java
@@ -32,7 +32,7 @@ import java.util.concurrent.atomic.AtomicInteger;
 
 /**
  * A Mock ValueSource parser that produces ValueSources that returns a constant 
- * value butalso keeps track of how many times it was asked for a value for any 
+ * value but also keeps track of how many times it was asked for a value for any 
  * document via a static map and a user defined key.
  **/
 public class CountUsageValueSourceParser extends ValueSourceParser {
diff --git a/solr/core/src/test/org/apache/solr/core/ExitableDirectoryReaderTest.java b/solr/core/src/test/org/apache/solr/core/ExitableDirectoryReaderTest.java
index 5223c9f..5f0d537 100644
--- a/solr/core/src/test/org/apache/solr/core/ExitableDirectoryReaderTest.java
+++ b/solr/core/src/test/org/apache/solr/core/ExitableDirectoryReaderTest.java
@@ -82,7 +82,7 @@ public class ExitableDirectoryReaderTest extends SolrTestCaseJ4 {
 
   // There are lots of assumptions about how/when cache entries should be changed in this method. The
   // simple case above shows the root problem without the confusion. testFilterSimpleCase should be
-  // removed once it is running and this test should be un-ignored and the assumptiions verified.
+  // removed once it is running and this test should be un-ignored and the assumptions verified.
   // With all the weirdness, I'm not going to vouch for this test. Feel free to change it.
   @Test
   public void testCacheAssumptions() throws Exception {
diff --git a/solr/core/src/test/org/apache/solr/core/QueryResultKeyTest.java b/solr/core/src/test/org/apache/solr/core/QueryResultKeyTest.java
index f89e1b1..ef4facf 100644
--- a/solr/core/src/test/org/apache/solr/core/QueryResultKeyTest.java
+++ b/solr/core/src/test/org/apache/solr/core/QueryResultKeyTest.java
@@ -159,9 +159,9 @@ public class QueryResultKeyTest extends SolrTestCaseJ4 {
   /**
    * returns a "small" list of "small" random numbers.  The idea behind this method is 
    * that multiple calls have a decent change of returning two arrays which are the 
-   * same size and contain the same numbers but in a differnet order.
+   * same size and contain the same numbers but in a differed order.
    *
-   * the array is garunteed to always have at least 1 element
+   * the array is guaranteed to always have at least 1 element
    */
   private int[] smallArrayOfRandomNumbers() {
     int size = TestUtil.nextInt(random(), 1, 5);
diff --git a/solr/core/src/test/org/apache/solr/core/TestLazyCores.java b/solr/core/src/test/org/apache/solr/core/TestLazyCores.java
index 8ee4ec5..c239b44 100644
--- a/solr/core/src/test/org/apache/solr/core/TestLazyCores.java
+++ b/solr/core/src/test/org/apache/solr/core/TestLazyCores.java
@@ -425,7 +425,7 @@ public class TestLazyCores extends SolrTestCaseJ4 {
       };
       
       // with SOLR-6279 UNLOAD will wait for the core's reference count to have reached zero
-      // hence cN.close() need to preceed or run in parallel with unloadViaAdmin(...)
+      // hence cN.close() need to proceed or run in parallel with unloadViaAdmin(...)
       final TestThread cThread = new TestThread();
       cThread.start();
       
diff --git a/solr/core/src/test/org/apache/solr/core/TestMergePolicyConfig.java b/solr/core/src/test/org/apache/solr/core/TestMergePolicyConfig.java
index ffc5211..fd13a8e 100644
--- a/solr/core/src/test/org/apache/solr/core/TestMergePolicyConfig.java
+++ b/solr/core/src/test/org/apache/solr/core/TestMergePolicyConfig.java
@@ -114,7 +114,7 @@ public class TestMergePolicyConfig extends SolrTestCaseJ4 {
     
     assertCommitSomeNewDocs();
     // even though we have a single segment (which is 100% of the size of 
-    // the index which is higher then our 0.6D threashold) the
+    // the index which is higher then our 0.6D threshold) the
     // compound ratio doesn't matter because the segment was never merged
     assertCompoundSegments(h.getCore(), expectCFS);
 
diff --git a/solr/core/src/test/org/apache/solr/handler/component/DistributedFacetPivotLargeTest.java b/solr/core/src/test/org/apache/solr/handler/component/DistributedFacetPivotLargeTest.java
index 0fa4e8c..0c5e128 100644
--- a/solr/core/src/test/org/apache/solr/handler/component/DistributedFacetPivotLargeTest.java
+++ b/solr/core/src/test/org/apache/solr/handler/component/DistributedFacetPivotLargeTest.java
@@ -180,7 +180,7 @@ public class DistributedFacetPivotLargeTest extends BaseDistributedSearchTestCas
     //   ... but there's no refinement since mincount==0
     // - would it even matter
     //
-    // should we remove the refinement short circut?
+    // should we remove the refinement short circuit?
     //
     // rsp = query( params( "q", "*:*",
     //                      "rows", "0",
diff --git a/solr/core/src/test/org/apache/solr/response/TestCustomDocTransformer.java b/solr/core/src/test/org/apache/solr/response/TestCustomDocTransformer.java
index 212ab10..5e1b13f 100644
--- a/solr/core/src/test/org/apache/solr/response/TestCustomDocTransformer.java
+++ b/solr/core/src/test/org/apache/solr/response/TestCustomDocTransformer.java
@@ -61,7 +61,7 @@ public class TestCustomDocTransformer extends SolrTestCaseJ4 {
     assertQ( req(
         "q", "*:*", 
         "fl", "id,out:[custom extra=subject,title]"), 
-        // Check that the concatinated fields make it in the results
+        // Check that the concatenated fields make it in the results
         "//*[@numFound='" + max + "']",
         "//str[.='xx#title_0#']",
         "//str[.='xx#title_1#']",
@@ -102,7 +102,7 @@ public class TestCustomDocTransformer extends SolrTestCaseJ4 {
     }
 
     /**
-     * This transformer simply concatinates the values of multipe fields
+     * This transformer simply concatenates the values of multiple fields
      */
     @Override
     public void transform(SolrDocument doc, int docid, float score) throws IOException {
diff --git a/solr/core/src/test/org/apache/solr/response/TestRawResponseWriter.java b/solr/core/src/test/org/apache/solr/response/TestRawResponseWriter.java
index 89a96bf..bf1d8f6 100644
--- a/solr/core/src/test/org/apache/solr/response/TestRawResponseWriter.java
+++ b/solr/core/src/test/org/apache/solr/response/TestRawResponseWriter.java
@@ -171,7 +171,7 @@ public class TestRawResponseWriter extends SolrTestCaseJ4 {
     writerBinBase.write(bytes, req(), rsp);
     BinaryResponseParser parser = new BinaryResponseParser();
     NamedList<Object> out = parser.processResponse
-      (new ByteArrayInputStream(bytes.toByteArray()), /* encoding irelevent */ null);
+      (new ByteArrayInputStream(bytes.toByteArray()), /* encoding irrelevant */ null);
     assertEquals(RawResponseWriter.CONTENT, out.getName(0));
     assertEquals("test", out.getVal(0));
     assertEquals("foo", out.getName(1));
@@ -180,8 +180,8 @@ public class TestRawResponseWriter extends SolrTestCaseJ4 {
   }
 
   /**
-   * Generates a new {@link RawResponseWriter} wraping the specified baseWriter name 
-   * (which much either be an implicitly definied response writer, or one explicitly 
+   * Generates a new {@link RawResponseWriter} wrapping the specified baseWriter name 
+   * (which much either be an implicitly defined response writer, or one explicitly 
    * configured in solrconfig.xml)
    *
    * @param baseWriter null or the name of a valid base writer
diff --git a/solr/core/src/test/org/apache/solr/schema/AbstractCurrencyFieldTest.java b/solr/core/src/test/org/apache/solr/schema/AbstractCurrencyFieldTest.java
index c0907af..e633a13 100644
--- a/solr/core/src/test/org/apache/solr/schema/AbstractCurrencyFieldTest.java
+++ b/solr/core/src/test/org/apache/solr/schema/AbstractCurrencyFieldTest.java
@@ -309,7 +309,7 @@ public abstract class AbstractCurrencyFieldTest extends SolrTestCaseJ4 {
 
     assertU(commit());
 
-    // direct value source usage, gets "raw" form od default curency
+    // direct value source usage, gets "raw" form od default currency
     // default==USD, so raw==penies
     assertQ(req("fl", "id,func:field($f)",
                 "f", field(),
diff --git a/solr/core/src/test/org/apache/solr/schema/DocValuesTest.java b/solr/core/src/test/org/apache/solr/schema/DocValuesTest.java
index 6411a83..b4248da 100644
--- a/solr/core/src/test/org/apache/solr/schema/DocValuesTest.java
+++ b/solr/core/src/test/org/apache/solr/schema/DocValuesTest.java
@@ -105,7 +105,7 @@ public class DocValuesTest extends SolrTestCaseJ4 {
         assertEquals(4L, values.longVal(0));
         assertEquals(4L, values.objectVal(0));
 
-        // check reversability of created fields
+        // check reversibility of created fields
         tstToObj(schema.getField("floatdv"), -1.5f);
         tstToObj(schema.getField("floatdvs"), -1.5f);
         tstToObj(schema.getField("doubledv"), -1.5d);
diff --git a/solr/core/src/test/org/apache/solr/schema/MyCrazyCustomField.java b/solr/core/src/test/org/apache/solr/schema/MyCrazyCustomField.java
index d7b39a1..82f8f6c 100644
--- a/solr/core/src/test/org/apache/solr/schema/MyCrazyCustomField.java
+++ b/solr/core/src/test/org/apache/solr/schema/MyCrazyCustomField.java
@@ -29,7 +29,7 @@ import org.apache.solr.search.QParser;
 /**
  * Custom field that overrides the PrefixQuery behaviour to map queries such that:
  * (foo* becomes bar*) and (bar* becomes foo*).
- * This is used for testing overridded prefix query for custom fields in TestOverriddenPrefixQueryForCustomFieldType
+ * This is used for testing overridden prefix query for custom fields in TestOverriddenPrefixQueryForCustomFieldType
  */
 public class MyCrazyCustomField extends TextField {
 
diff --git a/solr/core/src/test/org/apache/solr/schema/TrieIntPrefixActsAsRangeQueryFieldType.java b/solr/core/src/test/org/apache/solr/schema/TrieIntPrefixActsAsRangeQueryFieldType.java
index 6628097..a58c268 100644
--- a/solr/core/src/test/org/apache/solr/schema/TrieIntPrefixActsAsRangeQueryFieldType.java
+++ b/solr/core/src/test/org/apache/solr/schema/TrieIntPrefixActsAsRangeQueryFieldType.java
@@ -21,7 +21,7 @@ import org.apache.solr.search.QParser;
 
 /**
  * Custom field type that overrides the prefix query behavior to map "X*" to [X TO Integer.MAX_VALUE].
- * * This is used for testing overridded prefix query for custom fields in TestOverriddenPrefixQueryForCustomFieldType
+ * * This is used for testing overridden prefix query for custom fields in TestOverriddenPrefixQueryForCustomFieldType
  */
 public class TrieIntPrefixActsAsRangeQueryFieldType extends TrieIntField {
 
diff --git a/solr/core/src/test/org/apache/solr/search/TestMissingGroups.java b/solr/core/src/test/org/apache/solr/search/TestMissingGroups.java
index caecb47..808c21c 100644
--- a/solr/core/src/test/org/apache/solr/search/TestMissingGroups.java
+++ b/solr/core/src/test/org/apache/solr/search/TestMissingGroups.java
@@ -85,7 +85,7 @@ public class TestMissingGroups extends SolrTestCaseJ4 {
         assertU(commit()); // mess with the segment counts
       }
     }
-    // doc#0: at least one doc that is garunteed not special and has no chance of being filtered
+    // doc#0: at least one doc that is guaranteed not special and has no chance of being filtered
     assertU(adoc(sdoc("id","0")));
     assertU(commit());
 
diff --git a/solr/core/src/test/org/apache/solr/search/TestRandomCollapseQParserPlugin.java b/solr/core/src/test/org/apache/solr/search/TestRandomCollapseQParserPlugin.java
index 2ba79e0..0edbaaa 100644
--- a/solr/core/src/test/org/apache/solr/search/TestRandomCollapseQParserPlugin.java
+++ b/solr/core/src/test/org/apache/solr/search/TestRandomCollapseQParserPlugin.java
@@ -178,11 +178,11 @@ public class TestRandomCollapseQParserPlugin extends SolrTestCaseJ4 {
                           NULL_IGNORE.equals(nullPolicy));
             }
             
-            // work arround for SOLR-8082...
+            // workaround for SOLR-8082...
             //
             // what's important is that we already did the collapsing on the *real* collapseField
             // to verify the groupHead returned is really the best our verification filter
-            // on docs with that value in a differnet ifeld containing the exact same values
+            // on docs with that value in a different field containing the exact same values
             final String checkField = collapseField.replace("float_dv", "float");
             
             final String checkFQ = ((null == collapseVal)
diff --git a/solr/core/src/test/org/apache/solr/search/TestRecovery.java b/solr/core/src/test/org/apache/solr/search/TestRecovery.java
index 6439498..12d3ec3 100644
--- a/solr/core/src/test/org/apache/solr/search/TestRecovery.java
+++ b/solr/core/src/test/org/apache/solr/search/TestRecovery.java
@@ -580,7 +580,7 @@ public class TestRecovery extends SolrTestCaseJ4 {
     version = addAndGetVersion(sdoc("id","reload1", "_version_", Long.toString(version)), null);
 
     // a deleteByQuery currently forces open a new realtime reader via the update log.
-    // This also tests that the update log was informed of the new udpate handler.
+    // This also tests that the update log was informed of the new update handler.
 
     deleteByQueryAndGetVersion("foo_t:hownowbrowncow", null);
 
diff --git a/solr/core/src/test/org/apache/solr/search/TestReloadDeadlock.java b/solr/core/src/test/org/apache/solr/search/TestReloadDeadlock.java
index b79caa6..ee17137 100644
--- a/solr/core/src/test/org/apache/solr/search/TestReloadDeadlock.java
+++ b/solr/core/src/test/org/apache/solr/search/TestReloadDeadlock.java
@@ -187,10 +187,10 @@ public class TestReloadDeadlock extends TestRTGBase {
         thread.join(10000); // Normally they'll all return immediately (or close to that).
       }
     } catch (InterruptedException ie) {
-      fail("Sholdn't have sat around here this long waiting for the threads to join.");
+      fail("Shouldn't have sat around here this long waiting for the threads to join.");
     }
     for (Thread thread : threads) { // Probably a silly test, but what the heck.
-      assertFalse("All threads shoul be dead, but at least thread " + thread.getName() + " is not", thread.isAlive());
+      assertFalse("All threads should be dead, but at least thread " + thread.getName() + " is not", thread.isAlive());
     }
   }
 
diff --git a/solr/core/src/test/org/apache/solr/search/TestSearcherReuse.java b/solr/core/src/test/org/apache/solr/search/TestSearcherReuse.java
index c11153b..1dfe1d7 100644
--- a/solr/core/src/test/org/apache/solr/search/TestSearcherReuse.java
+++ b/solr/core/src/test/org/apache/solr/search/TestSearcherReuse.java
@@ -127,7 +127,7 @@ public class TestSearcherReuse extends SolrTestCaseJ4 {
       baseReq.close();
     }
 
-    // now do a variety of things that *should* always garuntee a new searcher
+    // now do a variety of things that *should* always guarantee a new searcher
     SolrQueryRequest beforeReq;
 
     beforeReq = req("q","foo");
diff --git a/solr/core/src/test/org/apache/solr/search/TestSolr4Spatial2.java b/solr/core/src/test/org/apache/solr/search/TestSolr4Spatial2.java
index c97f7a6..7a7dc6b 100644
--- a/solr/core/src/test/org/apache/solr/search/TestSolr4Spatial2.java
+++ b/solr/core/src/test/org/apache/solr/search/TestSolr4Spatial2.java
@@ -25,7 +25,7 @@ import org.junit.Before;
 import org.junit.BeforeClass;
 import org.junit.Test;
 
-//Unlike TestSolr4Spatial, not parameterized / not generic.
+//Unlike TestSolr4Spatial, not parametrized / not generic.
 public class TestSolr4Spatial2 extends SolrTestCaseJ4 {
 
   @BeforeClass
diff --git a/solr/core/src/test/org/apache/solr/search/function/NvlValueSourceParser.java b/solr/core/src/test/org/apache/solr/search/function/NvlValueSourceParser.java
index 9c458e2..17b33db 100644
--- a/solr/core/src/test/org/apache/solr/search/function/NvlValueSourceParser.java
+++ b/solr/core/src/test/org/apache/solr/search/function/NvlValueSourceParser.java
@@ -26,7 +26,7 @@ import org.apache.solr.search.ValueSourceParser;
 
 /**
  * A sample ValueSourceParser for testing. Approximates the oracle NVL function,
- * letting you substitude a value when a "null" is encountered. In this case,
+ * letting you substitute a value when a "null" is encountered. In this case,
  * null is approximated by a float value, since ValueSource always returns a
  * float, even if the field is undefined for a document.
  * 
diff --git a/solr/core/src/test/org/apache/solr/search/function/TestFunctionQuery.java b/solr/core/src/test/org/apache/solr/search/function/TestFunctionQuery.java
index cc9dcce..7582801 100644
--- a/solr/core/src/test/org/apache/solr/search/function/TestFunctionQuery.java
+++ b/solr/core/src/test/org/apache/solr/search/function/TestFunctionQuery.java
@@ -86,7 +86,7 @@ public class TestFunctionQuery extends SolrTestCaseJ4 {
     assertU(commit());
   }
 
-  // replace \0 with the field name and create a parseable string 
+  // replace \0 with the field name and create a parsable string 
   public String func(String field, String template) {
     StringBuilder sb = new StringBuilder("{!func}");
     for (char ch : template.toCharArray()) {
diff --git a/solr/core/src/test/org/apache/solr/search/function/TestOrdValues.java b/solr/core/src/test/org/apache/solr/search/function/TestOrdValues.java
index 4b3ee1a..785ee55 100644
--- a/solr/core/src/test/org/apache/solr/search/function/TestOrdValues.java
+++ b/solr/core/src/test/org/apache/solr/search/function/TestOrdValues.java
@@ -153,11 +153,11 @@ public class TestOrdValues extends LuceneTestCase {
       log("-------- " + i + ". Explain doc " + id);
       log(s.explain(q, sd[i].doc));
       float expectedScore = N_DOCS - i - 1;
-      assertEquals("score of result " + i + " shuould be " + expectedScore + " != " + score, expectedScore, score, TEST_SCORE_TOLERANCE_DELTA);
+      assertEquals("score of result " + i + " should be " + expectedScore + " != " + score, expectedScore, score, TEST_SCORE_TOLERANCE_DELTA);
       String expectedId = inOrder
               ? id2String(N_DOCS - i) // in-order ==> larger  values first
               : id2String(i + 1);     // reverse  ==> smaller values first
-      assertTrue("id of result " + i + " shuould be " + expectedId + " != " + score, expectedId.equals(id));
+      assertTrue("id of result " + i + " should be " + expectedId + " != " + score, expectedId.equals(id));
     }
     r.close();
   }
diff --git a/solr/core/src/test/org/apache/solr/search/similarities/TestDFRSimilarityFactory.java b/solr/core/src/test/org/apache/solr/search/similarities/TestDFRSimilarityFactory.java
index 8665961..2159f1a 100644
--- a/solr/core/src/test/org/apache/solr/search/similarities/TestDFRSimilarityFactory.java
+++ b/solr/core/src/test/org/apache/solr/search/similarities/TestDFRSimilarityFactory.java
@@ -45,7 +45,7 @@ public class TestDFRSimilarityFactory extends BaseSimilarityTestCase {
     assertEquals(NormalizationH2.class, dfr.getNormalization().getClass());
   }
   
-  /** dfr with parameterized normalization */
+  /** dfr with parametrized normalization */
   public void testParameters() throws Exception {
     Similarity sim = getSimilarity("text_params");
     assertEquals(DFRSimilarity.class, sim.getClass());
diff --git a/solr/core/src/test/org/apache/solr/search/similarities/TestIBSimilarityFactory.java b/solr/core/src/test/org/apache/solr/search/similarities/TestIBSimilarityFactory.java
index 8e881cb..06e143d 100644
--- a/solr/core/src/test/org/apache/solr/search/similarities/TestIBSimilarityFactory.java
+++ b/solr/core/src/test/org/apache/solr/search/similarities/TestIBSimilarityFactory.java
@@ -45,7 +45,7 @@ public class TestIBSimilarityFactory extends BaseSimilarityTestCase {
     assertEquals(NormalizationH2.class, ib.getNormalization().getClass());
   }
   
-  /** ll/ttf/h3 with parameterized normalization */
+  /** ll/ttf/h3 with parametrized normalization */
   public void testParameters() throws Exception {
     Similarity sim = getSimilarity("text_params");
     assertEquals(IBSimilarity.class, sim.getClass());
diff --git a/solr/core/src/test/org/apache/solr/search/similarities/TestNonDefinedSimilarityFactory.java b/solr/core/src/test/org/apache/solr/search/similarities/TestNonDefinedSimilarityFactory.java
index 355e776..0dda891 100644
--- a/solr/core/src/test/org/apache/solr/search/similarities/TestNonDefinedSimilarityFactory.java
+++ b/solr/core/src/test/org/apache/solr/search/similarities/TestNonDefinedSimilarityFactory.java
@@ -23,7 +23,7 @@ import org.junit.After;
 
 /**
  * Verifies that the default behavior of the implicit {@link ClassicSimilarityFactory} 
- * (ie: no similarity configured in schema.xml at all) is consistnent with 
+ * (ie: no similarity configured in schema.xml at all) is consistent with 
  * expectations based on the luceneMatchVersion
  * @see <a href="https://issues.apache.org/jira/browse/SOLR-5561">SOLR-5561</a>
  * @see <a href="https://issues.apache.org/jira/browse/SOLR-8057">SOLR-8057</a>
diff --git a/solr/core/src/test/org/apache/solr/update/SoftAutoCommitTest.java b/solr/core/src/test/org/apache/solr/update/SoftAutoCommitTest.java
index 0daf241..4106884 100644
--- a/solr/core/src/test/org/apache/solr/update/SoftAutoCommitTest.java
+++ b/solr/core/src/test/org/apache/solr/update/SoftAutoCommitTest.java
@@ -125,11 +125,11 @@ public class SoftAutoCommitTest extends AbstractSolrTestCase {
     monitor.assertSaneOffers();
 
     final long soft529Ms = TimeUnit.MILLISECONDS.convert(soft529 - add529, TimeUnit.NANOSECONDS);
-    assertTrue("soft529 occured too fast, in " +
+    assertTrue("soft529 occurred too fast, in " +
             soft529Ms + "ms, less than soft commit interval " + softCommitWaitMillis,
         soft529Ms >= softCommitWaitMillis);
     final long hard529Ms = TimeUnit.MILLISECONDS.convert(hard529 - add529, TimeUnit.NANOSECONDS);
-    assertTrue("hard529 occured too fast, in " +
+    assertTrue("hard529 occurred too fast, in " +
             hard529Ms + "ms, less than hard commit interval " + hardCommitWaitMillis,
         hard529Ms >= hardCommitWaitMillis);
 
@@ -180,7 +180,7 @@ public class SoftAutoCommitTest extends AbstractSolrTestCase {
 
     monitor.assertSaneOffers();
 
-    // wait a bit, w/o other action we definitley shouldn't see any 
+    // wait a bit, w/o other action we definitely shouldn't see any 
     // new hard/soft commits 
     assertNull("Got a hard commit we weren't expecting",
                monitor.hard.poll(2, SECONDS));
@@ -256,11 +256,11 @@ public class SoftAutoCommitTest extends AbstractSolrTestCase {
     monitor.assertSaneOffers();
 
     final long soft529Ms = TimeUnit.MILLISECONDS.convert(soft529 - del529, TimeUnit.NANOSECONDS);
-    assertTrue("soft529 occured too fast, in " + soft529Ms +
+    assertTrue("soft529 occurred too fast, in " + soft529Ms +
             "ms, less than soft commit interval " + softCommitWaitMillis,
         soft529Ms >= softCommitWaitMillis);
     final long hard529Ms = TimeUnit.MILLISECONDS.convert(hard529 - del529, TimeUnit.NANOSECONDS);
-    assertTrue("hard529 occured too fast, in " +
+    assertTrue("hard529 occurred too fast, in " +
             hard529Ms + "ms, less than hard commit interval " + hardCommitWaitMillis,
         hard529Ms >= hardCommitWaitMillis);
 
@@ -276,7 +276,7 @@ public class SoftAutoCommitTest extends AbstractSolrTestCase {
                searcher529 + " !<= " + hard529,
                searcher529 <= hard529);
 
-    // clear commmits
+    // clear commits
     monitor.hard.clear();
     monitor.soft.clear();
     
@@ -325,7 +325,7 @@ public class SoftAutoCommitTest extends AbstractSolrTestCase {
       // have to assume none of the docs were added until
       // very end of the add window
       long softMs = TimeUnit.MILLISECONDS.convert(soft - fast5end, TimeUnit.NANOSECONDS);
-      assertTrue(i + ": soft occured too fast: " +
+      assertTrue(i + ": soft occurred too fast: " +
               softMs + " < (" + softCommitWaitMillis + " * " + i + ")",
           softMs >= (softCommitWaitMillis * i));
     }
@@ -341,7 +341,7 @@ public class SoftAutoCommitTest extends AbstractSolrTestCase {
       // have to assume none of the docs were added until
       // very end of the add window
       long hardMs = TimeUnit.MILLISECONDS.convert(hard - fast5end, TimeUnit.NANOSECONDS);
-      assertTrue(i + ": hard occured too fast: " +
+      assertTrue(i + ": hard occurred too fast: " +
               hardMs + " < (" + hardCommitWaitMillis + " * " + i + ")",
           hardMs >= (hardCommitWaitMillis * i));
     }
diff --git a/solr/core/src/test/org/apache/solr/update/TestDocBasedVersionConstraints.java b/solr/core/src/test/org/apache/solr/update/TestDocBasedVersionConstraints.java
index 5c5c703..10a07d9 100644
--- a/solr/core/src/test/org/apache/solr/update/TestDocBasedVersionConstraints.java
+++ b/solr/core/src/test/org/apache/solr/update/TestDocBasedVersionConstraints.java
@@ -46,7 +46,7 @@ public class TestDocBasedVersionConstraints extends SolrTestCaseJ4 {
 
   public void testSimpleUpdates() throws Exception {
 
-    // skip low version against commited data
+    // skip low version against committed data
     assertU(adoc("id", "aaa", "name", "a1", "my_version_l", "1001"));
     assertU(commit());
     assertU(adoc("id", "aaa", "name", "a2", "my_version_l", "1002"));
@@ -61,7 +61,7 @@ public class TestDocBasedVersionConstraints extends SolrTestCaseJ4 {
     assertJQ(req("qt","/get", "id","aaa", "fl","name")
              , "=={'doc':{'name':'a2'}}");
 
-    // skip low version against uncommited data from updateLog
+    // skip low version against uncommitted data from updateLog
     assertU(adoc("id", "aaa", "name", "a3", "my_version_l", "1003"));
     assertU(adoc("id", "aaa", "name", "XX", "my_version_l",    "7"));
     assertJQ(req("qt","/get", "id","aaa", "fl","name")
@@ -97,7 +97,7 @@ public class TestDocBasedVersionConstraints extends SolrTestCaseJ4 {
 
   public void testSimpleDeletes() throws Exception {
 
-    // skip low version delete against commited doc
+    // skip low version delete against committed doc
     assertU(adoc("id", "aaa", "name", "a1", "my_version_l", "1001"));
     assertU(commit());
     assertU(adoc("id", "aaa", "name", "a2", "my_version_l", "1002"));
@@ -112,7 +112,7 @@ public class TestDocBasedVersionConstraints extends SolrTestCaseJ4 {
     assertJQ(req("qt","/get", "id","aaa", "fl","name")
              , "=={'doc':{'name':'a2'}}");
 
-    // skip low version delete against uncommited doc from updateLog
+    // skip low version delete against uncommitted doc from updateLog
     assertU(adoc("id", "aaa", "name", "a3", "my_version_l", "1003"));
     deleteAndGetVersion("aaa",
                         params("del_version", "8"));
@@ -124,7 +124,7 @@ public class TestDocBasedVersionConstraints extends SolrTestCaseJ4 {
     assertJQ(req("qt","/get", "id","aaa", "fl","name")
              , "=={'doc':{'name':'a3'}}");
 
-    // skip low version add against uncommited "delete" from updateLog
+    // skip low version add against uncommitted "delete" from updateLog
     deleteAndGetVersion("aaa", params("del_version", "1010"));
     assertU(adoc("id", "aaa", "name", "XX", "my_version_l", "22"));
     assertJQ(req("qt","/get", "id","aaa", "fl","my_version_l")
@@ -153,7 +153,7 @@ public class TestDocBasedVersionConstraints extends SolrTestCaseJ4 {
    */
   public void testFloatVersionField() throws Exception {
 
-    // skip low version add & low version delete against commited doc
+    // skip low version add & low version delete against committed doc
     updateJ(jsonAdd(sdoc("id", "aaa", "name", "a1", "my_version_f", "10.01")),
             params("update.chain","external-version-float"));
     assertU(commit());
@@ -168,7 +168,7 @@ public class TestDocBasedVersionConstraints extends SolrTestCaseJ4 {
              , "=={'doc':{'name':'a1'}}");
     assertU(commit());
     
-    // skip low version delete against uncommited doc from updateLog
+    // skip low version delete against uncommitted doc from updateLog
     updateJ(jsonAdd(sdoc("id", "aaa", "name", "a2", "my_version_f", "10.02")), 
             params("update.chain","external-version-float"));
     deleteAndGetVersion("aaa", params("del_version", "8", 
@@ -181,7 +181,7 @@ public class TestDocBasedVersionConstraints extends SolrTestCaseJ4 {
     assertJQ(req("qt","/get", "id","aaa", "fl","name")
              , "=={'doc':{'name':'a2'}}");
 
-    // skip low version add against uncommited "delete" from updateLog
+    // skip low version add against uncommitted "delete" from updateLog
     deleteAndGetVersion("aaa", params("del_version", "10.10",
                                       "update.chain","external-version-float"));
     updateJ(jsonAdd(sdoc("id", "aaa", "name", "XX", "my_version_f", "10.05")),
@@ -209,7 +209,7 @@ public class TestDocBasedVersionConstraints extends SolrTestCaseJ4 {
 
   public void testFailOnOldVersion() throws Exception {
 
-    // fail low version add & low version delete against commited doc
+    // fail low version add & low version delete against committed doc
     updateJ(jsonAdd(sdoc("id", "aaa", "name", "a1", "my_version_l", "1001")),
             params("update.chain","external-version-failhard"));
     assertU(commit());
@@ -234,7 +234,7 @@ public class TestDocBasedVersionConstraints extends SolrTestCaseJ4 {
              , "=={'doc':{'name':'a1'}}");
     assertU(commit());
     
-    // fail low version delete against uncommited doc from updateLog
+    // fail low version delete against uncommitted doc from updateLog
     updateJ(jsonAdd(sdoc("id", "aaa", "name", "a2", "my_version_l", "1002")), 
             params("update.chain","external-version-failhard"));
     try {
@@ -252,7 +252,7 @@ public class TestDocBasedVersionConstraints extends SolrTestCaseJ4 {
     assertJQ(req("qt","/get", "id","aaa", "fl","name")
              , "=={'doc':{'name':'a2'}}");
 
-    // fail low version add against uncommited "delete" from updateLog
+    // fail low version add against uncommitted "delete" from updateLog
     deleteAndGetVersion("aaa", params("del_version", "1010",
                                       "update.chain","external-version-failhard"));
     try {
diff --git a/solr/core/src/test/org/apache/solr/update/processor/CloneFieldUpdateProcessorFactoryTest.java b/solr/core/src/test/org/apache/solr/update/processor/CloneFieldUpdateProcessorFactoryTest.java
index 5f9005b..c01c319 100644
--- a/solr/core/src/test/org/apache/solr/update/processor/CloneFieldUpdateProcessorFactoryTest.java
+++ b/solr/core/src/test/org/apache/solr/update/processor/CloneFieldUpdateProcessorFactoryTest.java
@@ -155,7 +155,7 @@ public class CloneFieldUpdateProcessorFactoryTest extends UpdateProcessorTestBas
 
     SolrInputDocument d;
 
-    // regardless of chain, all of these checks should be equivilent
+    // regardless of chain, all of these checks should be equivalent
     for (String chain : Arrays.asList("clone-single", "clone-single-regex",
                                       "clone-multi", "clone-multi-regex",
                                       "clone-array", "clone-array-regex", 
@@ -191,7 +191,7 @@ public class CloneFieldUpdateProcessorFactoryTest extends UpdateProcessorTestBas
                    2.3f, d.getField("dest_s").getBoost(), 0.0f);
     }
 
-    // should be equivilent for any chain matching source1_s and source2_s (but not source0_s)
+    // should be equivalent for any chain matching source1_s and source2_s (but not source0_s)
     for (String chain : Arrays.asList("clone-multi", "clone-multi-regex",
                                       "clone-array", "clone-array-regex", 
                                       "clone-selector", "clone-selector-regex")) {
@@ -236,7 +236,7 @@ public class CloneFieldUpdateProcessorFactoryTest extends UpdateProcessorTestBas
                    2.3f, d.getField("dest_s").getBoost(), 0.0f);
     }
     
-    // any chain that copies source1_s to dest_s should be equivilent for these assertions
+    // any chain that copies source1_s to dest_s should be equivalent for these assertions
     for (String chain : Arrays.asList("clone-simple-regex-syntax",
                                       "clone-single", "clone-single-regex",
                                       "clone-multi", "clone-multi-regex",
diff --git a/solr/core/src/test/org/apache/solr/update/processor/RecordingUpdateProcessorFactory.java b/solr/core/src/test/org/apache/solr/update/processor/RecordingUpdateProcessorFactory.java
index ea44046..48d0596 100644
--- a/solr/core/src/test/org/apache/solr/update/processor/RecordingUpdateProcessorFactory.java
+++ b/solr/core/src/test/org/apache/solr/update/processor/RecordingUpdateProcessorFactory.java
@@ -34,8 +34,8 @@ import java.util.concurrent.BlockingQueue;
 import java.util.concurrent.LinkedBlockingQueue;
 
 /**
- * This Factory can optionally save refrences to the commands it receives in 
- * BlockingQueues that tests can poll from to observe that the exepected commands 
+ * This Factory can optionally save references to the commands it receives in 
+ * BlockingQueues that tests can poll from to observe that the expected commands 
  * are executed.  By default, this factory does nothing except return the "next" 
  * processor from the chain unless it's told to {@link #startRecording()}
  */
diff --git a/solr/core/src/test/org/apache/solr/update/processor/ScriptEngineTest.java b/solr/core/src/test/org/apache/solr/update/processor/ScriptEngineTest.java
index 538d7cf..6bf20ce 100644
--- a/solr/core/src/test/org/apache/solr/update/processor/ScriptEngineTest.java
+++ b/solr/core/src/test/org/apache/solr/update/processor/ScriptEngineTest.java
@@ -30,7 +30,7 @@ import org.junit.BeforeClass;
 
 /**
  * Sanity tests basic functionality of {@link ScriptEngineManager} and 
- * {@link ScriptEngine} w/o excercising any Lucene specific code.
+ * {@link ScriptEngine} w/o exercising any Lucene specific code.
  */
 public class ScriptEngineTest extends LuceneTestCase {
 
diff --git a/solr/core/src/test/org/apache/solr/update/processor/UpdateRequestProcessorFactoryTest.java b/solr/core/src/test/org/apache/solr/update/processor/UpdateRequestProcessorFactoryTest.java
index 8325cc0..e9dc93f 100644
--- a/solr/core/src/test/org/apache/solr/update/processor/UpdateRequestProcessorFactoryTest.java
+++ b/solr/core/src/test/org/apache/solr/update/processor/UpdateRequestProcessorFactoryTest.java
@@ -77,7 +77,7 @@ public class UpdateRequestProcessorFactoryTest extends AbstractSolrTestCase {
   public void testUpdateDistribChainSkipping() throws Exception {
 
     // a key part of this test is verifying that LogUpdateProcessor is found in all chains because it
-    // is a @RunAllways processor -- but in order for that to work, we have to sanity check that the log
+    // is a @RunAlways processor -- but in order for that to work, we have to sanity check that the log
     // level is at least "INFO" otherwise the factory won't even produce a processor and all our assertions
     // are for nought.  (see LogUpdateProcessorFactory.getInstance)
     //
diff --git a/solr/core/src/test/org/apache/solr/util/DateMathParserTest.java b/solr/core/src/test/org/apache/solr/util/DateMathParserTest.java
index 726c71c..8840d34 100644
--- a/solr/core/src/test/org/apache/solr/util/DateMathParserTest.java
+++ b/solr/core/src/test/org/apache/solr/util/DateMathParserTest.java
@@ -38,11 +38,11 @@ public class DateMathParserTest extends LuceneTestCase {
 
   /**
    * A formatter for specifying every last nuance of a Date for easy
-   * refernece in assertion statements
+   * reference in assertion statements
    */
   private DateFormat fmt;
   /**
-   * A parser for reading in explicit dates that are convinient to type
+   * A parser for reading in explicit dates that are convenient to type
    * in a test
    */
   private DateFormat parser;

