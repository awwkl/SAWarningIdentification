GitDiffStart: 092545884ef91fc6afb8c39fa89fd9b0ab66b51a | Tue Mar 12 19:04:06 2013 +0000
diff --git a/lucene/CHANGES.txt b/lucene/CHANGES.txt
index ff615c0..4aabcb1 100644
--- a/lucene/CHANGES.txt
+++ b/lucene/CHANGES.txt
@@ -27,11 +27,13 @@ Changes in backwards compatibility policy
   multiple ngrams derived from the same input token. (Walter Underwood
   via Mike McCandless)
 
-
 * LUCENE-4822: KeywordTokenFilter is now an abstract class. Subclasses
   need to implement #isKeyword() in order to mark terms as keywords. 
   The existing functionality has been factored out into a new 
   SetKeywordTokenFilter class. (Simon Willnauer, Uwe Schindler)
+  
+* LUCENE-4642: Remove Tokenizer's and subclasses' ctors taking
+  AttributeSource. (Renaud Delbru, Uwe Schindler, Steve Rowe)
 
 New Features
 
@@ -54,6 +56,10 @@ New Features
   determine whether the last token was finished or not, so that a
   query "i " will no longer suggest "Isla de Muerta" for example.
   (Mike McCandless)
+  
+* LUCENE-4642: Add create(AttributeFactory) to TokenizerFactory and
+  subclasses with ctors taking AttributeFactory. 
+  (Renaud Delbru, Uwe Schindler, Steve Rowe)
 
 Optimizations
 
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/KeywordTokenizer.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/KeywordTokenizer.java
index 40da5d1..14d103e 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/KeywordTokenizer.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/KeywordTokenizer.java
@@ -49,14 +49,6 @@ public final class KeywordTokenizer extends Tokenizer {
     termAtt.resizeBuffer(bufferSize);
   }
 
-  public KeywordTokenizer(AttributeSource source, Reader input, int bufferSize) {
-    super(source, input);
-    if (bufferSize <= 0) {
-      throw new IllegalArgumentException("bufferSize must be > 0");
-    }
-    termAtt.resizeBuffer(bufferSize);
-  }
-
   public KeywordTokenizer(AttributeFactory factory, Reader input, int bufferSize) {
     super(factory, input);
     if (bufferSize <= 0) {
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/KeywordTokenizerFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/KeywordTokenizerFactory.java
index 526025d..42071f3 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/KeywordTokenizerFactory.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/KeywordTokenizerFactory.java
@@ -17,8 +17,8 @@ package org.apache.lucene.analysis.core;
  * limitations under the License.
  */
 
-import org.apache.lucene.analysis.core.KeywordTokenizer;
 import org.apache.lucene.analysis.util.TokenizerFactory;
+import org.apache.lucene.util.AttributeSource.AttributeFactory;
 
 import java.io.Reader;
 
@@ -37,4 +37,9 @@ public class KeywordTokenizerFactory extends TokenizerFactory {
   public KeywordTokenizer create(Reader input) {
     return new KeywordTokenizer(input);
   }
+
+  @Override
+  public KeywordTokenizer create(AttributeFactory factory, Reader input) {
+    return new KeywordTokenizer(factory, input, KeywordTokenizer.DEFAULT_BUFFER_SIZE);
+  }
 }
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/LetterTokenizer.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/LetterTokenizer.java
index 5fcbd48..c0b4319 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/LetterTokenizer.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/LetterTokenizer.java
@@ -59,20 +59,6 @@ public class LetterTokenizer extends CharTokenizer {
   }
   
   /**
-   * Construct a new LetterTokenizer using a given {@link AttributeSource}.
-   * 
-   * @param matchVersion
-   *          Lucene version to match See {@link <a href="#version">above</a>}
-   * @param source
-   *          the attribute source to use for this {@link Tokenizer}
-   * @param in
-   *          the input to split up into tokens
-   */
-  public LetterTokenizer(Version matchVersion, AttributeSource source, Reader in) {
-    super(matchVersion, source, in);
-  }
-  
-  /**
    * Construct a new LetterTokenizer using a given
    * {@link org.apache.lucene.util.AttributeSource.AttributeFactory}.
    * 
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/LetterTokenizerFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/LetterTokenizerFactory.java
index 7a3cb69..1a18f51 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/LetterTokenizerFactory.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/LetterTokenizerFactory.java
@@ -17,8 +17,8 @@ package org.apache.lucene.analysis.core;
  * limitations under the License.
  */
 
-import org.apache.lucene.analysis.core.LetterTokenizer;
 import org.apache.lucene.analysis.util.TokenizerFactory;
+import org.apache.lucene.util.AttributeSource.AttributeFactory;
 
 import java.io.Reader;
 import java.util.Map;
@@ -45,4 +45,9 @@ public class LetterTokenizerFactory extends TokenizerFactory {
   public LetterTokenizer create(Reader input) {
     return new LetterTokenizer(luceneMatchVersion, input);
   }
+
+  @Override
+  public LetterTokenizer create(AttributeFactory factory, Reader input) {
+    return new LetterTokenizer(luceneMatchVersion, factory, input);
+  }
 }
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/LowerCaseTokenizer.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/LowerCaseTokenizer.java
index ce7b0a8..4ba4d37 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/LowerCaseTokenizer.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/LowerCaseTokenizer.java
@@ -60,20 +60,6 @@ public final class LowerCaseTokenizer extends LetterTokenizer {
     super(matchVersion, in);
   }
 
-  /** 
-   * Construct a new LowerCaseTokenizer using a given {@link AttributeSource}.
-   *
-   * @param matchVersion
-   *          Lucene version to match See {@link <a href="#version">above</a>}
-   * @param source
-   *          the attribute source to use for this {@link Tokenizer}
-   * @param in
-   *          the input to split up into tokens
-   */
-  public LowerCaseTokenizer(Version matchVersion, AttributeSource source, Reader in) {
-    super(matchVersion, source, in);
-  }
-
   /**
    * Construct a new LowerCaseTokenizer using a given
    * {@link org.apache.lucene.util.AttributeSource.AttributeFactory}.
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/LowerCaseTokenizerFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/LowerCaseTokenizerFactory.java
index d669c04..2a1ca83 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/LowerCaseTokenizerFactory.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/LowerCaseTokenizerFactory.java
@@ -17,10 +17,10 @@ package org.apache.lucene.analysis.core;
  * limitations under the License.
  */
 
-import org.apache.lucene.analysis.core.LowerCaseTokenizer;
 import org.apache.lucene.analysis.util.AbstractAnalysisFactory;
 import org.apache.lucene.analysis.util.MultiTermAwareComponent;
 import org.apache.lucene.analysis.util.TokenizerFactory;
+import org.apache.lucene.util.AttributeSource.AttributeFactory;
 
 import java.io.Reader;
 import java.util.Map;
@@ -48,6 +48,11 @@ public class LowerCaseTokenizerFactory extends TokenizerFactory implements Multi
   }
 
   @Override
+  public LowerCaseTokenizer create(AttributeFactory factory, Reader input) {
+    return new LowerCaseTokenizer(luceneMatchVersion, factory, input);
+  }
+
+  @Override
   public AbstractAnalysisFactory getMultiTermComponent() {
     LowerCaseFilterFactory filt = new LowerCaseFilterFactory();
     filt.setLuceneMatchVersion(luceneMatchVersion);
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/WhitespaceTokenizer.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/WhitespaceTokenizer.java
index c3e6de5..0603704 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/WhitespaceTokenizer.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/WhitespaceTokenizer.java
@@ -51,20 +51,6 @@ public final class WhitespaceTokenizer extends CharTokenizer {
   }
 
   /**
-   * Construct a new WhitespaceTokenizer using a given {@link AttributeSource}.
-   * 
-   * @param matchVersion
-   *          Lucene version to match See {@link <a href="#version">above</a>}
-   * @param source
-   *          the attribute source to use for this {@link Tokenizer}
-   * @param in
-   *          the input to split up into tokens
-   */
-  public WhitespaceTokenizer(Version matchVersion, AttributeSource source, Reader in) {
-    super(matchVersion, source, in);
-  }
-
-  /**
    * Construct a new WhitespaceTokenizer using a given
    * {@link org.apache.lucene.util.AttributeSource.AttributeFactory}.
    *
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/WhitespaceTokenizerFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/WhitespaceTokenizerFactory.java
index 3372ced..bdd50ee 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/WhitespaceTokenizerFactory.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/WhitespaceTokenizerFactory.java
@@ -17,8 +17,8 @@ package org.apache.lucene.analysis.core;
  * limitations under the License.
  */
 
-import org.apache.lucene.analysis.core.WhitespaceTokenizer;
 import org.apache.lucene.analysis.util.TokenizerFactory;
+import org.apache.lucene.util.AttributeSource.AttributeFactory;
 
 import java.io.Reader;
 import java.util.Map;
@@ -44,4 +44,9 @@ public class WhitespaceTokenizerFactory extends TokenizerFactory {
   public WhitespaceTokenizer create(Reader input) {
     return new WhitespaceTokenizer(luceneMatchVersion,input);
   }
+
+  @Override
+  public WhitespaceTokenizer create(AttributeFactory factory, Reader input) {
+    return new WhitespaceTokenizer(luceneMatchVersion, factory, input);
+  }
 }
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenizer.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenizer.java
index 788c9fd..ba2c56e 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenizer.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenizer.java
@@ -96,20 +96,6 @@ public final class EdgeNGramTokenizer extends Tokenizer {
 
   /**
    * Creates EdgeNGramTokenizer that can generate n-grams in the sizes of the given range
-   *
-   * @param source {@link AttributeSource} to use
-   * @param input {@link Reader} holding the input to be tokenized
-   * @param side the {@link Side} from which to chop off an n-gram
-   * @param minGram the smallest n-gram to generate
-   * @param maxGram the largest n-gram to generate
-   */
-  public EdgeNGramTokenizer(AttributeSource source, Reader input, Side side, int minGram, int maxGram) {
-    super(source, input);
-    init(side, minGram, maxGram);
-  }
-
-  /**
-   * Creates EdgeNGramTokenizer that can generate n-grams in the sizes of the given range
    * 
    * @param factory {@link org.apache.lucene.util.AttributeSource.AttributeFactory} to use
    * @param input {@link Reader} holding the input to be tokenized
@@ -136,19 +122,6 @@ public final class EdgeNGramTokenizer extends Tokenizer {
 
   /**
    * Creates EdgeNGramTokenizer that can generate n-grams in the sizes of the given range
-   *
-   * @param source {@link AttributeSource} to use
-   * @param input {@link Reader} holding the input to be tokenized
-   * @param sideLabel the name of the {@link Side} from which to chop off an n-gram
-   * @param minGram the smallest n-gram to generate
-   * @param maxGram the largest n-gram to generate
-   */
-  public EdgeNGramTokenizer(AttributeSource source, Reader input, String sideLabel, int minGram, int maxGram) {
-    this(source, input, Side.getSide(sideLabel), minGram, maxGram);
-  }
-
-  /**
-   * Creates EdgeNGramTokenizer that can generate n-grams in the sizes of the given range
    * 
    * @param factory {@link org.apache.lucene.util.AttributeSource.AttributeFactory} to use
    * @param input {@link Reader} holding the input to be tokenized
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenizerFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenizerFactory.java
index 67e95af..5f30314 100755
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenizerFactory.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenizerFactory.java
@@ -17,8 +17,8 @@ package org.apache.lucene.analysis.ngram;
  * limitations under the License.
  */
 
-import org.apache.lucene.analysis.ngram.EdgeNGramTokenizer;
 import org.apache.lucene.analysis.util.TokenizerFactory;
+import org.apache.lucene.util.AttributeSource.AttributeFactory;
 
 import java.io.Reader;
 import java.util.Map;
@@ -59,4 +59,9 @@ public class EdgeNGramTokenizerFactory extends TokenizerFactory {
   public EdgeNGramTokenizer create(Reader input) {
     return new EdgeNGramTokenizer(input, side, minGramSize, maxGramSize);
   }
+
+  @Override
+  public EdgeNGramTokenizer create(AttributeFactory factory, Reader input) {
+    return new EdgeNGramTokenizer(factory, input, side, minGramSize, maxGramSize);
+  }
 }
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizer.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizer.java
index d4b21e6..81ce887 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizer.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizer.java
@@ -56,18 +56,6 @@ public final class NGramTokenizer extends Tokenizer {
 
   /**
    * Creates NGramTokenizer with given min and max n-grams.
-   * @param source {@link AttributeSource} to use
-   * @param input {@link Reader} holding the input to be tokenized
-   * @param minGram the smallest n-gram to generate
-   * @param maxGram the largest n-gram to generate
-   */
-  public NGramTokenizer(AttributeSource source, Reader input, int minGram, int maxGram) {
-    super(source, input);
-    init(minGram, maxGram);
-  }
-
-  /**
-   * Creates NGramTokenizer with given min and max n-grams.
    * @param factory {@link org.apache.lucene.util.AttributeSource.AttributeFactory} to use
    * @param input {@link Reader} holding the input to be tokenized
    * @param minGram the smallest n-gram to generate
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizerFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizerFactory.java
index 01c2072..d41d7d6 100755
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizerFactory.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizerFactory.java
@@ -18,8 +18,8 @@ package org.apache.lucene.analysis.ngram;
  */
 
 import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.ngram.NGramTokenizer;
 import org.apache.lucene.analysis.util.TokenizerFactory;
+import org.apache.lucene.util.AttributeSource.AttributeFactory;
 
 import java.io.Reader;
 import java.util.Map;
@@ -54,4 +54,9 @@ public class NGramTokenizerFactory extends TokenizerFactory {
   public NGramTokenizer create(Reader input) {
     return new NGramTokenizer(input, minGramSize, maxGramSize);
   }
+
+  @Override
+  public NGramTokenizer create(AttributeFactory factory, Reader input) {
+    return new NGramTokenizer(factory, input, minGramSize, maxGramSize);
+  }
 }
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/path/PathHierarchyTokenizerFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/path/PathHierarchyTokenizerFactory.java
index 28b7301..91efe8e 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/path/PathHierarchyTokenizerFactory.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/path/PathHierarchyTokenizerFactory.java
@@ -21,8 +21,6 @@ import java.io.Reader;
 import java.util.Map;
 
 import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.path.PathHierarchyTokenizer;
-import org.apache.lucene.analysis.path.ReversePathHierarchyTokenizer;
 import org.apache.lucene.analysis.util.TokenizerFactory;
 
 /**
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternTokenizerFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternTokenizerFactory.java
index 250a46a..a87bca3 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternTokenizerFactory.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternTokenizerFactory.java
@@ -91,7 +91,7 @@ public class PatternTokenizerFactory extends TokenizerFactory
    * Split the input using configured pattern
    */
   @Override
-  public Tokenizer create(final Reader in) {
+  public PatternTokenizer create(final Reader in) {
     try {
       return new PatternTokenizer(in, pattern, group);
     } catch( IOException ex ) {
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizer.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizer.java
index c837ab3..76187dd 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizer.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizer.java
@@ -104,14 +104,6 @@ public final class ClassicTokenizer extends Tokenizer {
   }
 
   /**
-   * Creates a new ClassicTokenizer with a given {@link AttributeSource}. 
-   */
-  public ClassicTokenizer(Version matchVersion, AttributeSource source, Reader input) {
-    super(source, input);
-    init(matchVersion);
-  }
-
-  /**
    * Creates a new ClassicTokenizer with a given {@link org.apache.lucene.util.AttributeSource.AttributeFactory} 
    */
   public ClassicTokenizer(Version matchVersion, AttributeFactory factory, Reader input) {
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizerFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizerFactory.java
index 89f8252..6719f6f 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizerFactory.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizerFactory.java
@@ -17,10 +17,8 @@ package org.apache.lucene.analysis.standard;
  * limitations under the License.
  */
 
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.standard.ClassicTokenizer;
-import org.apache.lucene.analysis.standard.StandardAnalyzer;
 import org.apache.lucene.analysis.util.TokenizerFactory;
+import org.apache.lucene.util.AttributeSource.AttributeFactory;
 
 import java.io.Reader;
 import java.util.Map;
@@ -50,9 +48,16 @@ public class ClassicTokenizerFactory extends TokenizerFactory {
   }
 
   @Override
-  public Tokenizer create(Reader input) {
+  public ClassicTokenizer create(Reader input) {
     ClassicTokenizer tokenizer = new ClassicTokenizer(luceneMatchVersion, input); 
     tokenizer.setMaxTokenLength(maxTokenLength);
     return tokenizer;
   }
+
+  @Override
+  public ClassicTokenizer create(AttributeFactory factory, Reader input) {
+    ClassicTokenizer tokenizer = new ClassicTokenizer(luceneMatchVersion, factory, input); 
+    tokenizer.setMaxTokenLength(maxTokenLength);
+    return tokenizer;
+  }
 }
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizer.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizer.java
index ed83d9e..f1e1949 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizer.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizer.java
@@ -118,14 +118,6 @@ public final class StandardTokenizer extends Tokenizer {
   }
 
   /**
-   * Creates a new StandardTokenizer with a given {@link AttributeSource}. 
-   */
-  public StandardTokenizer(Version matchVersion, AttributeSource source, Reader input) {
-    super(source, input);
-    init(matchVersion);
-  }
-
-  /**
    * Creates a new StandardTokenizer with a given {@link org.apache.lucene.util.AttributeSource.AttributeFactory} 
    */
   public StandardTokenizer(Version matchVersion, AttributeFactory factory, Reader input) {
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizerFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizerFactory.java
index 385a3f8..6f60d64 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizerFactory.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizerFactory.java
@@ -17,9 +17,8 @@ package org.apache.lucene.analysis.standard;
  * limitations under the License.
  */
 
-import org.apache.lucene.analysis.standard.StandardAnalyzer;
-import org.apache.lucene.analysis.standard.StandardTokenizer;
 import org.apache.lucene.analysis.util.TokenizerFactory;
+import org.apache.lucene.util.AttributeSource.AttributeFactory;
 
 import java.io.Reader;
 import java.util.Map;
@@ -54,4 +53,12 @@ public class StandardTokenizerFactory extends TokenizerFactory {
     tokenizer.setMaxTokenLength(maxTokenLength);
     return tokenizer;
   }
+
+  @Override
+  public StandardTokenizer create(AttributeFactory factory, Reader input) {
+    StandardTokenizer tokenizer
+      = new StandardTokenizer(luceneMatchVersion, factory, input); 
+    tokenizer.setMaxTokenLength(maxTokenLength);
+    return tokenizer;
+  }
 }
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailTokenizer.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailTokenizer.java
index 6d3251b..9992a53 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailTokenizer.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailTokenizer.java
@@ -102,14 +102,6 @@ public final class UAX29URLEmailTokenizer extends Tokenizer {
   }
 
   /**
-   * Creates a new UAX29URLEmailTokenizer with a given {@link AttributeSource}. 
-   */
-  public UAX29URLEmailTokenizer(Version matchVersion, AttributeSource source, Reader input) {
-    super(source, input);
-    this.scanner = getScannerFor(matchVersion);
-  }
-
-  /**
    * Creates a new UAX29URLEmailTokenizer with a given {@link AttributeFactory} 
    */
   public UAX29URLEmailTokenizer(Version matchVersion, AttributeFactory factory, Reader input) {
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailTokenizerFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailTokenizerFactory.java
index 53acea2..866d3f7 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailTokenizerFactory.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailTokenizerFactory.java
@@ -17,9 +17,8 @@ package org.apache.lucene.analysis.standard;
  * limitations under the License.
  */
 
-import org.apache.lucene.analysis.standard.StandardAnalyzer;
-import org.apache.lucene.analysis.standard.UAX29URLEmailTokenizer;
 import org.apache.lucene.analysis.util.TokenizerFactory;
+import org.apache.lucene.util.AttributeSource.AttributeFactory;
 
 import java.io.Reader;
 import java.util.Map;
@@ -54,4 +53,11 @@ public class UAX29URLEmailTokenizerFactory extends TokenizerFactory {
     tokenizer.setMaxTokenLength(maxTokenLength);
     return tokenizer;
   }
+
+  @Override
+  public UAX29URLEmailTokenizer create(AttributeFactory factory, Reader input) {
+    UAX29URLEmailTokenizer tokenizer = new UAX29URLEmailTokenizer(luceneMatchVersion, factory, input); 
+    tokenizer.setMaxTokenLength(maxTokenLength);
+    return tokenizer;
+  }
 }
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/CharTokenizer.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/CharTokenizer.java
index 4bdef52..4d7693d 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/CharTokenizer.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/CharTokenizer.java
@@ -51,22 +51,6 @@ public abstract class CharTokenizer extends Tokenizer {
    * 
    * @param matchVersion
    *          Lucene version to match
-   * @param source
-   *          the attribute source to use for this {@link Tokenizer}
-   * @param input
-   *          the input to split up into tokens
-   */
-  public CharTokenizer(Version matchVersion, AttributeSource source,
-      Reader input) {
-    super(source, input);
-    charUtils = CharacterUtils.getInstance(matchVersion);
-  }
-  
-  /**
-   * Creates a new {@link CharTokenizer} instance
-   * 
-   * @param matchVersion
-   *          Lucene version to match
    * @param factory
    *          the attribute factory to use for this {@link Tokenizer}
    * @param input
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/TokenizerFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/TokenizerFactory.java
index 5050936..c482c3c 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/TokenizerFactory.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/TokenizerFactory.java
@@ -18,6 +18,7 @@ package org.apache.lucene.analysis.util;
  */
 
 import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.util.AttributeSource.AttributeFactory;
 
 import java.io.Reader;
 import java.util.Set;
@@ -63,4 +64,9 @@ public abstract class TokenizerFactory extends AbstractAnalysisFactory {
 
   /** Creates a TokenStream of the specified input */
   public abstract Tokenizer create(Reader input);
+  
+  /** Creates a TokenStream of the specified input using the given AttributeFactory */
+  public Tokenizer create(AttributeFactory factory, Reader input) {
+    throw new UnsupportedOperationException();
+  }
 }
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/wikipedia/WikipediaTokenizer.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/wikipedia/WikipediaTokenizer.java
index 0d8029a..984c4de 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/wikipedia/WikipediaTokenizer.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/wikipedia/WikipediaTokenizer.java
@@ -159,19 +159,6 @@ public final class WikipediaTokenizer extends Tokenizer {
     this.scanner = new WikipediaTokenizerImpl(null); // best effort NPE if you dont call reset
     init(tokenOutput, untokenizedTypes);
   }
-
-  /**
-   * Creates a new instance of the {@link org.apache.lucene.analysis.wikipedia.WikipediaTokenizer}.  Attaches the
-   * <code>input</code> to a the newly created JFlex scanner. Uses the given {@link AttributeSource}.
-   *
-   * @param input The input
-   * @param tokenOutput One of {@link #TOKENS_ONLY}, {@link #UNTOKENIZED_ONLY}, {@link #BOTH}
-   */
-  public WikipediaTokenizer(AttributeSource source, Reader input, int tokenOutput, Set<String> untokenizedTypes) {
-    super(source, input);
-    this.scanner = new WikipediaTokenizerImpl(null); // best effort NPE if you dont call reset
-    init(tokenOutput, untokenizedTypes);
-  }
   
   private void init(int tokenOutput, Set<String> untokenizedTypes) {
     // TODO: cutover to enum
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/wikipedia/WikipediaTokenizerFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/wikipedia/WikipediaTokenizerFactory.java
index 2f5d2a6..cb470a9 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/wikipedia/WikipediaTokenizerFactory.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/wikipedia/WikipediaTokenizerFactory.java
@@ -18,10 +18,10 @@ package org.apache.lucene.analysis.wikipedia;
  */
 
 import java.io.Reader;
+import java.util.Collections;
 
-import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.util.TokenizerFactory;
-import org.apache.lucene.analysis.wikipedia.WikipediaTokenizer;
+import org.apache.lucene.util.AttributeSource.AttributeFactory;
 
 /** 
  * Factory for {@link WikipediaTokenizer}.
@@ -36,7 +36,13 @@ import org.apache.lucene.analysis.wikipedia.WikipediaTokenizer;
 public class WikipediaTokenizerFactory extends TokenizerFactory {
   // TODO: add support for WikipediaTokenizer's advanced options.
   @Override
-  public Tokenizer create(Reader input) {
+  public WikipediaTokenizer create(Reader input) {
     return new WikipediaTokenizer(input);
   }
+
+  @Override
+  public WikipediaTokenizer create(AttributeFactory factory, Reader input) {
+    return new WikipediaTokenizer(factory, input, WikipediaTokenizer.TOKENS_ONLY, 
+        Collections.<String>emptySet());
+  }
 }
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestFactories.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestFactories.java
index edfab82..d40813b 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestFactories.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestFactories.java
@@ -146,7 +146,7 @@ public class TestFactories extends BaseTokenStreamTestCase {
   // some silly classes just so we can use checkRandomData
   private TokenizerFactory assertingTokenizer = new TokenizerFactory() {
     @Override
-    public Tokenizer create(Reader input) {
+    public MockTokenizer create(Reader input) {
       return new MockTokenizer(input);
     }
   };
diff --git a/lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/segmentation/ICUTokenizerFactory.java b/lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/segmentation/ICUTokenizerFactory.java
index a9345d5..b611a81 100644
--- a/lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/segmentation/ICUTokenizerFactory.java
+++ b/lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/segmentation/ICUTokenizerFactory.java
@@ -144,7 +144,7 @@ public class ICUTokenizerFactory extends TokenizerFactory implements ResourceLoa
   }
 
   @Override
-  public Tokenizer create(Reader input) {
+  public ICUTokenizer create(Reader input) {
     assert config != null : "inform must be called first!";
     return new ICUTokenizer(input, config);
   }
diff --git a/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizerFactory.java b/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizerFactory.java
index 614ea7a..d199628 100644
--- a/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizerFactory.java
+++ b/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizerFactory.java
@@ -89,7 +89,7 @@ public class JapaneseTokenizerFactory extends TokenizerFactory implements Resour
   }
   
   @Override
-  public Tokenizer create(Reader input) {
+  public JapaneseTokenizer create(Reader input) {
     return new JapaneseTokenizer(input, userDictionary, discardPunctuation, mode);
   }
   
diff --git a/lucene/analysis/smartcn/src/java/org/apache/lucene/analysis/cn/smart/SentenceTokenizer.java b/lucene/analysis/smartcn/src/java/org/apache/lucene/analysis/cn/smart/SentenceTokenizer.java
index da98907..e25ed6c 100644
--- a/lucene/analysis/smartcn/src/java/org/apache/lucene/analysis/cn/smart/SentenceTokenizer.java
+++ b/lucene/analysis/smartcn/src/java/org/apache/lucene/analysis/cn/smart/SentenceTokenizer.java
@@ -52,10 +52,6 @@ public final class SentenceTokenizer extends Tokenizer {
     super(reader);
   }
 
-  public SentenceTokenizer(AttributeSource source, Reader reader) {
-    super(source, reader);
-  }
-
   public SentenceTokenizer(AttributeFactory factory, Reader reader) {
     super(factory, reader);
   }
diff --git a/lucene/analysis/smartcn/src/java/org/apache/lucene/analysis/cn/smart/SmartChineseSentenceTokenizerFactory.java b/lucene/analysis/smartcn/src/java/org/apache/lucene/analysis/cn/smart/SmartChineseSentenceTokenizerFactory.java
index 99e6155..df823e0 100644
--- a/lucene/analysis/smartcn/src/java/org/apache/lucene/analysis/cn/smart/SmartChineseSentenceTokenizerFactory.java
+++ b/lucene/analysis/smartcn/src/java/org/apache/lucene/analysis/cn/smart/SmartChineseSentenceTokenizerFactory.java
@@ -19,9 +19,8 @@ package org.apache.lucene.analysis.cn.smart;
 
 import java.io.Reader;
 
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.cn.smart.SentenceTokenizer;
 import org.apache.lucene.analysis.util.TokenizerFactory;
+import org.apache.lucene.util.AttributeSource.AttributeFactory;
 
 /**
  * Factory for the SmartChineseAnalyzer {@link SentenceTokenizer}
@@ -29,7 +28,12 @@ import org.apache.lucene.analysis.util.TokenizerFactory;
  */
 public class SmartChineseSentenceTokenizerFactory extends TokenizerFactory {
   @Override
-  public Tokenizer create(Reader input) {
+  public SentenceTokenizer create(Reader input) {
     return new SentenceTokenizer(input);
   }
+
+  @Override
+  public SentenceTokenizer create(AttributeFactory factory, Reader input) {
+    return new SentenceTokenizer(factory, input);
+  }
 }
diff --git a/lucene/analysis/uima/src/java/org/apache/lucene/analysis/uima/UIMAAnnotationsTokenizerFactory.java b/lucene/analysis/uima/src/java/org/apache/lucene/analysis/uima/UIMAAnnotationsTokenizerFactory.java
index a57f54a..a34ddb9 100644
--- a/lucene/analysis/uima/src/java/org/apache/lucene/analysis/uima/UIMAAnnotationsTokenizerFactory.java
+++ b/lucene/analysis/uima/src/java/org/apache/lucene/analysis/uima/UIMAAnnotationsTokenizerFactory.java
@@ -17,9 +17,7 @@ package org.apache.lucene.analysis.uima;
  * limitations under the License.
  */
 
-import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.util.TokenizerFactory;
-import org.apache.lucene.analysis.uima.UIMAAnnotationsTokenizer;
 
 import java.io.Reader;
 import java.util.HashMap;
@@ -54,7 +52,7 @@ public class UIMAAnnotationsTokenizerFactory extends TokenizerFactory {
   }
 
   @Override
-  public Tokenizer create(Reader input) {
+  public UIMAAnnotationsTokenizer create(Reader input) {
     return new UIMAAnnotationsTokenizer(descriptorPath, tokenType, configurationParameters, input);
   }
 }
diff --git a/lucene/analysis/uima/src/java/org/apache/lucene/analysis/uima/UIMATypeAwareAnnotationsTokenizerFactory.java b/lucene/analysis/uima/src/java/org/apache/lucene/analysis/uima/UIMATypeAwareAnnotationsTokenizerFactory.java
index 265b965..48415a6 100644
--- a/lucene/analysis/uima/src/java/org/apache/lucene/analysis/uima/UIMATypeAwareAnnotationsTokenizerFactory.java
+++ b/lucene/analysis/uima/src/java/org/apache/lucene/analysis/uima/UIMATypeAwareAnnotationsTokenizerFactory.java
@@ -17,7 +17,6 @@ package org.apache.lucene.analysis.uima;
  * limitations under the License.
  */
 
-import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.util.TokenizerFactory;
 
 import java.io.Reader;
@@ -55,7 +54,7 @@ public class UIMATypeAwareAnnotationsTokenizerFactory extends TokenizerFactory {
   }
 
   @Override
-  public Tokenizer create(Reader input) {
+  public UIMATypeAwareAnnotationsTokenizer create(Reader input) {
     return new UIMATypeAwareAnnotationsTokenizer(descriptorPath, tokenType, featurePath, configurationParameters, input);
   }
 }
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/Tokenizer.java b/lucene/core/src/java/org/apache/lucene/analysis/Tokenizer.java
index a0900bc..9013bdb 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/Tokenizer.java
+++ b/lucene/core/src/java/org/apache/lucene/analysis/Tokenizer.java
@@ -47,13 +47,6 @@ public abstract class Tokenizer extends TokenStream {
     this.input = input;
   }
 
-  /** Construct a token stream processing the given input using the given AttributeSource. */
-  protected Tokenizer(AttributeSource source, Reader input) {
-    super(source);
-    assert input != null: "input must not be null";
-    this.input = input;
-  }
-  
   /**
    * {@inheritDoc}
    * <p>
diff --git a/solr/core/src/java/org/apache/solr/analysis/TrieTokenizerFactory.java b/solr/core/src/java/org/apache/solr/analysis/TrieTokenizerFactory.java
index 196fece..671e453 100644
--- a/solr/core/src/java/org/apache/solr/analysis/TrieTokenizerFactory.java
+++ b/solr/core/src/java/org/apache/solr/analysis/TrieTokenizerFactory.java
@@ -22,12 +22,15 @@ import org.apache.lucene.analysis.tokenattributes.CharTermAttributeImpl;
 import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.util.TokenizerFactory;
+import org.apache.lucene.util.Attribute;
+import org.apache.lucene.util.AttributeImpl;
 import org.apache.solr.common.SolrException;
 import org.apache.solr.schema.DateField;
 import static org.apache.solr.schema.TrieField.TrieTypes;
 
 import java.io.IOException;
 import java.io.Reader;
+import java.util.Iterator;
 
 /**
  * Tokenizer for trie fields. It uses NumericTokenStream to create multiple trie encoded string per number.
@@ -71,9 +74,18 @@ final class TrieTokenizer extends Tokenizer {
     return new NumericTokenStream(precisionStep);
   }
 
-  public TrieTokenizer(Reader input, TrieTypes type, NumericTokenStream ts) {
-    // must share the attribute source with the NumericTokenStream we delegate to
-    super(ts, input);
+  public TrieTokenizer(Reader input, TrieTypes type, final NumericTokenStream ts) {
+    // Häckidy-Hick-Hack: must share the attributes with the NumericTokenStream we delegate to, so we create a fake factory:
+    super(new AttributeFactory() {
+      @Override
+      public AttributeImpl createAttributeInstance(Class<? extends Attribute> attClass) {
+        return (AttributeImpl) ts.addAttribute(attClass);
+      }
+    }, input);
+    // add all attributes:
+    for (Iterator<Class<? extends Attribute>> it = ts.getAttributeClassesIterator(); it.hasNext();) {
+      addAttribute(it.next());
+    }
     this.type = type;
     this.ts = ts;
     // dates tend to be longer, especially when math is involved
diff --git a/solr/test-framework/src/java/org/apache/solr/analysis/MockCharFilterFactory.java b/solr/test-framework/src/java/org/apache/solr/analysis/MockCharFilterFactory.java
index 8b67cbf..9ff414c 100644
--- a/solr/test-framework/src/java/org/apache/solr/analysis/MockCharFilterFactory.java
+++ b/solr/test-framework/src/java/org/apache/solr/analysis/MockCharFilterFactory.java
@@ -20,7 +20,6 @@ package org.apache.solr.analysis;
 import java.io.Reader;
 import java.util.Map;
 
-import org.apache.lucene.analysis.CharFilter;
 import org.apache.lucene.analysis.MockCharFilter;
 import org.apache.lucene.analysis.util.CharFilterFactory;
 
@@ -41,7 +40,7 @@ public class MockCharFilterFactory extends CharFilterFactory {
   }
 
   @Override
-  public CharFilter create(Reader input) {
+  public MockCharFilter create(Reader input) {
     return new MockCharFilter(input, remainder);
   }
 }
diff --git a/solr/test-framework/src/java/org/apache/solr/analysis/MockTokenizerFactory.java b/solr/test-framework/src/java/org/apache/solr/analysis/MockTokenizerFactory.java
index e72e32f..d2782ea 100644
--- a/solr/test-framework/src/java/org/apache/solr/analysis/MockTokenizerFactory.java
+++ b/solr/test-framework/src/java/org/apache/solr/analysis/MockTokenizerFactory.java
@@ -55,7 +55,7 @@ public class MockTokenizerFactory extends TokenizerFactory {
 
 
   @Override
-  public Tokenizer create(Reader input) {
+  public MockTokenizer create(Reader input) {
     MockTokenizer t = new MockTokenizer(input, pattern, false);
     t.setEnableChecks(enableChecks);
     return t;

