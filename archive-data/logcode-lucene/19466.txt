GitDiffStart: e5cb7f668a919906a478ebcce78b336af50d747c | Tue Sep 1 20:10:33 2009 +0000
diff --git a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/SmartChineseAnalyzer.java b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/SmartChineseAnalyzer.java
deleted file mode 100644
index 2b09621..0000000
--- a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/SmartChineseAnalyzer.java
+++ /dev/null
@@ -1,146 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.lucene.analysis.cn;
-
-import java.io.IOException;
-import java.io.InputStream;
-import java.io.InputStreamReader;
-import java.io.Reader;
-import java.util.Set;
-
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.PorterStemFilter;
-import org.apache.lucene.analysis.StopFilter;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.WordlistLoader;
-import org.apache.lucene.analysis.cn.smart.SentenceTokenizer;
-import org.apache.lucene.analysis.cn.smart.WordTokenFilter;
-
-/**
- * <p>
- * SmartChineseAnalyzer is an analyzer for Chinese or mixed Chinese-English text.
- * The analyzer uses probabilistic knowledge to find the optimal word segmentation for Simplified Chinese text.
- * The text is first broken into sentences, then each sentence is segmented into words.
- * </p>
- * <p>
- * Segmentation is based upon the <a href="http://en.wikipedia.org/wiki/Hidden_Markov_Model">Hidden Markov Model</a>. 
- * A large training corpus was used to calculate Chinese word frequency probability.
- * </p>
- * <p>
- * This analyzer requires a dictionary to provide statistical data. 
- * SmartChineseAnalyzer has an included dictionary out-of-box.
- * </p>
- * <p>
- * The included dictionary data is from <a href="http://www.ictclas.org">ICTCLAS1.0</a>.
- * Thanks to ICTCLAS for their hard work, and for contributing the data under the Apache 2 License!
- * </p>
- * <p><font color="#FF0000">
- * WARNING: The status of the analyzers/smartcn <b>analysis.cn</b> package is experimental. 
- * The APIs and file formats introduced here might change in the future and will not be 
- * supported anymore in such a case.</font>
- * </p>
- */
-public class SmartChineseAnalyzer extends Analyzer {
-
-  private final Set stopWords;
-
-  /**
-   * Create a new SmartChineseAnalyzer, using the default stopword list.
-   */
-  public SmartChineseAnalyzer() {
-    this(true);
-  }
-
-  /**
-   * <p>
-   * Create a new SmartChineseAnalyzer, optionally using the default stopword list.
-   * </p>
-   * <p>
-   * The included default stopword list is simply a list of punctuation.
-   * If you do not use this list, punctuation will not be removed from the text!
-   * </p>
-   * 
-   * @param useDefaultStopWords true to use the default stopword list.
-   */
-  public SmartChineseAnalyzer(boolean useDefaultStopWords) {
-    if (useDefaultStopWords) {
-      try {
-      InputStream stream = this.getClass().getResourceAsStream("stopwords.txt");
-      InputStreamReader reader = new InputStreamReader(stream, "UTF-8");
-      stopWords = WordlistLoader.getWordSet(reader, "//");
-      } catch (IOException e) {
-        // TODO: throw IOException
-        throw new RuntimeException(e);
-      }
-    }else{
-      stopWords = null;
-    }
-  }
-
-  /**
-   * <p>
-   * Create a new SmartChineseAnalyzer, using the provided {@link Set} of stopwords.
-   * </p>
-   * <p>
-   * Note: the set should include punctuation, unless you want to index punctuation!
-   * </p>
-   * @param stopWords {@link Set} of stopwords to use.
-   */
-  public SmartChineseAnalyzer(Set stopWords) {
-    this.stopWords = stopWords;
-  }
-
-  public TokenStream tokenStream(String fieldName, Reader reader) {
-    TokenStream result = new SentenceTokenizer(reader);
-    result = new WordTokenFilter(result);
-    // result = new LowerCaseFilter(result);
-    // LowerCaseFilter is not needed, as SegTokenFilter lowercases Basic Latin text.
-    // The porter stemming is too strict, this is not a bug, this is a feature:)
-    result = new PorterStemFilter(result);
-    if (stopWords != null) {
-      result = new StopFilter(result, stopWords, false);
-    }
-    return result;
-  }
-  
-  private static final class SavedStreams {
-    Tokenizer tokenStream;
-    TokenStream filteredTokenStream;
-  }
-  
-  public TokenStream reusableTokenStream(String fieldName, Reader reader)
-      throws IOException {
-    SavedStreams streams = (SavedStreams) getPreviousTokenStream();
-    if (streams == null) {
-      streams = new SavedStreams();
-      setPreviousTokenStream(streams);
-      streams.tokenStream = new SentenceTokenizer(reader);
-      streams.filteredTokenStream = new WordTokenFilter(streams.tokenStream);
-      streams.filteredTokenStream = new PorterStemFilter(streams.filteredTokenStream);
-      if (stopWords != null) {
-        streams.filteredTokenStream = new StopFilter(streams.filteredTokenStream, stopWords, false);
-      }
-    } else {
-      streams.tokenStream.reset(reader);
-      streams.filteredTokenStream.reset(); // reset WordTokenFilter's state
-    }
-
-    return streams.filteredTokenStream;
-  }
-}
diff --git a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/package.html b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/package.html
deleted file mode 100644
index d9d596f..0000000
--- a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/package.html
+++ /dev/null
@@ -1,50 +0,0 @@
-<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-<html>
-<head>
-<META http-equiv="Content-Type" content="text/html; charset=UTF-8">
-</head>
-<body>
-<div>
-Analyzer for Simplified Chinese, which indexes words.
-</div>
-<div>
-<font color="#FF0000">
-WARNING: The status of the analyzers/smartcn <b>analysis.cn</b> package is experimental. The APIs
-and file formats introduced here might change in the future and will not be supported anymore
-in such a case.
-</font>
-</div>
-<div>
-Three analyzers are provided for Chinese, each of which treats Chinese text in a different way.
-<ul>
-	<li>ChineseAnalyzer (in the analyzers/cn package): Index unigrams (individual Chinese characters) as a token.
-	<li>CJKAnalyzer (in the analyzers/cjk package): Index bigrams (overlapping groups of two adjacent Chinese characters) as tokens.
-	<li>SmartChineseAnalyzer (in this package): Index words (attempt to segment Chinese text into words) as tokens.
-</ul>
-
-Example phraseï¼? "???ä¸??äº?"
-<ol>
-	<li>ChineseAnalyzer: ??????ä¸???½ï?äº?</li>
-	<li>CJKAnalyzer: ???ï¼??ä¸??ä¸??ï¼??äº?</li>
-	<li>SmartChineseAnalyzer: ??????ä¸??ï¼?ºº</li>
-</ol>
-</div>
-
-</body>
-</html>
diff --git a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/AnalyzerProfile.java b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/AnalyzerProfile.java
index bd2fe29..a323911 100644
--- a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/AnalyzerProfile.java
+++ b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/AnalyzerProfile.java
@@ -28,7 +28,7 @@ import java.util.Properties;
  * SmartChineseAnalyzer has a built-in dictionary and stopword list out-of-box.
  * </p>
  * <p><font color="#FF0000">
- * WARNING: The status of the analyzers/smartcn <b>analysis.cn</b> package is experimental. 
+ * WARNING: The status of the analyzers/smartcn <b>analysis.cn.smart</b> package is experimental. 
  * The APIs and file formats introduced here might change in the future and will not be 
  * supported anymore in such a case.</font>
  * </p>
diff --git a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/CharType.java b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/CharType.java
index 539509f..e9c237c 100644
--- a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/CharType.java
+++ b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/CharType.java
@@ -20,7 +20,7 @@ package org.apache.lucene.analysis.cn.smart;
 /**
  * Internal SmartChineseAnalyzer character type constants.
  * <p><font color="#FF0000">
- * WARNING: The status of the analyzers/smartcn <b>analysis.cn</b> package is experimental. 
+ * WARNING: The status of the analyzers/smartcn <b>analysis.cn.smart</b> package is experimental. 
  * The APIs and file formats introduced here might change in the future and will not be 
  * supported anymore in such a case.</font>
  * </p>
diff --git a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/SentenceTokenizer.java b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/SentenceTokenizer.java
index 0c41842..21195c3 100644
--- a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/SentenceTokenizer.java
+++ b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/SentenceTokenizer.java
@@ -32,7 +32,7 @@ import org.apache.lucene.util.AttributeSource;
  * The output tokens can then be broken into words with {@link WordTokenFilter}
  * </p>
  * <p><font color="#FF0000">
- * WARNING: The status of the analyzers/smartcn <b>analysis.cn</b> package is experimental. 
+ * WARNING: The status of the analyzers/smartcn <b>analysis.cn.smart</b> package is experimental. 
  * The APIs and file formats introduced here might change in the future and will not be 
  * supported anymore in such a case.</font>
  * </p>
diff --git a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/SmartChineseAnalyzer.java b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/SmartChineseAnalyzer.java
new file mode 100644
index 0000000..442c265
--- /dev/null
+++ b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/SmartChineseAnalyzer.java
@@ -0,0 +1,146 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.lucene.analysis.cn.smart;
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.InputStreamReader;
+import java.io.Reader;
+import java.util.Set;
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.PorterStemFilter;
+import org.apache.lucene.analysis.StopFilter;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.WordlistLoader;
+import org.apache.lucene.analysis.cn.smart.SentenceTokenizer;
+import org.apache.lucene.analysis.cn.smart.WordTokenFilter;
+
+/**
+ * <p>
+ * SmartChineseAnalyzer is an analyzer for Chinese or mixed Chinese-English text.
+ * The analyzer uses probabilistic knowledge to find the optimal word segmentation for Simplified Chinese text.
+ * The text is first broken into sentences, then each sentence is segmented into words.
+ * </p>
+ * <p>
+ * Segmentation is based upon the <a href="http://en.wikipedia.org/wiki/Hidden_Markov_Model">Hidden Markov Model</a>. 
+ * A large training corpus was used to calculate Chinese word frequency probability.
+ * </p>
+ * <p>
+ * This analyzer requires a dictionary to provide statistical data. 
+ * SmartChineseAnalyzer has an included dictionary out-of-box.
+ * </p>
+ * <p>
+ * The included dictionary data is from <a href="http://www.ictclas.org">ICTCLAS1.0</a>.
+ * Thanks to ICTCLAS for their hard work, and for contributing the data under the Apache 2 License!
+ * </p>
+ * <p><font color="#FF0000">
+ * WARNING: The status of the analyzers/smartcn <b>analysis.cn.smart</b> package is experimental. 
+ * The APIs and file formats introduced here might change in the future and will not be 
+ * supported anymore in such a case.</font>
+ * </p>
+ */
+public class SmartChineseAnalyzer extends Analyzer {
+
+  private final Set stopWords;
+
+  /**
+   * Create a new SmartChineseAnalyzer, using the default stopword list.
+   */
+  public SmartChineseAnalyzer() {
+    this(true);
+  }
+
+  /**
+   * <p>
+   * Create a new SmartChineseAnalyzer, optionally using the default stopword list.
+   * </p>
+   * <p>
+   * The included default stopword list is simply a list of punctuation.
+   * If you do not use this list, punctuation will not be removed from the text!
+   * </p>
+   * 
+   * @param useDefaultStopWords true to use the default stopword list.
+   */
+  public SmartChineseAnalyzer(boolean useDefaultStopWords) {
+    if (useDefaultStopWords) {
+      try {
+      InputStream stream = this.getClass().getResourceAsStream("stopwords.txt");
+      InputStreamReader reader = new InputStreamReader(stream, "UTF-8");
+      stopWords = WordlistLoader.getWordSet(reader, "//");
+      } catch (IOException e) {
+        // TODO: throw IOException
+        throw new RuntimeException(e);
+      }
+    }else{
+      stopWords = null;
+    }
+  }
+
+  /**
+   * <p>
+   * Create a new SmartChineseAnalyzer, using the provided {@link Set} of stopwords.
+   * </p>
+   * <p>
+   * Note: the set should include punctuation, unless you want to index punctuation!
+   * </p>
+   * @param stopWords {@link Set} of stopwords to use.
+   */
+  public SmartChineseAnalyzer(Set stopWords) {
+    this.stopWords = stopWords;
+  }
+
+  public TokenStream tokenStream(String fieldName, Reader reader) {
+    TokenStream result = new SentenceTokenizer(reader);
+    result = new WordTokenFilter(result);
+    // result = new LowerCaseFilter(result);
+    // LowerCaseFilter is not needed, as SegTokenFilter lowercases Basic Latin text.
+    // The porter stemming is too strict, this is not a bug, this is a feature:)
+    result = new PorterStemFilter(result);
+    if (stopWords != null) {
+      result = new StopFilter(result, stopWords, false);
+    }
+    return result;
+  }
+  
+  private static final class SavedStreams {
+    Tokenizer tokenStream;
+    TokenStream filteredTokenStream;
+  }
+  
+  public TokenStream reusableTokenStream(String fieldName, Reader reader)
+      throws IOException {
+    SavedStreams streams = (SavedStreams) getPreviousTokenStream();
+    if (streams == null) {
+      streams = new SavedStreams();
+      setPreviousTokenStream(streams);
+      streams.tokenStream = new SentenceTokenizer(reader);
+      streams.filteredTokenStream = new WordTokenFilter(streams.tokenStream);
+      streams.filteredTokenStream = new PorterStemFilter(streams.filteredTokenStream);
+      if (stopWords != null) {
+        streams.filteredTokenStream = new StopFilter(streams.filteredTokenStream, stopWords, false);
+      }
+    } else {
+      streams.tokenStream.reset(reader);
+      streams.filteredTokenStream.reset(); // reset WordTokenFilter's state
+    }
+
+    return streams.filteredTokenStream;
+  }
+}
diff --git a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/Utility.java b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/Utility.java
index 36e73a1..c9147f6 100644
--- a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/Utility.java
+++ b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/Utility.java
@@ -22,7 +22,7 @@ import org.apache.lucene.analysis.cn.smart.hhmm.SegTokenFilter; // for javadoc
 /**
  * SmartChineseAnalyzer utility constants and methods
  * <p><font color="#FF0000">
- * WARNING: The status of the analyzers/smartcn <b>analysis.cn</b> package is experimental. 
+ * WARNING: The status of the analyzers/smartcn <b>analysis.cn.smart</b> package is experimental. 
  * The APIs and file formats introduced here might change in the future and will not be 
  * supported anymore in such a case.</font>
  * </p>
diff --git a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/WordSegmenter.java b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/WordSegmenter.java
index 04378b1..4ca00cb 100644
--- a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/WordSegmenter.java
+++ b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/WordSegmenter.java
@@ -27,7 +27,7 @@ import org.apache.lucene.analysis.cn.smart.hhmm.SegTokenFilter;
 /**
  * Segment a sentence of Chinese text into words.
  * <p><font color="#FF0000">
- * WARNING: The status of the analyzers/smartcn <b>analysis.cn</b> package is experimental. 
+ * WARNING: The status of the analyzers/smartcn <b>analysis.cn.smart</b> package is experimental. 
  * The APIs and file formats introduced here might change in the future and will not be 
  * supported anymore in such a case.</font>
  * </p>
diff --git a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/WordTokenFilter.java b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/WordTokenFilter.java
index 17b9757..91f23ee 100644
--- a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/WordTokenFilter.java
+++ b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/WordTokenFilter.java
@@ -31,7 +31,7 @@ import org.apache.lucene.analysis.tokenattributes.TypeAttribute;
 /**
  * A {@link TokenFilter} that breaks sentences into words.
  * <p><font color="#FF0000">
- * WARNING: The status of the analyzers/smartcn <b>analysis.cn</b> package is experimental. 
+ * WARNING: The status of the analyzers/smartcn <b>analysis.cn.smart</b> package is experimental. 
  * The APIs and file formats introduced here might change in the future and will not be 
  * supported anymore in such a case.</font>
  * </p>
diff --git a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/WordType.java b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/WordType.java
index 8878ac5..e1b12fc 100644
--- a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/WordType.java
+++ b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/WordType.java
@@ -20,7 +20,7 @@ package org.apache.lucene.analysis.cn.smart;
 /**
  * Internal SmartChineseAnalyzer token type constants
  * <p><font color="#FF0000">
- * WARNING: The status of the analyzers/smartcn <b>analysis.cn</b> package is experimental. 
+ * WARNING: The status of the analyzers/smartcn <b>analysis.cn.smart</b> package is experimental. 
  * The APIs and file formats introduced here might change in the future and will not be 
  * supported anymore in such a case.</font>
  * </p>
diff --git a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/AbstractDictionary.java b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/AbstractDictionary.java
index 6ccebc1..9b37ae9 100644
--- a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/AbstractDictionary.java
+++ b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/AbstractDictionary.java
@@ -27,7 +27,7 @@ import java.io.UnsupportedEncodingException;
  * Contains methods for dealing with GB2312 encoding.
  * </p>
  * <p><font color="#FF0000">
- * WARNING: The status of the analyzers/smartcn <b>analysis.cn</b> package is experimental. 
+ * WARNING: The status of the analyzers/smartcn <b>analysis.cn.smart</b> package is experimental. 
  * The APIs and file formats introduced here might change in the future and will not be 
  * supported anymore in such a case.</font>
  * </p>
diff --git a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/BiSegGraph.java b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/BiSegGraph.java
index e481627..ef37f15 100644
--- a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/BiSegGraph.java
+++ b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/BiSegGraph.java
@@ -32,7 +32,7 @@ import org.apache.lucene.analysis.cn.smart.Utility;
  * For each start offset, a list of possible token pairs is stored.
  * </p>
  * <p><font color="#FF0000">
- * WARNING: The status of the analyzers/smartcn <b>analysis.cn</b> package is experimental. 
+ * WARNING: The status of the analyzers/smartcn <b>analysis.cn.smart</b> package is experimental. 
  * The APIs and file formats introduced here might change in the future and will not be 
  * supported anymore in such a case.</font>
  * </p>
diff --git a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/BigramDictionary.java b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/BigramDictionary.java
index 13f8569..8fa8e9d 100644
--- a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/BigramDictionary.java
+++ b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/BigramDictionary.java
@@ -35,7 +35,7 @@ import org.apache.lucene.analysis.cn.smart.AnalyzerProfile;
 /**
  * SmartChineseAnalyzer Bigram dictionary.
  * <p><font color="#FF0000">
- * WARNING: The status of the analyzers/smartcn <b>analysis.cn</b> package is experimental. 
+ * WARNING: The status of the analyzers/smartcn <b>analysis.cn.smart</b> package is experimental. 
  * The APIs and file formats introduced here might change in the future and will not be 
  * supported anymore in such a case.</font>
  * </p>
diff --git a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/HHMMSegmenter.java b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/HHMMSegmenter.java
index 8e729ca..4200813 100644
--- a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/HHMMSegmenter.java
+++ b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/HHMMSegmenter.java
@@ -27,7 +27,7 @@ import org.apache.lucene.analysis.cn.smart.hhmm.PathNode;//javadoc @link
 /**
  * Finds the optimal segmentation of a sentence into Chinese words
  * <p><font color="#FF0000">
- * WARNING: The status of the analyzers/smartcn <b>analysis.cn</b> package is experimental. 
+ * WARNING: The status of the analyzers/smartcn <b>analysis.cn.smart</b> package is experimental. 
  * The APIs and file formats introduced here might change in the future and will not be 
  * supported anymore in such a case.</font>
  * </p>
diff --git a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/PathNode.java b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/PathNode.java
index 6e18279..47ad030 100644
--- a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/PathNode.java
+++ b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/PathNode.java
@@ -23,7 +23,7 @@ package org.apache.lucene.analysis.cn.smart.hhmm;
  * Used by {@link BiSegGraph} to maximize the segmentation with the Viterbi algorithm.
  * </p>
  * <p><font color="#FF0000">
- * WARNING: The status of the analyzers/smartcn <b>analysis.cn</b> package is experimental. 
+ * WARNING: The status of the analyzers/smartcn <b>analysis.cn.smart</b> package is experimental. 
  * The APIs and file formats introduced here might change in the future and will not be 
  * supported anymore in such a case.</font>
  * </p>
diff --git a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/SegGraph.java b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/SegGraph.java
index 45f868f..7228b5c 100644
--- a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/SegGraph.java
+++ b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/SegGraph.java
@@ -29,7 +29,7 @@ import java.util.Map;
  * For each start offset, a list of possible tokens is stored.
  * </p>
  * <p><font color="#FF0000">
- * WARNING: The status of the analyzers/smartcn <b>analysis.cn</b> package is experimental. 
+ * WARNING: The status of the analyzers/smartcn <b>analysis.cn.smart</b> package is experimental. 
  * The APIs and file formats introduced here might change in the future and will not be 
  * supported anymore in such a case.</font>
  * </p>
diff --git a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/SegToken.java b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/SegToken.java
index 9bc9427..1536e6d 100644
--- a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/SegToken.java
+++ b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/SegToken.java
@@ -24,7 +24,7 @@ import org.apache.lucene.analysis.cn.smart.WordType; // for javadocs
 /**
  * SmartChineseAnalyzer internal token
  * <p><font color="#FF0000">
- * WARNING: The status of the analyzers/smartcn <b>analysis.cn</b> package is experimental. 
+ * WARNING: The status of the analyzers/smartcn <b>analysis.cn.smart</b> package is experimental. 
  * The APIs and file formats introduced here might change in the future and will not be 
  * supported anymore in such a case.</font>
  * </p>
diff --git a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/SegTokenFilter.java b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/SegTokenFilter.java
index f9ac9d5..ca8f766 100644
--- a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/SegTokenFilter.java
+++ b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/SegTokenFilter.java
@@ -26,7 +26,7 @@ import org.apache.lucene.analysis.cn.smart.WordType;
  * Additionally, all punctuation is converted into {@link Utility#COMMON_DELIMITER}
  * </p>
  * <p><font color="#FF0000">
- * WARNING: The status of the analyzers/smartcn <b>analysis.cn</b> package is experimental. 
+ * WARNING: The status of the analyzers/smartcn <b>analysis.cn.smart</b> package is experimental. 
  * The APIs and file formats introduced here might change in the future and will not be 
  * supported anymore in such a case.</font>
  * </p>
diff --git a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/SegTokenPair.java b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/SegTokenPair.java
index 6a8e3aa..11729bb 100644
--- a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/SegTokenPair.java
+++ b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/SegTokenPair.java
@@ -22,7 +22,7 @@ import java.util.Arrays;
 /**
  * A pair of tokens in {@link SegGraph}
  * <p><font color="#FF0000">
- * WARNING: The status of the analyzers/smartcn <b>analysis.cn</b> package is experimental. 
+ * WARNING: The status of the analyzers/smartcn <b>analysis.cn.smart</b> package is experimental. 
  * The APIs and file formats introduced here might change in the future and will not be 
  * supported anymore in such a case.</font>
  * </p>
diff --git a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/WordDictionary.java b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/WordDictionary.java
index 073df06..c76b1a3 100644
--- a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/WordDictionary.java
+++ b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/WordDictionary.java
@@ -37,7 +37,7 @@ import org.apache.lucene.analysis.cn.smart.Utility;
  * SmartChineseAnalyzer Word Dictionary
  *
  * <p><font color="#FF0000">
- * WARNING: The status of the analyzers/smartcn <b>analysis.cn</b> package is experimental. 
+ * WARNING: The status of the analyzers/smartcn <b>analysis.cn.smart</b> package is experimental. 
  * The APIs and file formats introduced here might change in the future and will not be 
  * supported anymore in such a case.</font>
  * </p>
diff --git a/contrib/analyzers/smartcn/src/resources/org/apache/lucene/analysis/cn/smart/stopwords.txt b/contrib/analyzers/smartcn/src/resources/org/apache/lucene/analysis/cn/smart/stopwords.txt
new file mode 100644
index 0000000..fb0d71a
--- /dev/null
+++ b/contrib/analyzers/smartcn/src/resources/org/apache/lucene/analysis/cn/smart/stopwords.txt
@@ -0,0 +1,59 @@
+////////// Punctuation tokens to remove ////////////////
+,
+.
+`
+-
+_
+=
+?
+'
+|
+"
+(
+)
+{
+}
+[
+]
+<
+>
+*
+#
+&
+^
+$
+@
+!
+~
+:
+;
++
+/
+\
+??
+??
+??
+ï¼?
+ï¼?
+??
+??
+ï¼?
+ï¼?
+ï¼?
+Â·
+ï¼?
+??
+??
+ï¼?
+ï¼?
+??
+??
+ï¼?
+ï¼?
+??
+// the line below contains an IDEOGRAPHIC SPACE character (Used as a space in Chinese)
+??
+
+//////////////// English Stop Words ////////////////
+
+//////////////// Chinese Stop Words ////////////////
diff --git a/contrib/analyzers/smartcn/src/resources/org/apache/lucene/analysis/cn/stopwords.txt b/contrib/analyzers/smartcn/src/resources/org/apache/lucene/analysis/cn/stopwords.txt
deleted file mode 100644
index fb0d71a..0000000
--- a/contrib/analyzers/smartcn/src/resources/org/apache/lucene/analysis/cn/stopwords.txt
+++ /dev/null
@@ -1,59 +0,0 @@
-////////// Punctuation tokens to remove ////////////////
-,
-.
-`
--
-_
-=
-?
-'
-|
-"
-(
-)
-{
-}
-[
-]
-<
->
-*
-#
-&
-^
-$
-@
-!
-~
-:
-;
-+
-/
-\
-??
-??
-??
-ï¼?
-ï¼?
-??
-??
-ï¼?
-ï¼?
-ï¼?
-Â·
-ï¼?
-??
-??
-ï¼?
-ï¼?
-??
-??
-ï¼?
-ï¼?
-??
-// the line below contains an IDEOGRAPHIC SPACE character (Used as a space in Chinese)
-??
-
-//////////////// English Stop Words ////////////////
-
-//////////////// Chinese Stop Words ////////////////
diff --git a/contrib/analyzers/smartcn/src/test/org/apache/lucene/analysis/cn/TestSmartChineseAnalyzer.java b/contrib/analyzers/smartcn/src/test/org/apache/lucene/analysis/cn/TestSmartChineseAnalyzer.java
deleted file mode 100644
index 8fce34a..0000000
--- a/contrib/analyzers/smartcn/src/test/org/apache/lucene/analysis/cn/TestSmartChineseAnalyzer.java
+++ /dev/null
@@ -1,152 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.lucene.analysis.cn;
-
-import java.io.FileNotFoundException;
-import java.io.IOException;
-import java.io.Reader;
-import java.io.UnsupportedEncodingException;
-import java.util.Date;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.Analyzer;
-
-public class TestSmartChineseAnalyzer extends BaseTokenStreamTestCase {
-  
-  public void testChineseStopWordsDefault() throws Exception {
-    Analyzer ca = new SmartChineseAnalyzer(); /* will load stopwords */
-    String sentence = "??´­ä¹°ä???????è£???";
-    String result[] = { "??", "è´?¹°", "äº?", "???", "??", "???" };
-    assertAnalyzesTo(ca, sentence, result);
-  }
-  
-  /*
-   * This test is the same as the above, except with two phrases.
-   * This tests to ensure the SentenceTokenizer->WordTokenFilter chain works correctly.
-   */
-  public void testChineseStopWordsDefaultTwoPhrases() throws Exception {
-    Analyzer ca = new SmartChineseAnalyzer(); /* will load stopwords */
-    String sentence = "??´­ä¹°ä???????è£??? ??´­ä¹°ä???????è£???";
-    String result[] = { "??", "è´?¹°", "äº?", "???", "??", "???", "??", "è´?¹°", "äº?", "???", "??", "???" };
-    assertAnalyzesTo(ca, sentence, result);
-  }
-  
-  /*
-   * This test is the same as the above, except using an ideographic space as a separator.
-   * This tests to ensure the stopwords are working correctly.
-   */
-  public void testChineseStopWordsDefaultTwoPhrasesIdeoSpace() throws Exception {
-    Analyzer ca = new SmartChineseAnalyzer(); /* will load stopwords */
-    String sentence = "??´­ä¹°ä???????è£?????´­ä¹°ä???????è£???";
-    String result[] = { "??", "è´?¹°", "äº?", "???", "??", "???", "??", "è´?¹°", "äº?", "???", "??", "???" };
-    assertAnalyzesTo(ca, sentence, result);
-  }
-  
-  /*
-   * Punctuation is handled in a strange way if you disable stopwords
-   * In this example the IDEOGRAPHIC FULL STOP is converted into a comma.
-   * if you don't supply (true) to the constructor, or use a different stopwords list,
-   * then punctuation is indexed.
-   */
-  public void testChineseStopWordsOff() throws Exception {  
-    Analyzer ca = new SmartChineseAnalyzer(false); /* doesnt load stopwords */
-    String sentence = "??´­ä¹°ä???????è£???";
-    String result[] = { "??", "è´?¹°", "äº?", "???", "??", "???", "," };
-    assertAnalyzesTo(ca, sentence, result);
-  }
-  
-  public void testChineseAnalyzer() throws Exception {
-    Analyzer ca = new SmartChineseAnalyzer(true);
-    String sentence = "??´­ä¹°ä???????è£???";
-    String[] result = { "??", "è´?¹°", "äº?", "???", "??", "???" };
-    assertAnalyzesTo(ca, sentence, result);
-  }
-  
-  /*
-   * English words are lowercased and porter-stemmed.
-   */
-  public void testMixedLatinChinese() throws Exception {
-    assertAnalyzesTo(new SmartChineseAnalyzer(true), "??´­ä¹? Tests äº???·å????", 
-        new String[] { "??", "è´?¹°", "test", "äº?", "???", "??", "???"});
-  }
-  
-  /*
-   * Numerics are parsed as their own tokens
-   */
-  public void testNumerics() throws Exception {
-    assertAnalyzesTo(new SmartChineseAnalyzer(true), "??´­ä¹? Tests äº???·å????1234",
-      new String[] { "??", "è´?¹°", "test", "äº?", "???", "??", "???", "1234"});
-  }
-  
-  /*
-   * Full width alphas and numerics are folded to half-width
-   */
-  public void testFullWidth() throws Exception {
-    assertAnalyzesTo(new SmartChineseAnalyzer(true), "??´­ä¹? ï¼´ï?ï½??ï½? äº???·å????ï¼??ï¼??",
-        new String[] { "??", "è´?¹°", "test", "äº?", "???", "??", "???", "1234"});
-  }
-  
-  /*
-   * Presentation form delimiters are removed
-   */
-  public void testDelimiters() throws Exception {
-    assertAnalyzesTo(new SmartChineseAnalyzer(true), "??´­ä¹°ï¸± Tests äº???·å????", 
-        new String[] { "??", "è´?¹°", "test", "äº?", "???", "??", "???"});
-  }
-  
-  /*
-   * Text from writing systems other than Chinese and Latin are parsed as individual characters.
-   * (regardless of Unicode category)
-   */
-  public void testNonChinese() throws Exception {
-    assertAnalyzesTo(new SmartChineseAnalyzer(true), "??´­ä¹? Ø±?Ø¨Ø±ØªTests äº???·å????", 
-        new String[] { "??", "è´?¹°", "Ø±", "?", "Ø¨", "Ø±", "Øª", "test", "äº?", "???", "??", "???"});
-  }
-  
-  /*
-   * Test what the analyzer does with out-of-vocabulary words.
-   * In this case the name is Yousaf Raza Gillani.
-   * Currently it is being analyzed into single characters...
-   */
-  public void testOOV() throws Exception {
-    assertAnalyzesTo(new SmartChineseAnalyzer(true), "ä¼??ç¦?·æ???·å???°¼",
-      new String[] { "ä¼?", "ç´?", "ç¦?", "??", "??", "??", "??", "å°?" });
-    
-    assertAnalyzesTo(new SmartChineseAnalyzer(true), "ä¼??ç¦???????°¼",
-      new String[] { "ä¼?", "ç´?", "ç¦?", "??", "??", "??", "??", "å°?" });
-  }
-  
-  public void testOffsets() throws Exception {
-    assertAnalyzesTo(new SmartChineseAnalyzer(true), "??´­ä¹°ä???????è£?",
-        new String[] { "??", "è´?¹°", "äº?", "???", "??", "???" },
-        new int[] { 0, 1, 3, 4, 6, 7 },
-        new int[] { 1, 3, 4, 6, 7, 9 });
-  }
-  
-  public void testReusableTokenStream() throws Exception {
-    Analyzer a = new SmartChineseAnalyzer();
-    assertAnalyzesToReuse(a, "??´­ä¹? Tests äº???·å????", 
-        new String[] { "??", "è´?¹°", "test", "äº?", "???", "??", "???"},
-        new int[] { 0, 1, 4, 10, 11, 13, 14 },
-        new int[] { 1, 3, 9, 11, 13, 14, 16 });
-    assertAnalyzesToReuse(a, "??´­ä¹°ä???????è£???",
-        new String[] { "??", "è´?¹°", "äº?", "???", "??", "???" },
-        new int[] { 0, 1, 3, 4, 6, 7 },
-        new int[] { 1, 3, 4, 6, 7, 9 });
-  }
-}
diff --git a/contrib/analyzers/smartcn/src/test/org/apache/lucene/analysis/cn/smart/TestSmartChineseAnalyzer.java b/contrib/analyzers/smartcn/src/test/org/apache/lucene/analysis/cn/smart/TestSmartChineseAnalyzer.java
new file mode 100644
index 0000000..cc4031d
--- /dev/null
+++ b/contrib/analyzers/smartcn/src/test/org/apache/lucene/analysis/cn/smart/TestSmartChineseAnalyzer.java
@@ -0,0 +1,152 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.lucene.analysis.cn.smart;
+
+import java.io.FileNotFoundException;
+import java.io.IOException;
+import java.io.Reader;
+import java.io.UnsupportedEncodingException;
+import java.util.Date;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.Analyzer;
+
+public class TestSmartChineseAnalyzer extends BaseTokenStreamTestCase {
+  
+  public void testChineseStopWordsDefault() throws Exception {
+    Analyzer ca = new SmartChineseAnalyzer(); /* will load stopwords */
+    String sentence = "??´­ä¹°ä???????è£???";
+    String result[] = { "??", "è´?¹°", "äº?", "???", "??", "???" };
+    assertAnalyzesTo(ca, sentence, result);
+  }
+  
+  /*
+   * This test is the same as the above, except with two phrases.
+   * This tests to ensure the SentenceTokenizer->WordTokenFilter chain works correctly.
+   */
+  public void testChineseStopWordsDefaultTwoPhrases() throws Exception {
+    Analyzer ca = new SmartChineseAnalyzer(); /* will load stopwords */
+    String sentence = "??´­ä¹°ä???????è£??? ??´­ä¹°ä???????è£???";
+    String result[] = { "??", "è´?¹°", "äº?", "???", "??", "???", "??", "è´?¹°", "äº?", "???", "??", "???" };
+    assertAnalyzesTo(ca, sentence, result);
+  }
+  
+  /*
+   * This test is the same as the above, except using an ideographic space as a separator.
+   * This tests to ensure the stopwords are working correctly.
+   */
+  public void testChineseStopWordsDefaultTwoPhrasesIdeoSpace() throws Exception {
+    Analyzer ca = new SmartChineseAnalyzer(); /* will load stopwords */
+    String sentence = "??´­ä¹°ä???????è£?????´­ä¹°ä???????è£???";
+    String result[] = { "??", "è´?¹°", "äº?", "???", "??", "???", "??", "è´?¹°", "äº?", "???", "??", "???" };
+    assertAnalyzesTo(ca, sentence, result);
+  }
+  
+  /*
+   * Punctuation is handled in a strange way if you disable stopwords
+   * In this example the IDEOGRAPHIC FULL STOP is converted into a comma.
+   * if you don't supply (true) to the constructor, or use a different stopwords list,
+   * then punctuation is indexed.
+   */
+  public void testChineseStopWordsOff() throws Exception {  
+    Analyzer ca = new SmartChineseAnalyzer(false); /* doesnt load stopwords */
+    String sentence = "??´­ä¹°ä???????è£???";
+    String result[] = { "??", "è´?¹°", "äº?", "???", "??", "???", "," };
+    assertAnalyzesTo(ca, sentence, result);
+  }
+  
+  public void testChineseAnalyzer() throws Exception {
+    Analyzer ca = new SmartChineseAnalyzer(true);
+    String sentence = "??´­ä¹°ä???????è£???";
+    String[] result = { "??", "è´?¹°", "äº?", "???", "??", "???" };
+    assertAnalyzesTo(ca, sentence, result);
+  }
+  
+  /*
+   * English words are lowercased and porter-stemmed.
+   */
+  public void testMixedLatinChinese() throws Exception {
+    assertAnalyzesTo(new SmartChineseAnalyzer(true), "??´­ä¹? Tests äº???·å????", 
+        new String[] { "??", "è´?¹°", "test", "äº?", "???", "??", "???"});
+  }
+  
+  /*
+   * Numerics are parsed as their own tokens
+   */
+  public void testNumerics() throws Exception {
+    assertAnalyzesTo(new SmartChineseAnalyzer(true), "??´­ä¹? Tests äº???·å????1234",
+      new String[] { "??", "è´?¹°", "test", "äº?", "???", "??", "???", "1234"});
+  }
+  
+  /*
+   * Full width alphas and numerics are folded to half-width
+   */
+  public void testFullWidth() throws Exception {
+    assertAnalyzesTo(new SmartChineseAnalyzer(true), "??´­ä¹? ï¼´ï?ï½??ï½? äº???·å????ï¼??ï¼??",
+        new String[] { "??", "è´?¹°", "test", "äº?", "???", "??", "???", "1234"});
+  }
+  
+  /*
+   * Presentation form delimiters are removed
+   */
+  public void testDelimiters() throws Exception {
+    assertAnalyzesTo(new SmartChineseAnalyzer(true), "??´­ä¹°ï¸± Tests äº???·å????", 
+        new String[] { "??", "è´?¹°", "test", "äº?", "???", "??", "???"});
+  }
+  
+  /*
+   * Text from writing systems other than Chinese and Latin are parsed as individual characters.
+   * (regardless of Unicode category)
+   */
+  public void testNonChinese() throws Exception {
+    assertAnalyzesTo(new SmartChineseAnalyzer(true), "??´­ä¹? Ø±?Ø¨Ø±ØªTests äº???·å????", 
+        new String[] { "??", "è´?¹°", "Ø±", "?", "Ø¨", "Ø±", "Øª", "test", "äº?", "???", "??", "???"});
+  }
+  
+  /*
+   * Test what the analyzer does with out-of-vocabulary words.
+   * In this case the name is Yousaf Raza Gillani.
+   * Currently it is being analyzed into single characters...
+   */
+  public void testOOV() throws Exception {
+    assertAnalyzesTo(new SmartChineseAnalyzer(true), "ä¼??ç¦?·æ???·å???°¼",
+      new String[] { "ä¼?", "ç´?", "ç¦?", "??", "??", "??", "??", "å°?" });
+    
+    assertAnalyzesTo(new SmartChineseAnalyzer(true), "ä¼??ç¦???????°¼",
+      new String[] { "ä¼?", "ç´?", "ç¦?", "??", "??", "??", "??", "å°?" });
+  }
+  
+  public void testOffsets() throws Exception {
+    assertAnalyzesTo(new SmartChineseAnalyzer(true), "??´­ä¹°ä???????è£?",
+        new String[] { "??", "è´?¹°", "äº?", "???", "??", "???" },
+        new int[] { 0, 1, 3, 4, 6, 7 },
+        new int[] { 1, 3, 4, 6, 7, 9 });
+  }
+  
+  public void testReusableTokenStream() throws Exception {
+    Analyzer a = new SmartChineseAnalyzer();
+    assertAnalyzesToReuse(a, "??´­ä¹? Tests äº???·å????", 
+        new String[] { "??", "è´?¹°", "test", "äº?", "???", "??", "???"},
+        new int[] { 0, 1, 4, 10, 11, 13, 14 },
+        new int[] { 1, 3, 9, 11, 13, 14, 16 });
+    assertAnalyzesToReuse(a, "??´­ä¹°ä???????è£???",
+        new String[] { "??", "è´?¹°", "äº?", "???", "??", "???" },
+        new int[] { 0, 1, 3, 4, 6, 7 },
+        new int[] { 1, 3, 4, 6, 7, 9 });
+  }
+}

