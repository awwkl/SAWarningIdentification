GitDiffStart: 950991783af0f4e20e2fd1470dd1c72e98c76f95 | Tue Dec 23 18:46:35 2003 +0000
diff --git a/sandbox/contributions/analyzers/src/java/org/apache/lucene/analysis/br/BrazilianAnalyzer.java b/sandbox/contributions/analyzers/src/java/org/apache/lucene/analysis/br/BrazilianAnalyzer.java
new file mode 100644
index 0000000..c790cb3
--- /dev/null
+++ b/sandbox/contributions/analyzers/src/java/org/apache/lucene/analysis/br/BrazilianAnalyzer.java
@@ -0,0 +1,120 @@
+package org.apache.lucene.analysis.br;
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.LowerCaseFilter;
+import org.apache.lucene.analysis.StopFilter;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.standard.StandardFilter;
+import org.apache.lucene.analysis.standard.StandardTokenizer;
+import java.io.File;
+import java.io.Reader;
+import java.util.Hashtable;
+
+/**
+ * Analyzer for brazilian language. Supports an external list of stopwords (words that
+ * will not be indexed at all) and an external list of exclusions (word that will
+ * not be stemmed, but indexed).
+ *
+ * @author    Jo? Kramer
+ * @version   $Id: BrazilianAnalyzer.java,v 1.0 2001/02/13 21:29:04
+ */
+public final class BrazilianAnalyzer extends Analyzer {
+
+	/**
+	 * List of typical german stopwords.
+	 */
+	private String[] BRAZILIAN_STOP_WORDS = {
+      "a","ainda","alem","ambas","ambos","antes",
+      "ao","aonde","aos","apos","aquele","aqueles",
+      "as","assim","com","como","contra","contudo",
+      "cuja","cujas","cujo","cujos","da","das","de",
+      "dela","dele","deles","demais","depois","desde",
+      "desta","deste","dispoe","dispoem","diversa",
+      "diversas","diversos","do","dos","durante","e",
+      "ela","elas","ele","eles","em","entao","entre",
+      "essa","essas","esse","esses","esta","estas",
+      "este","estes","ha","isso","isto","logo","mais",
+      "mas","mediante","menos","mesma","mesmas","mesmo",
+      "mesmos","na","nas","nao","nas","nem","nesse","neste",
+      "nos","o","os","ou","outra","outras","outro","outros",
+      "pelas","pelas","pelo","pelos","perante","pois","por",
+      "porque","portanto","proprio","propios","quais","qual",
+      "qualquer","quando","quanto","que","quem","quer","se",
+      "seja","sem","sendo","seu","seus","sob","sobre","sua",
+      "suas","tal","tambem","teu","teus","toda","todas","todo",
+      "todos","tua","tuas","tudo","um","uma","umas","uns"};
+
+
+	/**
+	 * Contains the stopwords used with the StopFilter.
+	 */
+	private Hashtable stoptable = new Hashtable();
+	/**
+	 * Contains words that should be indexed but not stemmed.
+	 */
+	private Hashtable excltable = new Hashtable();
+
+	/**
+	 * Builds an analyzer.
+	 */
+	public BrazilianAnalyzer() {
+		stoptable = StopFilter.makeStopTable( BRAZILIAN_STOP_WORDS );
+	}
+
+	/**
+	 * Builds an analyzer with the given stop words.
+	 */
+	public BrazilianAnalyzer( String[] stopwords ) {
+		stoptable = StopFilter.makeStopTable( stopwords );
+	}
+
+	/**
+	 * Builds an analyzer with the given stop words.
+	 */
+	public BrazilianAnalyzer( Hashtable stopwords ) {
+		stoptable = stopwords;
+	}
+
+	/**
+	 * Builds an analyzer with the given stop words.
+	 */
+	public BrazilianAnalyzer( File stopwords ) {
+		stoptable = WordlistLoader.getWordtable( stopwords );
+	}
+
+	/**
+	 * Builds an exclusionlist from an array of Strings.
+	 */
+	public void setStemExclusionTable( String[] exclusionlist ) {
+		excltable = StopFilter.makeStopTable( exclusionlist );
+	}
+	/**
+	 * Builds an exclusionlist from a Hashtable.
+	 */
+	public void setStemExclusionTable( Hashtable exclusionlist ) {
+		excltable = exclusionlist;
+	}
+	/**
+	 * Builds an exclusionlist from the words contained in the given file.
+	 */
+	public void setStemExclusionTable( File exclusionlist ) {
+		excltable = WordlistLoader.getWordtable( exclusionlist );
+	}
+	
+	/**
+	 * Creates a TokenStream which tokenizes all the text in the provided Reader.
+	 *
+	 * @return  A TokenStream build from a StandardTokenizer filtered with
+	 * 			StandardFilter, StopFilter, GermanStemFilter and LowerCaseFilter.
+	 */
+	public final TokenStream tokenStream(String fieldName, Reader reader) {
+		TokenStream result = new StandardTokenizer( reader );
+		result = new StandardFilter( result );
+		result = new StopFilter( result, stoptable );
+		result = new BrazilianStemFilter( result, excltable );
+		// Convert to lowercase after stemming!
+		result = new LowerCaseFilter( result );
+		return result;
+	}
+}
+
diff --git a/sandbox/contributions/analyzers/src/java/org/apache/lucene/analysis/br/BrazilianStemFilter.java b/sandbox/contributions/analyzers/src/java/org/apache/lucene/analysis/br/BrazilianStemFilter.java
new file mode 100644
index 0000000..64d0d28
--- /dev/null
+++ b/sandbox/contributions/analyzers/src/java/org/apache/lucene/analysis/br/BrazilianStemFilter.java
@@ -0,0 +1,67 @@
+package org.apache.lucene.analysis.br;
+
+import org.apache.lucene.analysis.Token;
+import org.apache.lucene.analysis.TokenFilter;
+import org.apache.lucene.analysis.TokenStream;
+import java.io.IOException;
+import java.util.Hashtable;
+
+/**
+ * Based on (copied) the GermanStemFilter
+ *
+ *
+ * @author    Jo? Kramer
+ *
+ *
+ * A filter that stemms german words. It supports a table of words that should
+ * not be stemmed at all.
+ *
+ * @author    Gerhard Schwarz
+ * @version   $Id$
+ */
+public final class BrazilianStemFilter extends TokenFilter {
+
+	/**
+	 * The actual token in the input stream.
+	 */
+	private Token token = null;
+	private BrazilianStemmer stemmer = null;
+	private Hashtable exclusions = null;
+
+	public BrazilianStemFilter( TokenStream in ) {
+		stemmer = new BrazilianStemmer();
+		input = in;
+	}
+
+	/**
+	 * Builds a BrazilianStemFilter that uses an exclusiontable.
+	 */
+	public BrazilianStemFilter( TokenStream in, Hashtable exclusiontable ) {
+		this( in );
+		this.exclusions = exclusions;
+	}
+
+	/**
+	 * @return  Returns the next token in the stream, or null at EOS.
+	 */
+	public final Token next()
+		throws IOException {
+		if ( ( token = input.next() ) == null ) {
+			return null;
+		}
+		// Check the exclusiontable.
+		else if ( exclusions != null && exclusions.contains( token.termText() ) ) {
+			return token;
+		}
+		else {
+			String s = stemmer.stem( token.termText() );
+			// If not stemmed, dont waste the time creating a new token.
+			if ( (s != null) && !s.equals( token.termText() ) ) {
+				return new Token( s, 0, s.length(), token.type() );
+			}
+			return token;
+		}
+	}
+}
+
+
diff --git a/sandbox/contributions/analyzers/src/java/org/apache/lucene/analysis/br/BrazilianStemmer.java b/sandbox/contributions/analyzers/src/java/org/apache/lucene/analysis/br/BrazilianStemmer.java
new file mode 100644
index 0000000..450d1e2
--- /dev/null
+++ b/sandbox/contributions/analyzers/src/java/org/apache/lucene/analysis/br/BrazilianStemmer.java
@@ -0,0 +1,1022 @@
+package org.apache.lucene.analysis.br;
+
+/**
+ * A stemmer for brazilian words. The algorithm is based on the report
+ * "A Fast and Simple Stemming Algorithm for German Words" by J?g
+ * Caumanns (joerg.caumanns@isst.fhg.de).
+ *
+ * @author    Gerhard Schwarz
+ * @version   $Id$
+ */
+
+public class BrazilianStemmer {
+
+	/**
+	 * Changed term
+	 */
+	private   String TERM ;
+	private   String CT ;
+	private   String R1 ;
+	private   String R2 ;
+	private   String RV ;
+
+
+	/**
+	 * Buffer for the terms while stemming them.
+	 */
+	private StringBuffer sb = new StringBuffer();
+	/**
+	 * Amount of characters that are removed with <tt>substitute()</tt> while stemming.
+	 */
+	private int substCount = 0;
+
+	public BrazilianStemmer() {
+	}
+
+	/**
+	 * Stemms the given term to an unique <tt>discriminator</tt>.
+	 *
+	 * @param word  The term that should be stemmed.
+	 * @return      Discriminator for <tt>term</tt>
+	 */
+	protected String stem( String term ) {
+    boolean altered = false ; // altered the term
+
+    // creates CT
+    createCT(term) ;
+    
+		if ( !isIndexable( CT ) ) {
+			return null;
+		}
+		if ( !isStemmable( CT ) ) {
+			return CT ;
+		}
+
+    R1 = getR1(CT) ;
+    R2 = getR1(R1) ;
+    RV = getRV(CT) ;
+    TERM = term + ";" +CT ;
+
+    altered = step1() ;
+    if (!altered) {
+      altered = step2() ;
+    }
+
+    if (altered) {
+      step3();
+    } else {
+      step4();
+    }
+
+    step5() ;
+
+    return CT ;
+	}
+
+	/**
+	 * Checks a term if it can be processed correctly.
+	 *
+	 * @return  true if, and only if, the given term consists in letters.
+	 */
+	private boolean isStemmable( String term ) {
+		for ( int c = 0; c < term.length(); c++ ) {
+			// Discard terms that contain non-letter characters.
+			if ( !Character.isLetter(term.charAt(c))) {
+				return false;
+			}
+		}
+		return true;
+	}
+
+	/**
+	 * Checks a term if it can be processed indexed.
+	 *
+	 * @return  true if it can be indexed
+	 */
+	private boolean isIndexable( String term ) {
+		return (term.length() < 30) && (term.length() > 2) ;
+	}
+
+	/**
+	 * See if string is 'a','e','i','o','u'
+   *
+   * @return true if is vowel
+	 */
+	private boolean isVowel( char value ) {
+    return (value == 'a') ||
+           (value == 'e') ||
+           (value == 'i') ||
+           (value == 'o') ||
+           (value == 'u') ;
+  }
+
+	/**
+	 * Gets R1
+   *
+   * R1 - is the region after the first non-vowel follwing a vowel,
+   *      or is the null region at the end of the word if there is
+   *      no such non-vowel.
+   *
+   * @return null or a string representing R1
+	 */
+	private String getR1( String value ) {
+    int     i;
+    int     j;
+    String  r1 = null ;
+
+    // be-safe !!!
+    if (value == null) {
+      return null ;
+    }
+
+    // find 1st vowel
+    i = value.length()-1 ;
+    for (j=0 ; j < i ; j++) {
+      if (isVowel(value.charAt(j))) {
+        break ;
+      }
+    }
+
+    if (!(j < i)) {
+      return null ;
+    }
+
+    // find 1st non-vowel
+    for ( ; j < i ; j++) {
+      if (!(isVowel(value.charAt(j)))) {
+        break ;
+      }
+    }
+
+    if (!(j < i)) {
+      return null ;
+    }
+
+    return value.substring(j+1) ;
+  }
+
+	/**
+	 * Gets RV
+   *
+   * RV - IF the second letter is a consoant, RV is the region after
+   *      the next following vowel,
+   *
+   *      OR if the first two letters are vowels, RV is the region
+   *      after the next consoant,
+   *
+   *      AND otherwise (consoant-vowel case) RV is the region after
+   *      the third letter.
+   *
+   *      BUT RV is the end of the word if this positions cannot be
+   *      found.
+   *
+   * @return null or a string representing RV
+	 */
+	private String getRV( String value ) {
+    int     i;
+    int     j;
+    String  r1 = null ;
+
+    // be-safe !!!
+    if (value == null) {
+      return null ;
+    }
+
+    i = value.length()-1 ;
+
+    // RV - IF the second letter is a consoant, RV is the region after
+    //      the next following vowel,
+    if ((i > 0) && !isVowel(value.charAt(1))) {
+      // find 1st vowel
+      for (j=2 ; j < i ; j++) {
+        if (isVowel(value.charAt(j))) {
+          break ;
+        }
+      }
+
+      if (j < i) {
+        return value.substring(j+1) ;
+      }
+    }
+
+
+    // RV - OR if the first two letters are vowels, RV is the region
+    //      after the next consoant,
+    if ((i > 1) &&
+        isVowel(value.charAt(0)) &&
+        isVowel(value.charAt(1))) {
+      // find 1st consoant
+      for (j=2 ; j < i ; j++) {
+        if (!isVowel(value.charAt(j))) {
+          break ;
+        }
+      }
+
+      if (j < i) {
+        return value.substring(j+1) ;
+      }
+    }
+
+    // RV - AND otherwise (consoant-vowel case) RV is the region after
+    //      the third letter.
+    if (i > 2) {
+      return value.substring(3) ;
+    }
+
+    return null ;
+  }
+
+	/**
+   * 1) Turn to lowercase
+   * 2) Remove accents
+   * 3) ? -> a ; ? -> o
+   * 4) ? -> c
+   *
+   * @return null or a string transformed
+	 */
+	private String changeTerm( String value ) {
+    int     i;
+    int     j;
+    String  r = "" ;
+
+    // be-safe !!!
+    if (value == null) {
+      return null ;
+    }
+
+    value = value.toLowerCase() ;
+    for (j=0 ; j < value.length() ; j++) {
+      if ((value.charAt(j) == '?') ||
+          (value.charAt(j) == '?') ||
+          (value.charAt(j) == '?')) {
+        r= r + "a" ; continue ;
+      }
+      if ((value.charAt(j) == '?') ||
+          (value.charAt(j) == '?')) {
+        r= r + "e" ; continue ;
+      }
+      if (value.charAt(j) == '?') {
+        r= r + "i" ; continue ;
+      }
+      if ((value.charAt(j) == '?') ||
+          (value.charAt(j) == '?') ||
+          (value.charAt(j) == '?')) {
+        r= r + "o" ; continue ;
+      }
+      if ((value.charAt(j) == '?') ||
+          (value.charAt(j) == '?')) {
+        r= r + "u" ; continue ;
+      }
+      if (value.charAt(j) == '?') {
+        r= r + "c" ; continue ;
+      }
+      if (value.charAt(j) == '?') {
+        r= r + "n" ; continue ;
+      }
+
+      r= r+ value.charAt(j) ;
+    }
+
+    return r ;
+  }
+
+	/**
+   * Check if a string ends with a suffix
+   *
+   * @return true if the string ends with the specified suffix
+	 */
+	private boolean suffix( String value, String suffix ) {
+
+    // be-safe !!!
+    if ((value == null) || (suffix == null)) {
+      return false ;
+    }
+
+    if (suffix.length() > value.length()) {
+      return false ;
+    }
+
+    return value.substring(value.length()-suffix.length()).equals(suffix);
+  }
+
+	/**
+   * Replace a string suffix by another
+   *
+   * @return the replaced String
+	 */
+	private String replaceSuffix( String value, String toReplace, String changeTo ) {
+    String vvalue ;
+
+    // be-safe !!!
+    if ((value == null) ||
+        (toReplace == null) ||
+        (changeTo == null) ) {
+      return value ;
+    }
+
+    vvalue = removeSuffix(value,toReplace) ;
+
+    if (value.equals(vvalue)) {
+      return value ;
+    } else {
+      return vvalue + changeTo ;
+    }
+  }
+
+	/**
+   * Remove a string suffix
+   *
+   * @return the String without the suffix
+	 */
+	private String removeSuffix( String value, String toRemove ) {
+    // be-safe !!!
+    if ((value == null) ||
+        (toRemove == null) ||
+        !suffix(value,toRemove) ) {
+      return value ;
+    }
+
+    return value.substring(0,value.length()-toRemove.length()) ;
+  }
+
+	/**
+   * See if a suffix is preceded by a String
+   *
+   * @return true if the suffix is preceded
+	 */
+	private boolean suffixPreceded( String value, String suffix, String preceded ) {
+    // be-safe !!!
+    if ((value == null) ||
+        (suffix == null) ||
+        (preceded == null) ||
+        !suffix(value,suffix) ) {
+      return false ;
+    }
+
+    return suffix(removeSuffix(value,suffix),preceded) ;
+  }
+
+	/**
+	 * Creates CT (changed term) , substituting * '?' and '?' for 'a~' and 'o~'.
+	 */
+	private void createCT( String term ) {
+    CT = changeTerm(term) ;
+
+    if (CT.length() < 2) return ;
+    
+    // if the first character is ... , remove it
+    if ((CT.charAt(0) == '"')  ||
+        (CT.charAt(0) == '\'') ||
+        (CT.charAt(0) == '-')  ||
+        (CT.charAt(0) == ',')  ||
+        (CT.charAt(0) == ';')  ||
+        (CT.charAt(0) == '.')  ||
+        (CT.charAt(0) == '?')  ||
+        (CT.charAt(0) == '!')
+        ) {
+        CT = CT.substring(1);
+    }
+
+    if (CT.length() < 2) return ;
+    
+    // if the last character is ... , remove it
+    if ((CT.charAt(CT.length()-1) == '-') ||
+        (CT.charAt(CT.length()-1) == ',') ||
+        (CT.charAt(CT.length()-1) == ';') ||
+        (CT.charAt(CT.length()-1) == '.') ||
+        (CT.charAt(CT.length()-1) == '?') ||
+        (CT.charAt(CT.length()-1) == '!') ||
+        (CT.charAt(CT.length()-1) == '\'') ||
+        (CT.charAt(CT.length()-1) == '"')
+        ) {
+        CT = CT.substring(0,CT.length()-1);
+    }
+  }
+
+
+	/**
+	 * Standart suffix removal.
+   * Search for the longest among the following suffixes, and perform
+   * the following actions:
+   *
+   * @return false if no ending was removed
+	 */
+	private boolean step1() {
+    if (CT == null) return false ;
+
+    // suffix lenght = 7
+    if (suffix(CT,"uciones") && suffix(R2,"uciones")) {
+        CT = replaceSuffix(CT,"uciones","u") ; return true;
+    }
+
+    // suffix lenght = 6
+    if (CT.length() >= 6) {
+      if (suffix(CT,"imentos") && suffix(R2,"imentos")) {
+          CT = removeSuffix(CT,"imentos") ; return true;
+      }
+      if (suffix(CT,"amentos") && suffix(R2,"amentos")) {
+          CT = removeSuffix(CT,"amentos") ; return true;
+      }
+      if (suffix(CT,"adores") && suffix(R2,"adores")) {
+          CT = removeSuffix(CT,"adores") ; return true;
+      }
+      if (suffix(CT,"adoras") && suffix(R2,"adoras")) {
+          CT = removeSuffix(CT,"adoras") ; return true;
+      }
+      if (suffix(CT,"logias") && suffix(R2,"logias")) {
+          replaceSuffix(CT,"logias","log") ; return true;
+      }
+      if (suffix(CT,"encias") && suffix(R2,"encias")) {
+          CT = replaceSuffix(CT,"encias","ente") ; return true;
+      }
+      if (suffix(CT,"amente") && suffix(R1,"amente")) {
+          CT = removeSuffix(CT,"amente") ; return true;
+      }
+      if (suffix(CT,"idades") && suffix(R2,"idades")) {
+          CT = removeSuffix(CT,"idades") ; return true;
+      }
+    }
+
+    // suffix lenght = 5
+    if (CT.length() >= 5) {
+      if (suffix(CT,"acoes") && suffix(R2,"acoes")) {
+          CT = removeSuffix(CT,"acoes") ; return true;
+      }
+      if (suffix(CT,"imento") && suffix(R2,"imento")) {
+          CT = removeSuffix(CT,"imento") ; return true;
+      }
+      if (suffix(CT,"amento") && suffix(R2,"amento")) {
+          CT = removeSuffix(CT,"amento") ; return true;
+      }
+      if (suffix(CT,"adora") && suffix(R2,"adora")) {
+          CT = removeSuffix(CT,"adora") ; return true;
+      }
+      if (suffix(CT,"ismos") && suffix(R2,"ismos")) {
+          CT = removeSuffix(CT,"ismos") ; return true;
+      }
+      if (suffix(CT,"istas") && suffix(R2,"istas")) {
+          CT = removeSuffix(CT,"istas") ; return true;
+      }
+      if (suffix(CT,"logia") && suffix(R2,"logia")) {
+          CT = replaceSuffix(CT,"logia","log") ; return true;
+      }
+      if (suffix(CT,"ucion") && suffix(R2,"ucion")) {
+          CT = replaceSuffix(CT,"ucion","u") ; return true;
+      }
+      if (suffix(CT,"encia") && suffix(R2,"encia")) {
+          CT = replaceSuffix(CT,"encia","ente") ; return true;
+      }
+      if (suffix(CT,"mente") && suffix(R2,"mente")) {
+          CT = removeSuffix(CT,"mente") ; return true;
+      }
+      if (suffix(CT,"idade") && suffix(R2,"idade")) {
+          CT = removeSuffix(CT,"idade") ; return true;
+      }
+    }
+
+    // suffix lenght = 4
+    if (CT.length() >= 4) {
+      if (suffix(CT,"acao") && suffix(R2,"acao")) {
+          CT = removeSuffix(CT,"acao") ; return true;
+      }
+      if (suffix(CT,"ezas") && suffix(R2,"ezas")) {
+          CT = removeSuffix(CT,"ezas") ; return true;
+      }
+      if (suffix(CT,"icos") && suffix(R2,"icos")) {
+          CT = removeSuffix(CT,"icos") ; return true ;
+      }
+      if (suffix(CT,"icas") && suffix(R2,"icas")) {
+          CT = removeSuffix(CT,"icas") ; return true ;
+      }
+      if (suffix(CT,"ismo") && suffix(R2,"ismo")) {
+          CT = removeSuffix(CT,"ismo") ; return true ;
+      }
+      if (suffix(CT,"avel") && suffix(R2,"avel")) {
+          CT = removeSuffix(CT,"avel") ; return true ;
+      }
+      if (suffix(CT,"ivel") && suffix(R2,"ivel")) {
+          CT = removeSuffix(CT,"ivel") ; return true ;
+      }
+      if (suffix(CT,"ista") && suffix(R2,"ista")) {
+          CT = removeSuffix(CT,"ista") ; return true ;
+      }
+      if (suffix(CT,"osos") && suffix(R2,"osos")) {
+          CT = removeSuffix(CT,"osos") ; return true ;
+      }
+      if (suffix(CT,"osas") && suffix(R2,"osas")) {
+          CT = removeSuffix(CT,"osas") ; return true ;
+      }
+      if (suffix(CT,"ador") && suffix(R2,"ador")) {
+          CT = removeSuffix(CT,"ador") ; return true ;
+      }
+      if (suffix(CT,"ivas") && suffix(R2,"ivas")) {
+          CT = removeSuffix(CT,"ivas") ; return true ;
+      }
+      if (suffix(CT,"ivos") && suffix(R2,"ivos")) {
+          CT = removeSuffix(CT,"ivos") ; return true ;
+      }
+      if (suffix(CT,"iras") &&
+          suffix(RV,"iras") &&
+          suffixPreceded(CT,"iras","e")) {
+          CT = replaceSuffix(CT,"iras","ir") ; return true ;
+      }
+    }
+
+    // suffix lenght = 3
+    if (CT.length() >= 3) {
+      if (suffix(CT,"eza") && suffix(R2,"eza")) {
+          CT = removeSuffix(CT,"eza") ; return true ;
+      }
+      if (suffix(CT,"ico") && suffix(R2,"ico")) {
+          CT = removeSuffix(CT,"ico") ; return true ;
+      }
+      if (suffix(CT,"ica") && suffix(R2,"ica")) {
+          CT = removeSuffix(CT,"ica") ; return true ;
+      }
+      if (suffix(CT,"oso") && suffix(R2,"oso")) {
+          CT = removeSuffix(CT,"oso") ; return true ;
+      }
+      if (suffix(CT,"osa") && suffix(R2,"osa")) {
+          CT = removeSuffix(CT,"osa") ; return true ;
+      }
+      if (suffix(CT,"iva") && suffix(R2,"iva")) {
+          CT = removeSuffix(CT,"iva") ; return true ;
+      }
+      if (suffix(CT,"ivo") && suffix(R2,"ivo")) {
+          CT = removeSuffix(CT,"ivo") ; return true ;
+      }
+      if (suffix(CT,"ira") &&
+          suffix(RV,"ira") &&
+          suffixPreceded(CT,"ira","e")) {
+          CT = replaceSuffix(CT,"ira","ir") ; return true ;
+      }
+    }
+
+    // no ending was removed by step1
+    return false ;
+  }
+
+
+	/**
+	 * Verb suffixes.
+   *
+   * Search for the longest among the following suffixes in RV,
+   * and if found, delete.
+   *
+   * @return false if no ending was removed
+	*/
+	private boolean step2() {
+    if (RV == null) return false ;
+
+    // suffix lenght = 7
+    if (RV.length() >= 7) {
+      if (suffix(RV,"issemos")) {
+        CT = removeSuffix(CT,"issemos") ; return true;
+      }
+      if (suffix(RV,"essemos")) {
+        CT = removeSuffix(CT,"essemos") ; return true;
+      }
+      if (suffix(RV,"assemos")) {
+        CT = removeSuffix(CT,"assemos") ; return true;
+      }
+      if (suffix(RV,"ariamos")) {
+        CT = removeSuffix(CT,"ariamos") ; return true;
+      }
+      if (suffix(RV,"eriamos")) {
+        CT = removeSuffix(CT,"eriamos") ; return true;
+      }
+      if (suffix(RV,"iriamos")) {
+        CT = removeSuffix(CT,"iriamos") ; return true;
+      }
+    }
+
+    // suffix lenght = 6
+    if (RV.length() >= 6) {
+      if (suffix(RV,"iremos")) {
+        CT = removeSuffix(CT,"iremos") ; return true;
+      }
+      if (suffix(RV,"eremos")) {
+        CT = removeSuffix(CT,"eremos") ; return true;
+      }
+      if (suffix(RV,"aremos")) {
+        CT = removeSuffix(CT,"aremos") ; return true;
+      }
+      if (suffix(RV,"avamos")) {
+        CT = removeSuffix(CT,"avamos") ; return true;
+      }
+      if (suffix(RV,"iramos")) {
+        CT = removeSuffix(CT,"iramos") ; return true;
+      }
+      if (suffix(RV,"eramos")) {
+        CT = removeSuffix(CT,"eramos") ; return true;
+      }
+      if (suffix(RV,"aramos")) {
+        CT = removeSuffix(CT,"aramos") ; return true;
+      }
+      if (suffix(RV,"asseis")) {
+        CT = removeSuffix(CT,"asseis") ; return true;
+      }
+      if (suffix(RV,"esseis")) {
+        CT = removeSuffix(CT,"esseis") ; return true;
+      }
+      if (suffix(RV,"isseis")) {
+        CT = removeSuffix(CT,"isseis") ; return true;
+      }
+      if (suffix(RV,"arieis")) {
+        CT = removeSuffix(CT,"arieis") ; return true;
+      }
+      if (suffix(RV,"erieis")) {
+        CT = removeSuffix(CT,"erieis") ; return true;
+      }
+      if (suffix(RV,"irieis")) {
+        CT = removeSuffix(CT,"irieis") ; return true;
+      }
+    }
+
+
+    // suffix lenght = 5
+    if (RV.length() >= 5) {
+      if (suffix(RV,"irmos")) {
+        CT = removeSuffix(CT,"irmos") ; return true;
+      }
+      if (suffix(RV,"iamos")) {
+        CT = removeSuffix(CT,"iamos") ; return true;
+      }
+      if (suffix(RV,"armos")) {
+        CT = removeSuffix(CT,"armos") ; return true;
+      }
+      if (suffix(RV,"ermos")) {
+        CT = removeSuffix(CT,"ermos") ; return true;
+      }
+      if (suffix(RV,"areis")) {
+        CT = removeSuffix(CT,"areis") ; return true;
+      }
+      if (suffix(RV,"ereis")) {
+        CT = removeSuffix(CT,"ereis") ; return true;
+      }
+      if (suffix(RV,"ireis")) {
+        CT = removeSuffix(CT,"ireis") ; return true;
+      }
+      if (suffix(RV,"asses")) {
+        CT = removeSuffix(CT,"asses") ; return true;
+      }
+      if (suffix(RV,"esses")) {
+        CT = removeSuffix(CT,"esses") ; return true;
+      }
+      if (suffix(RV,"isses")) {
+        CT = removeSuffix(CT,"isses") ; return true;
+      }
+      if (suffix(RV,"astes")) {
+        CT = removeSuffix(CT,"astes") ; return true;
+      }
+      if (suffix(RV,"assem")) {
+        CT = removeSuffix(CT,"assem") ; return true;
+      }
+      if (suffix(RV,"essem")) {
+        CT = removeSuffix(CT,"essem") ; return true;
+      }
+      if (suffix(RV,"issem")) {
+        CT = removeSuffix(CT,"issem") ; return true;
+      }
+      if (suffix(RV,"ardes")) {
+        CT = removeSuffix(CT,"ardes") ; return true;
+      }
+      if (suffix(RV,"erdes")) {
+        CT = removeSuffix(CT,"erdes") ; return true;
+      }
+      if (suffix(RV,"irdes")) {
+        CT = removeSuffix(CT,"irdes") ; return true;
+      }
+      if (suffix(RV,"ariam")) {
+        CT = removeSuffix(CT,"ariam") ; return true;
+      }
+      if (suffix(RV,"eriam")) {
+        CT = removeSuffix(CT,"eriam") ; return true;
+      }
+      if (suffix(RV,"iriam")) {
+        CT = removeSuffix(CT,"iriam") ; return true;
+      }
+      if (suffix(RV,"arias")) {
+        CT = removeSuffix(CT,"arias") ; return true;
+      }
+      if (suffix(RV,"erias")) {
+        CT = removeSuffix(CT,"erias") ; return true;
+      }
+      if (suffix(RV,"irias")) {
+        CT = removeSuffix(CT,"irias") ; return true;
+      }
+      if (suffix(RV,"estes")) {
+        CT = removeSuffix(CT,"estes") ; return true;
+      }
+      if (suffix(RV,"istes")) {
+        CT = removeSuffix(CT,"istes") ; return true;
+      }
+      if (suffix(RV,"areis")) {
+        CT = removeSuffix(CT,"areis") ; return true;
+      }
+      if (suffix(RV,"aveis")) {
+        CT = removeSuffix(CT,"aveis") ; return true;
+      }
+    }
+
+    // suffix lenght = 4
+    if (RV.length() >= 4) {
+      if (suffix(RV,"aria")) {
+        CT = removeSuffix(CT,"aria") ; return true;
+      }
+      if (suffix(RV,"eria")) {
+        CT = removeSuffix(CT,"eria") ; return true;
+      }
+      if (suffix(RV,"iria")) {
+        CT = removeSuffix(CT,"iria") ; return true;
+      }
+      if (suffix(RV,"asse")) {
+        CT = removeSuffix(CT,"asse") ; return true;
+      }
+      if (suffix(RV,"esse")) {
+        CT = removeSuffix(CT,"esse") ; return true;
+      }
+      if (suffix(RV,"isse")) {
+        CT = removeSuffix(CT,"isse") ; return true;
+      }
+      if (suffix(RV,"aste")) {
+        CT = removeSuffix(CT,"aste") ; return true;
+      }
+      if (suffix(RV,"este")) {
+        CT = removeSuffix(CT,"este") ; return true;
+      }
+      if (suffix(RV,"iste")) {
+        CT = removeSuffix(CT,"iste") ; return true;
+      }
+      if (suffix(RV,"arei")) {
+        CT = removeSuffix(CT,"arei") ; return true;
+      }
+      if (suffix(RV,"erei")) {
+        CT = removeSuffix(CT,"erei") ; return true;
+      }
+      if (suffix(RV,"irei")) {
+        CT = removeSuffix(CT,"irei") ; return true;
+      }
+      if (suffix(RV,"aram")) {
+        CT = removeSuffix(CT,"aram") ; return true;
+      }
+      if (suffix(RV,"eram")) {
+        CT = removeSuffix(CT,"eram") ; return true;
+      }
+      if (suffix(RV,"iram")) {
+        CT = removeSuffix(CT,"iram") ; return true;
+      }
+      if (suffix(RV,"avam")) {
+        CT = removeSuffix(CT,"avam") ; return true;
+      }
+      if (suffix(RV,"arem")) {
+        CT = removeSuffix(CT,"arem") ; return true;
+      }
+      if (suffix(RV,"erem")) {
+        CT = removeSuffix(CT,"erem") ; return true;
+      }
+      if (suffix(RV,"irem")) {
+        CT = removeSuffix(CT,"irem") ; return true;
+      }
+      if (suffix(RV,"ando")) {
+        CT = removeSuffix(CT,"ando") ; return true;
+      }
+      if (suffix(RV,"endo")) {
+        CT = removeSuffix(CT,"endo") ; return true;
+      }
+      if (suffix(RV,"indo")) {
+        CT = removeSuffix(CT,"indo") ; return true;
+      }
+      if (suffix(RV,"arao")) {
+        CT = removeSuffix(CT,"arao") ; return true;
+      }
+      if (suffix(RV,"erao")) {
+        CT = removeSuffix(CT,"erao") ; return true;
+      }
+      if (suffix(RV,"irao")) {
+        CT = removeSuffix(CT,"irao") ; return true;
+      }
+      if (suffix(RV,"adas")) {
+        CT = removeSuffix(CT,"adas") ; return true;
+      }
+      if (suffix(RV,"idas")) {
+        CT = removeSuffix(CT,"idas") ; return true;
+      }
+      if (suffix(RV,"aras")) {
+        CT = removeSuffix(CT,"aras") ; return true;
+      }
+      if (suffix(RV,"eras")) {
+        CT = removeSuffix(CT,"eras") ; return true;
+      }
+      if (suffix(RV,"iras")) {
+        CT = removeSuffix(CT,"iras") ; return true;
+      }
+      if (suffix(RV,"avas")) {
+        CT = removeSuffix(CT,"avas") ; return true;
+      }
+      if (suffix(RV,"ares")) {
+        CT = removeSuffix(CT,"ares") ; return true;
+      }
+      if (suffix(RV,"eres")) {
+        CT = removeSuffix(CT,"eres") ; return true;
+      }
+      if (suffix(RV,"ires")) {
+        CT = removeSuffix(CT,"ires") ; return true;
+      }
+      if (suffix(RV,"ados")) {
+        CT = removeSuffix(CT,"ados") ; return true;
+      }
+      if (suffix(RV,"idos")) {
+        CT = removeSuffix(CT,"idos") ; return true;
+      }
+      if (suffix(RV,"amos")) {
+        CT = removeSuffix(CT,"amos") ; return true;
+      }
+      if (suffix(RV,"emos")) {
+        CT = removeSuffix(CT,"emos") ; return true;
+      }
+      if (suffix(RV,"imos")) {
+        CT = removeSuffix(CT,"imos") ; return true;
+      }
+      if (suffix(RV,"iras")) {
+        CT = removeSuffix(CT,"iras") ; return true;
+      }
+      if (suffix(RV,"ieis")) {
+        CT = removeSuffix(CT,"ieis") ; return true;
+      }
+    }
+
+    // suffix lenght = 3
+    if (RV.length() >= 3) {
+      if (suffix(RV,"ada")) {
+        CT = removeSuffix(CT,"ada") ; return true;
+      }
+      if (suffix(RV,"ida")) {
+        CT = removeSuffix(CT,"ida") ; return true;
+      }
+      if (suffix(RV,"ara")) {
+        CT = removeSuffix(CT,"ara") ; return true;
+      }
+      if (suffix(RV,"era")) {
+        CT = removeSuffix(CT,"era") ; return true;
+      }
+      if (suffix(RV,"ira")) {
+        CT = removeSuffix(CT,"ava") ; return true;
+      }
+      if (suffix(RV,"iam")) {
+        CT = removeSuffix(CT,"iam") ; return true;
+      }
+      if (suffix(RV,"ado")) {
+        CT = removeSuffix(CT,"ado") ; return true;
+      }
+      if (suffix(RV,"ido")) {
+        CT = removeSuffix(CT,"ido") ; return true;
+      }
+      if (suffix(RV,"ias")) {
+        CT = removeSuffix(CT,"ias") ; return true;
+      }
+      if (suffix(RV,"ais")) {
+        CT = removeSuffix(CT,"ais") ; return true;
+      }
+      if (suffix(RV,"eis")) {
+        CT = removeSuffix(CT,"eis") ; return true;
+      }
+      if (suffix(RV,"ira")) {
+        CT = removeSuffix(CT,"ira") ; return true;
+      }
+      if (suffix(RV,"ear")) {
+        CT = removeSuffix(CT,"ear") ; return true;
+      }
+    }
+
+    // suffix lenght = 2
+    if (RV.length() >= 2) {
+      if (suffix(RV,"ia")) {
+        CT = removeSuffix(CT,"ia") ; return true;
+      }
+      if (suffix(RV,"ei")) {
+        CT = removeSuffix(CT,"ei") ; return true;
+      }
+      if (suffix(RV,"am")) {
+        CT = removeSuffix(CT,"am") ; return true;
+      }
+      if (suffix(RV,"em")) {
+        CT = removeSuffix(CT,"em") ; return true;
+      }
+      if (suffix(RV,"ar")) {
+        CT = removeSuffix(CT,"ar") ; return true;
+      }
+      if (suffix(RV,"er")) {
+        CT = removeSuffix(CT,"er") ; return true;
+      }
+      if (suffix(RV,"ir")) {
+        CT = removeSuffix(CT,"ir") ; return true;
+      }
+      if (suffix(RV,"as")) {
+        CT = removeSuffix(CT,"as") ; return true;
+      }
+      if (suffix(RV,"es")) {
+        CT = removeSuffix(CT,"es") ; return true;
+      }
+      if (suffix(RV,"is")) {
+        CT = removeSuffix(CT,"is") ; return true;
+      }
+      if (suffix(RV,"eu")) {
+        CT = removeSuffix(CT,"eu") ; return true;
+      }
+      if (suffix(RV,"iu")) {
+        CT = removeSuffix(CT,"iu") ; return true;
+      }
+      if (suffix(RV,"iu")) {
+        CT = removeSuffix(CT,"iu") ; return true;
+      }
+      if (suffix(RV,"ou")) {
+        CT = removeSuffix(CT,"ou") ; return true;
+      }
+    }
+
+    // no ending was removed by step2
+    return false ;
+  }
+
+	/**
+	 * Delete suffix 'i' if in RV and preceded by 'c'
+   *
+	*/
+	private void step3() {
+    if (RV == null) return ;
+
+    if (suffix(RV,"i") && suffixPreceded(RV,"i","c")) {
+      CT = removeSuffix(CT,"i") ;
+    }
+
+  }
+
+	/**
+	 * Residual suffix
+   *
+   * If the word ends with one of the suffixes (os a i o ? ? ?)
+   * in RV, delete it
+   *
+	*/
+	private void step4() {
+    if (RV == null) return  ;
+
+    if (suffix(RV,"os")) {
+      CT = removeSuffix(CT,"os") ; return ;
+    }
+    if (suffix(RV,"a")) {
+      CT = removeSuffix(CT,"a") ; return ;
+    }
+    if (suffix(RV,"i")) {
+      CT = removeSuffix(CT,"i") ; return ;
+    }
+    if (suffix(RV,"o")) {
+      CT = removeSuffix(CT,"o") ; return ;
+    }
+
+  }
+
+	/**
+	 * If the word ends with one of ( e ? ?) in RV,delete it,
+   * and if preceded by 'gu' (or 'ci') with the 'u' (or 'i') in RV,
+   * delete the 'u' (or 'i')
+   *
+   * Or if the word ends ? remove the cedilha
+   *
+	*/
+	private void step5() {
+    if (RV == null) return  ;
+
+    if (suffix(RV,"e")) {
+      if (suffixPreceded(RV,"e","gu")) {
+        CT = removeSuffix(CT,"e") ;
+        CT = removeSuffix(CT,"u") ;
+        return ;
+      }
+
+      if (suffixPreceded(RV,"e","ci")) {
+        CT = removeSuffix(CT,"e") ;
+        CT = removeSuffix(CT,"i") ;
+        return ;
+      }
+
+      CT = removeSuffix(CT,"e") ; return ;
+    }
+  }
+
+	/**
+	 * For log and debug purpose
+	 *
+	 * @return  TERM, CT, RV, R1 and R2
+	 */
+	public String log() {
+    return " (TERM = " + TERM + ")" +
+           " (CT = " + CT +")" +
+           " (RV = " + RV +")" +
+           " (R1 = " + R1 +")" +
+           " (R2 = " + R2 +")" ;
+	}
+
+}
+
diff --git a/sandbox/contributions/analyzers/src/java/org/apache/lucene/analysis/br/WordlistLoader.java b/sandbox/contributions/analyzers/src/java/org/apache/lucene/analysis/br/WordlistLoader.java
new file mode 100644
index 0000000..d5a8cf2
--- /dev/null
+++ b/sandbox/contributions/analyzers/src/java/org/apache/lucene/analysis/br/WordlistLoader.java
@@ -0,0 +1,85 @@
+package org.apache.lucene.analysis.br;
+
+import java.io.File;
+import java.io.FileReader;
+import java.io.IOException;
+import java.io.LineNumberReader;
+import java.util.Hashtable;
+
+/**
+ * Loads a textfile and adds every entry to a Hashtable. If a file is not found
+ * or on any error, an empty table is returned.
+ *
+ * @author    Gerhard Schwarz
+ * @version   $Id$
+ */
+public class WordlistLoader {
+
+	/**
+	 * @param path      Path to the wordlist.
+	 * @param wordfile  Name of the wordlist.
+	 */
+	public static Hashtable getWordtable( String path, String wordfile ) {
+		if ( path == null || wordfile == null ) {
+			return new Hashtable();
+		}
+		File absoluteName = new File( path, wordfile );
+		return getWordtable( absoluteName );
+	}
+	/**
+	 * @param wordfile  Complete path to the wordlist
+	 */
+	public static Hashtable getWordtable( String wordfile ) {
+		if ( wordfile == null ) {
+			return new Hashtable();
+		}
+		File absoluteName = new File( wordfile );
+		return getWordtable( absoluteName );
+	}
+
+	/**
+	 * @param wordfile  File containing the wordlist.
+	 */
+	public static Hashtable getWordtable( File wordfile ) {
+		if ( wordfile == null ) {
+			return new Hashtable();
+		}
+		Hashtable result = null;
+		try {
+			LineNumberReader lnr = new LineNumberReader( new FileReader( wordfile ) );
+			String word = null;
+			String[] stopwords = new String[100];
+			int wordcount = 0;
+			while ( ( word = lnr.readLine() ) != null ) {
+				wordcount++;
+				if ( wordcount == stopwords.length ) {
+					String[] tmp = new String[stopwords.length + 50];
+					System.arraycopy( stopwords, 0, tmp, 0, wordcount );
+					stopwords = tmp;
+				}
+				stopwords[wordcount] = word;
+			}
+			result = makeWordTable( stopwords, wordcount );
+		}
+		// On error, use an empty table.
+		catch ( IOException e ) {
+			result = new Hashtable();
+		}
+		return result;
+	}
+
+	/**
+	 * Builds the wordlist table.
+	 *
+	 * @param words   Word that where read.
+	 * @param length  Amount of words that where read into <tt>words</tt>.
+	 */
+	private static Hashtable makeWordTable( String[] words, int length ) {
+		Hashtable table = new Hashtable( length );
+		for ( int i = 0; i < length; i++ ) {
+			table.put( words[i], words[i] );
+		}
+		return table;
+	}
+}
+
diff --git a/sandbox/contributions/analyzers/src/java/org/apache/lucene/analysis/cjk/CJKAnalyzer.java b/sandbox/contributions/analyzers/src/java/org/apache/lucene/analysis/cjk/CJKAnalyzer.java
new file mode 100644
index 0000000..da97fa4
--- /dev/null
+++ b/sandbox/contributions/analyzers/src/java/org/apache/lucene/analysis/cjk/CJKAnalyzer.java
@@ -0,0 +1,127 @@
+/* ====================================================================
+ * The Apache Software License, Version 1.1
+ *
+ * Copyright (c) 2001 The Apache Software Foundation.  All rights
+ * reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in
+ *    the documentation and/or other materials provided with the
+ *    distribution.
+ *
+ * 3. The end-user documentation included with the redistribution,
+ *    if any, must include the following acknowledgment:
+ *       "This product includes software developed by the
+ *        Apache Software Foundation (http://www.apache.org/)."
+ *    Alternately, this acknowledgment may appear in the software itself,
+ *    if and wherever such third-party acknowledgments normally appear.
+ *
+ * 4. The names "Apache" and "Apache Software Foundation" and
+ *    "Apache Lucene" must not be used to endorse or promote products
+ *    derived from this software without prior written permission. For
+ *    written permission, please contact apache@apache.org.
+ *
+ * 5. Products derived from this software may not be called "Apache",
+ *    "Apache Lucene", nor may "Apache" appear in their name, without
+ *    prior written permission of the Apache Software Foundation.
+ *
+ * THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESSED OR IMPLIED
+ * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+ * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED.  IN NO EVENT SHALL THE APACHE SOFTWARE FOUNDATION OR
+ * ITS CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
+ * USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+ * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT
+ * OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
+ * SUCH DAMAGE.
+ * ====================================================================
+ *
+ * This software consists of voluntary contributions made by many
+ * individuals on behalf of the Apache Software Foundation.  For more
+ * information on the Apache Software Foundation, please see
+ * <http://www.apache.org/>.
+ *
+ * $Id$
+ */
+
+package org.apache.lucene.analysis.cjk;
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.StopFilter;
+import org.apache.lucene.analysis.TokenStream;
+
+import java.io.Reader;
+
+import java.util.Hashtable;
+
+
+/**
+ * Filters CJKTokenizer with StopFilter.
+ *
+ * @author Che, Dong
+ */
+public class CJKAnalyzer extends Analyzer {
+    //~ Static fields/initializers ---------------------------------------------
+
+    /**
+     * An array containing some common English words that are not usually
+     * useful for searching. and some double-byte interpunctions.....
+     */
+    private static String[] stopWords = {
+                                            "a", "and", "are", "as", "at", "be",
+                                            "but", "by", "for", "if", "in",
+                                            "into", "is", "it", "no", "not",
+                                            "of", "on", "or", "s", "such", "t",
+                                            "that", "the", "their", "then",
+                                            "there", "these", "they", "this",
+                                            "to", "was", "will", "with", "",
+                                            "www"
+                                        };
+
+    //~ Instance fields --------------------------------------------------------
+
+    /** stop word list */
+    private Hashtable stopTable;
+
+    //~ Constructors -----------------------------------------------------------
+
+    /**
+     * Builds an analyzer which removes words in STOP_WORDS.
+     */
+    public CJKAnalyzer() {
+        stopTable = StopFilter.makeStopTable(stopWords);
+    }
+
+    /**
+     * Builds an analyzer which removes words in the provided array.
+     *
+     * @param stopWords stop word array
+     */
+    public CJKAnalyzer(String[] stopWords) {
+        stopTable = StopFilter.makeStopTable(stopWords);
+    }
+
+    //~ Methods ----------------------------------------------------------------
+
+    /**
+     * get token stream from input
+     *
+     * @param fieldName lucene field name
+     * @param reader input reader
+     *
+     * @return TokenStream
+     */
+    public final TokenStream tokenStream(String fieldName, Reader reader) {
+        return new StopFilter(new CJKTokenizer(reader), stopTable);
+    }
+}
diff --git a/sandbox/contributions/analyzers/src/java/org/apache/lucene/analysis/cjk/CJKTokenizer.java b/sandbox/contributions/analyzers/src/java/org/apache/lucene/analysis/cjk/CJKTokenizer.java
new file mode 100644
index 0000000..7866cd8
--- /dev/null
+++ b/sandbox/contributions/analyzers/src/java/org/apache/lucene/analysis/cjk/CJKTokenizer.java
@@ -0,0 +1,284 @@
+/* ====================================================================
+ * The Apache Software License, Version 1.1
+ *
+ * Copyright (c) 2001 The Apache Software Foundation.  All rights
+ * reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in
+ *    the documentation and/or other materials provided with the
+ *    distribution.
+ *
+ * 3. The end-user documentation included with the redistribution,
+ *    if any, must include the following acknowledgment:
+ *       "This product includes software developed by the
+ *        Apache Software Foundation (http://www.apache.org/)."
+ *    Alternately, this acknowledgment may appear in the software itself,
+ *    if and wherever such third-party acknowledgments normally appear.
+ *
+ * 4. The names "Apache" and "Apache Software Foundation" and
+ *    "Apache Lucene" must not be used to endorse or promote products
+ *    derived from this software without prior written permission. For
+ *    written permission, please contact apache@apache.org.
+ *
+ * 5. Products derived from this software may not be called "Apache",
+ *    "Apache Lucene", nor may "Apache" appear in their name, without
+ *    prior written permission of the Apache Software Foundation.
+ *
+ * THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESSED OR IMPLIED
+ * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+ * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED.  IN NO EVENT SHALL THE APACHE SOFTWARE FOUNDATION OR
+ * ITS CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
+ * USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+ * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT
+ * OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
+ * SUCH DAMAGE.
+ * ====================================================================
+ *
+ * This software consists of voluntary contributions made by many
+ * individuals on behalf of the Apache Software Foundation.  For more
+ * information on the Apache Software Foundation, please see
+ * <http://www.apache.org/>.
+ *
+ * $Id$
+ */
+
+package org.apache.lucene.analysis.cjk;
+
+import org.apache.lucene.analysis.Token;
+import org.apache.lucene.analysis.Tokenizer;
+
+import java.io.Reader;
+
+
+/**
+ * <p>
+ * CJKTokenizer was modified from StopTokenizer which does a decent job for
+ * most European languages. and it perferm other token method for double-byte
+ * Characters: the token will return at each two charactors with overlap match.<br>
+ * Example: "java C1C2C3C4" will be segment to: "java" "C1C2" "C2C3" "C3C4" it
+ * also need filter filter zero length token ""<br>
+ * for Digit: digit, '+', '#' will token as letter<br>
+ * for more info on Asia language(Chinese Japanese Korean) text segmentation:
+ * please search  <a
+ * href="http://www.google.com/search?q=word+chinese+segment">google</a>
+ * </p>
+ *
+ * @author Che, Dong
+ */
+public final class CJKTokenizer extends Tokenizer {
+    //~ Static fields/initializers ---------------------------------------------
+
+    /** Max word length */
+    private static final int MAX_WORD_LEN = 255;
+
+    /** buffer size: */
+    private static final int IO_BUFFER_SIZE = 256;
+
+    //~ Instance fields --------------------------------------------------------
+
+    /** word offset, used to imply which character(in ) is parsed */
+    private int offset = 0;
+
+    /** the index used only for ioBuffer */
+    private int bufferIndex = 0;
+
+    /** data length */
+    private int dataLen = 0;
+
+    /**
+     * character buffer, store the characters which are used to compose <br>
+     * the returned Token
+     */
+    private final char[] buffer = new char[MAX_WORD_LEN];
+
+    /**
+     * I/O buffer, used to store the content of the input(one of the <br>
+     * members of Tokenizer)
+     */
+    private final char[] ioBuffer = new char[IO_BUFFER_SIZE];
+
+    /** word type: single=>ASCII  double=>non-ASCII word=>default */
+    private String tokenType = "word";
+
+    /**
+     * tag: previous character is a cached double-byte character  "C1C2C3C4"
+     * ----(set the C1 isTokened) C1C2 "C2C3C4" ----(set the C2 isTokened)
+     * C1C2 C2C3 "C3C4" ----(set the C3 isTokened) "C1C2 C2C3 C3C4"
+     */
+    private boolean preIsTokened = false;
+
+    //~ Constructors -----------------------------------------------------------
+
+    /**
+     * Construct a token stream processing the given input.
+     *
+     * @param in I/O reader
+     */
+    public CJKTokenizer(Reader in) {
+        input = in;
+    }
+
+    //~ Methods ----------------------------------------------------------------
+
+    /**
+     * Returns the next token in the stream, or null at EOS.
+     *
+     * @return Token
+     *
+     * @throws java.io.IOException - throw IOException when read error <br>
+     *         hanppened in the InputStream
+     *
+     * @see "http://java.sun.com/j2se/1.3/docs/api/java/lang/Character.UnicodeBlock.html"
+     *      for detail
+     */
+    public final Token next() throws java.io.IOException {
+        /** how many character(s) has been stored in buffer */
+        int length = 0;
+
+        /** the position used to create Token */
+        int start = offset;
+
+        while (true) {
+            /** current charactor */
+            char c;
+
+            /** unicode block of current charactor for detail */
+            Character.UnicodeBlock ub;
+
+            offset++;
+
+            if (bufferIndex >= dataLen) {
+                dataLen = input.read(ioBuffer);
+                bufferIndex = 0;
+            }
+
+            if (dataLen == -1) {
+                if (length > 0) {
+                    if (preIsTokened == true) {
+                        length = 0;
+                        preIsTokened = false;
+                    }
+
+                    break;
+                } else {
+                    return null;
+                }
+            } else {
+                //get current character
+                c = (char) ioBuffer[bufferIndex++];
+
+                //get the UnicodeBlock of the current character
+                ub = Character.UnicodeBlock.of(c);
+            }
+
+            //if the current character is ASCII or Extend ASCII
+            if ((ub == Character.UnicodeBlock.BASIC_LATIN)
+                    || (ub == Character.UnicodeBlock.HALFWIDTH_AND_FULLWIDTH_FORMS)
+               ) {
+                if (ub == Character.UnicodeBlock.HALFWIDTH_AND_FULLWIDTH_FORMS) {
+                    /** convert  HALFWIDTH_AND_FULLWIDTH_FORMS to BASIC_LATIN */
+                    int i = (int) c;
+                    i = i - 65248;
+                    c = (char) i;
+                }
+
+                // if the current character is a letter or "_" "+" "#"
+                if (Character.isLetterOrDigit(c)
+                        || ((c == '_') || (c == '+') || (c == '#'))
+                   ) {
+                    if (length == 0) {
+                        // "javaC1C2C3C4linux" <br>
+                        //      ^--: the current character begin to token the ASCII
+                        // letter
+                        start = offset - 1;
+                    } else if (tokenType == "double") {
+                        // "javaC1C2C3C4linux" <br>
+                        //              ^--: the previous non-ASCII
+                        // : the current character
+                        offset--;
+                        bufferIndex--;
+                        tokenType = "single";
+
+                        if (preIsTokened == true) {
+                            // there is only one non-ASCII has been stored
+                            length = 0;
+                            preIsTokened = false;
+
+                            break;
+                        } else {
+                            break;
+                        }
+                    }
+
+                    // store the LowerCase(c) in the buffer
+                    buffer[length++] = Character.toLowerCase(c);
+                    tokenType = "single";
+
+                    // break the procedure if buffer overflowed!
+                    if (length == MAX_WORD_LEN) {
+                        break;
+                    }
+                } else if (length > 0) {
+                    if (preIsTokened == true) {
+                        length = 0;
+                        preIsTokened = false;
+                    } else {
+                        break;
+                    }
+                }
+            } else {
+                // non-ASCII letter, eg."C1C2C3C4"
+                if (Character.isLetter(c)) {
+                    if (length == 0) {
+                        start = offset - 1;
+                        buffer[length++] = c;
+                        tokenType = "double";
+                    } else {
+                        if (tokenType == "single") {
+                            offset--;
+                            bufferIndex--;
+
+                            //return the previous ASCII characters
+                            break;
+                        } else {
+                            buffer[length++] = c;
+                            tokenType = "double";
+
+                            if (length == 2) {
+                                offset--;
+                                bufferIndex--;
+                                preIsTokened = true;
+
+                                break;
+                            }
+                        }
+                    }
+                } else if (length > 0) {
+                    if (preIsTokened == true) {
+                        // empty the buffer
+                        length = 0;
+                        preIsTokened = false;
+                    } else {
+                        break;
+                    }
+                }
+            }
+        }
+
+        return new Token(new String(buffer, 0, length), start, start + length,
+                         tokenType
+                        );
+    }
+}
diff --git a/sandbox/contributions/analyzers/src/java/org/apache/lucene/analysis/cz/CzechAnalyzer.java b/sandbox/contributions/analyzers/src/java/org/apache/lucene/analysis/cz/CzechAnalyzer.java
new file mode 100644
index 0000000..4ad9c6f
--- /dev/null
+++ b/sandbox/contributions/analyzers/src/java/org/apache/lucene/analysis/cz/CzechAnalyzer.java
@@ -0,0 +1,181 @@
+package org.apache.lucene.analysis.cz;
+
+/* ====================================================================
+ * The Apache Software License, Version 1.1
+ *
+ * Copyright (c) 2001 The Apache Software Foundation.  All rights
+ * reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in
+ *    the documentation and/or other materials provided with the
+ *    distribution.
+ *
+ * 3. The end-user documentation included with the redistribution,
+ *    if any, must include the following acknowledgment:
+ *       "This product includes software developed by the
+ *        Apache Software Foundation (http://www.apache.org/)."
+ *    Alternately, this acknowledgment may appear in the software itself,
+ *    if and wherever such third-party acknowledgments normally appear.
+ *
+ * 4. The names "Apache" and "Apache Software Foundation" and
+ *    "Apache Lucene" must not be used to endorse or promote products
+ *    derived from this software without prior written permission. For
+ *    written permission, please contact apache@apache.org.
+ *
+ * 5. Products derived from this software may not be called "Apache",
+ *    "Apache Lucene", nor may "Apache" appear in their name, without
+ *    prior written permission of the Apache Software Foundation.
+ *
+ * THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESSED OR IMPLIED
+ * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+ * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED.  IN NO EVENT SHALL THE APACHE SOFTWARE FOUNDATION OR
+ * ITS CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
+ * USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+ * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT
+ * OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
+ * SUCH DAMAGE.
+ * ====================================================================
+ *
+ * This software consists of voluntary contributions made by many
+ * individuals on behalf of the Apache Software Foundation.  For more
+ * information on the Apache Software Foundation, please see
+ * <http://www.apache.org/>.
+ */
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.LowerCaseFilter;
+import org.apache.lucene.analysis.StopFilter;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.de.WordlistLoader;
+import org.apache.lucene.analysis.standard.StandardFilter;
+import org.apache.lucene.analysis.standard.StandardTokenizer;
+
+import java.io.*;
+import java.util.Hashtable;
+
+/**
+ * Analyzer for Czech language. Supports an external list of stopwords (words that
+ * will not be indexed at all).
+ * A default set of stopwords is used unless an alternative list is specified, the
+ * exclusion list is empty by default.
+ *
+ * @author    Lukas Zapletal [lzap@root.cz]
+ */
+public final class CzechAnalyzer extends Analyzer {
+
+	/**
+	 * List of typical stopwords.
+	 */
+	private static String[] STOP_WORDS = {
+        "a","s","k","o","i","u","v","z","dnes","cz","t\u00edmto","bude\u0161","budem",
+        "byli","jse\u0161","m\u016fj","sv\u00fdm","ta","tomto","tohle","tuto","tyto",
+        "jej","zda","pro\u010d","m\u00e1te","tato","kam","tohoto","kdo","kte\u0159\u00ed",
+        "mi","n\u00e1m","tom","tomuto","m\u00edt","nic","proto","kterou","byla",
+        "toho","proto\u017ee","asi","ho","na\u0161i","napi\u0161te","re","co\u017e","t\u00edm",
+        "tak\u017ee","sv\u00fdch","jej\u00ed","sv\u00fdmi","jste","aj","tu","tedy","teto",
+        "bylo","kde","ke","prav\u00e9","ji","nad","nejsou","\u010di","pod","t\u00e9ma",
+        "mezi","p\u0159es","ty","pak","v\u00e1m","ani","kdy\u017e","v\u0161ak","neg","jsem",
+        "tento","\u010dl\u00e1nku","\u010dl\u00e1nky","aby","jsme","p\u0159ed","pta","jejich",
+        "byl","je\u0161t\u011b","a\u017e","bez","tak\u00e9","pouze","prvn\u00ed","va\u0161e","kter\u00e1",
+        "n\u00e1s","nov\u00fd","tipy","pokud","m\u016f\u017ee","strana","jeho","sv\u00e9","jin\u00e9",
+        "zpr\u00e1vy","nov\u00e9","nen\u00ed","v\u00e1s","jen","podle","zde","u\u017e","b\u00fdt","v\u00edce",
+        "bude","ji\u017e","ne\u017e","kter\u00fd","by","kter\u00e9","co","nebo","ten","tak",
+        "m\u00e1","p\u0159i","od","po","jsou","jak","dal\u0161\u00ed","ale","si","se","ve",
+        "to","jako","za","zp\u011bt","ze","do","pro","je","na","atd","atp",
+        "jakmile","p\u0159i\u010dem\u017e","j\u00e1","on","ona","ono","oni","ony","my","vy",
+        "j\u00ed","ji","m\u011b","mne","jemu","tomu","t\u011bm","t\u011bmu","n\u011bmu","n\u011bmu\u017e",
+        "jeho\u017e","j\u00ed\u017e","jeliko\u017e","je\u017e","jako\u017e","na\u010de\u017e",
+    };
+	
+	/**
+	 * Contains the stopwords used with the StopFilter.
+	 */
+	private Hashtable stoptable = new Hashtable();
+
+	/**
+	 * Builds an analyzer.
+	 */
+	public CzechAnalyzer() {
+		stoptable = StopFilter.makeStopTable( STOP_WORDS );
+	}
+
+	/**
+	 * Builds an analyzer with the given stop words.
+	 */
+	public CzechAnalyzer( String[] stopwords ) {
+		stoptable = StopFilter.makeStopTable( stopwords );
+	}
+
+	/**
+	 * Builds an analyzer with the given stop words.
+	 */
+	public CzechAnalyzer( Hashtable stopwords ) {
+		stoptable = stopwords;
+	}
+
+	/**
+	 * Builds an analyzer with the given stop words.
+	 */
+	public CzechAnalyzer( File stopwords ) {
+		stoptable = WordlistLoader.getWordtable( stopwords );
+	}
+
+    /**
+     * Loads stopwords hash from resource stream (file, database...).
+     * @param   wordfile    File containing the wordlist
+     * @param   encoding    Encoding used (win-1250, iso-8859-2, ...}, null for default system encoding
+     */
+    public void loadStopWords( InputStream wordfile, String encoding ) {
+        if ( wordfile == null ) {
+            stoptable = new Hashtable();
+            return;
+        }
+        try {
+            // clear any previous table (if present)
+            stoptable = new Hashtable();
+
+            InputStreamReader isr;
+            if (encoding == null)
+                isr = new InputStreamReader(wordfile);
+            else
+                isr = new InputStreamReader(wordfile, encoding);
+
+
+            LineNumberReader lnr = new LineNumberReader(isr);
+            String word;
+            while ( ( word = lnr.readLine() ) != null ) {
+                stoptable.put(word, word);
+            }
+
+        } catch ( IOException e ) {
+            stoptable = null;
+        }
+    }
+
+	/**
+	 * Creates a TokenStream which tokenizes all the text in the provided Reader.
+	 *
+	 * @return  A TokenStream build from a StandardTokenizer filtered with
+	 * 			StandardFilter, StopFilter, GermanStemFilter and LowerCaseFilter
+	 */
+	public final TokenStream tokenStream( String fieldName, Reader reader ) {
+		TokenStream result = new StandardTokenizer( reader );
+		result = new StandardFilter( result );
+		result = new LowerCaseFilter( result );
+        result = new StopFilter( result, stoptable );
+		return result;
+	}
+}
+

