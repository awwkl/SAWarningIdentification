GitDiffStart: 4ca4b6d6e399226befe0563cc16853bfd9f17050 | Tue Apr 28 20:09:41 2015 +0000
diff --git a/lucene/CHANGES.txt b/lucene/CHANGES.txt
index a29b614..c9204be 100644
--- a/lucene/CHANGES.txt
+++ b/lucene/CHANGES.txt
@@ -101,6 +101,9 @@ Optimizations
 * LUCENE-6392: Highligher- reduce memory of tokens in
   TokenStreamFromTermVector, and add maxStartOffset limit. (David Smiley)
 
+* LUCENE-6456: Queries that generate doc id sets that are too large for the
+  query cache are not cached instead of evicting everything. (Adrien Grand)
+
 Bug Fixes
 
 * LUCENE-6378: Fix all RuntimeExceptions to throw the underlying root cause.
diff --git a/lucene/core/src/java/org/apache/lucene/search/LRUQueryCache.java b/lucene/core/src/java/org/apache/lucene/search/LRUQueryCache.java
index 775e0b4..b03ddce 100644
--- a/lucene/core/src/java/org/apache/lucene/search/LRUQueryCache.java
+++ b/lucene/core/src/java/org/apache/lucene/search/LRUQueryCache.java
@@ -30,6 +30,7 @@ import java.util.Map;
 import java.util.Set;
 
 import org.apache.lucene.index.LeafReader;
+import org.apache.lucene.index.ReaderUtil;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.index.LeafReader.CoreClosedListener;
 import org.apache.lucene.index.LeafReaderContext;
@@ -552,6 +553,18 @@ public class LRUQueryCache implements QueryCache, Accountable {
       in.extractTerms(terms);
     }
 
+    private boolean cacheEntryHasReasonableWorstCaseSize(int maxDoc) {
+      // The worst-case (dense) is a bit set which needs one bit per document
+      final long worstCaseRamUsage = maxDoc / 8;
+      final long totalRamAvailable = maxRamBytesUsed;
+      // Imagine the worst-case that a cache entry is large than the size of
+      // the cache: not only will this entry be trashed immediately but it
+      // will also evict all current entries from the cache. For this reason
+      // we only cache on an IndexReader if we have available room for
+      // 5 different filters on this reader to avoid excessive trashing
+      return worstCaseRamUsage * 5 < totalRamAvailable;
+    }
+
     @Override
     protected Scorer scorer(LeafReaderContext context, Bits acceptDocs, float score) throws IOException {
       if (context.ord == 0) {
@@ -559,7 +572,8 @@ public class LRUQueryCache implements QueryCache, Accountable {
       }
       DocIdSet docIdSet = get(in.getQuery(), context);
       if (docIdSet == null) {
-        if (policy.shouldCache(in.getQuery(), context)) {
+        if (cacheEntryHasReasonableWorstCaseSize(ReaderUtil.getTopLevelContext(context).reader().maxDoc())
+            && policy.shouldCache(in.getQuery(), context)) {
           final Scorer scorer = in.scorer(context, null);
           if (scorer == null) {
             docIdSet = DocIdSet.EMPTY;
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache.java b/lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache.java
index 4496352..eb6d2af 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache.java
@@ -984,4 +984,27 @@ public class TestLRUQueryCache extends LuceneTestCase {
     
     IOUtils.close(w, reader, dir);
   }
+
+  public void testRefuseToCacheTooLargeEntries() throws IOException {
+    Directory dir = newDirectory();
+    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);
+    for (int i = 0; i < 100; ++i) {
+      w.addDocument(new Document());
+    }
+    IndexReader reader = w.getReader();
+
+    // size of 1 byte
+    final LRUQueryCache queryCache = new LRUQueryCache(1, 1);
+    final IndexSearcher searcher = newSearcher(reader);
+    searcher.setQueryCache(queryCache);
+    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);
+
+    searcher.count(new MatchAllDocsQuery());
+    assertEquals(0, queryCache.getCacheCount());
+    assertEquals(0, queryCache.getEvictionCount());
+
+    reader.close();
+    w.close();
+    dir.close();
+  }
 }

