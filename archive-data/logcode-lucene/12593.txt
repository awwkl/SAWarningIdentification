GitDiffStart: 5ed76836aa2b8d18fe72df9c2ca7555926a7a5fb | Tue May 1 02:27:44 2012 +0000
diff --git a/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer.java b/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer.java
index fe9dbe4..f6f49ac 100644
--- a/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer.java
+++ b/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer.java
@@ -349,8 +349,8 @@ public final class JapaneseTokenizer extends Tokenizer {
     }
 
     public void add(int cost, int lastRightID, int backPos, int backIndex, int backID, Type backType) {
-      // NOTE: this isn't quite a true Viterbit search,
-      // becase we should check if lastRightID is
+      // NOTE: this isn't quite a true Viterbi search,
+      // because we should check if lastRightID is
       // already present here, and only update if the new
       // cost is less than the current cost, instead of
       // simply appending.  However, that will likely hurt
@@ -635,12 +635,12 @@ public final class JapaneseTokenizer extends Tokenizer {
         // path, across all paths, backtrace from it, and
         // then prune all others.  Note that this, in
         // general, can produce the wrong result, if the
-        // total bast path did not in fact back trace
+        // total best path did not in fact back trace
         // through this partial best path.  But it's the
         // best we can do... (short of not having a
         // safety!).
 
-        // First pass: find least cost parital path so far,
+        // First pass: find least cost partial path so far,
         // including ending at future positions:
         int leastIDX = -1;
         int leastCost = Integer.MAX_VALUE;
@@ -985,7 +985,7 @@ public final class JapaneseTokenizer extends Tokenizer {
     // token.  So, we could just directly set the attrs,
     // from the backtrace, in incrementToken w/o ever
     // creating Token; we'd have to defer calling freeBefore
-    // until after the bactrace was fully "consumed" by
+    // until after the backtrace was fully "consumed" by
     // incrementToken.
 
     while (pos > lastBackTracePos) {
diff --git a/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/Token.java b/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/Token.java
index 7a739088..1caf0e2 100644
--- a/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/Token.java
+++ b/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/Token.java
@@ -44,7 +44,6 @@ public class Token {
     this.length = length;
     this.type = type;
     this.position = position;
-    this.positionLength = positionLength;
     this.dictionary = dictionary;
   }
 
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsReader.java b/lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsReader.java
index cd70abb..94fd7b8 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsReader.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsReader.java
@@ -262,6 +262,10 @@ public class BlockTreeTermsReader extends FieldsProducer {
     }
   }
 
+  /**
+   * BlockTree statistics for a single field 
+   * returned by {@link FieldReader#computeStats()}.
+   */
   public static class Stats {
     public int indexNodeCount;
     public int indexArcCount;
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/DocValuesArraySource.java b/lucene/core/src/java/org/apache/lucene/codecs/DocValuesArraySource.java
index e83ab2a..413162d 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/DocValuesArraySource.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/DocValuesArraySource.java
@@ -1,16 +1,5 @@
 package org.apache.lucene.codecs;
 
-import java.io.IOException;
-import java.util.Collections;
-import java.util.EnumMap;
-import java.util.Map;
-
-import org.apache.lucene.index.DocValues.Source;
-import org.apache.lucene.index.DocValues.Type;
-import org.apache.lucene.store.IndexInput;
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.RamUsageEstimator;
-
 /**
  * Licensed to the Apache Software Foundation (ASF) under one or more
  * contributor license agreements. See the NOTICE file distributed with this
@@ -28,7 +17,21 @@ import org.apache.lucene.util.RamUsageEstimator;
  * the License.
  */
 
+import java.io.IOException;
+import java.util.Collections;
+import java.util.EnumMap;
+import java.util.Map;
+
+import org.apache.lucene.index.DocValues.Source;
+import org.apache.lucene.index.DocValues.Type;
+import org.apache.lucene.store.IndexInput;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.RamUsageEstimator;
+
 /**
+ * DocValues {@link Source} implementation backed by
+ * simple arrays.
+ * 
  * @lucene.experimental
  * @lucene.internal
  */
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/FieldInfosReader.java b/lucene/core/src/java/org/apache/lucene/codecs/FieldInfosReader.java
index dce9fbd..5ed0684 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/FieldInfosReader.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/FieldInfosReader.java
@@ -24,6 +24,7 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IOContext;
 
 /**
+ * Codec API for reading {@link FieldInfos}.
  * @lucene.experimental
  */
 public abstract class FieldInfosReader {
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/FieldInfosWriter.java b/lucene/core/src/java/org/apache/lucene/codecs/FieldInfosWriter.java
index bcdfce9..9087e2c 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/FieldInfosWriter.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/FieldInfosWriter.java
@@ -24,6 +24,7 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IOContext;
 
 /**
+ * Codec API for writing {@link FieldInfos}.
  * @lucene.experimental
  */
 public abstract class FieldInfosWriter {
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/FixedGapTermsIndexReader.java b/lucene/core/src/java/org/apache/lucene/codecs/FixedGapTermsIndexReader.java
index 8ebcb62..b167e58 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/FixedGapTermsIndexReader.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/FixedGapTermsIndexReader.java
@@ -36,7 +36,12 @@ import java.io.IOException;
 
 import org.apache.lucene.index.IndexFileNames;
 
-/** @lucene.experimental */
+/** 
+ * TermsIndexReader for simple every-nth terms indexes.
+ *
+ * @see FixedGapTermsIndexWriter
+ * @lucene.experimental 
+ */
 public class FixedGapTermsIndexReader extends TermsIndexReaderBase {
 
   // NOTE: long is overkill here, since this number is 128
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/FixedGapTermsIndexWriter.java b/lucene/core/src/java/org/apache/lucene/codecs/FixedGapTermsIndexWriter.java
index 83a796d..853261f 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/FixedGapTermsIndexWriter.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/FixedGapTermsIndexWriter.java
@@ -34,7 +34,7 @@ import java.io.IOException;
 
 /**
  * Selects every Nth term as and index term, and hold term
- * bytes fully expanded in memory.  This terms index
+ * bytes (mostly) fully expanded in memory.  This terms index
  * supports seeking by ord.  See {@link
  * VariableGapTermsIndexWriter} for a more memory efficient
  * terms index that does not support seeking by ord.
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/TermStats.java b/lucene/core/src/java/org/apache/lucene/codecs/TermStats.java
index edbd2fd..95341d1 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/TermStats.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/TermStats.java
@@ -17,6 +17,14 @@ package org.apache.lucene.codecs;
  * limitations under the License.
  */
 
+import org.apache.lucene.index.TermsEnum; // javadocs
+
+/**
+ * Holder for per-term statistics.
+ * 
+ * @see TermsEnum#docFreq
+ * @see TermsEnum#totalTermFreq
+ */
 public class TermStats {
   public final int docFreq;
   public final long totalTermFreq;
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/VariableGapTermsIndexWriter.java b/lucene/core/src/java/org/apache/lucene/codecs/VariableGapTermsIndexWriter.java
index e66e186..bb331d7 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/VariableGapTermsIndexWriter.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/VariableGapTermsIndexWriter.java
@@ -37,7 +37,7 @@ import org.apache.lucene.util.fst.Util;
 
 /**
  * Selects index terms according to provided pluggable
- * IndexTermPolicy, and stores them in a prefix trie that's
+ * {@link IndexTermSelector}, and stores them in a prefix trie that's
  * loaded entirely in RAM stored as an FST.  This terms
  * index only supports unsigned byte term sort order
  * (unicode codepoint order when the bytes are UTF8).
@@ -58,11 +58,23 @@ public class VariableGapTermsIndexWriter extends TermsIndexWriterBase {
   @SuppressWarnings("unused") private final FieldInfos fieldInfos; // unread
   private final IndexTermSelector policy;
 
-  /** @lucene.experimental */
+  /** 
+   * Hook for selecting which terms should be placed in the terms index.
+   * <p>
+   * {@link #newField} is called at the start of each new field, and
+   * {@link #isIndexTerm} for each term in that field.
+   * 
+   * @lucene.experimental 
+   */
   public static abstract class IndexTermSelector {
-    // Called sequentially on every term being written,
-    // returning true if this term should be indexed
+    /** 
+     * Called sequentially on every term being written,
+     * returning true if this term should be indexed
+     */
     public abstract boolean isIndexTerm(BytesRef term, TermStats stats);
+    /**
+     * Called when a new field is started.
+     */
     public abstract void newField(FieldInfo fieldInfo);
   }
 
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/appending/AppendingPostingsFormat.java b/lucene/core/src/java/org/apache/lucene/codecs/appending/AppendingPostingsFormat.java
index 91bd9c8..b7d7782 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/appending/AppendingPostingsFormat.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/appending/AppendingPostingsFormat.java
@@ -34,7 +34,7 @@ import org.apache.lucene.index.SegmentReadState;
 import org.apache.lucene.index.SegmentWriteState;
 
 /**
- * Appending postings impl
+ * Appending postings impl.
  */
 class AppendingPostingsFormat extends PostingsFormat {
   public static String CODEC_NAME = "Appending";
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/appending/AppendingSegmentInfosFormat.java b/lucene/core/src/java/org/apache/lucene/codecs/appending/AppendingSegmentInfosFormat.java
index daf398c..17c0187 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/appending/AppendingSegmentInfosFormat.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/appending/AppendingSegmentInfosFormat.java
@@ -20,6 +20,14 @@ package org.apache.lucene.codecs.appending;
 import org.apache.lucene.codecs.SegmentInfosWriter;
 import org.apache.lucene.codecs.lucene40.Lucene40SegmentInfosFormat;
 
+/**
+ * Append-only SegmentInfos format.
+ * <p>
+ * Only a writer is supplied, as the format is written 
+ * the same as {@link Lucene40SegmentInfosFormat}.
+ * 
+ * @see AppendingSegmentInfosWriter
+ */
 public class AppendingSegmentInfosFormat extends Lucene40SegmentInfosFormat {
   private final SegmentInfosWriter writer = new AppendingSegmentInfosWriter();
 
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/appending/AppendingSegmentInfosWriter.java b/lucene/core/src/java/org/apache/lucene/codecs/appending/AppendingSegmentInfosWriter.java
index bd69ac8..e855e5c 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/appending/AppendingSegmentInfosWriter.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/appending/AppendingSegmentInfosWriter.java
@@ -22,6 +22,13 @@ import java.io.IOException;
 import org.apache.lucene.codecs.lucene40.Lucene40SegmentInfosWriter;
 import org.apache.lucene.store.IndexOutput;
 
+/**
+ * Append-only SegmentInfos writer.
+ * <p>
+ * Extends {@link Lucene40SegmentInfosWriter}, writing the same
+ * format, but the first phase of a two-phase commit 
+ * ({@link #prepareCommit(IndexOutput)}) is not implemented.
+ */
 public class AppendingSegmentInfosWriter extends Lucene40SegmentInfosWriter {
 
   @Override
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40PostingsFormat.java b/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40PostingsFormat.java
index 8d63438..72f9ebd 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40PostingsFormat.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40PostingsFormat.java
@@ -97,7 +97,8 @@ import org.apache.lucene.util.fst.FST; // javadocs
  *    <li>SkipMinimum is the minimum document frequency a term must have in order to write any 
  *        skip data at all.</li>
  *    <li>DocFreq is the count of documents which contain the term.</li>
- *    <li>TotalTermFreq is the total number of occurrences of the term.</li>
+ *    <li>TotalTermFreq is the total number of occurrences of the term. This is encoded
+ *        as the difference between the total number of occurrences and the DocFreq.</li>
  *    <li>FreqDelta determines the position of this term's TermFreqs within the .frq
  *        file. In particular, it is the difference between the position of this term's
  *        data in that file and the position of the previous term's data (or zero, for
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/pulsing/Pulsing40PostingsFormat.java b/lucene/core/src/java/org/apache/lucene/codecs/pulsing/Pulsing40PostingsFormat.java
index 9c23d87..f99b755 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/pulsing/Pulsing40PostingsFormat.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/pulsing/Pulsing40PostingsFormat.java
@@ -19,8 +19,11 @@ package org.apache.lucene.codecs.pulsing;
 
 import org.apache.lucene.codecs.BlockTreeTermsWriter;
 import org.apache.lucene.codecs.lucene40.Lucene40PostingsBaseFormat;
+import org.apache.lucene.codecs.lucene40.Lucene40PostingsFormat; // javadocs
 
 /**
+ * Concrete pulsing implementation over {@link Lucene40PostingsFormat}.
+ * 
  * @lucene.experimental
  */
 public class Pulsing40PostingsFormat extends PulsingPostingsFormat {
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/pulsing/PulsingPostingsWriter.java b/lucene/core/src/java/org/apache/lucene/codecs/pulsing/PulsingPostingsWriter.java
index d1c095a..542d464 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/pulsing/PulsingPostingsWriter.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/pulsing/PulsingPostingsWriter.java
@@ -36,7 +36,15 @@ import org.apache.lucene.util.CodecUtil;
 // payload would not be inlined.  Though this is
 // presumably rare in practice...
 
-/** @lucene.experimental */
+/** 
+ * Writer for the pulsing format. 
+ * <p>
+ * Wraps another postings implementation and decides 
+ * (based on total number of occurrences), whether a terms 
+ * postings should be inlined into the term dictionary,
+ * or passed through to the wrapped writer.
+ *
+ * @lucene.experimental */
 public final class PulsingPostingsWriter extends PostingsWriterBase {
 
   final static String CODEC = "PulsedPostingsWriter";
diff --git a/lucene/core/src/java/org/apache/lucene/util/InfoStream.java b/lucene/core/src/java/org/apache/lucene/util/InfoStream.java
index bb8e3aa..fe5c7a4 100644
--- a/lucene/core/src/java/org/apache/lucene/util/InfoStream.java
+++ b/lucene/core/src/java/org/apache/lucene/util/InfoStream.java
@@ -17,9 +17,19 @@ package org.apache.lucene.util;
  * limitations under the License.
  */
 
+import org.apache.lucene.index.IndexWriter; // javadocs
+import org.apache.lucene.index.SegmentInfos; // javadocs
 import java.io.Closeable;
 
-/** @lucene.internal */
+/** 
+ * Debugging API for Lucene classes such as {@link IndexWriter} 
+ * and {@link SegmentInfos}.
+ * <p>
+ * NOTE: Enabling infostreams may cause performance degradation
+ * in some components.
+ * 
+ * @lucene.internal 
+ */
 public abstract class InfoStream implements Closeable {
 
   /** Instance of InfoStream that does no logging at all. */
diff --git a/lucene/core/src/java/org/apache/lucene/util/MultiBits.java b/lucene/core/src/java/org/apache/lucene/util/MultiBits.java
index e8bd594..b93b1c7 100644
--- a/lucene/core/src/java/org/apache/lucene/util/MultiBits.java
+++ b/lucene/core/src/java/org/apache/lucene/util/MultiBits.java
@@ -82,11 +82,23 @@ public final class MultiBits implements Bits {
     return b.toString();
   }
 
+  /**
+   * Represents a sub-Bits from 
+   * {@link MultiBits#getMatchingSub(org.apache.lucene.util.ReaderUtil.Slice) getMatchingSub()}.
+   */
   public final static class SubResult {
     public boolean matches;
     public Bits result;
   }
 
+  /**
+   * Returns a sub-Bits matching the provided <code>slice</code>
+   * <p>
+   * Because <code>null</code> usually has a special meaning for
+   * Bits (e.g. no deleted documents), you must check
+   * {@link SubResult#matches} instead to ensure the sub was 
+   * actually found.
+   */
   public SubResult getMatchingSub(ReaderUtil.Slice slice) {
     int reader = ReaderUtil.subIndex(slice.start, starts);
     assert reader != -1;
diff --git a/lucene/core/src/java/org/apache/lucene/util/MutableBits.java b/lucene/core/src/java/org/apache/lucene/util/MutableBits.java
index 66a6940..a826543 100644
--- a/lucene/core/src/java/org/apache/lucene/util/MutableBits.java
+++ b/lucene/core/src/java/org/apache/lucene/util/MutableBits.java
@@ -17,6 +17,9 @@ package org.apache.lucene.util;
  * limitations under the License.
  */
 
+/**
+ * Extension of Bits for live documents.
+ */
 public interface MutableBits extends Bits {
   public void clear(int bit);
 }
diff --git a/lucene/core/src/java/org/apache/lucene/util/NamedSPILoader.java b/lucene/core/src/java/org/apache/lucene/util/NamedSPILoader.java
index ed75f5b..124fbe6 100644
--- a/lucene/core/src/java/org/apache/lucene/util/NamedSPILoader.java
+++ b/lucene/core/src/java/org/apache/lucene/util/NamedSPILoader.java
@@ -74,6 +74,9 @@ public final class NamedSPILoader<S extends NamedSPILoader.NamedSPI> implements
     return services.values().iterator();
   }
   
+  /**
+   * Interface to support {@link NamedSPILoader#lookup(String)} by name.
+   */
   public static interface NamedSPI {
     String getName();
   }
diff --git a/lucene/core/src/java/org/apache/lucene/util/PrintStreamInfoStream.java b/lucene/core/src/java/org/apache/lucene/util/PrintStreamInfoStream.java
index 3785a1d..186d7ba 100644
--- a/lucene/core/src/java/org/apache/lucene/util/PrintStreamInfoStream.java
+++ b/lucene/core/src/java/org/apache/lucene/util/PrintStreamInfoStream.java
@@ -23,6 +23,9 @@ import java.util.Date;
 import java.util.concurrent.atomic.AtomicInteger;
 
 /**
+ * InfoStream implementation over a {@link PrintStream}
+ * such as <code>System.out</code>.
+ * 
  * @lucene.internal
  */
 public class PrintStreamInfoStream extends InfoStream {
diff --git a/lucene/core/src/java/org/apache/lucene/util/ReaderUtil.java b/lucene/core/src/java/org/apache/lucene/util/ReaderUtil.java
index 476b35e..d222090 100644
--- a/lucene/core/src/java/org/apache/lucene/util/ReaderUtil.java
+++ b/lucene/core/src/java/org/apache/lucene/util/ReaderUtil.java
@@ -35,6 +35,9 @@ public final class ReaderUtil {
 
   private ReaderUtil() {} // no instance
 
+  /**
+   * Subreader slice from a parent composite reader.
+   */
   public static class Slice {
     public static final Slice[] EMPTY_ARRAY = new Slice[0];
     public final int start;
diff --git a/lucene/core/src/java/org/apache/lucene/util/automaton/CompiledAutomaton.java b/lucene/core/src/java/org/apache/lucene/util/automaton/CompiledAutomaton.java
index 86b087e..8fa2a6c 100644
--- a/lucene/core/src/java/org/apache/lucene/util/automaton/CompiledAutomaton.java
+++ b/lucene/core/src/java/org/apache/lucene/util/automaton/CompiledAutomaton.java
@@ -30,25 +30,60 @@ import org.apache.lucene.util.BytesRef;
 /**
  * Immutable class holding compiled details for a given
  * Automaton.  The Automaton is deterministic, must not have
- * dead states but may not be minimal.
+ * dead states but is not necessarily minimal.
  *
  * @lucene.experimental
  */
 public class CompiledAutomaton {
-  public enum AUTOMATON_TYPE {NONE, ALL, SINGLE, PREFIX, NORMAL};
+  /**
+   * Automata are compiled into different internal forms for the
+   * most efficient execution depending upon the language they accept.
+   */
+  public enum AUTOMATON_TYPE {
+    /** Automaton that accepts no strings. */
+    NONE, 
+    /** Automaton that accepts all possible strings. */
+    ALL, 
+    /** Automaton that accepts only a single fixed string. */
+    SINGLE, 
+    /** Automaton that matches all Strings with a constant prefix. */
+    PREFIX, 
+    /** Catch-all for any other automata. */
+    NORMAL
+  };
   public final AUTOMATON_TYPE type;
 
-  // For PREFIX, this is the prefix term; for SINGLE this is
-  // the singleton term:
+  /** 
+   * For {@link AUTOMATON_TYPE#PREFIX}, this is the prefix term; 
+   * for {@link AUTOMATON_TYPE#SINGLE} this is the singleton term.
+   */
   public final BytesRef term;
 
-  // NOTE: the next 4 members are only non-null if type ==
-  // NORMAL:
+  /** 
+   * Matcher for quickly determining if a byte[] is accepted.
+   * only valid for {@link AUTOMATON_TYPE#NORMAL}.
+   */
   public final ByteRunAutomaton runAutomaton;
   // TODO: would be nice if these sortedTransitions had "int
   // to;" instead of "State to;" somehow:
+  /**
+   * Two dimensional array of transitions, indexed by state
+   * number for traversal. The state numbering is consistent with
+   * {@link #runAutomaton}. 
+   * Only valid for {@link AUTOMATON_TYPE#NORMAL}.
+   */
   public final Transition[][] sortedTransitions;
+  /**
+   * Shared common suffix accepted by the automaton. Only valid
+   * for {@link AUTOMATON_TYPE#NORMAL}, and only when the
+   * automaton accepts an infinite language.
+   */
   public final BytesRef commonSuffixRef;
+  /**
+   * Indicates if the automaton accepts a finite set of strings.
+   * Null if this was not computed.
+   * Only valid for {@link AUTOMATON_TYPE#NORMAL}.
+   */
   public final Boolean finite;
 
   public CompiledAutomaton(Automaton automaton) {
diff --git a/lucene/core/src/java/org/apache/lucene/util/fst/FST.java b/lucene/core/src/java/org/apache/lucene/util/fst/FST.java
index 2435ed7..a81f9f0 100644
--- a/lucene/core/src/java/org/apache/lucene/util/fst/FST.java
+++ b/lucene/core/src/java/org/apache/lucene/util/fst/FST.java
@@ -60,7 +60,9 @@ import org.apache.lucene.util.fst.Builder.UnCompiledNode;
  *  compact byte[] format.
  *  <p> The format is similar to what's used by Morfologik
  *  (http://sourceforge.net/projects/morfologik).
- *
+ *  
+ *  <p> See the {@link org.apache.lucene.util.fst package
+ *      documentation} for some simple examples.
  *  <p><b>NOTE</b>: the FST cannot be larger than ~2.1 GB
  *  because it uses int to address the byte[].
  *
diff --git a/lucene/core/src/java/org/apache/lucene/util/fst/package.html b/lucene/core/src/java/org/apache/lucene/util/fst/package.html
index c5be56e..3d5d55c 100644
--- a/lucene/core/src/java/org/apache/lucene/util/fst/package.html
+++ b/lucene/core/src/java/org/apache/lucene/util/fst/package.html
@@ -21,5 +21,72 @@
 </head>
 <body>
 Finite state transducers
+<p>
+This package implements <a href="http://en.wikipedia.org/wiki/Finite_state_transducer">
+Finite State Transducers</a> with the following characteristics:
+<ul>
+   <li>Fast construction of the minimal FST 
+       (but inputs must be provided in sorted order)</li>
+   <li>Low object overhead and quick deserialization (byte[] representation)</li>
+   <li>Optional compression: {@link org.apache.lucene.util.fst.FST#pack FST.pack()}</li>
+   <li>{@link org.apache.lucene.util.fst.Util#getByOutput Lookup-by-output} when the 
+       outputs are in sorted order (ordinals or file pointers)</li>
+   <li>Pluggable {@link org.apache.lucene.util.fst.Outputs Outputs} representation</li>
+   <li>{@link org.apache.lucene.util.fst.Util#shortestPaths N-shortest-paths} search by
+       weight</li>
+</ul>
+<p>
+FST Construction example:
+<pre class="prettyprint">
+    // input values (keys). These must be provided to Builder in sorted order!
+    String inputValues[] = { "cat", "dog", "dogs" }; 
+    long outputValues[] = { 5, 7, 12 };
+    
+    PositiveIntOutputs outputs = PositiveIntOutputs.getSingleton(true);
+    Builder<Long> builder = new Builder<Long>(INPUT_TYPE.BYTE1, outputs);
+    BytesRef scratchBytes = new BytesRef();
+    IntsRef scratchInts = new IntsRef();
+    for (int i = 0; i < inputValues.length; i++) {
+      scratchBytes.copyChars(inputValues[i]);
+      builder.add(Util.toIntsRef(scratchBytes, scratchInts), outputValues[i]);
+    }
+    FST<Long> fst = builder.finish();
+</pre>
+Retrieval by key:
+<pre class="prettyprint">
+    Long value = Util.get(fst, new BytesRef("dog"));
+    System.out.println(value); // 7
+</pre>
+Retrieval by value:
+<pre class="prettyprint">
+    // Only works because outputs are in sorted order
+    IntsRef key = Util.getByOutput(fst, 12);
+    System.out.println(Util.toBytesRef(key, scratchBytes).utf8ToString()); // dogs
+</pre>
+Iterate over key-value pairs in sorted order:
+<pre class="prettyprint">
+    // Like TermsEnum, this also supports seeking (advance)
+    BytesRefFSTEnum<Long> iterator = new BytesRefFSTEnum<Long>(fst);
+    while (iterator.next() != null) {
+      InputOutput<Long> mapEntry = iterator.current();
+      System.out.println(mapEntry.input.utf8ToString());
+      System.out.println(mapEntry.output);
+    }
+</pre>
+N-shortest paths by weight:
+<pre class="prettyprint">
+    // Only works because we passed 'true' for sharing to getSingleton
+    Comparator<Long> comparator = new Comparator<Long>() {
+      public int compare(Long left, Long right) {
+        return left.compareTo(right);
+      }
+    };
+    Arc<Long> firstArc = fst.getFirstArc(new Arc<Long>());
+    MinResult<Long> paths[] = Util.shortestPaths(fst, firstArc, comparator, 2);
+    System.out.println(Util.toBytesRef(paths[0].input, scratchBytes).utf8ToString()); // cat
+    System.out.println(paths[0].output); // 5
+    System.out.println(Util.toBytesRef(paths[1].input, scratchBytes).utf8ToString()); // dog
+    System.out.println(paths[1].output); // 7
+</pre>
 </body>
 </html>
diff --git a/lucene/misc/src/java/org/apache/lucene/misc/TermStats.java b/lucene/misc/src/java/org/apache/lucene/misc/TermStats.java
index 52b23b4..22de9b6 100644
--- a/lucene/misc/src/java/org/apache/lucene/misc/TermStats.java
+++ b/lucene/misc/src/java/org/apache/lucene/misc/TermStats.java
@@ -19,6 +19,10 @@ package org.apache.lucene.misc;
 
 import org.apache.lucene.util.BytesRef;
 
+/**
+ * Holder for a term along with its statistics
+ * ({@link #docFreq} and {@link #totalTermFreq}).
+ */
 public final class TermStats {
   public BytesRef termtext;
   public String field;
diff --git a/lucene/sandbox/src/java/org/apache/lucene/sandbox/queries/regex/RegexCapabilities.java b/lucene/sandbox/src/java/org/apache/lucene/sandbox/queries/regex/RegexCapabilities.java
index 9337ae2..0050288 100644
--- a/lucene/sandbox/src/java/org/apache/lucene/sandbox/queries/regex/RegexCapabilities.java
+++ b/lucene/sandbox/src/java/org/apache/lucene/sandbox/queries/regex/RegexCapabilities.java
@@ -33,6 +33,18 @@ public interface RegexCapabilities {
    */
   public RegexMatcher compile(String pattern);
 
+  /**
+   * Interface for basic regex matching.
+   * <p>
+   * Implementations return true for {@link #match} if the term 
+   * matches the regex.
+   * <p>
+   * Implementing {@link #prefix()} can restrict the TermsEnum to only
+   * a subset of terms when the regular expression matches a constant
+   * prefix.
+   * <p>
+   * NOTE: implementations cannot seek.
+   */
   public interface RegexMatcher {
     /**
      *
diff --git a/lucene/test-framework/src/java/org/apache/lucene/search/RandomSimilarityProvider.java b/lucene/test-framework/src/java/org/apache/lucene/search/RandomSimilarityProvider.java
index 49c347b..f2d2b1a 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/search/RandomSimilarityProvider.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/search/RandomSimilarityProvider.java
@@ -55,6 +55,13 @@ import org.apache.lucene.search.similarities.NormalizationZ;
 import org.apache.lucene.search.similarities.PerFieldSimilarityWrapper;
 import org.apache.lucene.search.similarities.Similarity;
 
+/**
+ * Similarity implementation that randomizes Similarity implementations
+ * per-field.
+ * <p>
+ * The choices are 'sticky', so the selected algorithm is always used
+ * for the same field.
+ */
 public class RandomSimilarityProvider extends PerFieldSimilarityWrapper {
   final DefaultSimilarity defaultSim = new DefaultSimilarity();
   final List<Similarity> knownSims;
diff --git a/lucene/test-framework/src/java/org/apache/lucene/util/automaton/AutomatonTestUtil.java b/lucene/test-framework/src/java/org/apache/lucene/util/automaton/AutomatonTestUtil.java
index f41cb95..149b5ad 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/util/automaton/AutomatonTestUtil.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/util/automaton/AutomatonTestUtil.java
@@ -31,6 +31,13 @@ import org.apache.lucene.util.ArrayUtil;
 import org.apache.lucene.util.UnicodeUtil;
 import org.apache.lucene.util._TestUtil;
 
+/**
+ * Utilities for testing automata.
+ * <p>
+ * Capable of generating random regular expressions,
+ * and automata, and also provides a number of very
+ * basic unoptimized implementations (*slow) for testing.
+ */
 public class AutomatonTestUtil {
   /** Returns random string, including full unicode range. */
   public static String randomRegexp(Random r) {

