GitDiffStart: 12f88eec3f1d12d5a1ebce05197e503dcf0260a5 | Fri May 18 17:38:07 2012 +0000
diff --git a/lucene/core/src/java/org/apache/lucene/index/DocFieldConsumer.java b/lucene/core/src/java/org/apache/lucene/index/DocFieldConsumer.java
index 1855530..58d0a14 100644
--- a/lucene/core/src/java/org/apache/lucene/index/DocFieldConsumer.java
+++ b/lucene/core/src/java/org/apache/lucene/index/DocFieldConsumer.java
@@ -23,7 +23,7 @@ import java.util.Map;
 abstract class DocFieldConsumer {
   /** Called when DocumentsWriterPerThread decides to create a new
    *  segment */
-  abstract void flush(Map<FieldInfo, DocFieldConsumerPerField> fieldsToFlush, SegmentWriteState state) throws IOException;
+  abstract void flush(Map<String, DocFieldConsumerPerField> fieldsToFlush, SegmentWriteState state) throws IOException;
 
   /** Called when an aborting exception is hit */
   abstract void abort();
diff --git a/lucene/core/src/java/org/apache/lucene/index/DocFieldProcessor.java b/lucene/core/src/java/org/apache/lucene/index/DocFieldProcessor.java
index e539e08..e538c2b 100644
--- a/lucene/core/src/java/org/apache/lucene/index/DocFieldProcessor.java
+++ b/lucene/core/src/java/org/apache/lucene/index/DocFieldProcessor.java
@@ -71,10 +71,10 @@ final class DocFieldProcessor extends DocConsumer {
   @Override
   public void flush(SegmentWriteState state) throws IOException {
 
-    Map<FieldInfo, DocFieldConsumerPerField> childFields = new HashMap<FieldInfo, DocFieldConsumerPerField>();
+    Map<String,DocFieldConsumerPerField> childFields = new HashMap<String,DocFieldConsumerPerField>();
     Collection<DocFieldConsumerPerField> fields = fields();
     for (DocFieldConsumerPerField f : fields) {
-      childFields.put(f.getFieldInfo(), f);
+      childFields.put(f.getFieldInfo().name, f);
     }
 
     fieldsWriter.flush(state);
diff --git a/lucene/core/src/java/org/apache/lucene/index/DocInverter.java b/lucene/core/src/java/org/apache/lucene/index/DocInverter.java
index 86ce4a3..91a9b3a 100644
--- a/lucene/core/src/java/org/apache/lucene/index/DocInverter.java
+++ b/lucene/core/src/java/org/apache/lucene/index/DocInverter.java
@@ -39,12 +39,12 @@ final class DocInverter extends DocFieldConsumer {
   }
 
   @Override
-  void flush(Map<FieldInfo, DocFieldConsumerPerField> fieldsToFlush, SegmentWriteState state) throws IOException {
+  void flush(Map<String, DocFieldConsumerPerField> fieldsToFlush, SegmentWriteState state) throws IOException {
 
-    Map<FieldInfo, InvertedDocConsumerPerField> childFieldsToFlush = new HashMap<FieldInfo, InvertedDocConsumerPerField>();
-    Map<FieldInfo, InvertedDocEndConsumerPerField> endChildFieldsToFlush = new HashMap<FieldInfo, InvertedDocEndConsumerPerField>();
+    Map<String, InvertedDocConsumerPerField> childFieldsToFlush = new HashMap<String, InvertedDocConsumerPerField>();
+    Map<String, InvertedDocEndConsumerPerField> endChildFieldsToFlush = new HashMap<String, InvertedDocEndConsumerPerField>();
 
-    for (Map.Entry<FieldInfo, DocFieldConsumerPerField> fieldToFlush : fieldsToFlush.entrySet()) {
+    for (Map.Entry<String, DocFieldConsumerPerField> fieldToFlush : fieldsToFlush.entrySet()) {
       DocInverterPerField perField = (DocInverterPerField) fieldToFlush.getValue();
       childFieldsToFlush.put(fieldToFlush.getKey(), perField.consumer);
       endChildFieldsToFlush.put(fieldToFlush.getKey(), perField.endConsumer);
diff --git a/lucene/core/src/java/org/apache/lucene/index/FieldInfo.java b/lucene/core/src/java/org/apache/lucene/index/FieldInfo.java
index d1cc1e3..4b63807 100644
--- a/lucene/core/src/java/org/apache/lucene/index/FieldInfo.java
+++ b/lucene/core/src/java/org/apache/lucene/index/FieldInfo.java
@@ -79,6 +79,12 @@ public final class FieldInfo {
     } else { // for non-indexed fields, leave defaults
       this.storeTermVector = false;
       this.storePayloads = false;
+      // nocommit these trip ... which is spooky... means
+      // the FI we are cloning was in a bad state...
+      //assert !storeTermVector;
+      //assert !storePayloads;
+      //assert !omitNorms;
+      //assert normsType == null;
       this.omitNorms = false;
       this.indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;
       this.normType = null;
@@ -155,7 +161,9 @@ public final class FieldInfo {
   }
   
   void setStorePayloads() {
-    storePayloads = true;
+    if (indexed && indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0) {
+      storePayloads = true;
+    }
   }
 
   void setNormValueType(Type type) {
diff --git a/lucene/core/src/java/org/apache/lucene/index/FieldInfos.java b/lucene/core/src/java/org/apache/lucene/index/FieldInfos.java
index 86049c9..3128c95 100644
--- a/lucene/core/src/java/org/apache/lucene/index/FieldInfos.java
+++ b/lucene/core/src/java/org/apache/lucene/index/FieldInfos.java
@@ -306,8 +306,12 @@ public class FieldInfos implements Iterable<FieldInfo> {
     }
     
     final FieldInfos finish() {
-      // nocommit: bogus we don't clone each FI
-      return new FieldInfos(byName.values().toArray(new FieldInfo[byName.size()]));
+      FieldInfo[] cloned = new FieldInfo[byName.size()];
+      int upto = 0;
+      for(FieldInfo fieldInfo : byName.values()) {
+        cloned[upto++] = fieldInfo.clone();
+      }
+      return new FieldInfos(cloned);
     }
   }
 }
diff --git a/lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter.java b/lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter.java
index 847ab57..6b10b1d 100644
--- a/lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter.java
+++ b/lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter.java
@@ -39,7 +39,7 @@ final class FreqProxTermsWriter extends TermsHashConsumer {
   // Other writers would presumably share alot of this...
 
   @Override
-  public void flush(Map<FieldInfo, TermsHashConsumerPerField> fieldsToFlush, final SegmentWriteState state) throws IOException {
+  public void flush(Map<String,TermsHashConsumerPerField> fieldsToFlush, final SegmentWriteState state) throws IOException {
 
     // Gather all FieldData's that have postings, across all
     // ThreadStates
@@ -80,15 +80,7 @@ final class FreqProxTermsWriter extends TermsHashConsumer {
         final FieldInfo fieldInfo = allFields.get(fieldNumber).fieldInfo;
         
         final FreqProxTermsWriterPerField fieldWriter = allFields.get(fieldNumber);
-        
-        // Aggregate the storePayload as seen by the same
-        // field across multiple threads
-        if (fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0) {
-          if (fieldWriter.hasPayloads) {
-            fieldInfo.setStorePayloads();
-          }
-        }
-        
+
         // If this field has postings then add them to the
         // segment
         fieldWriter.flush(fieldInfo.name, consumer, state);
diff --git a/lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField.java b/lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField.java
index efe237d..bc30c7d 100644
--- a/lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField.java
+++ b/lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField.java
@@ -68,7 +68,11 @@ final class FreqProxTermsWriterPerField extends TermsHashConsumerPerField implem
   }
 
   @Override
-  void finish() {}
+  void finish() {
+    if (hasPayloads) {
+      fieldInfo.setStorePayloads();
+    }
+  }
 
   boolean hasPayloads;
 
diff --git a/lucene/core/src/java/org/apache/lucene/index/InvertedDocConsumer.java b/lucene/core/src/java/org/apache/lucene/index/InvertedDocConsumer.java
index 5f4a840..4093285 100644
--- a/lucene/core/src/java/org/apache/lucene/index/InvertedDocConsumer.java
+++ b/lucene/core/src/java/org/apache/lucene/index/InvertedDocConsumer.java
@@ -26,7 +26,7 @@ abstract class InvertedDocConsumer {
   abstract void abort();
 
   /** Flush a new segment */
-  abstract void flush(Map<FieldInfo, InvertedDocConsumerPerField> fieldsToFlush, SegmentWriteState state) throws IOException;
+  abstract void flush(Map<String, InvertedDocConsumerPerField> fieldsToFlush, SegmentWriteState state) throws IOException;
 
   abstract InvertedDocConsumerPerField addField(DocInverterPerField docInverterPerField, FieldInfo fieldInfo);
 
diff --git a/lucene/core/src/java/org/apache/lucene/index/InvertedDocEndConsumer.java b/lucene/core/src/java/org/apache/lucene/index/InvertedDocEndConsumer.java
index 2477cef..9e97d40 100644
--- a/lucene/core/src/java/org/apache/lucene/index/InvertedDocEndConsumer.java
+++ b/lucene/core/src/java/org/apache/lucene/index/InvertedDocEndConsumer.java
@@ -21,7 +21,7 @@ import java.io.IOException;
 import java.util.Map;
 
 abstract class InvertedDocEndConsumer {
-  abstract void flush(Map<FieldInfo, InvertedDocEndConsumerPerField> fieldsToFlush, SegmentWriteState state) throws IOException;
+  abstract void flush(Map<String, InvertedDocEndConsumerPerField> fieldsToFlush, SegmentWriteState state) throws IOException;
   abstract void abort();
   abstract InvertedDocEndConsumerPerField addField(DocInverterPerField docInverterPerField, FieldInfo fieldInfo);
   abstract void startDocument() throws IOException;
diff --git a/lucene/core/src/java/org/apache/lucene/index/NormsConsumer.java b/lucene/core/src/java/org/apache/lucene/index/NormsConsumer.java
index 8d90c8a..a266247 100644
--- a/lucene/core/src/java/org/apache/lucene/index/NormsConsumer.java
+++ b/lucene/core/src/java/org/apache/lucene/index/NormsConsumer.java
@@ -55,13 +55,13 @@ final class NormsConsumer extends InvertedDocEndConsumer {
   /** Produce _X.nrm if any document had a field with norms
    *  not disabled */
   @Override
-  public void flush(Map<FieldInfo,InvertedDocEndConsumerPerField> fieldsToFlush, SegmentWriteState state) throws IOException {
+  public void flush(Map<String,InvertedDocEndConsumerPerField> fieldsToFlush, SegmentWriteState state) throws IOException {
     boolean success = false;
     boolean anythingFlushed = false;
     try {
       if (state.fieldInfos.hasNorms()) {
         for (FieldInfo fi : state.fieldInfos) {
-          final NormsConsumerPerField toWrite = (NormsConsumerPerField) fieldsToFlush.get(fi);
+          final NormsConsumerPerField toWrite = (NormsConsumerPerField) fieldsToFlush.get(fi.name);
           // we must check the final value of omitNorms for the fieldinfo, it could have 
           // changed for this field since the first time we added it.
           if (!fi.omitsNorms()) {
@@ -71,7 +71,7 @@ final class NormsConsumer extends InvertedDocEndConsumer {
               assert fi.getNormType() == type;
             } else if (fi.isIndexed()) {
               anythingFlushed = true;
-              assert fi.getNormType() == null;
+              assert fi.getNormType() == null: "got " + fi.getNormType() + "; field=" + fi.name;
             }
           }
         }
diff --git a/lucene/core/src/java/org/apache/lucene/index/SegmentMerger.java b/lucene/core/src/java/org/apache/lucene/index/SegmentMerger.java
index ebd27d6..898eaec 100644
--- a/lucene/core/src/java/org/apache/lucene/index/SegmentMerger.java
+++ b/lucene/core/src/java/org/apache/lucene/index/SegmentMerger.java
@@ -199,7 +199,8 @@ final class SegmentMerger {
   // NOTE: this is actually merging all the fieldinfos
   public void mergeDocValuesAndNormsFieldInfos() throws IOException {
     // mapping from all docvalues fields found to their promoted types
-    // this is because FieldInfos does not store the valueSize
+    // this is because FieldInfos does not store the
+    // valueSize
     Map<FieldInfo,TypePromoter> docValuesTypes = new HashMap<FieldInfo,TypePromoter>();
     Map<FieldInfo,TypePromoter> normValuesTypes = new HashMap<FieldInfo,TypePromoter>();
 
diff --git a/lucene/core/src/java/org/apache/lucene/index/TermVectorsConsumer.java b/lucene/core/src/java/org/apache/lucene/index/TermVectorsConsumer.java
index a0655d9..4e525a3 100644
--- a/lucene/core/src/java/org/apache/lucene/index/TermVectorsConsumer.java
+++ b/lucene/core/src/java/org/apache/lucene/index/TermVectorsConsumer.java
@@ -49,7 +49,7 @@ final class TermVectorsConsumer extends TermsHashConsumer {
   }
 
   @Override
-  void flush(Map<FieldInfo, TermsHashConsumerPerField> fieldsToFlush, final SegmentWriteState state) throws IOException {
+  void flush(Map<String, TermsHashConsumerPerField> fieldsToFlush, final SegmentWriteState state) throws IOException {
     if (writer != null) {
       // At least one doc in this run had term vectors enabled
       try {
diff --git a/lucene/core/src/java/org/apache/lucene/index/TermsHash.java b/lucene/core/src/java/org/apache/lucene/index/TermsHash.java
index 3ed8fc5..0a06aff 100644
--- a/lucene/core/src/java/org/apache/lucene/index/TermsHash.java
+++ b/lucene/core/src/java/org/apache/lucene/index/TermsHash.java
@@ -96,17 +96,17 @@ final class TermsHash extends InvertedDocConsumer {
   }
 
   @Override
-  void flush(Map<FieldInfo,InvertedDocConsumerPerField> fieldsToFlush, final SegmentWriteState state) throws IOException {
-    Map<FieldInfo,TermsHashConsumerPerField> childFields = new HashMap<FieldInfo,TermsHashConsumerPerField>();
-    Map<FieldInfo,InvertedDocConsumerPerField> nextChildFields;
+  void flush(Map<String,InvertedDocConsumerPerField> fieldsToFlush, final SegmentWriteState state) throws IOException {
+    Map<String,TermsHashConsumerPerField> childFields = new HashMap<String,TermsHashConsumerPerField>();
+    Map<String,InvertedDocConsumerPerField> nextChildFields;
 
     if (nextTermsHash != null) {
-      nextChildFields = new HashMap<FieldInfo,InvertedDocConsumerPerField>();
+      nextChildFields = new HashMap<String,InvertedDocConsumerPerField>();
     } else {
       nextChildFields = null;
     }
 
-    for (final Map.Entry<FieldInfo,InvertedDocConsumerPerField> entry : fieldsToFlush.entrySet()) {
+    for (final Map.Entry<String,InvertedDocConsumerPerField> entry : fieldsToFlush.entrySet()) {
       TermsHashPerField perField = (TermsHashPerField) entry.getValue();
       childFields.put(entry.getKey(), perField.consumer);
       if (nextTermsHash != null) {
diff --git a/lucene/core/src/java/org/apache/lucene/index/TermsHashConsumer.java b/lucene/core/src/java/org/apache/lucene/index/TermsHashConsumer.java
index 3ec6ec2..1e5a55d 100644
--- a/lucene/core/src/java/org/apache/lucene/index/TermsHashConsumer.java
+++ b/lucene/core/src/java/org/apache/lucene/index/TermsHashConsumer.java
@@ -21,7 +21,7 @@ import java.io.IOException;
 import java.util.Map;
 
 abstract class TermsHashConsumer {
-  abstract void flush(Map<FieldInfo, TermsHashConsumerPerField> fieldsToFlush, final SegmentWriteState state) throws IOException;
+  abstract void flush(Map<String, TermsHashConsumerPerField> fieldsToFlush, final SegmentWriteState state) throws IOException;
   abstract void abort();
   abstract void startDocument() throws IOException;
   abstract void finishDocument(TermsHash termsHash) throws IOException;

