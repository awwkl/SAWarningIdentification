GitDiffStart: 36b2f2512b53b3c4d5951dbeaf7d25106a806413 | Wed Feb 19 01:38:33 2014 +0000
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/charfilter/HTMLStripCharFilterTest.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/charfilter/HTMLStripCharFilterTest.java
index a833ea1..9c6c730 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/charfilter/HTMLStripCharFilterTest.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/charfilter/HTMLStripCharFilterTest.java
@@ -31,7 +31,7 @@ import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.MockTokenizer;
 import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class HTMLStripCharFilterTest extends BaseTokenStreamTestCase {
 
@@ -786,7 +786,7 @@ public class HTMLStripCharFilterTest extends BaseTokenStreamTestCase {
 
   public void testRandomBrokenHTML() throws Exception {
     int maxNumElements = 10000;
-    String text = _TestUtil.randomHtmlishString(random(), maxNumElements);
+    String text = TestUtil.randomHtmlishString(random(), maxNumElements);
     checkAnalysisConsistency(random(), newTestAnalyzer(), random().nextBoolean(), text);
   }
 
@@ -796,18 +796,18 @@ public class HTMLStripCharFilterTest extends BaseTokenStreamTestCase {
     int maxNumWords = 10000;
     int minWordLength = 3;
     int maxWordLength = 20;
-    int numWords = _TestUtil.nextInt(random(), minNumWords, maxNumWords);
-    switch (_TestUtil.nextInt(random(), 0, 4)) {
+    int numWords = TestUtil.nextInt(random(), minNumWords, maxNumWords);
+    switch (TestUtil.nextInt(random(), 0, 4)) {
       case 0: {
         for (int wordNum = 0 ; wordNum < numWords ; ++wordNum) {
-          text.append(_TestUtil.randomUnicodeString(random(), maxWordLength));
+          text.append(TestUtil.randomUnicodeString(random(), maxWordLength));
           text.append(' ');
         }
         break;
       }
       case 1: {
         for (int wordNum = 0 ; wordNum < numWords ; ++wordNum) {
-          text.append(_TestUtil.randomRealisticUnicodeString
+          text.append(TestUtil.randomRealisticUnicodeString
               (random(), minWordLength, maxWordLength));
           text.append(' ');
         }
@@ -815,7 +815,7 @@ public class HTMLStripCharFilterTest extends BaseTokenStreamTestCase {
       }
       default: { // ASCII 50% of the time
         for (int wordNum = 0 ; wordNum < numWords ; ++wordNum) {
-          text.append(_TestUtil.randomSimpleString(random()));
+          text.append(TestUtil.randomSimpleString(random()));
           text.append(' ');
         }
       }
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/charfilter/TestMappingCharFilter.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/charfilter/TestMappingCharFilter.java
index ea28c74..55975a3 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/charfilter/TestMappingCharFilter.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/charfilter/TestMappingCharFilter.java
@@ -33,8 +33,8 @@ import org.apache.lucene.analysis.CharFilter;
 import org.apache.lucene.analysis.MockTokenizer;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.UnicodeUtil;
-import org.apache.lucene.util._TestUtil;
 
 public class TestMappingCharFilter extends BaseTokenStreamTestCase {
 
@@ -274,9 +274,9 @@ public class TestMappingCharFilter extends BaseTokenStreamTestCase {
     int num = random.nextInt(5);
     //System.out.println("NormalizeCharMap=");
     for (int i = 0; i < num; i++) {
-      String key = _TestUtil.randomSimpleString(random);
+      String key = TestUtil.randomSimpleString(random);
       if (!keys.contains(key) && key.length() != 0) {
-        String value = _TestUtil.randomSimpleString(random);
+        String value = TestUtil.randomSimpleString(random);
         builder.add(key, value);
         keys.add(key);
         //System.out.println("mapping: '" + key + "' => '" + value + "'");
@@ -294,7 +294,7 @@ public class TestMappingCharFilter extends BaseTokenStreamTestCase {
         System.out.println("\nTEST iter=" + iter);
       }
 
-      final char endLetter = (char) _TestUtil.nextInt(random, 'b', 'z');
+      final char endLetter = (char) TestUtil.nextInt(random, 'b', 'z');
 
       final Map<String,String> map = new HashMap<String,String>();
       final NormalizeCharMap.Builder builder = new NormalizeCharMap.Builder();
@@ -303,9 +303,9 @@ public class TestMappingCharFilter extends BaseTokenStreamTestCase {
         System.out.println("  mappings:");
       }
       while (map.size() < numMappings) {
-        final String key = _TestUtil.randomSimpleStringRange(random, 'a', endLetter, 7);
+        final String key = TestUtil.randomSimpleStringRange(random, 'a', endLetter, 7);
         if (key.length() != 0 && !map.containsKey(key)) {
-          final String value = _TestUtil.randomSimpleString(random);
+          final String value = TestUtil.randomSimpleString(random);
           map.put(key, value);
           builder.add(key, value);
           if (VERBOSE) {
@@ -321,7 +321,7 @@ public class TestMappingCharFilter extends BaseTokenStreamTestCase {
       }
 
       for(int iter2=0;iter2<100;iter2++) {
-        final String content = _TestUtil.randomSimpleStringRange(random, 'a', endLetter, atLeast(1000));
+        final String content = TestUtil.randomSimpleStringRange(random, 'a', endLetter, atLeast(1000));
 
         if (VERBOSE) {
           System.out.println("  content=" + content);
@@ -427,7 +427,7 @@ public class TestMappingCharFilter extends BaseTokenStreamTestCase {
             }
             actualBuilder.append((char) ch);
           } else {
-            final char[] buffer = new char[_TestUtil.nextInt(random, 1, 100)];
+            final char[] buffer = new char[TestUtil.nextInt(random, 1, 100)];
             final int off = buffer.length == 1 ? 0 : random.nextInt(buffer.length-1);
             final int count = mapFilter.read(buffer, off, buffer.length-off);
             if (count == -1) {
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestDuelingAnalyzers.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestDuelingAnalyzers.java
index 0f1ebcf..89667f7 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestDuelingAnalyzers.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestDuelingAnalyzers.java
@@ -30,7 +30,7 @@ import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
 import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
 import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.automaton.Automaton;
 import org.apache.lucene.util.automaton.BasicOperations;
 import org.apache.lucene.util.automaton.CharacterRunAutomaton;
@@ -76,7 +76,7 @@ public class TestDuelingAnalyzers extends LuceneTestCase {
       }
     };
     for (int i = 0; i < 1000; i++) {
-      String s = _TestUtil.randomSimpleString(random);
+      String s = TestUtil.randomSimpleString(random);
       assertEquals(s, left.tokenStream("foo", newStringReader(s)), 
                    right.tokenStream("foo", newStringReader(s)));
     }
@@ -97,7 +97,7 @@ public class TestDuelingAnalyzers extends LuceneTestCase {
     };
     int numIterations = atLeast(50);
     for (int i = 0; i < numIterations; i++) {
-      String s = _TestUtil.randomSimpleString(random, maxLength);
+      String s = TestUtil.randomSimpleString(random, maxLength);
       assertEquals(s, left.tokenStream("foo", newStringReader(s)), 
                    right.tokenStream("foo", newStringReader(s)));
     }
@@ -114,7 +114,7 @@ public class TestDuelingAnalyzers extends LuceneTestCase {
       }
     };
     for (int i = 0; i < 1000; i++) {
-      String s = _TestUtil.randomHtmlishString(random, 20);
+      String s = TestUtil.randomHtmlishString(random, 20);
       assertEquals(s, left.tokenStream("foo", newStringReader(s)), 
                    right.tokenStream("foo", newStringReader(s)));
     }
@@ -134,7 +134,7 @@ public class TestDuelingAnalyzers extends LuceneTestCase {
     };
     int numIterations = atLeast(50);
     for (int i = 0; i < numIterations; i++) {
-      String s = _TestUtil.randomHtmlishString(random, maxLength);
+      String s = TestUtil.randomHtmlishString(random, maxLength);
       assertEquals(s, left.tokenStream("foo", newStringReader(s)), 
                    right.tokenStream("foo", newStringReader(s)));
     }
@@ -151,7 +151,7 @@ public class TestDuelingAnalyzers extends LuceneTestCase {
       }
     };
     for (int i = 0; i < 1000; i++) {
-      String s = _TestUtil.randomUnicodeString(random);
+      String s = TestUtil.randomUnicodeString(random);
       assertEquals(s, left.tokenStream("foo", newStringReader(s)), 
                    right.tokenStream("foo", newStringReader(s)));
     }
@@ -171,7 +171,7 @@ public class TestDuelingAnalyzers extends LuceneTestCase {
     };
     int numIterations = atLeast(50);
     for (int i = 0; i < numIterations; i++) {
-      String s = _TestUtil.randomUnicodeString(random, maxLength);
+      String s = TestUtil.randomUnicodeString(random, maxLength);
       assertEquals(s, left.tokenStream("foo", newStringReader(s)), 
                    right.tokenStream("foo", newStringReader(s)));
     }
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestKeywordAnalyzer.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestKeywordAnalyzer.java
index a5ce14f..10d5f18 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestKeywordAnalyzer.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestKeywordAnalyzer.java
@@ -37,7 +37,7 @@ import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.RAMDirectory;
 import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestKeywordAnalyzer extends BaseTokenStreamTestCase {
   
@@ -97,21 +97,21 @@ public class TestKeywordAnalyzer extends BaseTokenStreamTestCase {
     writer.close();
 
     IndexReader reader = DirectoryReader.open(dir);
-    DocsEnum td = _TestUtil.docs(random(),
-                                 reader,
-                                 "partnum",
-                                 new BytesRef("Q36"),
-                                 MultiFields.getLiveDocs(reader),
-                                 null,
-                                 0);
+    DocsEnum td = TestUtil.docs(random(),
+        reader,
+        "partnum",
+        new BytesRef("Q36"),
+        MultiFields.getLiveDocs(reader),
+        null,
+        0);
     assertTrue(td.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
-    td = _TestUtil.docs(random(),
-                        reader,
-                        "partnum",
-                        new BytesRef("Q37"),
-                        MultiFields.getLiveDocs(reader),
-                        null,
-                        0);
+    td = TestUtil.docs(random(),
+        reader,
+        "partnum",
+        new BytesRef("Q37"),
+        MultiFields.getLiveDocs(reader),
+        null,
+        0);
     assertTrue(td.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
   }
 
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.java
index 1278b26..bca5e1e 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.java
@@ -85,8 +85,8 @@ import org.apache.lucene.util.AttributeSource;
 import org.apache.lucene.util.AttributeSource.AttributeFactory;
 import org.apache.lucene.util.CharsRef;
 import org.apache.lucene.util.Rethrow;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.Version;
-import org.apache.lucene.util._TestUtil;
 import org.apache.lucene.util.automaton.CharacterRunAutomaton;
 import org.junit.AfterClass;
 import org.junit.BeforeClass;
@@ -305,7 +305,7 @@ public class TestRandomChains extends BaseTokenStreamTestCase {
         // TODO: could cause huge ram usage to use full int range for some filters
         // (e.g. allocate enormous arrays)
         // return Integer.valueOf(random.nextInt());
-        return Integer.valueOf(_TestUtil.nextInt(random, -100, 100));
+        return Integer.valueOf(TestUtil.nextInt(random, -100, 100));
       }
     });
     put(char.class, new ArgProducer() {
@@ -372,7 +372,7 @@ public class TestRandomChains extends BaseTokenStreamTestCase {
         Collection<char[]> col = new ArrayList<char[]>();
         int num = random.nextInt(5);
         for (int i = 0; i < num; i++) {
-          col.add(_TestUtil.randomSimpleString(random).toCharArray());
+          col.add(TestUtil.randomSimpleString(random).toCharArray());
         }
         return col;
       }
@@ -383,7 +383,7 @@ public class TestRandomChains extends BaseTokenStreamTestCase {
         CharArraySet set = new CharArraySet(TEST_VERSION_CURRENT, num, random.nextBoolean());
         for (int i = 0; i < num; i++) {
           // TODO: make nastier
-          set.add(_TestUtil.randomSimpleString(random));
+          set.add(TestUtil.randomSimpleString(random));
         }
         return set;
       }
@@ -451,7 +451,7 @@ public class TestRandomChains extends BaseTokenStreamTestCase {
           // a token type
           return StandardTokenizer.TOKEN_TYPES[random.nextInt(StandardTokenizer.TOKEN_TYPES.length)];
         } else {
-          return _TestUtil.randomSimpleString(random);
+          return TestUtil.randomSimpleString(random);
         }
       }
     });
@@ -463,9 +463,9 @@ public class TestRandomChains extends BaseTokenStreamTestCase {
         int num = random.nextInt(5);
         //System.out.println("NormalizeCharMap=");
         for (int i = 0; i < num; i++) {
-          String key = _TestUtil.randomSimpleString(random);
+          String key = TestUtil.randomSimpleString(random);
           if (!keys.contains(key) && key.length() > 0) {
-            String value = _TestUtil.randomSimpleString(random);
+            String value = TestUtil.randomSimpleString(random);
             builder.add(key, value);
             keys.add(key);
             //System.out.println("mapping: '" + key + "' => '" + value + "'");
@@ -492,7 +492,7 @@ public class TestRandomChains extends BaseTokenStreamTestCase {
         CharArrayMap<String> map = new CharArrayMap<String>(TEST_VERSION_CURRENT, num, random.nextBoolean());
         for (int i = 0; i < num; i++) {
           // TODO: make nastier
-          map.put(_TestUtil.randomSimpleString(random), _TestUtil.randomSimpleString(random));
+          map.put(TestUtil.randomSimpleString(random), TestUtil.randomSimpleString(random));
         }
         return map;
       }
@@ -504,11 +504,11 @@ public class TestRandomChains extends BaseTokenStreamTestCase {
         for (int i = 0; i < num; i++) {
           String input = ""; 
           do {
-            input = _TestUtil.randomRealisticUnicodeString(random);
+            input = TestUtil.randomRealisticUnicodeString(random);
           } while(input.isEmpty());
-          String out = ""; _TestUtil.randomSimpleString(random);
+          String out = ""; TestUtil.randomSimpleString(random);
           do {
-            out = _TestUtil.randomRealisticUnicodeString(random);
+            out = TestUtil.randomRealisticUnicodeString(random);
           } while(out.isEmpty());
           builder.add(input, out);
         }
@@ -543,7 +543,7 @@ public class TestRandomChains extends BaseTokenStreamTestCase {
       
       private String randomNonEmptyString(Random random) {
         while(true) {
-          final String s = _TestUtil.randomUnicodeString(random).trim();
+          final String s = TestUtil.randomUnicodeString(random).trim();
           if (s.length() != 0 && s.indexOf('\u0000') == -1) {
             return s;
           }
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/HunspellStemFilterTest.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/HunspellStemFilterTest.java
index 19604c2..dd273fa 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/HunspellStemFilterTest.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/HunspellStemFilterTest.java
@@ -28,7 +28,7 @@ import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.core.KeywordTokenizer;
 import org.apache.lucene.analysis.miscellaneous.SetKeywordMarkerFilter;
 import org.apache.lucene.analysis.util.CharArraySet;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.AfterClass;
 import org.junit.BeforeClass;
 
@@ -56,13 +56,13 @@ public class HunspellStemFilterTest  extends BaseTokenStreamTestCase {
   public void testKeywordAttribute() throws IOException {
     MockTokenizer tokenizer = whitespaceMockTokenizer("lucene is awesome");
     tokenizer.setEnableChecks(true);
-    HunspellStemFilter filter = new HunspellStemFilter(tokenizer, DICTIONARY, _TestUtil.nextInt(random(), 1, 3));
+    HunspellStemFilter filter = new HunspellStemFilter(tokenizer, DICTIONARY, TestUtil.nextInt(random(), 1, 3));
     assertTokenStreamContents(filter, new String[]{"lucene", "lucen", "is", "awesome"}, new int[] {1, 0, 1, 1});
     
     // assert with keywork marker
     tokenizer = whitespaceMockTokenizer("lucene is awesome");
     CharArraySet set = new CharArraySet(TEST_VERSION_CURRENT, Arrays.asList("Lucene"), true);
-    filter = new HunspellStemFilter(new SetKeywordMarkerFilter(tokenizer, set), DICTIONARY, _TestUtil.nextInt(random(), 1, 3));
+    filter = new HunspellStemFilter(new SetKeywordMarkerFilter(tokenizer, set), DICTIONARY, TestUtil.nextInt(random(), 1, 3));
     assertTokenStreamContents(filter, new String[]{"lucene", "is", "awesome"}, new int[] {1, 1, 1});
   }
   
@@ -73,7 +73,7 @@ public class HunspellStemFilterTest  extends BaseTokenStreamTestCase {
       @Override
       protected TokenStreamComponents createComponents(String fieldName) {
         Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);
-        return new TokenStreamComponents(tokenizer, new HunspellStemFilter(tokenizer, DICTIONARY, _TestUtil.nextInt(random(), 1, 3)));
+        return new TokenStreamComponents(tokenizer, new HunspellStemFilter(tokenizer, DICTIONARY, TestUtil.nextInt(random(), 1, 3)));
       }  
     };
     checkRandomData(random(), analyzer, 1000*RANDOM_MULTIPLIER);
@@ -84,7 +84,7 @@ public class HunspellStemFilterTest  extends BaseTokenStreamTestCase {
       @Override
       protected TokenStreamComponents createComponents(String fieldName) {
         Tokenizer tokenizer = new KeywordTokenizer();
-        return new TokenStreamComponents(tokenizer, new HunspellStemFilter(tokenizer, DICTIONARY, _TestUtil.nextInt(random(), 1, 3)));
+        return new TokenStreamComponents(tokenizer, new HunspellStemFilter(tokenizer, DICTIONARY, TestUtil.nextInt(random(), 1, 3)));
       }
     };
     checkOneTerm(a, "", "");
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestCodepointCountFilter.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestCodepointCountFilter.java
index 55323ff..8c58f5e 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestCodepointCountFilter.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestCodepointCountFilter.java
@@ -18,16 +18,15 @@ package org.apache.lucene.analysis.miscellaneous;
  */
 
 import java.io.IOException;
-import java.io.Reader;
 import java.io.StringReader;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.core.KeywordTokenizer;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestCodepointCountFilter extends BaseTokenStreamTestCase {
   public void testFilterWithPosIncr() throws Exception {
@@ -52,9 +51,9 @@ public class TestCodepointCountFilter extends BaseTokenStreamTestCase {
   
   public void testRandomStrings() throws IOException {
     for (int i = 0; i < 10000; i++) {
-      String text = _TestUtil.randomUnicodeString(random(), 100);
-      int min = _TestUtil.nextInt(random(), 0, 100);
-      int max = _TestUtil.nextInt(random(), 0, 100);
+      String text = TestUtil.randomUnicodeString(random(), 100);
+      int min = TestUtil.nextInt(random(), 0, 100);
+      int max = TestUtil.nextInt(random(), 0, 100);
       int count = text.codePointCount(0, text.length());
       boolean expected = count >= min && count <= max;
       TokenStream stream = new KeywordTokenizer();
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLimitTokenCountAnalyzer.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLimitTokenCountAnalyzer.java
index b55482a..1d7fae1 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLimitTokenCountAnalyzer.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLimitTokenCountAnalyzer.java
@@ -30,7 +30,7 @@ import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.IndexWriterConfig;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.store.Directory;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestLimitTokenCountAnalyzer extends BaseTokenStreamTestCase {
 
@@ -59,7 +59,7 @@ public class TestLimitTokenCountAnalyzer extends BaseTokenStreamTestCase {
     
     for (boolean consumeAll : new boolean[] { true, false }) {
       Directory dir = newDirectory();
-      int limit = _TestUtil.nextInt(random(), 50, 101000);
+      int limit = TestUtil.nextInt(random(), 50, 101000);
       MockAnalyzer mock = new MockAnalyzer(random());
 
       // if we are consuming all tokens, we can use the checks, 
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestRemoveDuplicatesTokenFilter.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestRemoveDuplicatesTokenFilter.java
index c50d9fa..667bedb 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestRemoveDuplicatesTokenFilter.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestRemoveDuplicatesTokenFilter.java
@@ -30,10 +30,9 @@ import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
 import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
 import org.apache.lucene.util.CharsRef;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 import java.io.IOException;
-import java.io.Reader;
 import java.util.Iterator;
 import java.util.Arrays;
 
@@ -129,7 +128,7 @@ public class TestRemoveDuplicatesTokenFilter extends BaseTokenStreamTestCase {
   // some helper methods for the below test with synonyms
   private String randomNonEmptyString() {
     while(true) {
-      final String s = _TestUtil.randomUnicodeString(random()).trim();
+      final String s = TestUtil.randomUnicodeString(random()).trim();
       if (s.length() != 0 && s.indexOf('\u0000') == -1) {
         return s;
       }
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestStemmerOverrideFilter.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestStemmerOverrideFilter.java
index 94309c7..17f2fbb 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestStemmerOverrideFilter.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestStemmerOverrideFilter.java
@@ -31,7 +31,7 @@ import org.apache.lucene.analysis.core.KeywordTokenizer;
 import org.apache.lucene.analysis.core.WhitespaceTokenizer;
 import org.apache.lucene.analysis.en.PorterStemFilter;
 import org.apache.lucene.analysis.miscellaneous.StemmerOverrideFilter.StemmerOverrideMap;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * 
@@ -81,7 +81,7 @@ public class TestStemmerOverrideFilter extends BaseTokenStreamTestCase {
     Map<String,String> map = new HashMap<String,String>();
     int numTerms = atLeast(50);
     for (int i = 0; i < numTerms; i++) {
-      String randomRealisticUnicodeString = _TestUtil
+      String randomRealisticUnicodeString = TestUtil
           .randomRealisticUnicodeString(random());
       char[] charArray = randomRealisticUnicodeString.toCharArray();
       StringBuilder builder = new StringBuilder();
@@ -93,7 +93,7 @@ public class TestStemmerOverrideFilter extends BaseTokenStreamTestCase {
         j += Character.charCount(cp);
       }
       if (builder.length() > 0) {
-        String value = _TestUtil.randomSimpleString(random());
+        String value = TestUtil.randomSimpleString(random());
         map.put(builder.toString(),
             value.isEmpty() ? "a" : value);
         
@@ -124,10 +124,10 @@ public class TestStemmerOverrideFilter extends BaseTokenStreamTestCase {
     Map<String,String> map = new HashMap<String,String>();
     int numTerms = atLeast(50);
     for (int i = 0; i < numTerms; i++) {
-      String randomRealisticUnicodeString = _TestUtil
+      String randomRealisticUnicodeString = TestUtil
           .randomRealisticUnicodeString(random());
       if (randomRealisticUnicodeString.length() > 0) {
-        String value = _TestUtil.randomSimpleString(random());
+        String value = TestUtil.randomSimpleString(random());
         map.put(randomRealisticUnicodeString,
             value.isEmpty() ? "a" : value);
       }
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilterTest.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilterTest.java
index 72f4939..062bfc1 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilterTest.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilterTest.java
@@ -18,7 +18,6 @@ package org.apache.lucene.analysis.ngram;
  */
 
 import java.io.IOException;
-import java.io.Reader;
 import java.io.StringReader;
 import java.util.Random;
 
@@ -35,7 +34,8 @@ import org.apache.lucene.analysis.shingle.ShingleFilter;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
 import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
 import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Tests {@link EdgeNGramTokenFilter} for correctness.
@@ -171,8 +171,8 @@ public class EdgeNGramTokenFilterTest extends BaseTokenStreamTestCase {
   /** blast some random strings through the analyzer */
   public void testRandomStrings() throws Exception {
     for (int i = 0; i < 10; i++) {
-      final int min = _TestUtil.nextInt(random(), 2, 10);
-      final int max = _TestUtil.nextInt(random(), min, 20);
+      final int min = TestUtil.nextInt(random(), 2, 10);
+      final int max = TestUtil.nextInt(random(), min, 20);
     
       Analyzer a = new Analyzer() {
         @Override
@@ -215,10 +215,10 @@ public class EdgeNGramTokenFilterTest extends BaseTokenStreamTestCase {
   }
 
   public void testSupplementaryCharacters() throws IOException {
-    final String s = _TestUtil.randomUnicodeString(random(), 10);
+    final String s = TestUtil.randomUnicodeString(random(), 10);
     final int codePointCount = s.codePointCount(0, s.length());
-    final int minGram = _TestUtil.nextInt(random(), 1, 3);
-    final int maxGram = _TestUtil.nextInt(random(), minGram, 10);
+    final int minGram = TestUtil.nextInt(random(), 1, 3);
+    final int maxGram = TestUtil.nextInt(random(), minGram, 10);
     TokenStream tk = new KeywordTokenizer();
     ((Tokenizer)tk).setReader(new StringReader(s));
     tk = new EdgeNGramTokenFilter(TEST_VERSION_CURRENT, tk, minGram, maxGram);
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/ngram/EdgeNGramTokenizerTest.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/ngram/EdgeNGramTokenizerTest.java
index 5ebd608..99b2fb7 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/ngram/EdgeNGramTokenizerTest.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/ngram/EdgeNGramTokenizerTest.java
@@ -19,14 +19,13 @@ package org.apache.lucene.analysis.ngram;
 
 
 import java.io.IOException;
-import java.io.Reader;
 import java.io.StringReader;
 import java.util.Arrays;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 import com.carrotsearch.randomizedtesting.generators.RandomStrings;
 
@@ -101,8 +100,8 @@ public class EdgeNGramTokenizerTest extends BaseTokenStreamTestCase {
   /** blast some random strings through the analyzer */
   public void testRandomStrings() throws Exception {
     for (int i = 0; i < 10; i++) {
-      final int min = _TestUtil.nextInt(random(), 2, 10);
-      final int max = _TestUtil.nextInt(random(), min, 20);
+      final int min = TestUtil.nextInt(random(), 2, 10);
+      final int max = TestUtil.nextInt(random(), min, 20);
       
       Analyzer a = new Analyzer() {
         @Override
@@ -141,47 +140,47 @@ public class EdgeNGramTokenizerTest extends BaseTokenStreamTestCase {
 
   public void testLargeInput() throws IOException {
     // test sliding
-    final int minGram = _TestUtil.nextInt(random(), 1, 100);
-    final int maxGram = _TestUtil.nextInt(random(), minGram, 100);
-    testNGrams(minGram, maxGram, _TestUtil.nextInt(random(), 3 * 1024, 4 * 1024), "");
+    final int minGram = TestUtil.nextInt(random(), 1, 100);
+    final int maxGram = TestUtil.nextInt(random(), minGram, 100);
+    testNGrams(minGram, maxGram, TestUtil.nextInt(random(), 3 * 1024, 4 * 1024), "");
   }
 
   public void testLargeMaxGram() throws IOException {
     // test sliding with maxGram > 1024
-    final int minGram = _TestUtil.nextInt(random(), 1290, 1300);
-    final int maxGram = _TestUtil.nextInt(random(), minGram, 1300);
-    testNGrams(minGram, maxGram, _TestUtil.nextInt(random(), 3 * 1024, 4 * 1024), "");
+    final int minGram = TestUtil.nextInt(random(), 1290, 1300);
+    final int maxGram = TestUtil.nextInt(random(), minGram, 1300);
+    testNGrams(minGram, maxGram, TestUtil.nextInt(random(), 3 * 1024, 4 * 1024), "");
   }
 
   public void testPreTokenization() throws IOException {
-    final int minGram = _TestUtil.nextInt(random(), 1, 100);
-    final int maxGram = _TestUtil.nextInt(random(), minGram, 100);
-    testNGrams(minGram, maxGram, _TestUtil.nextInt(random(), 0, 4 * 1024), "a");
+    final int minGram = TestUtil.nextInt(random(), 1, 100);
+    final int maxGram = TestUtil.nextInt(random(), minGram, 100);
+    testNGrams(minGram, maxGram, TestUtil.nextInt(random(), 0, 4 * 1024), "a");
   }
 
   public void testHeavyPreTokenization() throws IOException {
-    final int minGram = _TestUtil.nextInt(random(), 1, 100);
-    final int maxGram = _TestUtil.nextInt(random(), minGram, 100);
-    testNGrams(minGram, maxGram, _TestUtil.nextInt(random(), 0, 4 * 1024), "abcdef");
+    final int minGram = TestUtil.nextInt(random(), 1, 100);
+    final int maxGram = TestUtil.nextInt(random(), minGram, 100);
+    testNGrams(minGram, maxGram, TestUtil.nextInt(random(), 0, 4 * 1024), "abcdef");
   }
 
   public void testFewTokenChars() throws IOException {
-    final char[] chrs = new char[_TestUtil.nextInt(random(), 4000, 5000)];
+    final char[] chrs = new char[TestUtil.nextInt(random(), 4000, 5000)];
     Arrays.fill(chrs, ' ');
     for (int i = 0; i < chrs.length; ++i) {
       if (random().nextFloat() < 0.1) {
         chrs[i] = 'a';
       }
     }
-    final int minGram = _TestUtil.nextInt(random(), 1, 2);
-    final int maxGram = _TestUtil.nextInt(random(), minGram, 2);
+    final int minGram = TestUtil.nextInt(random(), 1, 2);
+    final int maxGram = TestUtil.nextInt(random(), minGram, 2);
     testNGrams(minGram, maxGram, new String(chrs), " ");
   }
 
   public void testFullUTF8Range() throws IOException {
-    final int minGram = _TestUtil.nextInt(random(), 1, 100);
-    final int maxGram = _TestUtil.nextInt(random(), minGram, 100);
-    final String s = _TestUtil.randomUnicodeString(random(), 4 * 1024);
+    final int minGram = TestUtil.nextInt(random(), 1, 100);
+    final int maxGram = TestUtil.nextInt(random(), minGram, 100);
+    final String s = TestUtil.randomUnicodeString(random(), 4 * 1024);
     testNGrams(minGram, maxGram, s, "");
     testNGrams(minGram, maxGram, s, "abcdef");
   }
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/ngram/NGramTokenFilterTest.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/ngram/NGramTokenFilterTest.java
index d27f905..811a568 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/ngram/NGramTokenFilterTest.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/ngram/NGramTokenFilterTest.java
@@ -28,11 +28,10 @@ import org.apache.lucene.analysis.core.WhitespaceTokenizer;
 import org.apache.lucene.analysis.miscellaneous.ASCIIFoldingFilter;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
 import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.Version;
-import org.apache.lucene.util._TestUtil;
 
 import java.io.IOException;
-import java.io.Reader;
 import java.io.StringReader;
 import java.util.Random;
 
@@ -146,8 +145,8 @@ public class NGramTokenFilterTest extends BaseTokenStreamTestCase {
   /** blast some random strings through the analyzer */
   public void testRandomStrings() throws Exception {
     for (int i = 0; i < 10; i++) {
-      final int min = _TestUtil.nextInt(random(), 2, 10);
-      final int max = _TestUtil.nextInt(random(), min, 20);
+      final int min = TestUtil.nextInt(random(), 2, 10);
+      final int max = TestUtil.nextInt(random(), min, 20);
       Analyzer a = new Analyzer() {
         @Override
         protected TokenStreamComponents createComponents(String fieldName) {
@@ -186,10 +185,10 @@ public class NGramTokenFilterTest extends BaseTokenStreamTestCase {
   }
 
   public void testSupplementaryCharacters() throws IOException {
-    final String s = _TestUtil.randomUnicodeString(random(), 10);
+    final String s = TestUtil.randomUnicodeString(random(), 10);
     final int codePointCount = s.codePointCount(0, s.length());
-    final int minGram = _TestUtil.nextInt(random(), 1, 3);
-    final int maxGram = _TestUtil.nextInt(random(), minGram, 10);
+    final int minGram = TestUtil.nextInt(random(), 1, 3);
+    final int maxGram = TestUtil.nextInt(random(), minGram, 10);
     TokenStream tk = new KeywordTokenizer();
     ((Tokenizer)tk).setReader(new StringReader(s));
     tk = new NGramTokenFilter(TEST_VERSION_CURRENT, tk, minGram, maxGram);
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/ngram/NGramTokenizerTest.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/ngram/NGramTokenizerTest.java
index 4048159..a7aa260 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/ngram/NGramTokenizerTest.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/ngram/NGramTokenizerTest.java
@@ -18,22 +18,18 @@ package org.apache.lucene.analysis.ngram;
  */
 
 
-import static org.apache.lucene.analysis.ngram.NGramTokenizerTest.isTokenChar;
-
 import java.io.IOException;
-import java.io.Reader;
 import java.io.StringReader;
 import java.util.Arrays;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
 import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
 import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
 import org.apache.lucene.analysis.tokenattributes.PositionLengthAttribute;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 import com.carrotsearch.randomizedtesting.generators.RandomStrings;
 
@@ -115,8 +111,8 @@ public class NGramTokenizerTest extends BaseTokenStreamTestCase {
   /** blast some random strings through the analyzer */
   public void testRandomStrings() throws Exception {
     for (int i = 0; i < 10; i++) {
-      final int min = _TestUtil.nextInt(random(), 2, 10);
-      final int max = _TestUtil.nextInt(random(), min, 20);
+      final int min = TestUtil.nextInt(random(), 2, 10);
+      final int max = TestUtil.nextInt(random(), min, 20);
       Analyzer a = new Analyzer() {
         @Override
         protected TokenStreamComponents createComponents(String fieldName) {
@@ -205,47 +201,47 @@ public class NGramTokenizerTest extends BaseTokenStreamTestCase {
 
   public void testLargeInput() throws IOException {
     // test sliding
-    final int minGram = _TestUtil.nextInt(random(), 1, 100);
-    final int maxGram = _TestUtil.nextInt(random(), minGram, 100);
-    testNGrams(minGram, maxGram, _TestUtil.nextInt(random(), 3 * 1024, 4 * 1024), "");
+    final int minGram = TestUtil.nextInt(random(), 1, 100);
+    final int maxGram = TestUtil.nextInt(random(), minGram, 100);
+    testNGrams(minGram, maxGram, TestUtil.nextInt(random(), 3 * 1024, 4 * 1024), "");
   }
 
   public void testLargeMaxGram() throws IOException {
     // test sliding with maxGram > 1024
-    final int minGram = _TestUtil.nextInt(random(), 1290, 1300);
-    final int maxGram = _TestUtil.nextInt(random(), minGram, 1300);
-    testNGrams(minGram, maxGram, _TestUtil.nextInt(random(), 3 * 1024, 4 * 1024), "");
+    final int minGram = TestUtil.nextInt(random(), 1290, 1300);
+    final int maxGram = TestUtil.nextInt(random(), minGram, 1300);
+    testNGrams(minGram, maxGram, TestUtil.nextInt(random(), 3 * 1024, 4 * 1024), "");
   }
 
   public void testPreTokenization() throws IOException {
-    final int minGram = _TestUtil.nextInt(random(), 1, 100);
-    final int maxGram = _TestUtil.nextInt(random(), minGram, 100);
-    testNGrams(minGram, maxGram, _TestUtil.nextInt(random(), 0, 4 * 1024), "a");
+    final int minGram = TestUtil.nextInt(random(), 1, 100);
+    final int maxGram = TestUtil.nextInt(random(), minGram, 100);
+    testNGrams(minGram, maxGram, TestUtil.nextInt(random(), 0, 4 * 1024), "a");
   }
 
   public void testHeavyPreTokenization() throws IOException {
-    final int minGram = _TestUtil.nextInt(random(), 1, 100);
-    final int maxGram = _TestUtil.nextInt(random(), minGram, 100);
-    testNGrams(minGram, maxGram, _TestUtil.nextInt(random(), 0, 4 * 1024), "abcdef");
+    final int minGram = TestUtil.nextInt(random(), 1, 100);
+    final int maxGram = TestUtil.nextInt(random(), minGram, 100);
+    testNGrams(minGram, maxGram, TestUtil.nextInt(random(), 0, 4 * 1024), "abcdef");
   }
 
   public void testFewTokenChars() throws IOException {
-    final char[] chrs = new char[_TestUtil.nextInt(random(), 4000, 5000)];
+    final char[] chrs = new char[TestUtil.nextInt(random(), 4000, 5000)];
     Arrays.fill(chrs, ' ');
     for (int i = 0; i < chrs.length; ++i) {
       if (random().nextFloat() < 0.1) {
         chrs[i] = 'a';
       }
     }
-    final int minGram = _TestUtil.nextInt(random(), 1, 2);
-    final int maxGram = _TestUtil.nextInt(random(), minGram, 2);
+    final int minGram = TestUtil.nextInt(random(), 1, 2);
+    final int maxGram = TestUtil.nextInt(random(), minGram, 2);
     testNGrams(minGram, maxGram, new String(chrs), " ");
   }
 
   public void testFullUTF8Range() throws IOException {
-    final int minGram = _TestUtil.nextInt(random(), 1, 100);
-    final int maxGram = _TestUtil.nextInt(random(), minGram, 100);
-    final String s = _TestUtil.randomUnicodeString(random(), 4 * 1024);
+    final int minGram = TestUtil.nextInt(random(), 1, 100);
+    final int maxGram = TestUtil.nextInt(random(), minGram, 100);
+    final String s = TestUtil.randomUnicodeString(random(), 4 * 1024);
     testNGrams(minGram, maxGram, s, "");
     testNGrams(minGram, maxGram, s, "abcdef");
   }
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceCharFilter.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceCharFilter.java
index 12175ed..f3cf4b8 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceCharFilter.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceCharFilter.java
@@ -30,7 +30,7 @@ import org.apache.lucene.analysis.CharFilter;
 import org.apache.lucene.analysis.MockTokenizer;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.Ignore;
 
 /**
@@ -302,9 +302,9 @@ public class TestPatternReplaceCharFilter extends BaseTokenStreamTestCase {
     int numPatterns = 10 + random().nextInt(20);
     Random random = new Random(random().nextLong());
     for (int i = 0; i < numPatterns; i++) {
-      final Pattern p = _TestUtil.randomPattern(random());
+      final Pattern p = TestUtil.randomPattern(random());
 
-      final String replacement = _TestUtil.randomSimpleString(random);
+      final String replacement = TestUtil.randomSimpleString(random);
       Analyzer a = new Analyzer() {
         @Override
         protected TokenStreamComponents createComponents(String fieldName) {
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymMapFilter.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymMapFilter.java
index 7fd013e..946c902 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymMapFilter.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymMapFilter.java
@@ -18,7 +18,6 @@
 package org.apache.lucene.analysis.synonym;
 
 import java.io.IOException;
-import java.io.Reader;
 import java.io.StringReader;
 import java.util.ArrayList;
 import java.util.Arrays;
@@ -39,7 +38,7 @@ import org.apache.lucene.analysis.MockGraphTokenFilter;
 import org.apache.lucene.analysis.core.KeywordTokenizer;
 import org.apache.lucene.analysis.tokenattributes.*;
 import org.apache.lucene.util.CharsRef;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestSynonymMapFilter extends BaseTokenStreamTestCase {
 
@@ -383,7 +382,7 @@ public class TestSynonymMapFilter extends BaseTokenStreamTestCase {
 
   public void testRandom() throws Exception {
     
-    final int alphabetSize = _TestUtil.nextInt(random(), 2, 7);
+    final int alphabetSize = TestUtil.nextInt(random(), 2, 7);
 
     final int docLen = atLeast(3000);
     //final int docLen = 50;
@@ -405,7 +404,7 @@ public class TestSynonymMapFilter extends BaseTokenStreamTestCase {
     }
     b = new SynonymMap.Builder(dedup);
     for(int synIDX=0;synIDX<numSyn;synIDX++) {
-      final String synIn = getRandomString('a', alphabetSize, _TestUtil.nextInt(random(), 1, 5)).trim();
+      final String synIn = getRandomString('a', alphabetSize, TestUtil.nextInt(random(), 1, 5)).trim();
       OneSyn s = synMap.get(synIn);
       if (s == null) {
         s = new OneSyn();
@@ -415,7 +414,7 @@ public class TestSynonymMapFilter extends BaseTokenStreamTestCase {
         synMap.put(synIn, s);
         s.keepOrig = random().nextBoolean();
       }
-      final String synOut = getRandomString('0', 10, _TestUtil.nextInt(random(), 1, 5)).trim();
+      final String synOut = getRandomString('0', 10, TestUtil.nextInt(random(), 1, 5)).trim();
       s.out.add(synOut);
       add(synIn, synOut, s.keepOrig);
       if (VERBOSE) {
@@ -472,7 +471,7 @@ public class TestSynonymMapFilter extends BaseTokenStreamTestCase {
 
   private String randomNonEmptyString() {
     while(true) {
-      final String s = _TestUtil.randomUnicodeString(random()).trim();
+      final String s = TestUtil.randomUnicodeString(random()).trim();
       if (s.length() != 0 && s.indexOf('\u0000') == -1) {
         return s;
       }
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestCharArrayIterator.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestCharArrayIterator.java
index cbabcf1..d593b3d 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestCharArrayIterator.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestCharArrayIterator.java
@@ -22,8 +22,7 @@ import java.text.CharacterIterator;
 import java.util.Locale;
 
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util.UnicodeUtil;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestCharArrayIterator extends LuceneTestCase {
   
@@ -36,7 +35,7 @@ public class TestCharArrayIterator extends LuceneTestCase {
     BreakIterator bi = BreakIterator.getWordInstance(Locale.getDefault());
     CharArrayIterator ci = CharArrayIterator.newWordInstance();
     for (int i = 0; i < 10000; i++) {
-      char text[] = _TestUtil.randomUnicodeString(random()).toCharArray();
+      char text[] = TestUtil.randomUnicodeString(random()).toCharArray();
       ci.setText(text, 0, text.length);
       consume(bi, ci);
     }
@@ -66,7 +65,7 @@ public class TestCharArrayIterator extends LuceneTestCase {
     BreakIterator bi = BreakIterator.getSentenceInstance(Locale.getDefault());
     CharArrayIterator ci = CharArrayIterator.newSentenceInstance();
     for (int i = 0; i < 10000; i++) {
-      char text[] = _TestUtil.randomUnicodeString(random()).toCharArray();
+      char text[] = TestUtil.randomUnicodeString(random()).toCharArray();
       ci.setText(text, 0, text.length);
       consume(bi, ci);
     }
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestCharTokenizers.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestCharTokenizers.java
index 516026d..84a181e 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestCharTokenizers.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestCharTokenizers.java
@@ -18,7 +18,6 @@ package org.apache.lucene.analysis.util;
  */
 
 import java.io.IOException;
-import java.io.Reader;
 import java.io.StringReader;
 import java.util.Locale;
 
@@ -29,7 +28,7 @@ import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.core.LetterTokenizer;
 import org.apache.lucene.analysis.core.LowerCaseTokenizer;
 import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 
 /**
@@ -126,7 +125,7 @@ public class TestCharTokenizers extends BaseTokenStreamTestCase {
     };
     int num = 1000 * RANDOM_MULTIPLIER;
     for (int i = 0; i < num; i++) {
-      String s = _TestUtil.randomUnicodeString(random());
+      String s = TestUtil.randomUnicodeString(random());
       try (TokenStream ts = analyzer.tokenStream("foo", s)) {
         ts.reset();
         OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);
@@ -164,7 +163,7 @@ public class TestCharTokenizers extends BaseTokenStreamTestCase {
     };
     int num = 1000 * RANDOM_MULTIPLIER;
     for (int i = 0; i < num; i++) {
-      String s = _TestUtil.randomUnicodeString(random());
+      String s = TestUtil.randomUnicodeString(random());
       try (TokenStream ts = analyzer.tokenStream("foo", s)) {
         ts.reset();
         OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestCharacterUtils.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestCharacterUtils.java
index 3c88454..f31f913 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestCharacterUtils.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestCharacterUtils.java
@@ -24,7 +24,7 @@ import java.util.Arrays;
 
 import org.apache.lucene.analysis.util.CharacterUtils.CharacterBuffer;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.Test;
 
 /**
@@ -79,7 +79,7 @@ public class TestCharacterUtils extends LuceneTestCase {
   public void testCodePointCount() {
     CharacterUtils java4 = CharacterUtils.getJava4Instance();
     CharacterUtils java5 = CharacterUtils.getInstance(TEST_VERSION_CURRENT);
-    final String s = _TestUtil.randomUnicodeString(random());
+    final String s = TestUtil.randomUnicodeString(random());
     assertEquals(s.length(), java4.codePointCount(s));
     assertEquals(Character.codePointCount(s, 0, s.length()), java5.codePointCount(s));
   }
@@ -89,8 +89,8 @@ public class TestCharacterUtils extends LuceneTestCase {
     CharacterUtils java4 = CharacterUtils.getJava4Instance();
     CharacterUtils java5 = CharacterUtils.getInstance(TEST_VERSION_CURRENT);
     for (int i = 0; i < 10; ++i) {
-      final char[] s = _TestUtil.randomUnicodeString(random()).toCharArray();
-      final int index = _TestUtil.nextInt(random(), 0, s.length);
+      final char[] s = TestUtil.randomUnicodeString(random()).toCharArray();
+      final int index = TestUtil.nextInt(random(), 0, s.length);
       final int offset = random().nextInt(7) - 3;
       try {
         final int o = java4.offsetByCodePoints(s, 0, s.length, index, offset);
@@ -125,12 +125,12 @@ public class TestCharacterUtils extends LuceneTestCase {
   }
 
   private void testConversions(CharacterUtils charUtils) {
-    final char[] orig = _TestUtil.randomUnicodeString(random(), 100).toCharArray();
+    final char[] orig = TestUtil.randomUnicodeString(random(), 100).toCharArray();
     final int[] buf = new int[orig.length];
     final char[] restored = new char[buf.length];
-    final int o1 = _TestUtil.nextInt(random(), 0, Math.min(5, orig.length));
-    final int o2 = _TestUtil.nextInt(random(), 0, o1);
-    final int o3 = _TestUtil.nextInt(random(), 0, o1);
+    final int o1 = TestUtil.nextInt(random(), 0, Math.min(5, orig.length));
+    final int o2 = TestUtil.nextInt(random(), 0, o1);
+    final int o3 = TestUtil.nextInt(random(), 0, o1);
     final int codePointCount = charUtils.toCodePoints(orig, o1, orig.length - o1, buf, o2);
     final int charCount = charUtils.toChars(buf, o2, codePointCount, restored, o3);
     assertEquals(orig.length - o1, charCount);
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestFilesystemResourceLoader.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestFilesystemResourceLoader.java
index 8e065d6..977781b 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestFilesystemResourceLoader.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestFilesystemResourceLoader.java
@@ -26,7 +26,8 @@ import java.io.Writer;
 
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestFilesystemResourceLoader extends LuceneTestCase {
   
@@ -60,7 +61,7 @@ public class TestFilesystemResourceLoader extends LuceneTestCase {
   }
   
   public void testBaseDir() throws Exception {
-    final File base = _TestUtil.getTempDir("fsResourceLoaderBase").getAbsoluteFile();
+    final File base = TestUtil.getTempDir("fsResourceLoaderBase").getAbsoluteFile();
     try {
       base.mkdirs();
       Writer os = new OutputStreamWriter(new FileOutputStream(new File(base, "template.txt")), IOUtils.CHARSET_UTF_8);
@@ -86,7 +87,7 @@ public class TestFilesystemResourceLoader extends LuceneTestCase {
       assertClasspathDelegation(rl);
       assertNotFound(rl);
     } finally {
-      _TestUtil.rmDir(base);
+      TestUtil.rmDir(base);
     }
   }
   
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestRollingCharBuffer.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestRollingCharBuffer.java
index b0da1fd..d249663 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestRollingCharBuffer.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestRollingCharBuffer.java
@@ -21,7 +21,7 @@ import java.io.StringReader;
 import java.util.Random;
 
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestRollingCharBuffer extends LuceneTestCase {
 
@@ -37,7 +37,7 @@ public class TestRollingCharBuffer extends LuceneTestCase {
       if (stringLen == 0) {
         s = "";
       } else {
-        s = _TestUtil.randomUnicodeString(random, stringLen);
+        s = TestUtil.randomUnicodeString(random, stringLen);
       }
       if (VERBOSE) {
         System.out.println("\nTEST: iter=" + iter + " s.length()=" + s.length());
@@ -59,7 +59,7 @@ public class TestRollingCharBuffer extends LuceneTestCase {
           availCount++;
         } else if (random.nextBoolean()) {
           // Read previous char
-          int pos = _TestUtil.nextInt(random, nextRead-availCount, nextRead-1);
+          int pos = TestUtil.nextInt(random, nextRead - availCount, nextRead - 1);
           if (VERBOSE) {
             System.out.println("    old char pos=" + pos);
           }
@@ -70,7 +70,7 @@ public class TestRollingCharBuffer extends LuceneTestCase {
           if (availCount == 1) {
             length = 1;
           } else {
-            length = _TestUtil.nextInt(random, 1, availCount);
+            length = TestUtil.nextInt(random, 1, availCount);
           }
           int start;
           if (length == availCount) {
diff --git a/lucene/analysis/icu/src/test/org/apache/lucene/collation/TestICUCollationDocValuesField.java b/lucene/analysis/icu/src/test/org/apache/lucene/collation/TestICUCollationDocValuesField.java
index 9cc9fa9..99a489d 100644
--- a/lucene/analysis/icu/src/test/org/apache/lucene/collation/TestICUCollationDocValuesField.java
+++ b/lucene/analysis/icu/src/test/org/apache/lucene/collation/TestICUCollationDocValuesField.java
@@ -37,7 +37,7 @@ import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.LuceneTestCase.SuppressCodecs;
 
 import com.ibm.icu.text.Collator;
@@ -95,7 +95,7 @@ public class TestICUCollationDocValuesField extends LuceneTestCase {
     
     int numDocs = atLeast(500);
     for (int i = 0; i < numDocs; i++) {
-      String value = _TestUtil.randomSimpleString(random());
+      String value = TestUtil.randomSimpleString(random());
       field.setStringValue(value);
       collationField.setStringValue(value);
       iw.addDocument(doc);
@@ -107,8 +107,8 @@ public class TestICUCollationDocValuesField extends LuceneTestCase {
     
     int numChecks = atLeast(100);
     for (int i = 0; i < numChecks; i++) {
-      String start = _TestUtil.randomSimpleString(random());
-      String end = _TestUtil.randomSimpleString(random());
+      String start = TestUtil.randomSimpleString(random());
+      String end = TestUtil.randomSimpleString(random());
       BytesRef lowerVal = new BytesRef(collator.getCollationKey(start).toByteArray());
       BytesRef upperVal = new BytesRef(collator.getCollationKey(end).toByteArray());
       Query query = new ConstantScoreQuery(FieldCacheRangeFilter.newBytesRefRange("collated", lowerVal, upperVal, true, true));
diff --git a/lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestExtendedMode.java b/lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestExtendedMode.java
index e07dd8f..7a15700 100644
--- a/lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestExtendedMode.java
+++ b/lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestExtendedMode.java
@@ -18,7 +18,6 @@ package org.apache.lucene.analysis.ja;
  */
 
 import java.io.IOException;
-import java.io.Reader;
 import java.util.Random;
 
 import org.apache.lucene.analysis.Analyzer;
@@ -27,8 +26,8 @@ import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.ja.JapaneseTokenizer.Mode;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.UnicodeUtil;
-import org.apache.lucene.util._TestUtil;
 import org.apache.lucene.util.LuceneTestCase.Slow;
 
 @Slow
@@ -52,7 +51,7 @@ public class TestExtendedMode extends BaseTokenStreamTestCase {
   public void testSurrogates2() throws IOException {
     int numIterations = atLeast(1000);
     for (int i = 0; i < numIterations; i++) {
-      String s = _TestUtil.randomUnicodeString(random(), 100);
+      String s = TestUtil.randomUnicodeString(random(), 100);
       try (TokenStream ts = analyzer.tokenStream("foo", s)) {
         CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);
         ts.reset();
diff --git a/lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseTokenizer.java b/lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseTokenizer.java
index 4135d40..3ca8a46 100644
--- a/lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseTokenizer.java
+++ b/lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseTokenizer.java
@@ -35,8 +35,8 @@ import org.apache.lucene.analysis.ja.dict.UserDictionary;
 import org.apache.lucene.analysis.ja.tokenattributes.*;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
 import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.UnicodeUtil;
-import org.apache.lucene.util._TestUtil;
 import org.apache.lucene.util.LuceneTestCase.Slow;
 
 @Slow
@@ -212,7 +212,7 @@ public class TestJapaneseTokenizer extends BaseTokenStreamTestCase {
 
   public void testLargeDocReliability() throws Exception {
     for (int i = 0; i < 100; i++) {
-      String s = _TestUtil.randomUnicodeString(random(), 10000);
+      String s = TestUtil.randomUnicodeString(random(), 10000);
       try (TokenStream ts = analyzer.tokenStream("foo", s)) {
         ts.reset();
         while (ts.incrementToken()) {
@@ -235,7 +235,7 @@ public class TestJapaneseTokenizer extends BaseTokenStreamTestCase {
       if (VERBOSE) {
         System.out.println("\nTEST: iter=" + i);
       }
-      String s = _TestUtil.randomUnicodeString(random(), 100);
+      String s = TestUtil.randomUnicodeString(random(), 100);
       try (TokenStream ts = analyzer.tokenStream("foo", s)) {
         CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);
         ts.reset();
diff --git a/lucene/analysis/phonetic/src/test/org/apache/lucene/analysis/phonetic/DoubleMetaphoneFilterTest.java b/lucene/analysis/phonetic/src/test/org/apache/lucene/analysis/phonetic/DoubleMetaphoneFilterTest.java
index 8efc182..9069fc6 100644
--- a/lucene/analysis/phonetic/src/test/org/apache/lucene/analysis/phonetic/DoubleMetaphoneFilterTest.java
+++ b/lucene/analysis/phonetic/src/test/org/apache/lucene/analysis/phonetic/DoubleMetaphoneFilterTest.java
@@ -17,7 +17,6 @@
 package org.apache.lucene.analysis.phonetic;
 
 import java.io.IOException;
-import java.io.Reader;
 import java.io.StringReader;
 
 import org.apache.lucene.analysis.Analyzer;
@@ -27,7 +26,7 @@ import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.core.KeywordTokenizer;
 import org.apache.lucene.analysis.core.WhitespaceTokenizer;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class DoubleMetaphoneFilterTest extends BaseTokenStreamTestCase {
   
@@ -79,7 +78,7 @@ public class DoubleMetaphoneFilterTest extends BaseTokenStreamTestCase {
   }
 
   public void testRandom() throws Exception {
-    final int codeLen = _TestUtil.nextInt(random(), 1, 8);
+    final int codeLen = TestUtil.nextInt(random(), 1, 8);
     Analyzer a = new Analyzer() {
 
       @Override
diff --git a/lucene/analysis/stempel/src/test/org/egothor/stemmer/TestCompile.java b/lucene/analysis/stempel/src/test/org/egothor/stemmer/TestCompile.java
index a47e6fb..76bd275 100644
--- a/lucene/analysis/stempel/src/test/org/egothor/stemmer/TestCompile.java
+++ b/lucene/analysis/stempel/src/test/org/egothor/stemmer/TestCompile.java
@@ -65,18 +65,17 @@ import java.io.IOException;
 import java.io.InputStream;
 import java.io.InputStreamReader;
 import java.io.LineNumberReader;
-import java.net.URI;
 import java.util.Locale;
 import java.util.StringTokenizer;
 
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestCompile extends LuceneTestCase {
   
   public void testCompile() throws Exception {
-    File dir = _TestUtil.getTempDir("testCompile");
+    File dir = TestUtil.getTempDir("testCompile");
     dir.mkdirs();
     InputStream input = getClass().getResourceAsStream("testRules.txt");
     File output = new File(dir, "testRules.txt");
@@ -92,7 +91,7 @@ public class TestCompile extends LuceneTestCase {
   }
   
   public void testCompileBackwards() throws Exception {
-    File dir = _TestUtil.getTempDir("testCompile");
+    File dir = TestUtil.getTempDir("testCompile");
     dir.mkdirs();
     InputStream input = getClass().getResourceAsStream("testRules.txt");
     File output = new File(dir, "testRules.txt");
@@ -108,7 +107,7 @@ public class TestCompile extends LuceneTestCase {
   }
   
   public void testCompileMulti() throws Exception {
-    File dir = _TestUtil.getTempDir("testCompile");
+    File dir = TestUtil.getTempDir("testCompile");
     dir.mkdirs();
     InputStream input = getClass().getResourceAsStream("testRules.txt");
     File output = new File(dir, "testRules.txt");
diff --git a/lucene/benchmark/src/test/org/apache/lucene/benchmark/BenchmarkTestCase.java b/lucene/benchmark/src/test/org/apache/lucene/benchmark/BenchmarkTestCase.java
index b385846..a00d727 100644
--- a/lucene/benchmark/src/test/org/apache/lucene/benchmark/BenchmarkTestCase.java
+++ b/lucene/benchmark/src/test/org/apache/lucene/benchmark/BenchmarkTestCase.java
@@ -26,7 +26,7 @@ import java.io.StringReader;
 
 import org.apache.lucene.benchmark.byTask.Benchmark;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.AfterClass;
 import org.junit.BeforeClass;
 
@@ -36,7 +36,7 @@ public abstract class BenchmarkTestCase extends LuceneTestCase {
   
   @BeforeClass
   public static void beforeClassBenchmarkTestCase() {
-    WORKDIR = _TestUtil.getTempDir("benchmark");
+    WORKDIR = TestUtil.getTempDir("benchmark");
     WORKDIR.delete();
     WORKDIR.mkdirs();
   }
diff --git a/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic.java b/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic.java
index 55be93a..2100e79 100644
--- a/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic.java
+++ b/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic.java
@@ -48,7 +48,6 @@ import org.apache.lucene.index.IndexWriterConfig.OpenMode;
 import org.apache.lucene.index.IndexWriterConfig;
 import org.apache.lucene.index.LogDocMergePolicy;
 import org.apache.lucene.index.LogMergePolicy;
-import org.apache.lucene.index.MergePolicy;
 import org.apache.lucene.index.MultiFields;
 import org.apache.lucene.index.SegmentInfos;
 import org.apache.lucene.index.SerialMergeScheduler;
@@ -60,7 +59,8 @@ import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.search.FieldCache;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Test very simply that perf tasks - simple algorithms - are doing what they should.
@@ -505,7 +505,7 @@ public class TestPerfTasksLogic extends BenchmarkTestCase {
       TermsEnum termsEnum = terms.iterator(null);
       DocsEnum docs = null;
       while(termsEnum.next() != null) {
-        docs = _TestUtil.docs(random(), termsEnum, MultiFields.getLiveDocs(reader), docs, DocsEnum.FLAG_FREQS);
+        docs = TestUtil.docs(random(), termsEnum, MultiFields.getLiveDocs(reader), docs, DocsEnum.FLAG_FREQS);
         while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
           totalTokenCount2 += docs.freq();
         }
diff --git a/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/feeds/TrecContentSourceTest.java b/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/feeds/TrecContentSourceTest.java
index 0a2bb4e..81d2513 100644
--- a/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/feeds/TrecContentSourceTest.java
+++ b/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/feeds/TrecContentSourceTest.java
@@ -31,7 +31,8 @@ import org.apache.lucene.benchmark.byTask.feeds.TrecDocParser.ParsePathType;
 import org.apache.lucene.benchmark.byTask.utils.Config;
 import org.apache.lucene.document.DateTools;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TrecContentSourceTest extends LuceneTestCase {
 
@@ -343,8 +344,8 @@ public class TrecContentSourceTest extends LuceneTestCase {
    * supported formats - bzip, gzip, txt. 
    */
   public void testTrecFeedDirAllTypes() throws Exception {
-    File dataDir =  _TestUtil.getTempDir("trecFeedAllTypes");
-    _TestUtil.unzip(getDataFile("trecdocs.zip"), dataDir);
+    File dataDir =  TestUtil.getTempDir("trecFeedAllTypes");
+    TestUtil.unzip(getDataFile("trecdocs.zip"), dataDir);
     TrecContentSource tcs = new TrecContentSource();
     Properties props = new Properties();
     props.setProperty("print.props", "false");
diff --git a/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/tasks/AddIndexesTaskTest.java b/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/tasks/AddIndexesTaskTest.java
index 68f2aa3..b8a4da5 100644
--- a/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/tasks/AddIndexesTaskTest.java
+++ b/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/tasks/AddIndexesTaskTest.java
@@ -30,7 +30,8 @@ import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.IndexWriterConfig;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.RAMDirectory;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.BeforeClass;
 
 /** Tests the functionality of {@link AddIndexesTask}. */
@@ -40,7 +41,7 @@ public class AddIndexesTaskTest extends BenchmarkTestCase {
   
   @BeforeClass
   public static void beforeClassAddIndexesTaskTest() throws Exception {
-    testDir = _TestUtil.getTempDir("addIndexesTask");
+    testDir = TestUtil.getTempDir("addIndexesTask");
     
     // create a dummy index under inputDir
     inputDir = new File(testDir, "input");
diff --git a/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/utils/StreamUtilsTest.java b/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/utils/StreamUtilsTest.java
index 7a291a8..8c4c50c 100644
--- a/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/utils/StreamUtilsTest.java
+++ b/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/utils/StreamUtilsTest.java
@@ -21,7 +21,6 @@ import java.io.BufferedReader;
 import java.io.BufferedWriter;
 import java.io.File;
 import java.io.FileOutputStream;
-import java.io.FileWriter;
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.InputStreamReader;
@@ -30,9 +29,8 @@ import java.io.OutputStreamWriter;
 
 import org.apache.commons.compress.compressors.CompressorStreamFactory;
 import org.apache.lucene.benchmark.BenchmarkTestCase;
-import org.apache.lucene.benchmark.byTask.utils.StreamUtils;
 import org.apache.lucene.util.IOUtils;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.After;
 import org.junit.Before;
 import org.junit.Test;
@@ -138,14 +136,14 @@ public class StreamUtilsTest extends BenchmarkTestCase {
   public void setUp() throws Exception {
     super.setUp();
     testDir = new File(getWorkDir(),"ContentSourceTest");
-    _TestUtil.rmDir(testDir);
+    TestUtil.rmDir(testDir);
     assertTrue(testDir.mkdirs());
   }
 
   @Override
   @After
   public void tearDown() throws Exception {
-    _TestUtil.rmDir(testDir);
+    TestUtil.rmDir(testDir);
     super.tearDown();
   }
 
diff --git a/lucene/classification/src/test/org/apache/lucene/classification/ClassificationTestBase.java b/lucene/classification/src/test/org/apache/lucene/classification/ClassificationTestBase.java
index f8de59f..86ef649 100644
--- a/lucene/classification/src/test/org/apache/lucene/classification/ClassificationTestBase.java
+++ b/lucene/classification/src/test/org/apache/lucene/classification/ClassificationTestBase.java
@@ -28,7 +28,7 @@ import org.apache.lucene.search.Query;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.After;
 import org.junit.Before;
 
@@ -238,7 +238,7 @@ public abstract class ClassificationTestBase<T> extends LuceneTestCase {
   private String createRandomString(Random random) {
     StringBuilder builder = new StringBuilder();
     for (int i = 0; i < 20; i++) {
-      builder.append(_TestUtil.randomSimpleString(random, 5));
+      builder.append(TestUtil.randomSimpleString(random, 5));
       builder.append(" ");
     }
     return builder.toString();
diff --git a/lucene/classification/src/test/org/apache/lucene/classification/utils/DataSplitterTest.java b/lucene/classification/src/test/org/apache/lucene/classification/utils/DataSplitterTest.java
index 6e74cce..84cccb7 100644
--- a/lucene/classification/src/test/org/apache/lucene/classification/utils/DataSplitterTest.java
+++ b/lucene/classification/src/test/org/apache/lucene/classification/utils/DataSplitterTest.java
@@ -30,7 +30,7 @@ import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.index.SlowCompositeReaderWrapper;
 import org.apache.lucene.store.BaseDirectoryWrapper;
 import org.apache.lucene.store.Directory;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.LuceneTestCase;
 import org.junit.After;
 import org.junit.Before;
@@ -71,8 +71,8 @@ public class DataSplitterTest extends LuceneTestCase {
     for (int i = 0; i < 100; i++) {
       doc = new Document();
       doc.add(new Field(idFieldName, Integer.toString(i), ft));
-      doc.add(new Field(textFieldName, _TestUtil.randomUnicodeString(rnd, 1024), ft));
-      doc.add(new Field(classFieldName, _TestUtil.randomUnicodeString(rnd, 10), ft));
+      doc.add(new Field(textFieldName, TestUtil.randomUnicodeString(rnd, 1024), ft));
+      doc.add(new Field(classFieldName, TestUtil.randomUnicodeString(rnd, 10), ft));
       indexWriter.addDocument(doc, analyzer);
     }
 
diff --git a/lucene/codecs/src/test/org/apache/lucene/codecs/blockterms/TestFixedGapPostingsFormat.java b/lucene/codecs/src/test/org/apache/lucene/codecs/blockterms/TestFixedGapPostingsFormat.java
index 1aaeeff..c05cc14 100644
--- a/lucene/codecs/src/test/org/apache/lucene/codecs/blockterms/TestFixedGapPostingsFormat.java
+++ b/lucene/codecs/src/test/org/apache/lucene/codecs/blockterms/TestFixedGapPostingsFormat.java
@@ -20,13 +20,14 @@ package org.apache.lucene.codecs.blockterms;
 import org.apache.lucene.codecs.Codec;
 import org.apache.lucene.codecs.lucene41ords.Lucene41WithOrds;
 import org.apache.lucene.index.BasePostingsFormatTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Basic tests of a PF using FixedGap terms dictionary
  */
 public class TestFixedGapPostingsFormat extends BasePostingsFormatTestCase {
-  private final Codec codec = _TestUtil.alwaysPostingsFormat(new Lucene41WithOrds(_TestUtil.nextInt(random(), 1, 1000)));
+  private final Codec codec = TestUtil.alwaysPostingsFormat(new Lucene41WithOrds(TestUtil.nextInt(random(), 1, 1000)));
 
   @Override
   protected Codec getCodec() {
diff --git a/lucene/codecs/src/test/org/apache/lucene/codecs/blockterms/TestVarGapDocFreqIntervalPostingsFormat.java b/lucene/codecs/src/test/org/apache/lucene/codecs/blockterms/TestVarGapDocFreqIntervalPostingsFormat.java
index 16ae249..59608f8 100644
--- a/lucene/codecs/src/test/org/apache/lucene/codecs/blockterms/TestVarGapDocFreqIntervalPostingsFormat.java
+++ b/lucene/codecs/src/test/org/apache/lucene/codecs/blockterms/TestVarGapDocFreqIntervalPostingsFormat.java
@@ -20,13 +20,13 @@ package org.apache.lucene.codecs.blockterms;
 import org.apache.lucene.codecs.Codec;
 import org.apache.lucene.codecs.lucene41vargap.Lucene41VarGapFixedInterval;
 import org.apache.lucene.index.BasePostingsFormatTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Basic tests of a PF using VariableGap terms dictionary (fixed interval)
  */
 public class TestVarGapDocFreqIntervalPostingsFormat extends BasePostingsFormatTestCase {
-  private final Codec codec = _TestUtil.alwaysPostingsFormat(new Lucene41VarGapFixedInterval(_TestUtil.nextInt(random(), 1, 1000)));
+  private final Codec codec = TestUtil.alwaysPostingsFormat(new Lucene41VarGapFixedInterval(TestUtil.nextInt(random(), 1, 1000)));
 
   @Override
   protected Codec getCodec() {
diff --git a/lucene/codecs/src/test/org/apache/lucene/codecs/blockterms/TestVarGapFixedIntervalPostingsFormat.java b/lucene/codecs/src/test/org/apache/lucene/codecs/blockterms/TestVarGapFixedIntervalPostingsFormat.java
index 4ae298d..d0935a1 100644
--- a/lucene/codecs/src/test/org/apache/lucene/codecs/blockterms/TestVarGapFixedIntervalPostingsFormat.java
+++ b/lucene/codecs/src/test/org/apache/lucene/codecs/blockterms/TestVarGapFixedIntervalPostingsFormat.java
@@ -20,13 +20,13 @@ package org.apache.lucene.codecs.blockterms;
 import org.apache.lucene.codecs.Codec;
 import org.apache.lucene.codecs.lucene41vargap.Lucene41VarGapDocFreqInterval;
 import org.apache.lucene.index.BasePostingsFormatTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Basic tests of a PF using VariableGap terms dictionary (fixed interval, docFreq threshold)
  */
 public class TestVarGapFixedIntervalPostingsFormat extends BasePostingsFormatTestCase {
-  private final Codec codec = _TestUtil.alwaysPostingsFormat(new Lucene41VarGapDocFreqInterval(_TestUtil.nextInt(random(), 1, 100), _TestUtil.nextInt(random(), 1, 1000)));
+  private final Codec codec = TestUtil.alwaysPostingsFormat(new Lucene41VarGapDocFreqInterval(TestUtil.nextInt(random(), 1, 100), TestUtil.nextInt(random(), 1, 1000)));
 
   @Override
   protected Codec getCodec() {
diff --git a/lucene/codecs/src/test/org/apache/lucene/codecs/bloom/TestBloomPostingsFormat.java b/lucene/codecs/src/test/org/apache/lucene/codecs/bloom/TestBloomPostingsFormat.java
index ceff6b9..b844d6f 100644
--- a/lucene/codecs/src/test/org/apache/lucene/codecs/bloom/TestBloomPostingsFormat.java
+++ b/lucene/codecs/src/test/org/apache/lucene/codecs/bloom/TestBloomPostingsFormat.java
@@ -19,13 +19,13 @@ package org.apache.lucene.codecs.bloom;
 
 import org.apache.lucene.codecs.Codec;
 import org.apache.lucene.index.BasePostingsFormatTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Basic tests for BloomPostingsFormat
  */
 public class TestBloomPostingsFormat extends BasePostingsFormatTestCase {
-  private final Codec codec = _TestUtil.alwaysPostingsFormat(new TestBloomFilteredLucene41Postings());
+  private final Codec codec = TestUtil.alwaysPostingsFormat(new TestBloomFilteredLucene41Postings());
 
   @Override
   protected Codec getCodec() {
diff --git a/lucene/codecs/src/test/org/apache/lucene/codecs/diskdv/TestDiskDocValuesFormat.java b/lucene/codecs/src/test/org/apache/lucene/codecs/diskdv/TestDiskDocValuesFormat.java
index 1761e4f..b6cff44 100644
--- a/lucene/codecs/src/test/org/apache/lucene/codecs/diskdv/TestDiskDocValuesFormat.java
+++ b/lucene/codecs/src/test/org/apache/lucene/codecs/diskdv/TestDiskDocValuesFormat.java
@@ -19,13 +19,13 @@ package org.apache.lucene.codecs.diskdv;
 
 import org.apache.lucene.codecs.Codec;
 import org.apache.lucene.index.BaseCompressingDocValuesFormatTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Tests DiskDocValuesFormat
  */
 public class TestDiskDocValuesFormat extends BaseCompressingDocValuesFormatTestCase {
-  private final Codec codec = _TestUtil.alwaysDocValuesFormat(new DiskDocValuesFormat());
+  private final Codec codec = TestUtil.alwaysDocValuesFormat(new DiskDocValuesFormat());
 
   @Override
   protected Codec getCodec() {
diff --git a/lucene/codecs/src/test/org/apache/lucene/codecs/intblock/TestFixedIntBlockPostingsFormat.java b/lucene/codecs/src/test/org/apache/lucene/codecs/intblock/TestFixedIntBlockPostingsFormat.java
index 0793e75..2bf392c 100644
--- a/lucene/codecs/src/test/org/apache/lucene/codecs/intblock/TestFixedIntBlockPostingsFormat.java
+++ b/lucene/codecs/src/test/org/apache/lucene/codecs/intblock/TestFixedIntBlockPostingsFormat.java
@@ -20,14 +20,14 @@ package org.apache.lucene.codecs.intblock;
 import org.apache.lucene.codecs.Codec;
 import org.apache.lucene.codecs.mockintblock.MockFixedIntBlockPostingsFormat;
 import org.apache.lucene.index.BasePostingsFormatTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Basic tests for FixedIntBlock
  */
 public class TestFixedIntBlockPostingsFormat extends BasePostingsFormatTestCase {
   // TODO: randomize blocksize
-  private final Codec codec = _TestUtil.alwaysPostingsFormat(new MockFixedIntBlockPostingsFormat());
+  private final Codec codec = TestUtil.alwaysPostingsFormat(new MockFixedIntBlockPostingsFormat());
 
   @Override
   protected Codec getCodec() {
diff --git a/lucene/codecs/src/test/org/apache/lucene/codecs/intblock/TestVariableIntBlockPostingsFormat.java b/lucene/codecs/src/test/org/apache/lucene/codecs/intblock/TestVariableIntBlockPostingsFormat.java
index 8671fe7..201537d 100644
--- a/lucene/codecs/src/test/org/apache/lucene/codecs/intblock/TestVariableIntBlockPostingsFormat.java
+++ b/lucene/codecs/src/test/org/apache/lucene/codecs/intblock/TestVariableIntBlockPostingsFormat.java
@@ -20,14 +20,15 @@ package org.apache.lucene.codecs.intblock;
 import org.apache.lucene.codecs.Codec;
 import org.apache.lucene.codecs.mockintblock.MockVariableIntBlockPostingsFormat;
 import org.apache.lucene.index.BasePostingsFormatTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Basic tests for VariableIntBlock
  */
 public class TestVariableIntBlockPostingsFormat extends BasePostingsFormatTestCase {
   // TODO: randomize blocksize
-  private final Codec codec = _TestUtil.alwaysPostingsFormat( new MockVariableIntBlockPostingsFormat());
+  private final Codec codec = TestUtil.alwaysPostingsFormat(new MockVariableIntBlockPostingsFormat());
 
   @Override
   protected Codec getCodec() {
diff --git a/lucene/codecs/src/test/org/apache/lucene/codecs/memory/TestDirectDocValuesFormat.java b/lucene/codecs/src/test/org/apache/lucene/codecs/memory/TestDirectDocValuesFormat.java
index fa62152..1073c11 100644
--- a/lucene/codecs/src/test/org/apache/lucene/codecs/memory/TestDirectDocValuesFormat.java
+++ b/lucene/codecs/src/test/org/apache/lucene/codecs/memory/TestDirectDocValuesFormat.java
@@ -19,13 +19,13 @@ package org.apache.lucene.codecs.memory;
 
 import org.apache.lucene.codecs.Codec;
 import org.apache.lucene.index.BaseDocValuesFormatTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Tests DirectDocValuesFormat
  */
 public class TestDirectDocValuesFormat extends BaseDocValuesFormatTestCase {
-  private final Codec codec = _TestUtil.alwaysDocValuesFormat(new DirectDocValuesFormat());
+  private final Codec codec = TestUtil.alwaysDocValuesFormat(new DirectDocValuesFormat());
 
   @Override
   protected Codec getCodec() {
diff --git a/lucene/codecs/src/test/org/apache/lucene/codecs/memory/TestDirectPostingsFormat.java b/lucene/codecs/src/test/org/apache/lucene/codecs/memory/TestDirectPostingsFormat.java
index 85b4290..2b785e4 100644
--- a/lucene/codecs/src/test/org/apache/lucene/codecs/memory/TestDirectPostingsFormat.java
+++ b/lucene/codecs/src/test/org/apache/lucene/codecs/memory/TestDirectPostingsFormat.java
@@ -19,14 +19,15 @@ package org.apache.lucene.codecs.memory;
 
 import org.apache.lucene.codecs.Codec;
 import org.apache.lucene.index.BasePostingsFormatTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Tests DirectPostingsFormat
  */
 public class TestDirectPostingsFormat extends BasePostingsFormatTestCase {
   // TODO: randomize parameters
-  private final Codec codec = _TestUtil.alwaysPostingsFormat(new DirectPostingsFormat());
+  private final Codec codec = TestUtil.alwaysPostingsFormat(new DirectPostingsFormat());
 
   @Override
   protected Codec getCodec() {
diff --git a/lucene/codecs/src/test/org/apache/lucene/codecs/memory/TestMemoryDocValuesFormat.java b/lucene/codecs/src/test/org/apache/lucene/codecs/memory/TestMemoryDocValuesFormat.java
index 77c6ea5..81b2367 100644
--- a/lucene/codecs/src/test/org/apache/lucene/codecs/memory/TestMemoryDocValuesFormat.java
+++ b/lucene/codecs/src/test/org/apache/lucene/codecs/memory/TestMemoryDocValuesFormat.java
@@ -19,13 +19,13 @@ package org.apache.lucene.codecs.memory;
 
 import org.apache.lucene.codecs.Codec;
 import org.apache.lucene.index.BaseCompressingDocValuesFormatTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Tests MemoryDocValuesFormat
  */
 public class TestMemoryDocValuesFormat extends BaseCompressingDocValuesFormatTestCase {
-  private final Codec codec = _TestUtil.alwaysDocValuesFormat(new MemoryDocValuesFormat());
+  private final Codec codec = TestUtil.alwaysDocValuesFormat(new MemoryDocValuesFormat());
 
   @Override
   protected Codec getCodec() {
diff --git a/lucene/codecs/src/test/org/apache/lucene/codecs/memory/TestMemoryPostingsFormat.java b/lucene/codecs/src/test/org/apache/lucene/codecs/memory/TestMemoryPostingsFormat.java
index da9e3c8..524f970 100644
--- a/lucene/codecs/src/test/org/apache/lucene/codecs/memory/TestMemoryPostingsFormat.java
+++ b/lucene/codecs/src/test/org/apache/lucene/codecs/memory/TestMemoryPostingsFormat.java
@@ -19,14 +19,15 @@ package org.apache.lucene.codecs.memory;
 
 import org.apache.lucene.codecs.Codec;
 import org.apache.lucene.index.BasePostingsFormatTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Tests MemoryPostingsFormat
  */
 public class TestMemoryPostingsFormat extends BasePostingsFormatTestCase {
   // TODO: randomize doPack
-  private final Codec codec = _TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat());
+  private final Codec codec = TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat());
 
   @Override
   protected Codec getCodec() {
diff --git a/lucene/codecs/src/test/org/apache/lucene/codecs/pulsing/Test10KPulsings.java b/lucene/codecs/src/test/org/apache/lucene/codecs/pulsing/Test10KPulsings.java
index 4c07479..eaf9639 100644
--- a/lucene/codecs/src/test/org/apache/lucene/codecs/pulsing/Test10KPulsings.java
+++ b/lucene/codecs/src/test/org/apache/lucene/codecs/pulsing/Test10KPulsings.java
@@ -37,9 +37,8 @@ import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.store.BaseDirectoryWrapper;
-import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Pulses 10k terms/docs, 
@@ -51,9 +50,9 @@ import org.apache.lucene.util._TestUtil;
 public class Test10KPulsings extends LuceneTestCase {
   public void test10kPulsed() throws Exception {
     // we always run this test with pulsing codec.
-    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing41PostingsFormat(1));
+    Codec cp = TestUtil.alwaysPostingsFormat(new Pulsing41PostingsFormat(1));
     
-    File f = _TestUtil.getTempDir("10kpulsed");
+    File f = TestUtil.getTempDir("10kpulsed");
     BaseDirectoryWrapper dir = newFSDirectory(f);
     dir.setCheckIndexOnClose(false); // we do this ourselves explicitly
     RandomIndexWriter iw = new RandomIndexWriter(random(), dir, 
@@ -62,7 +61,7 @@ public class Test10KPulsings extends LuceneTestCase {
     Document document = new Document();
     FieldType ft = new FieldType(TextField.TYPE_STORED);
     
-    switch(_TestUtil.nextInt(random(), 0, 2)) {
+    switch(TestUtil.nextInt(random(), 0, 2)) {
       case 0: ft.setIndexOptions(IndexOptions.DOCS_ONLY); break;
       case 1: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS); break;
       default: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS); break; 
@@ -87,13 +86,13 @@ public class Test10KPulsings extends LuceneTestCase {
     for (int i = 0; i < 10050; i++) {
       String expected = df.format(i);
       assertEquals(expected, te.next().utf8ToString());
-      de = _TestUtil.docs(random(), te, null, de, DocsEnum.FLAG_NONE);
+      de = TestUtil.docs(random(), te, null, de, DocsEnum.FLAG_NONE);
       assertTrue(de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
       assertEquals(DocIdSetIterator.NO_MORE_DOCS, de.nextDoc());
     }
     ir.close();
 
-    _TestUtil.checkIndex(dir);
+    TestUtil.checkIndex(dir);
     dir.close();
   }
   
@@ -101,10 +100,10 @@ public class Test10KPulsings extends LuceneTestCase {
    */
   public void test10kNotPulsed() throws Exception {
     // we always run this test with pulsing codec.
-    int freqCutoff = _TestUtil.nextInt(random(), 1, 10);
-    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing41PostingsFormat(freqCutoff));
+    int freqCutoff = TestUtil.nextInt(random(), 1, 10);
+    Codec cp = TestUtil.alwaysPostingsFormat(new Pulsing41PostingsFormat(freqCutoff));
     
-    File f = _TestUtil.getTempDir("10knotpulsed");
+    File f = TestUtil.getTempDir("10knotpulsed");
     BaseDirectoryWrapper dir = newFSDirectory(f);
     dir.setCheckIndexOnClose(false); // we do this ourselves explicitly
     RandomIndexWriter iw = new RandomIndexWriter(random(), dir, 
@@ -113,7 +112,7 @@ public class Test10KPulsings extends LuceneTestCase {
     Document document = new Document();
     FieldType ft = new FieldType(TextField.TYPE_STORED);
     
-    switch(_TestUtil.nextInt(random(), 0, 2)) {
+    switch(TestUtil.nextInt(random(), 0, 2)) {
       case 0: ft.setIndexOptions(IndexOptions.DOCS_ONLY); break;
       case 1: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS); break;
       default: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS); break; 
@@ -145,13 +144,13 @@ public class Test10KPulsings extends LuceneTestCase {
     for (int i = 0; i < 10050; i++) {
       String expected = df.format(i);
       assertEquals(expected, te.next().utf8ToString());
-      de = _TestUtil.docs(random(), te, null, de, DocsEnum.FLAG_NONE);
+      de = TestUtil.docs(random(), te, null, de, DocsEnum.FLAG_NONE);
       assertTrue(de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
       assertEquals(DocIdSetIterator.NO_MORE_DOCS, de.nextDoc());
     }
     ir.close();
 
-    _TestUtil.checkIndex(dir);
+    TestUtil.checkIndex(dir);
     dir.close();
   }
 }
diff --git a/lucene/codecs/src/test/org/apache/lucene/codecs/pulsing/TestPulsingPostingsFormat.java b/lucene/codecs/src/test/org/apache/lucene/codecs/pulsing/TestPulsingPostingsFormat.java
index cf8ab1d..440ac38 100644
--- a/lucene/codecs/src/test/org/apache/lucene/codecs/pulsing/TestPulsingPostingsFormat.java
+++ b/lucene/codecs/src/test/org/apache/lucene/codecs/pulsing/TestPulsingPostingsFormat.java
@@ -19,14 +19,15 @@ package org.apache.lucene.codecs.pulsing;
 
 import org.apache.lucene.codecs.Codec;
 import org.apache.lucene.index.BasePostingsFormatTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Tests PulsingPostingsFormat
  */
 public class TestPulsingPostingsFormat extends BasePostingsFormatTestCase {
   // TODO: randomize cutoff
-  private final Codec codec = _TestUtil.alwaysPostingsFormat(new Pulsing41PostingsFormat());
+  private final Codec codec = TestUtil.alwaysPostingsFormat(new Pulsing41PostingsFormat());
 
   @Override
   protected Codec getCodec() {
diff --git a/lucene/codecs/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse.java b/lucene/codecs/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse.java
index d849951..a0e3282 100644
--- a/lucene/codecs/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse.java
+++ b/lucene/codecs/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse.java
@@ -27,7 +27,6 @@ import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.TextField;
 import org.apache.lucene.index.AtomicReader;
-import org.apache.lucene.index.CheckIndex;
 import org.apache.lucene.index.DirectoryReader;
 import org.apache.lucene.index.DocsAndPositionsEnum;
 import org.apache.lucene.index.DocsEnum;
@@ -36,7 +35,7 @@ import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.store.BaseDirectoryWrapper;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Tests that pulsing codec reuses its enums and wrapped enums
@@ -45,7 +44,7 @@ public class TestPulsingReuse extends LuceneTestCase {
   // TODO: this is a basic test. this thing is complicated, add more
   public void testSophisticatedReuse() throws Exception {
     // we always run this test with pulsing codec.
-    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing41PostingsFormat(1));
+    Codec cp = TestUtil.alwaysPostingsFormat(new Pulsing41PostingsFormat(1));
     Directory dir = newDirectory();
     RandomIndexWriter iw = new RandomIndexWriter(random(), dir, 
         newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));
@@ -83,7 +82,7 @@ public class TestPulsingReuse extends LuceneTestCase {
   /** tests reuse with Pulsing1(Pulsing2(Standard)) */
   public void testNestedPulsing() throws Exception {
     // we always run this test with pulsing codec.
-    Codec cp = _TestUtil.alwaysPostingsFormat(new NestedPulsingPostingsFormat());
+    Codec cp = TestUtil.alwaysPostingsFormat(new NestedPulsingPostingsFormat());
     BaseDirectoryWrapper dir = newDirectory();
     RandomIndexWriter iw = new RandomIndexWriter(random(), dir, 
         newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));
diff --git a/lucene/codecs/src/test/org/apache/lucene/codecs/sep/TestSepPostingsFormat.java b/lucene/codecs/src/test/org/apache/lucene/codecs/sep/TestSepPostingsFormat.java
index 64dd661..e49e189 100644
--- a/lucene/codecs/src/test/org/apache/lucene/codecs/sep/TestSepPostingsFormat.java
+++ b/lucene/codecs/src/test/org/apache/lucene/codecs/sep/TestSepPostingsFormat.java
@@ -20,14 +20,14 @@ package org.apache.lucene.codecs.sep;
 import org.apache.lucene.codecs.Codec;
 import org.apache.lucene.codecs.mocksep.MockSepPostingsFormat;
 import org.apache.lucene.index.BasePostingsFormatTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Tests sep layout
  */
 public class TestSepPostingsFormat extends BasePostingsFormatTestCase {
   // TODO: randomize cutoff
-  private final Codec codec = _TestUtil.alwaysPostingsFormat(new MockSepPostingsFormat());
+  private final Codec codec = TestUtil.alwaysPostingsFormat(new MockSepPostingsFormat());
 
   @Override
   protected Codec getCodec() {
diff --git a/lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer.java b/lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer.java
index a119723..3976416 100644
--- a/lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer.java
+++ b/lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer.java
@@ -33,7 +33,7 @@ import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.index.Terms;
 import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.automaton.Automaton;
 import org.apache.lucene.util.automaton.AutomatonTestUtil;
 import org.apache.lucene.util.automaton.BasicAutomata;
@@ -232,7 +232,7 @@ public class TestMockAnalyzer extends BaseTokenStreamTestCase {
     for (int i = 0; i < iters; i++) {
       final CharacterRunAutomaton dfa = new CharacterRunAutomaton(AutomatonTestUtil.randomAutomaton(random()));
       final boolean lowercase = random().nextBoolean();
-      final int limit = _TestUtil.nextInt(random(), 0, 500);
+      final int limit = TestUtil.nextInt(random(), 0, 500);
       Analyzer a = new Analyzer() {
         @Override
         protected TokenStreamComponents createComponents(String fieldName) {
@@ -248,7 +248,7 @@ public class TestMockAnalyzer extends BaseTokenStreamTestCase {
   public void testForwardOffsets() throws Exception {
     int num = atLeast(10000);
     for (int i = 0; i < num; i++) {
-      String s = _TestUtil.randomHtmlishString(random(), 20);
+      String s = TestUtil.randomHtmlishString(random(), 20);
       StringReader reader = new StringReader(s);
       MockCharFilter charfilter = new MockCharFilter(reader, 2);
       MockAnalyzer analyzer = new MockAnalyzer(random());
diff --git a/lucene/core/src/test/org/apache/lucene/analysis/TestToken.java b/lucene/core/src/test/org/apache/lucene/analysis/TestToken.java
index 7567198..acd3e4f 100644
--- a/lucene/core/src/test/org/apache/lucene/analysis/TestToken.java
+++ b/lucene/core/src/test/org/apache/lucene/analysis/TestToken.java
@@ -22,7 +22,7 @@ import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.Attribute;
 import org.apache.lucene.util.AttributeImpl;
 import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 import java.io.StringReader;
 import java.util.HashMap;
@@ -246,17 +246,17 @@ public class TestToken extends LuceneTestCase {
 
   public void testAttributeReflection() throws Exception {
     Token t = new Token("foobar", 6, 22, 8);
-    _TestUtil.assertAttributeReflection(t,
-      new HashMap<String,Object>() {{
-        put(CharTermAttribute.class.getName() + "#term", "foobar");
-        put(TermToBytesRefAttribute.class.getName() + "#bytes", new BytesRef("foobar"));
-        put(OffsetAttribute.class.getName() + "#startOffset", 6);
-        put(OffsetAttribute.class.getName() + "#endOffset", 22);
-        put(PositionIncrementAttribute.class.getName() + "#positionIncrement", 1);
-        put(PayloadAttribute.class.getName() + "#payload", null);
-        put(TypeAttribute.class.getName() + "#type", TypeAttribute.DEFAULT_TYPE);
-        put(FlagsAttribute.class.getName() + "#flags", 8);
-      }});
+    TestUtil.assertAttributeReflection(t,
+        new HashMap<String, Object>() {{
+          put(CharTermAttribute.class.getName() + "#term", "foobar");
+          put(TermToBytesRefAttribute.class.getName() + "#bytes", new BytesRef("foobar"));
+          put(OffsetAttribute.class.getName() + "#startOffset", 6);
+          put(OffsetAttribute.class.getName() + "#endOffset", 22);
+          put(PositionIncrementAttribute.class.getName() + "#positionIncrement", 1);
+          put(PayloadAttribute.class.getName() + "#payload", null);
+          put(TypeAttribute.class.getName() + "#type", TypeAttribute.DEFAULT_TYPE);
+          put(FlagsAttribute.class.getName() + "#flags", 8);
+        }});
   }
 
 
diff --git a/lucene/core/src/test/org/apache/lucene/analysis/tokenattributes/TestCharTermAttributeImpl.java b/lucene/core/src/test/org/apache/lucene/analysis/tokenattributes/TestCharTermAttributeImpl.java
index f1cfafe..2562201 100644
--- a/lucene/core/src/test/org/apache/lucene/analysis/tokenattributes/TestCharTermAttributeImpl.java
+++ b/lucene/core/src/test/org/apache/lucene/analysis/tokenattributes/TestCharTermAttributeImpl.java
@@ -20,7 +20,8 @@ package org.apache.lucene.analysis.tokenattributes;
 import org.apache.lucene.analysis.TestToken;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+
 import java.nio.CharBuffer;
 import java.util.HashMap;
 import java.util.Formatter;
@@ -132,7 +133,7 @@ public class TestCharTermAttributeImpl extends LuceneTestCase {
   public void testAttributeReflection() throws Exception {
     CharTermAttributeImpl t = new CharTermAttributeImpl();
     t.append("foobar");
-    _TestUtil.assertAttributeReflection(t, new HashMap<String,Object>() {{
+    TestUtil.assertAttributeReflection(t, new HashMap<String, Object>() {{
       put(CharTermAttribute.class.getName() + "#term", "foobar");
       put(TermToBytesRefAttribute.class.getName() + "#bytes", new BytesRef("foobar"));
     }});
diff --git a/lucene/core/src/test/org/apache/lucene/analysis/tokenattributes/TestSimpleAttributeImpl.java b/lucene/core/src/test/org/apache/lucene/analysis/tokenattributes/TestSimpleAttributeImpl.java
index 79ffe9a..7d547ea 100644
--- a/lucene/core/src/test/org/apache/lucene/analysis/tokenattributes/TestSimpleAttributeImpl.java
+++ b/lucene/core/src/test/org/apache/lucene/analysis/tokenattributes/TestSimpleAttributeImpl.java
@@ -17,7 +17,7 @@ package org.apache.lucene.analysis.tokenattributes;
  * limitations under the License.
  */
 
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.LuceneTestCase;
 
 import java.util.Collections;
@@ -27,21 +27,21 @@ public class TestSimpleAttributeImpl extends LuceneTestCase {
 
   // this checks using reflection API if the defaults are correct
   public void testAttributes() {
-    _TestUtil.assertAttributeReflection(new PositionIncrementAttributeImpl(),
-      Collections.singletonMap(PositionIncrementAttribute.class.getName()+"#positionIncrement", 1));
-    _TestUtil.assertAttributeReflection(new PositionLengthAttributeImpl(),
-      Collections.singletonMap(PositionLengthAttribute.class.getName()+"#positionLength", 1));
-    _TestUtil.assertAttributeReflection(new FlagsAttributeImpl(),
-      Collections.singletonMap(FlagsAttribute.class.getName()+"#flags", 0));
-    _TestUtil.assertAttributeReflection(new TypeAttributeImpl(),
-      Collections.singletonMap(TypeAttribute.class.getName()+"#type", TypeAttribute.DEFAULT_TYPE));
-    _TestUtil.assertAttributeReflection(new PayloadAttributeImpl(),
-      Collections.singletonMap(PayloadAttribute.class.getName()+"#payload", null));
-    _TestUtil.assertAttributeReflection(new KeywordAttributeImpl(),
-      Collections.singletonMap(KeywordAttribute.class.getName()+"#keyword", false));
-    _TestUtil.assertAttributeReflection(new OffsetAttributeImpl(), new HashMap<String,Object>() {{
-      put(OffsetAttribute.class.getName()+"#startOffset", 0);
-      put(OffsetAttribute.class.getName()+"#endOffset", 0);
+    TestUtil.assertAttributeReflection(new PositionIncrementAttributeImpl(),
+        Collections.singletonMap(PositionIncrementAttribute.class.getName() + "#positionIncrement", 1));
+    TestUtil.assertAttributeReflection(new PositionLengthAttributeImpl(),
+        Collections.singletonMap(PositionLengthAttribute.class.getName() + "#positionLength", 1));
+    TestUtil.assertAttributeReflection(new FlagsAttributeImpl(),
+        Collections.singletonMap(FlagsAttribute.class.getName() + "#flags", 0));
+    TestUtil.assertAttributeReflection(new TypeAttributeImpl(),
+        Collections.singletonMap(TypeAttribute.class.getName() + "#type", TypeAttribute.DEFAULT_TYPE));
+    TestUtil.assertAttributeReflection(new PayloadAttributeImpl(),
+        Collections.singletonMap(PayloadAttribute.class.getName() + "#payload", null));
+    TestUtil.assertAttributeReflection(new KeywordAttributeImpl(),
+        Collections.singletonMap(KeywordAttribute.class.getName() + "#keyword", false));
+    TestUtil.assertAttributeReflection(new OffsetAttributeImpl(), new HashMap<String, Object>() {{
+      put(OffsetAttribute.class.getName() + "#startOffset", 0);
+      put(OffsetAttribute.class.getName() + "#endOffset", 0);
     }});
   }
 
diff --git a/lucene/core/src/test/org/apache/lucene/codecs/compressing/AbstractTestCompressionMode.java b/lucene/core/src/test/org/apache/lucene/codecs/compressing/AbstractTestCompressionMode.java
index 33fbfb5..305bf38 100644
--- a/lucene/core/src/test/org/apache/lucene/codecs/compressing/AbstractTestCompressionMode.java
+++ b/lucene/core/src/test/org/apache/lucene/codecs/compressing/AbstractTestCompressionMode.java
@@ -24,7 +24,7 @@ import org.apache.lucene.store.ByteArrayDataInput;
 import org.apache.lucene.store.ByteArrayDataOutput;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 import com.carrotsearch.randomizedtesting.generators.RandomInts;
 
@@ -85,8 +85,8 @@ public abstract class AbstractTestCompressionMode extends LuceneTestCase {
     final int iterations = atLeast(10);
     for (int i = 0; i < iterations; ++i) {
       final byte[] decompressed = randomArray();
-      final int off = random().nextBoolean() ? 0 : _TestUtil.nextInt(random(), 0, decompressed.length);
-      final int len = random().nextBoolean() ? decompressed.length - off : _TestUtil.nextInt(random(), 0, decompressed.length - off);
+      final int off = random().nextBoolean() ? 0 : TestUtil.nextInt(random(), 0, decompressed.length);
+      final int len = random().nextBoolean() ? decompressed.length - off : TestUtil.nextInt(random(), 0, decompressed.length - off);
       final byte[] compressed = compress(decompressed, off, len);
       final byte[] restored = decompress(compressed, len);
       assertArrayEquals(Arrays.copyOfRange(decompressed, off, off+len), restored);
@@ -138,7 +138,7 @@ public abstract class AbstractTestCompressionMode extends LuceneTestCase {
   }
 
   public void testConstant() throws IOException {
-    final byte[] decompressed = new byte[_TestUtil.nextInt(random(), 1, 10000)];
+    final byte[] decompressed = new byte[TestUtil.nextInt(random(), 1, 10000)];
     Arrays.fill(decompressed, (byte) random().nextInt());
     test(decompressed);
   }
diff --git a/lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestBitVector.java b/lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestBitVector.java
index f8e294c..7e09e86 100644
--- a/lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestBitVector.java
+++ b/lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestBitVector.java
@@ -23,7 +23,8 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.store.RAMDirectory;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * <code>TestBitVector</code> tests the <code>BitVector</code>, obviously.
@@ -231,10 +232,10 @@ public class TestBitVector extends LuceneTestCase
 
     public void testClearedBitNearEnd() throws IOException {
       Directory d = newDirectory();
-      final int numBits = _TestUtil.nextInt(random(), 7, 1000);
+      final int numBits = TestUtil.nextInt(random(), 7, 1000);
       BitVector bv = new BitVector(numBits);
       bv.invertAll();
-      bv.clear(numBits-_TestUtil.nextInt(random(), 1, 7));
+      bv.clear(numBits- TestUtil.nextInt(random(), 1, 7));
       bv.write(d, "test", newIOContext(random()));
       assertEquals(numBits-1, bv.count());
       d.close();
@@ -242,7 +243,7 @@ public class TestBitVector extends LuceneTestCase
 
     public void testMostlySet() throws IOException {
       Directory d = newDirectory();
-      final int numBits = _TestUtil.nextInt(random(), 30, 1000);
+      final int numBits = TestUtil.nextInt(random(), 30, 1000);
       for(int numClear=0;numClear<20;numClear++) {
         BitVector bv = new BitVector(numBits);
         bv.invertAll();
diff --git a/lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestLucene40PostingsReader.java b/lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestLucene40PostingsReader.java
index fd97279..a18d6cd 100644
--- a/lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestLucene40PostingsReader.java
+++ b/lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestLucene40PostingsReader.java
@@ -33,7 +33,7 @@ import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.BeforeClass;
 
 public class TestLucene40PostingsReader extends LuceneTestCase {
@@ -53,7 +53,7 @@ public class TestLucene40PostingsReader extends LuceneTestCase {
    *  depends heavily on term vectors cross-check at checkIndex
    */
   public void testPostings() throws Exception {
-    Directory dir = newFSDirectory(_TestUtil.getTempDir("postings"));
+    Directory dir = newFSDirectory(TestUtil.getTempDir("postings"));
     IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));
     iwc.setCodec(Codec.forName("Lucene40"));
     RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);
@@ -116,7 +116,7 @@ public class TestLucene40PostingsReader extends LuceneTestCase {
     StringBuilder sb = new StringBuilder();
     int i = random().nextInt(terms.length);
     while (i < terms.length) {
-      int tf =  _TestUtil.nextInt(random(), 1, maxTF);
+      int tf =  TestUtil.nextInt(random(), 1, maxTF);
       for (int j = 0; j < tf; j++) {
         shuffled.add(terms[i]);
       }
diff --git a/lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum.java b/lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum.java
index 3c0cc76..2a8aada 100644
--- a/lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum.java
+++ b/lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum.java
@@ -36,7 +36,7 @@ import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.LineFileDocs;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.BeforeClass;
 
 // TODO: really this should be in BaseTestPF or somewhere else? useful test!
@@ -49,7 +49,7 @@ public class TestReuseDocsEnum extends LuceneTestCase {
   
   public void testReuseDocsEnumNoReuse() throws IOException {
     Directory dir = newDirectory();
-    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());
+    Codec cp = TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());
     RandomIndexWriter writer = new RandomIndexWriter(random(), dir,
         newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));
     int numdocs = atLeast(20);
@@ -76,7 +76,7 @@ public class TestReuseDocsEnum extends LuceneTestCase {
   // tests for reuse only if bits are the same either null or the same instance
   public void testReuseDocsEnumSameBitsOrNull() throws IOException {
     Directory dir = newDirectory();
-    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());
+    Codec cp = TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());
     RandomIndexWriter writer = new RandomIndexWriter(random(), dir,
         newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));
     int numdocs = atLeast(20);
@@ -120,7 +120,7 @@ public class TestReuseDocsEnum extends LuceneTestCase {
   // make sure we never reuse from another reader even if it is the same field & codec etc
   public void testReuseDocsEnumDifferentReader() throws IOException {
     Directory dir = newDirectory();
-    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());
+    Codec cp = TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());
     RandomIndexWriter writer = new RandomIndexWriter(random(), dir,
         newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));
     int numdocs = atLeast(20);
diff --git a/lucene/core/src/test/org/apache/lucene/codecs/lucene41/TestBlockPostingsFormat.java b/lucene/core/src/test/org/apache/lucene/codecs/lucene41/TestBlockPostingsFormat.java
index 1aa2836..77ae0df 100644
--- a/lucene/core/src/test/org/apache/lucene/codecs/lucene41/TestBlockPostingsFormat.java
+++ b/lucene/core/src/test/org/apache/lucene/codecs/lucene41/TestBlockPostingsFormat.java
@@ -19,13 +19,13 @@ package org.apache.lucene.codecs.lucene41;
 
 import org.apache.lucene.codecs.Codec;
 import org.apache.lucene.index.BasePostingsFormatTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Tests BlockPostingsFormat
  */
 public class TestBlockPostingsFormat extends BasePostingsFormatTestCase {
-  private final Codec codec = _TestUtil.alwaysPostingsFormat(new Lucene41PostingsFormat());
+  private final Codec codec = TestUtil.alwaysPostingsFormat(new Lucene41PostingsFormat());
 
   @Override
   protected Codec getCodec() {
diff --git a/lucene/core/src/test/org/apache/lucene/codecs/lucene41/TestBlockPostingsFormat2.java b/lucene/core/src/test/org/apache/lucene/codecs/lucene41/TestBlockPostingsFormat2.java
index 7f8287b..f336bd6 100644
--- a/lucene/core/src/test/org/apache/lucene/codecs/lucene41/TestBlockPostingsFormat2.java
+++ b/lucene/core/src/test/org/apache/lucene/codecs/lucene41/TestBlockPostingsFormat2.java
@@ -30,7 +30,7 @@ import org.apache.lucene.index.IndexWriterConfig.OpenMode;
 import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /** 
  * Tests special cases of BlockPostingsFormat 
@@ -43,9 +43,9 @@ public class TestBlockPostingsFormat2 extends LuceneTestCase {
   @Override
   public void setUp() throws Exception {
     super.setUp();
-    dir = newFSDirectory(_TestUtil.getTempDir("testDFBlockSize"));
+    dir = newFSDirectory(TestUtil.getTempDir("testDFBlockSize"));
     iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));
-    iwc.setCodec(_TestUtil.alwaysPostingsFormat(new Lucene41PostingsFormat()));
+    iwc.setCodec(TestUtil.alwaysPostingsFormat(new Lucene41PostingsFormat()));
     iw = new RandomIndexWriter(random(), dir, iwc.clone());
     iw.setDoRandomForceMerge(false); // we will ourselves
   }
@@ -53,7 +53,7 @@ public class TestBlockPostingsFormat2 extends LuceneTestCase {
   @Override
   public void tearDown() throws Exception {
     iw.close();
-    _TestUtil.checkIndex(dir); // for some extra coverage, checkIndex before we forceMerge
+    TestUtil.checkIndex(dir); // for some extra coverage, checkIndex before we forceMerge
     iwc.setOpenMode(OpenMode.APPEND);
     IndexWriter iw = new IndexWriter(dir, iwc.clone());
     iw.forceMerge(1);
diff --git a/lucene/core/src/test/org/apache/lucene/codecs/lucene41/TestBlockPostingsFormat3.java b/lucene/core/src/test/org/apache/lucene/codecs/lucene41/TestBlockPostingsFormat3.java
index 844ff2c..c4592e9 100644
--- a/lucene/core/src/test/org/apache/lucene/codecs/lucene41/TestBlockPostingsFormat3.java
+++ b/lucene/core/src/test/org/apache/lucene/codecs/lucene41/TestBlockPostingsFormat3.java
@@ -17,7 +17,6 @@ package org.apache.lucene.codecs.lucene41;
  * limitations under the License.
  */
 
-import java.io.Reader;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.HashSet;
@@ -53,7 +52,8 @@ import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.English;
 import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.automaton.AutomatonTestUtil;
 import org.apache.lucene.util.automaton.CompiledAutomaton;
 import org.apache.lucene.util.automaton.RegExp;
@@ -83,7 +83,7 @@ public class TestBlockPostingsFormat3 extends LuceneTestCase {
       }
     };
     IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);
-    iwc.setCodec(_TestUtil.alwaysPostingsFormat(new Lucene41PostingsFormat())); 
+    iwc.setCodec(TestUtil.alwaysPostingsFormat(new Lucene41PostingsFormat()));
     // TODO we could actually add more fields implemented with different PFs
     // or, just put this test into the usual rotation?
     RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc.clone());
@@ -123,7 +123,7 @@ public class TestBlockPostingsFormat3 extends LuceneTestCase {
     doc.add(field7);
     doc.add(field8);
     for (int i = 0; i < MAXDOC; i++) {
-      String stringValue = Integer.toString(i) + " verycommon " + English.intToEnglish(i).replace('-', ' ') + " " + _TestUtil.randomSimpleString(random());
+      String stringValue = Integer.toString(i) + " verycommon " + English.intToEnglish(i).replace('-', ' ') + " " + TestUtil.randomSimpleString(random());
       field1.setStringValue(stringValue);
       field2.setStringValue(stringValue);
       field3.setStringValue(stringValue);
@@ -136,7 +136,7 @@ public class TestBlockPostingsFormat3 extends LuceneTestCase {
     }
     iw.close();
     verify(dir);
-    _TestUtil.checkIndex(dir); // for some extra coverage, checkIndex before we forceMerge
+    TestUtil.checkIndex(dir); // for some extra coverage, checkIndex before we forceMerge
     iwc.setOpenMode(OpenMode.APPEND);
     IndexWriter iw2 = new IndexWriter(dir, iwc.clone());
     iw2.forceMerge(1);
diff --git a/lucene/core/src/test/org/apache/lucene/codecs/lucene45/TestLucene45DocValuesFormat.java b/lucene/core/src/test/org/apache/lucene/codecs/lucene45/TestLucene45DocValuesFormat.java
index 3f6171a..ad51a93 100644
--- a/lucene/core/src/test/org/apache/lucene/codecs/lucene45/TestLucene45DocValuesFormat.java
+++ b/lucene/core/src/test/org/apache/lucene/codecs/lucene45/TestLucene45DocValuesFormat.java
@@ -19,13 +19,13 @@ package org.apache.lucene.codecs.lucene45;
 
 import org.apache.lucene.codecs.Codec;
 import org.apache.lucene.index.BaseCompressingDocValuesFormatTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Tests Lucene45DocValuesFormat
  */
 public class TestLucene45DocValuesFormat extends BaseCompressingDocValuesFormatTestCase {
-  private final Codec codec = _TestUtil.alwaysDocValuesFormat(new Lucene45DocValuesFormat());
+  private final Codec codec = TestUtil.alwaysDocValuesFormat(new Lucene45DocValuesFormat());
 
   @Override
   protected Codec getCodec() {
diff --git a/lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat.java b/lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat.java
index 3bc908c..76f67d4 100644
--- a/lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat.java
+++ b/lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat.java
@@ -46,7 +46,8 @@ import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.search.TopDocs;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Basic tests of PerFieldDocValuesFormat
@@ -67,7 +68,7 @@ public class TestPerFieldDocValuesFormat extends BaseDocValuesFormatTestCase {
 
   @Override
   protected boolean codecAcceptsHugeBinaryValues(String field) {
-    return _TestUtil.fieldSupportsHugeBinaryDocValues(field);
+    return TestUtil.fieldSupportsHugeBinaryDocValues(field);
   }
   
   // just a simple trivial test
diff --git a/lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2.java b/lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2.java
index 0d92b7c..050770a 100644
--- a/lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2.java
+++ b/lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2.java
@@ -43,7 +43,8 @@ import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.search.TopDocs;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.Test;
 
 /**
@@ -107,7 +108,7 @@ public class TestPerFieldPostingsFormat2 extends LuceneTestCase {
     addDocs2(writer, 10);
     writer.commit();
     assertEquals(30, writer.maxDoc());
-    _TestUtil.checkIndex(dir);
+    TestUtil.checkIndex(dir);
     writer.forceMerge(1);
     assertEquals(30, writer.maxDoc());
     writer.close();
@@ -240,7 +241,7 @@ public class TestPerFieldPostingsFormat2 extends LuceneTestCase {
     final int docsPerRound = 97;
     int numRounds = atLeast(1);
     for (int i = 0; i < numRounds; i++) {
-      int num = _TestUtil.nextInt(random(), 30, 60);
+      int num = TestUtil.nextInt(random(), 30, 60);
       IndexWriterConfig config = newIndexWriterConfig(random(),
           TEST_VERSION_CURRENT, new MockAnalyzer(random()));
       config.setOpenMode(OpenMode.CREATE_OR_APPEND);
@@ -251,7 +252,7 @@ public class TestPerFieldPostingsFormat2 extends LuceneTestCase {
           FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);
           customType.setTokenized(random().nextBoolean());
           customType.setOmitNorms(random().nextBoolean());
-          Field field = newField("" + k, _TestUtil
+          Field field = newField("" + k, TestUtil
               .randomRealisticUnicodeString(random(), 128), customType);
           doc.add(field);
         }
diff --git a/lucene/core/src/test/org/apache/lucene/index/Test2BBinaryDocValues.java b/lucene/core/src/test/org/apache/lucene/index/Test2BBinaryDocValues.java
index 6ad9c63..0741446 100644
--- a/lucene/core/src/test/org/apache/lucene/index/Test2BBinaryDocValues.java
+++ b/lucene/core/src/test/org/apache/lucene/index/Test2BBinaryDocValues.java
@@ -26,8 +26,8 @@ import org.apache.lucene.store.ByteArrayDataOutput;
 import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.TimeUnits;
-import org.apache.lucene.util._TestUtil;
 import org.junit.Ignore;
 
 import com.carrotsearch.randomizedtesting.annotations.TimeoutSuite;
@@ -38,7 +38,7 @@ public class Test2BBinaryDocValues extends LuceneTestCase {
   
   // indexes Integer.MAX_VALUE docs with a fixed binary field
   public void testFixedBinary() throws Exception {
-    BaseDirectoryWrapper dir = newFSDirectory(_TestUtil.getTempDir("2BFixedBinary"));
+    BaseDirectoryWrapper dir = newFSDirectory(TestUtil.getTempDir("2BFixedBinary"));
     if (dir instanceof MockDirectoryWrapper) {
       ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);
     }
@@ -98,7 +98,7 @@ public class Test2BBinaryDocValues extends LuceneTestCase {
   
   // indexes Integer.MAX_VALUE docs with a variable binary field
   public void testVariableBinary() throws Exception {
-    BaseDirectoryWrapper dir = newFSDirectory(_TestUtil.getTempDir("2BVariableBinary"));
+    BaseDirectoryWrapper dir = newFSDirectory(TestUtil.getTempDir("2BVariableBinary"));
     if (dir instanceof MockDirectoryWrapper) {
       ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);
     }
diff --git a/lucene/core/src/test/org/apache/lucene/index/Test2BDocs.java b/lucene/core/src/test/org/apache/lucene/index/Test2BDocs.java
index e529a05..f298521 100644
--- a/lucene/core/src/test/org/apache/lucene/index/Test2BDocs.java
+++ b/lucene/core/src/test/org/apache/lucene/index/Test2BDocs.java
@@ -22,7 +22,7 @@ import java.util.Arrays;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.AfterClass;
 import org.junit.BeforeClass;
 
@@ -31,7 +31,7 @@ public class Test2BDocs extends LuceneTestCase {
   
   @BeforeClass
   public static void beforeClass() throws Exception {
-    dir = newFSDirectory(_TestUtil.getTempDir("2Bdocs"));
+    dir = newFSDirectory(TestUtil.getTempDir("2Bdocs"));
     IndexWriter iw = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, null));
     Document doc = new Document();
     for (int i = 0; i < 262144; i++) {
@@ -61,7 +61,7 @@ public class Test2BDocs extends LuceneTestCase {
   }
   
   public void testExactlyAtLimit() throws Exception {
-    Directory dir2 = newFSDirectory(_TestUtil.getTempDir("2BDocs2"));
+    Directory dir2 = newFSDirectory(TestUtil.getTempDir("2BDocs2"));
     IndexWriter iw = new IndexWriter(dir2, new IndexWriterConfig(TEST_VERSION_CURRENT, null));
     Document doc = new Document();
     for (int i = 0; i < 262143; i++) {
diff --git a/lucene/core/src/test/org/apache/lucene/index/Test2BNumericDocValues.java b/lucene/core/src/test/org/apache/lucene/index/Test2BNumericDocValues.java
index 1ac17a2..f83ef7a 100644
--- a/lucene/core/src/test/org/apache/lucene/index/Test2BNumericDocValues.java
+++ b/lucene/core/src/test/org/apache/lucene/index/Test2BNumericDocValues.java
@@ -23,8 +23,8 @@ import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.store.BaseDirectoryWrapper;
 import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.TimeUnits;
-import org.apache.lucene.util._TestUtil;
 import org.junit.Ignore;
 
 import com.carrotsearch.randomizedtesting.annotations.TimeoutSuite;
@@ -35,7 +35,7 @@ public class Test2BNumericDocValues extends LuceneTestCase {
   
   // indexes Integer.MAX_VALUE docs with an increasing dv field
   public void testNumerics() throws Exception {
-    BaseDirectoryWrapper dir = newFSDirectory(_TestUtil.getTempDir("2BNumerics"));
+    BaseDirectoryWrapper dir = newFSDirectory(TestUtil.getTempDir("2BNumerics"));
     if (dir instanceof MockDirectoryWrapper) {
       ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);
     }
diff --git a/lucene/core/src/test/org/apache/lucene/index/Test2BPositions.java b/lucene/core/src/test/org/apache/lucene/index/Test2BPositions.java
index 1426c82..7b99513 100644
--- a/lucene/core/src/test/org/apache/lucene/index/Test2BPositions.java
+++ b/lucene/core/src/test/org/apache/lucene/index/Test2BPositions.java
@@ -28,8 +28,9 @@ import org.apache.lucene.document.TextField;
 import org.apache.lucene.store.BaseDirectoryWrapper;
 import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.TimeUnits;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.LuceneTestCase.SuppressCodecs;
 import org.junit.Ignore;
 
@@ -46,7 +47,7 @@ public class Test2BPositions extends LuceneTestCase {
   // uses lots of space and takes a few minutes
   @Ignore("Very slow. Enable manually by removing @Ignore.")
   public void test() throws Exception {
-    BaseDirectoryWrapper dir = newFSDirectory(_TestUtil.getTempDir("2BPositions"));
+    BaseDirectoryWrapper dir = newFSDirectory(TestUtil.getTempDir("2BPositions"));
     if (dir instanceof MockDirectoryWrapper) {
       ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);
     }
diff --git a/lucene/core/src/test/org/apache/lucene/index/Test2BPostings.java b/lucene/core/src/test/org/apache/lucene/index/Test2BPostings.java
index 5825eb8..8fad986 100644
--- a/lucene/core/src/test/org/apache/lucene/index/Test2BPostings.java
+++ b/lucene/core/src/test/org/apache/lucene/index/Test2BPostings.java
@@ -29,8 +29,9 @@ import org.apache.lucene.store.BaseDirectoryWrapper;
 import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.LuceneTestCase.SuppressCodecs;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.TimeUnits;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 import com.carrotsearch.randomizedtesting.annotations.TimeoutSuite;
 
@@ -44,7 +45,7 @@ public class Test2BPostings extends LuceneTestCase {
 
   @Nightly
   public void test() throws Exception {
-    BaseDirectoryWrapper dir = newFSDirectory(_TestUtil.getTempDir("2BPostings"));
+    BaseDirectoryWrapper dir = newFSDirectory(TestUtil.getTempDir("2BPostings"));
     if (dir instanceof MockDirectoryWrapper) {
       ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);
     }
diff --git a/lucene/core/src/test/org/apache/lucene/index/Test2BPostingsBytes.java b/lucene/core/src/test/org/apache/lucene/index/Test2BPostingsBytes.java
index 3332bb6..71ffeae 100644
--- a/lucene/core/src/test/org/apache/lucene/index/Test2BPostingsBytes.java
+++ b/lucene/core/src/test/org/apache/lucene/index/Test2BPostingsBytes.java
@@ -30,8 +30,8 @@ import org.apache.lucene.index.FieldInfo.IndexOptions;
 import org.apache.lucene.store.BaseDirectoryWrapper;
 import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.TimeUnits;
-import org.apache.lucene.util._TestUtil;
 import org.apache.lucene.util.LuceneTestCase.SuppressCodecs;
 import org.junit.Ignore;
 
@@ -50,7 +50,7 @@ public class Test2BPostingsBytes extends LuceneTestCase {
   // with some codecs needs more heap space as well.
   @Ignore("Very slow. Enable manually by removing @Ignore.")
   public void test() throws Exception {
-    BaseDirectoryWrapper dir = newFSDirectory(_TestUtil.getTempDir("2BPostingsBytes1"));
+    BaseDirectoryWrapper dir = newFSDirectory(TestUtil.getTempDir("2BPostingsBytes1"));
     if (dir instanceof MockDirectoryWrapper) {
       ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);
     }
@@ -93,7 +93,7 @@ public class Test2BPostingsBytes extends LuceneTestCase {
     IndexReader subReaders[] = new IndexReader[1000];
     Arrays.fill(subReaders, oneThousand);
     MultiReader mr = new MultiReader(subReaders);
-    BaseDirectoryWrapper dir2 = newFSDirectory(_TestUtil.getTempDir("2BPostingsBytes2"));
+    BaseDirectoryWrapper dir2 = newFSDirectory(TestUtil.getTempDir("2BPostingsBytes2"));
     if (dir2 instanceof MockDirectoryWrapper) {
       ((MockDirectoryWrapper)dir2).setThrottling(MockDirectoryWrapper.Throttling.NEVER);
     }
@@ -108,7 +108,7 @@ public class Test2BPostingsBytes extends LuceneTestCase {
     subReaders = new IndexReader[2000];
     Arrays.fill(subReaders, oneMillion);
     mr = new MultiReader(subReaders);
-    BaseDirectoryWrapper dir3 = newFSDirectory(_TestUtil.getTempDir("2BPostingsBytes3"));
+    BaseDirectoryWrapper dir3 = newFSDirectory(TestUtil.getTempDir("2BPostingsBytes3"));
     if (dir3 instanceof MockDirectoryWrapper) {
       ((MockDirectoryWrapper)dir3).setThrottling(MockDirectoryWrapper.Throttling.NEVER);
     }
diff --git a/lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues.java b/lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues.java
index 41f803c..b7c7a0f 100644
--- a/lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues.java
+++ b/lucene/core/src/test/org/apache/lucene/index/Test2BSortedDocValues.java
@@ -26,8 +26,8 @@ import org.apache.lucene.store.BaseDirectoryWrapper;
 import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.TimeUnits;
-import org.apache.lucene.util._TestUtil;
 import org.junit.Ignore;
 
 import com.carrotsearch.randomizedtesting.annotations.TimeoutSuite;
@@ -38,7 +38,7 @@ public class Test2BSortedDocValues extends LuceneTestCase {
   
   // indexes Integer.MAX_VALUE docs with a fixed binary field
   public void testFixedSorted() throws Exception {
-    BaseDirectoryWrapper dir = newFSDirectory(_TestUtil.getTempDir("2BFixedSorted"));
+    BaseDirectoryWrapper dir = newFSDirectory(TestUtil.getTempDir("2BFixedSorted"));
     if (dir instanceof MockDirectoryWrapper) {
       ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);
     }
@@ -95,7 +95,7 @@ public class Test2BSortedDocValues extends LuceneTestCase {
   // indexes Integer.MAX_VALUE docs with a fixed binary field
   // TODO: must use random.nextBytes (like Test2BTerms) to avoid BytesRefHash probing issues
   public void test2BOrds() throws Exception {
-    BaseDirectoryWrapper dir = newFSDirectory(_TestUtil.getTempDir("2BOrds"));
+    BaseDirectoryWrapper dir = newFSDirectory(TestUtil.getTempDir("2BOrds"));
     if (dir instanceof MockDirectoryWrapper) {
       ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);
     }
diff --git a/lucene/core/src/test/org/apache/lucene/index/Test2BTerms.java b/lucene/core/src/test/org/apache/lucene/index/Test2BTerms.java
index a9601d2..b4249d0 100644
--- a/lucene/core/src/test/org/apache/lucene/index/Test2BTerms.java
+++ b/lucene/core/src/test/org/apache/lucene/index/Test2BTerms.java
@@ -62,7 +62,7 @@ public class Test2BTerms extends LuceneTestCase {
       addAttribute(TermToBytesRefAttribute.class);
       bytes.length = TOKEN_LEN;
       this.random = random;
-      nextSave = _TestUtil.nextInt(random, 500000, 1000000);
+      nextSave = TestUtil.nextInt(random, 500000, 1000000);
     }
     
     @Override
@@ -75,7 +75,7 @@ public class Test2BTerms extends LuceneTestCase {
       if (--nextSave == 0) {
         savedTerms.add(BytesRef.deepCopyOf(bytes));
         System.out.println("TEST: save term=" + bytes);
-        nextSave = _TestUtil.nextInt(random, 500000, 1000000);
+        nextSave = TestUtil.nextInt(random, 500000, 1000000);
       }
       return true;
     }
@@ -144,11 +144,11 @@ public class Test2BTerms extends LuceneTestCase {
     System.out.println("Starting Test2B");
     final long TERM_COUNT = ((long) Integer.MAX_VALUE) + 100000000;
 
-    final int TERMS_PER_DOC = _TestUtil.nextInt(random(), 100000, 1000000);
+    final int TERMS_PER_DOC = TestUtil.nextInt(random(), 100000, 1000000);
 
     List<BytesRef> savedTerms = null;
 
-    BaseDirectoryWrapper dir = newFSDirectory(_TestUtil.getTempDir("2BTerms"));
+    BaseDirectoryWrapper dir = newFSDirectory(TestUtil.getTempDir("2BTerms"));
     //MockDirectoryWrapper dir = newFSDirectory(new File("/p/lucene/indices/2bindex"));
     if (dir instanceof MockDirectoryWrapper) {
       ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);
@@ -212,7 +212,7 @@ public class Test2BTerms extends LuceneTestCase {
     r.close();
 
     System.out.println("TEST: now CheckIndex...");
-    CheckIndex.Status status = _TestUtil.checkIndex(dir);
+    CheckIndex.Status status = TestUtil.checkIndex(dir);
     final long tc = status.segmentInfos.get(0).termIndexStatus.termCount;
     assertTrue("count " + tc + " is not > " + Integer.MAX_VALUE, tc > Integer.MAX_VALUE);
 
@@ -224,13 +224,13 @@ public class Test2BTerms extends LuceneTestCase {
     System.out.println("TEST: findTerms");
     final TermsEnum termsEnum = MultiFields.getTerms(r, "field").iterator(null);
     final List<BytesRef> savedTerms = new ArrayList<BytesRef>();
-    int nextSave = _TestUtil.nextInt(random(), 500000, 1000000);
+    int nextSave = TestUtil.nextInt(random(), 500000, 1000000);
     BytesRef term;
     while((term = termsEnum.next()) != null) {
       if (--nextSave == 0) {
         savedTerms.add(BytesRef.deepCopyOf(term));
         System.out.println("TEST: add " + term);
-        nextSave = _TestUtil.nextInt(random(), 500000, 1000000);
+        nextSave = TestUtil.nextInt(random(), 500000, 1000000);
       }
     }
     return savedTerms;
diff --git a/lucene/core/src/test/org/apache/lucene/index/Test4GBStoredFields.java b/lucene/core/src/test/org/apache/lucene/index/Test4GBStoredFields.java
index 6bca06b..14b5ba5 100644
--- a/lucene/core/src/test/org/apache/lucene/index/Test4GBStoredFields.java
+++ b/lucene/core/src/test/org/apache/lucene/index/Test4GBStoredFields.java
@@ -25,8 +25,9 @@ import org.apache.lucene.store.MMapDirectory;
 import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.TimeUnits;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.LuceneTestCase.SuppressCodecs;
 
 import com.carrotsearch.randomizedtesting.annotations.TimeoutSuite;
@@ -41,7 +42,7 @@ public class Test4GBStoredFields extends LuceneTestCase {
 
   @Nightly
   public void test() throws Exception {
-    MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), new MMapDirectory(_TestUtil.getTempDir("4GBStoredFields")));
+    MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), new MMapDirectory(TestUtil.getTempDir("4GBStoredFields")));
     dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);
 
     IndexWriter w = new IndexWriter(dir,
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestAddIndexes.java b/lucene/core/src/test/org/apache/lucene/index/TestAddIndexes.java
index 0a5a7c6..31aeac8 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestAddIndexes.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestAddIndexes.java
@@ -46,7 +46,7 @@ import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.store.RAMDirectory;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestAddIndexes extends LuceneTestCase {
   
@@ -66,7 +66,7 @@ public class TestAddIndexes extends LuceneTestCase {
     addDocs(writer, 100);
     assertEquals(100, writer.maxDoc());
     writer.close();
-    _TestUtil.checkIndex(dir);
+    TestUtil.checkIndex(dir);
 
     writer = newWriter(
         aux,
@@ -91,7 +91,7 @@ public class TestAddIndexes extends LuceneTestCase {
     writer.addIndexes(aux, aux2);
     assertEquals(190, writer.maxDoc());
     writer.close();
-    _TestUtil.checkIndex(dir);
+    TestUtil.checkIndex(dir);
 
     // make sure the old index is correct
     verifyNumDocs(aux, 40);
@@ -540,7 +540,7 @@ public class TestAddIndexes extends LuceneTestCase {
   private void verifyTermDocs(Directory dir, Term term, int numDocs)
       throws IOException {
     IndexReader reader = DirectoryReader.open(dir);
-    DocsEnum docsEnum = _TestUtil.docs(random(), reader, term.field, term.bytes, null, null, DocsEnum.FLAG_NONE);
+    DocsEnum docsEnum = TestUtil.docs(random(), reader, term.field, term.bytes, null, null, DocsEnum.FLAG_NONE);
     int count = 0;
     while (docsEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)
       count++;
@@ -915,7 +915,7 @@ public class TestAddIndexes extends LuceneTestCase {
     CommitAndAddIndexes3 c = new CommitAndAddIndexes3(NUM_COPY);
     c.launchThreads(-1);
 
-    Thread.sleep(_TestUtil.nextInt(random(), 10, 500));
+    Thread.sleep(TestUtil.nextInt(random(), 10, 500));
 
     // Close w/o first stopping/joining the threads
     if (VERBOSE) {
@@ -940,7 +940,7 @@ public class TestAddIndexes extends LuceneTestCase {
     CommitAndAddIndexes3 c = new CommitAndAddIndexes3(NUM_COPY);
     c.launchThreads(-1);
 
-    Thread.sleep(_TestUtil.nextInt(random(), 10, 500));
+    Thread.sleep(TestUtil.nextInt(random(), 10, 500));
 
     // Close w/o first stopping/joining the threads
     if (VERBOSE) {
@@ -1016,7 +1016,7 @@ public class TestAddIndexes extends LuceneTestCase {
     assertEquals(100, writer.maxDoc());
     writer.commit();
     writer.close();
-    _TestUtil.checkIndex(dir);
+    TestUtil.checkIndex(dir);
 
     writer = newWriter(
         aux,
@@ -1141,7 +1141,7 @@ public class TestAddIndexes extends LuceneTestCase {
       Directory dir = newDirectory();
       IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT,
           new MockAnalyzer(random()));
-      conf.setCodec(_TestUtil.alwaysPostingsFormat(new Pulsing41PostingsFormat(1 + random().nextInt(20))));
+      conf.setCodec(TestUtil.alwaysPostingsFormat(new Pulsing41PostingsFormat(1 + random().nextInt(20))));
       IndexWriter w = new IndexWriter(dir, conf);
       try {
         w.addIndexes(toAdd);
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestAllFilesHaveCodecHeader.java b/lucene/core/src/test/org/apache/lucene/index/TestAllFilesHaveCodecHeader.java
index 30b922c..defea12 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestAllFilesHaveCodecHeader.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestAllFilesHaveCodecHeader.java
@@ -29,7 +29,7 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Test that a plain default puts codec headers in all files.
@@ -49,7 +49,7 @@ public class TestAllFilesHaveCodecHeader extends LuceneTestCase {
     doc.add(bodyField);
     for (int i = 0; i < 100; i++) {
       idField.setStringValue(Integer.toString(i));
-      bodyField.setStringValue(_TestUtil.randomUnicodeString(random()));
+      bodyField.setStringValue(TestUtil.randomUnicodeString(random()));
       riw.addDocument(doc);
       if (random().nextInt(7) == 0) {
         riw.commit();
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestAtomicUpdate.java b/lucene/core/src/test/org/apache/lucene/index/TestAtomicUpdate.java
index 644477e..e94667c 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestAtomicUpdate.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestAtomicUpdate.java
@@ -17,7 +17,6 @@ package org.apache.lucene.index;
  */
 
 import java.io.File;
-import java.io.IOException;
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.*;
@@ -176,10 +175,10 @@ public class TestAtomicUpdate extends LuceneTestCase {
     directory.close();
 
     // Second in an FSDirectory:
-    File dirPath = _TestUtil.getTempDir("lucene.test.atomic");
+    File dirPath = TestUtil.getTempDir("lucene.test.atomic");
     directory = newFSDirectory(dirPath);
     runTest(directory);
     directory.close();
-    _TestUtil.rmDir(dirPath);
+    TestUtil.rmDir(dirPath);
   }
 }
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java b/lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java
index a46ef93..91d6c61 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java
@@ -63,7 +63,7 @@ import org.apache.lucene.util.Constants;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.LuceneTestCase.SuppressCodecs;
 import org.apache.lucene.util.StringHelper;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.AfterClass;
 import org.junit.BeforeClass;
 
@@ -205,7 +205,7 @@ public class TestBackwardsCompatibility extends LuceneTestCase {
    */
   private static IndexUpgrader newIndexUpgrader(Directory dir) {
     final boolean streamType = random().nextBoolean();
-    final int choice = _TestUtil.nextInt(random(), 0, 2);
+    final int choice = TestUtil.nextInt(random(), 0, 2);
     switch (choice) {
       case 0: return new IndexUpgrader(dir, TEST_VERSION_CURRENT);
       case 1: return new IndexUpgrader(dir, TEST_VERSION_CURRENT, 
@@ -224,9 +224,9 @@ public class TestBackwardsCompatibility extends LuceneTestCase {
     names.addAll(Arrays.asList(oldSingleSegmentNames));
     oldIndexDirs = new HashMap<String,Directory>();
     for (String name : names) {
-      File dir = _TestUtil.getTempDir(name);
+      File dir = TestUtil.getTempDir(name);
       File dataFile = new File(TestBackwardsCompatibility.class.getResource("index." + name + ".zip").toURI());
-      _TestUtil.unzip(dataFile, dir);
+      TestUtil.unzip(dataFile, dir);
       oldIndexDirs.put(name, newFSDirectory(dir));
     }
   }
@@ -245,8 +245,8 @@ public class TestBackwardsCompatibility extends LuceneTestCase {
       if (VERBOSE) {
         System.out.println("TEST: index " + unsupportedNames[i]);
       }
-      File oldIndxeDir = _TestUtil.getTempDir(unsupportedNames[i]);
-      _TestUtil.unzip(getDataFile("unsupported." + unsupportedNames[i] + ".zip"), oldIndxeDir);
+      File oldIndxeDir = TestUtil.getTempDir(unsupportedNames[i]);
+      TestUtil.unzip(getDataFile("unsupported." + unsupportedNames[i] + ".zip"), oldIndxeDir);
       BaseDirectoryWrapper dir = newFSDirectory(oldIndxeDir);
       // don't checkindex, these are intentionally not supported
       dir.setCheckIndexOnClose(false);
@@ -295,7 +295,7 @@ public class TestBackwardsCompatibility extends LuceneTestCase {
       assertTrue(bos.toString("UTF-8").contains(IndexFormatTooOldException.class.getName()));
 
       dir.close();
-      _TestUtil.rmDir(oldIndxeDir);
+      TestUtil.rmDir(oldIndxeDir);
     }
   }
   
@@ -388,7 +388,7 @@ public class TestBackwardsCompatibility extends LuceneTestCase {
     IndexReader reader = DirectoryReader.open(dir);
     IndexSearcher searcher = newSearcher(reader);
 
-    _TestUtil.checkIndex(dir);
+    TestUtil.checkIndex(dir);
     
     // true if this is a 4.0+ index
     final boolean is40Index = MultiFields.getMergedFieldInfos(reader).fieldInfo("content5") != null;
@@ -594,7 +594,7 @@ public class TestBackwardsCompatibility extends LuceneTestCase {
   public File createIndex(String dirName, boolean doCFS, boolean fullyMerged) throws IOException {
     // we use a real directory name that is not cleaned up, because this method is only used to create backwards indexes:
     File indexDir = new File("/tmp/idx", dirName);
-    _TestUtil.rmDir(indexDir);
+    TestUtil.rmDir(indexDir);
     Directory dir = newFSDirectory(indexDir);
     LogByteSizeMergePolicy mp = new LogByteSizeMergePolicy();
     mp.setNoCFSRatio(doCFS ? 1.0 : 0.0);
@@ -642,8 +642,8 @@ public class TestBackwardsCompatibility extends LuceneTestCase {
   public void testExactFileNames() throws IOException {
 
     String outputDirName = "lucene.backwardscompat0.index";
-    File outputDir = _TestUtil.getTempDir(outputDirName);
-    _TestUtil.rmDir(outputDir);
+    File outputDir = TestUtil.getTempDir(outputDirName);
+    TestUtil.rmDir(outputDir);
 
     try {
       Directory dir = newFSDirectory(outputDir);
@@ -701,7 +701,7 @@ public class TestBackwardsCompatibility extends LuceneTestCase {
       }
       dir.close();
     } finally {
-      _TestUtil.rmDir(outputDir);
+      TestUtil.rmDir(outputDir);
     }
   }
 
@@ -811,7 +811,7 @@ public class TestBackwardsCompatibility extends LuceneTestCase {
       // should be found exactly
       assertEquals(TermsEnum.SeekStatus.FOUND,
                    terms.seekCeil(aaaTerm));
-      assertEquals(35, countDocs(_TestUtil.docs(random(), terms, null, null, DocsEnum.FLAG_NONE)));
+      assertEquals(35, countDocs(TestUtil.docs(random(), terms, null, null, DocsEnum.FLAG_NONE)));
       assertNull(terms.next());
 
       // should hit end of field
@@ -823,12 +823,12 @@ public class TestBackwardsCompatibility extends LuceneTestCase {
       assertEquals(TermsEnum.SeekStatus.NOT_FOUND,
                    terms.seekCeil(new BytesRef("a")));
       assertTrue(terms.term().bytesEquals(aaaTerm));
-      assertEquals(35, countDocs(_TestUtil.docs(random(), terms, null, null, DocsEnum.FLAG_NONE)));
+      assertEquals(35, countDocs(TestUtil.docs(random(), terms, null, null, DocsEnum.FLAG_NONE)));
       assertNull(terms.next());
 
       assertEquals(TermsEnum.SeekStatus.FOUND,
                    terms.seekCeil(aaaTerm));
-      assertEquals(35, countDocs(_TestUtil.docs(random(), terms,null, null, DocsEnum.FLAG_NONE)));
+      assertEquals(35, countDocs(TestUtil.docs(random(), terms, null, null, DocsEnum.FLAG_NONE)));
       assertNull(terms.next());
 
       r.close();
@@ -952,9 +952,9 @@ public class TestBackwardsCompatibility extends LuceneTestCase {
   public void testCommandLineArgs() throws Exception {
 
     for (String name : oldIndexDirs.keySet()) {
-      File dir = _TestUtil.getTempDir(name);
+      File dir = TestUtil.getTempDir(name);
       File dataFile = new File(TestBackwardsCompatibility.class.getResource("index." + name + ".zip").toURI());
-      _TestUtil.unzip(dataFile, dir);
+      TestUtil.unzip(dataFile, dir);
 
       String path = dir.getAbsolutePath();
       
@@ -1045,11 +1045,11 @@ public class TestBackwardsCompatibility extends LuceneTestCase {
   public static final String moreTermsIndex = "moreterms.40.zip";
 
   public void testMoreTerms() throws Exception {
-    File oldIndexDir = _TestUtil.getTempDir("moreterms");
-    _TestUtil.unzip(getDataFile(moreTermsIndex), oldIndexDir);
+    File oldIndexDir = TestUtil.getTempDir("moreterms");
+    TestUtil.unzip(getDataFile(moreTermsIndex), oldIndexDir);
     Directory dir = newFSDirectory(oldIndexDir);
     // TODO: more tests
-    _TestUtil.checkIndex(dir);
+    TestUtil.checkIndex(dir);
     dir.close();
   }
 }
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions.java b/lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions.java
index 54b25b5..8b3c93b 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions.java
@@ -33,7 +33,7 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase.SuppressCodecs;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Simple test that adds numeric terms, where each term has the 
@@ -45,8 +45,8 @@ public class TestBagOfPositions extends LuceneTestCase {
   public void test() throws Exception {
     List<String> postingsList = new ArrayList<String>();
     int numTerms = atLeast(300);
-    final int maxTermsPerDoc = _TestUtil.nextInt(random(), 10, 20);
-    boolean isSimpleText = "SimpleText".equals(_TestUtil.getPostingsFormat("field"));
+    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);
+    boolean isSimpleText = "SimpleText".equals(TestUtil.getPostingsFormat("field"));
 
     IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));
 
@@ -68,11 +68,11 @@ public class TestBagOfPositions extends LuceneTestCase {
 
     final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);
 
-    Directory dir = newFSDirectory(_TestUtil.getTempDir("bagofpositions"));
+    Directory dir = newFSDirectory(TestUtil.getTempDir("bagofpositions"));
 
     final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);
 
-    int threadCount = _TestUtil.nextInt(random(), 1, 5);
+    int threadCount = TestUtil.nextInt(random(), 1, 5);
     if (VERBOSE) {
       System.out.println("config: " + iw.w.getConfig());
       System.out.println("threadCount=" + threadCount);
@@ -87,7 +87,7 @@ public class TestBagOfPositions extends LuceneTestCase {
     if (options == 0) {
       fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions
       fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING
-    } else if (options == 1 && !doesntSupportOffsets.contains(_TestUtil.getPostingsFormat("field"))) {
+    } else if (options == 1 && !doesntSupportOffsets.contains(TestUtil.getPostingsFormat("field"))) {
       fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);
     }
     // else just positions
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestBagOfPostings.java b/lucene/core/src/test/org/apache/lucene/index/TestBagOfPostings.java
index 28d058b..5720699 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestBagOfPostings.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestBagOfPostings.java
@@ -32,7 +32,8 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase.SuppressCodecs;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Simple test that adds numeric terms, where each term has the 
@@ -43,9 +44,9 @@ public class TestBagOfPostings extends LuceneTestCase {
   public void test() throws Exception {
     List<String> postingsList = new ArrayList<String>();
     int numTerms = atLeast(300);
-    final int maxTermsPerDoc = _TestUtil.nextInt(random(), 10, 20);
+    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);
 
-    boolean isSimpleText = "SimpleText".equals(_TestUtil.getPostingsFormat("field"));
+    boolean isSimpleText = "SimpleText".equals(TestUtil.getPostingsFormat("field"));
 
     IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));
 
@@ -69,10 +70,10 @@ public class TestBagOfPostings extends LuceneTestCase {
 
     final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);
 
-    Directory dir = newFSDirectory(_TestUtil.getTempDir("bagofpostings"));
+    Directory dir = newFSDirectory(TestUtil.getTempDir("bagofpostings"));
     final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);
 
-    int threadCount = _TestUtil.nextInt(random(), 1, 5);
+    int threadCount = TestUtil.nextInt(random(), 1, 5);
     if (VERBOSE) {
       System.out.println("config: " + iw.w.getConfig());
       System.out.println("threadCount=" + threadCount);
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestCodecHoldsOpenFiles.java b/lucene/core/src/test/org/apache/lucene/index/TestCodecHoldsOpenFiles.java
index 05b493b..171b97f 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestCodecHoldsOpenFiles.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestCodecHoldsOpenFiles.java
@@ -23,7 +23,8 @@ import org.apache.lucene.document.Document;
 import org.apache.lucene.document.TextField;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestCodecHoldsOpenFiles extends LuceneTestCase {
   public void test() throws Exception {
@@ -49,7 +50,7 @@ public class TestCodecHoldsOpenFiles extends LuceneTestCase {
     }
 
     for(AtomicReaderContext cxt : r.leaves()) {
-      _TestUtil.checkReader(cxt.reader());
+      TestUtil.checkReader(cxt.reader());
     }
 
     r.close();
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestCodecs.java b/lucene/core/src/test/org/apache/lucene/index/TestCodecs.java
index 4ebb857..30a6bd9 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestCodecs.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestCodecs.java
@@ -49,7 +49,7 @@ import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.Constants;
 import org.apache.lucene.util.InfoStream;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.BeforeClass;
 
 // TODO: test multiple codecs here?
@@ -187,7 +187,7 @@ public class TestCodecs extends LuceneTestCase {
       // Make term text
       String text2;
       while(true) {
-        text2 = _TestUtil.randomUnicodeString(random());
+        text2 = TestUtil.randomUnicodeString(random());
         if (!termsSeen.contains(text2) && !text2.endsWith(".")) {
           termsSeen.add(text2);
           break;
@@ -205,7 +205,7 @@ public class TestCodecs extends LuceneTestCase {
 
       int docID = 0;
       for(int j=0;j<docFreq;j++) {
-        docID += _TestUtil.nextInt(random(), 1, 10);
+        docID += TestUtil.nextInt(random(), 1, 10);
         docs[j] = docID;
 
         if (!omitTF) {
@@ -213,7 +213,7 @@ public class TestCodecs extends LuceneTestCase {
           positions[j] = new PositionData[termFreq];
           int position = 0;
           for(int k=0;k<termFreq;k++) {
-            position += _TestUtil.nextInt(random(), 1, 10);
+            position += TestUtil.nextInt(random(), 1, 10);
 
             final BytesRef payload;
             if (storePayloads && random().nextInt(4) == 0) {
@@ -276,7 +276,7 @@ public class TestCodecs extends LuceneTestCase {
       // make sure it properly fully resets (rewinds) its
       // internal state:
       for(int iter=0;iter<2;iter++) {
-        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, DocsEnum.FLAG_NONE);
+        docsEnum = TestUtil.docs(random(), termsEnum, null, docsEnum, DocsEnum.FLAG_NONE);
         assertEquals(terms[i].docs[0], docsEnum.nextDoc());
         assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());
       }
@@ -341,7 +341,7 @@ public class TestCodecs extends LuceneTestCase {
     final IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT,
       new MockAnalyzer(random()));
     config.setMergePolicy(newLogMergePolicy());
-    config.setCodec(_TestUtil.alwaysPostingsFormat(new MockSepPostingsFormat()));
+    config.setCodec(TestUtil.alwaysPostingsFormat(new MockSepPostingsFormat()));
     final IndexWriter writer = new IndexWriter(dir, config);
 
     try {
@@ -472,7 +472,7 @@ public class TestCodecs extends LuceneTestCase {
         assertEquals(status, TermsEnum.SeekStatus.FOUND);
         assertEquals(term.docs.length, termsEnum.docFreq());
         if (field.omitTF) {
-          this.verifyDocs(term.docs, term.positions, _TestUtil.docs(random(), termsEnum, null, null, DocsEnum.FLAG_NONE), false);
+          this.verifyDocs(term.docs, term.positions, TestUtil.docs(random(), termsEnum, null, null, DocsEnum.FLAG_NONE), false);
         } else {
           this.verifyDocs(term.docs, term.positions, termsEnum.docsAndPositions(null, null), true);
         }
@@ -492,7 +492,7 @@ public class TestCodecs extends LuceneTestCase {
           assertTrue(termsEnum.term().bytesEquals(new BytesRef(term.text2)));
           assertEquals(term.docs.length, termsEnum.docFreq());
           if (field.omitTF) {
-            this.verifyDocs(term.docs, term.positions, _TestUtil.docs(random(), termsEnum, null, null, DocsEnum.FLAG_NONE), false);
+            this.verifyDocs(term.docs, term.positions, TestUtil.docs(random(), termsEnum, null, null, DocsEnum.FLAG_NONE), false);
           } else {
             this.verifyDocs(term.docs, term.positions, termsEnum.docsAndPositions(null, null), true);
           }
@@ -503,7 +503,7 @@ public class TestCodecs extends LuceneTestCase {
           System.out.println("TEST: seek non-exist terms");
         }
         for(int i=0;i<100;i++) {
-          final String text2 = _TestUtil.randomUnicodeString(random()) + ".";
+          final String text2 = TestUtil.randomUnicodeString(random()) + ".";
           status = termsEnum.seekCeil(new BytesRef(text2));
           assertTrue(status == TermsEnum.SeekStatus.NOT_FOUND ||
                      status == TermsEnum.SeekStatus.END);
@@ -549,11 +549,11 @@ public class TestCodecs extends LuceneTestCase {
               if (postings != null) {
                 docs = postings;
               } else {
-                docs = _TestUtil.docs(random(), termsEnum, null, null, DocsEnum.FLAG_FREQS);
+                docs = TestUtil.docs(random(), termsEnum, null, null, DocsEnum.FLAG_FREQS);
               }
             } else {
               postings = null;
-              docs = _TestUtil.docs(random(), termsEnum, null, null, DocsEnum.FLAG_NONE);
+              docs = TestUtil.docs(random(), termsEnum, null, null, DocsEnum.FLAG_NONE);
             }
             assertNotNull(docs);
             int upto2 = -1;
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestCompoundFile.java b/lucene/core/src/test/org/apache/lucene/index/TestCompoundFile.java
index bf41466..963e9fe 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestCompoundFile.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestCompoundFile.java
@@ -32,7 +32,8 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.store.SimpleFSDirectory;
 import org.apache.lucene.store._TestHelper;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 
 public class TestCompoundFile extends LuceneTestCase
@@ -42,7 +43,7 @@ public class TestCompoundFile extends LuceneTestCase
     @Override
     public void setUp() throws Exception {
        super.setUp();
-       File file = _TestUtil.getTempDir("testIndex");
+       File file = TestUtil.getTempDir("testIndex");
        // use a simple FSDir here, to be sure to have SimpleFSInputs
        dir = new SimpleFSDirectory(file,null);
     }
@@ -775,7 +776,7 @@ public class TestCompoundFile extends LuceneTestCase
   // when reading a CFS with many subs:
   public void testManySubFiles() throws IOException {
 
-    final Directory d = newFSDirectory(_TestUtil.getTempDir("CFSManySubFiles"));
+    final Directory d = newFSDirectory(TestUtil.getTempDir("CFSManySubFiles"));
     final int FILE_COUNT = atLeast(500);
 
     for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {
@@ -820,7 +821,7 @@ public class TestCompoundFile extends LuceneTestCase
     doc.add(bodyField);
     for (int i = 0; i < 100; i++) {
       idField.setStringValue(Integer.toString(i));
-      bodyField.setStringValue(_TestUtil.randomUnicodeString(random()));
+      bodyField.setStringValue(TestUtil.randomUnicodeString(random()));
       riw.addDocument(doc);
       if (random().nextInt(7) == 0) {
         riw.commit();
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestConcurrentMergeScheduler.java b/lucene/core/src/test/org/apache/lucene/index/TestConcurrentMergeScheduler.java
index eb77e4c..580f0e7 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestConcurrentMergeScheduler.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestConcurrentMergeScheduler.java
@@ -33,7 +33,7 @@ import org.apache.lucene.index.IndexWriterConfig.OpenMode;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestConcurrentMergeScheduler extends LuceneTestCase {
   
@@ -265,8 +265,8 @@ public class TestConcurrentMergeScheduler extends LuceneTestCase {
     Directory dir = newDirectory();
     IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));
 
-    final int maxMergeCount = _TestUtil.nextInt(random(), 1, 5);
-    final int maxMergeThreads = _TestUtil.nextInt(random(), 1, maxMergeCount);
+    final int maxMergeCount = TestUtil.nextInt(random(), 1, 5);
+    final int maxMergeThreads = TestUtil.nextInt(random(), 1, maxMergeCount);
     final CountDownLatch enoughMergesWaiting = new CountDownLatch(maxMergeCount);
     final AtomicInteger runningMergeCount = new AtomicInteger(0);
     final AtomicBoolean failed = new AtomicBoolean();
@@ -352,9 +352,9 @@ public class TestConcurrentMergeScheduler extends LuceneTestCase {
     IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));
     iwc.setMaxBufferedDocs(5);
     iwc.setMergeScheduler(new TrackingCMS());
-    if (_TestUtil.getPostingsFormat("id").equals("SimpleText")) {
+    if (TestUtil.getPostingsFormat("id").equals("SimpleText")) {
       // no
-      iwc.setCodec(_TestUtil.alwaysPostingsFormat(new Lucene41PostingsFormat()));
+      iwc.setCodec(TestUtil.alwaysPostingsFormat(new Lucene41PostingsFormat()));
     }
     RandomIndexWriter w = new RandomIndexWriter(random(), d, iwc);
     for(int i=0;i<1000;i++) {
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestCrashCausesCorruptIndex.java b/lucene/core/src/test/org/apache/lucene/index/TestCrashCausesCorruptIndex.java
index 2a3b87c..7ca4ef6 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestCrashCausesCorruptIndex.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestCrashCausesCorruptIndex.java
@@ -32,7 +32,8 @@ import org.apache.lucene.store.FilterDirectory;
 import org.apache.lucene.store.IOContext;
 import org.apache.lucene.store.IndexOutput;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestCrashCausesCorruptIndex extends LuceneTestCase  {
 
@@ -42,7 +43,7 @@ public class TestCrashCausesCorruptIndex extends LuceneTestCase  {
    * LUCENE-3627: This test fails.
    */
   public void testCrashCorruptsIndexing() throws Exception {
-    path = _TestUtil.getTempDir("testCrashCorruptsIndexing");
+    path = TestUtil.getTempDir("testCrashCorruptsIndexing");
         
     indexAndCrashOnCreateOutputSegments2();
 
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestDeletionPolicy.java b/lucene/core/src/test/org/apache/lucene/index/TestDeletionPolicy.java
index f4d3f36..122a32c 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestDeletionPolicy.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestDeletionPolicy.java
@@ -35,7 +35,7 @@ import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /*
   Verify we can read the pre-2.1 file format, do searches
@@ -235,7 +235,7 @@ public class TestDeletionPolicy extends LuceneTestCase {
     writer.close();
 
     long lastDeleteTime = 0;
-    final int targetNumDelete = _TestUtil.nextInt(random(), 1, 5);
+    final int targetNumDelete = TestUtil.nextInt(random(), 1, 5);
     while (policy.numDelete < targetNumDelete) {
       // Record last time when writer performed deletes of
       // past commits
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader.java b/lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader.java
index 9aeb536..bc7358f 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader.java
@@ -29,7 +29,6 @@ import java.util.Random;
 import java.util.Set;
 
 import org.apache.lucene.analysis.MockAnalyzer;
-import org.apache.lucene.codecs.lucene41.Lucene41PostingsFormat;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.FieldType;
@@ -45,7 +44,7 @@ import org.apache.lucene.store.NoSuchDirectoryException;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.Assume;
 
 public class TestDirectoryReader extends LuceneTestCase {
@@ -94,18 +93,18 @@ public class TestDirectoryReader extends LuceneTestCase {
     // test mixing up TermDocs and TermEnums from different readers.
     TermsEnum te2 = MultiFields.getTerms(mr2, "body").iterator(null);
     te2.seekCeil(new BytesRef("wow"));
-    DocsEnum td = _TestUtil.docs(random(), mr2,
-                                 "body",
-                                 te2.term(),
-                                 MultiFields.getLiveDocs(mr2),
-                                 null,
-                                 0);
+    DocsEnum td = TestUtil.docs(random(), mr2,
+        "body",
+        te2.term(),
+        MultiFields.getLiveDocs(mr2),
+        null,
+        0);
 
     TermsEnum te3 = MultiFields.getTerms(mr3, "body").iterator(null);
     te3.seekCeil(new BytesRef("wow"));
-    td = _TestUtil.docs(random(), te3, MultiFields.getLiveDocs(mr3),
-                        td,
-                        0);
+    td = TestUtil.docs(random(), te3, MultiFields.getLiveDocs(mr3),
+        td,
+        0);
     
     int ret = 0;
 
@@ -352,12 +351,12 @@ void assertTermDocsCount(String msg,
                                    Term term,
                                    int expected)
   throws IOException {
-  DocsEnum tdocs = _TestUtil.docs(random(), reader,
-                                  term.field(),
-                                  new BytesRef(term.text()),
-                                  MultiFields.getLiveDocs(reader),
-                                  null,
-                                  0);
+  DocsEnum tdocs = TestUtil.docs(random(), reader,
+      term.field(),
+      new BytesRef(term.text()),
+      MultiFields.getLiveDocs(reader),
+      null,
+      0);
   int count = 0;
   if (tdocs != null) {
     while(tdocs.nextDoc()!= DocIdSetIterator.NO_MORE_DOCS) {
@@ -439,7 +438,7 @@ void assertTermDocsCount(String msg,
   
 public void testFilesOpenClose() throws IOException {
       // Create initial data set
-      File dirFile = _TestUtil.getTempDir("TestIndexReader.testFilesOpenClose");
+      File dirFile = TestUtil.getTempDir("TestIndexReader.testFilesOpenClose");
       Directory dir = newFSDirectory(dirFile);
       IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));
       addDoc(writer, "test");
@@ -447,7 +446,7 @@ public void testFilesOpenClose() throws IOException {
       dir.close();
 
       // Try to erase the data - this ensures that the writer closed all files
-      _TestUtil.rmDir(dirFile);
+      TestUtil.rmDir(dirFile);
       dir = newFSDirectory(dirFile);
 
       // Now create the data set again, just as before
@@ -464,11 +463,11 @@ public void testFilesOpenClose() throws IOException {
 
       // The following will fail if reader did not close
       // all files
-      _TestUtil.rmDir(dirFile);
+      TestUtil.rmDir(dirFile);
   }
 
   public void testOpenReaderAfterDelete() throws IOException {
-    File dirFile = _TestUtil.getTempDir("deletetest");
+    File dirFile = TestUtil.getTempDir("deletetest");
     Directory dir = newFSDirectory(dirFile);
     try {
       DirectoryReader.open(dir);
@@ -716,8 +715,8 @@ public void testFilesOpenClose() throws IOException {
   // DirectoryReader on a non-existent directory, you get a
   // good exception
   public void testNoDir() throws Throwable {
-    File tempDir = _TestUtil.getTempDir("doesnotexist");
-    _TestUtil.rmDir(tempDir);
+    File tempDir = TestUtil.getTempDir("doesnotexist");
+    TestUtil.rmDir(tempDir);
     Directory dir = newFSDirectory(tempDir);
     try {
       DirectoryReader.open(dir);
@@ -1091,7 +1090,7 @@ public void testFilesOpenClose() throws IOException {
   }
 
   public void testIndexExistsOnNonExistentDirectory() throws Exception {
-    File tempDir = _TestUtil.getTempDir("testIndexExistsOnNonExistentDirectory");
+    File tempDir = TestUtil.getTempDir("testIndexExistsOnNonExistentDirectory");
     tempDir.delete();
     Directory dir = newFSDirectory(tempDir);
     assertFalse(DirectoryReader.indexExists(dir));
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestDirectoryReaderReopen.java b/lucene/core/src/test/org/apache/lucene/index/TestDirectoryReaderReopen.java
index bf58077..8938953 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestDirectoryReaderReopen.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestDirectoryReaderReopen.java
@@ -38,7 +38,7 @@ import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestDirectoryReaderReopen extends LuceneTestCase {
   
@@ -196,7 +196,7 @@ public class TestDirectoryReaderReopen extends LuceneTestCase {
   public void testThreadSafety() throws Exception {
     final Directory dir = newDirectory();
     // NOTE: this also controls the number of threads!
-    final int n = _TestUtil.nextInt(random(), 20, 40);
+    final int n = TestUtil.nextInt(random(), 20, 40);
     IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer(random())));
     for (int i = 0; i < n; i++) {
@@ -275,7 +275,7 @@ public class TestDirectoryReaderReopen extends LuceneTestCase {
                 }
               }
               synchronized(this) {
-                wait(_TestUtil.nextInt(random(), 1, 100));
+                wait(TestUtil.nextInt(random(), 1, 100));
               }
             }
           }
@@ -294,7 +294,7 @@ public class TestDirectoryReaderReopen extends LuceneTestCase {
               }
               
               synchronized(this) {
-                wait(_TestUtil.nextInt(random(), 1, 100));
+                wait(TestUtil.nextInt(random(), 1, 100));
               }
             }
           }
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestDoc.java b/lucene/core/src/test/org/apache/lucene/index/TestDoc.java
index 711fd60..53ee2cc 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestDoc.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestDoc.java
@@ -43,7 +43,7 @@ import org.apache.lucene.store.TrackingDirectoryWrapper;
 import org.apache.lucene.util.Constants;
 import org.apache.lucene.util.InfoStream;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 
 /** JUnit adaptation of an older test case DocTest. */
@@ -62,10 +62,10 @@ public class TestDoc extends LuceneTestCase {
         if (VERBOSE) {
           System.out.println("TEST: setUp");
         }
-        workDir = _TestUtil.getTempDir("TestDoc");
+        workDir = TestUtil.getTempDir("TestDoc");
         workDir.mkdirs();
 
-        indexDir = _TestUtil.getTempDir("testIndex");
+        indexDir = TestUtil.getTempDir("testIndex");
         indexDir.mkdirs();
 
         Directory directory = newFSDirectory(indexDir);
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestDocCount.java b/lucene/core/src/test/org/apache/lucene/index/TestDocCount.java
index 132865c..6518319 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestDocCount.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestDocCount.java
@@ -23,7 +23,7 @@ import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Tests the Terms.docCount statistic
@@ -49,9 +49,9 @@ public class TestDocCount extends LuceneTestCase {
   
   private Document doc() {
     Document doc = new Document();
-    int numFields = _TestUtil.nextInt(random(), 1, 10);
+    int numFields = TestUtil.nextInt(random(), 1, 10);
     for (int i = 0; i < numFields; i++) {
-      doc.add(newStringField("" + _TestUtil.nextInt(random(), 'a', 'z'), "" + _TestUtil.nextInt(random(), 'a', 'z'), Field.Store.NO));
+      doc.add(newStringField("" + TestUtil.nextInt(random(), 'a', 'z'), "" + TestUtil.nextInt(random(), 'a', 'z'), Field.Store.NO));
     }
     return doc;
   }
@@ -70,7 +70,7 @@ public class TestDocCount extends LuceneTestCase {
       FixedBitSet visited = new FixedBitSet(ir.maxDoc());
       TermsEnum te = terms.iterator(null);
       while (te.next() != null) {
-        DocsEnum de = _TestUtil.docs(random(), te, null, null, DocsEnum.FLAG_NONE);
+        DocsEnum de = TestUtil.docs(random(), te, null, null, DocsEnum.FLAG_NONE);
         while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
           visited.set(de.docID());
         }
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestDocTermOrds.java b/lucene/core/src/test/org/apache/lucene/index/TestDocTermOrds.java
index 83a6165..d557859 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestDocTermOrds.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestDocTermOrds.java
@@ -38,7 +38,7 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.StringHelper;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 // TODO:
 //   - test w/ del docs
@@ -97,7 +97,7 @@ public class TestDocTermOrds extends LuceneTestCase {
     final int NUM_TERMS = atLeast(20);
     final Set<BytesRef> terms = new HashSet<BytesRef>();
     while(terms.size() < NUM_TERMS) {
-      final String s = _TestUtil.randomRealisticUnicodeString(random());
+      final String s = TestUtil.randomRealisticUnicodeString(random());
       //final String s = _TestUtil.randomSimpleString(random);
       if (s.length() > 0) {
         terms.add(new BytesRef(s));
@@ -113,7 +113,7 @@ public class TestDocTermOrds extends LuceneTestCase {
     // Sometimes swap in codec that impls ord():
     if (random().nextInt(10) == 7) {
       // Make sure terms index has ords:
-      Codec codec = _TestUtil.alwaysPostingsFormat(PostingsFormat.forName("Lucene41WithOrds"));
+      Codec codec = TestUtil.alwaysPostingsFormat(PostingsFormat.forName("Lucene41WithOrds"));
       conf.setCodec(codec);
     }
     
@@ -127,7 +127,7 @@ public class TestDocTermOrds extends LuceneTestCase {
 
       doc.add(new IntField("id", id, Field.Store.YES));
       
-      final int termCount = _TestUtil.nextInt(random(), 0, 20*RANDOM_MULTIPLIER);
+      final int termCount = TestUtil.nextInt(random(), 0, 20 * RANDOM_MULTIPLIER);
       while(ordsForDocSet.size() < termCount) {
         ordsForDocSet.add(random().nextInt(termsArray.length));
       }
@@ -182,12 +182,12 @@ public class TestDocTermOrds extends LuceneTestCase {
     Directory dir = newDirectory();
 
     final Set<String> prefixes = new HashSet<String>();
-    final int numPrefix = _TestUtil.nextInt(random(), 2, 7);
+    final int numPrefix = TestUtil.nextInt(random(), 2, 7);
     if (VERBOSE) {
       System.out.println("TEST: use " + numPrefix + " prefixes");
     }
     while(prefixes.size() < numPrefix) {
-      prefixes.add(_TestUtil.randomRealisticUnicodeString(random()));
+      prefixes.add(TestUtil.randomRealisticUnicodeString(random()));
       //prefixes.add(_TestUtil.randomSimpleString(random));
     }
     final String[] prefixesArray = prefixes.toArray(new String[prefixes.size()]);
@@ -195,7 +195,7 @@ public class TestDocTermOrds extends LuceneTestCase {
     final int NUM_TERMS = atLeast(20);
     final Set<BytesRef> terms = new HashSet<BytesRef>();
     while(terms.size() < NUM_TERMS) {
-      final String s = prefixesArray[random().nextInt(prefixesArray.length)] + _TestUtil.randomRealisticUnicodeString(random());
+      final String s = prefixesArray[random().nextInt(prefixesArray.length)] + TestUtil.randomRealisticUnicodeString(random());
       //final String s = prefixesArray[random.nextInt(prefixesArray.length)] + _TestUtil.randomSimpleString(random);
       if (s.length() > 0) {
         terms.add(new BytesRef(s));
@@ -210,7 +210,7 @@ public class TestDocTermOrds extends LuceneTestCase {
 
     // Sometimes swap in codec that impls ord():
     if (random().nextInt(10) == 7) {
-      Codec codec = _TestUtil.alwaysPostingsFormat(PostingsFormat.forName("Lucene41WithOrds"));
+      Codec codec = TestUtil.alwaysPostingsFormat(PostingsFormat.forName("Lucene41WithOrds"));
       conf.setCodec(codec);
     }
     
@@ -224,7 +224,7 @@ public class TestDocTermOrds extends LuceneTestCase {
 
       doc.add(new IntField("id", id, Field.Store.YES));
       
-      final int termCount = _TestUtil.nextInt(random(), 0, 20*RANDOM_MULTIPLIER);
+      final int termCount = TestUtil.nextInt(random(), 0, 20 * RANDOM_MULTIPLIER);
       while(ordsForDocSet.size() < termCount) {
         ordsForDocSet.add(random().nextInt(termsArray.length));
       }
@@ -303,7 +303,7 @@ public class TestDocTermOrds extends LuceneTestCase {
                                             "field",
                                             prefixRef,
                                             Integer.MAX_VALUE,
-                                            _TestUtil.nextInt(random(), 2, 10));
+                                            TestUtil.nextInt(random(), 2, 10));
                                             
 
     final FieldCache.Ints docIDToID = FieldCache.DEFAULT.getInts(r, "id", false);
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestDocValuesFormat.java b/lucene/core/src/test/org/apache/lucene/index/TestDocValuesFormat.java
index 6bc3554..11d5764 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestDocValuesFormat.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestDocValuesFormat.java
@@ -18,7 +18,8 @@ package org.apache.lucene.index;
  */
 
 import org.apache.lucene.codecs.Codec;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /** Tests the codec configuration defined by LuceneTestCase randomly
  *  (typically a mix across different fields).
@@ -32,6 +33,6 @@ public class TestDocValuesFormat extends BaseDocValuesFormatTestCase {
 
   @Override
   protected boolean codecAcceptsHugeBinaryValues(String field) {
-    return _TestUtil.fieldSupportsHugeBinaryDocValues(field);
+    return TestUtil.fieldSupportsHugeBinaryDocValues(field);
   }
 }
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestDocValuesWithThreads.java b/lucene/core/src/test/org/apache/lucene/index/TestDocValuesWithThreads.java
index 964fc51..0ba4897 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestDocValuesWithThreads.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestDocValuesWithThreads.java
@@ -34,7 +34,8 @@ import org.apache.lucene.search.FieldCache;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestDocValuesWithThreads extends LuceneTestCase {
 
@@ -50,10 +51,10 @@ public class TestDocValuesWithThreads extends LuceneTestCase {
       Document d = new Document();
       long number = random().nextLong();
       d.add(new NumericDocValuesField("number", number));
-      BytesRef bytes = new BytesRef(_TestUtil.randomRealisticUnicodeString(random()));
+      BytesRef bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));
       d.add(new BinaryDocValuesField("bytes", bytes));
       binary.add(bytes);
-      bytes = new BytesRef(_TestUtil.randomRealisticUnicodeString(random()));
+      bytes = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));
       d.add(new SortedDocValuesField("sorted", bytes));
       sorted.add(bytes);
       w.addDocument(d);
@@ -67,7 +68,7 @@ public class TestDocValuesWithThreads extends LuceneTestCase {
     assertEquals(1, r.leaves().size());
     final AtomicReader ar = r.leaves().get(0).reader();
 
-    int numThreads = _TestUtil.nextInt(random(), 2, 5);
+    int numThreads = TestUtil.nextInt(random(), 2, 5);
     List<Thread> threads = new ArrayList<Thread>();
     final CountDownLatch startingGun = new CountDownLatch(1);
     for(int t=0;t<numThreads;t++) {
@@ -143,9 +144,9 @@ public class TestDocValuesWithThreads extends LuceneTestCase {
     while (numDocs < NUM_DOCS) {
       final String s;
       if (random.nextBoolean()) {
-        s = _TestUtil.randomSimpleString(random);
+        s = TestUtil.randomSimpleString(random);
       } else {
-        s = _TestUtil.randomUnicodeString(random);
+        s = TestUtil.randomUnicodeString(random);
       }
       final BytesRef br = new BytesRef(s);
 
@@ -181,7 +182,7 @@ public class TestDocValuesWithThreads extends LuceneTestCase {
 
     final long END_TIME = System.currentTimeMillis() + (TEST_NIGHTLY ? 30 : 1);
 
-    final int NUM_THREADS = _TestUtil.nextInt(random(), 1, 10);
+    final int NUM_THREADS = TestUtil.nextInt(random(), 1, 10);
     Thread[] threads = new Thread[NUM_THREADS];
     for(int thread=0;thread<NUM_THREADS;thread++) {
       threads[thread] = new Thread() {
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions.java b/lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions.java
index c4423bb..3bd8797 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions.java
@@ -30,7 +30,7 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestDocsAndPositions extends LuceneTestCase {
   private String fieldName;
@@ -224,7 +224,7 @@ public class TestDocsAndPositions extends LuceneTestCase {
       IndexReaderContext topReaderContext = reader.getContext();
       for (AtomicReaderContext context : topReaderContext.leaves()) {
         int maxDoc = context.reader().maxDoc();
-        DocsEnum docsEnum = _TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, DocsEnum.FLAG_FREQS);
+        DocsEnum docsEnum = TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, DocsEnum.FLAG_FREQS);
         if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {
           assertNull(docsEnum);
           continue;
@@ -334,7 +334,7 @@ public class TestDocsAndPositions extends LuceneTestCase {
     writer.addDocument(doc);
     DirectoryReader reader = writer.getReader();
     AtomicReader r = getOnlySegmentReader(reader);
-    DocsEnum disi = _TestUtil.docs(random(), r, "foo", new BytesRef("bar"), null, null, DocsEnum.FLAG_NONE);
+    DocsEnum disi = TestUtil.docs(random(), r, "foo", new BytesRef("bar"), null, null, DocsEnum.FLAG_NONE);
     int docid = disi.docID();
     assertEquals(-1, docid);
     assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
@@ -342,7 +342,7 @@ public class TestDocsAndPositions extends LuceneTestCase {
     // now reuse and check again
     TermsEnum te = r.terms("foo").iterator(null);
     assertTrue(te.seekExact(new BytesRef("bar")));
-    disi = _TestUtil.docs(random(), te, null, disi, DocsEnum.FLAG_NONE);
+    disi = TestUtil.docs(random(), te, null, disi, DocsEnum.FLAG_NONE);
     docid = disi.docID();
     assertEquals(-1, docid);
     assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter.java b/lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter.java
index 7253341..638a8bf 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter.java
@@ -18,7 +18,6 @@ package org.apache.lucene.index;
  */
 
 import java.io.IOException;
-import java.io.Reader;
 
 import org.apache.lucene.analysis.*;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
@@ -35,7 +34,8 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.AttributeSource;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestDocumentWriter extends LuceneTestCase {
   private Directory dir;
@@ -283,7 +283,7 @@ public class TestDocumentWriter extends LuceneTestCase {
     writer.addDocument(doc);
     writer.close();
 
-    _TestUtil.checkIndex(dir);
+    TestUtil.checkIndex(dir);
 
     IndexReader reader = DirectoryReader.open(dir);
     // f1
@@ -324,7 +324,7 @@ public class TestDocumentWriter extends LuceneTestCase {
     writer.forceMerge(1); // be sure to have a single segment
     writer.close();
 
-    _TestUtil.checkIndex(dir);
+    TestUtil.checkIndex(dir);
 
     SegmentReader reader = getOnlySegmentReader(DirectoryReader.open(dir));
     FieldInfos fi = reader.getFieldInfos();
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestDuelingCodecs.java b/lucene/core/src/test/org/apache/lucene/index/TestDuelingCodecs.java
index 6ea6e0b..3da7cb0 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestDuelingCodecs.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestDuelingCodecs.java
@@ -30,7 +30,7 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LineFileDocs;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Compares one codec against another
@@ -92,8 +92,8 @@ public class TestDuelingCodecs extends LuceneTestCase {
     rightWriter.close();
     
     // check that our readers are valid
-    _TestUtil.checkReader(leftReader);
-    _TestUtil.checkReader(rightReader);
+    TestUtil.checkReader(leftReader);
+    TestUtil.checkReader(rightReader);
     
     info = "left: " + leftCodec.toString() + " / right: " + rightCodec.toString();
   }
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestFieldsReader.java b/lucene/core/src/test/org/apache/lucene/index/TestFieldsReader.java
index 78462cb..a3fa208 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestFieldsReader.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestFieldsReader.java
@@ -24,18 +24,9 @@ import java.util.*;
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.DocumentStoredFieldVisitor;
-import org.apache.lucene.document.DoubleField;
 import org.apache.lucene.document.Field;
-import org.apache.lucene.document.FieldType.NumericType;
-import org.apache.lucene.document.FieldType;
-import org.apache.lucene.document.FloatField;
-import org.apache.lucene.document.IntField;
-import org.apache.lucene.document.LongField;
-import org.apache.lucene.document.StoredField;
-import org.apache.lucene.document.StringField;
 import org.apache.lucene.index.FieldInfo.IndexOptions;
 import org.apache.lucene.index.IndexWriterConfig.OpenMode;
-import org.apache.lucene.search.FieldCache;
 import org.apache.lucene.store.BaseDirectory;
 import org.apache.lucene.store.BufferedIndexInput;
 import org.apache.lucene.store.Directory;
@@ -43,7 +34,7 @@ import org.apache.lucene.store.IOContext;
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.store.IndexOutput;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.AfterClass;
 import org.junit.BeforeClass;
 
@@ -200,7 +191,7 @@ public class TestFieldsReader extends LuceneTestCase {
 
   // LUCENE-1262
   public void testExceptions() throws Throwable {
-    File indexDir = _TestUtil.getTempDir("testfieldswriterexceptions");
+    File indexDir = TestUtil.getTempDir("testfieldswriterexceptions");
 
     try {
       Directory dir = new FaultyFSDirectory(indexDir);
@@ -236,7 +227,7 @@ public class TestFieldsReader extends LuceneTestCase {
       reader.close();
       dir.close();
     } finally {
-      _TestUtil.rmDir(indexDir);
+      TestUtil.rmDir(indexDir);
     }
 
   }
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestFlex.java b/lucene/core/src/test/org/apache/lucene/index/TestFlex.java
index 2bd65a9..37cc495 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestFlex.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestFlex.java
@@ -65,7 +65,7 @@ public class TestFlex extends LuceneTestCase {
   public void testTermOrd() throws Exception {
     Directory d = newDirectory();
     IndexWriter w = new IndexWriter(d, newIndexWriterConfig(TEST_VERSION_CURRENT,
-                                                             new MockAnalyzer(random())).setCodec(_TestUtil.alwaysPostingsFormat(new Lucene41PostingsFormat())));
+                                                             new MockAnalyzer(random())).setCodec(TestUtil.alwaysPostingsFormat(new Lucene41PostingsFormat())));
     Document doc = new Document();
     doc.add(newTextField("f", "a b c", Field.Store.NO));
     w.addDocument(doc);
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestForTooMuchCloning.java b/lucene/core/src/test/org/apache/lucene/index/TestForTooMuchCloning.java
index 1f243b0..3f4c245 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestForTooMuchCloning.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestForTooMuchCloning.java
@@ -27,7 +27,8 @@ import org.apache.lucene.search.TopDocs;
 import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestForTooMuchCloning extends LuceneTestCase {
 
@@ -46,7 +47,7 @@ public class TestForTooMuchCloning extends LuceneTestCase {
     for(int docs=0;docs<numDocs;docs++) {
       StringBuilder sb = new StringBuilder();
       for(int terms=0;terms<100;terms++) {
-        sb.append(_TestUtil.randomRealisticUnicodeString(random()));
+        sb.append(TestUtil.randomRealisticUnicodeString(random()));
         sb.append(' ');
       }
       final Document doc = new Document();
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestForceMergeForever.java b/lucene/core/src/test/org/apache/lucene/index/TestForceMergeForever.java
index 80ead16..53be31c 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestForceMergeForever.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestForceMergeForever.java
@@ -25,7 +25,7 @@ import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LineFileDocs;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestForceMergeForever extends LuceneTestCase {
 
@@ -57,7 +57,7 @@ public class TestForceMergeForever extends LuceneTestCase {
     final MyIndexWriter w = new MyIndexWriter(d, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));
 
     // Try to make an index that requires merging:
-    w.getConfig().setMaxBufferedDocs(_TestUtil.nextInt(random(), 2, 11));
+    w.getConfig().setMaxBufferedDocs(TestUtil.nextInt(random(), 2, 11));
     final int numStartDocs = atLeast(20);
     final LineFileDocs docs = new LineFileDocs(random(), true);
     for(int docIDX=0;docIDX<numStartDocs;docIDX++) {
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestIndexInput.java b/lucene/core/src/test/org/apache/lucene/index/TestIndexInput.java
index 23a129b..1594e2d 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestIndexInput.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestIndexInput.java
@@ -18,7 +18,8 @@ package org.apache.lucene.index;
  */
 
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.store.ByteArrayDataInput;
 import org.apache.lucene.store.ByteArrayDataOutput;
 import org.apache.lucene.store.DataInput;
@@ -100,9 +101,9 @@ public class TestIndexInput extends LuceneTestCase {
       final long l1;
       if (rarely()) {
         // a long with lots of zeroes at the end
-        l1 = LONGS[i] = _TestUtil.nextLong(random, 0, Integer.MAX_VALUE) << 32;
+        l1 = LONGS[i] = TestUtil.nextLong(random, 0, Integer.MAX_VALUE) << 32;
       } else {
-        l1 = LONGS[i] = _TestUtil.nextLong(random, 0, Long.MAX_VALUE);
+        l1 = LONGS[i] = TestUtil.nextLong(random, 0, Long.MAX_VALUE);
       }
       bdo.writeVLong(l1);
       bdo.writeLong(l1);
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriter.java b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriter.java
index da69db1..cf8a1ba 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriter.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriter.java
@@ -18,7 +18,6 @@ package org.apache.lucene.index;
  */
 
 import java.io.IOException;
-import java.io.Reader;
 import java.io.StringReader;
 import java.util.ArrayList;
 import java.util.Arrays;
@@ -71,8 +70,8 @@ import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.SetOnce;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.ThreadInterruptedException;
-import org.apache.lucene.util._TestUtil;
 import org.apache.lucene.util.automaton.Automaton;
 import org.apache.lucene.util.automaton.BasicAutomata;
 import org.apache.lucene.util.automaton.CharacterRunAutomaton;
@@ -319,7 +318,7 @@ public class TestIndexWriter extends LuceneTestCase {
         Document doc = new Document();
         doc.add(new Field("field", "aaa" + j, storedTextType));
         writer.addDocument(doc);
-        _TestUtil.syncConcurrentMerges(writer);
+        TestUtil.syncConcurrentMerges(writer);
         int flushCount = writer.getFlushCount();
         if (j == 1)
           lastFlushCount = flushCount;
@@ -378,7 +377,7 @@ public class TestIndexWriter extends LuceneTestCase {
       int lastFlushCount = -1;
       for(int j=1;j<52;j++) {
         writer.deleteDocuments(new Term("field", "aaa" + j));
-        _TestUtil.syncConcurrentMerges(writer);
+        TestUtil.syncConcurrentMerges(writer);
         int flushCount = writer.getFlushCount();
        
         if (j == 1)
@@ -554,12 +553,12 @@ public class TestIndexWriter extends LuceneTestCase {
       assertEquals(1, reader.numDocs());
       Term t = new Term("field", "a");
       assertEquals(1, reader.docFreq(t));
-      DocsEnum td = _TestUtil.docs(random(), reader,
-                                   "field",
-                                   new BytesRef("a"),
-                                   MultiFields.getLiveDocs(reader),
-                                   null,
-                                   DocsEnum.FLAG_FREQS);
+      DocsEnum td = TestUtil.docs(random(), reader,
+          "field",
+          new BytesRef("a"),
+          MultiFields.getLiveDocs(reader),
+          null,
+          DocsEnum.FLAG_FREQS);
       td.nextDoc();
       assertEquals(128*1024, td.freq());
       reader.close();
@@ -1145,7 +1144,7 @@ public class TestIndexWriter extends LuceneTestCase {
         }
 
         try {
-          _TestUtil.checkIndex(dir);
+          TestUtil.checkIndex(dir);
         } catch (Exception e) {
           failed = true;
           System.out.println("CheckIndex FAILED: unexpected exception");
@@ -1311,12 +1310,12 @@ public class TestIndexWriter extends LuceneTestCase {
 
 
     // test that the terms were indexed.
-    assertTrue(_TestUtil.docs(random(), ir, "binary", new BytesRef("doc1field1"), null, null, DocsEnum.FLAG_NONE).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
-    assertTrue(_TestUtil.docs(random(), ir, "binary", new BytesRef("doc2field1"), null, null, DocsEnum.FLAG_NONE).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
-    assertTrue(_TestUtil.docs(random(), ir, "binary", new BytesRef("doc3field1"), null, null, DocsEnum.FLAG_NONE).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
-    assertTrue(_TestUtil.docs(random(), ir, "string", new BytesRef("doc1field2"), null, null, DocsEnum.FLAG_NONE).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
-    assertTrue(_TestUtil.docs(random(), ir, "string", new BytesRef("doc2field2"), null, null, DocsEnum.FLAG_NONE).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
-    assertTrue(_TestUtil.docs(random(), ir, "string", new BytesRef("doc3field2"), null, null, DocsEnum.FLAG_NONE).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
+    assertTrue(TestUtil.docs(random(), ir, "binary", new BytesRef("doc1field1"), null, null, DocsEnum.FLAG_NONE).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
+    assertTrue(TestUtil.docs(random(), ir, "binary", new BytesRef("doc2field1"), null, null, DocsEnum.FLAG_NONE).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
+    assertTrue(TestUtil.docs(random(), ir, "binary", new BytesRef("doc3field1"), null, null, DocsEnum.FLAG_NONE).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
+    assertTrue(TestUtil.docs(random(), ir, "string", new BytesRef("doc1field2"), null, null, DocsEnum.FLAG_NONE).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
+    assertTrue(TestUtil.docs(random(), ir, "string", new BytesRef("doc2field2"), null, null, DocsEnum.FLAG_NONE).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
+    assertTrue(TestUtil.docs(random(), ir, "string", new BytesRef("doc3field2"), null, null, DocsEnum.FLAG_NONE).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
 
     ir.close();
     dir.close();
@@ -1469,7 +1468,7 @@ public class TestIndexWriter extends LuceneTestCase {
     // Tests that if FSDir is opened w/ a NoLockFactory (or SingleInstanceLF),
     // then IndexWriter ctor succeeds. Previously (LUCENE-2386) it failed
     // when listAll() was called in IndexFileDeleter.
-    Directory dir = newFSDirectory(_TestUtil.getTempDir("emptyFSDirNoLock"), NoLockFactory.getNoLockFactory());
+    Directory dir = newFSDirectory(TestUtil.getTempDir("emptyFSDirNoLock"), NoLockFactory.getNoLockFactory());
     new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random()))).close();
     dir.close();
   }
@@ -1589,7 +1588,7 @@ public class TestIndexWriter extends LuceneTestCase {
 
     indexWriter.close();
 
-    _TestUtil.checkIndex(dir);
+    TestUtil.checkIndex(dir);
 
     assertNoUnreferencedFiles(dir, "no tv files");
     DirectoryReader r0 = DirectoryReader.open(dir);
@@ -1776,7 +1775,7 @@ public class TestIndexWriter extends LuceneTestCase {
   }
 
   public void testWhetherDeleteAllDeletesWriteLock() throws Exception {
-    Directory d = newFSDirectory(_TestUtil.getTempDir("TestIndexWriter.testWhetherDeleteAllDeletesWriteLock"));
+    Directory d = newFSDirectory(TestUtil.getTempDir("TestIndexWriter.testWhetherDeleteAllDeletesWriteLock"));
     // Must use SimpleFSLockFactory... NativeFSLockFactory
     // somehow "knows" a lock is held against write.lock
     // even if you remove that file:
@@ -2025,7 +2024,7 @@ public class TestIndexWriter extends LuceneTestCase {
 
   // LUCENE-4398
   public void testRotatingFieldNames() throws Exception {
-    Directory dir = newFSDirectory(_TestUtil.getTempDir("TestIndexWriter.testChangingFields"));
+    Directory dir = newFSDirectory(TestUtil.getTempDir("TestIndexWriter.testChangingFields"));
     IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));
     iwc.setRAMBufferSizeMB(0.2);
     iwc.setMaxBufferedDocs(-1);
@@ -2146,7 +2145,7 @@ public class TestIndexWriter extends LuceneTestCase {
       for (int j = 0; j < numDocs; j++) {
         Document doc = new Document();
         doc.add(newField("id", ""+ (docId++), idFt));
-        doc.add(newField("foo", _TestUtil.randomSimpleString(random()), ft));
+        doc.add(newField("foo", TestUtil.randomSimpleString(random()), ft));
         docs.add(doc);
       }
       boolean success = false;
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterCommit.java b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterCommit.java
index a23fb4a..a36cbc3 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterCommit.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterCommit.java
@@ -18,7 +18,6 @@ package org.apache.lucene.index;
  */
 
 import java.io.IOException;
-import java.io.Reader;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.concurrent.atomic.AtomicBoolean;
@@ -33,7 +32,7 @@ import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestIndexWriterCommit extends LuceneTestCase {
   /*
@@ -178,8 +177,8 @@ public class TestIndexWriterCommit extends LuceneTestCase {
     // sum because the merged FST may use array encoding for
     // some arcs (which uses more space):
 
-    final String idFormat = _TestUtil.getPostingsFormat("id");
-    final String contentFormat = _TestUtil.getPostingsFormat("content");
+    final String idFormat = TestUtil.getPostingsFormat("id");
+    final String contentFormat = TestUtil.getPostingsFormat("content");
     assumeFalse("This test cannot run with Memory codec", idFormat.equals("Memory") || contentFormat.equals("Memory"));
     MockDirectoryWrapper dir = newMockDirectory();
     Analyzer analyzer;
@@ -330,7 +329,7 @@ public class TestIndexWriterCommit extends LuceneTestCase {
     final Directory dir = newDirectory();
     final RandomIndexWriter w = new RandomIndexWriter(random(), dir, newIndexWriterConfig(
                                                                                         TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));
-    _TestUtil.reduceOpenFiles(w.w);
+    TestUtil.reduceOpenFiles(w.w);
     w.commit();
     final AtomicBoolean failed = new AtomicBoolean();
     Thread[] threads = new Thread[NUM_THREADS];
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete.java b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete.java
index 52832f1..36af529 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete.java
@@ -20,7 +20,6 @@ package org.apache.lucene.index;
 import java.io.ByteArrayOutputStream;
 import java.io.IOException;
 import java.io.PrintStream;
-import java.io.Reader;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.List;
@@ -45,7 +44,8 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.store.RAMDirectory;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestIndexWriterDelete extends LuceneTestCase {
 
@@ -631,7 +631,7 @@ public class TestIndexWriterDelete extends LuceneTestCase {
         // If the close() succeeded, make sure there are
         // no unreferenced files.
         if (success) {
-          _TestUtil.checkIndex(dir);
+          TestUtil.checkIndex(dir);
           TestIndexWriter.assertNoUnreferencedFiles(dir, "after writer.close");
         }
         dir.setRandomIOExceptionRate(randomIOExceptionRate);
@@ -953,7 +953,7 @@ public class TestIndexWriterDelete extends LuceneTestCase {
     int upto = 0;
     while(upto < ids.size()) {
       final int left = ids.size() - upto;
-      final int inc = Math.min(left, _TestUtil.nextInt(random(), 1, 20));
+      final int inc = Math.min(left, TestUtil.nextInt(random(), 1, 20));
       final int limit = upto + inc;
       while(upto < limit) {
         w.deleteDocuments(new Term("id", ""+ids.get(upto++)));
@@ -970,7 +970,7 @@ public class TestIndexWriterDelete extends LuceneTestCase {
   public void testIndexingThenDeleting() throws Exception {
     // TODO: move this test to its own class and just @SuppressCodecs?
     // TODO: is it enough to just use newFSDirectory?
-    final String fieldFormat = _TestUtil.getPostingsFormat("field");
+    final String fieldFormat = TestUtil.getPostingsFormat("field");
     assumeFalse("This test cannot run with Memory codec", fieldFormat.equals("Memory"));
     assumeFalse("This test cannot run with SimpleText codec", fieldFormat.equals("SimpleText"));
     assumeFalse("This test cannot run with Direct codec", fieldFormat.equals("Direct"));
@@ -1124,7 +1124,7 @@ public class TestIndexWriterDelete extends LuceneTestCase {
     while(true) {
       StringBuilder sb = new StringBuilder();
       for(int termIDX=0;termIDX<100;termIDX++) {
-        sb.append(' ').append(_TestUtil.randomRealisticUnicodeString(random()));
+        sb.append(' ').append(TestUtil.randomRealisticUnicodeString(random()));
       }
       if (id == 500) {
         w.deleteDocuments(new Term("id", "0"));
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java
index ed486eb..39762ae 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java
@@ -19,7 +19,6 @@ package org.apache.lucene.index;
 
 import java.io.FileNotFoundException;
 import java.io.IOException;
-import java.io.Reader;
 import java.io.StringReader;
 import java.nio.file.NoSuchFileException;
 import java.util.ArrayList;
@@ -60,7 +59,7 @@ import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.InfoStream;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestIndexWriterExceptions extends LuceneTestCase {
 
@@ -175,7 +174,7 @@ public class TestIndexWriterExceptions extends LuceneTestCase {
         Term idTerm = new Term("id", id);
         try {
           if (r.nextBoolean()) {
-            writer.updateDocuments(idTerm, new DocCopyIterator(doc, _TestUtil.nextInt(r, 1, 20)));
+            writer.updateDocuments(idTerm, new DocCopyIterator(doc, TestUtil.nextInt(r, 1, 20)));
           } else {
             writer.updateDocument(idTerm, doc);
           }
@@ -185,7 +184,7 @@ public class TestIndexWriterExceptions extends LuceneTestCase {
             re.printStackTrace(System.out);
           }
           try {
-            _TestUtil.checkIndex(writer.getDirectory());
+            TestUtil.checkIndex(writer.getDirectory());
           } catch (IOException ioe) {
             System.out.println(Thread.currentThread().getName() + ": unexpected exception1");
             ioe.printStackTrace(System.out);
@@ -509,12 +508,12 @@ public class TestIndexWriterExceptions extends LuceneTestCase {
 
     // Make sure the doc that hit the exception was marked
     // as deleted:
-    DocsEnum tdocs = _TestUtil.docs(random(), reader,
-                                    t.field(),
-                                    new BytesRef(t.text()),
-                                    MultiFields.getLiveDocs(reader),
-                                    null,
-                                    0);
+    DocsEnum tdocs = TestUtil.docs(random(), reader,
+        t.field(),
+        new BytesRef(t.text()),
+        MultiFields.getLiveDocs(reader),
+        null,
+        0);
 
     int count = 0;
     while(tdocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
@@ -1276,7 +1275,7 @@ public class TestIndexWriterExceptions extends LuceneTestCase {
           }
           if (random().nextInt(20) == 0) {
             w.commit();
-            _TestUtil.checkIndex(dir);
+            TestUtil.checkIndex(dir);
           }
             
         }
@@ -1297,7 +1296,7 @@ public class TestIndexWriterExceptions extends LuceneTestCase {
           }
           if (random().nextInt(20) == 0) {
             w.commit();
-            _TestUtil.checkIndex(dir);
+            TestUtil.checkIndex(dir);
           }
         }
         document = new Document();
@@ -1435,7 +1434,7 @@ public class TestIndexWriterExceptions extends LuceneTestCase {
     }
 
     docs.clear();
-    final int limit = _TestUtil.nextInt(random(), 2, 25);
+    final int limit = TestUtil.nextInt(random(), 2, 25);
     final int crashAt = random().nextInt(limit);
     for(int docCount=0;docCount<limit;docCount++) {
       Document doc = new Document();
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge.java b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge.java
index 11c1353..863af0b 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge.java
@@ -26,7 +26,7 @@ import org.apache.lucene.index.IndexWriterConfig.OpenMode;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestIndexWriterForceMerge extends LuceneTestCase {
   public void testPartialMerge() throws IOException {
@@ -36,7 +36,7 @@ public class TestIndexWriterForceMerge extends LuceneTestCase {
     final Document doc = new Document();
     doc.add(newStringField("content", "aaa", Field.Store.NO));
     final int incrMin = TEST_NIGHTLY ? 15 : 40;
-    for(int numDocs=10;numDocs<500;numDocs += _TestUtil.nextInt(random(), incrMin, 5*incrMin)) {
+    for(int numDocs=10;numDocs<500;numDocs += TestUtil.nextInt(random(), incrMin, 5 * incrMin)) {
       LogDocMergePolicy ldmp = new LogDocMergePolicy();
       ldmp.setMinMergeDocs(1);
       ldmp.setMergeFactor(5);
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterLockRelease.java b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterLockRelease.java
index e6467f1..0833c6e 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterLockRelease.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterLockRelease.java
@@ -25,7 +25,8 @@ import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.index.IndexWriterConfig.OpenMode;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * This tests the patch for issue #LUCENE-715 (IndexWriter does not
@@ -35,7 +36,7 @@ import org.apache.lucene.util._TestUtil;
 public class TestIndexWriterLockRelease extends LuceneTestCase {
   
   public void testIndexWriterLockRelease() throws IOException {
-    Directory dir = newFSDirectory(_TestUtil.getTempDir("testLockRelease"));
+    Directory dir = newFSDirectory(TestUtil.getTempDir("testLockRelease"));
     try {
       new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND));
     } catch (FileNotFoundException | NoSuchFileException e) {
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull.java b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull.java
index ff33ff7..c418e4a 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull.java
@@ -34,7 +34,7 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.store.RAMDirectory;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 import static org.apache.lucene.index.TestIndexWriter.assertNoUnreferencedFiles;
 
@@ -55,7 +55,7 @@ public class TestIndexWriterOnDiskFull extends LuceneTestCase {
         System.out.println("TEST: pass=" + pass);
       }
       boolean doAbort = pass == 1;
-      long diskFree = _TestUtil.nextInt(random(), 100, 300);
+      long diskFree = TestUtil.nextInt(random(), 100, 300);
       while(true) {
         if (VERBOSE) {
           System.out.println("TEST: cycle: diskFree=" + diskFree);
@@ -112,7 +112,7 @@ public class TestIndexWriterOnDiskFull extends LuceneTestCase {
 
           //_TestUtil.syncConcurrentMerges(ms);
 
-          if (_TestUtil.anyFilesExceptWriteLock(dir)) {
+          if (TestUtil.anyFilesExceptWriteLock(dir)) {
             assertNoUnreferencedFiles(dir, "after disk full during addDocument");
             
             // Make sure reader can open the index:
@@ -122,7 +122,7 @@ public class TestIndexWriterOnDiskFull extends LuceneTestCase {
           dir.close();
           // Now try again w/ more space:
 
-          diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random(), 400, 600) : _TestUtil.nextInt(random(), 3000, 5000);
+          diskFree += TEST_NIGHTLY ? TestUtil.nextInt(random(), 400, 600) : TestUtil.nextInt(random(), 3000, 5000);
         } else {
           //_TestUtil.syncConcurrentMerges(writer);
           dir.setMaxSizeInBytes(0);
@@ -156,8 +156,8 @@ public class TestIndexWriterOnDiskFull extends LuceneTestCase {
     // sum because the merged FST may use array encoding for
     // some arcs (which uses more space):
 
-    final String idFormat = _TestUtil.getPostingsFormat("id");
-    final String contentFormat = _TestUtil.getPostingsFormat("content");
+    final String idFormat = TestUtil.getPostingsFormat("id");
+    final String contentFormat = TestUtil.getPostingsFormat("content");
     assumeFalse("This test cannot run with Memory codec", idFormat.equals("Memory") || contentFormat.equals("Memory"));
 
     int START_COUNT = 57;
@@ -227,7 +227,7 @@ public class TestIndexWriterOnDiskFull extends LuceneTestCase {
       }
       
       // Start with 100 bytes more than we are currently using:
-      long diskFree = diskUsage+_TestUtil.nextInt(random(), 50, 200);
+      long diskFree = diskUsage+ TestUtil.nextInt(random(), 50, 200);
       
       int method = iter;
       
@@ -355,7 +355,7 @@ public class TestIndexWriterOnDiskFull extends LuceneTestCase {
           
           // Make sure all threads from
           // ConcurrentMergeScheduler are done
-          _TestUtil.syncConcurrentMerges(writer);
+          TestUtil.syncConcurrentMerges(writer);
           
           if (VERBOSE) {
             System.out.println("  now test readers");
@@ -442,12 +442,12 @@ public class TestIndexWriterOnDiskFull extends LuceneTestCase {
         // Wait for all BG threads to finish else
         // dir.close() will throw IOException because
         // there are still open files
-        _TestUtil.syncConcurrentMerges(ms);
+        TestUtil.syncConcurrentMerges(ms);
         
         dir.close();
         
         // Try again with more free space:
-        diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random(), 4000, 8000) : _TestUtil.nextInt(random(), 40000, 80000);
+        diskFree += TEST_NIGHTLY ? TestUtil.nextInt(random(), 4000, 8000) : TestUtil.nextInt(random(), 40000, 80000);
       }
     }
     
@@ -514,7 +514,7 @@ public class TestIndexWriterOnDiskFull extends LuceneTestCase {
       // expected
       assertTrue(ftdm.didFail1 || ftdm.didFail2);
     }
-    _TestUtil.checkIndex(dir);
+    TestUtil.checkIndex(dir);
     ftdm.clearDoFail();
     w.addDocument(doc);
     w.close();
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnJRECrash.java b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnJRECrash.java
index 75b393f..3c6dd3e 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnJRECrash.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnJRECrash.java
@@ -30,7 +30,7 @@ import java.util.List;
 
 import org.apache.lucene.store.BaseDirectoryWrapper;
 import org.apache.lucene.util.Constants;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 import com.carrotsearch.randomizedtesting.SeedUtils;
 /**
@@ -43,7 +43,7 @@ public class TestIndexWriterOnJRECrash extends TestNRTThreads {
   @Override
   public void setUp() throws Exception {
     super.setUp();
-    tempDir = _TestUtil.getTempDir("jrecrash");
+    tempDir = TestUtil.getTempDir("jrecrash");
     tempDir.delete();
     tempDir.mkdir();
   }
@@ -67,7 +67,7 @@ public class TestIndexWriterOnJRECrash extends TestNRTThreads {
       //    Codec.getDefault().getName().equals("Lucene4x"));
       
       // we are the fork, setup a crashing thread
-      final int crashTime = _TestUtil.nextInt(random(), 3000, 4000);
+      final int crashTime = TestUtil.nextInt(random(), 3000, 4000);
       Thread t = new Thread() {
         @Override
         public void run() {
@@ -162,7 +162,7 @@ public class TestIndexWriterOnJRECrash extends TestNRTThreads {
         // design we don't try to be smart about this case
         // since that too risky):
         if (SegmentInfos.getLastCommitGeneration(dir) > 1) {
-          _TestUtil.checkIndex(dir);
+          TestUtil.checkIndex(dir);
         }
         dir.close();
         return true;
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors.java b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors.java
index 4d7fcbd..a1e27bb 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors.java
@@ -28,11 +28,11 @@ import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.util.LineFileDocs;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.PrintStreamInfoStream;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestIndexWriterOutOfFileDescriptors extends LuceneTestCase {
   public void test() throws Exception {
-    MockDirectoryWrapper dir = newMockFSDirectory(_TestUtil.getTempDir("TestIndexWriterOutOfFileDescriptors"));
+    MockDirectoryWrapper dir = newMockFSDirectory(TestUtil.getTempDir("TestIndexWriterOutOfFileDescriptors"));
     dir.setPreventDoubleWrite(false);
     double rate = random().nextDouble()*0.01;
     //System.out.println("rate=" + rate);
@@ -129,7 +129,7 @@ public class TestIndexWriterOutOfFileDescriptors extends LuceneTestCase {
         // it to addIndexes later:
         dir.setRandomIOExceptionRateOnOpen(0.0);
         r = DirectoryReader.open(dir);
-        dirCopy = newMockFSDirectory(_TestUtil.getTempDir("TestIndexWriterOutOfFileDescriptors.copy"));
+        dirCopy = newMockFSDirectory(TestUtil.getTempDir("TestIndexWriterOutOfFileDescriptors.copy"));
         Set<String> files = new HashSet<String>();
         for (String file : dir.listAll()) {
           dir.copy(dirCopy, file, file, IOContext.DEFAULT);
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader.java b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader.java
index a4d1958..5fedf2b 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader.java
@@ -41,8 +41,8 @@ import org.apache.lucene.store.RAMDirectory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.InfoStream;
 import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.ThreadInterruptedException;
-import org.apache.lucene.util._TestUtil;
 import org.junit.Test;
 
 public class TestIndexWriterReader extends LuceneTestCase {
@@ -51,11 +51,11 @@ public class TestIndexWriterReader extends LuceneTestCase {
   
   public static int count(Term t, IndexReader r) throws IOException {
     int count = 0;
-    DocsEnum td = _TestUtil.docs(random(), r,
-                                 t.field(), new BytesRef(t.text()),
-                                 MultiFields.getLiveDocs(r),
-                                 null,
-                                 0);
+    DocsEnum td = TestUtil.docs(random(), r,
+        t.field(), new BytesRef(t.text()),
+        MultiFields.getLiveDocs(r),
+        null,
+        0);
 
     if (td != null) {
       while (td.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
@@ -370,7 +370,7 @@ public class TestIndexWriterReader extends LuceneTestCase {
     Directory mainDir = getAssertNoDeletesDirectory(newDirectory());
 
     IndexWriter mainWriter = new IndexWriter(mainDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));
-    _TestUtil.reduceOpenFiles(mainWriter);
+    TestUtil.reduceOpenFiles(mainWriter);
 
     AddDirectoriesThreads addDirThreads = new AddDirectoriesThreads(numIter, mainWriter);
     addDirThreads.launchThreads(numDirs);
@@ -384,7 +384,7 @@ public class TestIndexWriterReader extends LuceneTestCase {
     
     assertTrue(addDirThreads.failures.size() == 0);
 
-    _TestUtil.checkIndex(mainDir);
+    TestUtil.checkIndex(mainDir);
 
     IndexReader reader = DirectoryReader.open(mainDir);
     assertEquals(addDirThreads.count.intValue(), reader.numDocs());
@@ -413,7 +413,7 @@ public class TestIndexWriterReader extends LuceneTestCase {
       this.mainWriter = mainWriter;
       addDir = newDirectory();
       IndexWriter writer = new IndexWriter(addDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(2));
-      _TestUtil.reduceOpenFiles(writer);
+      TestUtil.reduceOpenFiles(writer);
       for (int i = 0; i < NUM_INIT_DOCS; i++) {
         Document doc = DocHelper.createDocument(i, "addindex", 4);
         writer.addDocument(doc);
@@ -659,9 +659,9 @@ public class TestIndexWriterReader extends LuceneTestCase {
 
     // get a reader to put writer into near real-time mode
     DirectoryReader r1 = writer.getReader();
-    _TestUtil.checkIndex(dir1);
+    TestUtil.checkIndex(dir1);
     writer.commit();
-    _TestUtil.checkIndex(dir1);
+    TestUtil.checkIndex(dir1);
     assertEquals(100, r1.numDocs());
 
     for (int i = 0; i < 10; i++) {
@@ -691,7 +691,7 @@ public class TestIndexWriterReader extends LuceneTestCase {
     DirectoryReader r = writer.getReader();
     writer.close();
 
-    _TestUtil.checkIndex(dir1);
+    TestUtil.checkIndex(dir1);
 
     // reader should remain usable even after IndexWriter is closed:
     assertEquals(100, r.numDocs());
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterWithThreads.java b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterWithThreads.java
index 540f1f3..4e40b41 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterWithThreads.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterWithThreads.java
@@ -40,8 +40,8 @@ import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LineFileDocs;
 import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.ThreadInterruptedException;
-import org.apache.lucene.util._TestUtil;
 import org.apache.lucene.util.LuceneTestCase.Slow;
 
 /**
@@ -228,12 +228,12 @@ public class TestIndexWriterWithThreads extends LuceneTestCase {
 
       // Quick test to make sure index is not corrupt:
       IndexReader reader = DirectoryReader.open(dir);
-      DocsEnum tdocs = _TestUtil.docs(random(), reader,
-                                      "field",
-                                      new BytesRef("aaa"),
-                                      MultiFields.getLiveDocs(reader),
-                                      null,
-                                      0);
+      DocsEnum tdocs = TestUtil.docs(random(), reader,
+          "field",
+          new BytesRef("aaa"),
+          MultiFields.getLiveDocs(reader),
+          null,
+          0);
       int count = 0;
       while(tdocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
         count++;
@@ -545,7 +545,7 @@ public class TestIndexWriterWithThreads extends LuceneTestCase {
       ((MockDirectoryWrapper)d).setPreventDoubleWrite(false);
     }
 
-    final int threadCount = _TestUtil.nextInt(random(), 2, 6);
+    final int threadCount = TestUtil.nextInt(random(), 2, 6);
 
     final AtomicReference<IndexWriter> writerRef = new AtomicReference<IndexWriter>();
     writerRef.set(new IndexWriter(d, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))));
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestIndexableField.java b/lucene/core/src/test/org/apache/lucene/index/TestIndexableField.java
index cd303f2..a83815f 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestIndexableField.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestIndexableField.java
@@ -35,7 +35,7 @@ import org.apache.lucene.search.TopDocs;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestIndexableField extends LuceneTestCase {
 
@@ -172,7 +172,7 @@ public class TestIndexableField extends LuceneTestCase {
     int baseCount = 0;
 
     for(int docCount=0;docCount<NUM_DOCS;docCount++) {
-      final int fieldCount = _TestUtil.nextInt(random(), 1, 17);
+      final int fieldCount = TestUtil.nextInt(random(), 1, 17);
       fieldsPerDoc[docCount] = fieldCount-1;
 
       final int finalDocCount = docCount;
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestLazyProxSkipping.java b/lucene/core/src/test/org/apache/lucene/index/TestLazyProxSkipping.java
index 0cb50fd..7469d04 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestLazyProxSkipping.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestLazyProxSkipping.java
@@ -18,7 +18,6 @@ package org.apache.lucene.index;
  */
 
 import java.io.IOException;
-import java.io.Reader;
 
 import org.apache.lucene.analysis.*;
 import org.apache.lucene.document.Document;
@@ -33,7 +32,7 @@ import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.store.RAMDirectory;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Tests lazy skipping on the proximity file.
@@ -132,7 +131,7 @@ public class TestLazyProxSkipping extends LuceneTestCase {
     }
  
     public void testLazySkipping() throws IOException {
-      final String fieldFormat = _TestUtil.getPostingsFormat(this.field);
+      final String fieldFormat = TestUtil.getPostingsFormat(this.field);
       assumeFalse("This test cannot run with Memory postings format", fieldFormat.equals("Memory"));
       assumeFalse("This test cannot run with Direct postings format", fieldFormat.equals("Direct"));
       assumeFalse("This test cannot run with SimpleText postings format", fieldFormat.equals("SimpleText"));
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestLongPostings.java b/lucene/core/src/test/org/apache/lucene/index/TestLongPostings.java
index 90fa89a..5c767c0 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestLongPostings.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestLongPostings.java
@@ -33,7 +33,8 @@ import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.LuceneTestCase.SuppressCodecs;
 import org.apache.lucene.util.FixedBitSet;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 @SuppressCodecs({ "SimpleText", "Memory", "Direct" })
 public class TestLongPostings extends LuceneTestCase {
@@ -43,7 +44,7 @@ public class TestLongPostings extends LuceneTestCase {
   private String getRandomTerm(String other) throws IOException {
     Analyzer a = new MockAnalyzer(random());
     while(true) {
-      String s = _TestUtil.randomRealisticUnicodeString(random());
+      String s = TestUtil.randomRealisticUnicodeString(random());
       if (other != null && s.equals(other)) {
         continue;
       }
@@ -77,7 +78,7 @@ public class TestLongPostings extends LuceneTestCase {
   public void testLongPostings() throws Exception {
     // Don't use _TestUtil.getTempDir so that we own the
     // randomness (ie same seed will point to same dir):
-    Directory dir = newFSDirectory(_TestUtil.getTempDir("longpostings" + "." + random().nextLong()));
+    Directory dir = newFSDirectory(TestUtil.getTempDir("longpostings" + "." + random().nextLong()));
 
     final int NUM_DOCS = atLeast(2000);
 
@@ -119,7 +120,7 @@ public class TestLongPostings extends LuceneTestCase {
       final Document doc = new Document();
       String s = isS1.get(idx) ? s1 : s2;
       final Field f = newTextField("field", s, Field.Store.NO);
-      final int count = _TestUtil.nextInt(random(), 1, 4);
+      final int count = TestUtil.nextInt(random(), 1, 4);
       for(int ct=0;ct<count;ct++) {
         doc.add(f);
       }
@@ -219,7 +220,7 @@ public class TestLongPostings extends LuceneTestCase {
           if (docID == -1) {
             targetDocID = random().nextInt(NUM_DOCS+1);
           } else {
-            targetDocID = docID + _TestUtil.nextInt(random(), 1, NUM_DOCS - docID);
+            targetDocID = docID + TestUtil.nextInt(random(), 1, NUM_DOCS - docID);
           }
           if (VERBOSE) {
             System.out.println("TEST: docID=" + docID + "; do advance(" + targetDocID + ")");
@@ -274,7 +275,7 @@ public class TestLongPostings extends LuceneTestCase {
   public void doTestLongPostingsNoPositions(IndexOptions options) throws Exception {
     // Don't use _TestUtil.getTempDir so that we own the
     // randomness (ie same seed will point to same dir):
-    Directory dir = newFSDirectory(_TestUtil.getTempDir("longpostings" + "." + random().nextLong()));
+    Directory dir = newFSDirectory(TestUtil.getTempDir("longpostings" + "." + random().nextLong()));
 
     final int NUM_DOCS = atLeast(2000);
 
@@ -319,7 +320,7 @@ public class TestLongPostings extends LuceneTestCase {
         final Document doc = new Document();
         String s = isS1.get(idx) ? s1 : s2;
         final Field f = newField("field", s, ft);
-        final int count = _TestUtil.nextInt(random(), 1, 4);
+        final int count = TestUtil.nextInt(random(), 1, 4);
         for(int ct=0;ct<count;ct++) {
           doc.add(f);
         }
@@ -374,10 +375,10 @@ public class TestLongPostings extends LuceneTestCase {
       final DocsEnum postings;
 
       if (options == IndexOptions.DOCS_ONLY) {
-        docs = _TestUtil.docs(random(), r, "field", new BytesRef(term), null, null, DocsEnum.FLAG_NONE);
+        docs = TestUtil.docs(random(), r, "field", new BytesRef(term), null, null, DocsEnum.FLAG_NONE);
         postings = null;
       } else {
-        docs = postings = _TestUtil.docs(random(), r, "field", new BytesRef(term), null, null, DocsEnum.FLAG_FREQS);
+        docs = postings = TestUtil.docs(random(), r, "field", new BytesRef(term), null, null, DocsEnum.FLAG_FREQS);
         assert postings != null;
       }
       assert docs != null;
@@ -420,7 +421,7 @@ public class TestLongPostings extends LuceneTestCase {
           if (docID == -1) {
             targetDocID = random().nextInt(NUM_DOCS+1);
           } else {
-            targetDocID = docID + _TestUtil.nextInt(random(), 1, NUM_DOCS - docID);
+            targetDocID = docID + TestUtil.nextInt(random(), 1, NUM_DOCS - docID);
           }
           if (VERBOSE) {
             System.out.println("TEST: docID=" + docID + "; do advance(" + targetDocID + ")");
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestMaxTermFrequency.java b/lucene/core/src/test/org/apache/lucene/index/TestMaxTermFrequency.java
index 97dc661..8441185 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestMaxTermFrequency.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestMaxTermFrequency.java
@@ -30,7 +30,7 @@ import org.apache.lucene.search.similarities.TFIDFSimilarity;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Tests the maxTermFrequency statistic in FieldInvertState
@@ -82,10 +82,10 @@ public class TestMaxTermFrequency extends LuceneTestCase {
    */
   private String addValue() {
     List<String> terms = new ArrayList<String>();
-    int maxCeiling = _TestUtil.nextInt(random(), 0, 255);
+    int maxCeiling = TestUtil.nextInt(random(), 0, 255);
     int max = 0;
     for (char ch = 'a'; ch <= 'z'; ch++) {
-      int num = _TestUtil.nextInt(random(), 0, maxCeiling);
+      int num = TestUtil.nextInt(random(), 0, maxCeiling);
       for (int i = 0; i < num; i++)
         terms.add(Character.toString(ch));
       max = Math.max(max, num);
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestMixedCodecs.java b/lucene/core/src/test/org/apache/lucene/index/TestMixedCodecs.java
index c884479..9cb54b1 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestMixedCodecs.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestMixedCodecs.java
@@ -26,7 +26,7 @@ import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestMixedCodecs extends LuceneTestCase {
 
@@ -56,7 +56,7 @@ public class TestMixedCodecs extends LuceneTestCase {
           w.close();
         }
         w = new RandomIndexWriter(random(), dir, iwc);
-        docsLeftInThisSegment = _TestUtil.nextInt(random(), 10, 100);
+        docsLeftInThisSegment = TestUtil.nextInt(random(), 10, 100);
       }
       final Document doc = new Document();
       doc.add(newStringField("id", String.valueOf(docUpto), Field.Store.YES));
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestMultiDocValues.java b/lucene/core/src/test/org/apache/lucene/index/TestMultiDocValues.java
index c36b049..72d546f 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestMultiDocValues.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestMultiDocValues.java
@@ -29,7 +29,8 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /** Tests MultiDocValues versus ordinary segment merging */
 public class TestMultiDocValues extends LuceneTestCase {
@@ -81,7 +82,7 @@ public class TestMultiDocValues extends LuceneTestCase {
 
     int numDocs = atLeast(500);
     for (int i = 0; i < numDocs; i++) {
-      ref.copyChars(_TestUtil.randomUnicodeString(random()));
+      ref.copyChars(TestUtil.randomUnicodeString(random()));
       iw.addDocument(doc);
       if (random().nextInt(17) == 0) {
         iw.commit();
@@ -120,7 +121,7 @@ public class TestMultiDocValues extends LuceneTestCase {
 
     int numDocs = atLeast(500);
     for (int i = 0; i < numDocs; i++) {
-      ref.copyChars(_TestUtil.randomUnicodeString(random()));
+      ref.copyChars(TestUtil.randomUnicodeString(random()));
       if (defaultCodecSupportsDocsWithField() && random().nextInt(7) == 0) {
         iw.addDocument(new Document());
       }
@@ -167,7 +168,7 @@ public class TestMultiDocValues extends LuceneTestCase {
 
     int numDocs = atLeast(500);
     for (int i = 0; i < numDocs; i++) {
-      ref.copyChars(_TestUtil.randomSimpleString(random(), 2));
+      ref.copyChars(TestUtil.randomSimpleString(random(), 2));
       iw.addDocument(doc);
       if (random().nextInt(17) == 0) {
         iw.commit();
@@ -210,7 +211,7 @@ public class TestMultiDocValues extends LuceneTestCase {
       Document doc = new Document();
       int numValues = random().nextInt(5);
       for (int j = 0; j < numValues; j++) {
-        doc.add(new SortedSetDocValuesField("bytes", new BytesRef(_TestUtil.randomUnicodeString(random()))));
+        doc.add(new SortedSetDocValuesField("bytes", new BytesRef(TestUtil.randomUnicodeString(random()))));
       }
       iw.addDocument(doc);
       if (random().nextInt(17) == 0) {
@@ -275,7 +276,7 @@ public class TestMultiDocValues extends LuceneTestCase {
       Document doc = new Document();
       int numValues = random().nextInt(5);
       for (int j = 0; j < numValues; j++) {
-        doc.add(new SortedSetDocValuesField("bytes", new BytesRef(_TestUtil.randomSimpleString(random(), 2))));
+        doc.add(new SortedSetDocValuesField("bytes", new BytesRef(TestUtil.randomSimpleString(random(), 2))));
       }
       iw.addDocument(doc);
       if (random().nextInt(17) == 0) {
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestMultiFields.java b/lucene/core/src/test/org/apache/lucene/index/TestMultiFields.java
index 1f51ecb..6c162fe 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestMultiFields.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestMultiFields.java
@@ -44,7 +44,7 @@ public class TestMultiFields extends LuceneTestCase {
       Set<Integer> deleted = new HashSet<Integer>();
       List<BytesRef> terms = new ArrayList<BytesRef>();
 
-      int numDocs = _TestUtil.nextInt(random(), 1, 100 * RANDOM_MULTIPLIER);
+      int numDocs = TestUtil.nextInt(random(), 1, 100 * RANDOM_MULTIPLIER);
       Document doc = new Document();
       Field f = newStringField("field", "", Field.Store.NO);
       doc.add(f);
@@ -64,7 +64,7 @@ public class TestMultiFields extends LuceneTestCase {
           docs.get(term).add(i);
           f.setStringValue(term.utf8ToString());
         } else {
-          String s = _TestUtil.randomUnicodeString(random(), 10);
+          String s = TestUtil.randomUnicodeString(random(), 10);
           BytesRef term = new BytesRef(s);
           if (!docs.containsKey(term)) {
             docs.put(term, new ArrayList<Integer>());
@@ -122,7 +122,7 @@ public class TestMultiFields extends LuceneTestCase {
           System.out.println("TEST: seek term="+ UnicodeUtil.toHexString(term.utf8ToString()) + " " + term);
         }
         
-        DocsEnum docsEnum = _TestUtil.docs(random(), reader, "field", term, liveDocs, null, DocsEnum.FLAG_NONE);
+        DocsEnum docsEnum = TestUtil.docs(random(), reader, "field", term, liveDocs, null, DocsEnum.FLAG_NONE);
         assertNotNull(docsEnum);
 
         for(int docID : docs.get(term)) {
@@ -163,8 +163,8 @@ public class TestMultiFields extends LuceneTestCase {
     w.addDocument(d);
     IndexReader r = w.getReader();
     w.close();
-    DocsEnum d1 = _TestUtil.docs(random(), r, "f", new BytesRef("j"), null, null, DocsEnum.FLAG_NONE);
-    DocsEnum d2 = _TestUtil.docs(random(), r, "f", new BytesRef("j"), null, null, DocsEnum.FLAG_NONE);
+    DocsEnum d1 = TestUtil.docs(random(), r, "f", new BytesRef("j"), null, null, DocsEnum.FLAG_NONE);
+    DocsEnum d2 = TestUtil.docs(random(), r, "f", new BytesRef("j"), null, null, DocsEnum.FLAG_NONE);
     assertEquals(0, d1.nextDoc());
     assertEquals(0, d2.nextDoc());
     r.close();
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestMultiLevelSkipList.java b/lucene/core/src/test/org/apache/lucene/index/TestMultiLevelSkipList.java
index 63f75f3..22c285f 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestMultiLevelSkipList.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestMultiLevelSkipList.java
@@ -18,7 +18,6 @@ package org.apache.lucene.index;
  */
 
 import java.io.IOException;
-import java.io.Reader;
 import java.util.concurrent.atomic.AtomicInteger;
 
 import org.apache.lucene.analysis.*;
@@ -33,7 +32,7 @@ import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.store.RAMDirectory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.Before;
 
 /**
@@ -69,7 +68,7 @@ public class TestMultiLevelSkipList extends LuceneTestCase {
 
   public void testSimpleSkip() throws IOException {
     Directory dir = new CountingRAMDirectory(new RAMDirectory());
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new PayloadAnalyzer()).setCodec(_TestUtil.alwaysPostingsFormat(new Lucene41PostingsFormat())).setMergePolicy(newLogMergePolicy()));
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new PayloadAnalyzer()).setCodec(TestUtil.alwaysPostingsFormat(new Lucene41PostingsFormat())).setMergePolicy(newLogMergePolicy()));
     Term term = new Term("test", "a");
     for (int i = 0; i < 5000; i++) {
       Document d1 = new Document();
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestNeverDelete.java b/lucene/core/src/test/org/apache/lucene/index/TestNeverDelete.java
index 8e9dec3..9f45e21 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestNeverDelete.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestNeverDelete.java
@@ -27,7 +27,7 @@ import org.apache.lucene.document.Field;
 import org.apache.lucene.store.BaseDirectoryWrapper;
 import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 // Make sure if you use NoDeletionPolicy that no file
 // referenced by a commit point is ever deleted
@@ -35,7 +35,7 @@ import org.apache.lucene.util._TestUtil;
 public class TestNeverDelete extends LuceneTestCase {
 
   public void testIndexing() throws Exception {
-    final File tmpDir = _TestUtil.getTempDir("TestNeverDelete");
+    final File tmpDir = TestUtil.getTempDir("TestNeverDelete");
     final BaseDirectoryWrapper d = newFSDirectory(tmpDir);
 
     // We want to "see" files removed if Lucene removed
@@ -49,7 +49,7 @@ public class TestNeverDelete extends LuceneTestCase {
                                                       newIndexWriterConfig(TEST_VERSION_CURRENT,
                                                                            new MockAnalyzer(random()))
                                                       .setIndexDeletionPolicy(NoDeletionPolicy.INSTANCE));
-    w.w.getConfig().setMaxBufferedDocs(_TestUtil.nextInt(random(), 5, 30));
+    w.w.getConfig().setMaxBufferedDocs(TestUtil.nextInt(random(), 5, 30));
 
     w.commit();
     Thread[] indexThreads = new Thread[random().nextInt(4)];
@@ -108,6 +108,6 @@ public class TestNeverDelete extends LuceneTestCase {
     w.close();
     d.close();
 
-    _TestUtil.rmDir(tmpDir);
+    TestUtil.rmDir(tmpDir);
   }
 }
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestNorms.java b/lucene/core/src/test/org/apache/lucene/index/TestNorms.java
index bb91737..7a0cdb2 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestNorms.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestNorms.java
@@ -36,7 +36,7 @@ import org.apache.lucene.util.LineFileDocs;
 import org.apache.lucene.util.LuceneTestCase.Slow;
 import org.apache.lucene.util.LuceneTestCase.SuppressCodecs;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Test that norms info is preserved during index life - including
@@ -107,7 +107,7 @@ public class TestNorms extends LuceneTestCase {
   }
   
   public void testMaxByteNorms() throws IOException {
-    Directory dir = newFSDirectory(_TestUtil.getTempDir("TestNorms.testMaxByteNorms"));
+    Directory dir = newFSDirectory(TestUtil.getTempDir("TestNorms.testMaxByteNorms"));
     buildIndex(dir);
     AtomicReader open = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(dir));
     NumericDocValues normValues = open.getNormValues(byteTestField);
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates.java b/lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates.java
index 69a7458..4d81ba5 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates.java
@@ -32,7 +32,8 @@ import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.LuceneTestCase.SuppressCodecs;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.Test;
 
 import com.carrotsearch.randomizedtesting.generators.RandomPicks;
@@ -981,7 +982,7 @@ public class TestNumericDocValuesUpdates extends LuceneTestCase {
     final IndexWriter writer = new IndexWriter(dir, conf);
     
     // create index
-    final int numThreads = _TestUtil.nextInt(random(), 3, 6);
+    final int numThreads = TestUtil.nextInt(random(), 3, 6);
     final int numDocs = atLeast(2000);
     for (int i = 0; i < numDocs; i++) {
       Document doc = new Document();
@@ -1200,10 +1201,10 @@ public class TestNumericDocValuesUpdates extends LuceneTestCase {
     IndexWriter writer = new IndexWriter(dir1, conf);
     
     final int numDocs = atLeast(50);
-    final int numTerms = _TestUtil.nextInt(random(), 1, numDocs / 5);
+    final int numTerms = TestUtil.nextInt(random(), 1, numDocs / 5);
     Set<String> randomTerms = new HashSet<String>();
     while (randomTerms.size() < numTerms) {
-      randomTerms.add(_TestUtil.randomSimpleString(random()));
+      randomTerms.add(TestUtil.randomSimpleString(random()));
     }
 
     // create first index
@@ -1298,10 +1299,10 @@ public class TestNumericDocValuesUpdates extends LuceneTestCase {
     // test data: lots of documents (few 10Ks) and lots of update terms (few hundreds)
     final int numDocs = atLeast(20000);
     final int numNumericFields = atLeast(5);
-    final int numTerms = _TestUtil.nextInt(random, 10, 100); // terms should affect many docs
+    final int numTerms = TestUtil.nextInt(random, 10, 100); // terms should affect many docs
     Set<String> updateTerms = new HashSet<String>();
     while (updateTerms.size() < numTerms) {
-      updateTerms.add(_TestUtil.randomSimpleString(random));
+      updateTerms.add(TestUtil.randomSimpleString(random));
     }
 
 //    System.out.println("numDocs=" + numDocs + " numNumericFields=" + numNumericFields + " numTerms=" + numTerms);
@@ -1309,7 +1310,7 @@ public class TestNumericDocValuesUpdates extends LuceneTestCase {
     // build a large index with many NDV fields and update terms
     for (int i = 0; i < numDocs; i++) {
       Document doc = new Document();
-      int numUpdateTerms = _TestUtil.nextInt(random, 1, numTerms / 10);
+      int numUpdateTerms = TestUtil.nextInt(random, 1, numTerms / 10);
       for (int j = 0; j < numUpdateTerms; j++) {
         doc.add(new StringField("upd", RandomPicks.randomFrom(random, updateTerms), Store.NO));
       }
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestOmitNorms.java b/lucene/core/src/test/org/apache/lucene/index/TestOmitNorms.java
index c400fc5..5be0818 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestOmitNorms.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestOmitNorms.java
@@ -27,7 +27,7 @@ import org.apache.lucene.document.FieldType;
 import org.apache.lucene.document.TextField;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestOmitNorms extends LuceneTestCase {
   // Tests whether the DocumentWriter correctly enable the
@@ -281,7 +281,7 @@ public class TestOmitNorms extends LuceneTestCase {
     riw.addDocument(d);
     
     // add a mix of f1's and f2's
-    int numExtraDocs = _TestUtil.nextInt(random(), 1, 1000);
+    int numExtraDocs = TestUtil.nextInt(random(), 1, 1000);
     for (int i = 0; i < numExtraDocs; i++) {
       d = new Document();
       d.add(random().nextBoolean() ? f1 : f2);
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestOmitPositions.java b/lucene/core/src/test/org/apache/lucene/index/TestOmitPositions.java
index aeee6e6..004b351 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestOmitPositions.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestOmitPositions.java
@@ -28,7 +28,7 @@ import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * 
@@ -53,7 +53,7 @@ public class TestOmitPositions extends LuceneTestCase {
     
     assertNull(MultiFields.getTermPositionsEnum(reader, null, "foo", new BytesRef("test")));
     
-    DocsEnum de = _TestUtil.docs(random(), reader, "foo", new BytesRef("test"), null, null, DocsEnum.FLAG_FREQS);
+    DocsEnum de = TestUtil.docs(random(), reader, "foo", new BytesRef("test"), null, null, DocsEnum.FLAG_FREQS);
     while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
       assertEquals(2, de.freq());
     }
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestParallelAtomicReader.java b/lucene/core/src/test/org/apache/lucene/index/TestParallelAtomicReader.java
index c1ff0bc..835f36f 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestParallelAtomicReader.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestParallelAtomicReader.java
@@ -28,7 +28,7 @@ import org.apache.lucene.search.*;
 import org.apache.lucene.store.AlreadyClosedException;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestParallelAtomicReader extends LuceneTestCase {
 
@@ -287,7 +287,7 @@ public class TestParallelAtomicReader extends LuceneTestCase {
     ParallelAtomicReader pr = new ParallelAtomicReader(
         SlowCompositeReaderWrapper.wrap(DirectoryReader.open(dir1)),
         SlowCompositeReaderWrapper.wrap(DirectoryReader.open(dir2)));
-    _TestUtil.checkReader(pr);
+    TestUtil.checkReader(pr);
     return newSearcher(pr);
   }
 
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestParallelTermEnum.java b/lucene/core/src/test/org/apache/lucene/index/TestParallelTermEnum.java
index 9d47186d..4849643 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestParallelTermEnum.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestParallelTermEnum.java
@@ -28,7 +28,7 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestParallelTermEnum extends LuceneTestCase {
   private AtomicReader ir1;
@@ -82,7 +82,7 @@ public class TestParallelTermEnum extends LuceneTestCase {
       BytesRef b = te.next();
       assertNotNull(b);
       assertEquals(t, b.utf8ToString());
-      DocsEnum td = _TestUtil.docs(random(), te, liveDocs, null, DocsEnum.FLAG_NONE);
+      DocsEnum td = TestUtil.docs(random(), te, liveDocs, null, DocsEnum.FLAG_NONE);
       assertTrue(td.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
       assertEquals(0, td.docID());
       assertEquals(td.nextDoc(), DocIdSetIterator.NO_MORE_DOCS);
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestPayloads.java b/lucene/core/src/test/org/apache/lucene/index/TestPayloads.java
index db24d51..dda5ab3 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestPayloads.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestPayloads.java
@@ -18,7 +18,6 @@ package org.apache.lucene.index;
  */
 
 import java.io.IOException;
-import java.io.Reader;
 import java.io.StringReader;
 import java.nio.charset.Charset;
 import java.util.ArrayList;
@@ -38,7 +37,7 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestPayloads extends LuceneTestCase {
     
@@ -301,7 +300,7 @@ public class TestPayloads extends LuceneTestCase {
     static final Charset utf8 = Charset.forName("UTF-8");
     private void generateRandomData(byte[] data) {
       // this test needs the random data to be valid unicode
-      String s = _TestUtil.randomFixedByteLengthUnicodeString(random(), data.length);
+      String s = TestUtil.randomFixedByteLengthUnicodeString(random(), data.length);
       byte b[] = s.getBytes(utf8);
       assert b.length == data.length;
       System.arraycopy(b, 0, data, 0, b.length);
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestPerSegmentDeletes.java b/lucene/core/src/test/org/apache/lucene/index/TestPerSegmentDeletes.java
index 4ff5db3..c504542 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestPerSegmentDeletes.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestPerSegmentDeletes.java
@@ -24,7 +24,6 @@ import java.util.Map;
 import java.util.Random;
 
 import org.apache.lucene.analysis.MockAnalyzer;
-import org.apache.lucene.index.MergePolicy.MergeTrigger;
 import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.MockDirectoryWrapper;
@@ -33,7 +32,7 @@ import org.apache.lucene.util.ArrayUtil;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestPerSegmentDeletes extends LuceneTestCase {
   public void testDeletes1() throws Exception {
@@ -228,7 +227,7 @@ public class TestPerSegmentDeletes extends LuceneTestCase {
     Terms cterms = fields.terms(term.field);
     TermsEnum ctermsEnum = cterms.iterator(null);
     if (ctermsEnum.seekExact(new BytesRef(term.text()))) {
-      DocsEnum docsEnum = _TestUtil.docs(random(), ctermsEnum, bits, null, DocsEnum.FLAG_NONE);
+      DocsEnum docsEnum = TestUtil.docs(random(), ctermsEnum, bits, null, DocsEnum.FLAG_NONE);
       return toArray(docsEnum);
     }
     return null;
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets.java b/lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets.java
index b745625..c460af4 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets.java
@@ -44,7 +44,7 @@ import org.apache.lucene.util.English;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.LuceneTestCase.SuppressCodecs;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 // TODO: we really need to test indexingoffsets, but then getting only docs / docs + freqs.
 // not all codecs store prx separate...
@@ -183,7 +183,7 @@ public class TestPostingsOffsets extends LuceneTestCase {
     int numSkippingTests = atLeast(50);
     
     for (int j = 0; j < numSkippingTests; j++) {
-      int num = _TestUtil.nextInt(random(), 100, Math.min(numDocs-1, 999));
+      int num = TestUtil.nextInt(random(), 100, Math.min(numDocs - 1, 999));
       DocsAndPositionsEnum dp = MultiFields.getTermPositionsEnum(reader, null, "numbers", new BytesRef("hundred"));
       int doc = dp.advance(num);
       assertEquals(num, doc);
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestPrefixCodedTerms.java b/lucene/core/src/test/org/apache/lucene/index/TestPrefixCodedTerms.java
index 3f55f07..11d2c23 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestPrefixCodedTerms.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestPrefixCodedTerms.java
@@ -18,7 +18,6 @@ package org.apache.lucene.index;
  */
 
 import java.util.ArrayList;
-import java.util.Collections;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Set;
@@ -26,7 +25,7 @@ import java.util.TreeSet;
 
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.MergedIterator;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestPrefixCodedTerms extends LuceneTestCase {
   
@@ -50,7 +49,7 @@ public class TestPrefixCodedTerms extends LuceneTestCase {
     Set<Term> terms = new TreeSet<Term>();
     int nterms = atLeast(10000);
     for (int i = 0; i < nterms; i++) {
-      Term term = new Term(_TestUtil.randomUnicodeString(random(), 2), _TestUtil.randomUnicodeString(random()));
+      Term term = new Term(TestUtil.randomUnicodeString(random(), 2), TestUtil.randomUnicodeString(random()));
       terms.add(term);
     }    
     
@@ -89,14 +88,14 @@ public class TestPrefixCodedTerms extends LuceneTestCase {
 
   @SuppressWarnings({"unchecked","rawtypes"})
   public void testMergeRandom() {
-    PrefixCodedTerms pb[] = new PrefixCodedTerms[_TestUtil.nextInt(random(), 2, 10)];
+    PrefixCodedTerms pb[] = new PrefixCodedTerms[TestUtil.nextInt(random(), 2, 10)];
     Set<Term> superSet = new TreeSet<Term>();
     
     for (int i = 0; i < pb.length; i++) {
       Set<Term> terms = new TreeSet<Term>();
-      int nterms = _TestUtil.nextInt(random(), 0, 10000);
+      int nterms = TestUtil.nextInt(random(), 0, 10000);
       for (int j = 0; j < nterms; j++) {
-        Term term = new Term(_TestUtil.randomUnicodeString(random(), 2), _TestUtil.randomUnicodeString(random(), 4));
+        Term term = new Term(TestUtil.randomUnicodeString(random(), 2), TestUtil.randomUnicodeString(random(), 4));
         terms.add(term);
       }
       superSet.addAll(terms);
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestReaderClosed.java b/lucene/core/src/test/org/apache/lucene/index/TestReaderClosed.java
index 7e38d4b..b929b7c 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestReaderClosed.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestReaderClosed.java
@@ -26,7 +26,7 @@ import org.apache.lucene.search.TermRangeQuery;
 import org.apache.lucene.store.AlreadyClosedException;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestReaderClosed extends LuceneTestCase {
   private IndexReader reader;
@@ -38,7 +38,7 @@ public class TestReaderClosed extends LuceneTestCase {
     dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random(), dir, 
         newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.KEYWORD, false))
-        .setMaxBufferedDocs(_TestUtil.nextInt(random(), 50, 1000)));
+        .setMaxBufferedDocs(TestUtil.nextInt(random(), 50, 1000)));
     
     Document doc = new Document();
     Field field = newStringField("field", "", Field.Store.NO);
@@ -48,7 +48,7 @@ public class TestReaderClosed extends LuceneTestCase {
     // but for preflex codec, the test can be very slow, so use less iterations.
     int num = atLeast(10);
     for (int i = 0; i < num; i++) {
-      field.setStringValue(_TestUtil.randomUnicodeString(random(), 10));
+      field.setStringValue(TestUtil.randomUnicodeString(random(), 10));
       writer.addDocument(doc);
     }
     reader = writer.getReader();
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates.java b/lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates.java
index fb493f0..008dd85 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates.java
@@ -43,7 +43,7 @@ public class TestRollingUpdates extends LuceneTestCase {
 
     //provider.register(new MemoryCodec());
     if (random().nextBoolean()) {
-      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));
+      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));
     }
 
     final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));
@@ -160,7 +160,7 @@ public class TestRollingUpdates extends LuceneTestCase {
       final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(
           TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(2));
       final int numUpdates = atLeast(20);
-      int numThreads = _TestUtil.nextInt(random(), 2, 6);
+      int numThreads = TestUtil.nextInt(random(), 2, 6);
       IndexingThread[] threads = new IndexingThread[numThreads];
       for (int i = 0; i < numThreads; i++) {
         threads[i] = new IndexingThread(docs, w, numUpdates);
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestSegmentMerger.java b/lucene/core/src/test/org/apache/lucene/index/TestSegmentMerger.java
index 0f8391b..e7e4fcf 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestSegmentMerger.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestSegmentMerger.java
@@ -29,7 +29,8 @@ import org.apache.lucene.util.Constants;
 import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.InfoStream;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestSegmentMerger extends LuceneTestCase {
   //The variables for the new merged segment
@@ -102,12 +103,12 @@ public class TestSegmentMerger extends LuceneTestCase {
     assertTrue(newDoc2 != null);
     assertTrue(DocHelper.numFields(newDoc2) == DocHelper.numFields(doc2) - DocHelper.unstored.size());
 
-    DocsEnum termDocs = _TestUtil.docs(random(), mergedReader,
-                                       DocHelper.TEXT_FIELD_2_KEY,
-                                       new BytesRef("field"),
-                                       MultiFields.getLiveDocs(mergedReader),
-                                       null,
-                                       0);
+    DocsEnum termDocs = TestUtil.docs(random(), mergedReader,
+        DocHelper.TEXT_FIELD_2_KEY,
+        new BytesRef("field"),
+        MultiFields.getLiveDocs(mergedReader),
+        null,
+        0);
     assertTrue(termDocs != null);
     assertTrue(termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
 
@@ -153,8 +154,8 @@ public class TestSegmentMerger extends LuceneTestCase {
   }
 
   public void testBuildDocMap() {
-    final int maxDoc = _TestUtil.nextInt(random(), 1, 128);
-    final int numDocs = _TestUtil.nextInt(random(), 0, maxDoc);
+    final int maxDoc = TestUtil.nextInt(random(), 1, 128);
+    final int numDocs = TestUtil.nextInt(random(), 0, maxDoc);
     final int numDeletedDocs = maxDoc - numDocs;
     final FixedBitSet liveDocs = new FixedBitSet(maxDoc);
     for (int i = 0; i < numDocs; ++i) {
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestSegmentReader.java b/lucene/core/src/test/org/apache/lucene/index/TestSegmentReader.java
index 8039094..11e1ab1 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestSegmentReader.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestSegmentReader.java
@@ -28,8 +28,7 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IOContext;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
-import org.junit.Assume;
+import org.apache.lucene.util.TestUtil;
 
 public class TestSegmentReader extends LuceneTestCase {
   private Directory dir;
@@ -128,20 +127,20 @@ public class TestSegmentReader extends LuceneTestCase {
       }
     }
     
-    DocsEnum termDocs = _TestUtil.docs(random(), reader,
-                                       DocHelper.TEXT_FIELD_1_KEY,
-                                       new BytesRef("field"),
-                                       MultiFields.getLiveDocs(reader),
-                                       null,
-                                       0);
+    DocsEnum termDocs = TestUtil.docs(random(), reader,
+        DocHelper.TEXT_FIELD_1_KEY,
+        new BytesRef("field"),
+        MultiFields.getLiveDocs(reader),
+        null,
+        0);
     assertTrue(termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
 
-    termDocs = _TestUtil.docs(random(), reader,
-                              DocHelper.NO_NORMS_KEY,
-                              new BytesRef(DocHelper.NO_NORMS_TEXT),
-                              MultiFields.getLiveDocs(reader),
-                              null,
-                              0);
+    termDocs = TestUtil.docs(random(), reader,
+        DocHelper.NO_NORMS_KEY,
+        new BytesRef(DocHelper.NO_NORMS_TEXT),
+        MultiFields.getLiveDocs(reader),
+        null,
+        0);
 
     assertTrue(termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
 
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs.java b/lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs.java
index bbc8a22..0843d87 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs.java
@@ -26,7 +26,7 @@ import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestSegmentTermDocs extends LuceneTestCase {
   private Document testDoc = new Document();
@@ -58,7 +58,7 @@ public class TestSegmentTermDocs extends LuceneTestCase {
 
     TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator(null);
     terms.seekCeil(new BytesRef("field"));
-    DocsEnum termDocs = _TestUtil.docs(random(), terms, reader.getLiveDocs(), null, DocsEnum.FLAG_FREQS);
+    DocsEnum termDocs = TestUtil.docs(random(), terms, reader.getLiveDocs(), null, DocsEnum.FLAG_FREQS);
     if (termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)    {
       int docId = termDocs.docID();
       assertTrue(docId == 0);
@@ -73,12 +73,12 @@ public class TestSegmentTermDocs extends LuceneTestCase {
       //After adding the document, we should be able to read it back in
       SegmentReader reader = new SegmentReader(info, newIOContext(random()));
       assertTrue(reader != null);
-      DocsEnum termDocs = _TestUtil.docs(random(), reader,
-                                         "textField2",
-                                         new BytesRef("bad"),
-                                         reader.getLiveDocs(),
-                                         null,
-                                         0);
+      DocsEnum termDocs = TestUtil.docs(random(), reader,
+          "textField2",
+          new BytesRef("bad"),
+          reader.getLiveDocs(),
+          null,
+          0);
 
       assertNull(termDocs);
       reader.close();
@@ -87,12 +87,12 @@ public class TestSegmentTermDocs extends LuceneTestCase {
       //After adding the document, we should be able to read it back in
       SegmentReader reader = new SegmentReader(info, newIOContext(random()));
       assertTrue(reader != null);
-      DocsEnum termDocs = _TestUtil.docs(random(), reader,
-                                         "junk",
-                                         new BytesRef("bad"),
-                                         reader.getLiveDocs(),
-                                         null,
-                                         0);
+      DocsEnum termDocs = TestUtil.docs(random(), reader,
+          "junk",
+          new BytesRef("bad"),
+          reader.getLiveDocs(),
+          null,
+          0);
       assertNull(termDocs);
       reader.close();
     }
@@ -120,12 +120,12 @@ public class TestSegmentTermDocs extends LuceneTestCase {
     
     IndexReader reader = DirectoryReader.open(dir);
 
-    DocsEnum tdocs = _TestUtil.docs(random(), reader,
-                                    ta.field(),
-                                    new BytesRef(ta.text()),
-                                    MultiFields.getLiveDocs(reader),
-                                    null,
-                                    DocsEnum.FLAG_FREQS);
+    DocsEnum tdocs = TestUtil.docs(random(), reader,
+        ta.field(),
+        new BytesRef(ta.text()),
+        MultiFields.getLiveDocs(reader),
+        null,
+        DocsEnum.FLAG_FREQS);
     
     // without optimization (assumption skipInterval == 16)
     
@@ -145,12 +145,12 @@ public class TestSegmentTermDocs extends LuceneTestCase {
     assertFalse(tdocs.advance(10) != DocIdSetIterator.NO_MORE_DOCS);
     
     // without next
-    tdocs = _TestUtil.docs(random(), reader,
-                           ta.field(),
-                           new BytesRef(ta.text()),
-                           MultiFields.getLiveDocs(reader),
-                           null,
-                           0);
+    tdocs = TestUtil.docs(random(), reader,
+        ta.field(),
+        new BytesRef(ta.text()),
+        MultiFields.getLiveDocs(reader),
+        null,
+        0);
     
     assertTrue(tdocs.advance(0) != DocIdSetIterator.NO_MORE_DOCS);
     assertEquals(0, tdocs.docID());
@@ -163,12 +163,12 @@ public class TestSegmentTermDocs extends LuceneTestCase {
     // exactly skipInterval documents and therefore with optimization
     
     // with next
-    tdocs = _TestUtil.docs(random(), reader,
-                           tb.field(),
-                           new BytesRef(tb.text()),
-                           MultiFields.getLiveDocs(reader),
-                           null,
-                           DocsEnum.FLAG_FREQS);
+    tdocs = TestUtil.docs(random(), reader,
+        tb.field(),
+        new BytesRef(tb.text()),
+        MultiFields.getLiveDocs(reader),
+        null,
+        DocsEnum.FLAG_FREQS);
 
     assertTrue(tdocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
     assertEquals(10, tdocs.docID());
@@ -187,12 +187,12 @@ public class TestSegmentTermDocs extends LuceneTestCase {
     assertFalse(tdocs.advance(26) != DocIdSetIterator.NO_MORE_DOCS);
     
     // without next
-    tdocs = _TestUtil.docs(random(), reader,
-                           tb.field(),
-                           new BytesRef(tb.text()),
-                           MultiFields.getLiveDocs(reader),
-                           null,
-                           DocsEnum.FLAG_FREQS);
+    tdocs = TestUtil.docs(random(), reader,
+        tb.field(),
+        new BytesRef(tb.text()),
+        MultiFields.getLiveDocs(reader),
+        null,
+        DocsEnum.FLAG_FREQS);
     
     assertTrue(tdocs.advance(5) != DocIdSetIterator.NO_MORE_DOCS);
     assertEquals(10, tdocs.docID());
@@ -207,12 +207,12 @@ public class TestSegmentTermDocs extends LuceneTestCase {
     // much more than skipInterval documents and therefore with optimization
     
     // with next
-    tdocs = _TestUtil.docs(random(), reader,
-                           tc.field(),
-                           new BytesRef(tc.text()),
-                           MultiFields.getLiveDocs(reader),
-                           null,
-                           DocsEnum.FLAG_FREQS);
+    tdocs = TestUtil.docs(random(), reader,
+        tc.field(),
+        new BytesRef(tc.text()),
+        MultiFields.getLiveDocs(reader),
+        null,
+        DocsEnum.FLAG_FREQS);
 
     assertTrue(tdocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
     assertEquals(26, tdocs.docID());
@@ -233,12 +233,12 @@ public class TestSegmentTermDocs extends LuceneTestCase {
     assertFalse(tdocs.advance(76) != DocIdSetIterator.NO_MORE_DOCS);
     
     //without next
-    tdocs = _TestUtil.docs(random(), reader,
-                           tc.field(),
-                           new BytesRef(tc.text()),
-                           MultiFields.getLiveDocs(reader),
-                           null,
-                           0);
+    tdocs = TestUtil.docs(random(), reader,
+        tc.field(),
+        new BytesRef(tc.text()),
+        MultiFields.getLiveDocs(reader),
+        null,
+        0);
     assertTrue(tdocs.advance(5) != DocIdSetIterator.NO_MORE_DOCS);
     assertEquals(26, tdocs.docID());
     assertTrue(tdocs.advance(40) != DocIdSetIterator.NO_MORE_DOCS);
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestSegmentTermEnum.java b/lucene/core/src/test/org/apache/lucene/index/TestSegmentTermEnum.java
index 1379a3c..b2796ea 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestSegmentTermEnum.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestSegmentTermEnum.java
@@ -22,7 +22,7 @@ import java.io.IOException;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.codecs.lucene41.Lucene41PostingsFormat;
 import org.apache.lucene.document.Document;
@@ -75,7 +75,7 @@ public class TestSegmentTermEnum extends LuceneTestCase {
 
   public void testPrevTermAtEnd() throws IOException
   {
-    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(_TestUtil.alwaysPostingsFormat(new Lucene41PostingsFormat())));
+    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(TestUtil.alwaysPostingsFormat(new Lucene41PostingsFormat())));
     addDoc(writer, "aaa bbb");
     writer.close();
     SegmentReader reader = getOnlySegmentReader(DirectoryReader.open(dir));
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestStressAdvance.java b/lucene/core/src/test/org/apache/lucene/index/TestStressAdvance.java
index 3a13352..c24b171 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestStressAdvance.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestStressAdvance.java
@@ -82,11 +82,11 @@ public class TestStressAdvance extends LuceneTestCase {
           System.out.println("\nTEST: iter=" + iter + " iter2=" + iter2);
         }
         assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef("a")));
-        de = _TestUtil.docs(random(), te, null, de, DocsEnum.FLAG_NONE);
+        de = TestUtil.docs(random(), te, null, de, DocsEnum.FLAG_NONE);
         testOne(de, aDocIDs);
 
         assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef("b")));
-        de = _TestUtil.docs(random(), te, null, de, DocsEnum.FLAG_NONE);
+        de = TestUtil.docs(random(), te, null, de, DocsEnum.FLAG_NONE);
         testOne(de, bDocIDs);
       }
 
@@ -115,7 +115,7 @@ public class TestStressAdvance extends LuceneTestCase {
         docID = docs.nextDoc();
       } else {
         // test advance()
-        final int inc = _TestUtil.nextInt(random(), 1, expected.size()-1-upto);
+        final int inc = TestUtil.nextInt(random(), 1, expected.size() - 1 - upto);
         if (VERBOSE) {
           System.out.println("    do advance inc=" + inc);
         }
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestStressIndexing2.java b/lucene/core/src/test/org/apache/lucene/index/TestStressIndexing2.java
index 9ce0b06..9c154cb 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestStressIndexing2.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestStressIndexing2.java
@@ -187,7 +187,7 @@ public class TestStressIndexing2 extends LuceneTestCase {
       }
     }
 
-    _TestUtil.checkIndex(dir);
+    TestUtil.checkIndex(dir);
     DocsAndWriter dw = new DocsAndWriter();
     dw.docs = docs;
     dw.writer = w;
@@ -233,7 +233,7 @@ public class TestStressIndexing2 extends LuceneTestCase {
     }
 
     //System.out.println("TEST: checkindex");
-    _TestUtil.checkIndex(dir);
+    TestUtil.checkIndex(dir);
 
     return docs;
   }
@@ -333,7 +333,7 @@ public class TestStressIndexing2 extends LuceneTestCase {
       Bits liveDocs = MultiFields.getLiveDocs(r1);
       DocsEnum docs = null;
       while(termsEnum.next() != null) {
-        docs = _TestUtil.docs(random(), termsEnum, liveDocs, docs, DocsEnum.FLAG_NONE);
+        docs = TestUtil.docs(random(), termsEnum, liveDocs, docs, DocsEnum.FLAG_NONE);
         while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
           fail("r1 is not empty but r2 is");
         }
@@ -353,9 +353,9 @@ public class TestStressIndexing2 extends LuceneTestCase {
         break;
       }
 
-      termDocs1 = _TestUtil.docs(random(), termsEnum, liveDocs1, termDocs1, DocsEnum.FLAG_NONE);
+      termDocs1 = TestUtil.docs(random(), termsEnum, liveDocs1, termDocs1, DocsEnum.FLAG_NONE);
       if (termsEnum2.seekExact(term)) {
-        termDocs2 = _TestUtil.docs(random(), termsEnum2, liveDocs2, termDocs2, DocsEnum.FLAG_NONE);
+        termDocs2 = TestUtil.docs(random(), termsEnum2, liveDocs2, termDocs2, DocsEnum.FLAG_NONE);
       } else {
         termDocs2 = null;
       }
@@ -412,7 +412,7 @@ public class TestStressIndexing2 extends LuceneTestCase {
                   System.out.println("          pos=" + dpEnum.nextPosition());
                 }
               } else {
-                dEnum = _TestUtil.docs(random(), termsEnum3, null, dEnum, DocsEnum.FLAG_FREQS);
+                dEnum = TestUtil.docs(random(), termsEnum3, null, dEnum, DocsEnum.FLAG_FREQS);
                 assertNotNull(dEnum);
                 assertTrue(dEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
                 final int freq = dEnum.freq();
@@ -444,7 +444,7 @@ public class TestStressIndexing2 extends LuceneTestCase {
                   System.out.println("          pos=" + dpEnum.nextPosition());
                 }
               } else {
-                dEnum = _TestUtil.docs(random(), termsEnum3, null, dEnum, DocsEnum.FLAG_FREQS);
+                dEnum = TestUtil.docs(random(), termsEnum3, null, dEnum, DocsEnum.FLAG_FREQS);
                 assertNotNull(dEnum);
                 assertTrue(dEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
                 final int freq = dEnum.freq();
@@ -503,7 +503,7 @@ public class TestStressIndexing2 extends LuceneTestCase {
         }
         
         //System.out.println("TEST: term1=" + term1);
-        docs1 = _TestUtil.docs(random(), termsEnum1, liveDocs1, docs1, DocsEnum.FLAG_FREQS);
+        docs1 = TestUtil.docs(random(), termsEnum1, liveDocs1, docs1, DocsEnum.FLAG_FREQS);
         while (docs1.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
           int d = docs1.docID();
           int f = docs1.freq();
@@ -536,7 +536,7 @@ public class TestStressIndexing2 extends LuceneTestCase {
         }
         
         //System.out.println("TEST: term1=" + term1);
-        docs2 = _TestUtil.docs(random(), termsEnum2, liveDocs2, docs2, DocsEnum.FLAG_FREQS);
+        docs2 = TestUtil.docs(random(), termsEnum2, liveDocs2, docs2, DocsEnum.FLAG_FREQS);
         while (docs2.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
           int d = r2r1[docs2.docID()];
           int f = docs2.freq();
@@ -662,8 +662,8 @@ public class TestStressIndexing2 extends LuceneTestCase {
           assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum1.nextDoc());
           assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum2.nextDoc());
         } else {
-          dEnum1 = _TestUtil.docs(random(), termsEnum1, null, dEnum1, DocsEnum.FLAG_FREQS);
-          dEnum2 = _TestUtil.docs(random(), termsEnum2, null, dEnum2, DocsEnum.FLAG_FREQS);
+          dEnum1 = TestUtil.docs(random(), termsEnum1, null, dEnum1, DocsEnum.FLAG_FREQS);
+          dEnum2 = TestUtil.docs(random(), termsEnum2, null, dEnum2, DocsEnum.FLAG_FREQS);
           assertNotNull(dEnum1);
           assertNotNull(dEnum2);
           int docID1 = dEnum1.nextDoc();
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestStressNRT.java b/lucene/core/src/test/org/apache/lucene/index/TestStressNRT.java
index 1af5a43..fa3b909 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestStressNRT.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestStressNRT.java
@@ -37,7 +37,7 @@ import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.search.TopDocs;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestStressNRT extends LuceneTestCase {
   volatile DirectoryReader reader;
@@ -71,15 +71,15 @@ public class TestStressNRT extends LuceneTestCase {
     final int deletePercent = random().nextInt(50);
     final int deleteByQueryPercent = random().nextInt(25);
     final int ndocs = atLeast(50);
-    final int nWriteThreads = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);
-    final int maxConcurrentCommits = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max
+    final int nWriteThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);
+    final int maxConcurrentCommits = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max
     
     final boolean tombstones = random().nextBoolean();
 
     // query variables
     final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total
 
-    final int nReadThreads = _TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);
+    final int nReadThreads = TestUtil.nextInt(random(), 1, TEST_NIGHTLY ? 10 : 5);
     initModel(ndocs);
 
     final FieldType storedOnlyType = new FieldType();
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestSumDocFreq.java b/lucene/core/src/test/org/apache/lucene/index/TestSumDocFreq.java
index 119e4ff..223fa70 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestSumDocFreq.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestSumDocFreq.java
@@ -21,7 +21,7 @@ import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Tests {@link Terms#getSumDocFreq()}
@@ -44,11 +44,11 @@ public class TestSumDocFreq extends LuceneTestCase {
     doc.add(field2);
     for (int i = 0; i < numDocs; i++) {
       id.setStringValue("" + i);
-      char ch1 = (char) _TestUtil.nextInt(random(), 'a', 'z');
-      char ch2 = (char) _TestUtil.nextInt(random(), 'a', 'z');
+      char ch1 = (char) TestUtil.nextInt(random(), 'a', 'z');
+      char ch2 = (char) TestUtil.nextInt(random(), 'a', 'z');
       field1.setStringValue("" + ch1 + " " + ch2);
-      ch1 = (char) _TestUtil.nextInt(random(), 'a', 'z');
-      ch2 = (char) _TestUtil.nextInt(random(), 'a', 'z');
+      ch1 = (char) TestUtil.nextInt(random(), 'a', 'z');
+      ch2 = (char) TestUtil.nextInt(random(), 'a', 'z');
       field2.setStringValue("" + ch1 + " " + ch2);
       writer.addDocument(doc);
     }
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java b/lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java
index 6a281d3..6aa4512 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java
@@ -18,7 +18,6 @@ package org.apache.lucene.index;
  */
 
 import java.io.IOException;
-import java.io.Reader;
 import java.util.Arrays;
 
 import org.apache.lucene.analysis.*;
@@ -35,7 +34,7 @@ import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestTermVectorsReader extends LuceneTestCase {
   //Must be lexicographically sorted, will do in setup, versus trying to maintain here
@@ -226,7 +225,7 @@ public class TestTermVectorsReader extends LuceneTestCase {
         //System.out.println("Term: " + term);
         assertEquals(testTerms[i], term);
         
-        docsEnum = _TestUtil.docs(random(), termsEnum, null, docsEnum, DocsEnum.FLAG_NONE);
+        docsEnum = TestUtil.docs(random(), termsEnum, null, docsEnum, DocsEnum.FLAG_NONE);
         assertNotNull(docsEnum);
         int doc = docsEnum.docID();
         assertEquals(-1, doc);
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestTermdocPerf.java b/lucene/core/src/test/org/apache/lucene/index/TestTermdocPerf.java
index 7b180c8..48245af 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestTermdocPerf.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestTermdocPerf.java
@@ -18,7 +18,6 @@ package org.apache.lucene.index;
 
 
 import java.io.IOException;
-import java.io.Reader;
 import java.util.Random;
 
 import org.apache.lucene.analysis.Analyzer;
@@ -31,7 +30,7 @@ import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 class RepeatingTokenizer extends Tokenizer {
   
@@ -124,7 +123,7 @@ public class TestTermdocPerf extends LuceneTestCase {
     final Random random = new Random(random().nextLong());
     for (int i=0; i<iter; i++) {
       tenum.seekCeil(new BytesRef("val"));
-      tdocs = _TestUtil.docs(random, tenum, MultiFields.getLiveDocs(reader), tdocs, DocsEnum.FLAG_NONE);
+      tdocs = TestUtil.docs(random, tenum, MultiFields.getLiveDocs(reader), tdocs, DocsEnum.FLAG_NONE);
       while (tdocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
         ret += tdocs.docID();
       }
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestTermsEnum.java b/lucene/core/src/test/org/apache/lucene/index/TestTermsEnum.java
index d3843fe..011bb8a 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestTermsEnum.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestTermsEnum.java
@@ -31,7 +31,7 @@ import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LineFileDocs;
 import org.apache.lucene.util.LuceneTestCase.SuppressCodecs;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.automaton.Automaton;
 import org.apache.lucene.util.automaton.BasicAutomata;
 import org.apache.lucene.util.automaton.CompiledAutomaton;
@@ -93,9 +93,9 @@ public class TestTermsEnum extends LuceneTestCase {
         if (random().nextBoolean()) {
           // likely fake term
           if (random().nextBoolean()) {
-            target = new BytesRef(_TestUtil.randomSimpleString(random()));
+            target = new BytesRef(TestUtil.randomSimpleString(random()));
           } else {
-            target = new BytesRef(_TestUtil.randomRealisticUnicodeString(random()));
+            target = new BytesRef(TestUtil.randomRealisticUnicodeString(random()));
           }
           exists = "likely not";
         } else {
@@ -332,7 +332,7 @@ public class TestTermsEnum extends LuceneTestCase {
           }
           assertEquals(expected, actual);
           assertEquals(1, te.docFreq());
-          docsEnum = _TestUtil.docs(random(), te, null, docsEnum, DocsEnum.FLAG_NONE);
+          docsEnum = TestUtil.docs(random(), te, null, docsEnum, DocsEnum.FLAG_NONE);
           final int docID = docsEnum.nextDoc();
           assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);
           assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());
@@ -524,11 +524,11 @@ public class TestTermsEnum extends LuceneTestCase {
 
   private String getRandomString() {
     //return _TestUtil.randomSimpleString(random());
-    return _TestUtil.randomRealisticUnicodeString(random());
+    return TestUtil.randomRealisticUnicodeString(random());
   }
 
   public void testRandomTerms() throws Exception {
-    final String[] terms = new String[_TestUtil.nextInt(random(), 1, atLeast(1000))];
+    final String[] terms = new String[TestUtil.nextInt(random(), 1, atLeast(1000))];
     final Set<String> seen = new HashSet<String>();
 
     final boolean allowEmptyString = random().nextBoolean();
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestTermsEnum2.java b/lucene/core/src/test/org/apache/lucene/index/TestTermsEnum2.java
index 813771a..fb1356e 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestTermsEnum2.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestTermsEnum2.java
@@ -34,7 +34,8 @@ import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.automaton.*;
 
 public class TestTermsEnum2 extends LuceneTestCase {
@@ -53,7 +54,7 @@ public class TestTermsEnum2 extends LuceneTestCase {
     RandomIndexWriter writer = new RandomIndexWriter(random(), dir,
         newIndexWriterConfig(TEST_VERSION_CURRENT,
             new MockAnalyzer(random(), MockTokenizer.KEYWORD, false))
-            .setMaxBufferedDocs(_TestUtil.nextInt(random(), 50, 1000)));
+            .setMaxBufferedDocs(TestUtil.nextInt(random(), 50, 1000)));
     Document doc = new Document();
     Field field = newStringField("field", "", Field.Store.YES);
     doc.add(field);
@@ -61,7 +62,7 @@ public class TestTermsEnum2 extends LuceneTestCase {
  
     int num = atLeast(200);
     for (int i = 0; i < num; i++) {
-      String s = _TestUtil.randomUnicodeString(random());
+      String s = TestUtil.randomUnicodeString(random());
       field.setStringValue(s);
       terms.add(new BytesRef(s));
       writer.addDocument(doc);
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestTieredMergePolicy.java b/lucene/core/src/test/org/apache/lucene/index/TestTieredMergePolicy.java
index 4f1e7ae..155e8fe 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestTieredMergePolicy.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestTieredMergePolicy.java
@@ -22,7 +22,8 @@ import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestTieredMergePolicy extends LuceneTestCase {
 
@@ -81,7 +82,7 @@ public class TestTieredMergePolicy extends LuceneTestCase {
 
       IndexWriter w = new IndexWriter(dir, conf);
       int maxCount = 0;
-      final int numDocs = _TestUtil.nextInt(random(), 20, 100);
+      final int numDocs = TestUtil.nextInt(random(), 20, 100);
       for(int i=0;i<numDocs;i++) {
         Document doc = new Document();
         doc.add(newTextField("content", "aaa " + (i%4), Field.Store.NO));
@@ -94,7 +95,7 @@ public class TestTieredMergePolicy extends LuceneTestCase {
       w.flush(true, true);
 
       int segmentCount = w.getSegmentCount();
-      int targetCount = _TestUtil.nextInt(random(), 1, segmentCount);
+      int targetCount = TestUtil.nextInt(random(), 1, segmentCount);
       if (VERBOSE) {
         System.out.println("TEST: merge to " + targetCount + " segs (current count=" + segmentCount + ")");
       }
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestUniqueTermCount.java b/lucene/core/src/test/org/apache/lucene/index/TestUniqueTermCount.java
index 3afa9a2..5d87e9f 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestUniqueTermCount.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestUniqueTermCount.java
@@ -30,7 +30,7 @@ import org.apache.lucene.search.TermStatistics;
 import org.apache.lucene.search.similarities.Similarity;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Tests the uniqueTermCount statistic in FieldInvertState
@@ -83,10 +83,10 @@ public class TestUniqueTermCount extends LuceneTestCase {
   private String addValue() {
     StringBuilder sb = new StringBuilder();
     HashSet<String> terms = new HashSet<String>();
-    int num = _TestUtil.nextInt(random(), 0, 255);
+    int num = TestUtil.nextInt(random(), 0, 255);
     for (int i = 0; i < num; i++) {
       sb.append(' ');
-      char term = (char) _TestUtil.nextInt(random(), 'a', 'z');
+      char term = (char) TestUtil.nextInt(random(), 'a', 'z');
       sb.append(term);
       terms.add("" + term);
     }
diff --git a/lucene/core/src/test/org/apache/lucene/search/BaseTestRangeFilter.java b/lucene/core/src/test/org/apache/lucene/search/BaseTestRangeFilter.java
index 861e541..846b943 100644
--- a/lucene/core/src/test/org/apache/lucene/search/BaseTestRangeFilter.java
+++ b/lucene/core/src/test/org/apache/lucene/search/BaseTestRangeFilter.java
@@ -33,7 +33,7 @@ import org.apache.lucene.index.IndexWriterConfig.OpenMode;
 import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.AfterClass;
 import org.junit.BeforeClass;
 import org.junit.Test;
@@ -136,8 +136,8 @@ public class BaseTestRangeFilter extends LuceneTestCase {
 
     RandomIndexWriter writer = new RandomIndexWriter(random, index.index, 
                                                      newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(random))
-                                                     .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)).setMergePolicy(newLogMergePolicy()));
-    _TestUtil.reduceOpenFiles(writer.w);
+                                                     .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(TestUtil.nextInt(random, 50, 1000)).setMergePolicy(newLogMergePolicy()));
+    TestUtil.reduceOpenFiles(writer.w);
 
     while(true) {
 
diff --git a/lucene/core/src/test/org/apache/lucene/search/FuzzyTermOnShortTermsTest.java b/lucene/core/src/test/org/apache/lucene/search/FuzzyTermOnShortTermsTest.java
index 8c0684a..02f45e9 100644
--- a/lucene/core/src/test/org/apache/lucene/search/FuzzyTermOnShortTermsTest.java
+++ b/lucene/core/src/test/org/apache/lucene/search/FuzzyTermOnShortTermsTest.java
@@ -18,7 +18,6 @@ package org.apache.lucene.search;
 
 
 import java.io.IOException;
-import java.io.Reader;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.MockTokenizer;
@@ -31,7 +30,7 @@ import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.Test;
 
 
@@ -85,7 +84,7 @@ public class FuzzyTermOnShortTermsTest extends LuceneTestCase {
       Directory directory = newDirectory();
       RandomIndexWriter writer = new RandomIndexWriter(random(), directory,
           newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer)
-          .setMaxBufferedDocs(_TestUtil.nextInt(random(), 100, 1000)).setMergePolicy(newLogMergePolicy()));
+          .setMaxBufferedDocs(TestUtil.nextInt(random(), 100, 1000)).setMergePolicy(newLogMergePolicy()));
 
       for (String s : vals){
          Document d = new Document();
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestBoolean2.java b/lucene/core/src/test/org/apache/lucene/search/TestBoolean2.java
index 859bbeb..531db4e 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestBoolean2.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestBoolean2.java
@@ -34,7 +34,8 @@ import org.apache.lucene.store.IOContext;
 import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.store.RAMDirectory;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.AfterClass;
 import org.junit.BeforeClass;
 import org.junit.Test;
@@ -92,7 +93,7 @@ public class TestBoolean2 extends LuceneTestCase {
 
     RandomIndexWriter w = new RandomIndexWriter(random(), dir2, 
         newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))
-        .setMaxBufferedDocs(_TestUtil.nextInt(random(), 50, 1000)));
+        .setMaxBufferedDocs(TestUtil.nextInt(random(), 50, 1000)));
     Document doc = new Document();
     doc.add(newTextField("field2", "xxx", Field.Store.NO));
     for(int i=0;i<NUM_EXTRA_DOCS/2;i++) {
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestBooleanOr.java b/lucene/core/src/test/org/apache/lucene/search/TestBooleanOr.java
index a25121b..a9fe1da 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestBooleanOr.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestBooleanOr.java
@@ -24,12 +24,11 @@ import org.apache.lucene.document.TextField;
 import org.apache.lucene.index.AtomicReaderContext;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.SerialMergeScheduler;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestBooleanOr extends LuceneTestCase {
 
@@ -210,7 +209,7 @@ public class TestBooleanOr extends LuceneTestCase {
       };
 
     while (end.intValue() < docCount) {
-      final int inc = _TestUtil.nextInt(random(), 1, 1000);
+      final int inc = TestUtil.nextInt(random(), 1, 1000);
       end.getAndAdd(inc);
       scorer.score(c, end.intValue(), -1);
     }
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestBooleanQuery.java b/lucene/core/src/test/org/apache/lucene/search/TestBooleanQuery.java
index 342d1cb..faa779a 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestBooleanQuery.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestBooleanQuery.java
@@ -42,7 +42,8 @@ import org.apache.lucene.search.spans.SpanTermQuery;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.NamedThreadFactory;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestBooleanQuery extends LuceneTestCase {
   
@@ -217,7 +218,7 @@ public class TestBooleanQuery extends LuceneTestCase {
         System.out.println("iter=" + iter);
       }
       final List<String> terms = new ArrayList<String>(Arrays.asList("a", "b", "c", "d", "e", "f"));
-      final int numTerms = _TestUtil.nextInt(random(), 1, terms.size());
+      final int numTerms = TestUtil.nextInt(random(), 1, terms.size());
       while(terms.size() > numTerms) {
         terms.remove(random().nextInt(terms.size()));
       }
@@ -269,7 +270,7 @@ public class TestBooleanQuery extends LuceneTestCase {
             nextDoc = scorer.nextDoc();
           } else {
             // advance
-            int inc = _TestUtil.nextInt(random(), 1, left-1);
+            int inc = TestUtil.nextInt(random(), 1, left - 1);
             nextUpto = inc + upto;
             nextDoc = scorer.advance(hits.get(nextUpto).doc);
           }
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter.java b/lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter.java
index e60808b..f644a42 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter.java
@@ -35,7 +35,7 @@ import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestCachingWrapperFilter extends LuceneTestCase {
   Directory dir;
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestDocTermOrdsRangeFilter.java b/lucene/core/src/test/org/apache/lucene/search/TestDocTermOrdsRangeFilter.java
index 89d2b70..fc11cb0 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestDocTermOrdsRangeFilter.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestDocTermOrdsRangeFilter.java
@@ -33,8 +33,8 @@ import org.apache.lucene.index.Term;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.UnicodeUtil;
-import org.apache.lucene.util._TestUtil;
 
 /**
  * Tests the DocTermOrdsRangeFilter
@@ -53,7 +53,7 @@ public class TestDocTermOrdsRangeFilter extends LuceneTestCase {
     fieldName = random().nextBoolean() ? "field" : ""; // sometimes use an empty string as field name
     RandomIndexWriter writer = new RandomIndexWriter(random(), dir, 
         newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.KEYWORD, false))
-        .setMaxBufferedDocs(_TestUtil.nextInt(random(), 50, 1000)));
+        .setMaxBufferedDocs(TestUtil.nextInt(random(), 50, 1000)));
     List<String> terms = new ArrayList<String>();
     int num = atLeast(200);
     for (int i = 0; i < num; i++) {
@@ -61,7 +61,7 @@ public class TestDocTermOrdsRangeFilter extends LuceneTestCase {
       doc.add(newStringField("id", Integer.toString(i), Field.Store.NO));
       int numTerms = random().nextInt(4);
       for (int j = 0; j < numTerms; j++) {
-        String s = _TestUtil.randomUnicodeString(random());
+        String s = TestUtil.randomUnicodeString(random());
         doc.add(newStringField(fieldName, s, Field.Store.NO));
         // if the default codec doesn't support sortedset, we will uninvert at search time
         if (defaultCodecSupportsSortedSet()) {
@@ -103,8 +103,8 @@ public class TestDocTermOrdsRangeFilter extends LuceneTestCase {
   public void testRanges() throws Exception {
     int num = atLeast(1000);
     for (int i = 0; i < num; i++) {
-      BytesRef lowerVal = new BytesRef(_TestUtil.randomUnicodeString(random()));
-      BytesRef upperVal = new BytesRef(_TestUtil.randomUnicodeString(random()));
+      BytesRef lowerVal = new BytesRef(TestUtil.randomUnicodeString(random()));
+      BytesRef upperVal = new BytesRef(TestUtil.randomUnicodeString(random()));
       if (upperVal.compareTo(lowerVal) < 0) {
         assertSame(upperVal, lowerVal, random().nextBoolean(), random().nextBoolean());
       } else {
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestDocTermOrdsRewriteMethod.java b/lucene/core/src/test/org/apache/lucene/search/TestDocTermOrdsRewriteMethod.java
index c1557be..64c5382 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestDocTermOrdsRewriteMethod.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestDocTermOrdsRewriteMethod.java
@@ -33,10 +33,10 @@ import org.apache.lucene.index.Term;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.automaton.AutomatonTestUtil;
 import org.apache.lucene.util.automaton.RegExp;
 import org.apache.lucene.util.UnicodeUtil;
-import org.apache.lucene.util._TestUtil;
 
 /**
  * Tests the DocTermOrdsRewriteMethod
@@ -55,7 +55,7 @@ public class TestDocTermOrdsRewriteMethod extends LuceneTestCase {
     fieldName = random().nextBoolean() ? "field" : ""; // sometimes use an empty string as field name
     RandomIndexWriter writer = new RandomIndexWriter(random(), dir, 
         newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.KEYWORD, false))
-        .setMaxBufferedDocs(_TestUtil.nextInt(random(), 50, 1000)));
+        .setMaxBufferedDocs(TestUtil.nextInt(random(), 50, 1000)));
     List<String> terms = new ArrayList<String>();
     int num = atLeast(200);
     for (int i = 0; i < num; i++) {
@@ -63,7 +63,7 @@ public class TestDocTermOrdsRewriteMethod extends LuceneTestCase {
       doc.add(newStringField("id", Integer.toString(i), Field.Store.NO));
       int numTerms = random().nextInt(4);
       for (int j = 0; j < numTerms; j++) {
-        String s = _TestUtil.randomUnicodeString(random());
+        String s = TestUtil.randomUnicodeString(random());
         doc.add(newStringField(fieldName, s, Field.Store.NO));
         // if the default codec doesn't support sortedset, we will uninvert at search time
         if (defaultCodecSupportsSortedSet()) {
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestFieldCache.java b/lucene/core/src/test/org/apache/lucene/search/TestFieldCache.java
index 2c4d345..8c2148a 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestFieldCache.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestFieldCache.java
@@ -62,7 +62,7 @@ import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.NumericUtils;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.AfterClass;
 import org.junit.BeforeClass;
 
@@ -321,10 +321,10 @@ public class TestFieldCache extends LuceneTestCase {
         s = unicodeStrings[random().nextInt(i)];
       }
       if (s == null) {
-        s = _TestUtil.randomUnicodeString(random());
+        s = TestUtil.randomUnicodeString(random());
       }
     } else {
-      s = _TestUtil.randomUnicodeString(random());
+      s = TestUtil.randomUnicodeString(random());
     }
     return s;
   }
@@ -694,7 +694,7 @@ public class TestFieldCache extends LuceneTestCase {
     Document doc = new Document();
     LongField field = new LongField("f", 0L, Store.YES);
     doc.add(field);
-    final long[] values = new long[_TestUtil.nextInt(random(), 1, 10)];
+    final long[] values = new long[TestUtil.nextInt(random(), 1, 10)];
     for (int i = 0; i < values.length; ++i) {
       final long v;
       switch (random().nextInt(10)) {
@@ -708,7 +708,7 @@ public class TestFieldCache extends LuceneTestCase {
           v = Long.MAX_VALUE;
           break;
         default:
-          v = _TestUtil.nextLong(random(), -10, 10);
+          v = TestUtil.nextLong(random(), -10, 10);
           break;
       }
       values[i] = v;
@@ -740,7 +740,7 @@ public class TestFieldCache extends LuceneTestCase {
     Document doc = new Document();
     IntField field = new IntField("f", 0, Store.YES);
     doc.add(field);
-    final int[] values = new int[_TestUtil.nextInt(random(), 1, 10)];
+    final int[] values = new int[TestUtil.nextInt(random(), 1, 10)];
     for (int i = 0; i < values.length; ++i) {
       final int v;
       switch (random().nextInt(10)) {
@@ -754,7 +754,7 @@ public class TestFieldCache extends LuceneTestCase {
           v = Integer.MAX_VALUE;
           break;
         default:
-          v = _TestUtil.nextInt(random(), -10, 10);
+          v = TestUtil.nextInt(random(), -10, 10);
           break;
       }
       values[i] = v;
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestFilteredQuery.java b/lucene/core/src/test/org/apache/lucene/search/TestFilteredQuery.java
index 0889052..d1ec6f5 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestFilteredQuery.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestFilteredQuery.java
@@ -37,7 +37,7 @@ import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.DocIdBitSet;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * FilteredQuery JUnit tests.
@@ -392,7 +392,7 @@ public class TestFilteredQuery extends LuceneTestCase {
         }
       };
     }
-    return _TestUtil.randomFilterStrategy(random);
+    return TestUtil.randomFilterStrategy(random);
   }
   
   /*
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestIndexSearcher.java b/lucene/core/src/test/org/apache/lucene/search/TestIndexSearcher.java
index 5c24a46..a16e545 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestIndexSearcher.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestIndexSearcher.java
@@ -32,7 +32,7 @@ import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.NamedThreadFactory;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.Test;
 
 public class TestIndexSearcher extends LuceneTestCase {
@@ -116,7 +116,7 @@ public class TestIndexSearcher extends LuceneTestCase {
       }
     }
     
-    _TestUtil.shutdownExecutorService(service);
+    TestUtil.shutdownExecutorService(service);
   }
   
   @Test
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestLiveFieldValues.java b/lucene/core/src/test/org/apache/lucene/search/TestLiveFieldValues.java
index 055de01..2da514f 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestLiveFieldValues.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestLiveFieldValues.java
@@ -39,12 +39,12 @@ import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestLiveFieldValues extends LuceneTestCase {
   public void test() throws Exception {
 
-    Directory dir = newFSDirectory(_TestUtil.getTempDir("livefieldupdates"));
+    Directory dir = newFSDirectory(TestUtil.getTempDir("livefieldupdates"));
     IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));
 
     final IndexWriter w = new IndexWriter(dir, iwc);
@@ -73,7 +73,7 @@ public class TestLiveFieldValues extends LuceneTestCase {
         }
     };
 
-    int numThreads = _TestUtil.nextInt(random(), 2, 5);
+    int numThreads = TestUtil.nextInt(random(), 2, 5);
     if (VERBOSE) {
       System.out.println(numThreads + " threads");
     }
@@ -82,7 +82,7 @@ public class TestLiveFieldValues extends LuceneTestCase {
     List<Thread> threads = new ArrayList<Thread>();
 
     final int iters = atLeast(1000);
-    final int idCount = _TestUtil.nextInt(random(), 100, 10000);
+    final int idCount = TestUtil.nextInt(random(), 100, 10000);
 
     final double reopenChance = random().nextDouble()*0.01;
     final double deleteChance = random().nextDouble()*0.25;
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestMinShouldMatch2.java b/lucene/core/src/test/org/apache/lucene/search/TestMinShouldMatch2.java
index c8e963c..4ca3722 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestMinShouldMatch2.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestMinShouldMatch2.java
@@ -42,7 +42,7 @@ import org.apache.lucene.search.similarities.Similarity.SimWeight;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.LuceneTestCase.SuppressCodecs;
 import org.junit.AfterClass;
 import org.junit.BeforeClass;
@@ -107,7 +107,7 @@ public class TestMinShouldMatch2 extends LuceneTestCase {
   private static void addSome(Document doc, String values[]) {
     List<String> list = Arrays.asList(values);
     Collections.shuffle(list, random());
-    int howMany = _TestUtil.nextInt(random(), 1, list.size());
+    int howMany = TestUtil.nextInt(random(), 1, list.size());
     for (int i = 0; i < howMany; i++) {
       doc.add(new StringField("field", list.get(i), Field.Store.NO));
       doc.add(new SortedSetDocValuesField("dv", new BytesRef(list.get(i))));
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestMultiValuedNumericRangeQuery.java b/lucene/core/src/test/org/apache/lucene/search/TestMultiValuedNumericRangeQuery.java
index 86c6904..6ae70d2 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestMultiValuedNumericRangeQuery.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestMultiValuedNumericRangeQuery.java
@@ -29,7 +29,8 @@ import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestMultiValuedNumericRangeQuery extends LuceneTestCase {
 
@@ -42,7 +43,7 @@ public class TestMultiValuedNumericRangeQuery extends LuceneTestCase {
     Directory directory = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random(), directory,
         newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))
-        .setMaxBufferedDocs(_TestUtil.nextInt(random(), 50, 1000)));
+        .setMaxBufferedDocs(TestUtil.nextInt(random(), 50, 1000)));
     
     DecimalFormat format = new DecimalFormat("00000000000", new DecimalFormatSymbols(Locale.ROOT));
     
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestNumericRangeQuery32.java b/lucene/core/src/test/org/apache/lucene/search/TestNumericRangeQuery32.java
index 8dea3da..150ca07 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestNumericRangeQuery32.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestNumericRangeQuery32.java
@@ -37,7 +37,7 @@ import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.NumericUtils;
 import org.apache.lucene.util.TestNumericUtils; // NaN arrays
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.AfterClass;
 import org.junit.BeforeClass;
 import org.junit.Test;
@@ -61,7 +61,7 @@ public class TestNumericRangeQuery32 extends LuceneTestCase {
     directory = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random(), directory,
         newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))
-        .setMaxBufferedDocs(_TestUtil.nextInt(random(), 100, 1000))
+        .setMaxBufferedDocs(TestUtil.nextInt(random(), 100, 1000))
         .setMergePolicy(newLogMergePolicy()));
     
     final FieldType storedInt = new FieldType(IntField.TYPE_NOT_STORED);
@@ -370,7 +370,7 @@ public class TestNumericRangeQuery32 extends LuceneTestCase {
   private void testRandomTrieAndClassicRangeQuery(int precisionStep) throws Exception {
     String field="field"+precisionStep;
     int totalTermCountT=0,totalTermCountC=0,termCountT,termCountC;
-    int num = _TestUtil.nextInt(random(), 10, 20);
+    int num = TestUtil.nextInt(random(), 10, 20);
     for (int i = 0; i < num; i++) {
       int lower=(int)(random().nextDouble()*noDocs*distance)+startOffset;
       int upper=(int)(random().nextDouble()*noDocs*distance)+startOffset;
@@ -493,7 +493,7 @@ public class TestNumericRangeQuery32 extends LuceneTestCase {
   private void testRangeSplit(int precisionStep) throws Exception {
     String field="ascfield"+precisionStep;
     // 10 random tests
-    int num = _TestUtil.nextInt(random(), 10, 20);
+    int num = TestUtil.nextInt(random(), 10, 20);
     for (int  i =0;  i< num; i++) {
       int lower=(int)(random().nextDouble()*noDocs - noDocs/2);
       int upper=(int)(random().nextDouble()*noDocs - noDocs/2);
@@ -569,7 +569,7 @@ public class TestNumericRangeQuery32 extends LuceneTestCase {
     String field="field"+precisionStep;
     // 10 random tests, the index order is ascending,
     // so using a reverse sort field should retun descending documents
-    int num = _TestUtil.nextInt(random(), 10, 20);
+    int num = TestUtil.nextInt(random(), 10, 20);
     for (int i = 0; i < num; i++) {
       int lower=(int)(random().nextDouble()*noDocs*distance)+startOffset;
       int upper=(int)(random().nextDouble()*noDocs*distance)+startOffset;
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestNumericRangeQuery64.java b/lucene/core/src/test/org/apache/lucene/search/TestNumericRangeQuery64.java
index 3f17c65..961598d 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestNumericRangeQuery64.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestNumericRangeQuery64.java
@@ -37,7 +37,8 @@ import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.NumericUtils;
 import org.apache.lucene.util.TestNumericUtils; // NaN arrays
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.AfterClass;
 import org.junit.BeforeClass;
 import org.junit.Test;
@@ -61,7 +62,7 @@ public class TestNumericRangeQuery64 extends LuceneTestCase {
     directory = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random(), directory,
         newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))
-        .setMaxBufferedDocs(_TestUtil.nextInt(random(), 100, 1000))
+        .setMaxBufferedDocs(TestUtil.nextInt(random(), 100, 1000))
         .setMergePolicy(newLogMergePolicy()));
 
     final FieldType storedLong = new FieldType(LongField.TYPE_NOT_STORED);
@@ -397,7 +398,7 @@ public class TestNumericRangeQuery64 extends LuceneTestCase {
   private void testRandomTrieAndClassicRangeQuery(int precisionStep) throws Exception {
     String field="field"+precisionStep;
     int totalTermCountT=0,totalTermCountC=0,termCountT,termCountC;
-    int num = _TestUtil.nextInt(random(), 10, 20);
+    int num = TestUtil.nextInt(random(), 10, 20);
     for (int i = 0; i < num; i++) {
       long lower=(long)(random().nextDouble()*noDocs*distance)+startOffset;
       long upper=(long)(random().nextDouble()*noDocs*distance)+startOffset;
@@ -525,7 +526,7 @@ public class TestNumericRangeQuery64 extends LuceneTestCase {
   private void testRangeSplit(int precisionStep) throws Exception {
     String field="ascfield"+precisionStep;
     // 10 random tests
-    int num = _TestUtil.nextInt(random(), 10, 20);
+    int num = TestUtil.nextInt(random(), 10, 20);
     for (int i = 0; i < num; i++) {
       long lower=(long)(random().nextDouble()*noDocs - noDocs/2);
       long upper=(long)(random().nextDouble()*noDocs - noDocs/2);
@@ -611,7 +612,7 @@ public class TestNumericRangeQuery64 extends LuceneTestCase {
     String field="field"+precisionStep;
     // 10 random tests, the index order is ascending,
     // so using a reverse sort field should retun descending documents
-    int num = _TestUtil.nextInt(random(), 10, 20);
+    int num = TestUtil.nextInt(random(), 10, 20);
     for (int i = 0; i < num; i++) {
       long lower=(long)(random().nextDouble()*noDocs*distance)+startOffset;
       long upper=(long)(random().nextDouble()*noDocs*distance)+startOffset;
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery.java b/lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery.java
index a2dbdad..d96dad8 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery.java
@@ -31,8 +31,6 @@ import org.apache.lucene.util.*;
 import org.junit.AfterClass;
 import org.junit.BeforeClass;
 
-import com.carrotsearch.randomizedtesting.annotations.Seed;
-
 /**
  * Tests {@link PhraseQuery}.
  *
@@ -602,7 +600,7 @@ public class TestPhraseQuery extends LuceneTestCase {
     int NUM_DOCS = atLeast(10);
     for (int i = 0; i < NUM_DOCS; i++) {
       // must be > 4096 so it spans multiple chunks
-      int termCount = _TestUtil.nextInt(random(), 4097, 8200);
+      int termCount = TestUtil.nextInt(random(), 4097, 8200);
 
       List<String> doc = new ArrayList<String>();
 
@@ -612,7 +610,7 @@ public class TestPhraseQuery extends LuceneTestCase {
           // make new non-empty-string term
           String term;
           while(true) {
-            term = _TestUtil.randomUnicodeString(r);
+            term = TestUtil.randomUnicodeString(r);
             if (term.length() > 0) {
               break;
             }
@@ -630,7 +628,7 @@ public class TestPhraseQuery extends LuceneTestCase {
         } else {
           // pick existing sub-phrase
           List<String> lastDoc = docs.get(r.nextInt(docs.size()));
-          int len = _TestUtil.nextInt(r, 1, 10);
+          int len = TestUtil.nextInt(r, 1, 10);
           int start = r.nextInt(lastDoc.size()-len);
           for(int k=start;k<start+len;k++) {
             String t = lastDoc.get(k);
@@ -654,7 +652,7 @@ public class TestPhraseQuery extends LuceneTestCase {
       int docID = r.nextInt(docs.size());
       List<String> doc = docs.get(docID);
       
-      final int numTerm = _TestUtil.nextInt(r, 2, 20);
+      final int numTerm = TestUtil.nextInt(r, 2, 20);
       final int start = r.nextInt(doc.size()-numTerm);
       PhraseQuery pq = new PhraseQuery();
       StringBuilder sb = new StringBuilder();
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestPrefixRandom.java b/lucene/core/src/test/org/apache/lucene/search/TestPrefixRandom.java
index 6a4228f..5501ce7 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestPrefixRandom.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestPrefixRandom.java
@@ -34,7 +34,8 @@ import org.apache.lucene.util.AttributeSource;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.StringHelper;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Create an index with random unicode terms
@@ -51,7 +52,7 @@ public class TestPrefixRandom extends LuceneTestCase {
     dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random(), dir, 
         newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.KEYWORD, false))
-        .setMaxBufferedDocs(_TestUtil.nextInt(random(), 50, 1000)));
+        .setMaxBufferedDocs(TestUtil.nextInt(random(), 50, 1000)));
     
     Document doc = new Document();
     Field field = newStringField("field", "", Field.Store.NO);
@@ -59,7 +60,7 @@ public class TestPrefixRandom extends LuceneTestCase {
 
     int num = atLeast(1000);
     for (int i = 0; i < num; i++) {
-      field.setStringValue(_TestUtil.randomUnicodeString(random(), 10));
+      field.setStringValue(TestUtil.randomUnicodeString(random(), 10));
       writer.addDocument(doc);
     }
     reader = writer.getReader();
@@ -113,7 +114,7 @@ public class TestPrefixRandom extends LuceneTestCase {
   public void testPrefixes() throws Exception {
       int num = atLeast(100);
       for (int i = 0; i < num; i++)
-        assertSame(_TestUtil.randomUnicodeString(random(), 5));
+        assertSame(TestUtil.randomUnicodeString(random(), 5));
   }
   
   /** check that the # of hits is the same as from a very
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestRegexpRandom.java b/lucene/core/src/test/org/apache/lucene/search/TestRegexpRandom.java
index 97015d5..95760e1 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestRegexpRandom.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestRegexpRandom.java
@@ -32,7 +32,7 @@ import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Create an index with terms from 000-999.
@@ -50,7 +50,7 @@ public class TestRegexpRandom extends LuceneTestCase {
     dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random(), dir,
         newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))
-        .setMaxBufferedDocs(_TestUtil.nextInt(random(), 50, 1000)));
+        .setMaxBufferedDocs(TestUtil.nextInt(random(), 50, 1000)));
     
     Document doc = new Document();
     FieldType customType = new FieldType(TextField.TYPE_STORED);
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestRegexpRandom2.java b/lucene/core/src/test/org/apache/lucene/search/TestRegexpRandom2.java
index 54ab48a..582e00f 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestRegexpRandom2.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestRegexpRandom2.java
@@ -37,8 +37,8 @@ import org.apache.lucene.util.AttributeSource;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.CharsRef;
 import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.UnicodeUtil;
-import org.apache.lucene.util._TestUtil;
 import org.apache.lucene.util.automaton.Automaton;
 import org.apache.lucene.util.automaton.AutomatonTestUtil;
 import org.apache.lucene.util.automaton.CharacterRunAutomaton;
@@ -62,14 +62,14 @@ public class TestRegexpRandom2 extends LuceneTestCase {
     fieldName = random().nextBoolean() ? "field" : ""; // sometimes use an empty string as field name
     RandomIndexWriter writer = new RandomIndexWriter(random(), dir, 
         newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.KEYWORD, false))
-        .setMaxBufferedDocs(_TestUtil.nextInt(random(), 50, 1000)));
+        .setMaxBufferedDocs(TestUtil.nextInt(random(), 50, 1000)));
     Document doc = new Document();
     Field field = newStringField(fieldName, "", Field.Store.NO);
     doc.add(field);
     List<String> terms = new ArrayList<String>();
     int num = atLeast(200);
     for (int i = 0; i < num; i++) {
-      String s = _TestUtil.randomUnicodeString(random());
+      String s = TestUtil.randomUnicodeString(random());
       field.setStringValue(s);
       terms.add(s);
       writer.addDocument(doc);
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads.java b/lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads.java
index 3935add..2356e91 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestSameScoresWithThreads.java
@@ -35,8 +35,8 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LineFileDocs;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util.RamUsageEstimator;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestSameScoresWithThreads extends LuceneTestCase {
 
@@ -80,7 +80,7 @@ public class TestSameScoresWithThreads extends LuceneTestCase {
 
     if (!answers.isEmpty()) {
       final CountDownLatch startingGun = new CountDownLatch(1);
-      int numThreads = _TestUtil.nextInt(random(), 2, 5);
+      int numThreads = TestUtil.nextInt(random(), 2, 5);
       Thread[] threads = new Thread[numThreads];
       for(int threadID=0;threadID<numThreads;threadID++) {
         Thread thread = new Thread() {
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestSearchAfter.java b/lucene/core/src/test/org/apache/lucene/search/TestSearchAfter.java
index 31da62b..38e8914 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestSearchAfter.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestSearchAfter.java
@@ -40,7 +40,7 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.English;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Tests IndexSearcher's searchAfter() method
@@ -133,15 +133,15 @@ public class TestSearchAfter extends LuceneTestCase {
 
       fields.add(new FloatField("float", random().nextFloat(), Field.Store.NO));
       fields.add(new DoubleField("double", random().nextDouble(), Field.Store.NO));
-      fields.add(newStringField("bytes", _TestUtil.randomRealisticUnicodeString(random()), Field.Store.NO));
-      fields.add(newStringField("bytesval", _TestUtil.randomRealisticUnicodeString(random()), Field.Store.NO));
+      fields.add(newStringField("bytes", TestUtil.randomRealisticUnicodeString(random()), Field.Store.NO));
+      fields.add(newStringField("bytesval", TestUtil.randomRealisticUnicodeString(random()), Field.Store.NO));
       fields.add(new DoubleField("double", random().nextDouble(), Field.Store.NO));
 
       fields.add(new NumericDocValuesField("intdocvalues", random().nextInt()));
       fields.add(new FloatDocValuesField("floatdocvalues", random().nextFloat()));
-      fields.add(new SortedDocValuesField("sortedbytesdocvalues", new BytesRef(_TestUtil.randomRealisticUnicodeString(random()))));
-      fields.add(new SortedDocValuesField("sortedbytesdocvaluesval", new BytesRef(_TestUtil.randomRealisticUnicodeString(random()))));
-      fields.add(new BinaryDocValuesField("straightbytesdocvalues", new BytesRef(_TestUtil.randomRealisticUnicodeString(random()))));
+      fields.add(new SortedDocValuesField("sortedbytesdocvalues", new BytesRef(TestUtil.randomRealisticUnicodeString(random()))));
+      fields.add(new SortedDocValuesField("sortedbytesdocvaluesval", new BytesRef(TestUtil.randomRealisticUnicodeString(random()))));
+      fields.add(new BinaryDocValuesField("straightbytesdocvalues", new BytesRef(TestUtil.randomRealisticUnicodeString(random()))));
 
       Document document = new Document();
       document.add(new StoredField("id", ""+i));
@@ -210,7 +210,7 @@ public class TestSearchAfter extends LuceneTestCase {
   }
 
   Sort getRandomSort() {
-    SortField[] sortFields = new SortField[_TestUtil.nextInt(random(), 2, 7)];
+    SortField[] sortFields = new SortField[TestUtil.nextInt(random(), 2, 7)];
     for(int i=0;i<sortFields.length;i++) {
       sortFields[i] = allSortFields.get(random().nextInt(allSortFields.size()));
     }
@@ -220,7 +220,7 @@ public class TestSearchAfter extends LuceneTestCase {
   void assertQuery(Query query, Filter filter, Sort sort) throws Exception {
     int maxDoc = searcher.getIndexReader().maxDoc();
     TopDocs all;
-    int pageSize = _TestUtil.nextInt(random(), 1, maxDoc*2);
+    int pageSize = TestUtil.nextInt(random(), 1, maxDoc * 2);
     if (VERBOSE) {
       System.out.println("\nassertQuery " + (iter++) + ": query=" + query + " filter=" + filter + " sort=" + sort + " pageSize=" + pageSize);
     }
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestSearcherManager.java b/lucene/core/src/test/org/apache/lucene/search/TestSearcherManager.java
index ae2274c..963ec79 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestSearcherManager.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestSearcherManager.java
@@ -42,7 +42,7 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.LuceneTestCase.SuppressCodecs;
 import org.apache.lucene.util.NamedThreadFactory;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 @SuppressCodecs({ "SimpleText", "Memory", "Direct" })
 public class TestSearcherManager extends ThreadedIndexingAndSearchingTestCase {
@@ -52,7 +52,7 @@ public class TestSearcherManager extends ThreadedIndexingAndSearchingTestCase {
   private SearcherLifetimeManager.Pruner pruner;
 
   public void testSearcherManager() throws Exception {
-    pruner = new SearcherLifetimeManager.PruneByAge(TEST_NIGHTLY ? _TestUtil.nextInt(random(), 1, 20) : 1);
+    pruner = new SearcherLifetimeManager.PruneByAge(TEST_NIGHTLY ? TestUtil.nextInt(random(), 1, 20) : 1);
     runTest("TestSearcherManager");
   }
 
@@ -110,9 +110,9 @@ public class TestSearcherManager extends ThreadedIndexingAndSearchingTestCase {
           }
 
           while(System.currentTimeMillis() < stopTime) {
-            Thread.sleep(_TestUtil.nextInt(random(), 1, 100));
+            Thread.sleep(TestUtil.nextInt(random(), 1, 100));
             writer.commit();
-            Thread.sleep(_TestUtil.nextInt(random(), 1, 5));
+            Thread.sleep(TestUtil.nextInt(random(), 1, 5));
             boolean block = random().nextBoolean();
             if (block) {
               mgr.maybeRefreshBlocking();
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestShardSearching.java b/lucene/core/src/test/org/apache/lucene/search/TestShardSearching.java
index 6589f5a..7d2c585 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestShardSearching.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestShardSearching.java
@@ -30,7 +30,7 @@ import org.apache.lucene.index.Term;
 import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase.SuppressCodecs;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 // TODO
 //   - other queries besides PrefixQuery & TermQuery (but:
@@ -65,13 +65,13 @@ public class TestShardSearching extends ShardSearchingTestBase {
   }
 
   public void testSimple() throws Exception {
-    final int numNodes = _TestUtil.nextInt(random(), 1, 10);
+    final int numNodes = TestUtil.nextInt(random(), 1, 10);
 
     final double runTimeSec = atLeast(3);
 
-    final int minDocsToMakeTerms = _TestUtil.nextInt(random(), 5, 20);
+    final int minDocsToMakeTerms = TestUtil.nextInt(random(), 5, 20);
 
-    final int maxSearcherAgeSeconds = _TestUtil.nextInt(random(), 1, 3);
+    final int maxSearcherAgeSeconds = TestUtil.nextInt(random(), 1, 3);
 
     if (VERBOSE) {
       System.out.println("TEST: numNodes=" + numNodes + " runTimeSec=" + runTimeSec + " maxSearcherAgeSeconds=" + maxSearcherAgeSeconds);
@@ -200,7 +200,7 @@ public class TestShardSearching extends ShardSearchingTestBase {
               if (t.length() <= 1) {
                 prefix = t;
               } else {
-                prefix = t.substring(0, _TestUtil.nextInt(random(), 1, 2));
+                prefix = t.substring(0, TestUtil.nextInt(random(), 1, 2));
               }
               query = new PrefixQuery(new Term("body", prefix));
             }
@@ -276,7 +276,7 @@ public class TestShardSearching extends ShardSearchingTestBase {
 
   private PreviousSearchState assertSame(IndexSearcher mockSearcher, NodeState.ShardIndexSearcher shardSearcher, Query q, Sort sort, PreviousSearchState state) throws IOException {
 
-    int numHits = _TestUtil.nextInt(random(), 1, 100);
+    int numHits = TestUtil.nextInt(random(), 1, 100);
     if (state != null && state.searchAfterLocal == null) {
       // In addition to what we last searched:
       numHits += state.numHitsPaged;
@@ -384,7 +384,7 @@ public class TestShardSearching extends ShardSearchingTestBase {
       sd.doc += base[sd.shardIndex];
     }
 
-    _TestUtil.assertEquals(hits, shardHits);
+    TestUtil.assertEquals(hits, shardHits);
 
     if (moreHits) {
       // Return a continuation:
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestSloppyPhraseQuery2.java b/lucene/core/src/test/org/apache/lucene/search/TestSloppyPhraseQuery2.java
index 316991e..92ddbe4 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestSloppyPhraseQuery2.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestSloppyPhraseQuery2.java
@@ -20,7 +20,8 @@ package org.apache.lucene.search;
 import java.util.Random;
 
 import org.apache.lucene.index.Term;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * random sloppy phrase query tests
@@ -186,17 +187,17 @@ public class TestSloppyPhraseQuery2 extends SearchEquivalenceTestBase {
   
   private MultiPhraseQuery randomPhraseQuery(long seed) {
     Random random = new Random(seed);
-    int length = _TestUtil.nextInt(random, 2, 5);
+    int length = TestUtil.nextInt(random, 2, 5);
     MultiPhraseQuery pq = new MultiPhraseQuery();
     int position = 0;
     for (int i = 0; i < length; i++) {
-      int depth = _TestUtil.nextInt(random, 1, 3);
+      int depth = TestUtil.nextInt(random, 1, 3);
       Term terms[] = new Term[depth];
       for (int j = 0; j < depth; j++) {
-        terms[j] = new Term("field", "" + (char) _TestUtil.nextInt(random, 'a', 'z'));
+        terms[j] = new Term("field", "" + (char) TestUtil.nextInt(random, 'a', 'z'));
       }
       pq.add(terms, position);
-      position += _TestUtil.nextInt(random, 1, 3);
+      position += TestUtil.nextInt(random, 1, 3);
     }
     return pq;
   }
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestSortRandom.java b/lucene/core/src/test/org/apache/lucene/search/TestSortRandom.java
index 794f6a2..bfa3dd7 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestSortRandom.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestSortRandom.java
@@ -40,7 +40,8 @@ import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /** random sorting tests */
 public class TestSortRandom extends LuceneTestCase {
@@ -53,7 +54,7 @@ public class TestSortRandom extends LuceneTestCase {
     final RandomIndexWriter writer = new RandomIndexWriter(random, dir);
     final boolean allowDups = random.nextBoolean();
     final Set<String> seen = new HashSet<String>();
-    final int maxLength = _TestUtil.nextInt(random, 5, 100);
+    final int maxLength = TestUtil.nextInt(random, 5, 100);
     if (VERBOSE) {
       System.out.println("TEST: NUM_DOCS=" + NUM_DOCS + " maxLength=" + maxLength + " allowDups=" + allowDups);
     }
@@ -69,9 +70,9 @@ public class TestSortRandom extends LuceneTestCase {
       if (random().nextInt(10) != 7) {
         final String s;
         if (random.nextBoolean()) {
-          s = _TestUtil.randomSimpleString(random, maxLength);
+          s = TestUtil.randomSimpleString(random, maxLength);
         } else {
-          s = _TestUtil.randomUnicodeString(random, maxLength);
+          s = TestUtil.randomUnicodeString(random, maxLength);
         }
 
         if (!allowDups) {
@@ -145,7 +146,7 @@ public class TestSortRandom extends LuceneTestCase {
       } else {
         sort = new Sort(sf, SortField.FIELD_DOC);
       }
-      final int hitCount = _TestUtil.nextInt(random, 1, r.maxDoc() + 20);
+      final int hitCount = TestUtil.nextInt(random, 1, r.maxDoc() + 20);
       final RandomFilter f = new RandomFilter(random, random.nextFloat(), docValues);
       int queryType = random.nextInt(3);
       if (queryType == 0) {
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestTopDocsMerge.java b/lucene/core/src/test/org/apache/lucene/search/TestTopDocsMerge.java
index 4c49c3d..1dcd43d 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestTopDocsMerge.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestTopDocsMerge.java
@@ -35,7 +35,8 @@ import org.apache.lucene.index.ReaderUtil;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestTopDocsMerge extends LuceneTestCase {
 
@@ -86,7 +87,7 @@ public class TestTopDocsMerge extends LuceneTestCase {
 
       for(int contentIDX=0;contentIDX<content.length;contentIDX++) {
         final StringBuilder sb = new StringBuilder();
-        final int numTokens = _TestUtil.nextInt(random(), 1, 10);
+        final int numTokens = TestUtil.nextInt(random(), 1, 10);
         for(int tokenIDX=0;tokenIDX<numTokens;tokenIDX++) {
           sb.append(tokens[random().nextInt(tokens.length)]).append(' ');
         }
@@ -95,7 +96,7 @@ public class TestTopDocsMerge extends LuceneTestCase {
 
       for(int docIDX=0;docIDX<numDocs;docIDX++) {
         final Document doc = new Document();
-        doc.add(newStringField("string", _TestUtil.randomRealisticUnicodeString(random()), Field.Store.NO));
+        doc.add(newStringField("string", TestUtil.randomRealisticUnicodeString(random()), Field.Store.NO));
         doc.add(newTextField("text", content[random().nextInt(content.length)], Field.Store.NO));
         doc.add(new FloatField("float", random().nextFloat(), Field.Store.NO));
         final int intValue;
@@ -166,14 +167,14 @@ public class TestTopDocsMerge extends LuceneTestCase {
         // Sort by score
         sort = null;
       } else {
-        final SortField[] randomSortFields = new SortField[_TestUtil.nextInt(random(), 1, 3)];
+        final SortField[] randomSortFields = new SortField[TestUtil.nextInt(random(), 1, 3)];
         for(int sortIDX=0;sortIDX<randomSortFields.length;sortIDX++) {
           randomSortFields[sortIDX] = sortFields.get(random().nextInt(sortFields.size()));
         }
         sort = new Sort(randomSortFields);
       }
 
-      final int numHits = _TestUtil.nextInt(random(), 1, numDocs+5);
+      final int numHits = TestUtil.nextInt(random(), 1, numDocs + 5);
       //final int numHits = 5;
       
       if (VERBOSE) {
@@ -239,7 +240,7 @@ public class TestTopDocsMerge extends LuceneTestCase {
         }
       }
 
-      _TestUtil.assertEquals(topHits, mergedHits);
+      TestUtil.assertEquals(topHits, mergedHits);
     }
     reader.close();
     dir.close();
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestWildcardRandom.java b/lucene/core/src/test/org/apache/lucene/search/TestWildcardRandom.java
index 9396efb..c929046 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestWildcardRandom.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestWildcardRandom.java
@@ -30,7 +30,8 @@ import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Create an index with terms from 000-999.
@@ -48,7 +49,7 @@ public class TestWildcardRandom extends LuceneTestCase {
     dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random(), dir,
         newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))
-        .setMaxBufferedDocs(_TestUtil.nextInt(random(), 50, 1000)));
+        .setMaxBufferedDocs(TestUtil.nextInt(random(), 50, 1000)));
     
     Document doc = new Document();
     Field field = newStringField("field", "", Field.Store.NO);
diff --git a/lucene/core/src/test/org/apache/lucene/search/spans/TestBasics.java b/lucene/core/src/test/org/apache/lucene/search/spans/TestBasics.java
index ec7ad70..2dfeb1c 100644
--- a/lucene/core/src/test/org/apache/lucene/search/spans/TestBasics.java
+++ b/lucene/core/src/test/org/apache/lucene/search/spans/TestBasics.java
@@ -18,7 +18,6 @@ package org.apache.lucene.search.spans;
  */
 
 import java.io.IOException;
-import java.io.Reader;
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.Collections;
@@ -44,7 +43,7 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.English;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.AfterClass;
 import org.junit.BeforeClass;
 import org.junit.Test;
@@ -111,7 +110,7 @@ public class TestBasics extends LuceneTestCase {
     directory = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random(), directory,
         newIndexWriterConfig(TEST_VERSION_CURRENT, simplePayloadAnalyzer)
-                                                     .setMaxBufferedDocs(_TestUtil.nextInt(random(), 100, 1000)).setMergePolicy(newLogMergePolicy()));
+                                                     .setMaxBufferedDocs(TestUtil.nextInt(random(), 100, 1000)).setMergePolicy(newLogMergePolicy()));
     //writer.infoStream = System.out;
     for (int i = 0; i < 2000; i++) {
       Document doc = new Document();
diff --git a/lucene/core/src/test/org/apache/lucene/store/TestBufferedIndexInput.java b/lucene/core/src/test/org/apache/lucene/store/TestBufferedIndexInput.java
index 2010c2a..349e8b9 100644
--- a/lucene/core/src/test/org/apache/lucene/store/TestBufferedIndexInput.java
+++ b/lucene/core/src/test/org/apache/lucene/store/TestBufferedIndexInput.java
@@ -21,9 +21,6 @@ import java.io.File;
 import java.io.FileOutputStream;
 import java.io.IOException;
 import java.io.OutputStream;
-import java.io.RandomAccessFile;
-import java.nio.channels.FileChannel;
-import java.nio.file.StandardOpenOption;
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.List;
@@ -41,10 +38,9 @@ import org.apache.lucene.index.IndexWriterConfig.OpenMode;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.TermQuery;
-import org.apache.lucene.store.NIOFSDirectory.NIOFSIndexInput;
-import org.apache.lucene.store.SimpleFSDirectory.SimpleFSIndexInput;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.ArrayUtil;
 
 public class TestBufferedIndexInput extends LuceneTestCase {
@@ -227,7 +223,7 @@ public class TestBufferedIndexInput extends LuceneTestCase {
     }
 
     public void testSetBufferSize() throws IOException {
-      File indexDir = _TestUtil.getTempDir("testSetBufferSize");
+      File indexDir = TestUtil.getTempDir("testSetBufferSize");
       MockFSDirectory dir = new MockFSDirectory(indexDir, random());
       try {
         IndexWriter writer = new IndexWriter(
@@ -279,7 +275,7 @@ public class TestBufferedIndexInput extends LuceneTestCase {
         writer.close();
         reader.close();
       } finally {
-        _TestUtil.rmDir(indexDir);
+        TestUtil.rmDir(indexDir);
       }
     }
 
diff --git a/lucene/core/src/test/org/apache/lucene/store/TestCopyBytes.java b/lucene/core/src/test/org/apache/lucene/store/TestCopyBytes.java
index 69eaa6a..12981de 100644
--- a/lucene/core/src/test/org/apache/lucene/store/TestCopyBytes.java
+++ b/lucene/core/src/test/org/apache/lucene/store/TestCopyBytes.java
@@ -20,7 +20,7 @@ package org.apache.lucene.store;
 import java.io.IOException;
 
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 import org.junit.Test;
 
@@ -41,8 +41,8 @@ public class TestCopyBytes extends LuceneTestCase {
       
       // make random file
       IndexOutput out = dir.createOutput("test", newIOContext(random()));
-      byte[] bytes = new byte[_TestUtil.nextInt(random(), 1, 77777)];
-      final int size = _TestUtil.nextInt(random(), 1, 1777777);
+      byte[] bytes = new byte[TestUtil.nextInt(random(), 1, 77777)];
+      final int size = TestUtil.nextInt(random(), 1, 1777777);
       int upto = 0;
       int byteUpto = 0;
       while (upto < size) {
@@ -71,7 +71,7 @@ public class TestCopyBytes extends LuceneTestCase {
           upto++;
         } else {
           final int chunk = Math.min(
-              _TestUtil.nextInt(random(), 1, bytes.length), size - upto);
+              TestUtil.nextInt(random(), 1, bytes.length), size - upto);
           out.copyBytes(in, chunk);
           upto += chunk;
         }
@@ -90,7 +90,7 @@ public class TestCopyBytes extends LuceneTestCase {
           upto++;
         } else {
           final int limit = Math.min(
-              _TestUtil.nextInt(random(), 1, bytes.length), size - upto);
+              TestUtil.nextInt(random(), 1, bytes.length), size - upto);
           in2.readBytes(bytes, 0, limit);
           for (int byteIdx = 0; byteIdx < limit; byteIdx++) {
             assertEquals(value(upto), bytes[byteIdx]);
@@ -109,7 +109,7 @@ public class TestCopyBytes extends LuceneTestCase {
   
   // LUCENE-3541
   public void testCopyBytesWithThreads() throws Exception {
-    int datalen = _TestUtil.nextInt(random(), 101, 10000);
+    int datalen = TestUtil.nextInt(random(), 101, 10000);
     byte data[] = new byte[datalen];
     random().nextBytes(data);
     
diff --git a/lucene/core/src/test/org/apache/lucene/store/TestDirectory.java b/lucene/core/src/test/org/apache/lucene/store/TestDirectory.java
index e7c4e2c..c5b13c8 100644
--- a/lucene/core/src/test/org/apache/lucene/store/TestDirectory.java
+++ b/lucene/core/src/test/org/apache/lucene/store/TestDirectory.java
@@ -25,7 +25,7 @@ import java.util.Arrays;
 
 import org.apache.lucene.store.MockDirectoryWrapper.Throttling;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestDirectory extends LuceneTestCase {
   public void testDetectClose() throws Throwable {
@@ -134,7 +134,7 @@ public class TestDirectory extends LuceneTestCase {
   // Test that different instances of FSDirectory can coexist on the same
   // path, can read, write, and lock files.
   public void testDirectInstantiation() throws Exception {
-    final File path = _TestUtil.getTempDir("testDirectInstantiation");
+    final File path = TestUtil.getTempDir("testDirectInstantiation");
     
     final byte[] largeBuffer = new byte[random().nextInt(256*1024)], largeReadBuffer = new byte[largeBuffer.length];
     for (int i = 0; i < largeBuffer.length; i++) {
@@ -217,7 +217,7 @@ public class TestDirectory extends LuceneTestCase {
       assertFalse(dir.isOpen);
     }
     
-    _TestUtil.rmDir(path);
+    TestUtil.rmDir(path);
   }
 
   // LUCENE-1464
@@ -229,7 +229,7 @@ public class TestDirectory extends LuceneTestCase {
       assertTrue(!path.exists());
       dir.close();
     } finally {
-      _TestUtil.rmDir(path);
+      TestUtil.rmDir(path);
     }
   }
 
@@ -240,7 +240,7 @@ public class TestDirectory extends LuceneTestCase {
 
   // LUCENE-1468
   public void testFSDirectoryFilter() throws IOException {
-    checkDirectoryFilter(newFSDirectory(_TestUtil.getTempDir("test")));
+    checkDirectoryFilter(newFSDirectory(TestUtil.getTempDir("test")));
   }
 
   // LUCENE-1468
@@ -257,20 +257,20 @@ public class TestDirectory extends LuceneTestCase {
 
   // LUCENE-1468
   public void testCopySubdir() throws Throwable {
-    File path = _TestUtil.getTempDir("testsubdir");
+    File path = TestUtil.getTempDir("testsubdir");
     try {
       path.mkdirs();
       new File(path, "subdir").mkdirs();
       Directory fsDir = new SimpleFSDirectory(path, null);
       assertEquals(0, new RAMDirectory(fsDir, newIOContext(random())).listAll().length);
     } finally {
-      _TestUtil.rmDir(path);
+      TestUtil.rmDir(path);
     }
   }
 
   // LUCENE-1468
   public void testNotDirectory() throws Throwable {
-    File path = _TestUtil.getTempDir("testnotdir");
+    File path = TestUtil.getTempDir("testnotdir");
     Directory fsDir = new SimpleFSDirectory(path, null);
     try {
       IndexOutput out = fsDir.createOutput("afile", newIOContext(random()));
@@ -284,7 +284,7 @@ public class TestDirectory extends LuceneTestCase {
       }
     } finally {
       fsDir.close();
-      _TestUtil.rmDir(path);
+      TestUtil.rmDir(path);
     }
   }
 }
diff --git a/lucene/core/src/test/org/apache/lucene/store/TestFileSwitchDirectory.java b/lucene/core/src/test/org/apache/lucene/store/TestFileSwitchDirectory.java
index 49f9113..bebc675 100644
--- a/lucene/core/src/test/org/apache/lucene/store/TestFileSwitchDirectory.java
+++ b/lucene/core/src/test/org/apache/lucene/store/TestFileSwitchDirectory.java
@@ -33,7 +33,7 @@ import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.IndexWriterConfig;
 import org.apache.lucene.index.TestIndexWriterReader;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestFileSwitchDirectory extends LuceneTestCase {
   /**
@@ -88,8 +88,8 @@ public class TestFileSwitchDirectory extends LuceneTestCase {
   }
   
   private Directory newFSSwitchDirectory(Set<String> primaryExtensions) throws IOException {
-    File primDir = _TestUtil.getTempDir("foo");
-    File secondDir = _TestUtil.getTempDir("bar");
+    File primDir = TestUtil.getTempDir("foo");
+    File secondDir = TestUtil.getTempDir("bar");
     return newFSSwitchDirectory(primDir, secondDir, primaryExtensions);
   }
 
@@ -102,10 +102,10 @@ public class TestFileSwitchDirectory extends LuceneTestCase {
   
   // LUCENE-3380 -- make sure we get exception if the directory really does not exist.
   public void testNoDir() throws Throwable {
-    File primDir = _TestUtil.getTempDir("foo");
-    File secondDir = _TestUtil.getTempDir("bar");
-    _TestUtil.rmDir(primDir);
-    _TestUtil.rmDir(secondDir);
+    File primDir = TestUtil.getTempDir("foo");
+    File secondDir = TestUtil.getTempDir("bar");
+    TestUtil.rmDir(primDir);
+    TestUtil.rmDir(secondDir);
     Directory dir = newFSSwitchDirectory(primDir, secondDir, Collections.<String>emptySet());
     try {
       DirectoryReader.open(dir);
diff --git a/lucene/core/src/test/org/apache/lucene/store/TestLockFactory.java b/lucene/core/src/test/org/apache/lucene/store/TestLockFactory.java
index 6f8345d..137ed92 100644
--- a/lucene/core/src/test/org/apache/lucene/store/TestLockFactory.java
+++ b/lucene/core/src/test/org/apache/lucene/store/TestLockFactory.java
@@ -36,7 +36,8 @@ import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestLockFactory extends LuceneTestCase {
 
@@ -135,7 +136,7 @@ public class TestLockFactory extends LuceneTestCase {
     // no unexpected exceptions are raised:
     @Nightly
     public void testStressLocks() throws Exception {
-      _testStressLocks(null, _TestUtil.getTempDir("index.TestLockFactory6"));
+      _testStressLocks(null, TestUtil.getTempDir("index.TestLockFactory6"));
     }
 
     // Verify: do stress test, by opening IndexReaders and
@@ -144,7 +145,7 @@ public class TestLockFactory extends LuceneTestCase {
     // NativeFSLockFactory:
     @Nightly
     public void testStressLocksNativeFSLockFactory() throws Exception {
-      File dir = _TestUtil.getTempDir("index.TestLockFactory7");
+      File dir = TestUtil.getTempDir("index.TestLockFactory7");
       _testStressLocks(new NativeFSLockFactory(dir), dir);
     }
 
@@ -170,7 +171,7 @@ public class TestLockFactory extends LuceneTestCase {
 
         dir.close();
         // Cleanup
-        _TestUtil.rmDir(indexDir);
+        TestUtil.rmDir(indexDir);
     }
 
     // Verify: NativeFSLockFactory works correctly
@@ -237,8 +238,8 @@ public class TestLockFactory extends LuceneTestCase {
     // Verify: NativeFSLockFactory assigns null as lockPrefix if the lockDir is inside directory
     public void testNativeFSLockFactoryPrefix() throws IOException {
 
-      File fdir1 = _TestUtil.getTempDir("TestLockFactory.8");
-      File fdir2 = _TestUtil.getTempDir("TestLockFactory.8.Lockdir");
+      File fdir1 = TestUtil.getTempDir("TestLockFactory.8");
+      File fdir2 = TestUtil.getTempDir("TestLockFactory.8.Lockdir");
       Directory dir1 = newFSDirectory(fdir1, new NativeFSLockFactory(fdir1));
       // same directory, but locks are stored somewhere else. The prefix of the lock factory should != null
       Directory dir2 = newFSDirectory(fdir1, new NativeFSLockFactory(fdir2));
@@ -251,8 +252,8 @@ public class TestLockFactory extends LuceneTestCase {
 
       dir1.close();
       dir2.close();
-      _TestUtil.rmDir(fdir1);
-      _TestUtil.rmDir(fdir2);
+      TestUtil.rmDir(fdir1);
+      TestUtil.rmDir(fdir2);
     }
 
     // Verify: default LockFactory has no prefix (ie
@@ -260,7 +261,7 @@ public class TestLockFactory extends LuceneTestCase {
     public void testDefaultFSLockFactoryPrefix() throws IOException {
 
       // Make sure we get null prefix, which wont happen if setLockFactory is ever called.
-      File dirName = _TestUtil.getTempDir("TestLockFactory.10");
+      File dirName = TestUtil.getTempDir("TestLockFactory.10");
 
       Directory dir = new SimpleFSDirectory(dirName);
       assertNull("Default lock prefix should be null", dir.getLockFactory().getLockPrefix());
@@ -274,7 +275,7 @@ public class TestLockFactory extends LuceneTestCase {
       assertNull("Default lock prefix should be null", dir.getLockFactory().getLockPrefix());
       dir.close();
  
-      _TestUtil.rmDir(dirName);
+      TestUtil.rmDir(dirName);
     }
 
     private class WriterThread extends Thread { 
diff --git a/lucene/core/src/test/org/apache/lucene/store/TestMultiMMap.java b/lucene/core/src/test/org/apache/lucene/store/TestMultiMMap.java
index dbc3461..9ddd715 100644
--- a/lucene/core/src/test/org/apache/lucene/store/TestMultiMMap.java
+++ b/lucene/core/src/test/org/apache/lucene/store/TestMultiMMap.java
@@ -28,7 +28,7 @@ import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.store.Directory.IndexInputSlicer;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Tests MMapDirectory's MultiMMapIndexInput
@@ -44,12 +44,12 @@ public class TestMultiMMap extends LuceneTestCase {
   public void setUp() throws Exception {
     super.setUp();
     assumeTrue("test requires a jre that supports unmapping", MMapDirectory.UNMAP_SUPPORTED);
-    workDir = _TestUtil.getTempDir("TestMultiMMap");
+    workDir = TestUtil.getTempDir("TestMultiMMap");
     workDir.mkdirs();
   }
   
   public void testCloneSafety() throws Exception {
-    MMapDirectory mmapDir = new MMapDirectory(_TestUtil.getTempDir("testCloneSafety"));
+    MMapDirectory mmapDir = new MMapDirectory(TestUtil.getTempDir("testCloneSafety"));
     IndexOutput io = mmapDir.createOutput("bytes", newIOContext(random()));
     io.writeVInt(5);
     io.close();
@@ -83,7 +83,7 @@ public class TestMultiMMap extends LuceneTestCase {
   }
   
   public void testCloneClose() throws Exception {
-    MMapDirectory mmapDir = new MMapDirectory(_TestUtil.getTempDir("testCloneClose"));
+    MMapDirectory mmapDir = new MMapDirectory(TestUtil.getTempDir("testCloneClose"));
     IndexOutput io = mmapDir.createOutput("bytes", newIOContext(random()));
     io.writeVInt(5);
     io.close();
@@ -105,7 +105,7 @@ public class TestMultiMMap extends LuceneTestCase {
   }
   
   public void testCloneSliceSafety() throws Exception {
-    MMapDirectory mmapDir = new MMapDirectory(_TestUtil.getTempDir("testCloneSliceSafety"));
+    MMapDirectory mmapDir = new MMapDirectory(TestUtil.getTempDir("testCloneSliceSafety"));
     IndexOutput io = mmapDir.createOutput("bytes", newIOContext(random()));
     io.writeInt(1);
     io.writeInt(2);
@@ -150,7 +150,7 @@ public class TestMultiMMap extends LuceneTestCase {
   }
 
   public void testCloneSliceClose() throws Exception {
-    MMapDirectory mmapDir = new MMapDirectory(_TestUtil.getTempDir("testCloneSliceClose"));
+    MMapDirectory mmapDir = new MMapDirectory(TestUtil.getTempDir("testCloneSliceClose"));
     IndexOutput io = mmapDir.createOutput("bytes", newIOContext(random()));
     io.writeInt(1);
     io.writeInt(2);
@@ -177,7 +177,7 @@ public class TestMultiMMap extends LuceneTestCase {
 
   public void testSeekZero() throws Exception {
     for (int i = 0; i < 31; i++) {
-      MMapDirectory mmapDir = new MMapDirectory(_TestUtil.getTempDir("testSeekZero"), null, 1<<i);
+      MMapDirectory mmapDir = new MMapDirectory(TestUtil.getTempDir("testSeekZero"), null, 1<<i);
       IndexOutput io = mmapDir.createOutput("zeroBytes", newIOContext(random()));
       io.close();
       IndexInput ii = mmapDir.openInput("zeroBytes", newIOContext(random()));
@@ -189,7 +189,7 @@ public class TestMultiMMap extends LuceneTestCase {
   
   public void testSeekSliceZero() throws Exception {
     for (int i = 0; i < 31; i++) {
-      MMapDirectory mmapDir = new MMapDirectory(_TestUtil.getTempDir("testSeekSliceZero"), null, 1<<i);
+      MMapDirectory mmapDir = new MMapDirectory(TestUtil.getTempDir("testSeekSliceZero"), null, 1<<i);
       IndexOutput io = mmapDir.createOutput("zeroBytes", newIOContext(random()));
       io.close();
       IndexInputSlicer slicer = mmapDir.createSlicer("zeroBytes", newIOContext(random()));
@@ -203,7 +203,7 @@ public class TestMultiMMap extends LuceneTestCase {
   
   public void testSeekEnd() throws Exception {
     for (int i = 0; i < 17; i++) {
-      MMapDirectory mmapDir = new MMapDirectory(_TestUtil.getTempDir("testSeekEnd"), null, 1<<i);
+      MMapDirectory mmapDir = new MMapDirectory(TestUtil.getTempDir("testSeekEnd"), null, 1<<i);
       IndexOutput io = mmapDir.createOutput("bytes", newIOContext(random()));
       byte bytes[] = new byte[1<<i];
       random().nextBytes(bytes);
@@ -221,7 +221,7 @@ public class TestMultiMMap extends LuceneTestCase {
   
   public void testSeekSliceEnd() throws Exception {
     for (int i = 0; i < 17; i++) {
-      MMapDirectory mmapDir = new MMapDirectory(_TestUtil.getTempDir("testSeekSliceEnd"), null, 1<<i);
+      MMapDirectory mmapDir = new MMapDirectory(TestUtil.getTempDir("testSeekSliceEnd"), null, 1<<i);
       IndexOutput io = mmapDir.createOutput("bytes", newIOContext(random()));
       byte bytes[] = new byte[1<<i];
       random().nextBytes(bytes);
@@ -241,7 +241,7 @@ public class TestMultiMMap extends LuceneTestCase {
   
   public void testSeeking() throws Exception {
     for (int i = 0; i < 10; i++) {
-      MMapDirectory mmapDir = new MMapDirectory(_TestUtil.getTempDir("testSeeking"), null, 1<<i);
+      MMapDirectory mmapDir = new MMapDirectory(TestUtil.getTempDir("testSeeking"), null, 1<<i);
       IndexOutput io = mmapDir.createOutput("bytes", newIOContext(random()));
       byte bytes[] = new byte[1<<(i+1)]; // make sure we switch buffers
       random().nextBytes(bytes);
@@ -268,7 +268,7 @@ public class TestMultiMMap extends LuceneTestCase {
   // the various offset+length and just does readBytes.
   public void testSlicedSeeking() throws Exception {
     for (int i = 0; i < 10; i++) {
-      MMapDirectory mmapDir = new MMapDirectory(_TestUtil.getTempDir("testSlicedSeeking"), null, 1<<i);
+      MMapDirectory mmapDir = new MMapDirectory(TestUtil.getTempDir("testSlicedSeeking"), null, 1<<i);
       IndexOutput io = mmapDir.createOutput("bytes", newIOContext(random()));
       byte bytes[] = new byte[1<<(i+1)]; // make sure we switch buffers
       random().nextBytes(bytes);
@@ -297,11 +297,11 @@ public class TestMultiMMap extends LuceneTestCase {
   public void testRandomChunkSizes() throws Exception {
     int num = atLeast(10);
     for (int i = 0; i < num; i++)
-      assertChunking(random(), _TestUtil.nextInt(random(), 20, 100));
+      assertChunking(random(), TestUtil.nextInt(random(), 20, 100));
   }
   
   private void assertChunking(Random random, int chunkSize) throws Exception {
-    File path = _TestUtil.createTempFile("mmap" + chunkSize, "tmp", workDir);
+    File path = TestUtil.createTempFile("mmap" + chunkSize, "tmp", workDir);
     path.delete();
     path.mkdirs();
     MMapDirectory mmapDir = new MMapDirectory(path, null, chunkSize);
@@ -319,7 +319,7 @@ public class TestMultiMMap extends LuceneTestCase {
     int numDocs = 100;
     for (int i = 0; i < numDocs; i++) {
       docid.setStringValue("" + i);
-      junk.setStringValue(_TestUtil.randomUnicodeString(random));
+      junk.setStringValue(TestUtil.randomUnicodeString(random));
       writer.addDocument(doc);
     }
     IndexReader reader = writer.getReader();
diff --git a/lucene/core/src/test/org/apache/lucene/store/TestNRTCachingDirectory.java b/lucene/core/src/test/org/apache/lucene/store/TestNRTCachingDirectory.java
index 6b53bc2..cb281ed 100644
--- a/lucene/core/src/test/org/apache/lucene/store/TestNRTCachingDirectory.java
+++ b/lucene/core/src/test/org/apache/lucene/store/TestNRTCachingDirectory.java
@@ -27,7 +27,6 @@ import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.index.DirectoryReader;
-import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.IndexWriterConfig;
 import org.apache.lucene.index.RandomIndexWriter;
@@ -38,8 +37,8 @@ import org.apache.lucene.search.TopDocs;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LineFileDocs;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util.Version;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestNRTCachingDirectory extends LuceneTestCase {
 
@@ -49,7 +48,7 @@ public class TestNRTCachingDirectory extends LuceneTestCase {
     IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));
     RandomIndexWriter w = new RandomIndexWriter(random(), cachedDir, conf);
     final LineFileDocs docs = new LineFileDocs(random(), true);
-    final int numDocs = _TestUtil.nextInt(random(), 100, 400);
+    final int numDocs = TestUtil.nextInt(random(), 100, 400);
 
     if (VERBOSE) {
       System.out.println("TEST: numDocs=" + numDocs);
@@ -123,8 +122,8 @@ public class TestNRTCachingDirectory extends LuceneTestCase {
   
   // LUCENE-3382 -- make sure we get exception if the directory really does not exist.
   public void testNoDir() throws Throwable {
-    File tempDir = _TestUtil.getTempDir("doesnotexist");
-    _TestUtil.rmDir(tempDir);
+    File tempDir = TestUtil.getTempDir("doesnotexist");
+    TestUtil.rmDir(tempDir);
     Directory dir = new NRTCachingDirectory(newFSDirectory(tempDir), 2.0, 25.0);
     try {
       DirectoryReader.open(dir);
@@ -137,7 +136,7 @@ public class TestNRTCachingDirectory extends LuceneTestCase {
   
   // LUCENE-3382 test that we can add a file, and then when we call list() we get it back
   public void testDirectoryFilter() throws IOException {
-    Directory dir = new NRTCachingDirectory(newFSDirectory(_TestUtil.getTempDir("foo")), 2.0, 25.0);
+    Directory dir = new NRTCachingDirectory(newFSDirectory(TestUtil.getTempDir("foo")), 2.0, 25.0);
     String name = "file";
     try {
       dir.createOutput(name, newIOContext(random())).close();
diff --git a/lucene/core/src/test/org/apache/lucene/store/TestRAMDirectory.java b/lucene/core/src/test/org/apache/lucene/store/TestRAMDirectory.java
index 82cd9ee..610267f 100644
--- a/lucene/core/src/test/org/apache/lucene/store/TestRAMDirectory.java
+++ b/lucene/core/src/test/org/apache/lucene/store/TestRAMDirectory.java
@@ -22,7 +22,8 @@ import java.io.IOException;
 
 import org.apache.lucene.document.Field;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.index.DirectoryReader;
@@ -49,7 +50,7 @@ public class TestRAMDirectory extends LuceneTestCase {
   @Override
   public void setUp() throws Exception {
     super.setUp();
-    indexDir = _TestUtil.getTempDir("RAMDirIndex");
+    indexDir = TestUtil.getTempDir("RAMDirIndex");
     
     Directory dir = newFSDirectory(indexDir);
     IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(
diff --git a/lucene/core/src/test/org/apache/lucene/store/TestWindowsMMap.java b/lucene/core/src/test/org/apache/lucene/store/TestWindowsMMap.java
index 14d5d95..25f970f 100644
--- a/lucene/core/src/test/org/apache/lucene/store/TestWindowsMMap.java
+++ b/lucene/core/src/test/org/apache/lucene/store/TestWindowsMMap.java
@@ -21,7 +21,7 @@ import java.io.File;
 
 import org.apache.lucene.document.Field;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
@@ -65,7 +65,7 @@ public class TestWindowsMMap extends LuceneTestCase {
     // sometimes the directory is not cleaned by rmDir, because on Windows it
     // may take some time until the files are finally dereferenced. So clean the
     // directory up front, or otherwise new IndexWriter will fail.
-    File dirPath = _TestUtil.getTempDir("testLuceneMmap");
+    File dirPath = TestUtil.getTempDir("testLuceneMmap");
     rmDir(dirPath);
     MMapDirectory dir = new MMapDirectory(dirPath, null);
     
diff --git a/lucene/core/src/test/org/apache/lucene/util/BaseSortTestCase.java b/lucene/core/src/test/org/apache/lucene/util/BaseSortTestCase.java
index 8646f23..dec5ddf 100644
--- a/lucene/core/src/test/org/apache/lucene/util/BaseSortTestCase.java
+++ b/lucene/core/src/test/org/apache/lucene/util/BaseSortTestCase.java
@@ -101,7 +101,7 @@ public abstract class BaseSortTestCase extends LuceneTestCase {
       public void set(Entry[] arr, int i) {
         arr[i] = i == 0
             ? new Entry(random().nextInt(6), 0)
-            : new Entry(arr[i - 1].value - _TestUtil.nextInt(random(), 1, 5), i);
+            : new Entry(arr[i - 1].value - TestUtil.nextInt(random(), 1, 5), i);
       }
     },
     ASCENDING_SEQUENCES {
@@ -117,7 +117,7 @@ public abstract class BaseSortTestCase extends LuceneTestCase {
       public void set(Entry[] arr, int i) {
         arr[i] = i == 0
             ? new Entry(random().nextInt(6), 0)
-            : new Entry(arr[i - 1].value + _TestUtil.nextInt(random(), -8, 10), i);
+            : new Entry(arr[i - 1].value + TestUtil.nextInt(random(), -8, 10), i);
       }
     };
     public abstract void set(Entry[] arr, int i);
diff --git a/lucene/core/src/test/org/apache/lucene/util/Test2BPagedBytes.java b/lucene/core/src/test/org/apache/lucene/util/Test2BPagedBytes.java
index 915531c..47446b1 100644
--- a/lucene/core/src/test/org/apache/lucene/util/Test2BPagedBytes.java
+++ b/lucene/core/src/test/org/apache/lucene/util/Test2BPagedBytes.java
@@ -30,7 +30,7 @@ import org.junit.Ignore;
 public class Test2BPagedBytes extends LuceneTestCase {
 
   public void test() throws Exception {
-    BaseDirectoryWrapper dir = newFSDirectory(_TestUtil.getTempDir("test2BPagedBytes"));
+    BaseDirectoryWrapper dir = newFSDirectory(TestUtil.getTempDir("test2BPagedBytes"));
     if (dir instanceof MockDirectoryWrapper) {
       ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);
     }
@@ -41,7 +41,7 @@ public class Test2BPagedBytes extends LuceneTestCase {
     long lastFP = 0;
     Random r2 = new Random(seed);
     while(netBytes < 1.1*Integer.MAX_VALUE) {
-      int numBytes = _TestUtil.nextInt(r2, 1, 32768);
+      int numBytes = TestUtil.nextInt(r2, 1, 32768);
       byte[] bytes = new byte[numBytes];
       r2.nextBytes(bytes);
       dataOutput.writeBytes(bytes, bytes.length);
@@ -59,7 +59,7 @@ public class Test2BPagedBytes extends LuceneTestCase {
     r2 = new Random(seed);
     netBytes = 0;
     while(netBytes < 1.1*Integer.MAX_VALUE) {
-      int numBytes = _TestUtil.nextInt(r2, 1, 32768);
+      int numBytes = TestUtil.nextInt(r2, 1, 32768);
       byte[] bytes = new byte[numBytes];
       r2.nextBytes(bytes);
       BytesRef expected = new BytesRef(bytes);
diff --git a/lucene/core/src/test/org/apache/lucene/util/TestByteBlockPool.java b/lucene/core/src/test/org/apache/lucene/util/TestByteBlockPool.java
index b971c0f..8b439f8 100644
--- a/lucene/core/src/test/org/apache/lucene/util/TestByteBlockPool.java
+++ b/lucene/core/src/test/org/apache/lucene/util/TestByteBlockPool.java
@@ -34,7 +34,7 @@ public class TestByteBlockPool extends LuceneTestCase {
       final int numValues = atLeast(100);
       BytesRef ref = new BytesRef();
       for (int i = 0; i < numValues; i++) {
-        final String value = _TestUtil.randomRealisticUnicodeString(random(),
+        final String value = TestUtil.randomRealisticUnicodeString(random(),
             maxLength);
         list.add(new BytesRef(value));
         ref.copyChars(value);
diff --git a/lucene/core/src/test/org/apache/lucene/util/TestBytesRef.java b/lucene/core/src/test/org/apache/lucene/util/TestBytesRef.java
index 0684a05..5fe2d25 100644
--- a/lucene/core/src/test/org/apache/lucene/util/TestBytesRef.java
+++ b/lucene/core/src/test/org/apache/lucene/util/TestBytesRef.java
@@ -40,7 +40,7 @@ public class TestBytesRef extends LuceneTestCase {
   
   public void testFromChars() {
     for (int i = 0; i < 100; i++) {
-      String s = _TestUtil.randomUnicodeString(random());
+      String s = TestUtil.randomUnicodeString(random());
       String s2 = new BytesRef(s).utf8ToString();
       assertEquals(s, s2);
     }
diff --git a/lucene/core/src/test/org/apache/lucene/util/TestBytesRefHash.java b/lucene/core/src/test/org/apache/lucene/util/TestBytesRefHash.java
index b45e8e3..f71f3c7 100644
--- a/lucene/core/src/test/org/apache/lucene/util/TestBytesRefHash.java
+++ b/lucene/core/src/test/org/apache/lucene/util/TestBytesRefHash.java
@@ -66,7 +66,7 @@ public class TestBytesRefHash extends LuceneTestCase {
       for (int i = 0; i < 797; i++) {
         String str;
         do {
-          str = _TestUtil.randomRealisticUnicodeString(random(), 1000);
+          str = TestUtil.randomRealisticUnicodeString(random(), 1000);
         } while (str.length() == 0);
         ref.copyChars(str);
         int count = hash.size();
@@ -100,7 +100,7 @@ public class TestBytesRefHash extends LuceneTestCase {
       for (int i = 0; i < 797; i++) {
         String str;
         do {
-          str = _TestUtil.randomRealisticUnicodeString(random(), 1000);
+          str = TestUtil.randomRealisticUnicodeString(random(), 1000);
         } while (str.length() == 0);
         ref.copyChars(str);
         int count = hash.size();
@@ -139,7 +139,7 @@ public class TestBytesRefHash extends LuceneTestCase {
       for (int i = 0; i < size; i++) {
         String str;
         do {
-          str = _TestUtil.randomRealisticUnicodeString(random(), 1000);
+          str = TestUtil.randomRealisticUnicodeString(random(), 1000);
         } while (str.length() == 0);
         ref.copyChars(str);
         final int key = hash.add(ref);
@@ -179,7 +179,7 @@ public class TestBytesRefHash extends LuceneTestCase {
       for (int i = 0; i < 797; i++) {
         String str;
         do {
-          str = _TestUtil.randomRealisticUnicodeString(random(), 1000);
+          str = TestUtil.randomRealisticUnicodeString(random(), 1000);
         } while (str.length() == 0);
         ref.copyChars(str);
         hash.add(ref);
@@ -218,7 +218,7 @@ public class TestBytesRefHash extends LuceneTestCase {
       for (int i = 0; i < 797; i++) {
         String str;
         do {
-          str = _TestUtil.randomRealisticUnicodeString(random(), 1000);
+          str = TestUtil.randomRealisticUnicodeString(random(), 1000);
         } while (str.length() == 0);
         ref.copyChars(str);
         int count = hash.size();
@@ -255,7 +255,7 @@ public class TestBytesRefHash extends LuceneTestCase {
       for (int i = 0; i < 797; i++) {
         String str;
         do {
-          str = _TestUtil.randomRealisticUnicodeString(random(), 1000);
+          str = TestUtil.randomRealisticUnicodeString(random(), 1000);
         } while (str.length() == 0);
         ref.copyChars(str);
         int count = hash.size();
@@ -318,7 +318,7 @@ public class TestBytesRefHash extends LuceneTestCase {
       for (int i = 0; i < 797; i++) {
         String str;
         do {
-          str = _TestUtil.randomRealisticUnicodeString(random(), 1000);
+          str = TestUtil.randomRealisticUnicodeString(random(), 1000);
         } while (str.length() == 0);
         ref.copyChars(str);
         int count = hash.size();
diff --git a/lucene/core/src/test/org/apache/lucene/util/TestCharsRef.java b/lucene/core/src/test/org/apache/lucene/util/TestCharsRef.java
index 1997bcc..3019109 100644
--- a/lucene/core/src/test/org/apache/lucene/util/TestCharsRef.java
+++ b/lucene/core/src/test/org/apache/lucene/util/TestCharsRef.java
@@ -26,7 +26,7 @@ public class TestCharsRef extends LuceneTestCase {
     CharsRef utf16[] = new CharsRef[numStrings];
     
     for (int i = 0; i < numStrings; i++) {
-      String s = _TestUtil.randomUnicodeString(random());
+      String s = TestUtil.randomUnicodeString(random());
       utf8[i] = new BytesRef(s);
       utf16[i] = new CharsRef(s);
     }
@@ -44,7 +44,7 @@ public class TestCharsRef extends LuceneTestCase {
     StringBuilder builder = new StringBuilder();
     int numStrings = atLeast(10);
     for (int i = 0; i < numStrings; i++) {
-      char[] charArray = _TestUtil.randomRealisticUnicodeString(random(), 1, 100).toCharArray();
+      char[] charArray = TestUtil.randomRealisticUnicodeString(random(), 1, 100).toCharArray();
       int offset = random().nextInt(charArray.length);
       int length = charArray.length - offset;
       builder.append(charArray, offset, length);
@@ -58,7 +58,7 @@ public class TestCharsRef extends LuceneTestCase {
     int numIters = atLeast(10);
     for (int i = 0; i < numIters; i++) {
       CharsRef ref = new CharsRef();
-      char[] charArray = _TestUtil.randomRealisticUnicodeString(random(), 1, 100).toCharArray();
+      char[] charArray = TestUtil.randomRealisticUnicodeString(random(), 1, 100).toCharArray();
       int offset = random().nextInt(charArray.length);
       int length = charArray.length - offset;
       String str = new String(charArray, offset, length);
diff --git a/lucene/core/src/test/org/apache/lucene/util/TestFixedBitSet.java b/lucene/core/src/test/org/apache/lucene/util/TestFixedBitSet.java
index 44d3078..9f31e30 100644
--- a/lucene/core/src/test/org/apache/lucene/util/TestFixedBitSet.java
+++ b/lucene/core/src/test/org/apache/lucene/util/TestFixedBitSet.java
@@ -104,7 +104,7 @@ public class TestFixedBitSet extends BaseDocIdSetTestCase<FixedBitSet> {
     FixedBitSet b0=null;
 
     for (int i=0; i<iter; i++) {
-      int sz = _TestUtil.nextInt(random(), 2, maxSize);
+      int sz = TestUtil.nextInt(random(), 2, maxSize);
       BitSet a = new BitSet(sz);
       FixedBitSet b = new FixedBitSet(sz);
 
diff --git a/lucene/core/src/test/org/apache/lucene/util/TestLongBitSet.java b/lucene/core/src/test/org/apache/lucene/util/TestLongBitSet.java
index 36264f3..070438e 100644
--- a/lucene/core/src/test/org/apache/lucene/util/TestLongBitSet.java
+++ b/lucene/core/src/test/org/apache/lucene/util/TestLongBitSet.java
@@ -68,7 +68,7 @@ public class TestLongBitSet extends LuceneTestCase {
     LongBitSet b0=null;
 
     for (int i=0; i<iter; i++) {
-      int sz = _TestUtil.nextInt(random(), 2, maxSize);
+      int sz = TestUtil.nextInt(random(), 2, maxSize);
       BitSet a = new BitSet(sz);
       LongBitSet b = new LongBitSet(sz);
 
diff --git a/lucene/core/src/test/org/apache/lucene/util/TestOpenBitSet.java b/lucene/core/src/test/org/apache/lucene/util/TestOpenBitSet.java
index 5266669..13b6277 100644
--- a/lucene/core/src/test/org/apache/lucene/util/TestOpenBitSet.java
+++ b/lucene/core/src/test/org/apache/lucene/util/TestOpenBitSet.java
@@ -349,7 +349,7 @@ public class TestOpenBitSet extends BaseDocIdSetTestCase<OpenBitSet> {
     // test ensureCapacityWords
     int numWords = random().nextInt(10) + 2; // make sure we grow the array (at least 128 bits)
     bits.ensureCapacityWords(numWords);
-    bit = _TestUtil.nextInt(random(), 127, (numWords << 6)-1); // pick a bit >= to 128, but still within range
+    bit = TestUtil.nextInt(random(), 127, (numWords << 6) - 1); // pick a bit >= to 128, but still within range
     bits.fastSet(bit);
     assertTrue(bits.fastGet(bit));
     bits.fastClear(bit);
diff --git a/lucene/core/src/test/org/apache/lucene/util/TestPForDeltaDocIdSet.java b/lucene/core/src/test/org/apache/lucene/util/TestPForDeltaDocIdSet.java
index b1e847b..0439730 100644
--- a/lucene/core/src/test/org/apache/lucene/util/TestPForDeltaDocIdSet.java
+++ b/lucene/core/src/test/org/apache/lucene/util/TestPForDeltaDocIdSet.java
@@ -24,7 +24,7 @@ public class TestPForDeltaDocIdSet extends BaseDocIdSetTestCase<PForDeltaDocIdSe
 
   @Override
   public PForDeltaDocIdSet copyOf(BitSet bs, int length) throws IOException {
-    final PForDeltaDocIdSet.Builder builder = new PForDeltaDocIdSet.Builder().setIndexInterval(_TestUtil.nextInt(random(), 1, 20));
+    final PForDeltaDocIdSet.Builder builder = new PForDeltaDocIdSet.Builder().setIndexInterval(TestUtil.nextInt(random(), 1, 20));
     for (int doc = bs.nextSetBit(0); doc != -1; doc = bs.nextSetBit(doc + 1)) {
       builder.add(doc);
     }
diff --git a/lucene/core/src/test/org/apache/lucene/util/TestPagedBytes.java b/lucene/core/src/test/org/apache/lucene/util/TestPagedBytes.java
index 801f246..99d2761 100644
--- a/lucene/core/src/test/org/apache/lucene/util/TestPagedBytes.java
+++ b/lucene/core/src/test/org/apache/lucene/util/TestPagedBytes.java
@@ -37,15 +37,15 @@ public class TestPagedBytes extends LuceneTestCase {
   public void testDataInputOutput() throws Exception {
     Random random = random();
     for(int iter=0;iter<5*RANDOM_MULTIPLIER;iter++) {
-      BaseDirectoryWrapper dir = newFSDirectory(_TestUtil.getTempDir("testOverflow"));
+      BaseDirectoryWrapper dir = newFSDirectory(TestUtil.getTempDir("testOverflow"));
       if (dir instanceof MockDirectoryWrapper) {
         ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);
       }
-      final int blockBits = _TestUtil.nextInt(random, 1, 20);
+      final int blockBits = TestUtil.nextInt(random, 1, 20);
       final int blockSize = 1 << blockBits;
       final PagedBytes p = new PagedBytes(blockBits);
       final IndexOutput out = dir.createOutput("foo", IOContext.DEFAULT);
-      final int numBytes = _TestUtil.nextInt(random(), 2, 10000000);
+      final int numBytes = TestUtil.nextInt(random(), 2, 10000000);
 
       final byte[] answer = new byte[numBytes];
       random().nextBytes(answer);
@@ -100,7 +100,7 @@ public class TestPagedBytes extends LuceneTestCase {
   public void testDataInputOutput2() throws Exception {
     Random random = random();
     for(int iter=0;iter<5*RANDOM_MULTIPLIER;iter++) {
-      final int blockBits = _TestUtil.nextInt(random, 1, 20);
+      final int blockBits = TestUtil.nextInt(random, 1, 20);
       final int blockSize = 1 << blockBits;
       final PagedBytes p = new PagedBytes(blockBits);
       final DataOutput out = p.getDataOutput();
@@ -150,17 +150,17 @@ public class TestPagedBytes extends LuceneTestCase {
 
   @Ignore // memory hole
   public void testOverflow() throws IOException {
-    BaseDirectoryWrapper dir = newFSDirectory(_TestUtil.getTempDir("testOverflow"));
+    BaseDirectoryWrapper dir = newFSDirectory(TestUtil.getTempDir("testOverflow"));
     if (dir instanceof MockDirectoryWrapper) {
       ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);
     }
-    final int blockBits = _TestUtil.nextInt(random(), 14, 28);
+    final int blockBits = TestUtil.nextInt(random(), 14, 28);
     final int blockSize = 1 << blockBits;
-    byte[] arr = new byte[_TestUtil.nextInt(random(), blockSize / 2, blockSize * 2)];
+    byte[] arr = new byte[TestUtil.nextInt(random(), blockSize / 2, blockSize * 2)];
     for (int i = 0; i < arr.length; ++i) {
       arr[i] = (byte) i;
     }
-    final long numBytes = (1L << 31) + _TestUtil.nextInt(random(), 1, blockSize * 3);
+    final long numBytes = (1L << 31) + TestUtil.nextInt(random(), 1, blockSize * 3);
     final PagedBytes p = new PagedBytes(blockBits);
     final IndexOutput out = dir.createOutput("foo", IOContext.DEFAULT);
     for (long i = 0; i < numBytes; ) {
@@ -176,7 +176,7 @@ public class TestPagedBytes extends LuceneTestCase {
     final PagedBytes.Reader reader = p.freeze(random().nextBoolean());
 
     for (long offset : new long[] {0L, Integer.MAX_VALUE, numBytes - 1,
-        _TestUtil.nextLong(random(), 1, numBytes - 2)}) {
+        TestUtil.nextLong(random(), 1, numBytes - 2)}) {
       BytesRef b = new BytesRef();
       reader.fillSlice(b, offset, 1);
       assertEquals(arr[(int) (offset % arr.length)], b.bytes[b.offset]);
diff --git a/lucene/core/src/test/org/apache/lucene/util/TestTimSorter.java b/lucene/core/src/test/org/apache/lucene/util/TestTimSorter.java
index 456d36d..8037e3b 100644
--- a/lucene/core/src/test/org/apache/lucene/util/TestTimSorter.java
+++ b/lucene/core/src/test/org/apache/lucene/util/TestTimSorter.java
@@ -25,7 +25,7 @@ public class TestTimSorter extends BaseSortTestCase {
 
   @Override
   public Sorter newSorter(Entry[] arr) {
-    return new ArrayTimSorter<Entry>(arr, ArrayUtil.<Entry>naturalComparator(), _TestUtil.nextInt(random(), 0, arr.length));
+    return new ArrayTimSorter<Entry>(arr, ArrayUtil.<Entry>naturalComparator(), TestUtil.nextInt(random(), 0, arr.length));
   }
 
 }
diff --git a/lucene/core/src/test/org/apache/lucene/util/TestUnicodeUtil.java b/lucene/core/src/test/org/apache/lucene/util/TestUnicodeUtil.java
index 688469c..139c2e2 100644
--- a/lucene/core/src/test/org/apache/lucene/util/TestUnicodeUtil.java
+++ b/lucene/core/src/test/org/apache/lucene/util/TestUnicodeUtil.java
@@ -111,7 +111,7 @@ public class TestUnicodeUtil extends LuceneTestCase {
     BytesRef utf8 = new BytesRef(20);
     int num = atLeast(50000);
     for (int i = 0; i < num; i++) {
-      final String s = _TestUtil.randomUnicodeString(random());
+      final String s = TestUtil.randomUnicodeString(random());
       UnicodeUtil.UTF16toUTF8(s, 0, s.length(), utf8);
       assertEquals(s.codePointCount(0, s.length()),
                    UnicodeUtil.codePointCount(utf8));
@@ -142,7 +142,7 @@ public class TestUnicodeUtil extends LuceneTestCase {
     int[] codePoints = new int[20];
     int num = atLeast(50000);
     for (int i = 0; i < num; i++) {
-      final String s = _TestUtil.randomUnicodeString(random());
+      final String s = TestUtil.randomUnicodeString(random());
       UnicodeUtil.UTF16toUTF8(s, 0, s.length(), utf8);
       UnicodeUtil.UTF8toUTF32(utf8, utf32);
       
@@ -208,7 +208,7 @@ public class TestUnicodeUtil extends LuceneTestCase {
   public void testUTF8UTF16CharsRef() {
     int num = atLeast(3989);
     for (int i = 0; i < num; i++) {
-      String unicode = _TestUtil.randomRealisticUnicodeString(random());
+      String unicode = TestUtil.randomRealisticUnicodeString(random());
       BytesRef ref = new BytesRef(unicode);
       char[] arr = new char[1 + random().nextInt(100)];
       int offset = random().nextInt(arr.length);
diff --git a/lucene/core/src/test/org/apache/lucene/util/TestWAH8DocIdSet.java b/lucene/core/src/test/org/apache/lucene/util/TestWAH8DocIdSet.java
index 9874d97..de135db 100644
--- a/lucene/core/src/test/org/apache/lucene/util/TestWAH8DocIdSet.java
+++ b/lucene/core/src/test/org/apache/lucene/util/TestWAH8DocIdSet.java
@@ -26,7 +26,7 @@ public class TestWAH8DocIdSet extends BaseDocIdSetTestCase<WAH8DocIdSet> {
 
   @Override
   public WAH8DocIdSet copyOf(BitSet bs, int length) throws IOException {
-    final int indexInterval = _TestUtil.nextInt(random(), 8, 256);
+    final int indexInterval = TestUtil.nextInt(random(), 8, 256);
     final WAH8DocIdSet.Builder builder = new WAH8DocIdSet.Builder().setIndexInterval(indexInterval);
     for (int i = bs.nextSetBit(0); i != -1; i = bs.nextSetBit(i + 1)) {
       builder.add(i);
@@ -42,8 +42,8 @@ public class TestWAH8DocIdSet extends BaseDocIdSetTestCase<WAH8DocIdSet> {
   }
 
   public void testUnion() throws IOException {
-    final int numBits = _TestUtil.nextInt(random(), 100, 1 << 20);
-    final int numDocIdSets = _TestUtil.nextInt(random(), 0, 4);
+    final int numBits = TestUtil.nextInt(random(), 100, 1 << 20);
+    final int numDocIdSets = TestUtil.nextInt(random(), 0, 4);
     final List<BitSet> fixedSets = new ArrayList<BitSet>(numDocIdSets);
     for (int i = 0; i < numDocIdSets; ++i) {
       fixedSets.add(randomSet(numBits, random().nextFloat() / 16));
@@ -64,8 +64,8 @@ public class TestWAH8DocIdSet extends BaseDocIdSetTestCase<WAH8DocIdSet> {
   }
 
   public void testIntersection() throws IOException {
-    final int numBits = _TestUtil.nextInt(random(), 100, 1 << 20);
-    final int numDocIdSets = _TestUtil.nextInt(random(), 1, 4);
+    final int numBits = TestUtil.nextInt(random(), 100, 1 << 20);
+    final int numDocIdSets = TestUtil.nextInt(random(), 1, 4);
     final List<BitSet> fixedSets = new ArrayList<BitSet>(numDocIdSets);
     for (int i = 0; i < numDocIdSets; ++i) {
       fixedSets.add(randomSet(numBits, random().nextFloat()));
diff --git a/lucene/core/src/test/org/apache/lucene/util/automaton/TestBasicOperations.java b/lucene/core/src/test/org/apache/lucene/util/automaton/TestBasicOperations.java
index b209201..622aa9d 100644
--- a/lucene/core/src/test/org/apache/lucene/util/automaton/TestBasicOperations.java
+++ b/lucene/core/src/test/org/apache/lucene/util/automaton/TestBasicOperations.java
@@ -28,7 +28,7 @@ public class TestBasicOperations extends LuceneTestCase {
   public void testStringUnion() {
     List<BytesRef> strings = new ArrayList<BytesRef>();
     for (int i = RandomInts.randomIntBetween(random(), 0, 1000); --i >= 0;) {
-      strings.add(new BytesRef(_TestUtil.randomUnicodeString(random())));
+      strings.add(new BytesRef(TestUtil.randomUnicodeString(random())));
     }
 
     Collections.sort(strings);
diff --git a/lucene/core/src/test/org/apache/lucene/util/automaton/TestCompiledAutomaton.java b/lucene/core/src/test/org/apache/lucene/util/automaton/TestCompiledAutomaton.java
index ae27033..b45ee8f 100644
--- a/lucene/core/src/test/org/apache/lucene/util/automaton/TestCompiledAutomaton.java
+++ b/lucene/core/src/test/org/apache/lucene/util/automaton/TestCompiledAutomaton.java
@@ -26,7 +26,7 @@ import java.util.Set;
 
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestCompiledAutomaton extends LuceneTestCase {
 
@@ -104,7 +104,7 @@ public class TestCompiledAutomaton extends LuceneTestCase {
 
   private String randomString() {
     // return _TestUtil.randomSimpleString(random);
-    return _TestUtil.randomRealisticUnicodeString(random());
+    return TestUtil.randomRealisticUnicodeString(random());
   }
 
   public void testBasic() throws Exception {
diff --git a/lucene/core/src/test/org/apache/lucene/util/automaton/TestDeterminizeLexicon.java b/lucene/core/src/test/org/apache/lucene/util/automaton/TestDeterminizeLexicon.java
index 69e0946..1bf01e7 100644
--- a/lucene/core/src/test/org/apache/lucene/util/automaton/TestDeterminizeLexicon.java
+++ b/lucene/core/src/test/org/apache/lucene/util/automaton/TestDeterminizeLexicon.java
@@ -22,7 +22,7 @@ import java.util.Collections;
 import java.util.List;
 
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Not thorough, but tries to test determinism correctness
@@ -38,7 +38,7 @@ public class TestDeterminizeLexicon extends LuceneTestCase {
       automata.clear();
       terms.clear();
       for (int j = 0; j < 5000; j++) {
-        String randomString = _TestUtil.randomUnicodeString(random());
+        String randomString = TestUtil.randomUnicodeString(random());
         terms.add(randomString);
         automata.add(BasicAutomata.makeString(randomString));
       }
diff --git a/lucene/core/src/test/org/apache/lucene/util/automaton/TestUTF32ToUTF8.java b/lucene/core/src/test/org/apache/lucene/util/automaton/TestUTF32ToUTF8.java
index eeff261..68c75a1 100644
--- a/lucene/core/src/test/org/apache/lucene/util/automaton/TestUTF32ToUTF8.java
+++ b/lucene/core/src/test/org/apache/lucene/util/automaton/TestUTF32ToUTF8.java
@@ -18,7 +18,7 @@ package org.apache.lucene.util.automaton;
  */
 
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.UnicodeUtil;
 
@@ -90,7 +90,7 @@ public class TestUTF32ToUTF8 extends LuceneTestCase {
     final int invalidRange = MAX_UNICODE - (endCode - startCode + 1);
     if (invalidRange > 0) {
       for(int iter=0;iter<iters;iter++) {
-        int x = _TestUtil.nextInt(r, 0, invalidRange-1);
+        int x = TestUtil.nextInt(r, 0, invalidRange - 1);
         final int code;
         if (x >= startCode) {
           code = endCode + 1 + x - startCode;
@@ -114,13 +114,13 @@ public class TestUTF32ToUTF8 extends LuceneTestCase {
   private int getCodeStart(Random r) {
     switch(r.nextInt(4)) {
     case 0:
-      return _TestUtil.nextInt(r, 0, 128);
+      return TestUtil.nextInt(r, 0, 128);
     case 1:
-      return _TestUtil.nextInt(r, 128, 2048);
+      return TestUtil.nextInt(r, 128, 2048);
     case 2:
-      return _TestUtil.nextInt(r, 2048, 65536);
+      return TestUtil.nextInt(r, 2048, 65536);
     default:
-      return _TestUtil.nextInt(r, 65536, 1+MAX_UNICODE);
+      return TestUtil.nextInt(r, 65536, 1 + MAX_UNICODE);
     }
   }
 
@@ -218,7 +218,7 @@ public class TestUTF32ToUTF8 extends LuceneTestCase {
       final String string;
       if (random().nextBoolean()) {
         // likely not accepted
-        string = _TestUtil.randomUnicodeString(random());
+        string = TestUtil.randomUnicodeString(random());
       } else {
         // will be accepted
         int[] codepoints = ras.getRandomAcceptedString(random());
diff --git a/lucene/core/src/test/org/apache/lucene/util/fst/Test2BFST.java b/lucene/core/src/test/org/apache/lucene/util/fst/Test2BFST.java
index a149ed6..21feb91 100644
--- a/lucene/core/src/test/org/apache/lucene/util/fst/Test2BFST.java
+++ b/lucene/core/src/test/org/apache/lucene/util/fst/Test2BFST.java
@@ -28,8 +28,8 @@ import org.apache.lucene.store.MMapDirectory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IntsRef;
 import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.TimeUnits;
-import org.apache.lucene.util._TestUtil;
 import org.apache.lucene.util.packed.PackedInts;
 import org.junit.Ignore;
 import com.carrotsearch.randomizedtesting.annotations.TimeoutSuite;
@@ -45,7 +45,7 @@ public class Test2BFST extends LuceneTestCase {
     IntsRef input = new IntsRef(ints, 0, ints.length);
     long seed = random().nextLong();
 
-    Directory dir = new MMapDirectory(_TestUtil.getTempDir("2BFST"));
+    Directory dir = new MMapDirectory(TestUtil.getTempDir("2BFST"));
 
     for(int doPackIter=0;doPackIter<2;doPackIter++) {
       boolean doPack = doPackIter == 1;
diff --git a/lucene/core/src/test/org/apache/lucene/util/fst/TestBytesStore.java b/lucene/core/src/test/org/apache/lucene/util/fst/TestBytesStore.java
index 7b598ed..390bef8 100644
--- a/lucene/core/src/test/org/apache/lucene/util/fst/TestBytesStore.java
+++ b/lucene/core/src/test/org/apache/lucene/util/fst/TestBytesStore.java
@@ -24,7 +24,7 @@ import org.apache.lucene.store.IOContext;
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.store.IndexOutput;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestBytesStore extends LuceneTestCase {
 
@@ -32,9 +32,9 @@ public class TestBytesStore extends LuceneTestCase {
 
     final int iters = atLeast(10);
     for(int iter=0;iter<iters;iter++) {
-      final int numBytes = _TestUtil.nextInt(random(), 1, 200000);
+      final int numBytes = TestUtil.nextInt(random(), 1, 200000);
       final byte[] expected = new byte[numBytes];
-      final int blockBits = _TestUtil.nextInt(random(), 8, 15);
+      final int blockBits = TestUtil.nextInt(random(), 8, 15);
       final BytesStore bytes = new BytesStore(blockBits);
       if (VERBOSE) {
         System.out.println("TEST: iter=" + iter + " numBytes=" + numBytes + " blockBits=" + blockBits);
@@ -98,7 +98,7 @@ public class TestBytesStore extends LuceneTestCase {
           {
             // reverse bytes
             if (pos > 1) {
-              int len = _TestUtil.nextInt(random(), 2, Math.min(100, pos));
+              int len = TestUtil.nextInt(random(), 2, Math.min(100, pos));
               int start;
               if (len == pos) {
                 start = 0;
@@ -127,7 +127,7 @@ public class TestBytesStore extends LuceneTestCase {
             // abs write random byte[]
             if (pos > 2) {
               int randomPos = random().nextInt(pos-1);
-              int len = _TestUtil.nextInt(random(), 1, Math.min(pos - randomPos - 1, 100));
+              int len = TestUtil.nextInt(random(), 1, Math.min(pos - randomPos - 1, 100));
               byte[] temp = new byte[len];
               random().nextBytes(temp);
               if (VERBOSE) {
@@ -144,8 +144,8 @@ public class TestBytesStore extends LuceneTestCase {
             // copyBytes
             if (pos > 1) {
               int src = random().nextInt(pos-1);
-              int dest = _TestUtil.nextInt(random(), src+1, pos-1);
-              int len = _TestUtil.nextInt(random(), 1, Math.min(300, pos - dest));
+              int dest = TestUtil.nextInt(random(), src + 1, pos - 1);
+              int len = TestUtil.nextInt(random(), 1, Math.min(300, pos - dest));
               if (VERBOSE) {
                 System.out.println("    copyBytes src=" + src + " dest=" + dest + " len=" + len);
               }
@@ -193,7 +193,7 @@ public class TestBytesStore extends LuceneTestCase {
 
         if (pos > 0 && random().nextInt(50) == 17) {
           // truncate
-          int len = _TestUtil.nextInt(random(), 1, Math.min(pos, 100));
+          int len = TestUtil.nextInt(random(), 1, Math.min(pos, 100));
           bytes.truncate(pos - len);
           pos -= len;
           Arrays.fill(expected, pos, pos+len, (byte) 0);
@@ -218,7 +218,7 @@ public class TestBytesStore extends LuceneTestCase {
         bytes.writeTo(out);
         out.close();
         IndexInput in = dir.openInput("bytes", IOContext.DEFAULT);
-        bytesToVerify = new BytesStore(in, numBytes, _TestUtil.nextInt(random(), 256, Integer.MAX_VALUE));
+        bytesToVerify = new BytesStore(in, numBytes, TestUtil.nextInt(random(), 256, Integer.MAX_VALUE));
         in.close();
         dir.close();
       } else {
@@ -289,13 +289,13 @@ public class TestBytesStore extends LuceneTestCase {
     }
 
     if (totalLength > 1) {
-      int numOps = _TestUtil.nextInt(random(), 100, 200);
+      int numOps = TestUtil.nextInt(random(), 100, 200);
       for(int op=0;op<numOps;op++) {
 
         int numBytes = random().nextInt(Math.min(1000, totalLength-1));
         int pos;
         if (reversed) {
-          pos = _TestUtil.nextInt(random(), numBytes, totalLength-1);
+          pos = TestUtil.nextInt(random(), numBytes, totalLength - 1);
         } else {
           pos = random().nextInt(totalLength-numBytes);
         }
diff --git a/lucene/core/src/test/org/apache/lucene/util/fst/TestFSTs.java b/lucene/core/src/test/org/apache/lucene/util/fst/TestFSTs.java
index 215443f..0da4c79 100644
--- a/lucene/core/src/test/org/apache/lucene/util/fst/TestFSTs.java
+++ b/lucene/core/src/test/org/apache/lucene/util/fst/TestFSTs.java
@@ -54,7 +54,7 @@ import org.apache.lucene.util.LineFileDocs;
 import org.apache.lucene.util.LuceneTestCase.Slow;
 import org.apache.lucene.util.LuceneTestCase.SuppressCodecs;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.automaton.Automaton;
 import org.apache.lucene.util.automaton.CompiledAutomaton;
 import org.apache.lucene.util.automaton.RegExp;
@@ -185,7 +185,7 @@ public class TestFSTs extends LuceneTestCase {
       final List<FSTTester.InputOutput<Long>> pairs = new ArrayList<FSTTester.InputOutput<Long>>(terms.length);
       long lastOutput = 0;
       for(int idx=0;idx<terms.length;idx++) {
-        final long value = lastOutput + _TestUtil.nextInt(random(), 1, 1000);
+        final long value = lastOutput + TestUtil.nextInt(random(), 1, 1000);
         lastOutput = value;
         pairs.add(new FSTTester.InputOutput<Long>(terms[idx], value));
       }
@@ -197,7 +197,7 @@ public class TestFSTs extends LuceneTestCase {
       final PositiveIntOutputs outputs = PositiveIntOutputs.getSingleton();
       final List<FSTTester.InputOutput<Long>> pairs = new ArrayList<FSTTester.InputOutput<Long>>(terms.length);
       for(int idx=0;idx<terms.length;idx++) {
-        pairs.add(new FSTTester.InputOutput<Long>(terms[idx], _TestUtil.nextLong(random(), 0, Long.MAX_VALUE)));
+        pairs.add(new FSTTester.InputOutput<Long>(terms[idx], TestUtil.nextLong(random(), 0, Long.MAX_VALUE)));
       }
       new FSTTester<Long>(random(), dir, inputMode, pairs, outputs, false).doTest(true);
     }
@@ -210,7 +210,7 @@ public class TestFSTs extends LuceneTestCase {
       final List<FSTTester.InputOutput<PairOutputs.Pair<Long,Long>>> pairs = new ArrayList<FSTTester.InputOutput<PairOutputs.Pair<Long,Long>>>(terms.length);
       long lastOutput = 0;
       for(int idx=0;idx<terms.length;idx++) {
-        final long value = lastOutput + _TestUtil.nextInt(random(), 1, 1000);
+        final long value = lastOutput + TestUtil.nextInt(random(), 1, 1000);
         lastOutput = value;
         pairs.add(new FSTTester.InputOutput<PairOutputs.Pair<Long,Long>>(terms[idx],
                                                                          outputs.newPair((long) idx, value)));
@@ -283,7 +283,7 @@ public class TestFSTs extends LuceneTestCase {
 
   @Nightly
   public void testBigSet() throws IOException {
-    testRandomWords(_TestUtil.nextInt(random(), 50000, 60000), 1);
+    testRandomWords(TestUtil.nextInt(random(), 50000, 60000), 1);
   }
   
   // Build FST for all unique terms in the test line docs
@@ -293,7 +293,7 @@ public class TestFSTs extends LuceneTestCase {
     final LineFileDocs docs = new LineFileDocs(random(), true);
     final int RUN_TIME_MSEC = atLeast(500);
     final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(-1).setRAMBufferSizeMB(64);
-    final File tempDir = _TestUtil.getTempDir("fstlines");
+    final File tempDir = TestUtil.getTempDir("fstlines");
     final Directory dir = newFSDirectory(tempDir);
     final IndexWriter writer = new IndexWriter(dir, conf);
     final long stopTime = System.currentTimeMillis() + RUN_TIME_MSEC;
@@ -663,7 +663,7 @@ public class TestFSTs extends LuceneTestCase {
             rand = new Random(17);
           }
           return outputs.newPair((long) ord,
-                                 (long) _TestUtil.nextInt(rand, 1, 5000));
+                                 (long) TestUtil.nextInt(rand, 1, 5000));
         }
       }.run(limit, verify, false);
     } else if (storeOrds) {
@@ -685,7 +685,7 @@ public class TestFSTs extends LuceneTestCase {
           if (ord == 0) {
             rand = new Random(17);
           }
-          return (long) _TestUtil.nextInt(rand, 1, 5000);
+          return (long) TestUtil.nextInt(rand, 1, 5000);
         }
       }.run(limit, verify, false);
     } else {
@@ -1302,7 +1302,7 @@ public class TestFSTs extends LuceneTestCase {
     for (int i = 0; i < numWords; i++) {
       String s;
       while (true) {
-        s = _TestUtil.randomSimpleString(random);
+        s = TestUtil.randomSimpleString(random);
         if (!slowCompletor.containsKey(s)) {
           break;
         }
@@ -1311,7 +1311,7 @@ public class TestFSTs extends LuceneTestCase {
       for (int j = 1; j < s.length(); j++) {
         allPrefixes.add(s.substring(0, j));
       }
-      int weight = _TestUtil.nextInt(random, 1, 100); // weights 1..100
+      int weight = TestUtil.nextInt(random, 1, 100); // weights 1..100
       slowCompletor.put(s, (long)weight);
     }
     
@@ -1342,7 +1342,7 @@ public class TestFSTs extends LuceneTestCase {
         prefixOutput += arc.output;
       }
 
-      final int topN = _TestUtil.nextInt(random, 1, 10);
+      final int topN = TestUtil.nextInt(random, 1, 10);
 
       Util.MinResult<Long>[] r = Util.shortestPaths(fst, arc, fst.outputs.getNoOutput(), minLongComparator, topN, true);
 
@@ -1420,7 +1420,7 @@ public class TestFSTs extends LuceneTestCase {
     for (int i = 0; i < numWords; i++) {
       String s;
       while (true) {
-        s = _TestUtil.randomSimpleString(random);
+        s = TestUtil.randomSimpleString(random);
         if (!slowCompletor.containsKey(s)) {
           break;
         }
@@ -1429,8 +1429,8 @@ public class TestFSTs extends LuceneTestCase {
       for (int j = 1; j < s.length(); j++) {
         allPrefixes.add(s.substring(0, j));
       }
-      int weight = _TestUtil.nextInt(random, 1, 100); // weights 1..100
-      int output = _TestUtil.nextInt(random, 0, 500); // outputs 0..500 
+      int weight = TestUtil.nextInt(random, 1, 100); // weights 1..100
+      int output = TestUtil.nextInt(random, 0, 500); // outputs 0..500
       slowCompletor.put(s, new TwoLongs(weight, output));
     }
     
@@ -1463,7 +1463,7 @@ public class TestFSTs extends LuceneTestCase {
         prefixOutput = outputs.add(prefixOutput, arc.output);
       }
 
-      final int topN = _TestUtil.nextInt(random, 1, 10);
+      final int topN = TestUtil.nextInt(random, 1, 10);
 
       Util.MinResult<Pair<Long,Long>>[] r = Util.shortestPaths(fst, arc, fst.outputs.getNoOutput(), minPairWeightComparator, topN, true);
 
diff --git a/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestLeaveFilesIfTestFails.java b/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestLeaveFilesIfTestFails.java
index e749b29..9e9c739 100644
--- a/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestLeaveFilesIfTestFails.java
+++ b/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestLeaveFilesIfTestFails.java
@@ -19,7 +19,7 @@ package org.apache.lucene.util.junitcompat;
 
 import java.io.File;
 
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.Assert;
 import org.junit.Test;
 import org.junit.runner.JUnitCore;
@@ -33,7 +33,7 @@ public class TestLeaveFilesIfTestFails extends WithNestedTests {
   public static class Nested1 extends WithNestedTests.AbstractNestedTest {
     static File file;
     public void testDummy() {
-      file = _TestUtil.getTempDir("leftover");
+      file = TestUtil.getTempDir("leftover");
       file.mkdirs();
       fail();
     }
diff --git a/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestSameRandomnessLocalePassedOrNot.java b/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestSameRandomnessLocalePassedOrNot.java
index 191348d..de92566 100644
--- a/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestSameRandomnessLocalePassedOrNot.java
+++ b/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestSameRandomnessLocalePassedOrNot.java
@@ -2,7 +2,7 @@ package org.apache.lucene.util.junitcompat;
 
 import java.util.*;
 
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.*;
 import org.junit.rules.RuleChain;
 import org.junit.rules.TestRule;
@@ -53,7 +53,7 @@ public class TestSameRandomnessLocalePassedOrNot extends WithNestedTests {
       seed = RandomizedContext.current().getRunnerSeedAsString();
 
       Random rnd = random();
-      pickString = _TestUtil.randomSimpleString(rnd);
+      pickString = TestUtil.randomSimpleString(rnd);
       
       defaultLocale = Locale.getDefault();
       defaultTimeZone = TimeZone.getDefault();
diff --git a/lucene/core/src/test/org/apache/lucene/util/packed/TestPackedInts.java b/lucene/core/src/test/org/apache/lucene/util/packed/TestPackedInts.java
index fc85914..d997f38 100644
--- a/lucene/core/src/test/org/apache/lucene/util/packed/TestPackedInts.java
+++ b/lucene/core/src/test/org/apache/lucene/util/packed/TestPackedInts.java
@@ -38,7 +38,7 @@ import org.apache.lucene.util.LongsRef;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.LuceneTestCase.Slow;
 import org.apache.lucene.util.RamUsageEstimator;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.packed.PackedInts.Reader;
 import org.junit.Ignore;
 
@@ -89,10 +89,10 @@ public class TestPackedInts extends LuceneTestCase {
     for (int iter = 0; iter < num; iter++) {
       for(int nbits=1;nbits<=64;nbits++) {
         final long maxValue = PackedInts.maxValue(nbits);
-        final int valueCount = _TestUtil.nextInt(random(), 1, 600);
+        final int valueCount = TestUtil.nextInt(random(), 1, 600);
         final int bufferSize = random().nextBoolean()
-            ? _TestUtil.nextInt(random(), 0, 48)
-            : _TestUtil.nextInt(random(), 0, 4096);
+            ? TestUtil.nextInt(random(), 0, 48)
+            : TestUtil.nextInt(random(), 0, 4096);
         final Directory d = newDirectory();
         
         IndexOutput out = d.createOutput("out.bin", newIOContext(random()));
@@ -106,13 +106,13 @@ public class TestPackedInts extends LuceneTestCase {
         PackedInts.Writer w = PackedInts.getWriter(out, valueCount, nbits, acceptableOverhead);
         final long startFp = out.getFilePointer();
 
-        final int actualValueCount = random().nextBoolean() ? valueCount : _TestUtil.nextInt(random(), 0, valueCount);
+        final int actualValueCount = random().nextBoolean() ? valueCount : TestUtil.nextInt(random(), 0, valueCount);
         final long[] values = new long[valueCount];
         for(int i=0;i<actualValueCount;i++) {
           if (nbits == 64) {
             values[i] = random().nextLong();
           } else {
-            values[i] = _TestUtil.nextLong(random(), 0, maxValue);
+            values[i] = TestUtil.nextLong(random(), 0, maxValue);
           }
           w.add(values[i]);
         }
@@ -170,7 +170,7 @@ public class TestPackedInts extends LuceneTestCase {
           PackedInts.ReaderIterator r = PackedInts.getReaderIterator(in, bufferSize);
           int i = 0;
           while (i < valueCount) {
-            final int count = _TestUtil.nextInt(random(), 1, 95);
+            final int count = TestUtil.nextInt(random(), 1, 95);
             final LongsRef next = r.next(count);
             for (int k = 0; k < next.length; ++k) {
               assertEquals("index=" + i + " valueCount="
@@ -266,8 +266,8 @@ public class TestPackedInts extends LuceneTestCase {
         System.out.println("\nTEST: iter=" + iter);
       }
       final int valueCount = atLeast(100000);
-      int bits1 = _TestUtil.nextInt(random(), 1, 64);
-      int bits2 = _TestUtil.nextInt(random(), 1, 64);
+      int bits1 = TestUtil.nextInt(random(), 1, 64);
+      int bits2 = TestUtil.nextInt(random(), 1, 64);
       if (bits1 > bits2) {
         int tmp = bits1;
         bits1 = bits2;
@@ -282,7 +282,7 @@ public class TestPackedInts extends LuceneTestCase {
 
       final long maxValue = PackedInts.maxValue(bits1);
       for(int i=0;i<valueCount;i++) {
-        final long val = _TestUtil.nextLong(random(), 0, maxValue);
+        final long val = TestUtil.nextLong(random(), 0, maxValue);
         packed1.set(i, val);
         packed2.set(i, val);
       }
@@ -292,7 +292,7 @@ public class TestPackedInts extends LuceneTestCase {
       // Copy random slice over, 20 times:
       for(int iter2=0;iter2<20;iter2++) {
         int start = random().nextInt(valueCount-1);
-        int len = _TestUtil.nextInt(random(), 1, valueCount-start);
+        int len = TestUtil.nextInt(random(), 1, valueCount - start);
         int offset;
         if (VERBOSE) {
           System.out.println("  copy " + len + " values @ " + start);
@@ -327,7 +327,7 @@ public class TestPackedInts extends LuceneTestCase {
   public void testRandomEquality() {
     final int numIters = atLeast(2);
     for (int i = 0; i < numIters; ++i) {
-      final int valueCount = _TestUtil.nextInt(random(), 1, 300);
+      final int valueCount = TestUtil.nextInt(random(), 1, 300);
 
       for (int bitsPerValue = 1 ;
            bitsPerValue <= 64 ;
@@ -386,7 +386,7 @@ public class TestPackedInts extends LuceneTestCase {
   private static void fill(PackedInts.Mutable packedInt, long maxValue, long randomSeed) {
     Random rnd2 = new Random(randomSeed);
     for (int i = 0 ; i < packedInt.size() ; i++) {
-      long value = _TestUtil.nextLong(rnd2, 0, maxValue);
+      long value = TestUtil.nextLong(rnd2, 0, maxValue);
       packedInt.set(i, value);
       assertEquals(String.format(Locale.ROOT,
               "The set/get of the value at index %d should match for %s",
@@ -528,7 +528,7 @@ public class TestPackedInts extends LuceneTestCase {
     final int from = random().nextInt(valueCount + 1);
     final int to = from + random().nextInt(valueCount + 1 - from);
     for (int bpv = 1; bpv <= 64; ++bpv) {
-      final long val = _TestUtil.nextLong(random(), 0, PackedInts.maxValue(bpv));
+      final long val = TestUtil.nextLong(random(), 0, PackedInts.maxValue(bpv));
       List<PackedInts.Mutable> packedInts = createPackedInts(valueCount, bpv);
       for (PackedInts.Mutable ints : packedInts) {
         String msg = ints.getClass().getSimpleName() + " bpv=" + bpv + ", from=" + from + ", to=" + to + ", val=" + val;
@@ -547,9 +547,9 @@ public class TestPackedInts extends LuceneTestCase {
 
   public void testPackedIntsNull() {
     // must be > 10 for the bulk reads below
-    int size = _TestUtil.nextInt(random(), 11, 256);
+    int size = TestUtil.nextInt(random(), 11, 256);
     Reader packedInts = new PackedInts.NullReader(size);
-    assertEquals(0, packedInts.get(_TestUtil.nextInt(random(), 0, size - 1)));
+    assertEquals(0, packedInts.get(TestUtil.nextInt(random(), 0, size - 1)));
     long[] arr = new long[size + 10];
     int r;
     Arrays.fill(arr, 1);
@@ -570,7 +570,7 @@ public class TestPackedInts extends LuceneTestCase {
   public void testBulkGet() {
     final int valueCount = 1111;
     final int index = random().nextInt(valueCount);
-    final int len = _TestUtil.nextInt(random(), 1, valueCount * 2);
+    final int len = TestUtil.nextInt(random(), 1, valueCount * 2);
     final int off = random().nextInt(77);
 
     for (int bpv = 1; bpv <= 64; ++bpv) {
@@ -605,7 +605,7 @@ public class TestPackedInts extends LuceneTestCase {
   public void testBulkSet() {
     final int valueCount = 1111;
     final int index = random().nextInt(valueCount);
-    final int len = _TestUtil.nextInt(random(), 1, valueCount * 2);
+    final int len = TestUtil.nextInt(random(), 1, valueCount * 2);
     final int off = random().nextInt(77);
     long[] arr = new long[off+len];
 
@@ -636,7 +636,7 @@ public class TestPackedInts extends LuceneTestCase {
   }
 
   public void testCopy() {
-    final int valueCount = _TestUtil.nextInt(random(), 5, 600);
+    final int valueCount = TestUtil.nextInt(random(), 5, 600);
     final int off1 = random().nextInt(valueCount);
     final int off2 = random().nextInt(valueCount);
     final int len = random().nextInt(Math.min(valueCount - off1, valueCount - off2));
@@ -691,9 +691,9 @@ public class TestPackedInts extends LuceneTestCase {
   }
 
   public void testPagedGrowableWriter() {
-    int pageSize = 1 << (_TestUtil.nextInt(random(), 6, 30));
+    int pageSize = 1 << (TestUtil.nextInt(random(), 6, 30));
     // supports 0 values?
-    PagedGrowableWriter writer = new PagedGrowableWriter(0, pageSize, _TestUtil.nextInt(random(), 1, 64), random().nextFloat());
+    PagedGrowableWriter writer = new PagedGrowableWriter(0, pageSize, TestUtil.nextInt(random(), 1, 64), random().nextFloat());
     assertEquals(0, writer.size());
 
     // compare against AppendingDeltaPackedLongBuffer
@@ -701,12 +701,12 @@ public class TestPackedInts extends LuceneTestCase {
     int size = random().nextInt(1000000);
     long max = 5;
     for (int i = 0; i < size; ++i) {
-      buf.add(_TestUtil.nextLong(random(), 0, max));
+      buf.add(TestUtil.nextLong(random(), 0, max));
       if (rarely()) {
-        max = PackedInts.maxValue(rarely() ? _TestUtil.nextInt(random(), 0, 63) : _TestUtil.nextInt(random(), 0, 31));
+        max = PackedInts.maxValue(rarely() ? TestUtil.nextInt(random(), 0, 63) : TestUtil.nextInt(random(), 0, 31));
       }
     }
-    writer = new PagedGrowableWriter(size, pageSize, _TestUtil.nextInt(random(), 1, 64), random().nextFloat());
+    writer = new PagedGrowableWriter(size, pageSize, TestUtil.nextInt(random(), 1, 64), random().nextFloat());
     assertEquals(size, writer.size());
     for (int i = size - 1; i >= 0; --i) {
       writer.set(i, buf.get(i));
@@ -719,7 +719,7 @@ public class TestPackedInts extends LuceneTestCase {
     assertEquals(RamUsageEstimator.sizeOf(writer), writer.ramBytesUsed(), 8);
 
     // test copy
-    PagedGrowableWriter copy = writer.resize(_TestUtil.nextLong(random(), writer.size() / 2, writer.size() * 3 / 2));
+    PagedGrowableWriter copy = writer.resize(TestUtil.nextLong(random(), writer.size() / 2, writer.size() * 3 / 2));
     for (long i = 0; i < copy.size(); ++i) {
       if (i < writer.size()) {
         assertEquals(writer.get(i), copy.get(i));
@@ -729,7 +729,7 @@ public class TestPackedInts extends LuceneTestCase {
     }
 
     // test grow
-    PagedGrowableWriter grow = writer.grow(_TestUtil.nextLong(random(), writer.size() / 2, writer.size() * 3 / 2));
+    PagedGrowableWriter grow = writer.grow(TestUtil.nextLong(random(), writer.size() / 2, writer.size() * 3 / 2));
     for (long i = 0; i < grow.size(); ++i) {
       if (i < writer.size()) {
         assertEquals(writer.get(i), grow.get(i));
@@ -740,9 +740,9 @@ public class TestPackedInts extends LuceneTestCase {
   }
 
   public void testPagedMutable() {
-    final int bitsPerValue = _TestUtil.nextInt(random(), 1, 64);
+    final int bitsPerValue = TestUtil.nextInt(random(), 1, 64);
     final long max = PackedInts.maxValue(bitsPerValue);
-    int pageSize = 1 << (_TestUtil.nextInt(random(), 6, 30));
+    int pageSize = 1 << (TestUtil.nextInt(random(), 6, 30));
     // supports 0 values?
     PagedMutable writer = new PagedMutable(0, pageSize, bitsPerValue, random().nextFloat() / 2);
     assertEquals(0, writer.size());
@@ -752,7 +752,7 @@ public class TestPackedInts extends LuceneTestCase {
     int size = random().nextInt(1000000);
     
     for (int i = 0; i < size; ++i) {
-      buf.add(bitsPerValue == 64 ? random().nextLong() : _TestUtil.nextLong(random(), 0, max));
+      buf.add(bitsPerValue == 64 ? random().nextLong() : TestUtil.nextLong(random(), 0, max));
     }
     writer = new PagedMutable(size, pageSize, bitsPerValue, random().nextFloat());
     assertEquals(size, writer.size());
@@ -767,7 +767,7 @@ public class TestPackedInts extends LuceneTestCase {
     assertEquals(RamUsageEstimator.sizeOf(writer) - RamUsageEstimator.sizeOf(writer.format), writer.ramBytesUsed());
 
     // test copy
-    PagedMutable copy = writer.resize(_TestUtil.nextLong(random(), writer.size() / 2, writer.size() * 3 / 2));
+    PagedMutable copy = writer.resize(TestUtil.nextLong(random(), writer.size() / 2, writer.size() * 3 / 2));
     for (long i = 0; i < copy.size(); ++i) {
       if (i < writer.size()) {
         assertEquals(writer.get(i), copy.get(i));
@@ -777,7 +777,7 @@ public class TestPackedInts extends LuceneTestCase {
     }
 
     // test grow
-    PagedMutable grow = writer.grow(_TestUtil.nextLong(random(), writer.size() / 2, writer.size() * 3 / 2));
+    PagedMutable grow = writer.grow(TestUtil.nextLong(random(), writer.size() / 2, writer.size() * 3 / 2));
     for (long i = 0; i < grow.size(); ++i) {
       if (i < writer.size()) {
         assertEquals(writer.get(i), grow.get(i));
@@ -790,14 +790,14 @@ public class TestPackedInts extends LuceneTestCase {
   // memory hole
   @Ignore
   public void testPagedGrowableWriterOverflow() {
-    final long size = _TestUtil.nextLong(random(), 2 * (long) Integer.MAX_VALUE, 3 * (long) Integer.MAX_VALUE);
-    final int pageSize = 1 << (_TestUtil.nextInt(random(), 16, 30));
+    final long size = TestUtil.nextLong(random(), 2 * (long) Integer.MAX_VALUE, 3 * (long) Integer.MAX_VALUE);
+    final int pageSize = 1 << (TestUtil.nextInt(random(), 16, 30));
     final PagedGrowableWriter writer = new PagedGrowableWriter(size, pageSize, 1, random().nextFloat());
-    final long index = _TestUtil.nextLong(random(), (long) Integer.MAX_VALUE, size - 1);
+    final long index = TestUtil.nextLong(random(), (long) Integer.MAX_VALUE, size - 1);
     writer.set(index, 2);
     assertEquals(2, writer.get(index));
     for (int i = 0; i < 1000000; ++i) {
-      final long idx = _TestUtil.nextLong(random(), 0, size);
+      final long idx = TestUtil.nextLong(random(), 0, size);
       if (idx == index) {
         assertEquals(2, writer.get(idx));
       } else {
@@ -807,7 +807,7 @@ public class TestPackedInts extends LuceneTestCase {
   }
 
   public void testSave() throws IOException {
-    final int valueCount = _TestUtil.nextInt(random(), 1, 2048);
+    final int valueCount = TestUtil.nextInt(random(), 1, 2048);
     for (int bpv = 1; bpv <= 64; ++bpv) {
       final int maxValue = (int) Math.min(PackedInts.maxValue(31), PackedInts.maxValue(bpv));
       final RAMDirectory directory = new RAMDirectory();
@@ -964,9 +964,9 @@ public class TestPackedInts extends LuceneTestCase {
     float[] ratioOptions = new float[]{PackedInts.DEFAULT, PackedInts.COMPACT, PackedInts.FAST};
     for (int bpv : new int[]{0, 1, 63, 64, RandomInts.randomIntBetween(random(), 2, 62)}) {
       for (DataType dataType : DataType.values()) {
-        final int pageSize = 1 << _TestUtil.nextInt(random(), 6, 20);
-        final int initialPageCount = _TestUtil.nextInt(random(), 0, 16);
-        float acceptableOverheadRatio = ratioOptions[_TestUtil.nextInt(random(), 0, ratioOptions.length - 1)];
+        final int pageSize = 1 << TestUtil.nextInt(random(), 6, 20);
+        final int initialPageCount = TestUtil.nextInt(random(), 0, 16);
+        float acceptableOverheadRatio = ratioOptions[TestUtil.nextInt(random(), 0, ratioOptions.length - 1)];
         AbstractAppendingLongBuffer buf;
         final int inc;
         switch (dataType) {
@@ -980,7 +980,7 @@ public class TestPackedInts extends LuceneTestCase {
             break;
           case MONOTONIC:
             buf = new MonotonicAppendingLongBuffer(initialPageCount, pageSize, acceptableOverheadRatio);
-            inc = _TestUtil.nextInt(random(), -1000, 1000);
+            inc = TestUtil.nextInt(random(), -1000, 1000);
             break;
           default:
             throw new RuntimeException("added a type and forgot to add it here?");
@@ -997,7 +997,7 @@ public class TestPackedInts extends LuceneTestCase {
             arr[i] = random().nextLong();
           }
         } else {
-          final long minValue = _TestUtil.nextLong(random(), Long.MIN_VALUE, Long.MAX_VALUE - PackedInts.maxValue(bpv));
+          final long minValue = TestUtil.nextLong(random(), Long.MIN_VALUE, Long.MAX_VALUE - PackedInts.maxValue(bpv));
           for (int i = 0; i < arr.length; ++i) {
             arr[i] = minValue + inc * i + random().nextLong() & PackedInts.maxValue(bpv); // _TestUtil.nextLong is too slow
           }
@@ -1031,7 +1031,7 @@ public class TestPackedInts extends LuceneTestCase {
 
 
         long[] target = new long[arr.length + 1024]; // check the request for more is OK.
-        for (int i = 0; i < arr.length; i += _TestUtil.nextInt(random(), 0, 10000)) {
+        for (int i = 0; i < arr.length; i += TestUtil.nextInt(random(), 0, 10000)) {
           int lenToRead = random().nextInt(buf.pageSize() * 2) + 1;
           lenToRead = Math.min(lenToRead, target.length - i);
           int lenToCheck = Math.min(lenToRead, arr.length - i);
@@ -1062,11 +1062,11 @@ public class TestPackedInts extends LuceneTestCase {
     final boolean[] skip = new boolean[longs.length];
     for (int i = 0; i < longs.length; ++i) {
       final int bpv = RandomInts.randomIntBetween(random(), 1, 64);
-      bitsPerValues[i] = random().nextBoolean() ? bpv : _TestUtil.nextInt(random(), bpv, 64);
+      bitsPerValues[i] = random().nextBoolean() ? bpv : TestUtil.nextInt(random(), bpv, 64);
       if (bpv == 64) {
         longs[i] = random().nextLong();
       } else {
-        longs[i] = _TestUtil.nextLong(random(), 0, PackedInts.maxValue(bpv));
+        longs[i] = TestUtil.nextLong(random(), 0, PackedInts.maxValue(bpv));
       }
       skip[i] = rarely();
     }
@@ -1102,7 +1102,7 @@ public class TestPackedInts extends LuceneTestCase {
   public void testBlockPackedReaderWriter() throws IOException {
     final int iters = atLeast(2);
     for (int iter = 0; iter < iters; ++iter) {
-      final int blockSize = 1 << _TestUtil.nextInt(random(), 6, 18);
+      final int blockSize = 1 << TestUtil.nextInt(random(), 6, 18);
       final int valueCount = random().nextInt(1 << 18);
       final long[] values = new long[valueCount];
       long minValue = 0;
@@ -1117,7 +1117,7 @@ public class TestPackedInts extends LuceneTestCase {
         } else if (bpv == 64) {
           values[i] = random().nextLong();
         } else {
-          values[i] = minValue + _TestUtil.nextLong(random(), 0, (1L << bpv) - 1);
+          values[i] = minValue + TestUtil.nextLong(random(), 0, (1L << bpv) - 1);
         }
       }
   
@@ -1146,7 +1146,7 @@ public class TestPackedInts extends LuceneTestCase {
           assertEquals("" + i, values[i], it.next());
           ++i;
         } else {
-          final LongsRef nextValues = it.next(_TestUtil.nextInt(random(), 1, 1024));
+          final LongsRef nextValues = it.next(TestUtil.nextInt(random(), 1, 1024));
           for (int j = 0; j < nextValues.length; ++j) {
             assertEquals("" + (i + j), values[i + j], nextValues.longs[nextValues.offset + j]);
           }
@@ -1170,7 +1170,7 @@ public class TestPackedInts extends LuceneTestCase {
       final BlockPackedReaderIterator it2 = new BlockPackedReaderIterator(in, PackedInts.VERSION_CURRENT, blockSize, valueCount);
       int i = 0;
       while (true) {
-        final int skip = _TestUtil.nextInt(random(), 0, valueCount - i);
+        final int skip = TestUtil.nextInt(random(), 0, valueCount - i);
         it2.skip(skip);
         i += skip;
         assertEquals(i, it2.ord());
@@ -1203,7 +1203,7 @@ public class TestPackedInts extends LuceneTestCase {
   public void testMonotonicBlockPackedReaderWriter() throws IOException {
     final int iters = atLeast(2);
     for (int iter = 0; iter < iters; ++iter) {
-      final int blockSize = 1 << _TestUtil.nextInt(random(), 6, 18);
+      final int blockSize = 1 << TestUtil.nextInt(random(), 6, 18);
       final int valueCount = random().nextInt(1 << 18);
       final long[] values = new long[valueCount];
       if (valueCount > 0) {
@@ -1213,7 +1213,7 @@ public class TestPackedInts extends LuceneTestCase {
           if (random().nextDouble() < 0.1d) {
             maxDelta = random().nextInt(64);
           }
-          values[i] = Math.max(0, values[i-1] + _TestUtil.nextInt(random(), -16, maxDelta));
+          values[i] = Math.max(0, values[i-1] + TestUtil.nextInt(random(), -16, maxDelta));
         }
       }
 
@@ -1243,13 +1243,13 @@ public class TestPackedInts extends LuceneTestCase {
 
   @Nightly
   public void testBlockReaderOverflow() throws IOException {
-    final long valueCount = _TestUtil.nextLong(random(), 1L + Integer.MAX_VALUE, (long) Integer.MAX_VALUE * 2);
-    final int blockSize = 1 << _TestUtil.nextInt(random(), 20, 22);
+    final long valueCount = TestUtil.nextLong(random(), 1L + Integer.MAX_VALUE, (long) Integer.MAX_VALUE * 2);
+    final int blockSize = 1 << TestUtil.nextInt(random(), 20, 22);
     final Directory dir = newDirectory();
     final IndexOutput out = dir.createOutput("out.bin", IOContext.DEFAULT);
     final BlockPackedWriter writer = new BlockPackedWriter(out, blockSize);
     long value = random().nextInt() & 0xFFFFFFFFL;
-    long valueOffset = _TestUtil.nextLong(random(), 0, valueCount - 1);
+    long valueOffset = TestUtil.nextLong(random(), 0, valueCount - 1);
     for (long i = 0; i < valueCount; ) {
       assertEquals(i, writer.ord());
       if ((i & (blockSize - 1)) == 0 && (i + blockSize < valueOffset || i > valueOffset && i + blockSize < valueCount)) {
@@ -1273,7 +1273,7 @@ public class TestPackedInts extends LuceneTestCase {
     final BlockPackedReader reader = new BlockPackedReader(in, PackedInts.VERSION_CURRENT, blockSize, valueCount, random().nextBoolean());
     assertEquals(value, reader.get(valueOffset));
     for (int i = 0; i < 5; ++i) {
-      final long offset = _TestUtil.nextLong(random(), 0, valueCount - 1);
+      final long offset = TestUtil.nextLong(random(), 0, valueCount - 1);
       if (offset == valueOffset) {
         assertEquals(value, reader.get(offset));
       } else {
diff --git a/lucene/demo/src/test/org/apache/lucene/demo/TestDemo.java b/lucene/demo/src/test/org/apache/lucene/demo/TestDemo.java
index afc445c..d3b91c3 100644
--- a/lucene/demo/src/test/org/apache/lucene/demo/TestDemo.java
+++ b/lucene/demo/src/test/org/apache/lucene/demo/TestDemo.java
@@ -23,7 +23,7 @@ import java.io.PrintStream;
 import java.nio.charset.Charset;
 
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestDemo extends LuceneTestCase {
 
@@ -44,7 +44,7 @@ public class TestDemo extends LuceneTestCase {
 
   public void testIndexSearch() throws Exception {
     File dir = getDataFile("test-files/docs");
-    File indexDir = _TestUtil.getTempDir("ContribDemoTest");
+    File indexDir = TestUtil.getTempDir("ContribDemoTest");
     IndexFiles.main(new String[] { "-create", "-docs", dir.getPath(), "-index", indexDir.getPath()});
     testOneSearch(indexDir, "apache", 3);
     testOneSearch(indexDir, "patent", 8);
diff --git a/lucene/expressions/src/test/org/apache/lucene/expressions/TestExpressionSorts.java b/lucene/expressions/src/test/org/apache/lucene/expressions/TestExpressionSorts.java
index 0617577..f98f40d 100644
--- a/lucene/expressions/src/test/org/apache/lucene/expressions/TestExpressionSorts.java
+++ b/lucene/expressions/src/test/org/apache/lucene/expressions/TestExpressionSorts.java
@@ -47,7 +47,7 @@ import org.apache.lucene.search.TopDocs;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.English;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Tests some basic expressions against different queries,
@@ -63,7 +63,7 @@ public class TestExpressionSorts extends LuceneTestCase {
     super.setUp();
     dir = newDirectory();
     RandomIndexWriter iw = new RandomIndexWriter(random(), dir);
-    int numDocs = _TestUtil.nextInt(random(), 2049, 4000);
+    int numDocs = TestUtil.nextInt(random(), 2049, 4000);
     for (int i = 0; i < numDocs; i++) {
       Document document = new Document();
       document.add(newTextField("english", English.intToEnglish(i), Field.Store.NO));
@@ -124,13 +124,13 @@ public class TestExpressionSorts extends LuceneTestCase {
           new SortField("score", SortField.Type.SCORE)
       };
       Collections.shuffle(Arrays.asList(fields), random());
-      int numSorts = _TestUtil.nextInt(random(), 1, fields.length);
+      int numSorts = TestUtil.nextInt(random(), 1, fields.length);
       assertQuery(query, filter, new Sort(Arrays.copyOfRange(fields, 0, numSorts)));
     }
   }
 
   void assertQuery(Query query, Filter filter, Sort sort) throws Exception {
-    int size = _TestUtil.nextInt(random(), 1, searcher.getIndexReader().maxDoc()/5);
+    int size = TestUtil.nextInt(random(), 1, searcher.getIndexReader().maxDoc() / 5);
     TopDocs expected = searcher.search(query, filter, size, sort, random().nextBoolean(), random().nextBoolean());
     
     // make our actual sort, mutating original by replacing some of the 
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/FacetTestCase.java b/lucene/facet/src/test/org/apache/lucene/facet/FacetTestCase.java
index 0ded954..80849a9 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/FacetTestCase.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/FacetTestCase.java
@@ -34,7 +34,7 @@ import org.apache.lucene.facet.taxonomy.TaxonomyFacetCounts;
 import org.apache.lucene.facet.taxonomy.TaxonomyReader;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public abstract class FacetTestCase extends LuceneTestCase {
   
@@ -60,7 +60,7 @@ public abstract class FacetTestCase extends LuceneTestCase {
   protected String[] getRandomTokens(int count) {
     String[] tokens = new String[count];
     for(int i=0;i<tokens.length;i++) {
-      tokens[i] = _TestUtil.randomRealisticUnicodeString(random(), 1, 10);
+      tokens[i] = TestUtil.randomRealisticUnicodeString(random(), 1, 10);
       //tokens[i] = _TestUtil.randomSimpleString(random(), 1, 10);
     }
     return tokens;
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/TestDrillSideways.java b/lucene/facet/src/test/org/apache/lucene/facet/TestDrillSideways.java
index 8d7d7ec..1120a99 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/TestDrillSideways.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/TestDrillSideways.java
@@ -62,7 +62,7 @@ import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.InPlaceMergeSorter;
 import org.apache.lucene.util.InfoStream;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestDrillSideways extends FacetTestCase {
 
@@ -411,7 +411,7 @@ public class TestDrillSideways extends FacetTestCase {
     bChance /= sum;
     cChance /= sum;
 
-    int numDims = _TestUtil.nextInt(random(), 2, 5);
+    int numDims = TestUtil.nextInt(random(), 2, 5);
     //int numDims = 3;
     int numDocs = atLeast(3000);
     //int numDocs = 20;
@@ -424,7 +424,7 @@ public class TestDrillSideways extends FacetTestCase {
     for(int dim=0;dim<numDims;dim++) {
       Set<String> values = new HashSet<String>();
       while (values.size() < valueCount) {
-        String s = _TestUtil.randomRealisticUnicodeString(random());
+        String s = TestUtil.randomRealisticUnicodeString(random());
         //String s = _TestUtil.randomString(random());
         if (s.length() > 0) {
           values.add(s);
@@ -523,7 +523,7 @@ public class TestDrillSideways extends FacetTestCase {
 
     if (random().nextBoolean()) {
       // Randomly delete a few docs:
-      int numDel = _TestUtil.nextInt(random(), 1, (int) (numDocs*0.05));
+      int numDel = TestUtil.nextInt(random(), 1, (int) (numDocs * 0.05));
       if (VERBOSE) {
         System.out.println("delete " + numDel);
       }
@@ -570,7 +570,7 @@ public class TestDrillSideways extends FacetTestCase {
     for(int iter=0;iter<numIters;iter++) {
 
       String contentToken = random().nextInt(30) == 17 ? null : randomContentToken(true);
-      int numDrillDown = _TestUtil.nextInt(random(), 1, Math.min(4, numDims));
+      int numDrillDown = TestUtil.nextInt(random(), 1, Math.min(4, numDims));
       if (VERBOSE) {
         System.out.println("\nTEST: iter=" + iter + " baseQuery=" + contentToken + " numDrillDown=" + numDrillDown + " useSortedSetDV=" + doUseDV);
       }
@@ -586,7 +586,7 @@ public class TestDrillSideways extends FacetTestCase {
             // Drill down on one value:
             drillDowns[dim] = new String[] {dimValues[dim][random().nextInt(dimValues[dim].length)]};
           } else {
-            int orCount = _TestUtil.nextInt(random(), 1, Math.min(5, dimValues[dim].length));
+            int orCount = TestUtil.nextInt(random(), 1, Math.min(5, dimValues[dim].length));
             drillDowns[dim] = new String[orCount];
             anyMultiValuedDrillDowns |= orCount > 1;
             for(int i=0;i<orCount;i++) {
@@ -956,7 +956,7 @@ public class TestDrillSideways extends FacetTestCase {
     }
 
     for(int dim=0;dim<expected.counts.length;dim++) {
-      int topN = random().nextBoolean() ? dimValues[dim].length : _TestUtil.nextInt(random(), 1, dimValues[dim].length);
+      int topN = random().nextBoolean() ? dimValues[dim].length : TestUtil.nextInt(random(), 1, dimValues[dim].length);
       FacetResult fr = actual.facets.getTopChildren(topN, "dim"+dim);
       if (VERBOSE) {
         System.out.println("    dim" + dim + " topN=" + topN + " (vs " + dimValues[dim].length + " unique values)");
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/TestFacetsConfig.java b/lucene/facet/src/test/org/apache/lucene/facet/TestFacetsConfig.java
index cd42496..c221681 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/TestFacetsConfig.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/TestFacetsConfig.java
@@ -29,19 +29,19 @@ import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.MatchAllDocsQuery;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.IOUtils;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestFacetsConfig extends FacetTestCase {
   
   public void testPathToStringAndBack() throws Exception {
     int iters = atLeast(1000);
     for(int i=0;i<iters;i++) {
-      int numParts = _TestUtil.nextInt(random(), 1, 6);
+      int numParts = TestUtil.nextInt(random(), 1, 6);
       String[] parts = new String[numParts];
       for(int j=0;j<numParts;j++) {
         String s;
         while (true) {
-          s = _TestUtil.randomUnicodeString(random());
+          s = TestUtil.randomUnicodeString(random());
           if (s.length() > 0) {
             break;
           }
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/range/TestRangeFacetCounts.java b/lucene/facet/src/test/org/apache/lucene/facet/range/TestRangeFacetCounts.java
index 8fcaec8..0dc324b 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/range/TestRangeFacetCounts.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/range/TestRangeFacetCounts.java
@@ -67,7 +67,7 @@ import org.apache.lucene.search.QueryWrapperFilter;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.IOUtils;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 
 public class TestRangeFacetCounts extends FacetTestCase {
@@ -401,7 +401,7 @@ public class TestRangeFacetCounts extends FacetTestCase {
       if (VERBOSE) {
         System.out.println("TEST: iter=" + iter);
       }
-      int numRange = _TestUtil.nextInt(random(), 1, 100);
+      int numRange = TestUtil.nextInt(random(), 1, 100);
       LongRange[] ranges = new LongRange[numRange];
       int[] expectedCounts = new int[numRange];
       long minAcceptedValue = Long.MAX_VALUE;
@@ -545,7 +545,7 @@ public class TestRangeFacetCounts extends FacetTestCase {
       if (VERBOSE) {
         System.out.println("TEST: iter=" + iter);
       }
-      int numRange = _TestUtil.nextInt(random(), 1, 5);
+      int numRange = TestUtil.nextInt(random(), 1, 5);
       DoubleRange[] ranges = new DoubleRange[numRange];
       int[] expectedCounts = new int[numRange];
       float minAcceptedValue = Float.POSITIVE_INFINITY;
@@ -703,7 +703,7 @@ public class TestRangeFacetCounts extends FacetTestCase {
       if (VERBOSE) {
         System.out.println("TEST: iter=" + iter);
       }
-      int numRange = _TestUtil.nextInt(random(), 1, 5);
+      int numRange = TestUtil.nextInt(random(), 1, 5);
       DoubleRange[] ranges = new DoubleRange[numRange];
       int[] expectedCounts = new int[numRange];
       double minAcceptedValue = Double.POSITIVE_INFINITY;
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/sortedset/TestSortedSetDocValuesFacets.java b/lucene/facet/src/test/org/apache/lucene/facet/sortedset/TestSortedSetDocValuesFacets.java
index bccd329..4210ba7 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/sortedset/TestSortedSetDocValuesFacets.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/sortedset/TestSortedSetDocValuesFacets.java
@@ -41,7 +41,7 @@ import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.search.TopDocs;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.IOUtils;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestSortedSetDocValuesFacets extends FacetTestCase {
 
@@ -278,7 +278,7 @@ public class TestSortedSetDocValuesFacets extends FacetTestCase {
     RandomIndexWriter w = new RandomIndexWriter(random(), indexDir);
     FacetsConfig config = new FacetsConfig();
     int numDocs = atLeast(1000);
-    int numDims = _TestUtil.nextInt(random(), 1, 7);
+    int numDims = TestUtil.nextInt(random(), 1, 7);
     List<TestDoc> testDocs = getRandomDocs(tokens, numDocs, numDims);
     for(TestDoc testDoc : testDocs) {
       Document doc = new Document();
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestFacetLabel.java b/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestFacetLabel.java
index e020008..3126e06 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestFacetLabel.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestFacetLabel.java
@@ -6,7 +6,7 @@ import org.apache.lucene.facet.FacetField;
 import org.apache.lucene.facet.FacetTestCase;
 import org.apache.lucene.facet.sortedset.SortedSetDocValuesFacetField;
 import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.Test;
 
 /*
@@ -267,7 +267,7 @@ public class TestFacetLabel extends FacetTestCase {
     String bigComp = null;
     while (true) {
       int len = FacetLabel.MAX_CATEGORY_PATH_LENGTH;
-      bigComp = _TestUtil.randomSimpleString(random(), len, len);
+      bigComp = TestUtil.randomSimpleString(random(), len, len);
       if (bigComp.indexOf('\u001f') != -1) {
         continue;
       }
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestSearcherTaxonomyManager.java b/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestSearcherTaxonomyManager.java
index 54bcd89..27af83a 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestSearcherTaxonomyManager.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestSearcherTaxonomyManager.java
@@ -32,7 +32,6 @@ import org.apache.lucene.facet.FacetTestCase;
 import org.apache.lucene.facet.Facets;
 import org.apache.lucene.facet.FacetsCollector;
 import org.apache.lucene.facet.FacetsConfig;
-import org.apache.lucene.facet.taxonomy.SearcherTaxonomyManager;
 import org.apache.lucene.facet.taxonomy.SearcherTaxonomyManager.SearcherAndTaxonomy;
 import org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyWriter;
 import org.apache.lucene.index.IndexWriter;
@@ -40,7 +39,7 @@ import org.apache.lucene.search.MatchAllDocsQuery;
 import org.apache.lucene.search.ReferenceManager;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.IOUtils;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestSearcherTaxonomyManager extends FacetTestCase {
 
@@ -70,7 +69,7 @@ public class TestSearcherTaxonomyManager extends FacetTestCase {
         List<String> paths = new ArrayList<String>();
         while (true) {
           Document doc = new Document();
-          int numPaths = _TestUtil.nextInt(random(), 1, 5);
+          int numPaths = TestUtil.nextInt(random(), 1, 5);
           for(int i=0;i<numPaths;i++) {
             String path;
             if (!paths.isEmpty() && random().nextInt(5) != 4) {
@@ -80,7 +79,7 @@ public class TestSearcherTaxonomyManager extends FacetTestCase {
               // Create new path
               path = null;
               while (true) {
-                path = _TestUtil.randomRealisticUnicodeString(random());
+                path = TestUtil.randomRealisticUnicodeString(random());
                 if (path.length() != 0 && !seen.contains(path)) {
                   seen.add(path);
                   paths.add(path);
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetCounts.java b/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetCounts.java
index 0a8e248..ec4abc3 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetCounts.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetCounts.java
@@ -55,7 +55,7 @@ import org.apache.lucene.search.similarities.PerFieldSimilarityWrapper;
 import org.apache.lucene.search.similarities.Similarity;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.IOUtils;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestTaxonomyFacetCounts extends FacetTestCase {
 
@@ -413,7 +413,7 @@ public class TestTaxonomyFacetCounts extends FacetTestCase {
   // LUCENE-4583: make sure if we require > 32 KB for one
   // document, we don't hit exc when using Facet42DocValuesFormat
   public void testManyFacetsInOneDocument() throws Exception {
-    assumeTrue("default Codec doesn't support huge BinaryDocValues", _TestUtil.fieldSupportsHugeBinaryDocValues(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));
+    assumeTrue("default Codec doesn't support huge BinaryDocValues", TestUtil.fieldSupportsHugeBinaryDocValues(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));
     Directory dir = newDirectory();
     Directory taxoDir = newDirectory();
     IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));
@@ -423,7 +423,7 @@ public class TestTaxonomyFacetCounts extends FacetTestCase {
     FacetsConfig config = new FacetsConfig();
     config.setMultiValued("dim", true);
     
-    int numLabels = _TestUtil.nextInt(random(), 40000, 100000);
+    int numLabels = TestUtil.nextInt(random(), 40000, 100000);
     
     Document doc = new Document();
     doc.add(newTextField("field", "text", Field.Store.NO));
@@ -678,7 +678,7 @@ public class TestTaxonomyFacetCounts extends FacetTestCase {
     DirectoryTaxonomyWriter tw = new DirectoryTaxonomyWriter(taxoDir);
     FacetsConfig config = new FacetsConfig();
     int numDocs = atLeast(1000);
-    int numDims = _TestUtil.nextInt(random(), 1, 7);
+    int numDims = TestUtil.nextInt(random(), 1, 7);
     List<TestDoc> testDocs = getRandomDocs(tokens, numDocs, numDims);
     for(TestDoc testDoc : testDocs) {
       Document doc = new Document();
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetSumValueSource.java b/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetSumValueSource.java
index 5561e6d..6735905 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetSumValueSource.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetSumValueSource.java
@@ -61,7 +61,7 @@ import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.search.TopDocs;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.IOUtils;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestTaxonomyFacetSumValueSource extends FacetTestCase {
 
@@ -428,7 +428,7 @@ public class TestTaxonomyFacetSumValueSource extends FacetTestCase {
     DirectoryTaxonomyWriter tw = new DirectoryTaxonomyWriter(taxoDir);
     FacetsConfig config = new FacetsConfig();
     int numDocs = atLeast(1000);
-    int numDims = _TestUtil.nextInt(random(), 1, 7);
+    int numDims = TestUtil.nextInt(random(), 1, 7);
     List<TestDoc> testDocs = getRandomDocs(tokens, numDocs, numDims);
     for(TestDoc testDoc : testDocs) {
       Document doc = new Document();
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/directory/TestAddTaxonomy.java b/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/directory/TestAddTaxonomy.java
index c78b8d3..f61e273 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/directory/TestAddTaxonomy.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/directory/TestAddTaxonomy.java
@@ -12,7 +12,7 @@ import org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyWriter.Memory
 import org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyWriter.OrdinalMap;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.IOUtils;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /*
  * Licensed to the Apache Software Foundation (ASF) under one or more
@@ -74,7 +74,7 @@ public class TestAddTaxonomy extends FacetTestCase {
   
   private OrdinalMap randomOrdinalMap() throws IOException {
     if (random().nextBoolean()) {
-      return new DiskOrdinalMap(_TestUtil.createTempFile("taxoMap", "", TEMP_DIR));
+      return new DiskOrdinalMap(TestUtil.createTempFile("taxoMap", "", TEMP_DIR));
     } else {
       return new MemoryOrdinalMap();
     }
@@ -160,8 +160,8 @@ public class TestAddTaxonomy extends FacetTestCase {
     Random random = random();
     int numTests = atLeast(3);
     for (int i = 0; i < numTests; i++) {
-      dotest(_TestUtil.nextInt(random, 2, 100), 
-             _TestUtil.nextInt(random, 100, 1000));
+      dotest(TestUtil.nextInt(random, 2, 100),
+             TestUtil.nextInt(random, 100, 1000));
     }
   }
   
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/directory/TestDirectoryTaxonomyWriter.java b/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/directory/TestDirectoryTaxonomyWriter.java
index f00935c..a676b28 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/directory/TestDirectoryTaxonomyWriter.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/directory/TestDirectoryTaxonomyWriter.java
@@ -29,7 +29,8 @@ import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.store.AlreadyClosedException;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.IOUtils;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.Test;
 
 /*
@@ -445,7 +446,7 @@ public class TestDirectoryTaxonomyWriter extends FacetTestCase {
     int ordinal = -1;
 
     int len = FacetLabel.MAX_CATEGORY_PATH_LENGTH - 4; // for the dimension and separator
-    bigs = _TestUtil.randomSimpleString(random(), len, len);
+    bigs = TestUtil.randomSimpleString(random(), len, len);
     FacetField ff = new FacetField("dim", bigs);
     FacetLabel cp = new FacetLabel("dim", bigs);
     ordinal = taxoWriter.addCategory(cp);
@@ -455,7 +456,7 @@ public class TestDirectoryTaxonomyWriter extends FacetTestCase {
 
     // Add tiny ones to cause a re-hash
     for (int i = 0; i < 3; i++) {
-      String s = _TestUtil.randomSimpleString(random(), 1, 10);
+      String s = TestUtil.randomSimpleString(random(), 1, 10);
       taxoWriter.addCategory(new FacetLabel("dim", s));
       doc = new Document();
       doc.add(new FacetField("dim", s));
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/writercache/TestCharBlockArray.java b/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/writercache/TestCharBlockArray.java
index 3f5ec18..799df78 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/writercache/TestCharBlockArray.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/writercache/TestCharBlockArray.java
@@ -11,7 +11,8 @@ import java.nio.charset.CodingErrorAction;
 
 import org.apache.lucene.facet.FacetTestCase;
 import org.apache.lucene.util.IOUtils;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.Test;
 
 /*
@@ -84,7 +85,7 @@ public class TestCharBlockArray extends FacetTestCase {
 
     assertEqualsInternal("GrowingCharArray<->StringBuilder mismatch.", builder, array);
 
-    File tempDir = _TestUtil.getTempDir("growingchararray");
+    File tempDir = TestUtil.getTempDir("growingchararray");
     File f = new File(tempDir, "GrowingCharArrayTest.tmp");
     BufferedOutputStream out = new BufferedOutputStream(new FileOutputStream(f));
     array.flush(out);
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/writercache/TestCompactLabelToOrdinal.java b/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/writercache/TestCompactLabelToOrdinal.java
index f9f485b..715a80e 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/writercache/TestCompactLabelToOrdinal.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/writercache/TestCompactLabelToOrdinal.java
@@ -11,7 +11,8 @@ import java.util.Random;
 import org.apache.lucene.facet.FacetTestCase;
 import org.apache.lucene.facet.taxonomy.FacetLabel;
 import org.apache.lucene.util.IOUtils;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.Test;
 
 /*
@@ -67,7 +68,7 @@ public class TestCompactLabelToOrdinal extends FacetTestCase {
       }
     }
 
-    File tmpDir = _TestUtil.getTempDir("testLableToOrdinal");
+    File tmpDir = TestUtil.getTempDir("testLableToOrdinal");
     File f = new File(tmpDir, "CompactLabelToOrdinalTest.tmp");
     int flushInterval = 10;
 
diff --git a/lucene/grouping/src/test/org/apache/lucene/search/grouping/AbstractGroupingTestCase.java b/lucene/grouping/src/test/org/apache/lucene/search/grouping/AbstractGroupingTestCase.java
index 843e017..b8e3a7f 100644
--- a/lucene/grouping/src/test/org/apache/lucene/search/grouping/AbstractGroupingTestCase.java
+++ b/lucene/grouping/src/test/org/apache/lucene/search/grouping/AbstractGroupingTestCase.java
@@ -18,7 +18,7 @@ package org.apache.lucene.search.grouping;
  */
 
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Base class for grouping related tests.
@@ -32,7 +32,7 @@ public abstract class AbstractGroupingTestCase extends LuceneTestCase {
       // B/c of DV based impl we can't see the difference between an empty string and a null value.
       // For that reason we don't generate empty string
       // groups.
-      randomValue = _TestUtil.randomRealisticUnicodeString(random());
+      randomValue = TestUtil.randomRealisticUnicodeString(random());
       //randomValue = _TestUtil.randomSimpleString(random());
     } while ("".equals(randomValue));
     return randomValue;
diff --git a/lucene/grouping/src/test/org/apache/lucene/search/grouping/AllGroupHeadsCollectorTest.java b/lucene/grouping/src/test/org/apache/lucene/search/grouping/AllGroupHeadsCollectorTest.java
index d5eeaf6..6d6dacd 100644
--- a/lucene/grouping/src/test/org/apache/lucene/search/grouping/AllGroupHeadsCollectorTest.java
+++ b/lucene/grouping/src/test/org/apache/lucene/search/grouping/AllGroupHeadsCollectorTest.java
@@ -46,7 +46,7 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 import java.io.IOException;
 import java.util.ArrayList;
@@ -178,14 +178,14 @@ public class AllGroupHeadsCollectorTest extends LuceneTestCase {
   }
 
   public void testRandom() throws Exception {
-    int numberOfRuns = _TestUtil.nextInt(random(), 3, 6);
+    int numberOfRuns = TestUtil.nextInt(random(), 3, 6);
     for (int iter = 0; iter < numberOfRuns; iter++) {
       if (VERBOSE) {
         System.out.println(String.format(Locale.ROOT, "TEST: iter=%d total=%d", iter, numberOfRuns));
       }
 
-      final int numDocs = _TestUtil.nextInt(random(), 100, 1000) * RANDOM_MULTIPLIER;
-      final int numGroups = _TestUtil.nextInt(random(), 1, numDocs);
+      final int numDocs = TestUtil.nextInt(random(), 100, 1000) * RANDOM_MULTIPLIER;
+      final int numGroups = TestUtil.nextInt(random(), 1, numDocs);
 
       if (VERBOSE) {
         System.out.println("TEST: numDocs=" + numDocs + " numGroups=" + numGroups);
@@ -197,11 +197,11 @@ public class AllGroupHeadsCollectorTest extends LuceneTestCase {
         do {
           // B/c of DV based impl we can't see the difference between an empty string and a null value.
           // For that reason we don't generate empty string groups.
-          randomValue = _TestUtil.randomRealisticUnicodeString(random());
+          randomValue = TestUtil.randomRealisticUnicodeString(random());
         } while ("".equals(randomValue));
         groups.add(new BytesRef(randomValue));
       }
-      final String[] contentStrings = new String[_TestUtil.nextInt(random(), 2, 20)];
+      final String[] contentStrings = new String[TestUtil.nextInt(random(), 2, 20)];
       if (VERBOSE) {
         System.out.println("TEST: create fake content");
       }
diff --git a/lucene/grouping/src/test/org/apache/lucene/search/grouping/DistinctValuesCollectorTest.java b/lucene/grouping/src/test/org/apache/lucene/search/grouping/DistinctValuesCollectorTest.java
index 1218193..bcdcd1a 100644
--- a/lucene/grouping/src/test/org/apache/lucene/search/grouping/DistinctValuesCollectorTest.java
+++ b/lucene/grouping/src/test/org/apache/lucene/search/grouping/DistinctValuesCollectorTest.java
@@ -41,7 +41,7 @@ import org.apache.lucene.search.grouping.term.TermDistinctValuesCollector;
 import org.apache.lucene.search.grouping.term.TermFirstPassGroupingCollector;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.mutable.MutableValue;
 import org.apache.lucene.util.mutable.MutableValueStr;
 
@@ -246,7 +246,7 @@ public class DistinctValuesCollectorTest extends AbstractGroupingTestCase {
 
   public void testRandom() throws Exception {
     Random random = random();
-    int numberOfRuns = _TestUtil.nextInt(random, 3, 6);
+    int numberOfRuns = TestUtil.nextInt(random, 3, 6);
     for (int indexIter = 0; indexIter < numberOfRuns; indexIter++) {
       IndexContext context = createIndexContext();
       for (int searchIter = 0; searchIter < 100; searchIter++) {
diff --git a/lucene/grouping/src/test/org/apache/lucene/search/grouping/GroupFacetCollectorTest.java b/lucene/grouping/src/test/org/apache/lucene/search/grouping/GroupFacetCollectorTest.java
index 9f89bf3..a6d43fc 100644
--- a/lucene/grouping/src/test/org/apache/lucene/search/grouping/GroupFacetCollectorTest.java
+++ b/lucene/grouping/src/test/org/apache/lucene/search/grouping/GroupFacetCollectorTest.java
@@ -33,7 +33,7 @@ import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.search.grouping.term.TermGroupFacetCollector;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 import java.io.IOException;
 import java.util.ArrayList;
@@ -372,7 +372,7 @@ public class GroupFacetCollectorTest extends AbstractGroupingTestCase {
 
   public void testRandom() throws Exception {
     Random random = random();
-    int numberOfRuns = _TestUtil.nextInt(random, 3, 6);
+    int numberOfRuns = TestUtil.nextInt(random, 3, 6);
     for (int indexIter = 0; indexIter < numberOfRuns; indexIter++) {
       boolean multipleFacetsPerDocument = random.nextBoolean();
       IndexContext context = createIndexContext(multipleFacetsPerDocument);
@@ -478,9 +478,9 @@ public class GroupFacetCollectorTest extends AbstractGroupingTestCase {
 
   private IndexContext createIndexContext(boolean multipleFacetValuesPerDocument) throws IOException {
     final Random random = random();
-    final int numDocs = _TestUtil.nextInt(random, 138, 1145) * RANDOM_MULTIPLIER;
-    final int numGroups = _TestUtil.nextInt(random, 1, numDocs / 4);
-    final int numFacets = _TestUtil.nextInt(random, 1, numDocs / 6);
+    final int numDocs = TestUtil.nextInt(random, 138, 1145) * RANDOM_MULTIPLIER;
+    final int numGroups = TestUtil.nextInt(random, 1, numDocs / 4);
+    final int numFacets = TestUtil.nextInt(random, 1, numDocs / 6);
 
     if (VERBOSE) {
       System.out.println("TEST: numDocs=" + numDocs + " numGroups=" + numGroups);
@@ -494,7 +494,7 @@ public class GroupFacetCollectorTest extends AbstractGroupingTestCase {
     for (int i = 0; i < numFacets; i++) {
       facetValues.add(generateRandomNonEmptyString());
     }
-    final String[] contentBrs = new String[_TestUtil.nextInt(random, 2, 20)];
+    final String[] contentBrs = new String[TestUtil.nextInt(random, 2, 20)];
     if (VERBOSE) {
       System.out.println("TEST: create fake content");
     }
diff --git a/lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping.java b/lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping.java
index 2ccc590..e740e67 100644
--- a/lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping.java
+++ b/lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping.java
@@ -39,7 +39,7 @@ import org.apache.lucene.search.grouping.term.TermSecondPassGroupingCollector;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.mutable.MutableValue;
 import org.apache.lucene.util.mutable.MutableValueStr;
 
@@ -619,16 +619,16 @@ public class TestGrouping extends LuceneTestCase {
   }
 
   public void testRandom() throws Exception {
-    int numberOfRuns = _TestUtil.nextInt(random(), 3, 6);
+    int numberOfRuns = TestUtil.nextInt(random(), 3, 6);
     for (int iter=0; iter<numberOfRuns; iter++) {
       if (VERBOSE) {
         System.out.println("TEST: iter=" + iter);
       }
 
-      final int numDocs = _TestUtil.nextInt(random(), 100, 1000) * RANDOM_MULTIPLIER;
+      final int numDocs = TestUtil.nextInt(random(), 100, 1000) * RANDOM_MULTIPLIER;
       //final int numDocs = _TestUtil.nextInt(random, 5, 20);
 
-      final int numGroups = _TestUtil.nextInt(random(), 1, numDocs);
+      final int numGroups = TestUtil.nextInt(random(), 1, numDocs);
 
       if (VERBOSE) {
         System.out.println("TEST: numDocs=" + numDocs + " numGroups=" + numGroups);
@@ -641,13 +641,13 @@ public class TestGrouping extends LuceneTestCase {
           // B/c of DV based impl we can't see the difference between an empty string and a null value.
           // For that reason we don't generate empty string
           // groups.
-          randomValue = _TestUtil.randomRealisticUnicodeString(random());
+          randomValue = TestUtil.randomRealisticUnicodeString(random());
           //randomValue = _TestUtil.randomSimpleString(random());
         } while ("".equals(randomValue));
 
         groups.add(new BytesRef(randomValue));
       }
-      final String[] contentStrings = new String[_TestUtil.nextInt(random(), 2, 20)];
+      final String[] contentStrings = new String[TestUtil.nextInt(random(), 2, 20)];
       if (VERBOSE) {
         System.out.println("TEST: create fake content");
       }
@@ -838,14 +838,14 @@ public class TestGrouping extends LuceneTestCase {
             }
           }
 
-          final int topNGroups = _TestUtil.nextInt(random(), 1, 30);
+          final int topNGroups = TestUtil.nextInt(random(), 1, 30);
           //final int topNGroups = 10;
-          final int docsPerGroup = _TestUtil.nextInt(random(), 1, 50);
+          final int docsPerGroup = TestUtil.nextInt(random(), 1, 50);
 
-          final int groupOffset = _TestUtil.nextInt(random(), 0, (topNGroups-1)/2);
+          final int groupOffset = TestUtil.nextInt(random(), 0, (topNGroups - 1) / 2);
           //final int groupOffset = 0;
 
-          final int docOffset = _TestUtil.nextInt(random(), 0, docsPerGroup-1);
+          final int docOffset = TestUtil.nextInt(random(), 0, docsPerGroup - 1);
           //final int docOffset = 0;
 
           final boolean doCache = random().nextBoolean();
diff --git a/lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestPostingsHighlighterRanking.java b/lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestPostingsHighlighterRanking.java
index 0050e73..284c2ce 100644
--- a/lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestPostingsHighlighterRanking.java
+++ b/lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestPostingsHighlighterRanking.java
@@ -44,7 +44,7 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.LuceneTestCase.SuppressCodecs;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 @SuppressCodecs({"MockFixedIntBlock", "MockVariableIntBlock", "MockSep", "MockRandom"})
 public class TestPostingsHighlighterRanking extends LuceneTestCase {
@@ -75,7 +75,7 @@ public class TestPostingsHighlighterRanking extends LuceneTestCase {
     
     for (int i = 0; i < numDocs; i++) {
       StringBuilder bodyText = new StringBuilder();
-      int numSentences = _TestUtil.nextInt(random(), 1, maxNumSentences);
+      int numSentences = TestUtil.nextInt(random(), 1, maxNumSentences);
       for (int j = 0; j < numSentences; j++) {
         bodyText.append(newSentence(random(), maxSentenceLength));
       }
@@ -144,14 +144,14 @@ public class TestPostingsHighlighterRanking extends LuceneTestCase {
    */
   private String newSentence(Random r, int maxSentenceLength) {
     StringBuilder sb = new StringBuilder();
-    int numElements = _TestUtil.nextInt(r, 1, maxSentenceLength);
+    int numElements = TestUtil.nextInt(r, 1, maxSentenceLength);
     for (int i = 0; i < numElements; i++) {
       if (sb.length() > 0) {
         sb.append(' ');
-        sb.append((char)_TestUtil.nextInt(r, 'a', 'z'));
+        sb.append((char) TestUtil.nextInt(r, 'a', 'z'));
       } else {
         // capitalize the first word to help breakiterator
-        sb.append((char)_TestUtil.nextInt(r, 'A', 'Z'));
+        sb.append((char) TestUtil.nextInt(r, 'A', 'Z'));
       }
     }
     sb.append(". "); // finalize sentence
diff --git a/lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FieldPhraseListTest.java b/lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FieldPhraseListTest.java
index afab821..e0f5ad1 100644
--- a/lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FieldPhraseListTest.java
+++ b/lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FieldPhraseListTest.java
@@ -23,7 +23,8 @@ import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.search.vectorhighlight.FieldPhraseList.WeightedPhraseInfo;
 import org.apache.lucene.search.vectorhighlight.FieldPhraseList.WeightedPhraseInfo.Toffs;
 import org.apache.lucene.search.vectorhighlight.FieldTermStack.TermInfo;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class FieldPhraseListTest extends AbstractTestCase {
   
@@ -269,7 +270,7 @@ public class FieldPhraseListTest extends AbstractTestCase {
 
   private WeightedPhraseInfo newInfo( int startOffset, int endOffset, float boost ) {
     LinkedList< TermInfo > infos = new LinkedList< TermInfo >();
-    infos.add( new TermInfo( _TestUtil.randomUnicodeString( random() ), startOffset, endOffset, 0, 0 ) );
+    infos.add( new TermInfo( TestUtil.randomUnicodeString(random()), startOffset, endOffset, 0, 0 ) );
     return new WeightedPhraseInfo( infos, boost );
   }
 
diff --git a/lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FieldTermStackTest.java b/lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FieldTermStackTest.java
index 2a4c673..6eef20f 100644
--- a/lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FieldTermStackTest.java
+++ b/lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FieldTermStackTest.java
@@ -21,7 +21,7 @@ import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.search.WildcardQuery;
 import org.apache.lucene.search.vectorhighlight.FieldTermStack.TermInfo;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class FieldTermStackTest extends AbstractTestCase {
   
@@ -176,10 +176,10 @@ public class FieldTermStackTest extends AbstractTestCase {
   }
 
   public void testTermInfoComparisonConsistency() {
-    TermInfo a = new TermInfo( _TestUtil.randomUnicodeString( random() ), 0, 0, 0, 1 );
-    TermInfo b = new TermInfo( _TestUtil.randomUnicodeString( random() ), 0, 0, 1, 1 );
-    TermInfo c = new TermInfo( _TestUtil.randomUnicodeString( random() ), 0, 0, 2, 1 );
-    TermInfo d = new TermInfo( _TestUtil.randomUnicodeString( random() ), 0, 0, 0, 1 );
+    TermInfo a = new TermInfo( TestUtil.randomUnicodeString(random()), 0, 0, 0, 1 );
+    TermInfo b = new TermInfo( TestUtil.randomUnicodeString(random()), 0, 0, 1, 1 );
+    TermInfo c = new TermInfo( TestUtil.randomUnicodeString(random()), 0, 0, 2, 1 );
+    TermInfo d = new TermInfo( TestUtil.randomUnicodeString(random()), 0, 0, 0, 1 );
 
     assertConsistentEquals( a, a );
     assertConsistentEquals( b, b );
diff --git a/lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/SimpleFragmentsBuilderTest.java b/lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/SimpleFragmentsBuilderTest.java
index 3dbd12b..e15b32a 100644
--- a/lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/SimpleFragmentsBuilderTest.java
+++ b/lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/SimpleFragmentsBuilderTest.java
@@ -35,7 +35,7 @@ import org.apache.lucene.search.Query;
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.search.highlight.SimpleHTMLEncoder;
 import org.apache.lucene.store.Directory;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 import java.util.ArrayList;
 import java.util.HashMap;
@@ -228,7 +228,7 @@ public class SimpleFragmentsBuilderTest extends AbstractTestCase {
     for (int i = 0; i < randomValues.length; i++) {
       String randomValue;
       do {
-        randomValue = _TestUtil.randomSimpleString(random());
+        randomValue = TestUtil.randomSimpleString(random());
       } while ("".equals(randomValue));
       randomValues[i] = randomValue;
     }
diff --git a/lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoin.java b/lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoin.java
index b788ea0..c7ddcdd 100644
--- a/lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoin.java
+++ b/lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoin.java
@@ -439,18 +439,18 @@ public class TestBlockJoin extends LuceneTestCase {
 
   private String[][] getRandomFields(int maxUniqueValues) {
 
-    final String[][] fields = new String[_TestUtil.nextInt(random(), 2, 4)][];
+    final String[][] fields = new String[TestUtil.nextInt(random(), 2, 4)][];
     for(int fieldID=0;fieldID<fields.length;fieldID++) {
       final int valueCount;
       if (fieldID == 0) {
         valueCount = 2;
       } else {
-        valueCount = _TestUtil.nextInt(random(), 1, maxUniqueValues);
+        valueCount = TestUtil.nextInt(random(), 1, maxUniqueValues);
       }
         
       final String[] values = fields[fieldID] = new String[valueCount];
       for(int i=0;i<valueCount;i++) {
-        values[i] = _TestUtil.randomRealisticUnicodeString(random());
+        values[i] = TestUtil.randomRealisticUnicodeString(random());
         //values[i] = _TestUtil.randomSimpleString(random);
       }
     }
@@ -490,7 +490,7 @@ public class TestBlockJoin extends LuceneTestCase {
     final Directory dir = newDirectory();
     final Directory joinDir = newDirectory();
 
-    final int numParentDocs = _TestUtil.nextInt(random(), 100*RANDOM_MULTIPLIER, 300*RANDOM_MULTIPLIER);
+    final int numParentDocs = TestUtil.nextInt(random(), 100 * RANDOM_MULTIPLIER, 300 * RANDOM_MULTIPLIER);
     //final int numParentDocs = 30;
 
     // Values for parent fields:
@@ -538,10 +538,10 @@ public class TestBlockJoin extends LuceneTestCase {
         System.out.println("  " + sb.toString());
       }
 
-      final int numChildDocs = _TestUtil.nextInt(random(), 1, 20);
+      final int numChildDocs = TestUtil.nextInt(random(), 1, 20);
       for(int childDocID=0;childDocID<numChildDocs;childDocID++) {
         // Denormalize: copy all parent fields into child doc:
-        Document childDoc = _TestUtil.cloneDocument(parentDoc);
+        Document childDoc = TestUtil.cloneDocument(parentDoc);
         Document joinChildDoc = new Document();
         joinDocs.add(joinChildDoc);
 
@@ -630,7 +630,7 @@ public class TestBlockJoin extends LuceneTestCase {
       } else if (random().nextInt(3) == 2) {
         BooleanQuery bq = new BooleanQuery();
         childQuery = bq;
-        final int numClauses = _TestUtil.nextInt(random(), 2, 4);
+        final int numClauses = TestUtil.nextInt(random(), 2, 4);
         boolean didMust = false;
         for(int clauseIDX=0;clauseIDX<numClauses;clauseIDX++) {
           Query clause;
@@ -641,7 +641,7 @@ public class TestBlockJoin extends LuceneTestCase {
             didMust = true;
           } else {
             occur = BooleanClause.Occur.SHOULD;
-            final int childFieldID = _TestUtil.nextInt(random(), 1, childFields.length-1);
+            final int childFieldID = TestUtil.nextInt(random(), 1, childFields.length - 1);
             clause = new TermQuery(new Term("child" + childFieldID,
                                             childFields[childFieldID][random().nextInt(childFields[childFieldID].length)]));
           }
@@ -653,7 +653,7 @@ public class TestBlockJoin extends LuceneTestCase {
         
         bq.add(new TermQuery(randomChildTerm(childFields[0])),
                BooleanClause.Occur.MUST);
-        final int childFieldID = _TestUtil.nextInt(random(), 1, childFields.length-1);
+        final int childFieldID = TestUtil.nextInt(random(), 1, childFields.length - 1);
         bq.add(new TermQuery(new Term("child" + childFieldID, childFields[childFieldID][random().nextInt(childFields[childFieldID].length)])),
                random().nextBoolean() ? BooleanClause.Occur.MUST : BooleanClause.Occur.MUST_NOT);
       }
@@ -761,7 +761,7 @@ public class TestBlockJoin extends LuceneTestCase {
 
       joinS.search(parentJoinQuery, c);
 
-      final int hitsPerGroup = _TestUtil.nextInt(random(), 1, 20);
+      final int hitsPerGroup = TestUtil.nextInt(random(), 1, 20);
       //final int hitsPerGroup = 100;
       final TopGroups<Integer> joinResults = c.getTopGroups(childJoinQuery, childSort, 0, hitsPerGroup, 0, true);
 
@@ -822,7 +822,7 @@ public class TestBlockJoin extends LuceneTestCase {
       } else if (random().nextInt(3) == 2) {
         BooleanQuery bq = new BooleanQuery();
         parentQuery2 = bq;
-        final int numClauses = _TestUtil.nextInt(random(), 2, 4);
+        final int numClauses = TestUtil.nextInt(random(), 2, 4);
         boolean didMust = false;
         for(int clauseIDX=0;clauseIDX<numClauses;clauseIDX++) {
           Query clause;
@@ -833,7 +833,7 @@ public class TestBlockJoin extends LuceneTestCase {
             didMust = true;
           } else {
             occur = BooleanClause.Occur.SHOULD;
-            final int fieldID = _TestUtil.nextInt(random(), 1, parentFields.length-1);
+            final int fieldID = TestUtil.nextInt(random(), 1, parentFields.length - 1);
             clause = new TermQuery(new Term("parent" + fieldID,
                                             parentFields[fieldID][random().nextInt(parentFields[fieldID].length)]));
           }
@@ -845,7 +845,7 @@ public class TestBlockJoin extends LuceneTestCase {
         
         bq.add(new TermQuery(randomParentTerm(parentFields[0])),
                BooleanClause.Occur.MUST);
-        final int fieldID = _TestUtil.nextInt(random(), 1, parentFields.length-1);
+        final int fieldID = TestUtil.nextInt(random(), 1, parentFields.length - 1);
         bq.add(new TermQuery(new Term("parent" + fieldID, parentFields[fieldID][random().nextInt(parentFields[fieldID].length)])),
                random().nextBoolean() ? BooleanClause.Occur.MUST : BooleanClause.Occur.MUST_NOT);
       }
diff --git a/lucene/join/src/test/org/apache/lucene/search/join/TestJoinUtil.java b/lucene/join/src/test/org/apache/lucene/search/join/TestJoinUtil.java
index f99f4d2..94f784a 100644
--- a/lucene/join/src/test/org/apache/lucene/search/join/TestJoinUtil.java
+++ b/lucene/join/src/test/org/apache/lucene/search/join/TestJoinUtil.java
@@ -51,7 +51,7 @@ import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.Test;
 
 import java.io.IOException;
@@ -244,18 +244,18 @@ public class TestJoinUtil extends LuceneTestCase {
   @Test
   @Slow
   public void testSingleValueRandomJoin() throws Exception {
-    int maxIndexIter = _TestUtil.nextInt(random(), 6, 12);
-    int maxSearchIter = _TestUtil.nextInt(random(), 13, 26);
-    executeRandomJoin(false, maxIndexIter, maxSearchIter, _TestUtil.nextInt(random(), 87, 764));
+    int maxIndexIter = TestUtil.nextInt(random(), 6, 12);
+    int maxSearchIter = TestUtil.nextInt(random(), 13, 26);
+    executeRandomJoin(false, maxIndexIter, maxSearchIter, TestUtil.nextInt(random(), 87, 764));
   }
 
   @Test
   @Slow
   // This test really takes more time, that is why the number of iterations are smaller.
   public void testMultiValueRandomJoin() throws Exception {
-    int maxIndexIter = _TestUtil.nextInt(random(), 3, 6);
-    int maxSearchIter = _TestUtil.nextInt(random(), 6, 12);
-    executeRandomJoin(true, maxIndexIter, maxSearchIter, _TestUtil.nextInt(random(), 11, 57));
+    int maxIndexIter = TestUtil.nextInt(random(), 3, 6);
+    int maxSearchIter = TestUtil.nextInt(random(), 6, 12);
+    executeRandomJoin(true, maxIndexIter, maxSearchIter, TestUtil.nextInt(random(), 11, 57));
   }
 
   private void executeRandomJoin(boolean multipleValuesPerDocument, int maxIndexIter, int maxSearchIter, int numberOfDocumentsToIndex) throws Exception {
@@ -387,7 +387,7 @@ public class TestJoinUtil extends LuceneTestCase {
     for (int i = 0; i < numRandomValues; i++) {
       String uniqueRandomValue;
       do {
-        uniqueRandomValue = _TestUtil.randomRealisticUnicodeString(random());
+        uniqueRandomValue = TestUtil.randomRealisticUnicodeString(random());
 //        uniqueRandomValue = _TestUtil.randomSimpleString(random);
       } while ("".equals(uniqueRandomValue) || trackSet.contains(uniqueRandomValue));
       // Generate unique values and empty strings aren't allowed.
diff --git a/lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest.java b/lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest.java
index 4188059..ce17390 100644
--- a/lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest.java
+++ b/lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest.java
@@ -74,7 +74,7 @@ import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.LineFileDocs;
 import org.apache.lucene.util.RamUsageEstimator;
 import org.apache.lucene.util.RecyclingByteBlockAllocator;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 import static org.hamcrest.CoreMatchers.equalTo;
 
@@ -148,7 +148,7 @@ public class MemoryIndexTest extends BaseTokenStreamTestCase {
     Directory ramdir = new RAMDirectory();
     Analyzer analyzer = randomAnalyzer();
     IndexWriter writer = new IndexWriter(ramdir,
-                                         new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodec(_TestUtil.alwaysPostingsFormat(new Lucene41PostingsFormat())));
+                                         new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodec(TestUtil.alwaysPostingsFormat(new Lucene41PostingsFormat())));
     Document doc = new Document();
     Field field1 = newTextField("foo", fooField.toString(), Field.Store.NO);
     Field field2 = newTextField("term", termField.toString(), Field.Store.NO);
@@ -313,7 +313,7 @@ public class MemoryIndexTest extends BaseTokenStreamTestCase {
       return TEST_TERMS[random().nextInt(TEST_TERMS.length)];
     } else {
       // return a random unicode term
-      return _TestUtil.randomUnicodeString(random());
+      return TestUtil.randomUnicodeString(random());
     }
   }
   
@@ -322,7 +322,7 @@ public class MemoryIndexTest extends BaseTokenStreamTestCase {
     MemoryIndex memory = new MemoryIndex(random().nextBoolean(),  random().nextInt(50) * 1024 * 1024);
     memory.addField("foo", "bar", analyzer);
     AtomicReader reader = (AtomicReader) memory.createSearcher().getIndexReader();
-    DocsEnum disi = _TestUtil.docs(random(), reader, "foo", new BytesRef("bar"), null, null, DocsEnum.FLAG_NONE);
+    DocsEnum disi = TestUtil.docs(random(), reader, "foo", new BytesRef("bar"), null, null, DocsEnum.FLAG_NONE);
     int docid = disi.docID();
     assertEquals(-1, docid);
     assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
diff --git a/lucene/misc/src/test/org/apache/lucene/index/TestIndexSplitter.java b/lucene/misc/src/test/org/apache/lucene/index/TestIndexSplitter.java
index 080f2fe..9ffd4a7 100644
--- a/lucene/misc/src/test/org/apache/lucene/index/TestIndexSplitter.java
+++ b/lucene/misc/src/test/org/apache/lucene/index/TestIndexSplitter.java
@@ -24,15 +24,15 @@ import org.apache.lucene.index.IndexWriterConfig.OpenMode;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestIndexSplitter extends LuceneTestCase {
   public void test() throws Exception {
     File dir = new File(TEMP_DIR, "testfilesplitter");
-    _TestUtil.rmDir(dir);
+    TestUtil.rmDir(dir);
     dir.mkdirs();
     File destDir = new File(TEMP_DIR, "testfilesplitterdest");
-    _TestUtil.rmDir(destDir);
+    TestUtil.rmDir(destDir);
     destDir.mkdirs();
     Directory fsDir = newFSDirectory(dir);
     // IndexSplitter.split makes its own commit directly with SIPC/SegmentInfos,
@@ -81,7 +81,7 @@ public class TestIndexSplitter extends LuceneTestCase {
     
     // now test cmdline
     File destDir2 = new File(TEMP_DIR, "testfilesplitterdest2");
-    _TestUtil.rmDir(destDir2);
+    TestUtil.rmDir(destDir2);
     destDir2.mkdirs();
     IndexSplitter.main(new String[] {dir.getAbsolutePath(), destDir2.getAbsolutePath(), splitSegName});
     assertEquals(5, destDir2.listFiles().length);
diff --git a/lucene/misc/src/test/org/apache/lucene/index/sorter/IndexSortingTest.java b/lucene/misc/src/test/org/apache/lucene/index/sorter/IndexSortingTest.java
index fefe41b..5b28375 100644
--- a/lucene/misc/src/test/org/apache/lucene/index/sorter/IndexSortingTest.java
+++ b/lucene/misc/src/test/org/apache/lucene/index/sorter/IndexSortingTest.java
@@ -26,7 +26,7 @@ import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.SlowCompositeReaderWrapper;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.Bits;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.BeforeClass;
 
 public class IndexSortingTest extends SorterTestBase {
@@ -73,7 +73,7 @@ public class IndexSortingTest extends SorterTestBase {
     
     // CheckIndex the target directory
     dir = target;
-    _TestUtil.checkIndex(dir);
+    TestUtil.checkIndex(dir);
     
     // set reader for tests
     reader = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(dir));
diff --git a/lucene/misc/src/test/org/apache/lucene/index/sorter/SorterTestBase.java b/lucene/misc/src/test/org/apache/lucene/index/sorter/SorterTestBase.java
index e12f528..372a119 100644
--- a/lucene/misc/src/test/org/apache/lucene/index/sorter/SorterTestBase.java
+++ b/lucene/misc/src/test/org/apache/lucene/index/sorter/SorterTestBase.java
@@ -68,7 +68,7 @@ import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.AfterClass;
 import org.junit.BeforeClass;
 import org.junit.Test;
@@ -172,7 +172,7 @@ public abstract class SorterTestBase extends LuceneTestCase {
     doc.add(new StringField(ID_FIELD, Integer.toString(id), Store.YES));
     doc.add(new StringField(DOCS_ENUM_FIELD, DOCS_ENUM_TERM, Store.NO));
     positions.setId(id);
-    if (doesntSupportOffsets.contains(_TestUtil.getPostingsFormat(DOC_POSITIONS_FIELD))) {
+    if (doesntSupportOffsets.contains(TestUtil.getPostingsFormat(DOC_POSITIONS_FIELD))) {
       // codec doesnt support offsets: just index positions for the field
       doc.add(new Field(DOC_POSITIONS_FIELD, positions, TextField.TYPE_NOT_STORED));
     } else {
@@ -264,7 +264,7 @@ public abstract class SorterTestBase extends LuceneTestCase {
       assertEquals("incorrect freq for doc=" + doc, sortedValues[doc].intValue() / 10 + 1, freq);
       for (int i = 0; i < freq; i++) {
         assertEquals("incorrect position for doc=" + doc, i, sortedPositions.nextPosition());
-        if (!doesntSupportOffsets.contains(_TestUtil.getPostingsFormat(DOC_POSITIONS_FIELD))) {
+        if (!doesntSupportOffsets.contains(TestUtil.getPostingsFormat(DOC_POSITIONS_FIELD))) {
           assertEquals("incorrect startOffset for doc=" + doc, i, sortedPositions.startOffset());
           assertEquals("incorrect endOffset for doc=" + doc, i, sortedPositions.endOffset());
         }
@@ -279,12 +279,12 @@ public abstract class SorterTestBase extends LuceneTestCase {
       assertTrue(((SortingDocsAndPositionsEnum) sortedPositions).reused(reuse)); // make sure reuse worked
     }
     doc = 0;
-    while ((doc = sortedPositions.advance(doc + _TestUtil.nextInt(random(), 1, 5))) != DocIdSetIterator.NO_MORE_DOCS) {
+    while ((doc = sortedPositions.advance(doc + TestUtil.nextInt(random(), 1, 5))) != DocIdSetIterator.NO_MORE_DOCS) {
       int freq = sortedPositions.freq();
       assertEquals("incorrect freq for doc=" + doc, sortedValues[doc].intValue() / 10 + 1, freq);
       for (int i = 0; i < freq; i++) {
         assertEquals("incorrect position for doc=" + doc, i, sortedPositions.nextPosition());
-        if (!doesntSupportOffsets.contains(_TestUtil.getPostingsFormat(DOC_POSITIONS_FIELD))) {
+        if (!doesntSupportOffsets.contains(TestUtil.getPostingsFormat(DOC_POSITIONS_FIELD))) {
           assertEquals("incorrect startOffset for doc=" + doc, i, sortedPositions.startOffset());
           assertEquals("incorrect endOffset for doc=" + doc, i, sortedPositions.endOffset());
         }
@@ -302,7 +302,7 @@ public abstract class SorterTestBase extends LuceneTestCase {
       }
     }
     final FixedBitSet bits = new FixedBitSet(maxDoc);
-    final int bitsSet = _TestUtil.nextInt(random(), 1, maxDoc - 1);
+    final int bitsSet = TestUtil.nextInt(random(), 1, maxDoc - 1);
     for (int i = 0; i < bitsSet; ++i) {
       while (true) {
         final int index = random().nextInt(maxDoc);
diff --git a/lucene/misc/src/test/org/apache/lucene/index/sorter/SortingAtomicReaderTest.java b/lucene/misc/src/test/org/apache/lucene/index/sorter/SortingAtomicReaderTest.java
index 24a0321..63876c7 100644
--- a/lucene/misc/src/test/org/apache/lucene/index/sorter/SortingAtomicReaderTest.java
+++ b/lucene/misc/src/test/org/apache/lucene/index/sorter/SortingAtomicReaderTest.java
@@ -22,7 +22,8 @@ import java.util.Arrays;
 
 import org.apache.lucene.index.AtomicReader;
 import org.apache.lucene.util.Bits;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.BeforeClass;
 
 public class SortingAtomicReaderTest extends SorterTestBase {
@@ -78,7 +79,7 @@ public class SortingAtomicReaderTest extends SorterTestBase {
       System.out.println();
     }
     
-    _TestUtil.checkReader(reader);
+    TestUtil.checkReader(reader);
   }
 
 }
diff --git a/lucene/misc/src/test/org/apache/lucene/index/sorter/TestEarlyTermination.java b/lucene/misc/src/test/org/apache/lucene/index/sorter/TestEarlyTermination.java
index ddbb922..a5bc3b2 100644
--- a/lucene/misc/src/test/org/apache/lucene/index/sorter/TestEarlyTermination.java
+++ b/lucene/misc/src/test/org/apache/lucene/index/sorter/TestEarlyTermination.java
@@ -42,7 +42,7 @@ import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.search.TopFieldCollector;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 import com.carrotsearch.randomizedtesting.generators.RandomPicks;
 
@@ -72,10 +72,10 @@ public class TestEarlyTermination extends LuceneTestCase {
   private void createRandomIndexes(int maxSegments) throws IOException {
     dir = newDirectory();
     numDocs = atLeast(150);
-    final int numTerms = _TestUtil.nextInt(random(), 1, numDocs / 5);
+    final int numTerms = TestUtil.nextInt(random(), 1, numDocs / 5);
     Set<String> randomTerms = new HashSet<String>();
     while (randomTerms.size() < numTerms) {
-      randomTerms.add(_TestUtil.randomSimpleString(random()));
+      randomTerms.add(TestUtil.randomSimpleString(random()));
     }
     terms = new ArrayList<String>(randomTerms);
     final long seed = random().nextLong();
@@ -106,7 +106,7 @@ public class TestEarlyTermination extends LuceneTestCase {
 
   public void testEarlyTermination() throws IOException {
     createRandomIndexes(5);
-    final int numHits = _TestUtil.nextInt(random(), 1, numDocs / 10);
+    final int numHits = TestUtil.nextInt(random(), 1, numDocs / 10);
     final Sort sort = new Sort(new SortField("ndv1", SortField.Type.LONG, false));
     final boolean fillFields = random().nextBoolean();
     final boolean trackDocScores = random().nextBoolean();
@@ -130,7 +130,7 @@ public class TestEarlyTermination extends LuceneTestCase {
     // test that the collector works correctly when the index was sorted by a
     // different sorter than the one specified in the ctor.
     createRandomIndexes(5);
-    final int numHits = _TestUtil.nextInt(random(), 1, numDocs / 10);
+    final int numHits = TestUtil.nextInt(random(), 1, numDocs / 10);
     final Sort sort = new Sort(new SortField("ndv2", SortField.Type.LONG, false));
     final boolean fillFields = random().nextBoolean();
     final boolean trackDocScores = random().nextBoolean();
diff --git a/lucene/misc/src/test/org/apache/lucene/index/sorter/TestSortingMergePolicy.java b/lucene/misc/src/test/org/apache/lucene/index/sorter/TestSortingMergePolicy.java
index 0ada118..93be226 100644
--- a/lucene/misc/src/test/org/apache/lucene/index/sorter/TestSortingMergePolicy.java
+++ b/lucene/misc/src/test/org/apache/lucene/index/sorter/TestSortingMergePolicy.java
@@ -42,7 +42,7 @@ import org.apache.lucene.index.Term;
 import org.apache.lucene.index.TieredMergePolicy;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 import com.carrotsearch.randomizedtesting.generators.RandomPicks;
 
@@ -73,13 +73,13 @@ public class TestSortingMergePolicy extends LuceneTestCase {
     MergePolicy mp;
     if (random().nextBoolean()) {
       TieredMergePolicy tmp = newTieredMergePolicy(random());
-      final int numSegs = _TestUtil.nextInt(random(), 3, 5);
+      final int numSegs = TestUtil.nextInt(random(), 3, 5);
       tmp.setSegmentsPerTier(numSegs);
-      tmp.setMaxMergeAtOnce(_TestUtil.nextInt(random(), 2, numSegs));
+      tmp.setMaxMergeAtOnce(TestUtil.nextInt(random(), 2, numSegs));
       mp = tmp;
     } else {
       LogMergePolicy lmp = newLogMergePolicy(random());
-      lmp.setMergeFactor(_TestUtil.nextInt(random(), 3, 5));
+      lmp.setMergeFactor(TestUtil.nextInt(random(), 3, 5));
       mp = lmp;
     }
     // wrap it with a sorting mp
@@ -90,10 +90,10 @@ public class TestSortingMergePolicy extends LuceneTestCase {
     dir1 = newDirectory();
     dir2 = newDirectory();
     final int numDocs = atLeast(150);
-    final int numTerms = _TestUtil.nextInt(random(), 1, numDocs / 5);
+    final int numTerms = TestUtil.nextInt(random(), 1, numDocs / 5);
     Set<String> randomTerms = new HashSet<String>();
     while (randomTerms.size() < numTerms) {
-      randomTerms.add(_TestUtil.randomSimpleString(random()));
+      randomTerms.add(TestUtil.randomSimpleString(random()));
     }
     terms = new ArrayList<String>(randomTerms);
     final long seed = random().nextLong();
diff --git a/lucene/misc/src/test/org/apache/lucene/misc/TestHighFreqTerms.java b/lucene/misc/src/test/org/apache/lucene/misc/TestHighFreqTerms.java
index 4faef8f..3ff868c 100644
--- a/lucene/misc/src/test/org/apache/lucene/misc/TestHighFreqTerms.java
+++ b/lucene/misc/src/test/org/apache/lucene/misc/TestHighFreqTerms.java
@@ -28,7 +28,7 @@ import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.AfterClass;
 import org.junit.BeforeClass;
 
@@ -46,7 +46,7 @@ public class TestHighFreqTerms extends LuceneTestCase {
        .setMaxBufferedDocs(2));
     indexDocs(writer);
     reader = DirectoryReader.open(dir);
-    _TestUtil.checkIndex(dir);
+    TestUtil.checkIndex(dir);
   }
   
   @AfterClass
diff --git a/lucene/misc/src/test/org/apache/lucene/util/fst/TestFSTsMisc.java b/lucene/misc/src/test/org/apache/lucene/util/fst/TestFSTsMisc.java
index ec39525..caa5b5f 100644
--- a/lucene/misc/src/test/org/apache/lucene/util/fst/TestFSTsMisc.java
+++ b/lucene/misc/src/test/org/apache/lucene/util/fst/TestFSTsMisc.java
@@ -29,7 +29,8 @@ import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IntsRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.fst.UpToTwoPositiveIntOutputs.TwoLongs;
 
 import static org.apache.lucene.util.fst.FSTTester.getRandomString;
@@ -91,15 +92,15 @@ public class TestFSTsMisc extends LuceneTestCase {
       long lastOutput = 0;
       for(int idx=0;idx<terms.length;idx++) {
         // Sometimes go backwards
-        long value = lastOutput + _TestUtil.nextInt(random(), -100, 1000);
+        long value = lastOutput + TestUtil.nextInt(random(), -100, 1000);
         while(value < 0) {
-          value = lastOutput + _TestUtil.nextInt(random(), -100, 1000);
+          value = lastOutput + TestUtil.nextInt(random(), -100, 1000);
         }
         final Object output;
         if (random().nextInt(5) == 3) {
-          long value2 = lastOutput + _TestUtil.nextInt(random(), -100, 1000);
+          long value2 = lastOutput + TestUtil.nextInt(random(), -100, 1000);
           while(value2 < 0) {
-            value2 = lastOutput + _TestUtil.nextInt(random(), -100, 1000);
+            value2 = lastOutput + TestUtil.nextInt(random(), -100, 1000);
           }
           List<Long> values = new ArrayList<Long>();
           values.add(value);
@@ -137,13 +138,13 @@ public class TestFSTsMisc extends LuceneTestCase {
       long lastOutput = 0;
       for(int idx=0;idx<terms.length;idx++) {
         
-        int outputCount = _TestUtil.nextInt(random(), 1, 7);
+        int outputCount = TestUtil.nextInt(random(), 1, 7);
         List<Long> values = new ArrayList<Long>();
         for(int i=0;i<outputCount;i++) {
           // Sometimes go backwards
-          long value = lastOutput + _TestUtil.nextInt(random(), -100, 1000);
+          long value = lastOutput + TestUtil.nextInt(random(), -100, 1000);
           while(value < 0) {
-            value = lastOutput + _TestUtil.nextInt(random(), -100, 1000);
+            value = lastOutput + TestUtil.nextInt(random(), -100, 1000);
           }
           values.add(value);
           lastOutput = value;
diff --git a/lucene/queries/src/test/org/apache/lucene/queries/CommonTermsQueryTest.java b/lucene/queries/src/test/org/apache/lucene/queries/CommonTermsQueryTest.java
index cc06eda..ec87641 100644
--- a/lucene/queries/src/test/org/apache/lucene/queries/CommonTermsQueryTest.java
+++ b/lucene/queries/src/test/org/apache/lucene/queries/CommonTermsQueryTest.java
@@ -48,7 +48,8 @@ import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LineFileDocs;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.PriorityQueue;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class CommonTermsQueryTest extends LuceneTestCase {
   
@@ -130,8 +131,8 @@ public class CommonTermsQueryTest extends LuceneTestCase {
         randomOccur(random()), random().nextFloat(), random().nextBoolean());
     int terms = atLeast(2);
     for (int i = 0; i < terms; i++) {
-      query.add(new Term(_TestUtil.randomRealisticUnicodeString(random()),
-          _TestUtil.randomRealisticUnicodeString(random())));
+      query.add(new Term(TestUtil.randomRealisticUnicodeString(random()),
+          TestUtil.randomRealisticUnicodeString(random())));
     }
     QueryUtils.checkHashEquals(query);
     QueryUtils.checkUnequal(new CommonTermsQuery(randomOccur(random()),
@@ -145,7 +146,7 @@ public class CommonTermsQueryTest extends LuceneTestCase {
           randomOccur(r), r.nextFloat(), r.nextBoolean());
       int leftTerms = atLeast(r, 2);
       for (int i = 0; i < leftTerms; i++) {
-        left.add(new Term(_TestUtil.randomRealisticUnicodeString(r), _TestUtil
+        left.add(new Term(TestUtil.randomRealisticUnicodeString(r), TestUtil
             .randomRealisticUnicodeString(r)));
       }
       left.setHighFreqMinimumNumberShouldMatch(r.nextInt(4));
@@ -156,7 +157,7 @@ public class CommonTermsQueryTest extends LuceneTestCase {
           randomOccur(r), r.nextFloat(), r.nextBoolean());
       int rightTerms = atLeast(r, 2);
       for (int i = 0; i < rightTerms; i++) {
-        right.add(new Term(_TestUtil.randomRealisticUnicodeString(r), _TestUtil
+        right.add(new Term(TestUtil.randomRealisticUnicodeString(r), TestUtil
             .randomRealisticUnicodeString(r)));
       }
       right.setHighFreqMinimumNumberShouldMatch(r.nextInt(4));
diff --git a/lucene/queries/src/test/org/apache/lucene/queries/TermFilterTest.java b/lucene/queries/src/test/org/apache/lucene/queries/TermFilterTest.java
index 2d65b8f..e46dd70 100644
--- a/lucene/queries/src/test/org/apache/lucene/queries/TermFilterTest.java
+++ b/lucene/queries/src/test/org/apache/lucene/queries/TermFilterTest.java
@@ -34,7 +34,7 @@ import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.search.TopDocs;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 import java.io.IOException;
 import java.util.ArrayList;
@@ -87,7 +87,7 @@ public class TermFilterTest extends LuceneTestCase {
     List<Term> terms = new ArrayList<Term>();
     for (int i = 0; i < num; i++) {
       String field = "field" + i;
-      String string = _TestUtil.randomRealisticUnicodeString(random());
+      String string = TestUtil.randomRealisticUnicodeString(random());
       terms.add(new Term(field, string));
       Document doc = new Document();
       doc.add(newStringField(field, string, Field.Store.NO));
@@ -122,7 +122,7 @@ public class TermFilterTest extends LuceneTestCase {
     for (int i = 0; i < num; i++) {
       String field1 = "field" + i;
       String field2 = "field" + i + num;
-      String value1 = _TestUtil.randomRealisticUnicodeString(random());
+      String value1 = TestUtil.randomRealisticUnicodeString(random());
       String value2 = value1 + "x"; // this must be not equal to value1
 
       TermFilter filter1 = termFilter(field1, value1);
diff --git a/lucene/queries/src/test/org/apache/lucene/queries/TermsFilterTest.java b/lucene/queries/src/test/org/apache/lucene/queries/TermsFilterTest.java
index c0c161e..2a07118 100644
--- a/lucene/queries/src/test/org/apache/lucene/queries/TermsFilterTest.java
+++ b/lucene/queries/src/test/org/apache/lucene/queries/TermsFilterTest.java
@@ -49,7 +49,8 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TermsFilterTest extends LuceneTestCase {
 
@@ -213,7 +214,7 @@ public class TermsFilterTest extends LuceneTestCase {
     List<Term> terms = new ArrayList<Term>();
     for (int i = 0; i < num; i++) {
       String field = "field" + (singleField ? "1" : random().nextInt(100));
-      String string = _TestUtil.randomRealisticUnicodeString(random());
+      String string = TestUtil.randomRealisticUnicodeString(random());
       terms.add(new Term(field, string));
       Document doc = new Document();
       doc.add(newStringField(field, string, Field.Store.YES));
@@ -279,7 +280,7 @@ public class TermsFilterTest extends LuceneTestCase {
     Set<Term> uniqueTerms = new HashSet<Term>();
     for (int i = 0; i < num; i++) {
       String field = "field" + (singleField ? "1" : random().nextInt(100));
-      String string = _TestUtil.randomRealisticUnicodeString(random());
+      String string = TestUtil.randomRealisticUnicodeString(random());
       terms.add(new Term(field, string));
       uniqueTerms.add(new Term(field, string));
       TermsFilter left = termsFilter(singleField ? random().nextBoolean() : false, uniqueTerms);
diff --git a/lucene/queries/src/test/org/apache/lucene/queries/function/FunctionTestSetup.java b/lucene/queries/src/test/org/apache/lucene/queries/function/FunctionTestSetup.java
index 4f3c012..76c64b8 100644
--- a/lucene/queries/src/test/org/apache/lucene/queries/function/FunctionTestSetup.java
+++ b/lucene/queries/src/test/org/apache/lucene/queries/function/FunctionTestSetup.java
@@ -21,7 +21,7 @@ import org.apache.lucene.search.FieldCache;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.AfterClass;
 import org.junit.Ignore;
 
@@ -113,7 +113,7 @@ public abstract class FunctionTestSetup extends LuceneTestCase {
     anlzr = new MockAnalyzer(random());
     IndexWriterConfig iwc = newIndexWriterConfig( TEST_VERSION_CURRENT, anlzr).setMergePolicy(newLogMergePolicy());
     if (doMultiSegment) {
-      iwc.setMaxBufferedDocs(_TestUtil.nextInt(random(), 2, 7));
+      iwc.setMaxBufferedDocs(TestUtil.nextInt(random(), 2, 7));
     }
     RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);
     // add docs not exactly in natural ID order, to verify we do check the order of docs by scores
diff --git a/lucene/queries/src/test/org/apache/lucene/queries/function/TestDocValuesFieldSources.java b/lucene/queries/src/test/org/apache/lucene/queries/function/TestDocValuesFieldSources.java
index 3d2a1a2..95bc62a 100644
--- a/lucene/queries/src/test/org/apache/lucene/queries/function/TestDocValuesFieldSources.java
+++ b/lucene/queries/src/test/org/apache/lucene/queries/function/TestDocValuesFieldSources.java
@@ -35,7 +35,8 @@ import org.apache.lucene.queries.function.valuesource.LongFieldSource;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.packed.PackedInts;
 
 import com.carrotsearch.randomizedtesting.generators.RandomInts;
@@ -75,7 +76,7 @@ public class TestDocValuesFieldSources extends LuceneTestCase {
         case SORTED:
         case BINARY:
           do {
-            vals[i] = _TestUtil.randomSimpleString(random(), 20);
+            vals[i] = TestUtil.randomSimpleString(random(), 20);
           } while (((String) vals[i]).isEmpty());
           f.setBytesValue(new BytesRef((String) vals[i]));
           break;
diff --git a/lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/standard/TestNumericQueryParser.java b/lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/standard/TestNumericQueryParser.java
index 0a9ba02..a209ce2 100644
--- a/lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/standard/TestNumericQueryParser.java
+++ b/lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/standard/TestNumericQueryParser.java
@@ -52,7 +52,7 @@ import org.apache.lucene.search.Query;
 import org.apache.lucene.search.TopDocs;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.AfterClass;
 import org.junit.BeforeClass;
 import org.junit.Test;
@@ -190,7 +190,7 @@ public class TestNumericQueryParser extends LuceneTestCase {
     directory = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random(), directory,
         newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))
-            .setMaxBufferedDocs(_TestUtil.nextInt(random(), 50, 1000))
+            .setMaxBufferedDocs(TestUtil.nextInt(random(), 50, 1000))
             .setMergePolicy(newLogMergePolicy()));
     
     Document doc = new Document();
diff --git a/lucene/queryparser/src/test/org/apache/lucene/queryparser/simple/TestSimpleQueryParser.java b/lucene/queryparser/src/test/org/apache/lucene/queryparser/simple/TestSimpleQueryParser.java
index c852a06..7b55a53 100644
--- a/lucene/queryparser/src/test/org/apache/lucene/queryparser/simple/TestSimpleQueryParser.java
+++ b/lucene/queryparser/src/test/org/apache/lucene/queryparser/simple/TestSimpleQueryParser.java
@@ -34,7 +34,8 @@ import org.apache.lucene.search.PrefixQuery;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.automaton.LevenshteinAutomata;
 
 import static org.apache.lucene.queryparser.simple.SimpleQueryParser.AND_OPERATOR;
@@ -623,9 +624,9 @@ public class TestSimpleQueryParser extends LuceneTestCase {
   // we aren't supposed to barf on any input...
   public void testRandomQueries() throws Exception {
     for (int i = 0; i < 1000; i++) {
-      String query = _TestUtil.randomUnicodeString(random());
+      String query = TestUtil.randomUnicodeString(random());
       parse(query); // no exception
-      parseKeyword(query, _TestUtil.nextInt(random(), 0, 1024)); // no exception
+      parseKeyword(query, TestUtil.nextInt(random(), 0, 1024)); // no exception
     }
   }
 
@@ -639,7 +640,7 @@ public class TestSimpleQueryParser extends LuceneTestCase {
         sb.append(chars[random().nextInt(chars.length)]);
       }
       parse(sb.toString()); // no exception
-      parseKeyword(sb.toString(), _TestUtil.nextInt(random(), 0, 1024)); // no exception
+      parseKeyword(sb.toString(), TestUtil.nextInt(random(), 0, 1024)); // no exception
     }
   }
 }
\ No newline at end of file
diff --git a/lucene/replicator/src/test/org/apache/lucene/replicator/IndexAndTaxonomyReplicationClientTest.java b/lucene/replicator/src/test/org/apache/lucene/replicator/IndexAndTaxonomyReplicationClientTest.java
index c5c4f93..0462ce0 100644
--- a/lucene/replicator/src/test/org/apache/lucene/replicator/IndexAndTaxonomyReplicationClientTest.java
+++ b/lucene/replicator/src/test/org/apache/lucene/replicator/IndexAndTaxonomyReplicationClientTest.java
@@ -48,8 +48,8 @@ import org.apache.lucene.search.TopDocs;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.ThreadInterruptedException;
-import org.apache.lucene.util._TestUtil;
 import org.junit.After;
 import org.junit.Before;
 import org.junit.Test;
@@ -91,7 +91,7 @@ public class IndexAndTaxonomyReplicationClientTest extends ReplicatorTestCase {
         indexReader.close();
         indexReader = newReader;
         lastIndexGeneration = newGeneration;
-        _TestUtil.checkIndex(indexDir);
+        TestUtil.checkIndex(indexDir);
         
         // verify taxonomy index
         DirectoryTaxonomyReader newTaxoReader = TaxonomyReader.openIfChanged(taxoReader);
@@ -99,7 +99,7 @@ public class IndexAndTaxonomyReplicationClientTest extends ReplicatorTestCase {
           taxoReader.close();
           taxoReader = newTaxoReader;
         }
-        _TestUtil.checkIndex(taxoDir);
+        TestUtil.checkIndex(taxoDir);
         
         // verify faceted search
         int id = Integer.parseInt(indexReader.getIndexCommit().getUserData().get(VERSION_ID), 16);
@@ -191,7 +191,7 @@ public class IndexAndTaxonomyReplicationClientTest extends ReplicatorTestCase {
     publishTaxoDir = newDirectory();
     handlerIndexDir = newMockDirectory();
     handlerTaxoDir = newMockDirectory();
-    clientWorkDir = _TestUtil.getTempDir("replicationClientTest");
+    clientWorkDir = TestUtil.getTempDir("replicationClientTest");
     sourceDirFactory = new PerSessionDirectoryFactory(clientWorkDir);
     replicator = new LocalReplicator();
     callback = new IndexAndTaxonomyReadyCallback(handlerIndexDir, handlerTaxoDir);
@@ -399,11 +399,11 @@ public class IndexAndTaxonomyReplicationClientTest extends ReplicatorTestCase {
               reader.close();
             }
             // verify index is fully consistent
-            _TestUtil.checkIndex(handlerIndexDir.getDelegate());
+            TestUtil.checkIndex(handlerIndexDir.getDelegate());
             
             // verify taxonomy index is fully consistent (since we only add one
             // category to all documents, there's nothing much more to validate
-            _TestUtil.checkIndex(handlerTaxoDir.getDelegate());
+            TestUtil.checkIndex(handlerTaxoDir.getDelegate());
           } catch (IOException e) {
             throw new RuntimeException(e);
           } finally {
diff --git a/lucene/replicator/src/test/org/apache/lucene/replicator/IndexReplicationClientTest.java b/lucene/replicator/src/test/org/apache/lucene/replicator/IndexReplicationClientTest.java
index 0df3490..76e92e8 100644
--- a/lucene/replicator/src/test/org/apache/lucene/replicator/IndexReplicationClientTest.java
+++ b/lucene/replicator/src/test/org/apache/lucene/replicator/IndexReplicationClientTest.java
@@ -33,8 +33,8 @@ import org.apache.lucene.replicator.ReplicationClient.SourceDirectoryFactory;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.ThreadInterruptedException;
-import org.apache.lucene.util._TestUtil;
 import org.junit.After;
 import org.junit.Before;
 import org.junit.Test;
@@ -68,7 +68,7 @@ public class IndexReplicationClientTest extends ReplicatorTestCase {
         reader.close();
         reader = newReader;
         lastGeneration = newGeneration;
-        _TestUtil.checkIndex(indexDir);
+        TestUtil.checkIndex(indexDir);
       }
       return null;
     }
@@ -136,7 +136,7 @@ public class IndexReplicationClientTest extends ReplicatorTestCase {
     super.setUp();
     publishDir = newMockDirectory();
     handlerDir = newMockDirectory();
-    sourceDirFactory = new PerSessionDirectoryFactory(_TestUtil.getTempDir("replicationClientTest"));
+    sourceDirFactory = new PerSessionDirectoryFactory(TestUtil.getTempDir("replicationClientTest"));
     replicator = new LocalReplicator();
     callback = new IndexReadyCallback(handlerDir);
     handler = new IndexReplicationHandler(handlerDir, callback);
@@ -305,7 +305,7 @@ public class IndexReplicationClientTest extends ReplicatorTestCase {
               reader.close();
             }
             // verify index consistency
-            _TestUtil.checkIndex(handlerDir.getDelegate());
+            TestUtil.checkIndex(handlerDir.getDelegate());
           } catch (IOException e) {
             // exceptions here are bad, don't ignore them
             throw new RuntimeException(e);
diff --git a/lucene/replicator/src/test/org/apache/lucene/replicator/http/HttpReplicatorTest.java b/lucene/replicator/src/test/org/apache/lucene/replicator/http/HttpReplicatorTest.java
index 46b5942..b549f7f 100644
--- a/lucene/replicator/src/test/org/apache/lucene/replicator/http/HttpReplicatorTest.java
+++ b/lucene/replicator/src/test/org/apache/lucene/replicator/http/HttpReplicatorTest.java
@@ -35,7 +35,7 @@ import org.apache.lucene.replicator.Replicator;
 import org.apache.lucene.replicator.ReplicatorTestCase;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.IOUtils;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.eclipse.jetty.server.Server;
 import org.eclipse.jetty.servlet.ServletHandler;
 import org.eclipse.jetty.servlet.ServletHolder;
@@ -68,7 +68,7 @@ public class HttpReplicatorTest extends ReplicatorTestCase {
   public void setUp() throws Exception {
     super.setUp();
     System.setProperty("org.eclipse.jetty.LEVEL", "DEBUG"); // sets stderr logging to DEBUG level
-    clientWorkDir = _TestUtil.getTempDir("httpReplicatorTest");
+    clientWorkDir = TestUtil.getTempDir("httpReplicatorTest");
     handlerIndexDir = newDirectory();
     serverIndexDir = newDirectory();
     serverReplicator = new LocalReplicator();
diff --git a/lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/DuplicateFilterTest.java b/lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/DuplicateFilterTest.java
index 2d9040b..260e85b 100644
--- a/lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/DuplicateFilterTest.java
+++ b/lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/DuplicateFilterTest.java
@@ -31,7 +31,7 @@ import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class DuplicateFilterTest extends LuceneTestCase {
   private static final String KEY_FIELD = "url";
@@ -134,12 +134,12 @@ public class DuplicateFilterTest extends LuceneTestCase {
     for (ScoreDoc hit : hits) {
       StoredDocument d = searcher.doc(hit.doc);
       String url = d.get(KEY_FIELD);
-      DocsEnum td = _TestUtil.docs(random(), reader,
-                                   KEY_FIELD,
-                                   new BytesRef(url),
-                                   MultiFields.getLiveDocs(reader),
-                                   null,
-                                   0);
+      DocsEnum td = TestUtil.docs(random(), reader,
+          KEY_FIELD,
+          new BytesRef(url),
+          MultiFields.getLiveDocs(reader),
+          null,
+          0);
 
       int lastDoc = 0;
       while (td.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
@@ -158,12 +158,12 @@ public class DuplicateFilterTest extends LuceneTestCase {
     for (ScoreDoc hit : hits) {
       StoredDocument d = searcher.doc(hit.doc);
       String url = d.get(KEY_FIELD);
-      DocsEnum td = _TestUtil.docs(random(), reader,
-                                   KEY_FIELD,
-                                   new BytesRef(url),
-                                   MultiFields.getLiveDocs(reader),
-                                   null,
-                                   0);
+      DocsEnum td = TestUtil.docs(random(), reader,
+          KEY_FIELD,
+          new BytesRef(url),
+          MultiFields.getLiveDocs(reader),
+          null,
+          0);
 
       int lastDoc = 0;
       td.nextDoc();
diff --git a/lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/TestSlowCollationMethods.java b/lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/TestSlowCollationMethods.java
index b556169..6b485f6 100644
--- a/lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/TestSlowCollationMethods.java
+++ b/lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/TestSlowCollationMethods.java
@@ -11,7 +11,7 @@ import org.apache.lucene.search.*;
 import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.AfterClass;
 import org.junit.BeforeClass;
 
@@ -55,12 +55,12 @@ public class TestSlowCollationMethods extends LuceneTestCase {
     RandomIndexWriter iw = new RandomIndexWriter(random(), dir);
     for (int i = 0; i < numDocs; i++) {
       Document doc = new Document();
-      String value = _TestUtil.randomUnicodeString(random());
+      String value = TestUtil.randomUnicodeString(random());
       Field field = newStringField("field", value, Field.Store.YES);
       doc.add(field);
       iw.addDocument(doc);
     }
-    splitDoc = _TestUtil.randomUnicodeString(random());
+    splitDoc = TestUtil.randomUnicodeString(random());
     reader = iw.getReader();
     iw.close();
 
@@ -130,8 +130,8 @@ public class TestSlowCollationMethods extends LuceneTestCase {
   public void testRangeQuery() throws Exception {
     int numQueries = 50*RANDOM_MULTIPLIER;
     for (int i = 0; i < numQueries; i++) {
-      String startPoint = _TestUtil.randomUnicodeString(random());
-      String endPoint = _TestUtil.randomUnicodeString(random());
+      String startPoint = TestUtil.randomUnicodeString(random());
+      String endPoint = TestUtil.randomUnicodeString(random());
       Query query = new SlowCollatedTermRangeQuery("field", startPoint, endPoint, true, true, collator);
       doTestRanges(startPoint, endPoint, query);
     }
@@ -140,8 +140,8 @@ public class TestSlowCollationMethods extends LuceneTestCase {
   public void testRangeFilter() throws Exception {
     int numQueries = 50*RANDOM_MULTIPLIER;
     for (int i = 0; i < numQueries; i++) {
-      String startPoint = _TestUtil.randomUnicodeString(random());
-      String endPoint = _TestUtil.randomUnicodeString(random());
+      String startPoint = TestUtil.randomUnicodeString(random());
+      String endPoint = TestUtil.randomUnicodeString(random());
       Query query = new ConstantScoreQuery(new SlowCollatedTermRangeFilter("field", startPoint, endPoint, true, true, collator));
       doTestRanges(startPoint, endPoint, query);
     }
@@ -162,7 +162,7 @@ public class TestSlowCollationMethods extends LuceneTestCase {
     RandomIndexWriter iw = new RandomIndexWriter(random(), dir);
     for (int i = 0; i < numDocs; i++) {
       Document doc = new Document();
-      String value = _TestUtil.randomUnicodeString(random());
+      String value = TestUtil.randomUnicodeString(random());
       Field field = newStringField("field", value, Field.Store.YES);
       doc.add(field);
       iw.addDocument(doc);
@@ -172,8 +172,8 @@ public class TestSlowCollationMethods extends LuceneTestCase {
 
     IndexSearcher searcher = newSearcher(reader);
 
-    String startPoint = _TestUtil.randomUnicodeString(random());
-    String endPoint = _TestUtil.randomUnicodeString(random());
+    String startPoint = TestUtil.randomUnicodeString(random());
+    String endPoint = TestUtil.randomUnicodeString(random());
     Query query = new SlowCollatedTermRangeQuery("field", startPoint, endPoint, true, true, collator);
     QueryUtils.check(random(), query, searcher);
     reader.close();
diff --git a/lucene/spatial/src/test/org/apache/lucene/spatial/SpatialTestCase.java b/lucene/spatial/src/test/org/apache/lucene/spatial/SpatialTestCase.java
index f1b7f8f..51e4bc6 100644
--- a/lucene/spatial/src/test/org/apache/lucene/spatial/SpatialTestCase.java
+++ b/lucene/spatial/src/test/org/apache/lucene/spatial/SpatialTestCase.java
@@ -34,7 +34,7 @@ import org.apache.lucene.search.TopDocs;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.After;
 import org.junit.Before;
 
@@ -72,7 +72,7 @@ public abstract class SpatialTestCase extends LuceneTestCase {
     final IndexWriterConfig indexWriterConfig = LuceneTestCase.newIndexWriterConfig(random, LuceneTestCase.TEST_VERSION_CURRENT, new MockAnalyzer(random));
     //TODO can we randomly choose a doc-values supported format?
     if (needsDocValues())
-      indexWriterConfig.setCodec( _TestUtil.alwaysDocValuesFormat(new Lucene45DocValuesFormat()));;
+      indexWriterConfig.setCodec( TestUtil.alwaysDocValuesFormat(new Lucene45DocValuesFormat()));;
     return indexWriterConfig;
   }
 
diff --git a/lucene/suggest/src/test/org/apache/lucene/search/spell/TestWordBreakSpellChecker.java b/lucene/suggest/src/test/org/apache/lucene/search/spell/TestWordBreakSpellChecker.java
index 58a8807..e5dfc45 100644
--- a/lucene/suggest/src/test/org/apache/lucene/search/spell/TestWordBreakSpellChecker.java
+++ b/lucene/suggest/src/test/org/apache/lucene/search/spell/TestWordBreakSpellChecker.java
@@ -35,7 +35,7 @@ import org.apache.lucene.search.spell.WordBreakSpellChecker.BreakSuggestionSortM
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.English;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestWordBreakSpellChecker extends LuceneTestCase {
   private Directory dir = null;
@@ -262,7 +262,7 @@ public class TestWordBreakSpellChecker extends LuceneTestCase {
     }    
   }
   public void testRandom() throws Exception {
-    int numDocs = _TestUtil.nextInt(random(), (10 * RANDOM_MULTIPLIER),
+    int numDocs = TestUtil.nextInt(random(), (10 * RANDOM_MULTIPLIER),
         (100 * RANDOM_MULTIPLIER));
     Directory dir = null;
     RandomIndexWriter writer = null;
@@ -271,24 +271,24 @@ public class TestWordBreakSpellChecker extends LuceneTestCase {
       dir = newDirectory();
       writer = new RandomIndexWriter(random(), dir, new MockAnalyzer(random(),
           MockTokenizer.WHITESPACE, false));
-      int maxLength = _TestUtil.nextInt(random(), 5, 50);
+      int maxLength = TestUtil.nextInt(random(), 5, 50);
       List<String> originals = new ArrayList<String>(numDocs);
       List<String[]> breaks = new ArrayList<String[]>(numDocs);
       for (int i = 0; i < numDocs; i++) {
         String orig = "";
         if (random().nextBoolean()) {
           while (!goodTestString(orig)) {
-            orig = _TestUtil.randomSimpleString(random(), maxLength);
+            orig = TestUtil.randomSimpleString(random(), maxLength);
           }
         } else {
           while (!goodTestString(orig)) {
-            orig = _TestUtil.randomUnicodeString(random(), maxLength);
+            orig = TestUtil.randomUnicodeString(random(), maxLength);
           }
         }
         originals.add(orig);
         int totalLength = orig.codePointCount(0, orig.length());
         int breakAt = orig.offsetByCodePoints(0,
-            _TestUtil.nextInt(random(), 1, totalLength - 1));
+            TestUtil.nextInt(random(), 1, totalLength - 1));
         String[] broken = new String[2];
         broken[0] = orig.substring(0, breakAt);
         broken[1] = orig.substring(breakAt);
diff --git a/lucene/suggest/src/test/org/apache/lucene/search/suggest/FileDictionaryTest.java b/lucene/suggest/src/test/org/apache/lucene/search/suggest/FileDictionaryTest.java
index 665af98..ba4e675 100644
--- a/lucene/suggest/src/test/org/apache/lucene/search/suggest/FileDictionaryTest.java
+++ b/lucene/suggest/src/test/org/apache/lucene/search/suggest/FileDictionaryTest.java
@@ -10,7 +10,8 @@ import java.util.Map;
 
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.Test;
 
 
@@ -36,18 +37,18 @@ public class FileDictionaryTest extends LuceneTestCase {
   private Map.Entry<List<String>, String> generateFileEntry(String fieldDelimiter, boolean hasWeight, boolean hasPayload) {
     List<String> entryValues = new ArrayList<>();
     StringBuilder sb = new StringBuilder();
-    String term = _TestUtil.randomSimpleString(random(), 1, 300);
+    String term = TestUtil.randomSimpleString(random(), 1, 300);
     sb.append(term);
     entryValues.add(term);
     if (hasWeight) {
       sb.append(fieldDelimiter);
-      long weight = _TestUtil.nextLong(random(), Long.MIN_VALUE, Long.MAX_VALUE);
+      long weight = TestUtil.nextLong(random(), Long.MIN_VALUE, Long.MAX_VALUE);
       sb.append(weight);
       entryValues.add(String.valueOf(weight));
     }
     if (hasPayload) {
       sb.append(fieldDelimiter);
-      String payload = _TestUtil.randomSimpleString(random(), 1, 300);
+      String payload = TestUtil.randomSimpleString(random(), 1, 300);
       sb.append(payload);
       entryValues.add(payload);
     }
diff --git a/lucene/suggest/src/test/org/apache/lucene/search/suggest/LookupBenchmarkTest.java b/lucene/suggest/src/test/org/apache/lucene/search/suggest/LookupBenchmarkTest.java
index 4874234..16ee899 100644
--- a/lucene/suggest/src/test/org/apache/lucene/search/suggest/LookupBenchmarkTest.java
+++ b/lucene/suggest/src/test/org/apache/lucene/search/suggest/LookupBenchmarkTest.java
@@ -33,7 +33,6 @@ import java.util.concurrent.Callable;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.search.suggest.Lookup; // javadocs
 import org.apache.lucene.search.suggest.analyzing.AnalyzingInfixSuggester;
 import org.apache.lucene.search.suggest.analyzing.AnalyzingSuggester;
 import org.apache.lucene.search.suggest.analyzing.FuzzySuggester;
@@ -162,7 +161,7 @@ public class LookupBenchmarkTest extends LuceneTestCase {
     } catch (InstantiationException e) {
       Analyzer a = new MockAnalyzer(random, MockTokenizer.KEYWORD, false);
       if (cls == AnalyzingInfixSuggester.class) {
-        lookup = new AnalyzingInfixSuggester(TEST_VERSION_CURRENT, _TestUtil.getTempDir("LookupBenchmarkTest"), a);
+        lookup = new AnalyzingInfixSuggester(TEST_VERSION_CURRENT, TestUtil.getTempDir("LookupBenchmarkTest"), a);
       } else {
         Constructor<? extends Lookup> ctor = cls.getConstructor(Analyzer.class);
         lookup = ctor.newInstance(a);
diff --git a/lucene/suggest/src/test/org/apache/lucene/search/suggest/PersistenceTest.java b/lucene/suggest/src/test/org/apache/lucene/search/suggest/PersistenceTest.java
index f98f90f..3a29eff 100644
--- a/lucene/suggest/src/test/org/apache/lucene/search/suggest/PersistenceTest.java
+++ b/lucene/suggest/src/test/org/apache/lucene/search/suggest/PersistenceTest.java
@@ -22,13 +22,12 @@ import java.io.FileInputStream;
 import java.io.FileOutputStream;
 import java.util.List;
 
-import org.apache.lucene.search.suggest.Lookup;
 import org.apache.lucene.search.suggest.Lookup.LookupResult;
 import org.apache.lucene.search.suggest.fst.FSTCompletionLookup;
 import org.apache.lucene.search.suggest.jaspell.JaspellLookup;
 import org.apache.lucene.search.suggest.tst.TSTLookup;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class PersistenceTest extends LuceneTestCase {
   public final String[] keys = new String[] {
@@ -82,7 +81,7 @@ public class PersistenceTest extends LuceneTestCase {
     Random random = random();
     long previous = Long.MIN_VALUE;
     for (Input k : keys) {
-      List<LookupResult> list = lookup.lookup(_TestUtil.bytesToCharSequence(k.term, random), false, 1);
+      List<LookupResult> list = lookup.lookup(TestUtil.bytesToCharSequence(k.term, random), false, 1);
       assertEquals(1, list.size());
       LookupResult lookupResult = list.get(0);
       assertNotNull(k.term.utf8ToString(), lookupResult.key);
diff --git a/lucene/suggest/src/test/org/apache/lucene/search/suggest/TestBytesRefArray.java b/lucene/suggest/src/test/org/apache/lucene/search/suggest/TestBytesRefArray.java
index 49bc12d..935b71b 100644
--- a/lucene/suggest/src/test/org/apache/lucene/search/suggest/TestBytesRefArray.java
+++ b/lucene/suggest/src/test/org/apache/lucene/search/suggest/TestBytesRefArray.java
@@ -24,7 +24,7 @@ import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefIterator;
 import org.apache.lucene.util.Counter;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestBytesRefArray extends LuceneTestCase {
 
@@ -41,7 +41,7 @@ public class TestBytesRefArray extends LuceneTestCase {
       BytesRef spare = new BytesRef();
       int initSize = list.size();
       for (int i = 0; i < entries; i++) {
-        String randomRealisticUnicodeString = _TestUtil
+        String randomRealisticUnicodeString = TestUtil
             .randomRealisticUnicodeString(random);
         spare.copyChars(randomRealisticUnicodeString);
         assertEquals(i+initSize, list.append(spare));
@@ -84,7 +84,7 @@ public class TestBytesRefArray extends LuceneTestCase {
       BytesRef spare = new BytesRef();
       final int initSize = list.size();
       for (int i = 0; i < entries; i++) {
-        String randomRealisticUnicodeString = _TestUtil
+        String randomRealisticUnicodeString = TestUtil
             .randomRealisticUnicodeString(random);
         spare.copyChars(randomRealisticUnicodeString);
         assertEquals(initSize + i, list.append(spare));
diff --git a/lucene/suggest/src/test/org/apache/lucene/search/suggest/TestInputIterator.java b/lucene/suggest/src/test/org/apache/lucene/search/suggest/TestInputIterator.java
index b0c423d..ae09978 100644
--- a/lucene/suggest/src/test/org/apache/lucene/search/suggest/TestInputIterator.java
+++ b/lucene/suggest/src/test/org/apache/lucene/search/suggest/TestInputIterator.java
@@ -24,12 +24,9 @@ import java.util.Map;
 import java.util.Random;
 import java.util.TreeMap;
 
-import org.apache.lucene.store.ByteArrayDataOutput;
-import org.apache.lucene.util.ArrayUtil;
 import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.BytesRefHash;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestInputIterator extends LuceneTestCase {
   
@@ -55,8 +52,8 @@ public class TestInputIterator extends LuceneTestCase {
       BytesRef key;
       BytesRef payload;
       do {
-        key = new BytesRef(_TestUtil.randomUnicodeString(random));
-        payload = new BytesRef(_TestUtil.randomUnicodeString(random));
+        key = new BytesRef(TestUtil.randomUnicodeString(random));
+        payload = new BytesRef(TestUtil.randomUnicodeString(random));
       } while (sorted.containsKey(key));
       long value = random.nextLong();
       sortedWithoutPayload.put(key, value);
diff --git a/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggesterTest.java b/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggesterTest.java
index 9384267..4981b33 100644
--- a/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggesterTest.java
+++ b/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggesterTest.java
@@ -19,7 +19,6 @@ package org.apache.lucene.search.suggest.analyzing;
 
 import java.io.File;
 import java.io.IOException;
-import java.io.Reader;
 import java.io.StringReader;
 import java.util.ArrayList;
 import java.util.List;
@@ -40,7 +39,7 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase.SuppressCodecs;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 // Test requires postings offsets:
 @SuppressCodecs({"Lucene3x","MockFixedIntBlock","MockVariableIntBlock","MockSep","MockRandom"})
@@ -52,7 +51,7 @@ public class AnalyzingInfixSuggesterTest extends LuceneTestCase {
       new Input("a penny saved is a penny earned", 10, new BytesRef("foobaz")),
     };
 
-    File tempDir = _TestUtil.getTempDir("AnalyzingInfixSuggesterTest");
+    File tempDir = TestUtil.getTempDir("AnalyzingInfixSuggesterTest");
 
     Analyzer a = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);
     AnalyzingInfixSuggester suggester = new AnalyzingInfixSuggester(TEST_VERSION_CURRENT, tempDir, a, a, 3) {
@@ -63,7 +62,7 @@ public class AnalyzingInfixSuggesterTest extends LuceneTestCase {
       };
     suggester.build(new InputArrayIterator(keys));
 
-    List<LookupResult> results = suggester.lookup(_TestUtil.stringToCharSequence("ear", random()), 10, true, true);
+    List<LookupResult> results = suggester.lookup(TestUtil.stringToCharSequence("ear", random()), 10, true, true);
     assertEquals(2, results.size());
     assertEquals("a penny saved is a penny <b>ear</b>ned", results.get(0).key);
     assertEquals(10, results.get(0).value);
@@ -73,19 +72,19 @@ public class AnalyzingInfixSuggesterTest extends LuceneTestCase {
     assertEquals(8, results.get(1).value);
     assertEquals(new BytesRef("foobar"), results.get(1).payload);
 
-    results = suggester.lookup(_TestUtil.stringToCharSequence("ear ", random()), 10, true, true);
+    results = suggester.lookup(TestUtil.stringToCharSequence("ear ", random()), 10, true, true);
     assertEquals(1, results.size());
     assertEquals("lend me your <b>ear</b>", results.get(0).key);
     assertEquals(8, results.get(0).value);
     assertEquals(new BytesRef("foobar"), results.get(0).payload);
 
-    results = suggester.lookup(_TestUtil.stringToCharSequence("pen", random()), 10, true, true);
+    results = suggester.lookup(TestUtil.stringToCharSequence("pen", random()), 10, true, true);
     assertEquals(1, results.size());
     assertEquals("a <b>pen</b>ny saved is a <b>pen</b>ny earned", results.get(0).key);
     assertEquals(10, results.get(0).value);
     assertEquals(new BytesRef("foobaz"), results.get(0).payload);
 
-    results = suggester.lookup(_TestUtil.stringToCharSequence("p", random()), 10, true, true);
+    results = suggester.lookup(TestUtil.stringToCharSequence("p", random()), 10, true, true);
     assertEquals(1, results.size());
     assertEquals("a <b>p</b>enny saved is a <b>p</b>enny earned", results.get(0).key);
     assertEquals(10, results.get(0).value);
@@ -100,7 +99,7 @@ public class AnalyzingInfixSuggesterTest extends LuceneTestCase {
       new Input("a penny saved is a penny earned", 10, new BytesRef("foobaz")),
     };
 
-    File tempDir = _TestUtil.getTempDir("AnalyzingInfixSuggesterTest");
+    File tempDir = TestUtil.getTempDir("AnalyzingInfixSuggesterTest");
 
     Analyzer a = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);
     AnalyzingInfixSuggester suggester = new AnalyzingInfixSuggester(TEST_VERSION_CURRENT, tempDir, a, a, 3) {
@@ -119,7 +118,7 @@ public class AnalyzingInfixSuggesterTest extends LuceneTestCase {
           return newFSDirectory(path);
         }
       };
-    List<LookupResult> results = suggester.lookup(_TestUtil.stringToCharSequence("ear", random()), 10, true, true);
+    List<LookupResult> results = suggester.lookup(TestUtil.stringToCharSequence("ear", random()), 10, true, true);
     assertEquals(2, results.size());
     assertEquals("a penny saved is a penny <b>ear</b>ned", results.get(0).key);
     assertEquals(10, results.get(0).value);
@@ -156,7 +155,7 @@ public class AnalyzingInfixSuggesterTest extends LuceneTestCase {
       new Input("a penny saved is a penny earned", 10, new BytesRef("foobaz")),
     };
 
-    File tempDir = _TestUtil.getTempDir("AnalyzingInfixSuggesterTest");
+    File tempDir = TestUtil.getTempDir("AnalyzingInfixSuggesterTest");
 
     Analyzer a = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);
     AnalyzingInfixSuggester suggester = new AnalyzingInfixSuggester(TEST_VERSION_CURRENT, tempDir, a, a, 3) {
@@ -208,7 +207,7 @@ public class AnalyzingInfixSuggesterTest extends LuceneTestCase {
       };
     suggester.build(new InputArrayIterator(keys));
 
-    List<LookupResult> results = suggester.lookup(_TestUtil.stringToCharSequence("ear", random()), 10, true, true);
+    List<LookupResult> results = suggester.lookup(TestUtil.stringToCharSequence("ear", random()), 10, true, true);
     assertEquals(1, results.size());
     assertEquals("a penny saved is a penny <b>ear</b>ned", toString((List<LookupHighlightFragment>) results.get(0).highlightKey));
     assertEquals(10, results.get(0).value);
@@ -237,7 +236,7 @@ public class AnalyzingInfixSuggesterTest extends LuceneTestCase {
       new Input("a penny saved is a penny earned", 10, new BytesRef("foobaz")),
     };
 
-    File tempDir = _TestUtil.getTempDir("AnalyzingInfixSuggesterTest");
+    File tempDir = TestUtil.getTempDir("AnalyzingInfixSuggesterTest");
 
     Analyzer a = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);
     int minPrefixLength = random().nextInt(10);
@@ -253,7 +252,7 @@ public class AnalyzingInfixSuggesterTest extends LuceneTestCase {
       for(int j=0;j<2;j++) {
         boolean doHighlight = j == 0;
 
-        List<LookupResult> results = suggester.lookup(_TestUtil.stringToCharSequence("ear", random()), 10, true, doHighlight);
+        List<LookupResult> results = suggester.lookup(TestUtil.stringToCharSequence("ear", random()), 10, true, doHighlight);
         assertEquals(2, results.size());
         if (doHighlight) {
           assertEquals("a penny saved is a penny <b>ear</b>ned", results.get(0).key);
@@ -270,7 +269,7 @@ public class AnalyzingInfixSuggesterTest extends LuceneTestCase {
         assertEquals(8, results.get(1).value);
         assertEquals(new BytesRef("foobar"), results.get(1).payload);
 
-        results = suggester.lookup(_TestUtil.stringToCharSequence("ear ", random()), 10, true, doHighlight);
+        results = suggester.lookup(TestUtil.stringToCharSequence("ear ", random()), 10, true, doHighlight);
         assertEquals(1, results.size());
         if (doHighlight) {
           assertEquals("lend me your <b>ear</b>", results.get(0).key);
@@ -280,7 +279,7 @@ public class AnalyzingInfixSuggesterTest extends LuceneTestCase {
         assertEquals(8, results.get(0).value);
         assertEquals(new BytesRef("foobar"), results.get(0).payload);
 
-        results = suggester.lookup(_TestUtil.stringToCharSequence("pen", random()), 10, true, doHighlight);
+        results = suggester.lookup(TestUtil.stringToCharSequence("pen", random()), 10, true, doHighlight);
         assertEquals(1, results.size());
         if (doHighlight) {
           assertEquals("a <b>pen</b>ny saved is a <b>pen</b>ny earned", results.get(0).key);
@@ -290,7 +289,7 @@ public class AnalyzingInfixSuggesterTest extends LuceneTestCase {
         assertEquals(10, results.get(0).value);
         assertEquals(new BytesRef("foobaz"), results.get(0).payload);
 
-        results = suggester.lookup(_TestUtil.stringToCharSequence("p", random()), 10, true, doHighlight);
+        results = suggester.lookup(TestUtil.stringToCharSequence("p", random()), 10, true, doHighlight);
         assertEquals(1, results.size());
         if (doHighlight) {
           assertEquals("a <b>p</b>enny saved is a <b>p</b>enny earned", results.get(0).key);
@@ -318,7 +317,7 @@ public class AnalyzingInfixSuggesterTest extends LuceneTestCase {
       new Input("a penny saved is a penny earned", 10, new BytesRef("foobaz")),
     };
 
-    File tempDir = _TestUtil.getTempDir("AnalyzingInfixSuggesterTest");
+    File tempDir = TestUtil.getTempDir("AnalyzingInfixSuggesterTest");
 
     Analyzer a = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);
     AnalyzingInfixSuggester suggester = new AnalyzingInfixSuggester(TEST_VERSION_CURRENT, tempDir, a, a, 3) {
@@ -328,7 +327,7 @@ public class AnalyzingInfixSuggesterTest extends LuceneTestCase {
         }
       };
     suggester.build(new InputArrayIterator(keys));
-    List<LookupResult> results = suggester.lookup(_TestUtil.stringToCharSequence("penn", random()), 10, true, true);
+    List<LookupResult> results = suggester.lookup(TestUtil.stringToCharSequence("penn", random()), 10, true, true);
     assertEquals(1, results.size());
     assertEquals("a <b>penn</b>y saved is a <b>penn</b>y earned", results.get(0).key);
     suggester.close();
@@ -339,7 +338,7 @@ public class AnalyzingInfixSuggesterTest extends LuceneTestCase {
       new Input("a Penny saved is a penny earned", 10, new BytesRef("foobaz")),
     };
 
-    File tempDir = _TestUtil.getTempDir("AnalyzingInfixSuggesterTest");
+    File tempDir = TestUtil.getTempDir("AnalyzingInfixSuggesterTest");
 
     Analyzer a = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, true);
     AnalyzingInfixSuggester suggester = new AnalyzingInfixSuggester(TEST_VERSION_CURRENT, tempDir, a, a, 3) {
@@ -349,7 +348,7 @@ public class AnalyzingInfixSuggesterTest extends LuceneTestCase {
         }
       };
     suggester.build(new InputArrayIterator(keys));
-    List<LookupResult> results = suggester.lookup(_TestUtil.stringToCharSequence("penn", random()), 10, true, true);
+    List<LookupResult> results = suggester.lookup(TestUtil.stringToCharSequence("penn", random()), 10, true, true);
     assertEquals(1, results.size());
     assertEquals("a <b>Penn</b>y saved is a <b>penn</b>y earned", results.get(0).key);
     suggester.close();
@@ -370,7 +369,7 @@ public class AnalyzingInfixSuggesterTest extends LuceneTestCase {
         }
       };
     suggester.build(new InputArrayIterator(keys));
-    results = suggester.lookup(_TestUtil.stringToCharSequence("penn", random()), 10, true, true);
+    results = suggester.lookup(TestUtil.stringToCharSequence("penn", random()), 10, true, true);
     assertEquals(1, results.size());
     assertEquals("a <b>Penny</b> saved is a <b>penny</b> earned", results.get(0).key);
     suggester.close();
@@ -381,7 +380,7 @@ public class AnalyzingInfixSuggesterTest extends LuceneTestCase {
       new Input("a penny saved is a penny earned", 10, new BytesRef("foobaz")),
     };
 
-    File tempDir = _TestUtil.getTempDir("AnalyzingInfixSuggesterTest");
+    File tempDir = TestUtil.getTempDir("AnalyzingInfixSuggesterTest");
 
     Analyzer a = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);
     AnalyzingInfixSuggester suggester = new AnalyzingInfixSuggester(TEST_VERSION_CURRENT, tempDir, a, a, 3) {
@@ -415,7 +414,7 @@ public class AnalyzingInfixSuggesterTest extends LuceneTestCase {
         }
       };
 
-    File tempDir = _TestUtil.getTempDir("AnalyzingInfixSuggesterTest");
+    File tempDir = TestUtil.getTempDir("AnalyzingInfixSuggesterTest");
 
     AnalyzingInfixSuggester suggester = new AnalyzingInfixSuggester(TEST_VERSION_CURRENT, tempDir, indexAnalyzer, queryAnalyzer, 3) {
         @Override
@@ -429,7 +428,7 @@ public class AnalyzingInfixSuggesterTest extends LuceneTestCase {
     };
 
     suggester.build(new InputArrayIterator(keys));
-    List<LookupResult> results = suggester.lookup(_TestUtil.stringToCharSequence("a", random()), 10, true, true);
+    List<LookupResult> results = suggester.lookup(TestUtil.stringToCharSequence("a", random()), 10, true, true);
     assertEquals(1, results.size());
     assertEquals("a bob for <b>a</b>pples", results.get(0).key);
     suggester.close();
diff --git a/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest.java b/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest.java
index 13a344a..ce8fbea 100644
--- a/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest.java
+++ b/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest.java
@@ -25,14 +25,12 @@ import java.io.InputStream;
 import java.io.OutputStream;
 import java.io.Reader;
 import java.util.ArrayList;
-import java.util.Arrays;
 import java.util.Collections;
 import java.util.Comparator;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
-import java.util.Random;
 import java.util.Set;
 import java.util.TreeSet;
 
@@ -57,7 +55,7 @@ import org.apache.lucene.search.suggest.InputArrayIterator;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LineFileDocs;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class AnalyzingSuggesterTest extends LuceneTestCase {
   
@@ -77,20 +75,20 @@ public class AnalyzingSuggesterTest extends LuceneTestCase {
     suggester.build(new InputArrayIterator(keys));
     
     // top N of 2, but only foo is available
-    List<LookupResult> results = suggester.lookup(_TestUtil.stringToCharSequence("f", random()), false, 2);
+    List<LookupResult> results = suggester.lookup(TestUtil.stringToCharSequence("f", random()), false, 2);
     assertEquals(1, results.size());
     assertEquals("foo", results.get(0).key.toString());
     assertEquals(50, results.get(0).value, 0.01F);
     
     // top N of 1 for 'bar': we return this even though
     // barbar is higher because exactFirst is enabled:
-    results = suggester.lookup(_TestUtil.stringToCharSequence("bar", random()), false, 1);
+    results = suggester.lookup(TestUtil.stringToCharSequence("bar", random()), false, 1);
     assertEquals(1, results.size());
     assertEquals("bar", results.get(0).key.toString());
     assertEquals(10, results.get(0).value, 0.01F);
     
     // top N Of 2 for 'b'
-    results = suggester.lookup(_TestUtil.stringToCharSequence("b", random()), false, 2);
+    results = suggester.lookup(TestUtil.stringToCharSequence("b", random()), false, 2);
     assertEquals(2, results.size());
     assertEquals("barbar", results.get(0).key.toString());
     assertEquals(12, results.get(0).value, 0.01F);
@@ -98,7 +96,7 @@ public class AnalyzingSuggesterTest extends LuceneTestCase {
     assertEquals(10, results.get(1).value, 0.01F);
     
     // top N of 3 for 'ba'
-    results = suggester.lookup(_TestUtil.stringToCharSequence("ba", random()), false, 3);
+    results = suggester.lookup(TestUtil.stringToCharSequence("ba", random()), false, 3);
     assertEquals(3, results.size());
     assertEquals("barbar", results.get(0).key.toString());
     assertEquals(12, results.get(0).value, 0.01F);
@@ -121,7 +119,7 @@ public class AnalyzingSuggesterTest extends LuceneTestCase {
     suggester.build(new InputArrayIterator(keys));
     for (int i = 0; i < 2; i++) {
       // top N of 2, but only foo is available
-      List<LookupResult> results = suggester.lookup(_TestUtil.stringToCharSequence("f", random()), false, 2);
+      List<LookupResult> results = suggester.lookup(TestUtil.stringToCharSequence("f", random()), false, 2);
       assertEquals(1, results.size());
       assertEquals("foo", results.get(0).key.toString());
       assertEquals(50, results.get(0).value, 0.01F);
@@ -129,14 +127,14 @@ public class AnalyzingSuggesterTest extends LuceneTestCase {
       
       // top N of 1 for 'bar': we return this even though
       // barbar is higher because exactFirst is enabled:
-      results = suggester.lookup(_TestUtil.stringToCharSequence("bar", random()), false, 1);
+      results = suggester.lookup(TestUtil.stringToCharSequence("bar", random()), false, 1);
       assertEquals(1, results.size());
       assertEquals("bar", results.get(0).key.toString());
       assertEquals(10, results.get(0).value, 0.01F);
       assertEquals(new BytesRef("goodbye"), results.get(0).payload);
       
       // top N Of 2 for 'b'
-      results = suggester.lookup(_TestUtil.stringToCharSequence("b", random()), false, 2);
+      results = suggester.lookup(TestUtil.stringToCharSequence("b", random()), false, 2);
       assertEquals(2, results.size());
       assertEquals("barbar", results.get(0).key.toString());
       assertEquals(12, results.get(0).value, 0.01F);
@@ -146,7 +144,7 @@ public class AnalyzingSuggesterTest extends LuceneTestCase {
       assertEquals(new BytesRef("goodbye"), results.get(1).payload);
       
       // top N of 3 for 'ba'
-      results = suggester.lookup(_TestUtil.stringToCharSequence("ba", random()), false, 3);
+      results = suggester.lookup(TestUtil.stringToCharSequence("ba", random()), false, 3);
       assertEquals(3, results.size());
       assertEquals("barbar", results.get(0).key.toString());
       assertEquals(12, results.get(0).value, 0.01F);
@@ -218,19 +216,19 @@ public class AnalyzingSuggesterTest extends LuceneTestCase {
 
     suggester.build(new InputArrayIterator(keys));
     
-    List<LookupResult> results = suggester.lookup(_TestUtil.stringToCharSequence("the ghost of chris", random()), false, 1);
+    List<LookupResult> results = suggester.lookup(TestUtil.stringToCharSequence("the ghost of chris", random()), false, 1);
     assertEquals(1, results.size());
     assertEquals("the ghost of christmas past", results.get(0).key.toString());
     assertEquals(50, results.get(0).value, 0.01F);
 
     // omit the 'the' since its a stopword, its suggested anyway
-    results = suggester.lookup(_TestUtil.stringToCharSequence("ghost of chris", random()), false, 1);
+    results = suggester.lookup(TestUtil.stringToCharSequence("ghost of chris", random()), false, 1);
     assertEquals(1, results.size());
     assertEquals("the ghost of christmas past", results.get(0).key.toString());
     assertEquals(50, results.get(0).value, 0.01F);
 
     // omit the 'the' and 'of' since they are stopwords, its suggested anyway
-    results = suggester.lookup(_TestUtil.stringToCharSequence("ghost chris", random()), false, 1);
+    results = suggester.lookup(TestUtil.stringToCharSequence("ghost chris", random()), false, 1);
     assertEquals(1, results.size());
     assertEquals("the ghost of christmas past", results.get(0).key.toString());
     assertEquals(50, results.get(0).value, 0.01F);
@@ -260,7 +258,7 @@ public class AnalyzingSuggesterTest extends LuceneTestCase {
     // pass, and more generally if the analyzer can know
     // that the user's current query has ended at a word, 
     // but, analyzers don't produce SEP tokens!
-    List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence("ab c", random()), false, 2);
+    List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence("ab c", random()), false, 2);
     assertEquals(2, r.size());
 
     // With no PRESERVE_SEPS specified, "ab c" should also
@@ -674,7 +672,7 @@ public class AnalyzingSuggesterTest extends LuceneTestCase {
     }
     
     for (int i = 0; i < numQueries; i++) {
-      int numTokens = _TestUtil.nextInt(random(), 1, 4);
+      int numTokens = TestUtil.nextInt(random(), 1, 4);
       String key;
       String analyzedKey;
       while(true) {
@@ -686,7 +684,7 @@ public class AnalyzingSuggesterTest extends LuceneTestCase {
           while (true) {
             // TODO: would be nice to fix this slowCompletor/comparator to
             // use full range, but we might lose some coverage too...
-            s = _TestUtil.randomSimpleString(random());
+            s = TestUtil.randomSimpleString(random());
             if (s.length() > 0) {
               if (token > 0) {
                 key += " ";
@@ -766,8 +764,8 @@ public class AnalyzingSuggesterTest extends LuceneTestCase {
         System.out.println("\nTEST: prefix=" + prefix);
       }
 
-      final int topN = _TestUtil.nextInt(random(), 1, 10);
-      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);
+      final int topN = TestUtil.nextInt(random(), 1, 10);
+      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);
 
       // 2. go thru whole set to find suggestions:
       List<TermFreq2> matches = new ArrayList<TermFreq2>();
@@ -923,7 +921,7 @@ public class AnalyzingSuggesterTest extends LuceneTestCase {
     assertEquals(3, results.get(2).value);
 
     // Try again after save/load:
-    File tmpDir = _TestUtil.getTempDir("AnalyzingSuggesterTest");
+    File tmpDir = TestUtil.getTempDir("AnalyzingSuggesterTest");
     tmpDir.mkdir();
 
     File path = new File(tmpDir, "suggester");
@@ -985,7 +983,7 @@ public class AnalyzingSuggesterTest extends LuceneTestCase {
     assertEquals(5, results.get(1).value);
 
     // Try again after save/load:
-    File tmpDir = _TestUtil.getTempDir("AnalyzingSuggesterTest");
+    File tmpDir = TestUtil.getTempDir("AnalyzingSuggesterTest");
     tmpDir.mkdir();
 
     File path = new File(tmpDir, "suggester");
@@ -1055,7 +1053,7 @@ public class AnalyzingSuggesterTest extends LuceneTestCase {
     assertEquals(5, results.get(1).value);
 
     // Try again after save/load:
-    File tmpDir = _TestUtil.getTempDir("AnalyzingSuggesterTest");
+    File tmpDir = TestUtil.getTempDir("AnalyzingSuggesterTest");
     tmpDir.mkdir();
 
     File path = new File(tmpDir, "suggester");
diff --git a/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggesterTest.java b/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggesterTest.java
index 4f6af62..b88e3e3 100644
--- a/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggesterTest.java
+++ b/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggesterTest.java
@@ -26,7 +26,7 @@ import org.apache.lucene.search.suggest.Lookup;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 import java.io.File;
 import java.io.IOException;
@@ -46,7 +46,7 @@ public class BlendedInfixSuggesterTest extends LuceneTestCase {
         new Input("star wars: episode v - the empire strikes back", 8, payload)
     };
 
-    File tempDir = _TestUtil.getTempDir("BlendedInfixSuggesterTest");
+    File tempDir = TestUtil.getTempDir("BlendedInfixSuggesterTest");
 
     Analyzer a = new StandardAnalyzer(TEST_VERSION_CURRENT, CharArraySet.EMPTY_SET);
     BlendedInfixSuggester suggester = new BlendedInfixSuggester(TEST_VERSION_CURRENT, tempDir, a, a,
@@ -90,7 +90,7 @@ public class BlendedInfixSuggesterTest extends LuceneTestCase {
         new Input("top of the lake", w, pl)
     };
 
-    File tempDir = _TestUtil.getTempDir("BlendedInfixSuggesterTest");
+    File tempDir = TestUtil.getTempDir("BlendedInfixSuggesterTest");
     Analyzer a = new StandardAnalyzer(TEST_VERSION_CURRENT, CharArraySet.EMPTY_SET);
 
     // BlenderType.LINEAR is used by default (remove position*10%)
@@ -141,7 +141,7 @@ public class BlendedInfixSuggesterTest extends LuceneTestCase {
         new Input("the returned", 10, ret),
     };
 
-    File tempDir = _TestUtil.getTempDir("BlendedInfixSuggesterTest");
+    File tempDir = TestUtil.getTempDir("BlendedInfixSuggesterTest");
     Analyzer a = new StandardAnalyzer(TEST_VERSION_CURRENT, CharArraySet.EMPTY_SET);
 
     // if factor is small, we don't get the expected element
@@ -201,7 +201,7 @@ public class BlendedInfixSuggesterTest extends LuceneTestCase {
         new Input("the returned", 10, ret),
     };
 
-    File tempDir = _TestUtil.getTempDir("BlendedInfixSuggesterTest");
+    File tempDir = TestUtil.getTempDir("BlendedInfixSuggesterTest");
     Analyzer a = new StandardAnalyzer(TEST_VERSION_CURRENT, CharArraySet.EMPTY_SET);
 
     // if factor is small, we don't get the expected element
diff --git a/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest.java b/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest.java
index ab08ff4..daac881 100644
--- a/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest.java
+++ b/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest.java
@@ -46,7 +46,7 @@ import org.apache.lucene.search.suggest.InputArrayIterator;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IntsRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.automaton.Automaton;
 import org.apache.lucene.util.automaton.State;
 import org.apache.lucene.util.fst.Util;
@@ -57,7 +57,7 @@ public class FuzzySuggesterTest extends LuceneTestCase {
     List<Input> keys = new ArrayList<Input>();
     int numTerms = atLeast(100);
     for (int i = 0; i < numTerms; i++) {
-      keys.add(new Input("boo" + _TestUtil.randomSimpleString(random()), 1 + random().nextInt(100)));
+      keys.add(new Input("boo" + TestUtil.randomSimpleString(random()), 1 + random().nextInt(100)));
     }
     keys.add(new Input("foo bar boo far", 12));
     MockAnalyzer analyzer = new MockAnalyzer(random(), MockTokenizer.KEYWORD, false);
@@ -67,7 +67,7 @@ public class FuzzySuggesterTest extends LuceneTestCase {
     int numIters = atLeast(10);
     for (int i = 0; i < numIters; i++) {
       String addRandomEdit = addRandomEdit("foo bar boo", FuzzySuggester.DEFAULT_NON_FUZZY_PREFIX);
-      List<LookupResult> results = suggester.lookup(_TestUtil.stringToCharSequence(addRandomEdit, random()), false, 2);
+      List<LookupResult> results = suggester.lookup(TestUtil.stringToCharSequence(addRandomEdit, random()), false, 2);
       assertEquals(addRandomEdit, 1, results.size());
       assertEquals("foo bar boo far", results.get(0).key.toString());
       assertEquals(12, results.get(0).value, 0.01F);  
@@ -78,7 +78,7 @@ public class FuzzySuggesterTest extends LuceneTestCase {
     List<Input> keys = new ArrayList<Input>();
     int numTerms = atLeast(100);
     for (int i = 0; i < numTerms; i++) {
-      keys.add(new Input("б??" + _TestUtil.randomSimpleString(random()), 1 + random().nextInt(100)));
+      keys.add(new Input("б??" + TestUtil.randomSimpleString(random()), 1 + random().nextInt(100)));
     }
     keys.add(new Input("??? ба? б?? ?а?", 12));
     MockAnalyzer analyzer = new MockAnalyzer(random(), MockTokenizer.KEYWORD, false);
@@ -88,7 +88,7 @@ public class FuzzySuggesterTest extends LuceneTestCase {
     int numIters = atLeast(10);
     for (int i = 0; i < numIters; i++) {
       String addRandomEdit = addRandomEdit("??? ба? б??", 0);
-      List<LookupResult> results = suggester.lookup(_TestUtil.stringToCharSequence(addRandomEdit, random()), false, 2);
+      List<LookupResult> results = suggester.lookup(TestUtil.stringToCharSequence(addRandomEdit, random()), false, 2);
       assertEquals(addRandomEdit, 1, results.size());
       assertEquals("??? ба? б?? ?а?", results.get(0).key.toString());
       assertEquals(12, results.get(0).value, 0.01F);
@@ -107,29 +107,29 @@ public class FuzzySuggesterTest extends LuceneTestCase {
     FuzzySuggester suggester = new FuzzySuggester(new MockAnalyzer(random(), MockTokenizer.KEYWORD, false));
     suggester.build(new InputArrayIterator(keys));
     
-    List<LookupResult> results = suggester.lookup(_TestUtil.stringToCharSequence("bariar", random()), false, 2);
+    List<LookupResult> results = suggester.lookup(TestUtil.stringToCharSequence("bariar", random()), false, 2);
     assertEquals(2, results.size());
     assertEquals("barbar", results.get(0).key.toString());
     assertEquals(12, results.get(0).value, 0.01F);
     
-    results = suggester.lookup(_TestUtil.stringToCharSequence("barbr", random()), false, 2);
+    results = suggester.lookup(TestUtil.stringToCharSequence("barbr", random()), false, 2);
     assertEquals(2, results.size());
     assertEquals("barbar", results.get(0).key.toString());
     assertEquals(12, results.get(0).value, 0.01F);
     
-    results = suggester.lookup(_TestUtil.stringToCharSequence("barbara", random()), false, 2);
+    results = suggester.lookup(TestUtil.stringToCharSequence("barbara", random()), false, 2);
     assertEquals(2, results.size());
     assertEquals("barbara", results.get(0).key.toString());
     assertEquals(6, results.get(0).value, 0.01F);
     
-    results = suggester.lookup(_TestUtil.stringToCharSequence("barbar", random()), false, 2);
+    results = suggester.lookup(TestUtil.stringToCharSequence("barbar", random()), false, 2);
     assertEquals(2, results.size());
     assertEquals("barbar", results.get(0).key.toString());
     assertEquals(12, results.get(0).value, 0.01F);
     assertEquals("barbara", results.get(1).key.toString());
     assertEquals(6, results.get(1).value, 0.01F);
     
-    results = suggester.lookup(_TestUtil.stringToCharSequence("barbaa", random()), false, 2);
+    results = suggester.lookup(TestUtil.stringToCharSequence("barbaa", random()), false, 2);
     assertEquals(2, results.size());
     assertEquals("barbar", results.get(0).key.toString());
     assertEquals(12, results.get(0).value, 0.01F);
@@ -137,20 +137,20 @@ public class FuzzySuggesterTest extends LuceneTestCase {
     assertEquals(6, results.get(1).value, 0.01F);
     
     // top N of 2, but only foo is available
-    results = suggester.lookup(_TestUtil.stringToCharSequence("f", random()), false, 2);
+    results = suggester.lookup(TestUtil.stringToCharSequence("f", random()), false, 2);
     assertEquals(1, results.size());
     assertEquals("foo", results.get(0).key.toString());
     assertEquals(50, results.get(0).value, 0.01F);
     
     // top N of 1 for 'bar': we return this even though
     // barbar is higher because exactFirst is enabled:
-    results = suggester.lookup(_TestUtil.stringToCharSequence("bar", random()), false, 1);
+    results = suggester.lookup(TestUtil.stringToCharSequence("bar", random()), false, 1);
     assertEquals(1, results.size());
     assertEquals("bar", results.get(0).key.toString());
     assertEquals(10, results.get(0).value, 0.01F);
     
     // top N Of 2 for 'b'
-    results = suggester.lookup(_TestUtil.stringToCharSequence("b", random()), false, 2);
+    results = suggester.lookup(TestUtil.stringToCharSequence("b", random()), false, 2);
     assertEquals(2, results.size());
     assertEquals("barbar", results.get(0).key.toString());
     assertEquals(12, results.get(0).value, 0.01F);
@@ -158,7 +158,7 @@ public class FuzzySuggesterTest extends LuceneTestCase {
     assertEquals(10, results.get(1).value, 0.01F);
     
     // top N of 3 for 'ba'
-    results = suggester.lookup(_TestUtil.stringToCharSequence("ba", random()), false, 3);
+    results = suggester.lookup(TestUtil.stringToCharSequence("ba", random()), false, 3);
     assertEquals(3, results.size());
     assertEquals("barbar", results.get(0).key.toString());
     assertEquals(12, results.get(0).value, 0.01F);
@@ -181,19 +181,19 @@ public class FuzzySuggesterTest extends LuceneTestCase {
         FuzzySuggester.DEFAULT_NON_FUZZY_PREFIX, FuzzySuggester.DEFAULT_MIN_FUZZY_LENGTH, FuzzySuggester.DEFAULT_UNICODE_AWARE);
     suggester.build(new InputArrayIterator(keys));
     
-    List<LookupResult> results = suggester.lookup(_TestUtil.stringToCharSequence("the ghost of chris", random()), false, 1);
+    List<LookupResult> results = suggester.lookup(TestUtil.stringToCharSequence("the ghost of chris", random()), false, 1);
     assertEquals(1, results.size());
     assertEquals("the ghost of christmas past", results.get(0).key.toString());
     assertEquals(50, results.get(0).value, 0.01F);
 
     // omit the 'the' since its a stopword, its suggested anyway
-    results = suggester.lookup(_TestUtil.stringToCharSequence("ghost of chris", random()), false, 1);
+    results = suggester.lookup(TestUtil.stringToCharSequence("ghost of chris", random()), false, 1);
     assertEquals(1, results.size());
     assertEquals("the ghost of christmas past", results.get(0).key.toString());
     assertEquals(50, results.get(0).value, 0.01F);
 
     // omit the 'the' and 'of' since they are stopwords, its suggested anyway
-    results = suggester.lookup(_TestUtil.stringToCharSequence("ghost chris", random()), false, 1);
+    results = suggester.lookup(TestUtil.stringToCharSequence("ghost chris", random()), false, 1);
     assertEquals(1, results.size());
     assertEquals("the ghost of christmas past", results.get(0).key.toString());
     assertEquals(50, results.get(0).value, 0.01F);
@@ -214,7 +214,7 @@ public class FuzzySuggesterTest extends LuceneTestCase {
     // pass, and more generally if the analyzer can know
     // that the user's current query has ended at a word, 
     // but, analyzers don't produce SEP tokens!
-    List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence("ab c", random()), false, 2);
+    List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence("ab c", random()), false, 2);
     assertEquals(2, r.size());
 
     // With no PRESERVE_SEPS specified, "ab c" should also
@@ -613,7 +613,7 @@ public class FuzzySuggesterTest extends LuceneTestCase {
     }
     
     for (int i = 0; i < numQueries; i++) {
-      int numTokens = _TestUtil.nextInt(random(), 1, 4);
+      int numTokens = TestUtil.nextInt(random(), 1, 4);
       String key;
       String analyzedKey;
       while(true) {
@@ -625,7 +625,7 @@ public class FuzzySuggesterTest extends LuceneTestCase {
           while (true) {
             // TODO: would be nice to fix this slowCompletor/comparator to
             // use full range, but we might lose some coverage too...
-            s = _TestUtil.randomSimpleString(random());
+            s = TestUtil.randomSimpleString(random());
             if (s.length() > 0) {
               if (token > 0) {
                 key += " ";
@@ -692,8 +692,8 @@ public class FuzzySuggesterTest extends LuceneTestCase {
         System.out.println("\nTEST: prefix=" + prefix);
       }
 
-      final int topN = _TestUtil.nextInt(random(), 1, 10);
-      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);
+      final int topN = TestUtil.nextInt(random(), 1, 10);
+      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);
 
       // 2. go thru whole set to find suggestions:
       List<LookupResult> matches = new ArrayList<LookupResult>();
@@ -919,7 +919,7 @@ public class FuzzySuggesterTest extends LuceneTestCase {
   }
 
   private String randomSimpleString(int maxLen) {
-    final int len = _TestUtil.nextInt(random(), 1, maxLen);
+    final int len = TestUtil.nextInt(random(), 1, maxLen);
     final char[] chars = new char[len];
     for(int j=0;j<len;j++) {
       chars[j] = (char) ('a' + random().nextInt(4));
diff --git a/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/TestFreeTextSuggester.java b/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/TestFreeTextSuggester.java
index ef8ca62..6ca17de 100644
--- a/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/TestFreeTextSuggester.java
+++ b/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/TestFreeTextSuggester.java
@@ -23,7 +23,6 @@ import java.io.FileOutputStream;
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.OutputStream;
-import java.io.Reader;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.Comparator;
@@ -48,7 +47,7 @@ import org.apache.lucene.search.suggest.InputIterator;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LineFileDocs;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.Ignore;
 
 public class TestFreeTextSuggester extends LuceneTestCase {
@@ -83,7 +82,7 @@ public class TestFreeTextSuggester extends LuceneTestCase {
                    toString(sug.lookup("b", 10)));
 
       // Try again after save/load:
-      File tmpDir = _TestUtil.getTempDir("FreeTextSuggesterTest");
+      File tmpDir = TestUtil.getTempDir("FreeTextSuggesterTest");
       tmpDir.mkdir();
 
       File path = new File(tmpDir, "suggester");
@@ -293,10 +292,10 @@ public class TestFreeTextSuggester extends LuceneTestCase {
   };
 
   public void testRandom() throws IOException {
-    String[] terms = new String[_TestUtil.nextInt(random(), 2, 10)];
+    String[] terms = new String[TestUtil.nextInt(random(), 2, 10)];
     Set<String> seen = new HashSet<String>();
     while (seen.size() < terms.length) {
-      String token = _TestUtil.randomSimpleString(random(), 1, 5);
+      String token = TestUtil.randomSimpleString(random(), 1, 5);
       if (!seen.contains(token)) {
         terms[seen.size()] = token;
         seen.add(token);
@@ -325,7 +324,7 @@ public class TestFreeTextSuggester extends LuceneTestCase {
       totTokens += docs[i].length;
     }
 
-    int grams = _TestUtil.nextInt(random(), 1, 4);
+    int grams = TestUtil.nextInt(random(), 1, 4);
 
     if (VERBOSE) {
       System.out.println("TEST: " + terms.length + " terms; " + numDocs + " docs; " + grams + " grams");
@@ -400,7 +399,7 @@ public class TestFreeTextSuggester extends LuceneTestCase {
 
     int lookups = atLeast(100);
     for(int iter=0;iter<lookups;iter++) {
-      String[] tokens = new String[_TestUtil.nextInt(random(), 1, 5)];
+      String[] tokens = new String[TestUtil.nextInt(random(), 1, 5)];
       for(int i=0;i<tokens.length;i++) {
         tokens[i] = getZipfToken(terms);
       }
@@ -413,10 +412,10 @@ public class TestFreeTextSuggester extends LuceneTestCase {
       } else {
         trimStart = 0;
       }
-      int trimAt = _TestUtil.nextInt(random(), trimStart, tokens[tokens.length-1].length());
+      int trimAt = TestUtil.nextInt(random(), trimStart, tokens[tokens.length - 1].length());
       tokens[tokens.length-1] = tokens[tokens.length-1].substring(0, trimAt);
 
-      int num = _TestUtil.nextInt(random(), 1, 100);
+      int num = TestUtil.nextInt(random(), 1, 100);
       StringBuilder b = new StringBuilder();
       for(String token : tokens) {
         b.append(' ');
diff --git a/lucene/suggest/src/test/org/apache/lucene/search/suggest/fst/FSTCompletionTest.java b/lucene/suggest/src/test/org/apache/lucene/search/suggest/fst/FSTCompletionTest.java
index 02a07b9..dc3f24c 100644
--- a/lucene/suggest/src/test/org/apache/lucene/search/suggest/fst/FSTCompletionTest.java
+++ b/lucene/suggest/src/test/org/apache/lucene/search/suggest/fst/FSTCompletionTest.java
@@ -159,7 +159,7 @@ public class FSTCompletionTest extends LuceneTestCase {
     Random r = random();
     List<Input> keys = new ArrayList<Input>();
     for (int i = 0; i < 5000; i++) {
-      keys.add(new Input(_TestUtil.randomSimpleString(r), -1));
+      keys.add(new Input(TestUtil.randomSimpleString(r), -1));
     }
 
     lookup.build(new InputArrayIterator(keys));
@@ -168,7 +168,7 @@ public class FSTCompletionTest extends LuceneTestCase {
     // are.
     Long previous = null; 
     for (Input tf : keys) {
-      Long current = ((Number)lookup.get(_TestUtil.bytesToCharSequence(tf.term, random()))).longValue();
+      Long current = ((Number)lookup.get(TestUtil.bytesToCharSequence(tf.term, random()))).longValue();
       if (previous != null) {
         assertEquals(previous, current);
       }
@@ -183,8 +183,8 @@ public class FSTCompletionTest extends LuceneTestCase {
     lookup.build(new InputArrayIterator(input));
     assertEquals(input.size(), lookup.getCount());
     for (Input tf : input) {
-      assertNotNull("Not found: " + tf.term.toString(), lookup.get(_TestUtil.bytesToCharSequence(tf.term, random())));
-      assertEquals(tf.term.utf8ToString(), lookup.lookup(_TestUtil.bytesToCharSequence(tf.term, random()), true, 1).get(0).key.toString());
+      assertNotNull("Not found: " + tf.term.toString(), lookup.get(TestUtil.bytesToCharSequence(tf.term, random())));
+      assertEquals(tf.term.utf8ToString(), lookup.lookup(TestUtil.bytesToCharSequence(tf.term, random()), true, 1).get(0).key.toString());
     }
 
     List<LookupResult> result = lookup.lookup(stringToCharSequence("wit"), true, 5);
@@ -221,7 +221,7 @@ public class FSTCompletionTest extends LuceneTestCase {
   }
 
   private CharSequence stringToCharSequence(String prefix) {
-    return _TestUtil.stringToCharSequence(prefix, random());
+    return TestUtil.stringToCharSequence(prefix, random());
   }
 
   private void assertMatchEquals(List<Completion> res, String... expected) {
diff --git a/lucene/suggest/src/test/org/apache/lucene/search/suggest/fst/TestSort.java b/lucene/suggest/src/test/org/apache/lucene/search/suggest/fst/TestSort.java
index 6b4c298..540fade 100644
--- a/lucene/suggest/src/test/org/apache/lucene/search/suggest/fst/TestSort.java
+++ b/lucene/suggest/src/test/org/apache/lucene/search/suggest/fst/TestSort.java
@@ -37,15 +37,15 @@ public class TestSort extends LuceneTestCase {
 
   @Before
   public void prepareTempDir() throws IOException {
-    tempDir = _TestUtil.getTempDir("mergesort");
-    _TestUtil.rmDir(tempDir);
+    tempDir = TestUtil.getTempDir("mergesort");
+    TestUtil.rmDir(tempDir);
     tempDir.mkdirs();
   }
   
   @After
   public void cleanup() throws IOException {
     if (tempDir != null)
-      _TestUtil.rmDir(tempDir);
+      TestUtil.rmDir(tempDir);
   }
 
   @Test
diff --git a/lucene/suggest/src/test/org/apache/lucene/search/suggest/fst/WFSTCompletionTest.java b/lucene/suggest/src/test/org/apache/lucene/search/suggest/fst/WFSTCompletionTest.java
index d1c4714..9439a3a 100644
--- a/lucene/suggest/src/test/org/apache/lucene/search/suggest/fst/WFSTCompletionTest.java
+++ b/lucene/suggest/src/test/org/apache/lucene/search/suggest/fst/WFSTCompletionTest.java
@@ -24,7 +24,7 @@ import org.apache.lucene.search.suggest.Input;
 import org.apache.lucene.search.suggest.InputArrayIterator;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class WFSTCompletionTest extends LuceneTestCase {
   
@@ -41,25 +41,25 @@ public class WFSTCompletionTest extends LuceneTestCase {
     suggester.build(new InputArrayIterator(keys));
     
     // top N of 2, but only foo is available
-    List<LookupResult> results = suggester.lookup(_TestUtil.stringToCharSequence("f", random), false, 2);
+    List<LookupResult> results = suggester.lookup(TestUtil.stringToCharSequence("f", random), false, 2);
     assertEquals(1, results.size());
     assertEquals("foo", results.get(0).key.toString());
     assertEquals(50, results.get(0).value, 0.01F);
 
     // make sure we don't get a dup exact suggestion:
-    results = suggester.lookup(_TestUtil.stringToCharSequence("foo", random), false, 2);
+    results = suggester.lookup(TestUtil.stringToCharSequence("foo", random), false, 2);
     assertEquals(1, results.size());
     assertEquals("foo", results.get(0).key.toString());
     assertEquals(50, results.get(0).value, 0.01F);
 
     // top N of 1 for 'bar': we return this even though barbar is higher
-    results = suggester.lookup(_TestUtil.stringToCharSequence("bar", random), false, 1);
+    results = suggester.lookup(TestUtil.stringToCharSequence("bar", random), false, 1);
     assertEquals(1, results.size());
     assertEquals("bar", results.get(0).key.toString());
     assertEquals(10, results.get(0).value, 0.01F);
     
     // top N Of 2 for 'b'
-    results = suggester.lookup(_TestUtil.stringToCharSequence("b", random), false, 2);
+    results = suggester.lookup(TestUtil.stringToCharSequence("b", random), false, 2);
     assertEquals(2, results.size());
     assertEquals("barbar", results.get(0).key.toString());
     assertEquals(12, results.get(0).value, 0.01F);
@@ -67,7 +67,7 @@ public class WFSTCompletionTest extends LuceneTestCase {
     assertEquals(10, results.get(1).value, 0.01F);
     
     // top N of 3 for 'ba'
-    results = suggester.lookup(_TestUtil.stringToCharSequence("ba", random), false, 3);
+    results = suggester.lookup(TestUtil.stringToCharSequence("ba", random), false, 3);
     assertEquals(3, results.size());
     assertEquals("barbar", results.get(0).key.toString());
     assertEquals(12, results.get(0).value, 0.01F);
@@ -138,7 +138,7 @@ public class WFSTCompletionTest extends LuceneTestCase {
       while (true) {
         // TODO: would be nice to fix this slowCompletor/comparator to
         // use full range, but we might lose some coverage too...
-        s = _TestUtil.randomSimpleString(random());
+        s = TestUtil.randomSimpleString(random());
         if (!slowCompletor.containsKey(s)) {
           break;
         }
@@ -159,8 +159,8 @@ public class WFSTCompletionTest extends LuceneTestCase {
     assertEquals(numWords, suggester.getCount());
     Random random = new Random(random().nextLong());
     for (String prefix : allPrefixes) {
-      final int topN = _TestUtil.nextInt(random, 1, 10);
-      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random), false, topN);
+      final int topN = TestUtil.nextInt(random, 1, 10);
+      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random), false, topN);
 
       // 2. go thru whole treemap (slowCompletor) and check its actually the best suggestion
       final List<LookupResult> matches = new ArrayList<LookupResult>();
diff --git a/lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase.java b/lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase.java
index aae538f..7a8ca28 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase.java
@@ -41,7 +41,7 @@ import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.LineFileDocs;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.Rethrow;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /** 
  * Base class for all Lucene unit tests that use TokenStreams. 
@@ -493,12 +493,12 @@ public abstract class BaseTokenStreamTestCase extends LuceneTestCase {
     boolean useCharFilter = random.nextBoolean();
     Directory dir = null;
     RandomIndexWriter iw = null;
-    final String postingsFormat =  _TestUtil.getPostingsFormat("dummy");
+    final String postingsFormat =  TestUtil.getPostingsFormat("dummy");
     boolean codecOk = iterations * maxWordLength < 100000 ||
         !(postingsFormat.equals("Memory") ||
             postingsFormat.equals("SimpleText"));
     if (rarely(random) && codecOk) {
-      dir = newFSDirectory(_TestUtil.getTempDir("bttc"));
+      dir = newFSDirectory(TestUtil.getTempDir("bttc"));
       iw = new RandomIndexWriter(new Random(seed), dir, a);
     }
     boolean success = false;
@@ -506,7 +506,7 @@ public abstract class BaseTokenStreamTestCase extends LuceneTestCase {
       checkRandomData(new Random(seed), a, iterations, maxWordLength, useCharFilter, simple, offsetsAreCorrect, iw);
       // now test with multiple threads: note we do the EXACT same thing we did before in each thread,
       // so this should only really fail from another thread if its an actual thread problem
-      int numThreads = _TestUtil.nextInt(random, 2, 4);
+      int numThreads = TestUtil.nextInt(random, 2, 4);
       AnalysisThread threads[] = new AnalysisThread[numThreads];
       for (int i = 0; i < threads.length; i++) {
         threads[i] = new AnalysisThread(seed, a, iterations, maxWordLength, useCharFilter, simple, offsetsAreCorrect, iw);
@@ -556,7 +556,7 @@ public abstract class BaseTokenStreamTestCase extends LuceneTestCase {
       if (random.nextBoolean()) {
         ft.setOmitNorms(true);
       }
-      String pf = _TestUtil.getPostingsFormat("dummy");
+      String pf = TestUtil.getPostingsFormat("dummy");
       boolean supportsOffsets = !doesntSupportOffsets.contains(pf);
       switch(random.nextInt(4)) {
         case 0: ft.setIndexOptions(IndexOptions.DOCS_ONLY); break;
@@ -598,7 +598,7 @@ public abstract class BaseTokenStreamTestCase extends LuceneTestCase {
           }
         } else {
           // synthetic
-          text = _TestUtil.randomAnalysisString(random, maxWordLength, simple);
+          text = TestUtil.randomAnalysisString(random, maxWordLength, simple);
         }
         
         try {
diff --git a/lucene/test-framework/src/java/org/apache/lucene/analysis/CollationTestBase.java b/lucene/test-framework/src/java/org/apache/lucene/analysis/CollationTestBase.java
index db4223e..3a1c5b3 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/analysis/CollationTestBase.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/analysis/CollationTestBase.java
@@ -46,7 +46,8 @@ import org.apache.lucene.search.TermRangeQuery;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Base test class for testing Unicode collation.
@@ -249,7 +250,7 @@ public abstract class CollationTestBase extends LuceneTestCase {
 
   public void assertThreadSafe(final Analyzer analyzer) throws Exception {
     int numTestPoints = 100;
-    int numThreads = _TestUtil.nextInt(random(), 3, 5);
+    int numThreads = TestUtil.nextInt(random(), 3, 5);
     final HashMap<String,BytesRef> map = new HashMap<String,BytesRef>();
     
     // create a map<String,SortKey> up front.
@@ -257,7 +258,7 @@ public abstract class CollationTestBase extends LuceneTestCase {
     // and ensure they are the same as the ones we produced in serial fashion.
 
     for (int i = 0; i < numTestPoints; i++) {
-      String term = _TestUtil.randomSimpleString(random());
+      String term = TestUtil.randomSimpleString(random());
       try (TokenStream ts = analyzer.tokenStream("fake", term)) {
         TermToBytesRefAttribute termAtt = ts.addAttribute(TermToBytesRefAttribute.class);
         BytesRef bytes = termAtt.getBytesRef();
diff --git a/lucene/test-framework/src/java/org/apache/lucene/analysis/MockGraphTokenFilter.java b/lucene/test-framework/src/java/org/apache/lucene/analysis/MockGraphTokenFilter.java
index 35f14b4..ecf4f3f 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/analysis/MockGraphTokenFilter.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/analysis/MockGraphTokenFilter.java
@@ -21,7 +21,7 @@ import java.io.IOException;
 import java.util.Random;
 
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 // TODO: sometimes remove tokens too...?
 
@@ -55,7 +55,7 @@ public final class MockGraphTokenFilter extends LookaheadTokenFilter<LookaheadTo
     }
     if (random.nextInt(7) == 5) {
 
-      final int posLength = _TestUtil.nextInt(random, 1, 5);
+      final int posLength = TestUtil.nextInt(random, 1, 5);
 
       if (DEBUG) {
         System.out.println("  do insert! posLen=" + posLength);
@@ -76,7 +76,7 @@ public final class MockGraphTokenFilter extends LookaheadTokenFilter<LookaheadTo
         insertToken();
         clearAttributes();
         posLenAtt.setPositionLength(posLength);
-        termAtt.append(_TestUtil.randomUnicodeString(random));
+        termAtt.append(TestUtil.randomUnicodeString(random));
         posIncAtt.setPositionIncrement(0);
         offsetAtt.setOffset(positions.get(outputPos).startOffset,
                             posEndData.endOffset);
diff --git a/lucene/test-framework/src/java/org/apache/lucene/analysis/MockHoleInjectingTokenFilter.java b/lucene/test-framework/src/java/org/apache/lucene/analysis/MockHoleInjectingTokenFilter.java
index 1718c1c..8d3ad2b 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/analysis/MockHoleInjectingTokenFilter.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/analysis/MockHoleInjectingTokenFilter.java
@@ -23,7 +23,7 @@ import java.util.Random;
 
 import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
 import org.apache.lucene.analysis.tokenattributes.PositionLengthAttribute;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 // TODO: maybe, instead to be more "natural", we should make
 // a MockRemovesTokensTF, ideally subclassing FilteringTF
@@ -64,7 +64,7 @@ public final class MockHoleInjectingTokenFilter extends TokenFilter {
       // Carefully inject a hole only where it won't mess up
       // the graph:
       if (posInc > 0 && maxPos <= nextPos && random.nextInt(5) == 3) {
-        final int holeSize = _TestUtil.nextInt(random, 1, 5);
+        final int holeSize = TestUtil.nextInt(random, 1, 5);
         posIncAtt.setPositionIncrement(posInc + holeSize);
         nextPos += holeSize;
       }
diff --git a/lucene/test-framework/src/java/org/apache/lucene/analysis/MockReaderWrapper.java b/lucene/test-framework/src/java/org/apache/lucene/analysis/MockReaderWrapper.java
index d089f4d..742059e 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/analysis/MockReaderWrapper.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/analysis/MockReaderWrapper.java
@@ -21,7 +21,7 @@ import java.io.IOException;
 import java.io.Reader;
 import java.util.Random;
 
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /** Wraps a Reader, and can throw random or fixed
  *  exceptions, and spoon feed read chars. */
@@ -68,7 +68,7 @@ public class MockReaderWrapper extends Reader {
     } else {
       // Spoon-feed: intentionally maybe return less than
       // the consumer asked for
-      realLen = _TestUtil.nextInt(random, 1, len);
+      realLen = TestUtil.nextInt(random, 1, len);
     }
     if (excAtChar != -1) {
       final int left = excAtChar - readSoFar;
diff --git a/lucene/test-framework/src/java/org/apache/lucene/codecs/mockrandom/MockRandomPostingsFormat.java b/lucene/test-framework/src/java/org/apache/lucene/codecs/mockrandom/MockRandomPostingsFormat.java
index 254cc96..eacde8e 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/codecs/mockrandom/MockRandomPostingsFormat.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/codecs/mockrandom/MockRandomPostingsFormat.java
@@ -64,7 +64,7 @@ import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.store.IndexOutput;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Randomly combines terms index impl w/ postings impls.
@@ -101,9 +101,9 @@ public final class MockRandomPostingsFormat extends PostingsFormat {
     public MockIntStreamFactory(Random random) {
       salt = random.nextInt();
       delegates.add(new MockSingleIntFactory());
-      final int blockSize = _TestUtil.nextInt(random, 1, 2000);
+      final int blockSize = TestUtil.nextInt(random, 1, 2000);
       delegates.add(new MockFixedIntBlockPostingsFormat.MockIntFactory(blockSize));
-      final int baseBlockSize = _TestUtil.nextInt(random, 1, 127);
+      final int baseBlockSize = TestUtil.nextInt(random, 1, 127);
       delegates.add(new MockVariableIntBlockPostingsFormat.MockIntFactory(baseBlockSize));
       // TODO: others
     }
@@ -147,7 +147,7 @@ public final class MockRandomPostingsFormat extends PostingsFormat {
 
     // we pull this before the seed intentionally: because its not consumed at runtime
     // (the skipInterval is written into postings header)
-    int skipInterval = _TestUtil.nextInt(seedRandom, minSkipInterval, 10);
+    int skipInterval = TestUtil.nextInt(seedRandom, minSkipInterval, 10);
     
     if (LuceneTestCase.VERBOSE) {
       System.out.println("MockRandomCodec: skipInterval=" + skipInterval);
@@ -183,7 +183,7 @@ public final class MockRandomPostingsFormat extends PostingsFormat {
     }
 
     if (random.nextBoolean()) {
-      final int totTFCutoff = _TestUtil.nextInt(random, 1, 20);
+      final int totTFCutoff = TestUtil.nextInt(random, 1, 20);
       if (LuceneTestCase.VERBOSE) {
         System.out.println("MockRandomCodec: writing pulsing postings with totTFCutoff=" + totTFCutoff);
       }
@@ -222,7 +222,7 @@ public final class MockRandomPostingsFormat extends PostingsFormat {
 
       // TODO: would be nice to allow 1 but this is very
       // slow to write
-      final int minTermsInBlock = _TestUtil.nextInt(random, 2, 100);
+      final int minTermsInBlock = TestUtil.nextInt(random, 2, 100);
       final int maxTermsInBlock = Math.max(2, (minTermsInBlock-1)*2 + random.nextInt(100));
 
       boolean success = false;
@@ -245,7 +245,7 @@ public final class MockRandomPostingsFormat extends PostingsFormat {
       final TermsIndexWriterBase indexWriter;
       try {
         if (random.nextBoolean()) {
-          int termIndexInterval = _TestUtil.nextInt(random, 1, 100);
+          int termIndexInterval = TestUtil.nextInt(random, 1, 100);
           if (LuceneTestCase.VERBOSE) {
             System.out.println("MockRandomCodec: fixed-gap terms index (tii=" + termIndexInterval + ")");
           }
@@ -254,18 +254,18 @@ public final class MockRandomPostingsFormat extends PostingsFormat {
           final VariableGapTermsIndexWriter.IndexTermSelector selector;
           final int n2 = random.nextInt(3);
           if (n2 == 0) {
-            final int tii = _TestUtil.nextInt(random, 1, 100);
+            final int tii = TestUtil.nextInt(random, 1, 100);
             selector = new VariableGapTermsIndexWriter.EveryNTermSelector(tii);
            if (LuceneTestCase.VERBOSE) {
               System.out.println("MockRandomCodec: variable-gap terms index (tii=" + tii + ")");
             }
           } else if (n2 == 1) {
-            final int docFreqThresh = _TestUtil.nextInt(random, 2, 100);
-            final int tii = _TestUtil.nextInt(random, 1, 100);
+            final int docFreqThresh = TestUtil.nextInt(random, 2, 100);
+            final int tii = TestUtil.nextInt(random, 1, 100);
             selector = new VariableGapTermsIndexWriter.EveryNOrDocFreqTermSelector(docFreqThresh, tii);
           } else {
             final long seed2 = random.nextLong();
-            final int gap = _TestUtil.nextInt(random, 2, 40);
+            final int gap = TestUtil.nextInt(random, 2, 40);
             if (LuceneTestCase.VERBOSE) {
              System.out.println("MockRandomCodec: random-gap terms index (max gap=" + gap + ")");
             }
@@ -322,7 +322,7 @@ public final class MockRandomPostingsFormat extends PostingsFormat {
 
     final Random random = new Random(seed);
     
-    int readBufferSize = _TestUtil.nextInt(random, 1, 4096);
+    int readBufferSize = TestUtil.nextInt(random, 1, 4096);
     if (LuceneTestCase.VERBOSE) {
       System.out.println("MockRandomCodec: readBufferSize=" + readBufferSize);
     }
@@ -343,7 +343,7 @@ public final class MockRandomPostingsFormat extends PostingsFormat {
     }
 
     if (random.nextBoolean()) {
-      final int totTFCutoff = _TestUtil.nextInt(random, 1, 20);
+      final int totTFCutoff = TestUtil.nextInt(random, 1, 20);
       if (LuceneTestCase.VERBOSE) {
         System.out.println("MockRandomCodec: reading pulsing postings with totTFCutoff=" + totTFCutoff);
       }
diff --git a/lucene/test-framework/src/java/org/apache/lucene/index/AlcoholicMergePolicy.java b/lucene/test-framework/src/java/org/apache/lucene/index/AlcoholicMergePolicy.java
index 25b922e..fedf224 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/index/AlcoholicMergePolicy.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/index/AlcoholicMergePolicy.java
@@ -24,7 +24,7 @@ import java.util.Locale;
 import java.util.Random;
 import java.util.TimeZone;
 
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /** 
  * <p>
@@ -47,9 +47,9 @@ public class AlcoholicMergePolicy extends LogMergePolicy {
   
   public AlcoholicMergePolicy(TimeZone tz, Random random) {
     this.calendar = new GregorianCalendar(tz, Locale.ROOT);
-    calendar.setTimeInMillis(_TestUtil.nextLong(random, 0, Long.MAX_VALUE));
+    calendar.setTimeInMillis(TestUtil.nextLong(random, 0, Long.MAX_VALUE));
     this.random = random;
-    maxMergeSize = _TestUtil.nextInt(random, 1024*1024, Integer.MAX_VALUE);
+    maxMergeSize = TestUtil.nextInt(random, 1024 * 1024, Integer.MAX_VALUE);
   }
   
   @Override
diff --git a/lucene/test-framework/src/java/org/apache/lucene/index/BaseCompressingDocValuesFormatTestCase.java b/lucene/test-framework/src/java/org/apache/lucene/index/BaseCompressingDocValuesFormatTestCase.java
index 381606f..119dcb9 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/index/BaseCompressingDocValuesFormatTestCase.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/index/BaseCompressingDocValuesFormatTestCase.java
@@ -26,7 +26,7 @@ import org.apache.lucene.document.Document;
 import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.RAMDirectory;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.packed.PackedInts;
 
 import com.carrotsearch.randomizedtesting.generators.RandomPicks;
@@ -47,7 +47,7 @@ public abstract class BaseCompressingDocValuesFormatTestCase extends BaseDocValu
     final IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));
     final IndexWriter iwriter = new IndexWriter(dir, iwc);
 
-    final int uniqueValueCount = _TestUtil.nextInt(random(), 1, 256);
+    final int uniqueValueCount = TestUtil.nextInt(random(), 1, 256);
     final List<Long> values = new ArrayList<Long>();
 
     final Document doc = new Document();
diff --git a/lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase.java b/lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase.java
index 9723df0..aab13f0 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase.java
@@ -56,7 +56,7 @@ import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefHash;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 import static org.apache.lucene.index.SortedSetDocValues.NO_MORE_ORDS;
 
@@ -1139,11 +1139,11 @@ public abstract class BaseDocValuesFormatTestCase extends LuceneTestCase {
     int numDocs = atLeast(100);
     BytesRefHash hash = new BytesRefHash();
     Map<String, String> docToString = new HashMap<String, String>();
-    int maxLength = _TestUtil.nextInt(random(), 1, 50);
+    int maxLength = TestUtil.nextInt(random(), 1, 50);
     for (int i = 0; i < numDocs; i++) {
       Document doc = new Document();
       doc.add(newTextField("id", "" + i, Field.Store.YES));
-      String string = _TestUtil.randomRealisticUnicodeString(random(), 1, maxLength);
+      String string = TestUtil.randomRealisticUnicodeString(random(), 1, maxLength);
       BytesRef br = new BytesRef(string);
       doc.add(new SortedDocValuesField("field", br));
       hash.add(br);
@@ -1175,7 +1175,7 @@ public abstract class BaseDocValuesFormatTestCase extends LuceneTestCase {
       Document doc = new Document();
       String id = "" + i + numDocs;
       doc.add(newTextField("id", id, Field.Store.YES));
-      String string = _TestUtil.randomRealisticUnicodeString(random(), 1, maxLength);
+      String string = TestUtil.randomRealisticUnicodeString(random(), 1, maxLength);
       BytesRef br = new BytesRef(string);
       hash.add(br);
       docToString.put(id, string);
@@ -1221,7 +1221,7 @@ public abstract class BaseDocValuesFormatTestCase extends LuceneTestCase {
     doTestNumericsVsStoredFields(new LongProducer() {
       @Override
       long next() {
-        return _TestUtil.nextLong(random(), minValue, maxValue);
+        return TestUtil.nextLong(random(), minValue, maxValue);
       }
     });
   }
@@ -1285,7 +1285,7 @@ public abstract class BaseDocValuesFormatTestCase extends LuceneTestCase {
     doTestMissingVsFieldCache(new LongProducer() {
       @Override
       long next() {
-        return _TestUtil.nextLong(random(), minValue, maxValue);
+        return TestUtil.nextLong(random(), minValue, maxValue);
       }
     });
   }
@@ -1431,7 +1431,7 @@ public abstract class BaseDocValuesFormatTestCase extends LuceneTestCase {
       if (minLength == maxLength) {
         length = minLength; // fixed length
       } else {
-        length = _TestUtil.nextInt(random(), minLength, maxLength);
+        length = TestUtil.nextInt(random(), minLength, maxLength);
       }
       byte buffer[] = new byte[length];
       random().nextBytes(buffer);
@@ -1470,7 +1470,7 @@ public abstract class BaseDocValuesFormatTestCase extends LuceneTestCase {
   public void testBinaryFixedLengthVsStoredFields() throws Exception {
     int numIterations = atLeast(1);
     for (int i = 0; i < numIterations; i++) {
-      int fixedLength = _TestUtil.nextInt(random(), 0, 10);
+      int fixedLength = TestUtil.nextInt(random(), 0, 10);
       doTestBinaryVsStoredFields(fixedLength, fixedLength);
     }
   }
@@ -1502,7 +1502,7 @@ public abstract class BaseDocValuesFormatTestCase extends LuceneTestCase {
       if (minLength == maxLength) {
         length = minLength; // fixed length
       } else {
-        length = _TestUtil.nextInt(random(), minLength, maxLength);
+        length = TestUtil.nextInt(random(), minLength, maxLength);
       }
       byte buffer[] = new byte[length];
       random().nextBytes(buffer);
@@ -1558,9 +1558,9 @@ public abstract class BaseDocValuesFormatTestCase extends LuceneTestCase {
       if (minLength == maxLength) {
         length = minLength; // fixed length
       } else {
-        length = _TestUtil.nextInt(random(), minLength, maxLength);
+        length = TestUtil.nextInt(random(), minLength, maxLength);
       }
-      String value = _TestUtil.randomSimpleString(random(), length);
+      String value = TestUtil.randomSimpleString(random(), length);
       indexedField.setStringValue(value);
       dvField.setBytesValue(new BytesRef(value));
       writer.addDocument(doc);
@@ -1592,7 +1592,7 @@ public abstract class BaseDocValuesFormatTestCase extends LuceneTestCase {
   public void testSortedFixedLengthVsStoredFields() throws Exception {
     int numIterations = atLeast(1);
     for (int i = 0; i < numIterations; i++) {
-      int fixedLength = _TestUtil.nextInt(random(), 1, 10);
+      int fixedLength = TestUtil.nextInt(random(), 1, 10);
       doTestSortedVsStoredFields(fixedLength, fixedLength);
     }
   }
@@ -1600,7 +1600,7 @@ public abstract class BaseDocValuesFormatTestCase extends LuceneTestCase {
   public void testSortedFixedLengthVsFieldCache() throws Exception {
     int numIterations = atLeast(1);
     for (int i = 0; i < numIterations; i++) {
-      int fixedLength = _TestUtil.nextInt(random(), 1, 10);
+      int fixedLength = TestUtil.nextInt(random(), 1, 10);
       doTestSortedVsFieldCache(fixedLength, fixedLength);
     }
   }
@@ -2082,13 +2082,13 @@ public abstract class BaseDocValuesFormatTestCase extends LuceneTestCase {
       if (minLength == maxLength) {
         length = minLength; // fixed length
       } else {
-        length = _TestUtil.nextInt(random(), minLength, maxLength);
+        length = TestUtil.nextInt(random(), minLength, maxLength);
       }
-      int numValues = _TestUtil.nextInt(random(), 0, maxValuesPerDoc);
+      int numValues = TestUtil.nextInt(random(), 0, maxValuesPerDoc);
       // create a random set of strings
       Set<String> values = new TreeSet<String>();
       for (int v = 0; v < numValues; v++) {
-        values.add(_TestUtil.randomSimpleString(random(), length));
+        values.add(TestUtil.randomSimpleString(random(), length));
       }
       
       // add ordered to the stored field
@@ -2146,7 +2146,7 @@ public abstract class BaseDocValuesFormatTestCase extends LuceneTestCase {
     assumeTrue("Codec does not support SORTED_SET", defaultCodecSupportsSortedSet());
     int numIterations = atLeast(1);
     for (int i = 0; i < numIterations; i++) {
-      int fixedLength = _TestUtil.nextInt(random(), 1, 10);
+      int fixedLength = TestUtil.nextInt(random(), 1, 10);
       doTestSortedSetVsStoredFields(fixedLength, fixedLength, 16);
     }
   }
@@ -2163,7 +2163,7 @@ public abstract class BaseDocValuesFormatTestCase extends LuceneTestCase {
     assumeTrue("Codec does not support SORTED_SET", defaultCodecSupportsSortedSet());
     int numIterations = atLeast(1);
     for (int i = 0; i < numIterations; i++) {
-      int fixedLength = _TestUtil.nextInt(random(), 1, 10);
+      int fixedLength = TestUtil.nextInt(random(), 1, 10);
       doTestSortedSetVsStoredFields(fixedLength, fixedLength, 1);
     }
   }
@@ -2256,7 +2256,7 @@ public abstract class BaseDocValuesFormatTestCase extends LuceneTestCase {
     
     // random seekExact(ord)
     for (long i = 0; i < numOrds; i++) {
-      long randomOrd = _TestUtil.nextLong(random(), 0, numOrds-1);
+      long randomOrd = TestUtil.nextLong(random(), 0, numOrds - 1);
       expected.seekExact(randomOrd);
       actual.seekExact(randomOrd);
       assertEquals(expected.ord(), actual.ord());
@@ -2265,7 +2265,7 @@ public abstract class BaseDocValuesFormatTestCase extends LuceneTestCase {
     
     // random seekExact(BytesRef)
     for (long i = 0; i < numOrds; i++) {
-      long randomOrd = _TestUtil.nextLong(random(), 0, numOrds-1);
+      long randomOrd = TestUtil.nextLong(random(), 0, numOrds - 1);
       expected.seekExact(randomOrd);
       actual.seekExact(expected.term());
       assertEquals(expected.ord(), actual.ord());
@@ -2274,7 +2274,7 @@ public abstract class BaseDocValuesFormatTestCase extends LuceneTestCase {
     
     // random seekCeil(BytesRef)
     for (long i = 0; i < numOrds; i++) {
-      BytesRef target = new BytesRef(_TestUtil.randomUnicodeString(random()));
+      BytesRef target = new BytesRef(TestUtil.randomUnicodeString(random()));
       SeekStatus expectedStatus = expected.seekCeil(target);
       assertEquals(expectedStatus, actual.seekCeil(target));
       if (expectedStatus != SeekStatus.END) {
@@ -2299,13 +2299,13 @@ public abstract class BaseDocValuesFormatTestCase extends LuceneTestCase {
       if (minLength == maxLength) {
         length = minLength; // fixed length
       } else {
-        length = _TestUtil.nextInt(random(), minLength, maxLength);
+        length = TestUtil.nextInt(random(), minLength, maxLength);
       }
       int numValues = random().nextInt(17);
       // create a random list of strings
       List<String> values = new ArrayList<String>();
       for (int v = 0; v < numValues; v++) {
-        values.add(_TestUtil.randomSimpleString(random(), length));
+        values.add(TestUtil.randomSimpleString(random(), length));
       }
       
       // add in any order to the indexed field
@@ -2363,7 +2363,7 @@ public abstract class BaseDocValuesFormatTestCase extends LuceneTestCase {
     assumeTrue("Codec does not support SORTED_SET", defaultCodecSupportsSortedSet());
     int numIterations = atLeast(1);
     for (int i = 0; i < numIterations; i++) {
-      int fixedLength = _TestUtil.nextInt(random(), 1, 10);
+      int fixedLength = TestUtil.nextInt(random(), 1, 10);
       doTestSortedSetVsUninvertedField(fixedLength, fixedLength);
     }
   }
@@ -2615,17 +2615,17 @@ public abstract class BaseDocValuesFormatTestCase extends LuceneTestCase {
     Analyzer analyzer = new MockAnalyzer(random());
     // FSDirectory because SimpleText will consume gobbs of
     // space when storing big binary values:
-    Directory d = newFSDirectory(_TestUtil.getTempDir("hugeBinaryValues"));
+    Directory d = newFSDirectory(TestUtil.getTempDir("hugeBinaryValues"));
     boolean doFixed = random().nextBoolean();
     int numDocs;
     int fixedLength = 0;
     if (doFixed) {
       // Sometimes make all values fixed length since some
       // codecs have different code paths for this:
-      numDocs = _TestUtil.nextInt(random(), 10, 20);
-      fixedLength = _TestUtil.nextInt(random(), 65537, 256*1024);
+      numDocs = TestUtil.nextInt(random(), 10, 20);
+      fixedLength = TestUtil.nextInt(random(), 65537, 256 * 1024);
     } else {
-      numDocs = _TestUtil.nextInt(random(), 100, 200);
+      numDocs = TestUtil.nextInt(random(), 100, 200);
     }
     IndexWriter w = new IndexWriter(d, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));
     List<byte[]> docBytes = new ArrayList<byte[]>();
@@ -2640,9 +2640,9 @@ public abstract class BaseDocValuesFormatTestCase extends LuceneTestCase {
       if (doFixed) {
         numBytes = fixedLength;
       } else if (docID == 0 || random().nextInt(5) == 3) {
-        numBytes = _TestUtil.nextInt(random(), 65537, 3*1024*1024);
+        numBytes = TestUtil.nextInt(random(), 65537, 3 * 1024 * 1024);
       } else {
-        numBytes = _TestUtil.nextInt(random(), 1, 1024*1024);
+        numBytes = TestUtil.nextInt(random(), 1, 1024 * 1024);
       }
       totalBytes += numBytes;
       if (totalBytes > 5 * 1024*1024) {
@@ -2713,17 +2713,17 @@ public abstract class BaseDocValuesFormatTestCase extends LuceneTestCase {
     Analyzer analyzer = new MockAnalyzer(random());
     // FSDirectory because SimpleText will consume gobbs of
     // space when storing big binary values:
-    Directory d = newFSDirectory(_TestUtil.getTempDir("hugeBinaryValues"));
+    Directory d = newFSDirectory(TestUtil.getTempDir("hugeBinaryValues"));
     boolean doFixed = random().nextBoolean();
     int numDocs;
     int fixedLength = 0;
     if (doFixed) {
       // Sometimes make all values fixed length since some
       // codecs have different code paths for this:
-      numDocs = _TestUtil.nextInt(random(), 10, 20);
+      numDocs = TestUtil.nextInt(random(), 10, 20);
       fixedLength = Lucene42DocValuesFormat.MAX_BINARY_FIELD_LENGTH;
     } else {
-      numDocs = _TestUtil.nextInt(random(), 100, 200);
+      numDocs = TestUtil.nextInt(random(), 100, 200);
     }
     IndexWriter w = new IndexWriter(d, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));
     List<byte[]> docBytes = new ArrayList<byte[]>();
@@ -2740,7 +2740,7 @@ public abstract class BaseDocValuesFormatTestCase extends LuceneTestCase {
       } else if (docID == 0 || random().nextInt(5) == 3) {
         numBytes = Lucene42DocValuesFormat.MAX_BINARY_FIELD_LENGTH;
       } else {
-        numBytes = _TestUtil.nextInt(random(), 1, Lucene42DocValuesFormat.MAX_BINARY_FIELD_LENGTH);
+        numBytes = TestUtil.nextInt(random(), 1, Lucene42DocValuesFormat.MAX_BINARY_FIELD_LENGTH);
       }
       totalBytes += numBytes;
       if (totalBytes > 5 * 1024*1024) {
@@ -2799,7 +2799,7 @@ public abstract class BaseDocValuesFormatTestCase extends LuceneTestCase {
     int numDocs = atLeast(300);
     for (int i = 0; i < numDocs; i++) {
       idField.setStringValue(Integer.toString(i));
-      int length = _TestUtil.nextInt(random(), 0, 8);
+      int length = TestUtil.nextInt(random(), 0, 8);
       byte buffer[] = new byte[length];
       random().nextBytes(buffer);
       storedBinField.setBytesValue(buffer);
@@ -2824,7 +2824,7 @@ public abstract class BaseDocValuesFormatTestCase extends LuceneTestCase {
     
     // compare
     final DirectoryReader ir = DirectoryReader.open(dir);
-    int numThreads = _TestUtil.nextInt(random(), 2, 7);
+    int numThreads = TestUtil.nextInt(random(), 2, 7);
     Thread threads[] = new Thread[numThreads];
     final CountDownLatch startingGun = new CountDownLatch(1);
     
@@ -2850,7 +2850,7 @@ public abstract class BaseDocValuesFormatTestCase extends LuceneTestCase {
                 assertEquals(Long.parseLong(expected), numerics.get(j));
               }
             }
-            _TestUtil.checkReader(ir);
+            TestUtil.checkReader(ir);
           } catch (Exception e) {
             throw new RuntimeException(e);
           }
@@ -2884,7 +2884,7 @@ public abstract class BaseDocValuesFormatTestCase extends LuceneTestCase {
     int numDocs = atLeast(300);
     for (int i = 0; i < numDocs; i++) {
       idField.setStringValue(Integer.toString(i));
-      int length = _TestUtil.nextInt(random(), 0, 8);
+      int length = TestUtil.nextInt(random(), 0, 8);
       byte buffer[] = new byte[length];
       random().nextBytes(buffer);
       storedBinField.setBytesValue(buffer);
@@ -2907,7 +2907,7 @@ public abstract class BaseDocValuesFormatTestCase extends LuceneTestCase {
       int numSortedSetFields = random().nextInt(3);
       Set<String> values = new TreeSet<String>();
       for (int j = 0; j < numSortedSetFields; j++) {
-        values.add(_TestUtil.randomSimpleString(random()));
+        values.add(TestUtil.randomSimpleString(random()));
       }
       for (String v : values) {
         doc.add(new SortedSetDocValuesField("dvSortedSet", new BytesRef(v)));
@@ -2929,7 +2929,7 @@ public abstract class BaseDocValuesFormatTestCase extends LuceneTestCase {
     
     // compare
     final DirectoryReader ir = DirectoryReader.open(dir);
-    int numThreads = _TestUtil.nextInt(random(), 2, 7);
+    int numThreads = TestUtil.nextInt(random(), 2, 7);
     Thread threads[] = new Thread[numThreads];
     final CountDownLatch startingGun = new CountDownLatch(1);
     
@@ -2997,7 +2997,7 @@ public abstract class BaseDocValuesFormatTestCase extends LuceneTestCase {
                 }
               }
             }
-            _TestUtil.checkReader(ir);
+            TestUtil.checkReader(ir);
           } catch (Exception e) {
             throw new RuntimeException(e);
           }
diff --git a/lucene/test-framework/src/java/org/apache/lucene/index/BasePostingsFormatTestCase.java b/lucene/test-framework/src/java/org/apache/lucene/index/BasePostingsFormatTestCase.java
index 8938be6..d48d5e1 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/index/BasePostingsFormatTestCase.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/index/BasePostingsFormatTestCase.java
@@ -23,7 +23,6 @@ import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.EnumSet;
-import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
@@ -57,7 +56,7 @@ import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.LineFileDocs;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.RamUsageEstimator;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.AfterClass;
 import org.junit.BeforeClass;
 
@@ -149,12 +148,12 @@ public abstract class BasePostingsFormatTestCase extends LuceneTestCase {
     public SeedPostings(long seed, int minDocFreq, int maxDocFreq, Bits liveDocs, IndexOptions options, boolean allowPayloads) {
       random = new Random(seed);
       docRandom = new Random(random.nextLong());
-      docFreq = _TestUtil.nextInt(random, minDocFreq, maxDocFreq);
+      docFreq = TestUtil.nextInt(random, minDocFreq, maxDocFreq);
       this.liveDocs = liveDocs;
       this.allowPayloads = allowPayloads;
 
       // TODO: more realistic to inversely tie this to numDocs:
-      maxDocSpacing = _TestUtil.nextInt(random, 1, 100);
+      maxDocSpacing = TestUtil.nextInt(random, 1, 100);
 
       if (random.nextInt(10) == 7) {
         // 10% of the time create big payloads:
@@ -193,21 +192,21 @@ public abstract class BasePostingsFormatTestCase extends LuceneTestCase {
           docID++;
         } else {
           // TODO: sometimes have a biggish gap here!
-          docID += _TestUtil.nextInt(docRandom, 1, maxDocSpacing);
+          docID += TestUtil.nextInt(docRandom, 1, maxDocSpacing);
         }
 
         if (random.nextInt(200) == 17) {
-          freq = _TestUtil.nextInt(random, 1, 1000);
+          freq = TestUtil.nextInt(random, 1, 1000);
         } else if (random.nextInt(10) == 17) {
-          freq = _TestUtil.nextInt(random, 1, 20);
+          freq = TestUtil.nextInt(random, 1, 20);
         } else {
-          freq = _TestUtil.nextInt(random, 1, 4);
+          freq = TestUtil.nextInt(random, 1, 4);
         }
 
         pos = 0;
         offset = 0;
         posUpto = 0;
-        posSpacing = _TestUtil.nextInt(random, 1, 100);
+        posSpacing = TestUtil.nextInt(random, 1, 100);
 
         upto++;
         return docID;
@@ -239,7 +238,7 @@ public abstract class BasePostingsFormatTestCase extends LuceneTestCase {
       } else if (posSpacing == 1) {
         pos++;
       } else {
-        pos += _TestUtil.nextInt(random, 1, posSpacing);
+        pos += TestUtil.nextInt(random, 1, posSpacing);
       }
 
       if (payloadSize != 0) {
@@ -344,7 +343,7 @@ public abstract class BasePostingsFormatTestCase extends LuceneTestCase {
     totalPayloadBytes = 0;
     fields = new TreeMap<String,SortedMap<BytesRef,Long>>();
 
-    final int numFields = _TestUtil.nextInt(random(), 1, 5);
+    final int numFields = TestUtil.nextInt(random(), 1, 5);
     if (VERBOSE) {
       System.out.println("TEST: " + numFields + " fields");
     }
@@ -353,7 +352,7 @@ public abstract class BasePostingsFormatTestCase extends LuceneTestCase {
     FieldInfo[] fieldInfoArray = new FieldInfo[numFields];
     int fieldUpto = 0;
     while (fieldUpto < numFields) {
-      String field = _TestUtil.randomSimpleString(random());
+      String field = TestUtil.randomSimpleString(random());
       if (fields.containsKey(field)) {
         continue;
       }
@@ -371,11 +370,11 @@ public abstract class BasePostingsFormatTestCase extends LuceneTestCase {
       if (random().nextInt(10) == 7) {
         numTerms = atLeast(50);
       } else {
-        numTerms = _TestUtil.nextInt(random(), 2, 20);
+        numTerms = TestUtil.nextInt(random(), 2, 20);
       }
 
       for(int termUpto=0;termUpto<numTerms;termUpto++) {
-        String term = _TestUtil.randomSimpleString(random());
+        String term = TestUtil.randomSimpleString(random());
         if (seenTerms.contains(term)) {
           continue;
         }
@@ -669,7 +668,7 @@ public abstract class BasePostingsFormatTestCase extends LuceneTestCase {
     for(int fieldUpto=0;fieldUpto<fields.size();fieldUpto++) {
       FieldInfo oldFieldInfo = fieldInfos.fieldInfo(fieldUpto);
 
-      String pf = _TestUtil.getPostingsFormat(codec, oldFieldInfo.name);
+      String pf = TestUtil.getPostingsFormat(codec, oldFieldInfo.name);
       int fieldMaxIndexOption;
       if (doesntSupportOffsets.contains(pf)) {
         fieldMaxIndexOption = Math.min(maxIndexOptionNoOffsets, maxIndexOption);
@@ -878,7 +877,7 @@ public abstract class BasePostingsFormatTestCase extends LuceneTestCase {
     }
 
     double skipChance = alwaysTestMax ? 0.5 : random().nextDouble();
-    int numSkips = expected.docFreq < 3 ? 1 : _TestUtil.nextInt(random(), 1, Math.min(20, expected.docFreq/3));
+    int numSkips = expected.docFreq < 3 ? 1 : TestUtil.nextInt(random(), 1, Math.min(20, expected.docFreq / 3));
     int skipInc = expected.docFreq/numSkips;
     int skipDocInc = maxDoc/numSkips;
 
@@ -921,7 +920,7 @@ public abstract class BasePostingsFormatTestCase extends LuceneTestCase {
         int targetDocID = -1;
         if (expected.upto < stopAt && random().nextBoolean()) {
           // Pick target we know exists:
-          final int skipCount = _TestUtil.nextInt(random(), 1, skipInc);
+          final int skipCount = TestUtil.nextInt(random(), 1, skipInc);
           for(int skip=0;skip<skipCount;skip++) {
             if (expected.nextDoc() == DocsEnum.NO_MORE_DOCS) {
               break;
@@ -929,7 +928,7 @@ public abstract class BasePostingsFormatTestCase extends LuceneTestCase {
           }
         } else {
           // Pick random target (might not exist):
-          final int skipDocIDs = _TestUtil.nextInt(random(), 1, skipDocInc);
+          final int skipDocIDs = TestUtil.nextInt(random(), 1, skipDocInc);
           if (skipDocIDs > 0) {
             targetDocID = expected.docID() + skipDocIDs;
             expected.advance(targetDocID);
@@ -1083,7 +1082,7 @@ public abstract class BasePostingsFormatTestCase extends LuceneTestCase {
                          final boolean alwaysTestMax) throws Exception {
 
     if (options.contains(Option.THREADS)) {
-      int numThreads = _TestUtil.nextInt(random(), 2, 5);
+      int numThreads = TestUtil.nextInt(random(), 2, 5);
       Thread[] threads = new Thread[numThreads];
       for(int threadUpto=0;threadUpto<numThreads;threadUpto++) {
         threads[threadUpto] = new TestThread(this, fieldsSource, options, maxTestOptions, maxIndexOptions, alwaysTestMax);
@@ -1212,7 +1211,7 @@ public abstract class BasePostingsFormatTestCase extends LuceneTestCase {
   /** Indexes all fields/terms at the specified
    *  IndexOptions, and fully tests at that IndexOptions. */
   private void testFull(IndexOptions options, boolean withPayloads) throws Exception {
-    File path = _TestUtil.getTempDir("testPostingsFormat.testExact");
+    File path = TestUtil.getTempDir("testPostingsFormat.testExact");
     Directory dir = newFSDirectory(path);
 
     // TODO test thread safety of buildIndex too
@@ -1233,7 +1232,7 @@ public abstract class BasePostingsFormatTestCase extends LuceneTestCase {
 
     fieldsProducer.close();
     dir.close();
-    _TestUtil.rmDir(path);
+    TestUtil.rmDir(path);
   }
 
   public void testDocsOnly() throws Exception {
@@ -1265,7 +1264,7 @@ public abstract class BasePostingsFormatTestCase extends LuceneTestCase {
     int iters = 5;
 
     for(int iter=0;iter<iters;iter++) {
-      File path = _TestUtil.getTempDir("testPostingsFormat");
+      File path = TestUtil.getTempDir("testPostingsFormat");
       Directory dir = newFSDirectory(path);
 
       boolean indexPayloads = random().nextBoolean();
@@ -1282,7 +1281,7 @@ public abstract class BasePostingsFormatTestCase extends LuceneTestCase {
       fieldsProducer = null;
 
       dir.close();
-      _TestUtil.rmDir(path);
+      TestUtil.rmDir(path);
     }
   }
   
@@ -1463,7 +1462,7 @@ public abstract class BasePostingsFormatTestCase extends LuceneTestCase {
                         totalTermFreq += docs.freq();
                         if (docs instanceof DocsAndPositionsEnum) {
                           DocsAndPositionsEnum posEnum = (DocsAndPositionsEnum) docs;
-                          int limit = _TestUtil.nextInt(random(), 1, docs.freq());
+                          int limit = TestUtil.nextInt(random(), 1, docs.freq());
                           for(int i=0;i<limit;i++) {
                             posEnum.nextPosition();
                           }
@@ -1514,7 +1513,7 @@ public abstract class BasePostingsFormatTestCase extends LuceneTestCase {
                           totalTermFreq += docs.freq();
                           if (docs instanceof DocsAndPositionsEnum) {
                             DocsAndPositionsEnum posEnum = (DocsAndPositionsEnum) docs;
-                            int limit = _TestUtil.nextInt(random(), 1, docs.freq());
+                            int limit = TestUtil.nextInt(random(), 1, docs.freq());
                             for(int i=0;i<limit;i++) {
                               posEnum.nextPosition();
                             }
diff --git a/lucene/test-framework/src/java/org/apache/lucene/index/BaseStoredFieldsFormatTestCase.java b/lucene/test-framework/src/java/org/apache/lucene/index/BaseStoredFieldsFormatTestCase.java
index 7e7e403..1c9a826 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/index/BaseStoredFieldsFormatTestCase.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/index/BaseStoredFieldsFormatTestCase.java
@@ -57,7 +57,8 @@ import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.store.MockDirectoryWrapper.Throttling;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 import com.carrotsearch.randomizedtesting.generators.RandomInts;
 import com.carrotsearch.randomizedtesting.generators.RandomPicks;
@@ -93,10 +94,10 @@ public abstract class BaseStoredFieldsFormatTestCase extends LuceneTestCase {
   public void testRandomStoredFields() throws IOException {
     Directory dir = newDirectory();
     Random rand = random();
-    RandomIndexWriter w = new RandomIndexWriter(rand, dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(_TestUtil.nextInt(rand, 5, 20)));
+    RandomIndexWriter w = new RandomIndexWriter(rand, dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(TestUtil.nextInt(rand, 5, 20)));
     //w.w.setNoCFSRatio(0.0);
     final int docCount = atLeast(200);
-    final int fieldCount = _TestUtil.nextInt(rand, 1, 5);
+    final int fieldCount = TestUtil.nextInt(rand, 1, 5);
 
     final List<Integer> fieldIDs = new ArrayList<Integer>();
 
@@ -129,7 +130,7 @@ public abstract class BaseStoredFieldsFormatTestCase extends LuceneTestCase {
       for(int field: fieldIDs) {
         final String s;
         if (rand.nextInt(4) != 3) {
-          s = _TestUtil.randomUnicodeString(rand, 1000);
+          s = TestUtil.randomUnicodeString(rand, 1000);
           doc.add(newField("f"+field, s, customType2));
         } else {
           s = null;
@@ -349,7 +350,7 @@ public abstract class BaseStoredFieldsFormatTestCase extends LuceneTestCase {
     ft.setStored(true);
     ft.freeze();
 
-    final String string = _TestUtil.randomSimpleString(random(), 50);
+    final String string = TestUtil.randomSimpleString(random(), 50);
     final byte[] bytes = string.getBytes("UTF-8");
     final long l = random().nextBoolean() ? random().nextInt(42) : random().nextLong();
     final int i = random().nextBoolean() ? random().nextInt(42) : random().nextInt();
@@ -597,7 +598,7 @@ public abstract class BaseStoredFieldsFormatTestCase extends LuceneTestCase {
     // for this test we force a FS dir
     // we can't just use newFSDirectory, because this test doesn't really index anything.
     // so if we get NRTCachingDir+SimpleText, we make massive stored fields and OOM (LUCENE-4484)
-    Directory dir = new MockDirectoryWrapper(random(), new MMapDirectory(_TestUtil.getTempDir("testBigDocuments")));
+    Directory dir = new MockDirectoryWrapper(random(), new MMapDirectory(TestUtil.getTempDir("testBigDocuments")));
     IndexWriterConfig iwConf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));
     iwConf.setMaxBufferedDocs(RandomInts.randomIntBetween(random(), 2, 30));
     RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwConf);
diff --git a/lucene/test-framework/src/java/org/apache/lucene/index/BaseTermVectorsFormatTestCase.java b/lucene/test-framework/src/java/org/apache/lucene/index/BaseTermVectorsFormatTestCase.java
index d170a0e..5b0bdd0 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/index/BaseTermVectorsFormatTestCase.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/index/BaseTermVectorsFormatTestCase.java
@@ -48,7 +48,7 @@ import org.apache.lucene.util.AttributeImpl;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 import com.carrotsearch.randomizedtesting.generators.RandomPicks;
 
@@ -216,17 +216,17 @@ public abstract class BaseTermVectorsFormatTestCase extends LuceneTestCase {
         final int o = random().nextInt(sampleTerms.length);
         terms[i] = sampleTerms[o];
         termBytes[i] = sampleTermBytes[o];
-        positionsIncrements[i] = _TestUtil.nextInt(random(), i == 0 ? 1 : 0, 10);
+        positionsIncrements[i] = TestUtil.nextInt(random(), i == 0 ? 1 : 0, 10);
         if (offsetsGoBackwards) {
           startOffsets[i] = random().nextInt();
           endOffsets[i] = random().nextInt();
         } else {
           if (i == 0) {
-            startOffsets[i] = _TestUtil.nextInt(random(), 0, 1 << 16);
+            startOffsets[i] = TestUtil.nextInt(random(), 0, 1 << 16);
           } else {
-            startOffsets[i] = startOffsets[i-1] + _TestUtil.nextInt(random(), 0, rarely() ? 1 << 16 : 20);
+            startOffsets[i] = startOffsets[i-1] + TestUtil.nextInt(random(), 0, rarely() ? 1 << 16 : 20);
           }
-          endOffsets[i] = startOffsets[i] + _TestUtil.nextInt(random(), 0, rarely() ? 1 << 10 : 20);
+          endOffsets[i] = startOffsets[i] + TestUtil.nextInt(random(), 0, rarely() ? 1 << 10 : 20);
         }
       }
 
@@ -320,7 +320,7 @@ public abstract class BaseTermVectorsFormatTestCase extends LuceneTestCase {
           this.fieldNames[i] = RandomPicks.randomFrom(random(), fieldNames);
         } while (usedFileNames.contains(this.fieldNames[i]));
         usedFileNames.add(this.fieldNames[i]);
-        tokenStreams[i] = new RandomTokenStream(_TestUtil.nextInt(random(), 1, maxTermCount), sampleTerms, sampleTermBytes);
+        tokenStreams[i] = new RandomTokenStream(TestUtil.nextInt(random(), 1, maxTermCount), sampleTerms, sampleTermBytes);
       }
     }
 
@@ -343,14 +343,14 @@ public abstract class BaseTermVectorsFormatTestCase extends LuceneTestCase {
     protected RandomDocumentFactory(int distinctFieldNames, int disctinctTerms) {
       final Set<String> fieldNames = new HashSet<String>();
       while (fieldNames.size() < distinctFieldNames) {
-        fieldNames.add(_TestUtil.randomSimpleString(random()));
+        fieldNames.add(TestUtil.randomSimpleString(random()));
         fieldNames.remove("id");
       }
       this.fieldNames = fieldNames.toArray(new String[0]);
       terms = new String[disctinctTerms];
       termBytes = new BytesRef[disctinctTerms];
       for (int i = 0; i < disctinctTerms; ++i) {
-        terms[i] = _TestUtil.randomRealisticUnicodeString(random());
+        terms[i] = TestUtil.randomRealisticUnicodeString(random());
         termBytes[i] = new BytesRef(terms[i]);
       }
     }
@@ -525,7 +525,7 @@ public abstract class BaseTermVectorsFormatTestCase extends LuceneTestCase {
       final Document emptyDoc = new Document();
       final Directory dir = newDirectory();
       final RandomIndexWriter writer = new RandomIndexWriter(random(), dir);
-      final RandomDocument doc = docFactory.newDocument(_TestUtil.nextInt(random(), 1, 3), 20, options);
+      final RandomDocument doc = docFactory.newDocument(TestUtil.nextInt(random(), 1, 3), 20, options);
       for (int i = 0; i < numDocs; ++i) {
         if (i == docWithVectors) {
           writer.addDocument(addId(doc.toDocument(), "42"));
@@ -560,7 +560,7 @@ public abstract class BaseTermVectorsFormatTestCase extends LuceneTestCase {
       }
       final Directory dir = newDirectory();
       final RandomIndexWriter writer = new RandomIndexWriter(random(), dir);
-      final RandomDocument doc = docFactory.newDocument(_TestUtil.nextInt(random(), 1, 2), atLeast(20000), options);
+      final RandomDocument doc = docFactory.newDocument(TestUtil.nextInt(random(), 1, 2), atLeast(20000), options);
       writer.addDocument(doc.toDocument());
       final IndexReader reader = writer.getReader();
       assertEquals(doc, reader.getTermVectors(0));
@@ -587,7 +587,7 @@ public abstract class BaseTermVectorsFormatTestCase extends LuceneTestCase {
 
   // different options for the same field
   public void testMixedOptions() throws IOException {
-    final int numFields = _TestUtil.nextInt(random(), 1, 3);
+    final int numFields = TestUtil.nextInt(random(), 1, 3);
     final RandomDocumentFactory docFactory = new RandomDocumentFactory(numFields, 10);
     for (Options options1 : validOptions()) {
       for (Options options2 : validOptions()) {
@@ -617,7 +617,7 @@ public abstract class BaseTermVectorsFormatTestCase extends LuceneTestCase {
     final int numDocs = atLeast(100);
     final RandomDocument[] docs = new RandomDocument[numDocs];
     for (int i = 0; i < numDocs; ++i) {
-      docs[i] = docFactory.newDocument(_TestUtil.nextInt(random(), 1, 3), _TestUtil.nextInt(random(), 10, 50), randomOptions());
+      docs[i] = docFactory.newDocument(TestUtil.nextInt(random(), 1, 3), TestUtil.nextInt(random(), 10, 50), randomOptions());
     }
     final Directory dir = newDirectory();
     final RandomIndexWriter writer = new RandomIndexWriter(random(), dir);
@@ -645,7 +645,7 @@ public abstract class BaseTermVectorsFormatTestCase extends LuceneTestCase {
     for (Options options : validOptions()) {
       final RandomDocument[] docs = new RandomDocument[numDocs];
       for (int i = 0; i < numDocs; ++i) {
-        docs[i] = docFactory.newDocument(_TestUtil.nextInt(random(), 1, 3), atLeast(10), options);
+        docs[i] = docFactory.newDocument(TestUtil.nextInt(random(), 1, 3), atLeast(10), options);
       }
       final Directory dir = newDirectory();
       final RandomIndexWriter writer = new RandomIndexWriter(random(), dir);
@@ -681,7 +681,7 @@ public abstract class BaseTermVectorsFormatTestCase extends LuceneTestCase {
     for (Options options : validOptions()) {
       final RandomDocument[] docs = new RandomDocument[numDocs];
       for (int i = 0; i < numDocs; ++i) {
-        docs[i] = docFactory.newDocument(_TestUtil.nextInt(random(), 1, 3), atLeast(10), options);
+        docs[i] = docFactory.newDocument(TestUtil.nextInt(random(), 1, 3), atLeast(10), options);
       }
       final Directory dir = newDirectory();
       final RandomIndexWriter writer = new RandomIndexWriter(random(), dir);
diff --git a/lucene/test-framework/src/java/org/apache/lucene/index/MockRandomMergePolicy.java b/lucene/test-framework/src/java/org/apache/lucene/index/MockRandomMergePolicy.java
index 0459de2..d4ec400 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/index/MockRandomMergePolicy.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/index/MockRandomMergePolicy.java
@@ -25,8 +25,7 @@ import java.util.List;
 import java.util.Map;
 import java.util.Random;
 
-import org.apache.lucene.index.MergePolicy.MergeTrigger;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * MergePolicy that makes random decisions for testing.
@@ -64,7 +63,7 @@ public class MockRandomMergePolicy extends MergePolicy {
 
       // TODO: sometimes make more than 1 merge?
       mergeSpec = new MergeSpecification();
-      final int segsToMerge = _TestUtil.nextInt(random, 1, numSegments);
+      final int segsToMerge = TestUtil.nextInt(random, 1, numSegments);
       mergeSpec.add(new OneMerge(segments.subList(0, segsToMerge)));
     }
 
@@ -93,7 +92,7 @@ public class MockRandomMergePolicy extends MergePolicy {
       int upto = 0;
       while(upto < eligibleSegments.size()) {
         int max = Math.min(10, eligibleSegments.size()-upto);
-        int inc = max <= 2 ? max : _TestUtil.nextInt(random, 2, max);
+        int inc = max <= 2 ? max : TestUtil.nextInt(random, 2, max);
         mergeSpec.add(new OneMerge(eligibleSegments.subList(upto, upto+inc)));
         upto += inc;
       }
diff --git a/lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec.java b/lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec.java
index 410b502..5e3911f 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec.java
@@ -55,7 +55,7 @@ import org.apache.lucene.codecs.pulsing.Pulsing41PostingsFormat;
 import org.apache.lucene.codecs.simpletext.SimpleTextDocValuesFormat;
 import org.apache.lucene.codecs.simpletext.SimpleTextPostingsFormat;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Codec that assigns per-field random postings formats.
@@ -123,9 +123,9 @@ public class RandomCodec extends Lucene46Codec {
     this.perFieldSeed = random.nextInt();
     // TODO: make it possible to specify min/max iterms per
     // block via CL:
-    int minItemsPerBlock = _TestUtil.nextInt(random, 2, 100);
+    int minItemsPerBlock = TestUtil.nextInt(random, 2, 100);
     int maxItemsPerBlock = 2*(Math.max(2, minItemsPerBlock-1)) + random.nextInt(100);
-    int lowFreqCutoff = _TestUtil.nextInt(random, 2, 100);
+    int lowFreqCutoff = TestUtil.nextInt(random, 2, 100);
 
     add(avoidCodecs,
         new Lucene41PostingsFormat(minItemsPerBlock, maxItemsPerBlock),
@@ -143,13 +143,13 @@ public class RandomCodec extends Lucene46Codec {
         //with such "wrapper" classes?
         new TestBloomFilteredLucene41Postings(),                
         new MockSepPostingsFormat(),
-        new MockFixedIntBlockPostingsFormat(_TestUtil.nextInt(random, 1, 2000)),
-        new MockVariableIntBlockPostingsFormat( _TestUtil.nextInt(random, 1, 127)),
+        new MockFixedIntBlockPostingsFormat(TestUtil.nextInt(random, 1, 2000)),
+        new MockVariableIntBlockPostingsFormat( TestUtil.nextInt(random, 1, 127)),
         new MockRandomPostingsFormat(random),
         new NestedPulsingPostingsFormat(),
-        new Lucene41WithOrds(_TestUtil.nextInt(random, 1, 1000)),
-        new Lucene41VarGapFixedInterval(_TestUtil.nextInt(random, 1, 1000)),
-        new Lucene41VarGapDocFreqInterval(_TestUtil.nextInt(random, 1, 100), _TestUtil.nextInt(random, 1, 1000)),
+        new Lucene41WithOrds(TestUtil.nextInt(random, 1, 1000)),
+        new Lucene41VarGapFixedInterval(TestUtil.nextInt(random, 1, 1000)),
+        new Lucene41VarGapDocFreqInterval(TestUtil.nextInt(random, 1, 100), TestUtil.nextInt(random, 1, 1000)),
         new SimpleTextPostingsFormat(),
         new AssertingPostingsFormat(),
         new MemoryPostingsFormat(true, random.nextFloat()),
diff --git a/lucene/test-framework/src/java/org/apache/lucene/index/RandomIndexWriter.java b/lucene/test-framework/src/java/org/apache/lucene/index/RandomIndexWriter.java
index 1eced5f..4790fa1 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/index/RandomIndexWriter.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/index/RandomIndexWriter.java
@@ -25,14 +25,13 @@ import java.util.Random;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.codecs.Codec;
-import org.apache.lucene.index.IndexWriter; // javadoc
 import org.apache.lucene.search.Query;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.InfoStream;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.NullInfoStream;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.Version;
-import org.apache.lucene.util._TestUtil;
 
 /** Silly class that randomizes the indexing experience.  EG
  *  it may swap in a different merge policy/scheduler; may
@@ -88,7 +87,7 @@ public class RandomIndexWriter implements Closeable {
     // TODO: this should be solved in a different way; Random should not be shared (!).
     this.r = new Random(r.nextLong());
     w = mockIndexWriter(dir, c, r);
-    flushAt = _TestUtil.nextInt(r, 10, 1000);
+    flushAt = TestUtil.nextInt(r, 10, 1000);
     codec = w.getConfig().getCodec();
     if (LuceneTestCase.VERBOSE) {
       System.out.println("RIW dir=" + dir + " config=" + w.getConfig());
@@ -155,7 +154,7 @@ public class RandomIndexWriter implements Closeable {
         System.out.println("RIW.add/updateDocument: now doing a commit at docCount=" + docCount);
       }
       w.commit();
-      flushAt += _TestUtil.nextInt(r, (int) (flushAtFactor * 10), (int) (flushAtFactor * 1000));
+      flushAt += TestUtil.nextInt(r, (int) (flushAtFactor * 10), (int) (flushAtFactor * 1000));
       if (flushAtFactor < 2e6) {
         // gradually but exponentially increase time b/w flushes
         flushAtFactor *= 1.05;
@@ -283,7 +282,7 @@ public class RandomIndexWriter implements Closeable {
         w.forceMerge(1);
       } else {
         // partial forceMerge
-        final int limit = _TestUtil.nextInt(r, 1, segCount);
+        final int limit = TestUtil.nextInt(r, 1, segCount);
         if (LuceneTestCase.VERBOSE) {
           System.out.println("RIW: doRandomForceMerge(" + limit + ")");
         }
diff --git a/lucene/test-framework/src/java/org/apache/lucene/index/ThreadedIndexingAndSearchingTestCase.java b/lucene/test-framework/src/java/org/apache/lucene/index/ThreadedIndexingAndSearchingTestCase.java
index 2c5d792..739d45a 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/index/ThreadedIndexingAndSearchingTestCase.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/index/ThreadedIndexingAndSearchingTestCase.java
@@ -39,7 +39,6 @@ import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.search.TopDocs;
 import org.apache.lucene.store.BaseDirectoryWrapper;
 import org.apache.lucene.store.Directory;
-import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.FailOnNonBulkMergesInfoStream;
@@ -47,7 +46,7 @@ import org.apache.lucene.util.LineFileDocs;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.NamedThreadFactory;
 import org.apache.lucene.util.PrintStreamInfoStream;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 // TODO
 //   - mix in forceMerge, addIndexes
@@ -137,12 +136,12 @@ public abstract class ThreadedIndexingAndSearchingTestCase extends LuceneTestCas
                   if (VERBOSE) {
                     System.out.println(Thread.currentThread().getName() + ": now long sleep");
                   }
-                  Thread.sleep(_TestUtil.nextInt(random(), 50, 500));
+                  Thread.sleep(TestUtil.nextInt(random(), 50, 500));
                 }
 
                 // Rate limit ingest rate:
                 if (random().nextInt(7) == 5) {
-                  Thread.sleep(_TestUtil.nextInt(random(), 1, 10));
+                  Thread.sleep(TestUtil.nextInt(random(), 1, 10));
                   if (VERBOSE) {
                     System.out.println(Thread.currentThread().getName() + ": done sleep");
                   }
@@ -187,16 +186,16 @@ public abstract class ThreadedIndexingAndSearchingTestCase extends LuceneTestCas
 
                     allSubDocs.add(subDocs);
                     doc.add(packIDField);
-                    docsList.add(_TestUtil.cloneDocument(doc));
+                    docsList.add(TestUtil.cloneDocument(doc));
                     docIDs.add(doc.get("docid"));
 
-                    final int maxDocCount = _TestUtil.nextInt(random(), 1, 10);
+                    final int maxDocCount = TestUtil.nextInt(random(), 1, 10);
                     while(docsList.size() < maxDocCount) {
                       doc = docs.nextDoc();
                       if (doc == null) {
                         break;
                       }
-                      docsList.add(_TestUtil.cloneDocument(doc));
+                      docsList.add(TestUtil.cloneDocument(doc));
                       docIDs.add(doc.get("docid"));
                     }
                     addCount.addAndGet(docsList.size());
@@ -317,7 +316,7 @@ public abstract class ThreadedIndexingAndSearchingTestCase extends LuceneTestCas
   }
 
   protected void runSearchThreads(final long stopTimeMS) throws Exception {
-    final int numThreads = _TestUtil.nextInt(random(), 1, 5);
+    final int numThreads = TestUtil.nextInt(random(), 1, 5);
     final Thread[] searchThreads = new Thread[numThreads];
     final AtomicInteger totHits = new AtomicInteger();
 
@@ -436,7 +435,7 @@ public abstract class ThreadedIndexingAndSearchingTestCase extends LuceneTestCas
 
     Random random = new Random(random().nextLong());
     final LineFileDocs docs = new LineFileDocs(random, true);
-    final File tempDir = _TestUtil.getTempDir(testName);
+    final File tempDir = TestUtil.getTempDir(testName);
     dir = getDirectory(newMockFSDirectory(tempDir)); // some subclasses rely on this being MDW
     if (dir instanceof BaseDirectoryWrapper) {
       ((BaseDirectoryWrapper) dir).setCheckIndexOnClose(false); // don't double-checkIndex, we do it ourselves.
@@ -497,13 +496,13 @@ public abstract class ThreadedIndexingAndSearchingTestCase extends LuceneTestCas
         });
     }
     writer = new IndexWriter(dir, conf);
-    _TestUtil.reduceOpenFiles(writer);
+    TestUtil.reduceOpenFiles(writer);
 
     final ExecutorService es = random().nextBoolean() ? null : Executors.newCachedThreadPool(new NamedThreadFactory(testName));
 
     doAfterWriter(es);
 
-    final int NUM_INDEX_THREADS = _TestUtil.nextInt(random(), 2, 4);
+    final int NUM_INDEX_THREADS = TestUtil.nextInt(random(), 2, 4);
 
     final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;
 
@@ -642,9 +641,9 @@ public abstract class ThreadedIndexingAndSearchingTestCase extends LuceneTestCas
       es.awaitTermination(1, TimeUnit.SECONDS);
     }
 
-    _TestUtil.checkIndex(dir);
+    TestUtil.checkIndex(dir);
     dir.close();
-    _TestUtil.rmDir(tempDir);
+    TestUtil.rmDir(tempDir);
 
     if (VERBOSE) {
       System.out.println("TEST: done [" + (System.currentTimeMillis()-t0) + " ms]");
diff --git a/lucene/test-framework/src/java/org/apache/lucene/search/AssertingIndexSearcher.java b/lucene/test-framework/src/java/org/apache/lucene/search/AssertingIndexSearcher.java
index a5c30a7..eef42b0 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/search/AssertingIndexSearcher.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/search/AssertingIndexSearcher.java
@@ -25,7 +25,7 @@ import java.util.concurrent.ExecutorService;
 import org.apache.lucene.index.AtomicReaderContext;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexReaderContext;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Helper class that adds some extra checks to ensure correct
@@ -85,7 +85,7 @@ public class AssertingIndexSearcher extends IndexSearcher {
   protected Query wrapFilter(Query query, Filter filter) {
     if (random.nextBoolean())
       return super.wrapFilter(query, filter);
-    return (filter == null) ? query : new FilteredQuery(query, filter, _TestUtil.randomFilterStrategy(random));
+    return (filter == null) ? query : new FilteredQuery(query, filter, TestUtil.randomFilterStrategy(random));
   }
 
   @Override
diff --git a/lucene/test-framework/src/java/org/apache/lucene/search/SearchEquivalenceTestBase.java b/lucene/test-framework/src/java/org/apache/lucene/search/SearchEquivalenceTestBase.java
index 68d3392..7710720 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/search/SearchEquivalenceTestBase.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/search/SearchEquivalenceTestBase.java
@@ -31,9 +31,8 @@ import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.automaton.BasicAutomata;
 import org.apache.lucene.util.automaton.CharacterRunAutomaton;
 import org.junit.AfterClass;
@@ -125,7 +124,7 @@ public abstract class SearchEquivalenceTestBase extends LuceneTestCase {
    * returns random character (a-z)
    */
   static char randomChar() {
-    return (char) _TestUtil.nextInt(random(), 'a', 'z');
+    return (char) TestUtil.nextInt(random(), 'a', 'z');
   }
 
   /**
@@ -173,8 +172,8 @@ public abstract class SearchEquivalenceTestBase extends LuceneTestCase {
   protected void assertSubsetOf(Query q1, Query q2, Filter filter) throws Exception {
     // TRUNK ONLY: test both filter code paths
     if (filter != null && random().nextBoolean()) {
-      q1 = new FilteredQuery(q1, filter, _TestUtil.randomFilterStrategy(random()));
-      q2 = new FilteredQuery(q2, filter,  _TestUtil.randomFilterStrategy(random()));
+      q1 = new FilteredQuery(q1, filter, TestUtil.randomFilterStrategy(random()));
+      q2 = new FilteredQuery(q2, filter,  TestUtil.randomFilterStrategy(random()));
       filter = null;
     }
     
diff --git a/lucene/test-framework/src/java/org/apache/lucene/search/ShardSearchingTestBase.java b/lucene/test-framework/src/java/org/apache/lucene/search/ShardSearchingTestBase.java
index 4b21b6d..2b0a613 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/search/ShardSearchingTestBase.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/search/ShardSearchingTestBase.java
@@ -36,7 +36,7 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LineFileDocs;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.PrintStreamInfoStream;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 // TODO
 //   - doc blocks?  so we can test joins/grouping...
@@ -447,7 +447,7 @@ public abstract class ShardSearchingTestBase extends LuceneTestCase {
 
     public NodeState(Random random, int nodeID, int numNodes) throws IOException {
       myNodeID = nodeID;
-      dir = newFSDirectory(_TestUtil.getTempDir("ShardSearchingTestBase"));
+      dir = newFSDirectory(TestUtil.getTempDir("ShardSearchingTestBase"));
       // TODO: set warmer
       IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));
       iwc.setOpenMode(IndexWriterConfig.OpenMode.CREATE);
diff --git a/lucene/test-framework/src/java/org/apache/lucene/store/BaseDirectoryWrapper.java b/lucene/test-framework/src/java/org/apache/lucene/store/BaseDirectoryWrapper.java
index 2791f24..87286da 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/store/BaseDirectoryWrapper.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/store/BaseDirectoryWrapper.java
@@ -20,7 +20,7 @@ package org.apache.lucene.store;
 import java.io.IOException;
 
 import org.apache.lucene.index.DirectoryReader;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 /**
  * Calls check index on close.
@@ -42,7 +42,7 @@ public class BaseDirectoryWrapper extends FilterDirectory {
   public void close() throws IOException {
     isOpen = false;
     if (checkIndexOnClose && DirectoryReader.indexExists(this)) {
-      _TestUtil.checkIndex(this, crossCheckTermVectorsOnClose);
+      TestUtil.checkIndex(this, crossCheckTermVectorsOnClose);
     }
     super.close();
   }
diff --git a/lucene/test-framework/src/java/org/apache/lucene/store/MockDirectoryWrapper.java b/lucene/test-framework/src/java/org/apache/lucene/store/MockDirectoryWrapper.java
index 0ee2300..e8eb029 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/store/MockDirectoryWrapper.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/store/MockDirectoryWrapper.java
@@ -42,8 +42,8 @@ import org.apache.lucene.index.IndexWriterConfig;
 import org.apache.lucene.index.NoDeletionPolicy;
 import org.apache.lucene.index.SegmentInfos;
 import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.ThrottledIndexOutput;
-import org.apache.lucene.util._TestUtil;
 
 /**
  * This is a Directory Wrapper that adds methods
@@ -661,7 +661,7 @@ public class MockDirectoryWrapper extends BaseDirectoryWrapper {
         if (LuceneTestCase.VERBOSE) {
           System.out.println("\nNOTE: MockDirectoryWrapper: now run CheckIndex");
         } 
-        _TestUtil.checkIndex(this, getCrossCheckTermVectorsOnClose());
+        TestUtil.checkIndex(this, getCrossCheckTermVectorsOnClose());
 
         // TODO: factor this out / share w/ TestIW.assertNoUnreferencedFiles
         if (assertNoUnreferencedFilesOnClose) {
diff --git a/lucene/test-framework/src/java/org/apache/lucene/util/BaseDocIdSetTestCase.java b/lucene/test-framework/src/java/org/apache/lucene/util/BaseDocIdSetTestCase.java
index 1d5406a..a92d275 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/util/BaseDocIdSetTestCase.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/util/BaseDocIdSetTestCase.java
@@ -86,7 +86,7 @@ public abstract class BaseDocIdSetTestCase<T extends DocIdSet> extends LuceneTes
 
   /** Compare the content of the set against a {@link BitSet}. */
   public void testAgainstBitSet() throws IOException {
-    final int numBits = _TestUtil.nextInt(random(), 100, 1 << 20);
+    final int numBits = TestUtil.nextInt(random(), 100, 1 << 20);
     // test various random sets with various load factors
     for (float percentSet : new float[] {0f, 0.0001f, random().nextFloat() / 2, 0.9f, 1f}) {
       final BitSet set = randomSet(numBits, percentSet);
@@ -103,7 +103,7 @@ public abstract class BaseDocIdSetTestCase<T extends DocIdSet> extends LuceneTes
     copy = copyOf(set, numBits); // then random index
     assertEquals(numBits, set, copy);
     // test regular increments
-    for (int inc = 2; inc < 1000; inc += _TestUtil.nextInt(random(), 1, 100)) {
+    for (int inc = 2; inc < 1000; inc += TestUtil.nextInt(random(), 1, 100)) {
       set = new BitSet(numBits);
       for (int d = random().nextInt(10); d < numBits; d += inc) {
         set.set(d);
diff --git a/lucene/test-framework/src/java/org/apache/lucene/util/CloseableFile.java b/lucene/test-framework/src/java/org/apache/lucene/util/CloseableFile.java
index 7aedb3f..33737b1 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/util/CloseableFile.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/util/CloseableFile.java
@@ -37,7 +37,7 @@ final class CloseableFile implements Closeable {
     if (failureMarker.wasSuccessful()) {
       if (file.exists()) {
         try {
-          _TestUtil.rmDir(file);
+          TestUtil.rmDir(file);
         } catch (IOException e) {
           // Ignore the exception from rmDir.
         }
diff --git a/lucene/test-framework/src/java/org/apache/lucene/util/LuceneTestCase.java b/lucene/test-framework/src/java/org/apache/lucene/util/LuceneTestCase.java
index b37d461..2ea67e5 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/util/LuceneTestCase.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/util/LuceneTestCase.java
@@ -638,7 +638,7 @@ public abstract class LuceneTestCase extends Assert {
   public static int atLeast(Random random, int i) {
     int min = (TEST_NIGHTLY ? 2*i : i) * RANDOM_MULTIPLIER;
     int max = min+(min/2);
-    return _TestUtil.nextInt(random, min, max);
+    return TestUtil.nextInt(random, min, max);
   }
   
   public static int atLeast(int i) {
@@ -744,8 +744,8 @@ public abstract class LuceneTestCase extends Assert {
     if (r.nextBoolean()) {
       c.setMergeScheduler(new SerialMergeScheduler());
     } else if (rarely(r)) {
-      int maxThreadCount = _TestUtil.nextInt(random(), 1, 4);
-      int maxMergeCount = _TestUtil.nextInt(random(), maxThreadCount, maxThreadCount+4);
+      int maxThreadCount = TestUtil.nextInt(random(), 1, 4);
+      int maxMergeCount = TestUtil.nextInt(random(), maxThreadCount, maxThreadCount + 4);
       ConcurrentMergeScheduler cms = new ConcurrentMergeScheduler();
       cms.setMaxMergesAndThreads(maxMergeCount, maxThreadCount);
       c.setMergeScheduler(cms);
@@ -753,15 +753,15 @@ public abstract class LuceneTestCase extends Assert {
     if (r.nextBoolean()) {
       if (rarely(r)) {
         // crazy value
-        c.setMaxBufferedDocs(_TestUtil.nextInt(r, 2, 15));
+        c.setMaxBufferedDocs(TestUtil.nextInt(r, 2, 15));
       } else {
         // reasonable value
-        c.setMaxBufferedDocs(_TestUtil.nextInt(r, 16, 1000));
+        c.setMaxBufferedDocs(TestUtil.nextInt(r, 16, 1000));
       }
     }
     if (r.nextBoolean()) {
-      int maxNumThreadStates = rarely(r) ? _TestUtil.nextInt(r, 5, 20) // crazy value
-          : _TestUtil.nextInt(r, 1, 4); // reasonable value
+      int maxNumThreadStates = rarely(r) ? TestUtil.nextInt(r, 5, 20) // crazy value
+          : TestUtil.nextInt(r, 1, 4); // reasonable value
 
       Method setIndexerThreadPoolMethod = null;
       try {
@@ -844,9 +844,9 @@ public abstract class LuceneTestCase extends Assert {
     LogMergePolicy logmp = r.nextBoolean() ? new LogDocMergePolicy() : new LogByteSizeMergePolicy();
     logmp.setCalibrateSizeByDeletes(r.nextBoolean());
     if (rarely(r)) {
-      logmp.setMergeFactor(_TestUtil.nextInt(r, 2, 9));
+      logmp.setMergeFactor(TestUtil.nextInt(r, 2, 9));
     } else {
-      logmp.setMergeFactor(_TestUtil.nextInt(r, 10, 50));
+      logmp.setMergeFactor(TestUtil.nextInt(r, 10, 50));
     }
     configureRandom(r, logmp);
     return logmp;
@@ -869,11 +869,11 @@ public abstract class LuceneTestCase extends Assert {
   public static TieredMergePolicy newTieredMergePolicy(Random r) {
     TieredMergePolicy tmp = new TieredMergePolicy();
     if (rarely(r)) {
-      tmp.setMaxMergeAtOnce(_TestUtil.nextInt(r, 2, 9));
-      tmp.setMaxMergeAtOnceExplicit(_TestUtil.nextInt(r, 2, 9));
+      tmp.setMaxMergeAtOnce(TestUtil.nextInt(r, 2, 9));
+      tmp.setMaxMergeAtOnceExplicit(TestUtil.nextInt(r, 2, 9));
     } else {
-      tmp.setMaxMergeAtOnce(_TestUtil.nextInt(r, 10, 50));
-      tmp.setMaxMergeAtOnceExplicit(_TestUtil.nextInt(r, 10, 50));
+      tmp.setMaxMergeAtOnce(TestUtil.nextInt(r, 10, 50));
+      tmp.setMaxMergeAtOnceExplicit(TestUtil.nextInt(r, 10, 50));
     }
     if (rarely(r)) {
       tmp.setMaxMergedSegmentMB(0.2 + r.nextDouble() * 2.0);
@@ -883,9 +883,9 @@ public abstract class LuceneTestCase extends Assert {
     tmp.setFloorSegmentMB(0.2 + r.nextDouble() * 2.0);
     tmp.setForceMergeDeletesPctAllowed(0.0 + r.nextDouble() * 30.0);
     if (rarely(r)) {
-      tmp.setSegmentsPerTier(_TestUtil.nextInt(r, 2, 20));
+      tmp.setSegmentsPerTier(TestUtil.nextInt(r, 2, 20));
     } else {
-      tmp.setSegmentsPerTier(_TestUtil.nextInt(r, 10, 50));
+      tmp.setSegmentsPerTier(TestUtil.nextInt(r, 10, 50));
     }
     configureRandom(r, tmp);
     tmp.setReclaimDeletesWeight(r.nextDouble()*4);
@@ -1160,7 +1160,7 @@ public abstract class LuceneTestCase extends Assert {
       final Class<? extends Directory> clazz = CommandLineUtil.loadDirectoryClass(clazzName);
       // If it is a FSDirectory type, try its ctor(File)
       if (FSDirectory.class.isAssignableFrom(clazz)) {
-        final File dir = _TestUtil.getTempDir("index");
+        final File dir = TestUtil.getTempDir("index");
         dir.mkdirs(); // ensure it's created so we 'have' it.
         return newFSDirectoryImpl(clazz.asSubclass(FSDirectory.class), dir);
       }
@@ -1256,7 +1256,7 @@ public abstract class LuceneTestCase extends Assert {
     } else if (oldContext.mergeInfo != null) {
       // Always return at least the estimatedMergeBytes of
       // the incoming IOContext:
-      return new IOContext(new MergeInfo(randomNumDocs, Math.max(oldContext.mergeInfo.estimatedMergeBytes, size), random.nextBoolean(), _TestUtil.nextInt(random, 1, 100)));
+      return new IOContext(new MergeInfo(randomNumDocs, Math.max(oldContext.mergeInfo.estimatedMergeBytes, size), random.nextBoolean(), TestUtil.nextInt(random, 1, 100)));
     } else {
       // Make a totally random IOContext:
       final IOContext context;
@@ -1312,7 +1312,7 @@ public abstract class LuceneTestCase extends Assert {
         // TODO: not useful to check DirectoryReader (redundant with checkindex)
         // but maybe sometimes run this on the other crazy readers maybeWrapReader creates?
         try {
-          _TestUtil.checkReader(r);
+          TestUtil.checkReader(r);
         } catch (IOException e) {
           throw new AssertionError(e);
         }
@@ -1326,7 +1326,7 @@ public abstract class LuceneTestCase extends Assert {
       if (random.nextBoolean()) {
         ex = null;
       } else {
-        threads = _TestUtil.nextInt(random, 1, 8);
+        threads = TestUtil.nextInt(random, 1, 8);
         ex = new ThreadPoolExecutor(threads, threads, 0L, TimeUnit.MILLISECONDS,
             new LinkedBlockingQueue<Runnable>(),
             new NamedThreadFactory("LuceneTestCase"));
@@ -1340,7 +1340,7 @@ public abstract class LuceneTestCase extends Assert {
        r.addReaderClosedListener(new ReaderClosedListener() {
          @Override
          public void onClose(IndexReader reader) {
-           _TestUtil.shutdownExecutorService(ex);
+           TestUtil.shutdownExecutorService(ex);
          }
        });
       }
@@ -1763,7 +1763,7 @@ public abstract class LuceneTestCase extends Assert {
               tests.add(new BytesRef(new byte[] {(byte) 0xFF, (byte) 0xFF})); // past the last term
               break;
             case 2:
-              tests.add(new BytesRef(_TestUtil.randomSimpleString(random()))); // random term
+              tests.add(new BytesRef(TestUtil.randomSimpleString(random()))); // random term
               break;
             default:
               throw new AssertionError();
diff --git a/lucene/test-framework/src/java/org/apache/lucene/util/TestUtil.java b/lucene/test-framework/src/java/org/apache/lucene/util/TestUtil.java
new file mode 100644
index 0000000..0f4337a
--- /dev/null
+++ b/lucene/test-framework/src/java/org/apache/lucene/util/TestUtil.java
@@ -0,0 +1,1174 @@
+package org.apache.lucene.util;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.BufferedOutputStream;
+import java.io.ByteArrayOutputStream;
+import java.io.File;
+import java.io.FileOutputStream;
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.OutputStream;
+import java.io.PrintStream;
+import java.math.BigDecimal;
+import java.math.BigInteger;
+import java.nio.CharBuffer;
+import java.util.Arrays;
+import java.util.Enumeration;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.Random;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.TimeUnit;
+import java.util.regex.Pattern;
+import java.util.regex.PatternSyntaxException;
+import java.util.zip.ZipEntry;
+import java.util.zip.ZipFile;
+
+import org.apache.lucene.codecs.Codec;
+import org.apache.lucene.codecs.DocValuesFormat;
+import org.apache.lucene.codecs.PostingsFormat;
+import org.apache.lucene.codecs.lucene46.Lucene46Codec;
+import org.apache.lucene.codecs.perfield.PerFieldDocValuesFormat;
+import org.apache.lucene.codecs.perfield.PerFieldPostingsFormat;
+import org.apache.lucene.document.BinaryDocValuesField;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.DoubleField;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.document.FieldType.NumericType;
+import org.apache.lucene.document.FloatField;
+import org.apache.lucene.document.IntField;
+import org.apache.lucene.document.LongField;
+import org.apache.lucene.document.NumericDocValuesField;
+import org.apache.lucene.document.SortedDocValuesField;
+import org.apache.lucene.index.AtomicReader;
+import org.apache.lucene.index.AtomicReaderContext;
+import org.apache.lucene.index.CheckIndex;
+import org.apache.lucene.index.CheckIndex.Status.DocValuesStatus;
+import org.apache.lucene.index.CheckIndex.Status.FieldNormStatus;
+import org.apache.lucene.index.CheckIndex.Status.StoredFieldStatus;
+import org.apache.lucene.index.CheckIndex.Status.TermIndexStatus;
+import org.apache.lucene.index.CheckIndex.Status.TermVectorStatus;
+import org.apache.lucene.index.ConcurrentMergeScheduler;
+import org.apache.lucene.index.DocsAndPositionsEnum;
+import org.apache.lucene.index.DocsEnum;
+import org.apache.lucene.index.FieldInfo.DocValuesType;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.IndexWriter;
+import org.apache.lucene.index.IndexableField;
+import org.apache.lucene.index.LogMergePolicy;
+import org.apache.lucene.index.MergePolicy;
+import org.apache.lucene.index.MergeScheduler;
+import org.apache.lucene.index.MultiFields;
+import org.apache.lucene.index.Terms;
+import org.apache.lucene.index.TermsEnum;
+import org.apache.lucene.index.TieredMergePolicy;
+import org.apache.lucene.search.FieldDoc;
+import org.apache.lucene.search.FilteredQuery;
+import org.apache.lucene.search.FilteredQuery.FilterStrategy;
+import org.apache.lucene.search.ScoreDoc;
+import org.apache.lucene.search.TopDocs;
+import org.apache.lucene.store.Directory;
+import org.junit.Assert;
+
+import com.carrotsearch.randomizedtesting.RandomizedContext;
+import com.carrotsearch.randomizedtesting.generators.RandomInts;
+import com.carrotsearch.randomizedtesting.generators.RandomPicks;
+
+/**
+ * General utility methods for Lucene unit tests. 
+ */
+public final class TestUtil {
+  private TestUtil() {
+    //
+  }
+
+  // the max number of retries we're going to do in getTempDir
+  private static final int GET_TEMP_DIR_RETRY_THRESHOLD = 1000;
+  
+  /**
+   * Returns a temp directory, based on the given description. Creates the
+   * directory.
+   */
+  public static File getTempDir(String desc) {
+    if (desc.length() < 3) {
+      throw new IllegalArgumentException("description must be at least 3 characters");
+    }
+    // always pull a long from master random. that way, the randomness of the test
+    // is not affected by whether it initialized the counter (in genTempFile) or not.
+    // note that the Random used by genTempFile is *not* the master Random, and therefore
+    // does not affect the randomness of the test.
+    final Random random = new Random(RandomizedContext.current().getRandom().nextLong());
+    int attempt = 0;
+    File f;
+    do {
+      f = genTempFile(random, desc, "tmp", LuceneTestCase.TEMP_DIR);
+    } while (!f.mkdir() && (attempt++) < GET_TEMP_DIR_RETRY_THRESHOLD);
+    
+    if (attempt > GET_TEMP_DIR_RETRY_THRESHOLD) {
+      throw new RuntimeException(
+          "failed to get a temporary dir too many times. check your temp directory and consider manually cleaning it.");
+    }
+    
+    LuceneTestCase.closeAfterSuite(new CloseableFile(f, LuceneTestCase.suiteFailureMarker));
+    return f;
+  }
+
+  /**
+   * Deletes a directory and everything underneath it.
+   */
+  public static void rmDir(File dir) throws IOException {
+    if (dir.exists()) {
+      if (dir.isFile() && !dir.delete()) {
+        throw new IOException("could not delete " + dir);
+      }
+      for (File f : dir.listFiles()) {
+        if (f.isDirectory()) {
+          rmDir(f);
+        } else {
+          if (!f.delete()) {
+            throw new IOException("could not delete " + f);
+          }
+        }
+      }
+      if (!dir.delete()) {
+        throw new IOException("could not delete " + dir);
+      }
+    }
+  }
+
+  /** 
+   * Convenience method: Unzip zipName + ".zip" under destDir, removing destDir first 
+   */
+  public static void unzip(File zipName, File destDir) throws IOException {
+    
+    ZipFile zipFile = new ZipFile(zipName);
+    
+    Enumeration<? extends ZipEntry> entries = zipFile.entries();
+    
+    rmDir(destDir);
+
+    destDir.mkdir();
+    LuceneTestCase.closeAfterSuite(new CloseableFile(destDir, LuceneTestCase.suiteFailureMarker));
+
+    while (entries.hasMoreElements()) {
+      ZipEntry entry = entries.nextElement();
+      
+      InputStream in = zipFile.getInputStream(entry);
+      File targetFile = new File(destDir, entry.getName());
+      if (entry.isDirectory()) {
+        // allow unzipping with directory structure
+        targetFile.mkdirs();
+      } else {
+        if (targetFile.getParentFile()!=null) {
+          // be on the safe side: do not rely on that directories are always extracted
+          // before their children (although this makes sense, but is it guaranteed?)
+          targetFile.getParentFile().mkdirs();   
+        }
+        OutputStream out = new BufferedOutputStream(new FileOutputStream(targetFile));
+        
+        byte[] buffer = new byte[8192];
+        int len;
+        while((len = in.read(buffer)) >= 0) {
+          out.write(buffer, 0, len);
+        }
+        
+        in.close();
+        out.close();
+      }
+    }
+    
+    zipFile.close();
+  }
+  
+  public static void syncConcurrentMerges(IndexWriter writer) {
+    syncConcurrentMerges(writer.getConfig().getMergeScheduler());
+  }
+
+  public static void syncConcurrentMerges(MergeScheduler ms) {
+    if (ms instanceof ConcurrentMergeScheduler)
+      ((ConcurrentMergeScheduler) ms).sync();
+  }
+
+  /** This runs the CheckIndex tool on the index in.  If any
+   *  issues are hit, a RuntimeException is thrown; else,
+   *  true is returned. */
+  public static CheckIndex.Status checkIndex(Directory dir) throws IOException {
+    return checkIndex(dir, true);
+  }
+
+  public static CheckIndex.Status checkIndex(Directory dir, boolean crossCheckTermVectors) throws IOException {
+    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);
+    CheckIndex checker = new CheckIndex(dir);
+    checker.setCrossCheckTermVectors(crossCheckTermVectors);
+    checker.setInfoStream(new PrintStream(bos, false, "UTF-8"), false);
+    CheckIndex.Status indexStatus = checker.checkIndex(null);
+    if (indexStatus == null || indexStatus.clean == false) {
+      System.out.println("CheckIndex failed");
+      System.out.println(bos.toString("UTF-8"));
+      throw new RuntimeException("CheckIndex failed");
+    } else {
+      if (LuceneTestCase.INFOSTREAM) {
+        System.out.println(bos.toString("UTF-8"));
+      }
+      return indexStatus;
+    }
+  }
+  
+  /** This runs the CheckIndex tool on the Reader.  If any
+   *  issues are hit, a RuntimeException is thrown */
+  public static void checkReader(IndexReader reader) throws IOException {
+    for (AtomicReaderContext context : reader.leaves()) {
+      checkReader(context.reader(), true);
+    }
+  }
+  
+  public static void checkReader(AtomicReader reader, boolean crossCheckTermVectors) throws IOException {
+    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);
+    PrintStream infoStream = new PrintStream(bos, false, "UTF-8");
+
+    FieldNormStatus fieldNormStatus = CheckIndex.testFieldNorms(reader, infoStream);
+    TermIndexStatus termIndexStatus = CheckIndex.testPostings(reader, infoStream);
+    StoredFieldStatus storedFieldStatus = CheckIndex.testStoredFields(reader, infoStream);
+    TermVectorStatus termVectorStatus = CheckIndex.testTermVectors(reader, infoStream, false, crossCheckTermVectors);
+    DocValuesStatus docValuesStatus = CheckIndex.testDocValues(reader, infoStream);
+    
+    if (fieldNormStatus.error != null || 
+      termIndexStatus.error != null ||
+      storedFieldStatus.error != null ||
+      termVectorStatus.error != null ||
+      docValuesStatus.error != null) {
+      System.out.println("CheckReader failed");
+      System.out.println(bos.toString("UTF-8"));
+      throw new RuntimeException("CheckReader failed");
+    } else {
+      if (LuceneTestCase.INFOSTREAM) {
+        System.out.println(bos.toString("UTF-8"));
+      }
+    }
+  }
+
+  /** start and end are BOTH inclusive */
+  public static int nextInt(Random r, int start, int end) {
+    return RandomInts.randomIntBetween(r, start, end);
+  }
+
+  /** start and end are BOTH inclusive */
+  public static long nextLong(Random r, long start, long end) {
+    assert end >= start;
+    final BigInteger range = BigInteger.valueOf(end).add(BigInteger.valueOf(1)).subtract(BigInteger.valueOf(start));
+    if (range.compareTo(BigInteger.valueOf(Integer.MAX_VALUE)) <= 0) {
+      return start + r.nextInt(range.intValue());
+    } else {
+      // probably not evenly distributed when range is large, but OK for tests
+      final BigInteger augend = new BigDecimal(range).multiply(new BigDecimal(r.nextDouble())).toBigInteger();
+      final long result = BigInteger.valueOf(start).add(augend).longValue();
+      assert result >= start;
+      assert result <= end;
+      return result;
+    }
+  }
+
+  public static String randomSimpleString(Random r, int maxLength) {
+    return randomSimpleString(r, 0, maxLength);
+  }
+  
+  public static String randomSimpleString(Random r, int minLength, int maxLength) {
+    final int end = nextInt(r, minLength, maxLength);
+    if (end == 0) {
+      // allow 0 length
+      return "";
+    }
+    final char[] buffer = new char[end];
+    for (int i = 0; i < end; i++) {
+      buffer[i] = (char) TestUtil.nextInt(r, 'a', 'z');
+    }
+    return new String(buffer, 0, end);
+  }
+
+  public static String randomSimpleStringRange(Random r, char minChar, char maxChar, int maxLength) {
+    final int end = nextInt(r, 0, maxLength);
+    if (end == 0) {
+      // allow 0 length
+      return "";
+    }
+    final char[] buffer = new char[end];
+    for (int i = 0; i < end; i++) {
+      buffer[i] = (char) TestUtil.nextInt(r, minChar, maxChar);
+    }
+    return new String(buffer, 0, end);
+  }
+
+  public static String randomSimpleString(Random r) {
+    return randomSimpleString(r, 0, 10);
+  }
+
+  /** Returns random string, including full unicode range. */
+  public static String randomUnicodeString(Random r) {
+    return randomUnicodeString(r, 20);
+  }
+
+  /**
+   * Returns a random string up to a certain length.
+   */
+  public static String randomUnicodeString(Random r, int maxLength) {
+    final int end = nextInt(r, 0, maxLength);
+    if (end == 0) {
+      // allow 0 length
+      return "";
+    }
+    final char[] buffer = new char[end];
+    randomFixedLengthUnicodeString(r, buffer, 0, buffer.length);
+    return new String(buffer, 0, end);
+  }
+
+  /**
+   * Fills provided char[] with valid random unicode code
+   * unit sequence.
+   */
+  public static void randomFixedLengthUnicodeString(Random random, char[] chars, int offset, int length) {
+    int i = offset;
+    final int end = offset + length;
+    while(i < end) {
+      final int t = random.nextInt(5);
+      if (0 == t && i < length - 1) {
+        // Make a surrogate pair
+        // High surrogate
+        chars[i++] = (char) nextInt(random, 0xd800, 0xdbff);
+        // Low surrogate
+        chars[i++] = (char) nextInt(random, 0xdc00, 0xdfff);
+      } else if (t <= 1) {
+        chars[i++] = (char) random.nextInt(0x80);
+      } else if (2 == t) {
+        chars[i++] = (char) nextInt(random, 0x80, 0x7ff);
+      } else if (3 == t) {
+        chars[i++] = (char) nextInt(random, 0x800, 0xd7ff);
+      } else if (4 == t) {
+        chars[i++] = (char) nextInt(random, 0xe000, 0xffff);
+      }
+    }
+  }
+  
+  /**
+   * Returns a String thats "regexpish" (contains lots of operators typically found in regular expressions)
+   * If you call this enough times, you might get a valid regex!
+   */
+  public static String randomRegexpishString(Random r) {
+    return randomRegexpishString(r, 20);
+  }
+
+  /**
+   * Maximum recursion bound for '+' and '*' replacements in
+   * {@link #randomRegexpishString(Random, int)}.
+   */
+  private final static int maxRecursionBound = 5;
+
+  /**
+   * Operators for {@link #randomRegexpishString(Random, int)}.
+   */
+  private final static List<String> ops = Arrays.asList(
+      ".", "?", 
+      "{0," + maxRecursionBound + "}",  // bounded replacement for '*'
+      "{1," + maxRecursionBound + "}",  // bounded replacement for '+'
+      "(",
+      ")",
+      "-",
+      "[",
+      "]",
+      "|"
+  );
+
+  /**
+   * Returns a String thats "regexpish" (contains lots of operators typically found in regular expressions)
+   * If you call this enough times, you might get a valid regex!
+   * 
+   * <P>Note: to avoid practically endless backtracking patterns we replace asterisk and plus
+   * operators with bounded repetitions. See LUCENE-4111 for more info.
+   * 
+   * @param maxLength A hint about maximum length of the regexpish string. It may be exceeded by a few characters.
+   */
+  public static String randomRegexpishString(Random r, int maxLength) {
+    final StringBuilder regexp = new StringBuilder(maxLength);
+    for (int i = nextInt(r, 0, maxLength); i > 0; i--) {
+      if (r.nextBoolean()) {
+        regexp.append((char) RandomInts.randomIntBetween(r, 'a', 'z'));
+      } else {
+        regexp.append(RandomPicks.randomFrom(r, ops));
+      }
+    }
+    return regexp.toString();
+  }
+
+  private static final String[] HTML_CHAR_ENTITIES = {
+      "AElig", "Aacute", "Acirc", "Agrave", "Alpha", "AMP", "Aring", "Atilde",
+      "Auml", "Beta", "COPY", "Ccedil", "Chi", "Dagger", "Delta", "ETH",
+      "Eacute", "Ecirc", "Egrave", "Epsilon", "Eta", "Euml", "Gamma", "GT",
+      "Iacute", "Icirc", "Igrave", "Iota", "Iuml", "Kappa", "Lambda", "LT",
+      "Mu", "Ntilde", "Nu", "OElig", "Oacute", "Ocirc", "Ograve", "Omega",
+      "Omicron", "Oslash", "Otilde", "Ouml", "Phi", "Pi", "Prime", "Psi",
+      "QUOT", "REG", "Rho", "Scaron", "Sigma", "THORN", "Tau", "Theta",
+      "Uacute", "Ucirc", "Ugrave", "Upsilon", "Uuml", "Xi", "Yacute", "Yuml",
+      "Zeta", "aacute", "acirc", "acute", "aelig", "agrave", "alefsym",
+      "alpha", "amp", "and", "ang", "apos", "aring", "asymp", "atilde",
+      "auml", "bdquo", "beta", "brvbar", "bull", "cap", "ccedil", "cedil",
+      "cent", "chi", "circ", "clubs", "cong", "copy", "crarr", "cup",
+      "curren", "dArr", "dagger", "darr", "deg", "delta", "diams", "divide",
+      "eacute", "ecirc", "egrave", "empty", "emsp", "ensp", "epsilon",
+      "equiv", "eta", "eth", "euml", "euro", "exist", "fnof", "forall",
+      "frac12", "frac14", "frac34", "frasl", "gamma", "ge", "gt", "hArr",
+      "harr", "hearts", "hellip", "iacute", "icirc", "iexcl", "igrave",
+      "image", "infin", "int", "iota", "iquest", "isin", "iuml", "kappa",
+      "lArr", "lambda", "lang", "laquo", "larr", "lceil", "ldquo", "le",
+      "lfloor", "lowast", "loz", "lrm", "lsaquo", "lsquo", "lt", "macr",
+      "mdash", "micro", "middot", "minus", "mu", "nabla", "nbsp", "ndash",
+      "ne", "ni", "not", "notin", "nsub", "ntilde", "nu", "oacute", "ocirc",
+      "oelig", "ograve", "oline", "omega", "omicron", "oplus", "or", "ordf",
+      "ordm", "oslash", "otilde", "otimes", "ouml", "para", "part", "permil",
+      "perp", "phi", "pi", "piv", "plusmn", "pound", "prime", "prod", "prop",
+      "psi", "quot", "rArr", "radic", "rang", "raquo", "rarr", "rceil",
+      "rdquo", "real", "reg", "rfloor", "rho", "rlm", "rsaquo", "rsquo",
+      "sbquo", "scaron", "sdot", "sect", "shy", "sigma", "sigmaf", "sim",
+      "spades", "sub", "sube", "sum", "sup", "sup1", "sup2", "sup3", "supe",
+      "szlig", "tau", "there4", "theta", "thetasym", "thinsp", "thorn",
+      "tilde", "times", "trade", "uArr", "uacute", "uarr", "ucirc", "ugrave",
+      "uml", "upsih", "upsilon", "uuml", "weierp", "xi", "yacute", "yen",
+      "yuml", "zeta", "zwj", "zwnj"
+  };
+  
+  public static String randomHtmlishString(Random random, int numElements) {
+    final int end = nextInt(random, 0, numElements);
+    if (end == 0) {
+      // allow 0 length
+      return "";
+    }
+    StringBuilder sb = new StringBuilder();
+    for (int i = 0; i < end; i++) {
+      int val = random.nextInt(25);
+      switch(val) {
+        case 0: sb.append("<p>"); break;
+        case 1: {
+          sb.append("<");
+          sb.append("    ".substring(nextInt(random, 0, 4)));
+          sb.append(randomSimpleString(random));
+          for (int j = 0 ; j < nextInt(random, 0, 10) ; ++j) {
+            sb.append(' ');
+            sb.append(randomSimpleString(random));
+            sb.append(" ".substring(nextInt(random, 0, 1)));
+            sb.append('=');
+            sb.append(" ".substring(nextInt(random, 0, 1)));
+            sb.append("\"".substring(nextInt(random, 0, 1)));
+            sb.append(randomSimpleString(random));
+            sb.append("\"".substring(nextInt(random, 0, 1)));
+          }
+          sb.append("    ".substring(nextInt(random, 0, 4)));
+          sb.append("/".substring(nextInt(random, 0, 1)));
+          sb.append(">".substring(nextInt(random, 0, 1)));
+          break;
+        }
+        case 2: {
+          sb.append("</");
+          sb.append("    ".substring(nextInt(random, 0, 4)));
+          sb.append(randomSimpleString(random));
+          sb.append("    ".substring(nextInt(random, 0, 4)));
+          sb.append(">".substring(nextInt(random, 0, 1)));
+          break;
+        }
+        case 3: sb.append(">"); break;
+        case 4: sb.append("</p>"); break;
+        case 5: sb.append("<!--"); break;
+        case 6: sb.append("<!--#"); break;
+        case 7: sb.append("<script><!-- f('"); break;
+        case 8: sb.append("</script>"); break;
+        case 9: sb.append("<?"); break;
+        case 10: sb.append("?>"); break;
+        case 11: sb.append("\""); break;
+        case 12: sb.append("\\\""); break;
+        case 13: sb.append("'"); break;
+        case 14: sb.append("\\'"); break;
+        case 15: sb.append("-->"); break;
+        case 16: {
+          sb.append("&");
+          switch(nextInt(random, 0, 2)) {
+            case 0: sb.append(randomSimpleString(random)); break;
+            case 1: sb.append(HTML_CHAR_ENTITIES[random.nextInt(HTML_CHAR_ENTITIES.length)]); break;
+          }
+          sb.append(";".substring(nextInt(random, 0, 1)));
+          break;
+        }
+        case 17: {
+          sb.append("&#");
+          if (0 == nextInt(random, 0, 1)) {
+            sb.append(nextInt(random, 0, Integer.MAX_VALUE - 1));
+            sb.append(";".substring(nextInt(random, 0, 1)));
+          }
+          break;
+        } 
+        case 18: {
+          sb.append("&#x");
+          if (0 == nextInt(random, 0, 1)) {
+            sb.append(Integer.toString(nextInt(random, 0, Integer.MAX_VALUE - 1), 16));
+            sb.append(";".substring(nextInt(random, 0, 1)));
+          }
+          break;
+        }
+          
+        case 19: sb.append(";"); break;
+        case 20: sb.append(nextInt(random, 0, Integer.MAX_VALUE - 1)); break;
+        case 21: sb.append("\n"); break;
+        case 22: sb.append("          ".substring(nextInt(random, 0, 10))); break;
+        case 23: {
+          sb.append("<");
+          if (0 == nextInt(random, 0, 3)) {
+            sb.append("          ".substring(nextInt(random, 1, 10)));
+          }
+          if (0 == nextInt(random, 0, 1)) {
+            sb.append("/");
+            if (0 == nextInt(random, 0, 3)) {
+              sb.append("          ".substring(nextInt(random, 1, 10)));
+            }
+          }
+          switch (nextInt(random, 0, 3)) {
+            case 0: sb.append(randomlyRecaseCodePoints(random, "script")); break;
+            case 1: sb.append(randomlyRecaseCodePoints(random, "style")); break;
+            case 2: sb.append(randomlyRecaseCodePoints(random, "br")); break;
+            // default: append nothing
+          }
+          sb.append(">".substring(nextInt(random, 0, 1)));
+          break;
+        }
+        default: sb.append(randomSimpleString(random));
+      }
+    }
+    return sb.toString();
+  }
+
+  /**
+   * Randomly upcases, downcases, or leaves intact each code point in the given string
+   */
+  public static String randomlyRecaseCodePoints(Random random, String str) {
+    StringBuilder builder = new StringBuilder();
+    int pos = 0;
+    while (pos < str.length()) {
+      int codePoint = str.codePointAt(pos);
+      pos += Character.charCount(codePoint);
+      switch (nextInt(random, 0, 2)) {
+        case 0: builder.appendCodePoint(Character.toUpperCase(codePoint)); break;
+        case 1: builder.appendCodePoint(Character.toLowerCase(codePoint)); break;
+        case 2: builder.appendCodePoint(codePoint); // leave intact
+      }
+    }
+    return builder.toString();
+  }
+
+  private static final int[] blockStarts = {
+    0x0000, 0x0080, 0x0100, 0x0180, 0x0250, 0x02B0, 0x0300, 0x0370, 0x0400, 
+    0x0500, 0x0530, 0x0590, 0x0600, 0x0700, 0x0750, 0x0780, 0x07C0, 0x0800, 
+    0x0900, 0x0980, 0x0A00, 0x0A80, 0x0B00, 0x0B80, 0x0C00, 0x0C80, 0x0D00, 
+    0x0D80, 0x0E00, 0x0E80, 0x0F00, 0x1000, 0x10A0, 0x1100, 0x1200, 0x1380, 
+    0x13A0, 0x1400, 0x1680, 0x16A0, 0x1700, 0x1720, 0x1740, 0x1760, 0x1780, 
+    0x1800, 0x18B0, 0x1900, 0x1950, 0x1980, 0x19E0, 0x1A00, 0x1A20, 0x1B00, 
+    0x1B80, 0x1C00, 0x1C50, 0x1CD0, 0x1D00, 0x1D80, 0x1DC0, 0x1E00, 0x1F00, 
+    0x2000, 0x2070, 0x20A0, 0x20D0, 0x2100, 0x2150, 0x2190, 0x2200, 0x2300, 
+    0x2400, 0x2440, 0x2460, 0x2500, 0x2580, 0x25A0, 0x2600, 0x2700, 0x27C0, 
+    0x27F0, 0x2800, 0x2900, 0x2980, 0x2A00, 0x2B00, 0x2C00, 0x2C60, 0x2C80, 
+    0x2D00, 0x2D30, 0x2D80, 0x2DE0, 0x2E00, 0x2E80, 0x2F00, 0x2FF0, 0x3000, 
+    0x3040, 0x30A0, 0x3100, 0x3130, 0x3190, 0x31A0, 0x31C0, 0x31F0, 0x3200, 
+    0x3300, 0x3400, 0x4DC0, 0x4E00, 0xA000, 0xA490, 0xA4D0, 0xA500, 0xA640, 
+    0xA6A0, 0xA700, 0xA720, 0xA800, 0xA830, 0xA840, 0xA880, 0xA8E0, 0xA900, 
+    0xA930, 0xA960, 0xA980, 0xAA00, 0xAA60, 0xAA80, 0xABC0, 0xAC00, 0xD7B0, 
+    0xE000, 0xF900, 0xFB00, 0xFB50, 0xFE00, 0xFE10, 
+    0xFE20, 0xFE30, 0xFE50, 0xFE70, 0xFF00, 0xFFF0, 
+    0x10000, 0x10080, 0x10100, 0x10140, 0x10190, 0x101D0, 0x10280, 0x102A0, 
+    0x10300, 0x10330, 0x10380, 0x103A0, 0x10400, 0x10450, 0x10480, 0x10800, 
+    0x10840, 0x10900, 0x10920, 0x10A00, 0x10A60, 0x10B00, 0x10B40, 0x10B60, 
+    0x10C00, 0x10E60, 0x11080, 0x12000, 0x12400, 0x13000, 0x1D000, 0x1D100, 
+    0x1D200, 0x1D300, 0x1D360, 0x1D400, 0x1F000, 0x1F030, 0x1F100, 0x1F200, 
+    0x20000, 0x2A700, 0x2F800, 0xE0000, 0xE0100, 0xF0000, 0x100000
+  };
+  
+  private static final int[] blockEnds = {
+    0x007F, 0x00FF, 0x017F, 0x024F, 0x02AF, 0x02FF, 0x036F, 0x03FF, 0x04FF, 
+    0x052F, 0x058F, 0x05FF, 0x06FF, 0x074F, 0x077F, 0x07BF, 0x07FF, 0x083F, 
+    0x097F, 0x09FF, 0x0A7F, 0x0AFF, 0x0B7F, 0x0BFF, 0x0C7F, 0x0CFF, 0x0D7F, 
+    0x0DFF, 0x0E7F, 0x0EFF, 0x0FFF, 0x109F, 0x10FF, 0x11FF, 0x137F, 0x139F, 
+    0x13FF, 0x167F, 0x169F, 0x16FF, 0x171F, 0x173F, 0x175F, 0x177F, 0x17FF, 
+    0x18AF, 0x18FF, 0x194F, 0x197F, 0x19DF, 0x19FF, 0x1A1F, 0x1AAF, 0x1B7F, 
+    0x1BBF, 0x1C4F, 0x1C7F, 0x1CFF, 0x1D7F, 0x1DBF, 0x1DFF, 0x1EFF, 0x1FFF, 
+    0x206F, 0x209F, 0x20CF, 0x20FF, 0x214F, 0x218F, 0x21FF, 0x22FF, 0x23FF, 
+    0x243F, 0x245F, 0x24FF, 0x257F, 0x259F, 0x25FF, 0x26FF, 0x27BF, 0x27EF, 
+    0x27FF, 0x28FF, 0x297F, 0x29FF, 0x2AFF, 0x2BFF, 0x2C5F, 0x2C7F, 0x2CFF, 
+    0x2D2F, 0x2D7F, 0x2DDF, 0x2DFF, 0x2E7F, 0x2EFF, 0x2FDF, 0x2FFF, 0x303F, 
+    0x309F, 0x30FF, 0x312F, 0x318F, 0x319F, 0x31BF, 0x31EF, 0x31FF, 0x32FF, 
+    0x33FF, 0x4DBF, 0x4DFF, 0x9FFF, 0xA48F, 0xA4CF, 0xA4FF, 0xA63F, 0xA69F, 
+    0xA6FF, 0xA71F, 0xA7FF, 0xA82F, 0xA83F, 0xA87F, 0xA8DF, 0xA8FF, 0xA92F, 
+    0xA95F, 0xA97F, 0xA9DF, 0xAA5F, 0xAA7F, 0xAADF, 0xABFF, 0xD7AF, 0xD7FF, 
+    0xF8FF, 0xFAFF, 0xFB4F, 0xFDFF, 0xFE0F, 0xFE1F, 
+    0xFE2F, 0xFE4F, 0xFE6F, 0xFEFF, 0xFFEF, 0xFFFF, 
+    0x1007F, 0x100FF, 0x1013F, 0x1018F, 0x101CF, 0x101FF, 0x1029F, 0x102DF, 
+    0x1032F, 0x1034F, 0x1039F, 0x103DF, 0x1044F, 0x1047F, 0x104AF, 0x1083F, 
+    0x1085F, 0x1091F, 0x1093F, 0x10A5F, 0x10A7F, 0x10B3F, 0x10B5F, 0x10B7F, 
+    0x10C4F, 0x10E7F, 0x110CF, 0x123FF, 0x1247F, 0x1342F, 0x1D0FF, 0x1D1FF, 
+    0x1D24F, 0x1D35F, 0x1D37F, 0x1D7FF, 0x1F02F, 0x1F09F, 0x1F1FF, 0x1F2FF, 
+    0x2A6DF, 0x2B73F, 0x2FA1F, 0xE007F, 0xE01EF, 0xFFFFF, 0x10FFFF
+  };
+  
+  /** Returns random string of length between 0-20 codepoints, all codepoints within the same unicode block. */
+  public static String randomRealisticUnicodeString(Random r) {
+    return randomRealisticUnicodeString(r, 20);
+  }
+  
+  /** Returns random string of length up to maxLength codepoints , all codepoints within the same unicode block. */
+  public static String randomRealisticUnicodeString(Random r, int maxLength) {
+    return randomRealisticUnicodeString(r, 0, maxLength);
+  }
+
+  /** Returns random string of length between min and max codepoints, all codepoints within the same unicode block. */
+  public static String randomRealisticUnicodeString(Random r, int minLength, int maxLength) {
+    final int end = nextInt(r, minLength, maxLength);
+    final int block = r.nextInt(blockStarts.length);
+    StringBuilder sb = new StringBuilder();
+    for (int i = 0; i < end; i++)
+      sb.appendCodePoint(nextInt(r, blockStarts[block], blockEnds[block]));
+    return sb.toString();
+  }
+  
+  /** Returns random string, with a given UTF-8 byte length*/
+  public static String randomFixedByteLengthUnicodeString(Random r, int length) {
+    
+    final char[] buffer = new char[length*3];
+    int bytes = length;
+    int i = 0;
+    for (; i < buffer.length && bytes != 0; i++) {
+      int t;
+      if (bytes >= 4) {
+        t = r.nextInt(5);
+      } else if (bytes >= 3) {
+        t = r.nextInt(4);
+      } else if (bytes >= 2) {
+        t = r.nextInt(2);
+      } else {
+        t = 0;
+      }
+      if (t == 0) {
+        buffer[i] = (char) r.nextInt(0x80);
+        bytes--;
+      } else if (1 == t) {
+        buffer[i] = (char) nextInt(r, 0x80, 0x7ff);
+        bytes -= 2;
+      } else if (2 == t) {
+        buffer[i] = (char) nextInt(r, 0x800, 0xd7ff);
+        bytes -= 3;
+      } else if (3 == t) {
+        buffer[i] = (char) nextInt(r, 0xe000, 0xffff);
+        bytes -= 3;
+      } else if (4 == t) {
+        // Make a surrogate pair
+        // High surrogate
+        buffer[i++] = (char) nextInt(r, 0xd800, 0xdbff);
+        // Low surrogate
+        buffer[i] = (char) nextInt(r, 0xdc00, 0xdfff);
+        bytes -= 4;
+      }
+
+    }
+    return new String(buffer, 0, i);
+  }
+
+  
+  /** Return a Codec that can read any of the
+   *  default codecs and formats, but always writes in the specified
+   *  format. */
+  public static Codec alwaysPostingsFormat(final PostingsFormat format) {
+    // TODO: we really need for postings impls etc to announce themselves
+    // (and maybe their params, too) to infostream on flush and merge.
+    // otherwise in a real debugging situation we won't know whats going on!
+    if (LuceneTestCase.VERBOSE) {
+      System.out.println("forcing postings format to:" + format);
+    }
+    return new Lucene46Codec() {
+      @Override
+      public PostingsFormat getPostingsFormatForField(String field) {
+        return format;
+      }
+    };
+  }
+  
+  /** Return a Codec that can read any of the
+   *  default codecs and formats, but always writes in the specified
+   *  format. */
+  public static Codec alwaysDocValuesFormat(final DocValuesFormat format) {
+    // TODO: we really need for docvalues impls etc to announce themselves
+    // (and maybe their params, too) to infostream on flush and merge.
+    // otherwise in a real debugging situation we won't know whats going on!
+    if (LuceneTestCase.VERBOSE) {
+      System.out.println("forcing docvalues format to:" + format);
+    }
+    return new Lucene46Codec() {
+      @Override
+      public DocValuesFormat getDocValuesFormatForField(String field) {
+        return format;
+      }
+    };
+  }
+
+  // TODO: generalize all 'test-checks-for-crazy-codecs' to
+  // annotations (LUCENE-3489)
+  public static String getPostingsFormat(String field) {
+    return getPostingsFormat(Codec.getDefault(), field);
+  }
+  
+  public static String getPostingsFormat(Codec codec, String field) {
+    PostingsFormat p = codec.postingsFormat();
+    if (p instanceof PerFieldPostingsFormat) {
+      return ((PerFieldPostingsFormat)p).getPostingsFormatForField(field).getName();
+    } else {
+      return p.getName();
+    }
+  }
+
+  public static String getDocValuesFormat(String field) {
+    return getDocValuesFormat(Codec.getDefault(), field);
+  }
+  
+  public static String getDocValuesFormat(Codec codec, String field) {
+    DocValuesFormat f = codec.docValuesFormat();
+    if (f instanceof PerFieldDocValuesFormat) {
+      return ((PerFieldDocValuesFormat) f).getDocValuesFormatForField(field).getName();
+    } else {
+      return f.getName();
+    }
+  }
+
+  // TODO: remove this, push this test to Lucene40/Lucene42 codec tests
+  public static boolean fieldSupportsHugeBinaryDocValues(String field) {
+    String dvFormat = getDocValuesFormat(field);
+    if (dvFormat.equals("Lucene40") || dvFormat.equals("Lucene42") || dvFormat.equals("Memory")) {
+      return false;
+    }
+    return true;
+  }
+
+  public static boolean anyFilesExceptWriteLock(Directory dir) throws IOException {
+    String[] files = dir.listAll();
+    if (files.length > 1 || (files.length == 1 && !files[0].equals("write.lock"))) {
+      return true;
+    } else {
+      return false;
+    }
+  }
+
+  /** just tries to configure things to keep the open file
+   * count lowish */
+  public static void reduceOpenFiles(IndexWriter w) {
+    // keep number of open files lowish
+    MergePolicy mp = w.getConfig().getMergePolicy();
+    if (mp instanceof LogMergePolicy) {
+      LogMergePolicy lmp = (LogMergePolicy) mp;
+      lmp.setMergeFactor(Math.min(5, lmp.getMergeFactor()));
+      lmp.setNoCFSRatio(1.0);
+    } else if (mp instanceof TieredMergePolicy) {
+      TieredMergePolicy tmp = (TieredMergePolicy) mp;
+      tmp.setMaxMergeAtOnce(Math.min(5, tmp.getMaxMergeAtOnce()));
+      tmp.setSegmentsPerTier(Math.min(5, tmp.getSegmentsPerTier()));
+      tmp.setNoCFSRatio(1.0);
+    }
+    MergeScheduler ms = w.getConfig().getMergeScheduler();
+    if (ms instanceof ConcurrentMergeScheduler) {
+      // wtf... shouldnt it be even lower since its 1 by default?!?!
+      ((ConcurrentMergeScheduler) ms).setMaxMergesAndThreads(3, 2);
+    }
+  }
+
+  /** Checks some basic behaviour of an AttributeImpl
+   * @param reflectedValues contains a map with "AttributeClass#key" as values
+   */
+  public static <T> void assertAttributeReflection(final AttributeImpl att, Map<String,T> reflectedValues) {
+    final Map<String,Object> map = new HashMap<String,Object>();
+    att.reflectWith(new AttributeReflector() {
+      @Override
+      public void reflect(Class<? extends Attribute> attClass, String key, Object value) {
+        map.put(attClass.getName() + '#' + key, value);
+      }
+    });
+    Assert.assertEquals("Reflection does not produce same map", reflectedValues, map);
+  }
+  
+  /** 
+   * insecure, fast version of File.createTempFile
+   * uses Random instead of SecureRandom.
+   */
+  public static File createTempFile(String prefix, String suffix, File directory)
+      throws IOException {
+    if (prefix.length() < 3) {
+      throw new IllegalArgumentException("prefix must be at least 3 characters");
+    }
+    String newSuffix = suffix == null ? ".tmp" : suffix;
+    // always pull a long from master random. that way, the randomness of the test
+    // is not affected by whether it initialized the counter (in genTempFile) or not.
+    // note that the Random used by genTempFile is *not* the master Random, and therefore
+    // does not affect the randomness of the test.
+    final Random random = new Random(RandomizedContext.current().getRandom().nextLong());
+    File result;
+    do {
+      result = genTempFile(random, prefix, newSuffix, directory);
+    } while (!result.createNewFile());
+    return result;
+  }
+
+  /* identify for differnt VM processes */
+  private static String counterBase;
+  
+  /* Temp file counter */
+  private static int counter;
+  private static final Object counterLock = new Object();
+
+  private static File genTempFile(Random random, String prefix, String suffix, File directory) {
+    final int identify;
+    synchronized (counterLock) {
+      if (counterBase == null) { // init once
+        counter = random.nextInt() & 0xFFFF; // up to five digits number
+        counterBase = Integer.toString(counter);
+      }
+      identify = counter++;
+    }
+    StringBuilder newName = new StringBuilder();
+    newName.append(prefix);
+    newName.append(counterBase);
+    newName.append(identify);
+    newName.append(suffix);
+    return new File(directory, newName.toString());
+  }
+
+  public static void assertEquals(TopDocs expected, TopDocs actual) {
+    Assert.assertEquals("wrong total hits", expected.totalHits, actual.totalHits);
+    Assert.assertEquals("wrong maxScore", expected.getMaxScore(), actual.getMaxScore(), 0.0);
+    Assert.assertEquals("wrong hit count", expected.scoreDocs.length, actual.scoreDocs.length);
+    for(int hitIDX=0;hitIDX<expected.scoreDocs.length;hitIDX++) {
+      final ScoreDoc expectedSD = expected.scoreDocs[hitIDX];
+      final ScoreDoc actualSD = actual.scoreDocs[hitIDX];
+      Assert.assertEquals("wrong hit docID", expectedSD.doc, actualSD.doc);
+      Assert.assertEquals("wrong hit score", expectedSD.score, actualSD.score, 0.0);
+      if (expectedSD instanceof FieldDoc) {
+        Assert.assertTrue(actualSD instanceof FieldDoc);
+        Assert.assertArrayEquals("wrong sort field values",
+                            ((FieldDoc) expectedSD).fields,
+                            ((FieldDoc) actualSD).fields);
+      } else {
+        Assert.assertFalse(actualSD instanceof FieldDoc);
+      }
+    }
+  }
+
+  // NOTE: this is likely buggy, and cannot clone fields
+  // with tokenStreamValues, etc.  Use at your own risk!!
+
+  // TODO: is there a pre-existing way to do this!!!
+  public static Document cloneDocument(Document doc1) {
+    final Document doc2 = new Document();
+    for(IndexableField f : doc1.getFields()) {
+      final Field field1 = (Field) f;
+      final Field field2;
+      final DocValuesType dvType = field1.fieldType().docValueType();
+      final NumericType numType = field1.fieldType().numericType();
+      if (dvType != null) {
+        switch(dvType) {
+          case NUMERIC:
+            field2 = new NumericDocValuesField(field1.name(), field1.numericValue().longValue());
+            break;
+          case BINARY:
+            field2 = new BinaryDocValuesField(field1.name(), field1.binaryValue());
+          break;
+          case SORTED:
+            field2 = new SortedDocValuesField(field1.name(), field1.binaryValue());
+            break;
+          default:
+            throw new IllegalStateException("unknown Type: " + dvType);
+        }
+      } else if (numType != null) {
+        switch (numType) {
+          case INT:
+            field2 = new IntField(field1.name(), field1.numericValue().intValue(), field1.fieldType());
+            break;
+          case FLOAT:
+            field2 = new FloatField(field1.name(), field1.numericValue().intValue(), field1.fieldType());
+            break;
+          case LONG:
+            field2 = new LongField(field1.name(), field1.numericValue().intValue(), field1.fieldType());
+            break;
+          case DOUBLE:
+            field2 = new DoubleField(field1.name(), field1.numericValue().intValue(), field1.fieldType());
+            break;
+          default:
+            throw new IllegalStateException("unknown Type: " + numType);
+        }
+      } else {
+        field2 = new Field(field1.name(), field1.stringValue(), field1.fieldType());
+      }
+      doc2.add(field2);
+    }
+
+    return doc2;
+  }
+
+  // Returns a DocsEnum, but randomly sometimes uses a
+  // DocsAndFreqsEnum, DocsAndPositionsEnum.  Returns null
+  // if field/term doesn't exist:
+  public static DocsEnum docs(Random random, IndexReader r, String field, BytesRef term, Bits liveDocs, DocsEnum reuse, int flags) throws IOException {
+    final Terms terms = MultiFields.getTerms(r, field);
+    if (terms == null) {
+      return null;
+    }
+    final TermsEnum termsEnum = terms.iterator(null);
+    if (!termsEnum.seekExact(term)) {
+      return null;
+    }
+    return docs(random, termsEnum, liveDocs, reuse, flags);
+  }
+
+  // Returns a DocsEnum from a positioned TermsEnum, but
+  // randomly sometimes uses a DocsAndFreqsEnum, DocsAndPositionsEnum.
+  public static DocsEnum docs(Random random, TermsEnum termsEnum, Bits liveDocs, DocsEnum reuse, int flags) throws IOException {
+    if (random.nextBoolean()) {
+      if (random.nextBoolean()) {
+        final int posFlags;
+        switch (random.nextInt(4)) {
+          case 0: posFlags = 0; break;
+          case 1: posFlags = DocsAndPositionsEnum.FLAG_OFFSETS; break;
+          case 2: posFlags = DocsAndPositionsEnum.FLAG_PAYLOADS; break;
+          default: posFlags = DocsAndPositionsEnum.FLAG_OFFSETS | DocsAndPositionsEnum.FLAG_PAYLOADS; break;
+        }
+        // TODO: cast to DocsAndPositionsEnum?
+        DocsAndPositionsEnum docsAndPositions = termsEnum.docsAndPositions(liveDocs, null, posFlags);
+        if (docsAndPositions != null) {
+          return docsAndPositions;
+        }
+      }
+      flags |= DocsEnum.FLAG_FREQS;
+    }
+    return termsEnum.docs(liveDocs, reuse, flags);
+  }
+  
+  public static CharSequence stringToCharSequence(String string, Random random) {
+    return bytesToCharSequence(new BytesRef(string), random);
+  }
+  
+  public static CharSequence bytesToCharSequence(BytesRef ref, Random random) {
+    switch(random.nextInt(5)) {
+    case 4:
+      CharsRef chars = new CharsRef(ref.length);
+      UnicodeUtil.UTF8toUTF16(ref.bytes, ref.offset, ref.length, chars);
+      return chars;
+    case 3:
+      return CharBuffer.wrap(ref.utf8ToString());
+    default:
+      return ref.utf8ToString();
+    }
+  }
+
+  /**
+   * Shutdown {@link ExecutorService} and wait for its.
+   */
+  public static void shutdownExecutorService(ExecutorService ex) {
+    if (ex != null) {
+      try {
+        ex.shutdown();
+        ex.awaitTermination(1, TimeUnit.SECONDS);
+      } catch (InterruptedException e) {
+        // Just report it on the syserr.
+        System.err.println("Could not properly shutdown executor service.");
+        e.printStackTrace(System.err);
+      }
+    }
+  }
+
+  /**
+   * Returns a valid (compiling) Pattern instance with random stuff inside. Be careful
+   * when applying random patterns to longer strings as certain types of patterns
+   * may explode into exponential times in backtracking implementations (such as Java's).
+   */
+  public static Pattern randomPattern(Random random) {
+    final String nonBmpString = "AB\uD840\uDC00C";
+    while (true) {
+      try {
+        Pattern p = Pattern.compile(TestUtil.randomRegexpishString(random));
+        String replacement = null;
+        // ignore bugs in Sun's regex impl
+        try {
+          replacement = p.matcher(nonBmpString).replaceAll("_");
+        } catch (StringIndexOutOfBoundsException jdkBug) {
+          System.out.println("WARNING: your jdk is buggy!");
+          System.out.println("Pattern.compile(\"" + p.pattern() + 
+              "\").matcher(\"AB\\uD840\\uDC00C\").replaceAll(\"_\"); should not throw IndexOutOfBounds!");
+        }
+        // Make sure the result of applying the pattern to a string with extended
+        // unicode characters is a valid utf16 string. See LUCENE-4078 for discussion.
+        if (replacement != null && UnicodeUtil.validUTF16String(replacement)) {
+          return p;
+        }
+      } catch (PatternSyntaxException ignored) {
+        // Loop trying until we hit something that compiles.
+      }
+    }
+  }
+    
+  
+  public static final FilterStrategy randomFilterStrategy(final Random random) {
+    switch(random.nextInt(6)) {
+      case 5:
+      case 4:
+        return new FilteredQuery.RandomAccessFilterStrategy() {
+          @Override
+          protected boolean useRandomAccess(Bits bits, int firstFilterDoc) {
+            return LuceneTestCase.random().nextBoolean();
+          }
+        };
+      case 3:
+        return FilteredQuery.RANDOM_ACCESS_FILTER_STRATEGY;
+      case 2:
+        return FilteredQuery.LEAP_FROG_FILTER_FIRST_STRATEGY;
+      case 1:
+        return FilteredQuery.LEAP_FROG_QUERY_FIRST_STRATEGY;
+      case 0: 
+        return FilteredQuery.QUERY_FIRST_FILTER_STRATEGY;
+      default:
+        return FilteredQuery.RANDOM_ACCESS_FILTER_STRATEGY;
+    }
+  }
+
+  /**
+   * Returns a random string in the specified length range consisting 
+   * entirely of whitespace characters 
+   * @see #WHITESPACE_CHARACTERS
+   */
+  public static String randomWhitespace(Random r, int minLength, int maxLength) {
+    final int end = nextInt(r, minLength, maxLength);
+    StringBuilder out = new StringBuilder();
+    for (int i = 0; i < end; i++) {
+      int offset = nextInt(r, 0, WHITESPACE_CHARACTERS.length-1);
+      char c = WHITESPACE_CHARACTERS[offset];
+      // sanity check
+      Assert.assertTrue("Not really whitespace? (@"+offset+"): " + c, Character.isWhitespace(c));
+      out.append(c);
+    }
+    return out.toString();
+  }
+
+  public static String randomAnalysisString(Random random, int maxLength, boolean simple) {
+    assert maxLength >= 0;
+
+    // sometimes just a purely random string
+    if (random.nextInt(31) == 0) {
+      return randomSubString(random, random.nextInt(maxLength), simple);
+    }
+
+    // otherwise, try to make it more realistic with 'words' since most tests use MockTokenizer
+    // first decide how big the string will really be: 0..n
+    maxLength = random.nextInt(maxLength);
+    int avgWordLength = TestUtil.nextInt(random, 3, 8);
+    StringBuilder sb = new StringBuilder();
+    while (sb.length() < maxLength) {
+      if (sb.length() > 0) {
+        sb.append(' ');
+      }
+      int wordLength = -1;
+      while (wordLength < 0) {
+        wordLength = (int) (random.nextGaussian() * 3 + avgWordLength);
+      }
+      wordLength = Math.min(wordLength, maxLength - sb.length());
+      sb.append(randomSubString(random, wordLength, simple));
+    }
+    return sb.toString();
+  }
+
+  public static String randomSubString(Random random, int wordLength, boolean simple) {
+    if (wordLength == 0) {
+      return "";
+    }
+
+    int evilness = TestUtil.nextInt(random, 0, 20);
+
+    StringBuilder sb = new StringBuilder();
+    while (sb.length() < wordLength) {;
+      if (simple) {
+        sb.append(random.nextBoolean() ? TestUtil.randomSimpleString(random, wordLength) : TestUtil.randomHtmlishString(random, wordLength));
+      } else {
+        if (evilness < 10) {
+          sb.append(TestUtil.randomSimpleString(random, wordLength));
+        } else if (evilness < 15) {
+          assert sb.length() == 0; // we should always get wordLength back!
+          sb.append(TestUtil.randomRealisticUnicodeString(random, wordLength, wordLength));
+        } else if (evilness == 16) {
+          sb.append(TestUtil.randomHtmlishString(random, wordLength));
+        } else if (evilness == 17) {
+          // gives a lot of punctuation
+          sb.append(TestUtil.randomRegexpishString(random, wordLength));
+        } else {
+          sb.append(TestUtil.randomUnicodeString(random, wordLength));
+        }
+      }
+    }
+    if (sb.length() > wordLength) {
+      sb.setLength(wordLength);
+      if (Character.isHighSurrogate(sb.charAt(wordLength-1))) {
+        sb.setLength(wordLength-1);
+      }
+    }
+
+    if (random.nextInt(17) == 0) {
+      // mix up case
+      String mixedUp = TestUtil.randomlyRecaseCodePoints(random, sb.toString());
+      assert mixedUp.length() == sb.length();
+      return mixedUp;
+    } else {
+      return sb.toString();
+    }
+  }
+  
+  /** List of characters that match {@link Character#isWhitespace} */
+  public static final char[] WHITESPACE_CHARACTERS = new char[] {
+    // :TODO: is this list exhaustive?
+    '\u0009',
+    '\n',    
+    '\u000B',
+    '\u000C',
+    '\r',    
+    '\u001C',
+    '\u001D',
+    '\u001E',
+    '\u001F',
+    '\u0020',
+    // '\u0085', faild sanity check?
+    '\u1680',
+    '\u180E',
+    '\u2000',
+    '\u2001',
+    '\u2002',
+    '\u2003',
+    '\u2004',
+    '\u2005',
+    '\u2006',
+    '\u2008',
+    '\u2009',
+    '\u200A',
+    '\u2028',
+    '\u2029',
+    '\u205F',
+    '\u3000',
+  };
+}
diff --git a/lucene/test-framework/src/java/org/apache/lucene/util/_TestUtil.java b/lucene/test-framework/src/java/org/apache/lucene/util/_TestUtil.java
deleted file mode 100644
index bcd0115..0000000
--- a/lucene/test-framework/src/java/org/apache/lucene/util/_TestUtil.java
+++ /dev/null
@@ -1,1174 +0,0 @@
-package org.apache.lucene.util;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.BufferedOutputStream;
-import java.io.ByteArrayOutputStream;
-import java.io.File;
-import java.io.FileOutputStream;
-import java.io.IOException;
-import java.io.InputStream;
-import java.io.OutputStream;
-import java.io.PrintStream;
-import java.math.BigDecimal;
-import java.math.BigInteger;
-import java.nio.CharBuffer;
-import java.util.Arrays;
-import java.util.Enumeration;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-import java.util.Random;
-import java.util.concurrent.ExecutorService;
-import java.util.concurrent.TimeUnit;
-import java.util.regex.Pattern;
-import java.util.regex.PatternSyntaxException;
-import java.util.zip.ZipEntry;
-import java.util.zip.ZipFile;
-
-import org.apache.lucene.codecs.Codec;
-import org.apache.lucene.codecs.DocValuesFormat;
-import org.apache.lucene.codecs.PostingsFormat;
-import org.apache.lucene.codecs.lucene46.Lucene46Codec;
-import org.apache.lucene.codecs.perfield.PerFieldDocValuesFormat;
-import org.apache.lucene.codecs.perfield.PerFieldPostingsFormat;
-import org.apache.lucene.document.BinaryDocValuesField;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.DoubleField;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.document.FieldType.NumericType;
-import org.apache.lucene.document.FloatField;
-import org.apache.lucene.document.IntField;
-import org.apache.lucene.document.LongField;
-import org.apache.lucene.document.NumericDocValuesField;
-import org.apache.lucene.document.SortedDocValuesField;
-import org.apache.lucene.index.AtomicReader;
-import org.apache.lucene.index.AtomicReaderContext;
-import org.apache.lucene.index.CheckIndex;
-import org.apache.lucene.index.CheckIndex.Status.DocValuesStatus;
-import org.apache.lucene.index.CheckIndex.Status.FieldNormStatus;
-import org.apache.lucene.index.CheckIndex.Status.StoredFieldStatus;
-import org.apache.lucene.index.CheckIndex.Status.TermIndexStatus;
-import org.apache.lucene.index.CheckIndex.Status.TermVectorStatus;
-import org.apache.lucene.index.ConcurrentMergeScheduler;
-import org.apache.lucene.index.DocsAndPositionsEnum;
-import org.apache.lucene.index.DocsEnum;
-import org.apache.lucene.index.FieldInfo.DocValuesType;
-import org.apache.lucene.index.FieldInfos;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.IndexableField;
-import org.apache.lucene.index.LogMergePolicy;
-import org.apache.lucene.index.MergePolicy;
-import org.apache.lucene.index.MergeScheduler;
-import org.apache.lucene.index.MultiFields;
-import org.apache.lucene.index.SegmentCommitInfo;
-import org.apache.lucene.index.SegmentReader;
-import org.apache.lucene.index.Terms;
-import org.apache.lucene.index.TermsEnum;
-import org.apache.lucene.index.TieredMergePolicy;
-import org.apache.lucene.search.FieldDoc;
-import org.apache.lucene.search.FilteredQuery;
-import org.apache.lucene.search.FilteredQuery.FilterStrategy;
-import org.apache.lucene.search.ScoreDoc;
-import org.apache.lucene.search.TopDocs;
-import org.apache.lucene.store.Directory;
-import org.junit.Assert;
-
-import com.carrotsearch.randomizedtesting.RandomizedContext;
-import com.carrotsearch.randomizedtesting.generators.RandomInts;
-import com.carrotsearch.randomizedtesting.generators.RandomPicks;
-
-/**
- * General utility methods for Lucene unit tests. 
- */
-public class _TestUtil {
-
-  // the max number of retries we're going to do in getTempDir
-  private static final int GET_TEMP_DIR_RETRY_THRESHOLD = 1000;
-  
-  /**
-   * Returns a temp directory, based on the given description. Creates the
-   * directory.
-   */
-  public static File getTempDir(String desc) {
-    if (desc.length() < 3) {
-      throw new IllegalArgumentException("description must be at least 3 characters");
-    }
-    // always pull a long from master random. that way, the randomness of the test
-    // is not affected by whether it initialized the counter (in genTempFile) or not.
-    // note that the Random used by genTempFile is *not* the master Random, and therefore
-    // does not affect the randomness of the test.
-    final Random random = new Random(RandomizedContext.current().getRandom().nextLong());
-    int attempt = 0;
-    File f;
-    do {
-      f = genTempFile(random, desc, "tmp", LuceneTestCase.TEMP_DIR);
-    } while (!f.mkdir() && (attempt++) < GET_TEMP_DIR_RETRY_THRESHOLD);
-    
-    if (attempt > GET_TEMP_DIR_RETRY_THRESHOLD) {
-      throw new RuntimeException(
-          "failed to get a temporary dir too many times. check your temp directory and consider manually cleaning it.");
-    }
-    
-    LuceneTestCase.closeAfterSuite(new CloseableFile(f, LuceneTestCase.suiteFailureMarker));
-    return f;
-  }
-
-  /**
-   * Deletes a directory and everything underneath it.
-   */
-  public static void rmDir(File dir) throws IOException {
-    if (dir.exists()) {
-      if (dir.isFile() && !dir.delete()) {
-        throw new IOException("could not delete " + dir);
-      }
-      for (File f : dir.listFiles()) {
-        if (f.isDirectory()) {
-          rmDir(f);
-        } else {
-          if (!f.delete()) {
-            throw new IOException("could not delete " + f);
-          }
-        }
-      }
-      if (!dir.delete()) {
-        throw new IOException("could not delete " + dir);
-      }
-    }
-  }
-
-  /** 
-   * Convenience method: Unzip zipName + ".zip" under destDir, removing destDir first 
-   */
-  public static void unzip(File zipName, File destDir) throws IOException {
-    
-    ZipFile zipFile = new ZipFile(zipName);
-    
-    Enumeration<? extends ZipEntry> entries = zipFile.entries();
-    
-    rmDir(destDir);
-
-    destDir.mkdir();
-    LuceneTestCase.closeAfterSuite(new CloseableFile(destDir, LuceneTestCase.suiteFailureMarker));
-
-    while (entries.hasMoreElements()) {
-      ZipEntry entry = entries.nextElement();
-      
-      InputStream in = zipFile.getInputStream(entry);
-      File targetFile = new File(destDir, entry.getName());
-      if (entry.isDirectory()) {
-        // allow unzipping with directory structure
-        targetFile.mkdirs();
-      } else {
-        if (targetFile.getParentFile()!=null) {
-          // be on the safe side: do not rely on that directories are always extracted
-          // before their children (although this makes sense, but is it guaranteed?)
-          targetFile.getParentFile().mkdirs();   
-        }
-        OutputStream out = new BufferedOutputStream(new FileOutputStream(targetFile));
-        
-        byte[] buffer = new byte[8192];
-        int len;
-        while((len = in.read(buffer)) >= 0) {
-          out.write(buffer, 0, len);
-        }
-        
-        in.close();
-        out.close();
-      }
-    }
-    
-    zipFile.close();
-  }
-  
-  public static void syncConcurrentMerges(IndexWriter writer) {
-    syncConcurrentMerges(writer.getConfig().getMergeScheduler());
-  }
-
-  public static void syncConcurrentMerges(MergeScheduler ms) {
-    if (ms instanceof ConcurrentMergeScheduler)
-      ((ConcurrentMergeScheduler) ms).sync();
-  }
-
-  /** This runs the CheckIndex tool on the index in.  If any
-   *  issues are hit, a RuntimeException is thrown; else,
-   *  true is returned. */
-  public static CheckIndex.Status checkIndex(Directory dir) throws IOException {
-    return checkIndex(dir, true);
-  }
-
-  public static CheckIndex.Status checkIndex(Directory dir, boolean crossCheckTermVectors) throws IOException {
-    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);
-    CheckIndex checker = new CheckIndex(dir);
-    checker.setCrossCheckTermVectors(crossCheckTermVectors);
-    checker.setInfoStream(new PrintStream(bos, false, "UTF-8"), false);
-    CheckIndex.Status indexStatus = checker.checkIndex(null);
-    if (indexStatus == null || indexStatus.clean == false) {
-      System.out.println("CheckIndex failed");
-      System.out.println(bos.toString("UTF-8"));
-      throw new RuntimeException("CheckIndex failed");
-    } else {
-      if (LuceneTestCase.INFOSTREAM) {
-        System.out.println(bos.toString("UTF-8"));
-      }
-      return indexStatus;
-    }
-  }
-  
-  /** This runs the CheckIndex tool on the Reader.  If any
-   *  issues are hit, a RuntimeException is thrown */
-  public static void checkReader(IndexReader reader) throws IOException {
-    for (AtomicReaderContext context : reader.leaves()) {
-      checkReader(context.reader(), true);
-    }
-  }
-  
-  public static void checkReader(AtomicReader reader, boolean crossCheckTermVectors) throws IOException {
-    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);
-    PrintStream infoStream = new PrintStream(bos, false, "UTF-8");
-
-    FieldNormStatus fieldNormStatus = CheckIndex.testFieldNorms(reader, infoStream);
-    TermIndexStatus termIndexStatus = CheckIndex.testPostings(reader, infoStream);
-    StoredFieldStatus storedFieldStatus = CheckIndex.testStoredFields(reader, infoStream);
-    TermVectorStatus termVectorStatus = CheckIndex.testTermVectors(reader, infoStream, false, crossCheckTermVectors);
-    DocValuesStatus docValuesStatus = CheckIndex.testDocValues(reader, infoStream);
-    
-    if (fieldNormStatus.error != null || 
-      termIndexStatus.error != null ||
-      storedFieldStatus.error != null ||
-      termVectorStatus.error != null ||
-      docValuesStatus.error != null) {
-      System.out.println("CheckReader failed");
-      System.out.println(bos.toString("UTF-8"));
-      throw new RuntimeException("CheckReader failed");
-    } else {
-      if (LuceneTestCase.INFOSTREAM) {
-        System.out.println(bos.toString("UTF-8"));
-      }
-    }
-  }
-
-  /** start and end are BOTH inclusive */
-  public static int nextInt(Random r, int start, int end) {
-    return RandomInts.randomIntBetween(r, start, end);
-  }
-
-  /** start and end are BOTH inclusive */
-  public static long nextLong(Random r, long start, long end) {
-    assert end >= start;
-    final BigInteger range = BigInteger.valueOf(end).add(BigInteger.valueOf(1)).subtract(BigInteger.valueOf(start));
-    if (range.compareTo(BigInteger.valueOf(Integer.MAX_VALUE)) <= 0) {
-      return start + r.nextInt(range.intValue());
-    } else {
-      // probably not evenly distributed when range is large, but OK for tests
-      final BigInteger augend = new BigDecimal(range).multiply(new BigDecimal(r.nextDouble())).toBigInteger();
-      final long result = BigInteger.valueOf(start).add(augend).longValue();
-      assert result >= start;
-      assert result <= end;
-      return result;
-    }
-  }
-
-  public static String randomSimpleString(Random r, int maxLength) {
-    return randomSimpleString(r, 0, maxLength);
-  }
-  
-  public static String randomSimpleString(Random r, int minLength, int maxLength) {
-    final int end = nextInt(r, minLength, maxLength);
-    if (end == 0) {
-      // allow 0 length
-      return "";
-    }
-    final char[] buffer = new char[end];
-    for (int i = 0; i < end; i++) {
-      buffer[i] = (char) _TestUtil.nextInt(r, 'a', 'z');
-    }
-    return new String(buffer, 0, end);
-  }
-
-  public static String randomSimpleStringRange(Random r, char minChar, char maxChar, int maxLength) {
-    final int end = nextInt(r, 0, maxLength);
-    if (end == 0) {
-      // allow 0 length
-      return "";
-    }
-    final char[] buffer = new char[end];
-    for (int i = 0; i < end; i++) {
-      buffer[i] = (char) _TestUtil.nextInt(r, minChar, maxChar);
-    }
-    return new String(buffer, 0, end);
-  }
-
-  public static String randomSimpleString(Random r) {
-    return randomSimpleString(r, 0, 10);
-  }
-
-  /** Returns random string, including full unicode range. */
-  public static String randomUnicodeString(Random r) {
-    return randomUnicodeString(r, 20);
-  }
-
-  /**
-   * Returns a random string up to a certain length.
-   */
-  public static String randomUnicodeString(Random r, int maxLength) {
-    final int end = nextInt(r, 0, maxLength);
-    if (end == 0) {
-      // allow 0 length
-      return "";
-    }
-    final char[] buffer = new char[end];
-    randomFixedLengthUnicodeString(r, buffer, 0, buffer.length);
-    return new String(buffer, 0, end);
-  }
-
-  /**
-   * Fills provided char[] with valid random unicode code
-   * unit sequence.
-   */
-  public static void randomFixedLengthUnicodeString(Random random, char[] chars, int offset, int length) {
-    int i = offset;
-    final int end = offset + length;
-    while(i < end) {
-      final int t = random.nextInt(5);
-      if (0 == t && i < length - 1) {
-        // Make a surrogate pair
-        // High surrogate
-        chars[i++] = (char) nextInt(random, 0xd800, 0xdbff);
-        // Low surrogate
-        chars[i++] = (char) nextInt(random, 0xdc00, 0xdfff);
-      } else if (t <= 1) {
-        chars[i++] = (char) random.nextInt(0x80);
-      } else if (2 == t) {
-        chars[i++] = (char) nextInt(random, 0x80, 0x7ff);
-      } else if (3 == t) {
-        chars[i++] = (char) nextInt(random, 0x800, 0xd7ff);
-      } else if (4 == t) {
-        chars[i++] = (char) nextInt(random, 0xe000, 0xffff);
-      }
-    }
-  }
-  
-  /**
-   * Returns a String thats "regexpish" (contains lots of operators typically found in regular expressions)
-   * If you call this enough times, you might get a valid regex!
-   */
-  public static String randomRegexpishString(Random r) {
-    return randomRegexpishString(r, 20);
-  }
-
-  /**
-   * Maximum recursion bound for '+' and '*' replacements in
-   * {@link #randomRegexpishString(Random, int)}.
-   */
-  private final static int maxRecursionBound = 5;
-
-  /**
-   * Operators for {@link #randomRegexpishString(Random, int)}.
-   */
-  private final static List<String> ops = Arrays.asList(
-      ".", "?", 
-      "{0," + maxRecursionBound + "}",  // bounded replacement for '*'
-      "{1," + maxRecursionBound + "}",  // bounded replacement for '+'
-      "(",
-      ")",
-      "-",
-      "[",
-      "]",
-      "|"
-  );
-
-  /**
-   * Returns a String thats "regexpish" (contains lots of operators typically found in regular expressions)
-   * If you call this enough times, you might get a valid regex!
-   * 
-   * <P>Note: to avoid practically endless backtracking patterns we replace asterisk and plus
-   * operators with bounded repetitions. See LUCENE-4111 for more info.
-   * 
-   * @param maxLength A hint about maximum length of the regexpish string. It may be exceeded by a few characters.
-   */
-  public static String randomRegexpishString(Random r, int maxLength) {
-    final StringBuilder regexp = new StringBuilder(maxLength);
-    for (int i = nextInt(r, 0, maxLength); i > 0; i--) {
-      if (r.nextBoolean()) {
-        regexp.append((char) RandomInts.randomIntBetween(r, 'a', 'z'));
-      } else {
-        regexp.append(RandomPicks.randomFrom(r, ops));
-      }
-    }
-    return regexp.toString();
-  }
-
-  private static final String[] HTML_CHAR_ENTITIES = {
-      "AElig", "Aacute", "Acirc", "Agrave", "Alpha", "AMP", "Aring", "Atilde",
-      "Auml", "Beta", "COPY", "Ccedil", "Chi", "Dagger", "Delta", "ETH",
-      "Eacute", "Ecirc", "Egrave", "Epsilon", "Eta", "Euml", "Gamma", "GT",
-      "Iacute", "Icirc", "Igrave", "Iota", "Iuml", "Kappa", "Lambda", "LT",
-      "Mu", "Ntilde", "Nu", "OElig", "Oacute", "Ocirc", "Ograve", "Omega",
-      "Omicron", "Oslash", "Otilde", "Ouml", "Phi", "Pi", "Prime", "Psi",
-      "QUOT", "REG", "Rho", "Scaron", "Sigma", "THORN", "Tau", "Theta",
-      "Uacute", "Ucirc", "Ugrave", "Upsilon", "Uuml", "Xi", "Yacute", "Yuml",
-      "Zeta", "aacute", "acirc", "acute", "aelig", "agrave", "alefsym",
-      "alpha", "amp", "and", "ang", "apos", "aring", "asymp", "atilde",
-      "auml", "bdquo", "beta", "brvbar", "bull", "cap", "ccedil", "cedil",
-      "cent", "chi", "circ", "clubs", "cong", "copy", "crarr", "cup",
-      "curren", "dArr", "dagger", "darr", "deg", "delta", "diams", "divide",
-      "eacute", "ecirc", "egrave", "empty", "emsp", "ensp", "epsilon",
-      "equiv", "eta", "eth", "euml", "euro", "exist", "fnof", "forall",
-      "frac12", "frac14", "frac34", "frasl", "gamma", "ge", "gt", "hArr",
-      "harr", "hearts", "hellip", "iacute", "icirc", "iexcl", "igrave",
-      "image", "infin", "int", "iota", "iquest", "isin", "iuml", "kappa",
-      "lArr", "lambda", "lang", "laquo", "larr", "lceil", "ldquo", "le",
-      "lfloor", "lowast", "loz", "lrm", "lsaquo", "lsquo", "lt", "macr",
-      "mdash", "micro", "middot", "minus", "mu", "nabla", "nbsp", "ndash",
-      "ne", "ni", "not", "notin", "nsub", "ntilde", "nu", "oacute", "ocirc",
-      "oelig", "ograve", "oline", "omega", "omicron", "oplus", "or", "ordf",
-      "ordm", "oslash", "otilde", "otimes", "ouml", "para", "part", "permil",
-      "perp", "phi", "pi", "piv", "plusmn", "pound", "prime", "prod", "prop",
-      "psi", "quot", "rArr", "radic", "rang", "raquo", "rarr", "rceil",
-      "rdquo", "real", "reg", "rfloor", "rho", "rlm", "rsaquo", "rsquo",
-      "sbquo", "scaron", "sdot", "sect", "shy", "sigma", "sigmaf", "sim",
-      "spades", "sub", "sube", "sum", "sup", "sup1", "sup2", "sup3", "supe",
-      "szlig", "tau", "there4", "theta", "thetasym", "thinsp", "thorn",
-      "tilde", "times", "trade", "uArr", "uacute", "uarr", "ucirc", "ugrave",
-      "uml", "upsih", "upsilon", "uuml", "weierp", "xi", "yacute", "yen",
-      "yuml", "zeta", "zwj", "zwnj"
-  };
-  
-  public static String randomHtmlishString(Random random, int numElements) {
-    final int end = nextInt(random, 0, numElements);
-    if (end == 0) {
-      // allow 0 length
-      return "";
-    }
-    StringBuilder sb = new StringBuilder();
-    for (int i = 0; i < end; i++) {
-      int val = random.nextInt(25);
-      switch(val) {
-        case 0: sb.append("<p>"); break;
-        case 1: {
-          sb.append("<");
-          sb.append("    ".substring(nextInt(random, 0, 4)));
-          sb.append(randomSimpleString(random));
-          for (int j = 0 ; j < nextInt(random, 0, 10) ; ++j) {
-            sb.append(' ');
-            sb.append(randomSimpleString(random));
-            sb.append(" ".substring(nextInt(random, 0, 1)));
-            sb.append('=');
-            sb.append(" ".substring(nextInt(random, 0, 1)));
-            sb.append("\"".substring(nextInt(random, 0, 1)));
-            sb.append(randomSimpleString(random));
-            sb.append("\"".substring(nextInt(random, 0, 1)));
-          }
-          sb.append("    ".substring(nextInt(random, 0, 4)));
-          sb.append("/".substring(nextInt(random, 0, 1)));
-          sb.append(">".substring(nextInt(random, 0, 1)));
-          break;
-        }
-        case 2: {
-          sb.append("</");
-          sb.append("    ".substring(nextInt(random, 0, 4)));
-          sb.append(randomSimpleString(random));
-          sb.append("    ".substring(nextInt(random, 0, 4)));
-          sb.append(">".substring(nextInt(random, 0, 1)));
-          break;
-        }
-        case 3: sb.append(">"); break;
-        case 4: sb.append("</p>"); break;
-        case 5: sb.append("<!--"); break;
-        case 6: sb.append("<!--#"); break;
-        case 7: sb.append("<script><!-- f('"); break;
-        case 8: sb.append("</script>"); break;
-        case 9: sb.append("<?"); break;
-        case 10: sb.append("?>"); break;
-        case 11: sb.append("\""); break;
-        case 12: sb.append("\\\""); break;
-        case 13: sb.append("'"); break;
-        case 14: sb.append("\\'"); break;
-        case 15: sb.append("-->"); break;
-        case 16: {
-          sb.append("&");
-          switch(nextInt(random, 0, 2)) {
-            case 0: sb.append(randomSimpleString(random)); break;
-            case 1: sb.append(HTML_CHAR_ENTITIES[random.nextInt(HTML_CHAR_ENTITIES.length)]); break;
-          }
-          sb.append(";".substring(nextInt(random, 0, 1)));
-          break;
-        }
-        case 17: {
-          sb.append("&#");
-          if (0 == nextInt(random, 0, 1)) {
-            sb.append(nextInt(random, 0, Integer.MAX_VALUE - 1));
-            sb.append(";".substring(nextInt(random, 0, 1)));
-          }
-          break;
-        } 
-        case 18: {
-          sb.append("&#x");
-          if (0 == nextInt(random, 0, 1)) {
-            sb.append(Integer.toString(nextInt(random, 0, Integer.MAX_VALUE - 1), 16));
-            sb.append(";".substring(nextInt(random, 0, 1)));
-          }
-          break;
-        }
-          
-        case 19: sb.append(";"); break;
-        case 20: sb.append(nextInt(random, 0, Integer.MAX_VALUE - 1)); break;
-        case 21: sb.append("\n"); break;
-        case 22: sb.append("          ".substring(nextInt(random, 0, 10))); break;
-        case 23: {
-          sb.append("<");
-          if (0 == nextInt(random, 0, 3)) {
-            sb.append("          ".substring(nextInt(random, 1, 10)));
-          }
-          if (0 == nextInt(random, 0, 1)) {
-            sb.append("/");
-            if (0 == nextInt(random, 0, 3)) {
-              sb.append("          ".substring(nextInt(random, 1, 10)));
-            }
-          }
-          switch (nextInt(random, 0, 3)) {
-            case 0: sb.append(randomlyRecaseCodePoints(random, "script")); break;
-            case 1: sb.append(randomlyRecaseCodePoints(random, "style")); break;
-            case 2: sb.append(randomlyRecaseCodePoints(random, "br")); break;
-            // default: append nothing
-          }
-          sb.append(">".substring(nextInt(random, 0, 1)));
-          break;
-        }
-        default: sb.append(randomSimpleString(random));
-      }
-    }
-    return sb.toString();
-  }
-
-  /**
-   * Randomly upcases, downcases, or leaves intact each code point in the given string
-   */
-  public static String randomlyRecaseCodePoints(Random random, String str) {
-    StringBuilder builder = new StringBuilder();
-    int pos = 0;
-    while (pos < str.length()) {
-      int codePoint = str.codePointAt(pos);
-      pos += Character.charCount(codePoint);
-      switch (nextInt(random, 0, 2)) {
-        case 0: builder.appendCodePoint(Character.toUpperCase(codePoint)); break;
-        case 1: builder.appendCodePoint(Character.toLowerCase(codePoint)); break;
-        case 2: builder.appendCodePoint(codePoint); // leave intact
-      }
-    }
-    return builder.toString();
-  }
-
-  private static final int[] blockStarts = {
-    0x0000, 0x0080, 0x0100, 0x0180, 0x0250, 0x02B0, 0x0300, 0x0370, 0x0400, 
-    0x0500, 0x0530, 0x0590, 0x0600, 0x0700, 0x0750, 0x0780, 0x07C0, 0x0800, 
-    0x0900, 0x0980, 0x0A00, 0x0A80, 0x0B00, 0x0B80, 0x0C00, 0x0C80, 0x0D00, 
-    0x0D80, 0x0E00, 0x0E80, 0x0F00, 0x1000, 0x10A0, 0x1100, 0x1200, 0x1380, 
-    0x13A0, 0x1400, 0x1680, 0x16A0, 0x1700, 0x1720, 0x1740, 0x1760, 0x1780, 
-    0x1800, 0x18B0, 0x1900, 0x1950, 0x1980, 0x19E0, 0x1A00, 0x1A20, 0x1B00, 
-    0x1B80, 0x1C00, 0x1C50, 0x1CD0, 0x1D00, 0x1D80, 0x1DC0, 0x1E00, 0x1F00, 
-    0x2000, 0x2070, 0x20A0, 0x20D0, 0x2100, 0x2150, 0x2190, 0x2200, 0x2300, 
-    0x2400, 0x2440, 0x2460, 0x2500, 0x2580, 0x25A0, 0x2600, 0x2700, 0x27C0, 
-    0x27F0, 0x2800, 0x2900, 0x2980, 0x2A00, 0x2B00, 0x2C00, 0x2C60, 0x2C80, 
-    0x2D00, 0x2D30, 0x2D80, 0x2DE0, 0x2E00, 0x2E80, 0x2F00, 0x2FF0, 0x3000, 
-    0x3040, 0x30A0, 0x3100, 0x3130, 0x3190, 0x31A0, 0x31C0, 0x31F0, 0x3200, 
-    0x3300, 0x3400, 0x4DC0, 0x4E00, 0xA000, 0xA490, 0xA4D0, 0xA500, 0xA640, 
-    0xA6A0, 0xA700, 0xA720, 0xA800, 0xA830, 0xA840, 0xA880, 0xA8E0, 0xA900, 
-    0xA930, 0xA960, 0xA980, 0xAA00, 0xAA60, 0xAA80, 0xABC0, 0xAC00, 0xD7B0, 
-    0xE000, 0xF900, 0xFB00, 0xFB50, 0xFE00, 0xFE10, 
-    0xFE20, 0xFE30, 0xFE50, 0xFE70, 0xFF00, 0xFFF0, 
-    0x10000, 0x10080, 0x10100, 0x10140, 0x10190, 0x101D0, 0x10280, 0x102A0, 
-    0x10300, 0x10330, 0x10380, 0x103A0, 0x10400, 0x10450, 0x10480, 0x10800, 
-    0x10840, 0x10900, 0x10920, 0x10A00, 0x10A60, 0x10B00, 0x10B40, 0x10B60, 
-    0x10C00, 0x10E60, 0x11080, 0x12000, 0x12400, 0x13000, 0x1D000, 0x1D100, 
-    0x1D200, 0x1D300, 0x1D360, 0x1D400, 0x1F000, 0x1F030, 0x1F100, 0x1F200, 
-    0x20000, 0x2A700, 0x2F800, 0xE0000, 0xE0100, 0xF0000, 0x100000
-  };
-  
-  private static final int[] blockEnds = {
-    0x007F, 0x00FF, 0x017F, 0x024F, 0x02AF, 0x02FF, 0x036F, 0x03FF, 0x04FF, 
-    0x052F, 0x058F, 0x05FF, 0x06FF, 0x074F, 0x077F, 0x07BF, 0x07FF, 0x083F, 
-    0x097F, 0x09FF, 0x0A7F, 0x0AFF, 0x0B7F, 0x0BFF, 0x0C7F, 0x0CFF, 0x0D7F, 
-    0x0DFF, 0x0E7F, 0x0EFF, 0x0FFF, 0x109F, 0x10FF, 0x11FF, 0x137F, 0x139F, 
-    0x13FF, 0x167F, 0x169F, 0x16FF, 0x171F, 0x173F, 0x175F, 0x177F, 0x17FF, 
-    0x18AF, 0x18FF, 0x194F, 0x197F, 0x19DF, 0x19FF, 0x1A1F, 0x1AAF, 0x1B7F, 
-    0x1BBF, 0x1C4F, 0x1C7F, 0x1CFF, 0x1D7F, 0x1DBF, 0x1DFF, 0x1EFF, 0x1FFF, 
-    0x206F, 0x209F, 0x20CF, 0x20FF, 0x214F, 0x218F, 0x21FF, 0x22FF, 0x23FF, 
-    0x243F, 0x245F, 0x24FF, 0x257F, 0x259F, 0x25FF, 0x26FF, 0x27BF, 0x27EF, 
-    0x27FF, 0x28FF, 0x297F, 0x29FF, 0x2AFF, 0x2BFF, 0x2C5F, 0x2C7F, 0x2CFF, 
-    0x2D2F, 0x2D7F, 0x2DDF, 0x2DFF, 0x2E7F, 0x2EFF, 0x2FDF, 0x2FFF, 0x303F, 
-    0x309F, 0x30FF, 0x312F, 0x318F, 0x319F, 0x31BF, 0x31EF, 0x31FF, 0x32FF, 
-    0x33FF, 0x4DBF, 0x4DFF, 0x9FFF, 0xA48F, 0xA4CF, 0xA4FF, 0xA63F, 0xA69F, 
-    0xA6FF, 0xA71F, 0xA7FF, 0xA82F, 0xA83F, 0xA87F, 0xA8DF, 0xA8FF, 0xA92F, 
-    0xA95F, 0xA97F, 0xA9DF, 0xAA5F, 0xAA7F, 0xAADF, 0xABFF, 0xD7AF, 0xD7FF, 
-    0xF8FF, 0xFAFF, 0xFB4F, 0xFDFF, 0xFE0F, 0xFE1F, 
-    0xFE2F, 0xFE4F, 0xFE6F, 0xFEFF, 0xFFEF, 0xFFFF, 
-    0x1007F, 0x100FF, 0x1013F, 0x1018F, 0x101CF, 0x101FF, 0x1029F, 0x102DF, 
-    0x1032F, 0x1034F, 0x1039F, 0x103DF, 0x1044F, 0x1047F, 0x104AF, 0x1083F, 
-    0x1085F, 0x1091F, 0x1093F, 0x10A5F, 0x10A7F, 0x10B3F, 0x10B5F, 0x10B7F, 
-    0x10C4F, 0x10E7F, 0x110CF, 0x123FF, 0x1247F, 0x1342F, 0x1D0FF, 0x1D1FF, 
-    0x1D24F, 0x1D35F, 0x1D37F, 0x1D7FF, 0x1F02F, 0x1F09F, 0x1F1FF, 0x1F2FF, 
-    0x2A6DF, 0x2B73F, 0x2FA1F, 0xE007F, 0xE01EF, 0xFFFFF, 0x10FFFF
-  };
-  
-  /** Returns random string of length between 0-20 codepoints, all codepoints within the same unicode block. */
-  public static String randomRealisticUnicodeString(Random r) {
-    return randomRealisticUnicodeString(r, 20);
-  }
-  
-  /** Returns random string of length up to maxLength codepoints , all codepoints within the same unicode block. */
-  public static String randomRealisticUnicodeString(Random r, int maxLength) {
-    return randomRealisticUnicodeString(r, 0, maxLength);
-  }
-
-  /** Returns random string of length between min and max codepoints, all codepoints within the same unicode block. */
-  public static String randomRealisticUnicodeString(Random r, int minLength, int maxLength) {
-    final int end = nextInt(r, minLength, maxLength);
-    final int block = r.nextInt(blockStarts.length);
-    StringBuilder sb = new StringBuilder();
-    for (int i = 0; i < end; i++)
-      sb.appendCodePoint(nextInt(r, blockStarts[block], blockEnds[block]));
-    return sb.toString();
-  }
-  
-  /** Returns random string, with a given UTF-8 byte length*/
-  public static String randomFixedByteLengthUnicodeString(Random r, int length) {
-    
-    final char[] buffer = new char[length*3];
-    int bytes = length;
-    int i = 0;
-    for (; i < buffer.length && bytes != 0; i++) {
-      int t;
-      if (bytes >= 4) {
-        t = r.nextInt(5);
-      } else if (bytes >= 3) {
-        t = r.nextInt(4);
-      } else if (bytes >= 2) {
-        t = r.nextInt(2);
-      } else {
-        t = 0;
-      }
-      if (t == 0) {
-        buffer[i] = (char) r.nextInt(0x80);
-        bytes--;
-      } else if (1 == t) {
-        buffer[i] = (char) nextInt(r, 0x80, 0x7ff);
-        bytes -= 2;
-      } else if (2 == t) {
-        buffer[i] = (char) nextInt(r, 0x800, 0xd7ff);
-        bytes -= 3;
-      } else if (3 == t) {
-        buffer[i] = (char) nextInt(r, 0xe000, 0xffff);
-        bytes -= 3;
-      } else if (4 == t) {
-        // Make a surrogate pair
-        // High surrogate
-        buffer[i++] = (char) nextInt(r, 0xd800, 0xdbff);
-        // Low surrogate
-        buffer[i] = (char) nextInt(r, 0xdc00, 0xdfff);
-        bytes -= 4;
-      }
-
-    }
-    return new String(buffer, 0, i);
-  }
-
-  
-  /** Return a Codec that can read any of the
-   *  default codecs and formats, but always writes in the specified
-   *  format. */
-  public static Codec alwaysPostingsFormat(final PostingsFormat format) {
-    // TODO: we really need for postings impls etc to announce themselves
-    // (and maybe their params, too) to infostream on flush and merge.
-    // otherwise in a real debugging situation we won't know whats going on!
-    if (LuceneTestCase.VERBOSE) {
-      System.out.println("forcing postings format to:" + format);
-    }
-    return new Lucene46Codec() {
-      @Override
-      public PostingsFormat getPostingsFormatForField(String field) {
-        return format;
-      }
-    };
-  }
-  
-  /** Return a Codec that can read any of the
-   *  default codecs and formats, but always writes in the specified
-   *  format. */
-  public static Codec alwaysDocValuesFormat(final DocValuesFormat format) {
-    // TODO: we really need for docvalues impls etc to announce themselves
-    // (and maybe their params, too) to infostream on flush and merge.
-    // otherwise in a real debugging situation we won't know whats going on!
-    if (LuceneTestCase.VERBOSE) {
-      System.out.println("forcing docvalues format to:" + format);
-    }
-    return new Lucene46Codec() {
-      @Override
-      public DocValuesFormat getDocValuesFormatForField(String field) {
-        return format;
-      }
-    };
-  }
-
-  // TODO: generalize all 'test-checks-for-crazy-codecs' to
-  // annotations (LUCENE-3489)
-  public static String getPostingsFormat(String field) {
-    return getPostingsFormat(Codec.getDefault(), field);
-  }
-  
-  public static String getPostingsFormat(Codec codec, String field) {
-    PostingsFormat p = codec.postingsFormat();
-    if (p instanceof PerFieldPostingsFormat) {
-      return ((PerFieldPostingsFormat)p).getPostingsFormatForField(field).getName();
-    } else {
-      return p.getName();
-    }
-  }
-
-  public static String getDocValuesFormat(String field) {
-    return getDocValuesFormat(Codec.getDefault(), field);
-  }
-  
-  public static String getDocValuesFormat(Codec codec, String field) {
-    DocValuesFormat f = codec.docValuesFormat();
-    if (f instanceof PerFieldDocValuesFormat) {
-      return ((PerFieldDocValuesFormat) f).getDocValuesFormatForField(field).getName();
-    } else {
-      return f.getName();
-    }
-  }
-
-  // TODO: remove this, push this test to Lucene40/Lucene42 codec tests
-  public static boolean fieldSupportsHugeBinaryDocValues(String field) {
-    String dvFormat = getDocValuesFormat(field);
-    if (dvFormat.equals("Lucene40") || dvFormat.equals("Lucene42") || dvFormat.equals("Memory")) {
-      return false;
-    }
-    return true;
-  }
-
-  public static boolean anyFilesExceptWriteLock(Directory dir) throws IOException {
-    String[] files = dir.listAll();
-    if (files.length > 1 || (files.length == 1 && !files[0].equals("write.lock"))) {
-      return true;
-    } else {
-      return false;
-    }
-  }
-
-  /** just tries to configure things to keep the open file
-   * count lowish */
-  public static void reduceOpenFiles(IndexWriter w) {
-    // keep number of open files lowish
-    MergePolicy mp = w.getConfig().getMergePolicy();
-    if (mp instanceof LogMergePolicy) {
-      LogMergePolicy lmp = (LogMergePolicy) mp;
-      lmp.setMergeFactor(Math.min(5, lmp.getMergeFactor()));
-      lmp.setNoCFSRatio(1.0);
-    } else if (mp instanceof TieredMergePolicy) {
-      TieredMergePolicy tmp = (TieredMergePolicy) mp;
-      tmp.setMaxMergeAtOnce(Math.min(5, tmp.getMaxMergeAtOnce()));
-      tmp.setSegmentsPerTier(Math.min(5, tmp.getSegmentsPerTier()));
-      tmp.setNoCFSRatio(1.0);
-    }
-    MergeScheduler ms = w.getConfig().getMergeScheduler();
-    if (ms instanceof ConcurrentMergeScheduler) {
-      // wtf... shouldnt it be even lower since its 1 by default?!?!
-      ((ConcurrentMergeScheduler) ms).setMaxMergesAndThreads(3, 2);
-    }
-  }
-
-  /** Checks some basic behaviour of an AttributeImpl
-   * @param reflectedValues contains a map with "AttributeClass#key" as values
-   */
-  public static <T> void assertAttributeReflection(final AttributeImpl att, Map<String,T> reflectedValues) {
-    final Map<String,Object> map = new HashMap<String,Object>();
-    att.reflectWith(new AttributeReflector() {
-      @Override
-      public void reflect(Class<? extends Attribute> attClass, String key, Object value) {
-        map.put(attClass.getName() + '#' + key, value);
-      }
-    });
-    Assert.assertEquals("Reflection does not produce same map", reflectedValues, map);
-  }
-  
-  /** 
-   * insecure, fast version of File.createTempFile
-   * uses Random instead of SecureRandom.
-   */
-  public static File createTempFile(String prefix, String suffix, File directory)
-      throws IOException {
-    if (prefix.length() < 3) {
-      throw new IllegalArgumentException("prefix must be at least 3 characters");
-    }
-    String newSuffix = suffix == null ? ".tmp" : suffix;
-    // always pull a long from master random. that way, the randomness of the test
-    // is not affected by whether it initialized the counter (in genTempFile) or not.
-    // note that the Random used by genTempFile is *not* the master Random, and therefore
-    // does not affect the randomness of the test.
-    final Random random = new Random(RandomizedContext.current().getRandom().nextLong());
-    File result;
-    do {
-      result = genTempFile(random, prefix, newSuffix, directory);
-    } while (!result.createNewFile());
-    return result;
-  }
-
-  /* identify for differnt VM processes */
-  private static String counterBase;
-  
-  /* Temp file counter */
-  private static int counter;
-  private static final Object counterLock = new Object();
-
-  private static File genTempFile(Random random, String prefix, String suffix, File directory) {
-    final int identify;
-    synchronized (counterLock) {
-      if (counterBase == null) { // init once
-        counter = random.nextInt() & 0xFFFF; // up to five digits number
-        counterBase = Integer.toString(counter);
-      }
-      identify = counter++;
-    }
-    StringBuilder newName = new StringBuilder();
-    newName.append(prefix);
-    newName.append(counterBase);
-    newName.append(identify);
-    newName.append(suffix);
-    return new File(directory, newName.toString());
-  }
-
-  public static void assertEquals(TopDocs expected, TopDocs actual) {
-    Assert.assertEquals("wrong total hits", expected.totalHits, actual.totalHits);
-    Assert.assertEquals("wrong maxScore", expected.getMaxScore(), actual.getMaxScore(), 0.0);
-    Assert.assertEquals("wrong hit count", expected.scoreDocs.length, actual.scoreDocs.length);
-    for(int hitIDX=0;hitIDX<expected.scoreDocs.length;hitIDX++) {
-      final ScoreDoc expectedSD = expected.scoreDocs[hitIDX];
-      final ScoreDoc actualSD = actual.scoreDocs[hitIDX];
-      Assert.assertEquals("wrong hit docID", expectedSD.doc, actualSD.doc);
-      Assert.assertEquals("wrong hit score", expectedSD.score, actualSD.score, 0.0);
-      if (expectedSD instanceof FieldDoc) {
-        Assert.assertTrue(actualSD instanceof FieldDoc);
-        Assert.assertArrayEquals("wrong sort field values",
-                            ((FieldDoc) expectedSD).fields,
-                            ((FieldDoc) actualSD).fields);
-      } else {
-        Assert.assertFalse(actualSD instanceof FieldDoc);
-      }
-    }
-  }
-
-  // NOTE: this is likely buggy, and cannot clone fields
-  // with tokenStreamValues, etc.  Use at your own risk!!
-
-  // TODO: is there a pre-existing way to do this!!!
-  public static Document cloneDocument(Document doc1) {
-    final Document doc2 = new Document();
-    for(IndexableField f : doc1.getFields()) {
-      final Field field1 = (Field) f;
-      final Field field2;
-      final DocValuesType dvType = field1.fieldType().docValueType();
-      final NumericType numType = field1.fieldType().numericType();
-      if (dvType != null) {
-        switch(dvType) {
-          case NUMERIC:
-            field2 = new NumericDocValuesField(field1.name(), field1.numericValue().longValue());
-            break;
-          case BINARY:
-            field2 = new BinaryDocValuesField(field1.name(), field1.binaryValue());
-          break;
-          case SORTED:
-            field2 = new SortedDocValuesField(field1.name(), field1.binaryValue());
-            break;
-          default:
-            throw new IllegalStateException("unknown Type: " + dvType);
-        }
-      } else if (numType != null) {
-        switch (numType) {
-          case INT:
-            field2 = new IntField(field1.name(), field1.numericValue().intValue(), field1.fieldType());
-            break;
-          case FLOAT:
-            field2 = new FloatField(field1.name(), field1.numericValue().intValue(), field1.fieldType());
-            break;
-          case LONG:
-            field2 = new LongField(field1.name(), field1.numericValue().intValue(), field1.fieldType());
-            break;
-          case DOUBLE:
-            field2 = new DoubleField(field1.name(), field1.numericValue().intValue(), field1.fieldType());
-            break;
-          default:
-            throw new IllegalStateException("unknown Type: " + numType);
-        }
-      } else {
-        field2 = new Field(field1.name(), field1.stringValue(), field1.fieldType());
-      }
-      doc2.add(field2);
-    }
-
-    return doc2;
-  }
-
-  // Returns a DocsEnum, but randomly sometimes uses a
-  // DocsAndFreqsEnum, DocsAndPositionsEnum.  Returns null
-  // if field/term doesn't exist:
-  public static DocsEnum docs(Random random, IndexReader r, String field, BytesRef term, Bits liveDocs, DocsEnum reuse, int flags) throws IOException {
-    final Terms terms = MultiFields.getTerms(r, field);
-    if (terms == null) {
-      return null;
-    }
-    final TermsEnum termsEnum = terms.iterator(null);
-    if (!termsEnum.seekExact(term)) {
-      return null;
-    }
-    return docs(random, termsEnum, liveDocs, reuse, flags);
-  }
-
-  // Returns a DocsEnum from a positioned TermsEnum, but
-  // randomly sometimes uses a DocsAndFreqsEnum, DocsAndPositionsEnum.
-  public static DocsEnum docs(Random random, TermsEnum termsEnum, Bits liveDocs, DocsEnum reuse, int flags) throws IOException {
-    if (random.nextBoolean()) {
-      if (random.nextBoolean()) {
-        final int posFlags;
-        switch (random.nextInt(4)) {
-          case 0: posFlags = 0; break;
-          case 1: posFlags = DocsAndPositionsEnum.FLAG_OFFSETS; break;
-          case 2: posFlags = DocsAndPositionsEnum.FLAG_PAYLOADS; break;
-          default: posFlags = DocsAndPositionsEnum.FLAG_OFFSETS | DocsAndPositionsEnum.FLAG_PAYLOADS; break;
-        }
-        // TODO: cast to DocsAndPositionsEnum?
-        DocsAndPositionsEnum docsAndPositions = termsEnum.docsAndPositions(liveDocs, null, posFlags);
-        if (docsAndPositions != null) {
-          return docsAndPositions;
-        }
-      }
-      flags |= DocsEnum.FLAG_FREQS;
-    }
-    return termsEnum.docs(liveDocs, reuse, flags);
-  }
-  
-  public static CharSequence stringToCharSequence(String string, Random random) {
-    return bytesToCharSequence(new BytesRef(string), random);
-  }
-  
-  public static CharSequence bytesToCharSequence(BytesRef ref, Random random) {
-    switch(random.nextInt(5)) {
-    case 4:
-      CharsRef chars = new CharsRef(ref.length);
-      UnicodeUtil.UTF8toUTF16(ref.bytes, ref.offset, ref.length, chars);
-      return chars;
-    case 3:
-      return CharBuffer.wrap(ref.utf8ToString());
-    default:
-      return ref.utf8ToString();
-    }
-  }
-
-  /**
-   * Shutdown {@link ExecutorService} and wait for its.
-   */
-  public static void shutdownExecutorService(ExecutorService ex) {
-    if (ex != null) {
-      try {
-        ex.shutdown();
-        ex.awaitTermination(1, TimeUnit.SECONDS);
-      } catch (InterruptedException e) {
-        // Just report it on the syserr.
-        System.err.println("Could not properly shutdown executor service.");
-        e.printStackTrace(System.err);
-      }
-    }
-  }
-
-  /**
-   * Returns a valid (compiling) Pattern instance with random stuff inside. Be careful
-   * when applying random patterns to longer strings as certain types of patterns
-   * may explode into exponential times in backtracking implementations (such as Java's).
-   */
-  public static Pattern randomPattern(Random random) {
-    final String nonBmpString = "AB\uD840\uDC00C";
-    while (true) {
-      try {
-        Pattern p = Pattern.compile(_TestUtil.randomRegexpishString(random));
-        String replacement = null;
-        // ignore bugs in Sun's regex impl
-        try {
-          replacement = p.matcher(nonBmpString).replaceAll("_");
-        } catch (StringIndexOutOfBoundsException jdkBug) {
-          System.out.println("WARNING: your jdk is buggy!");
-          System.out.println("Pattern.compile(\"" + p.pattern() + 
-              "\").matcher(\"AB\\uD840\\uDC00C\").replaceAll(\"_\"); should not throw IndexOutOfBounds!");
-        }
-        // Make sure the result of applying the pattern to a string with extended
-        // unicode characters is a valid utf16 string. See LUCENE-4078 for discussion.
-        if (replacement != null && UnicodeUtil.validUTF16String(replacement)) {
-          return p;
-        }
-      } catch (PatternSyntaxException ignored) {
-        // Loop trying until we hit something that compiles.
-      }
-    }
-  }
-    
-  
-  public static final FilterStrategy randomFilterStrategy(final Random random) {
-    switch(random.nextInt(6)) {
-      case 5:
-      case 4:
-        return new FilteredQuery.RandomAccessFilterStrategy() {
-          @Override
-          protected boolean useRandomAccess(Bits bits, int firstFilterDoc) {
-            return LuceneTestCase.random().nextBoolean();
-          }
-        };
-      case 3:
-        return FilteredQuery.RANDOM_ACCESS_FILTER_STRATEGY;
-      case 2:
-        return FilteredQuery.LEAP_FROG_FILTER_FIRST_STRATEGY;
-      case 1:
-        return FilteredQuery.LEAP_FROG_QUERY_FIRST_STRATEGY;
-      case 0: 
-        return FilteredQuery.QUERY_FIRST_FILTER_STRATEGY;
-      default:
-        return FilteredQuery.RANDOM_ACCESS_FILTER_STRATEGY;
-    }
-  }
-
-  /**
-   * Returns a random string in the specified length range consisting 
-   * entirely of whitespace characters 
-   * @see #WHITESPACE_CHARACTERS
-   */
-  public static String randomWhitespace(Random r, int minLength, int maxLength) {
-    final int end = nextInt(r, minLength, maxLength);
-    StringBuilder out = new StringBuilder();
-    for (int i = 0; i < end; i++) {
-      int offset = nextInt(r, 0, WHITESPACE_CHARACTERS.length-1);
-      char c = WHITESPACE_CHARACTERS[offset];
-      // sanity check
-      Assert.assertTrue("Not really whitespace? (@"+offset+"): " + c, Character.isWhitespace(c));
-      out.append(c);
-    }
-    return out.toString();
-  }
-
-  public static String randomAnalysisString(Random random, int maxLength, boolean simple) {
-    assert maxLength >= 0;
-
-    // sometimes just a purely random string
-    if (random.nextInt(31) == 0) {
-      return randomSubString(random, random.nextInt(maxLength), simple);
-    }
-
-    // otherwise, try to make it more realistic with 'words' since most tests use MockTokenizer
-    // first decide how big the string will really be: 0..n
-    maxLength = random.nextInt(maxLength);
-    int avgWordLength = _TestUtil.nextInt(random, 3, 8);
-    StringBuilder sb = new StringBuilder();
-    while (sb.length() < maxLength) {
-      if (sb.length() > 0) {
-        sb.append(' ');
-      }
-      int wordLength = -1;
-      while (wordLength < 0) {
-        wordLength = (int) (random.nextGaussian() * 3 + avgWordLength);
-      }
-      wordLength = Math.min(wordLength, maxLength - sb.length());
-      sb.append(randomSubString(random, wordLength, simple));
-    }
-    return sb.toString();
-  }
-
-  public static String randomSubString(Random random, int wordLength, boolean simple) {
-    if (wordLength == 0) {
-      return "";
-    }
-
-    int evilness = _TestUtil.nextInt(random, 0, 20);
-
-    StringBuilder sb = new StringBuilder();
-    while (sb.length() < wordLength) {;
-      if (simple) {
-        sb.append(random.nextBoolean() ? _TestUtil.randomSimpleString(random, wordLength) : _TestUtil.randomHtmlishString(random, wordLength));
-      } else {
-        if (evilness < 10) {
-          sb.append(_TestUtil.randomSimpleString(random, wordLength));
-        } else if (evilness < 15) {
-          assert sb.length() == 0; // we should always get wordLength back!
-          sb.append(_TestUtil.randomRealisticUnicodeString(random, wordLength, wordLength));
-        } else if (evilness == 16) {
-          sb.append(_TestUtil.randomHtmlishString(random, wordLength));
-        } else if (evilness == 17) {
-          // gives a lot of punctuation
-          sb.append(_TestUtil.randomRegexpishString(random, wordLength));
-        } else {
-          sb.append(_TestUtil.randomUnicodeString(random, wordLength));
-        }
-      }
-    }
-    if (sb.length() > wordLength) {
-      sb.setLength(wordLength);
-      if (Character.isHighSurrogate(sb.charAt(wordLength-1))) {
-        sb.setLength(wordLength-1);
-      }
-    }
-
-    if (random.nextInt(17) == 0) {
-      // mix up case
-      String mixedUp = _TestUtil.randomlyRecaseCodePoints(random, sb.toString());
-      assert mixedUp.length() == sb.length();
-      return mixedUp;
-    } else {
-      return sb.toString();
-    }
-  }
-  
-  /** List of characters that match {@link Character#isWhitespace} */
-  public static final char[] WHITESPACE_CHARACTERS = new char[] {
-    // :TODO: is this list exhaustive?
-    '\u0009',
-    '\n',    
-    '\u000B',
-    '\u000C',
-    '\r',    
-    '\u001C',
-    '\u001D',
-    '\u001E',
-    '\u001F',
-    '\u0020',
-    // '\u0085', faild sanity check?
-    '\u1680',
-    '\u180E',
-    '\u2000',
-    '\u2001',
-    '\u2002',
-    '\u2003',
-    '\u2004',
-    '\u2005',
-    '\u2006',
-    '\u2008',
-    '\u2009',
-    '\u200A',
-    '\u2028',
-    '\u2029',
-    '\u205F',
-    '\u3000',
-  };
-}
diff --git a/lucene/test-framework/src/java/org/apache/lucene/util/automaton/AutomatonTestUtil.java b/lucene/test-framework/src/java/org/apache/lucene/util/automaton/AutomatonTestUtil.java
index e770a69..67f5eaa 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/util/automaton/AutomatonTestUtil.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/util/automaton/AutomatonTestUtil.java
@@ -28,8 +28,8 @@ import java.util.Random;
 import java.util.Set;
 
 import org.apache.lucene.util.ArrayUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.UnicodeUtil;
-import org.apache.lucene.util._TestUtil;
 
 /**
  * Utilities for testing automata.
@@ -65,14 +65,14 @@ public class AutomatonTestUtil {
       if (0 == t && i < end - 1) {
         // Make a surrogate pair
         // High surrogate
-        buffer[i++] = (char) _TestUtil.nextInt(r, 0xd800, 0xdbff);
+        buffer[i++] = (char) TestUtil.nextInt(r, 0xd800, 0xdbff);
         // Low surrogate
-        buffer[i] = (char) _TestUtil.nextInt(r, 0xdc00, 0xdfff);
+        buffer[i] = (char) TestUtil.nextInt(r, 0xdc00, 0xdfff);
       }
       else if (t <= 1) buffer[i] = (char) r.nextInt(0x80);
-      else if (2 == t) buffer[i] = (char) _TestUtil.nextInt(r, 0x80, 0x800);
-      else if (3 == t) buffer[i] = (char) _TestUtil.nextInt(r, 0x800, 0xd7ff);
-      else if (4 == t) buffer[i] = (char) _TestUtil.nextInt(r, 0xe000, 0xffff);
+      else if (2 == t) buffer[i] = (char) TestUtil.nextInt(r, 0x80, 0x800);
+      else if (3 == t) buffer[i] = (char) TestUtil.nextInt(r, 0x800, 0xd7ff);
+      else if (4 == t) buffer[i] = (char) TestUtil.nextInt(r, 0xe000, 0xffff);
       else if (5 == t) buffer[i] = '.';
       else if (6 == t) buffer[i] = '?';
       else if (7 == t) buffer[i] = '*';
diff --git a/lucene/test-framework/src/java/org/apache/lucene/util/fst/FSTTester.java b/lucene/test-framework/src/java/org/apache/lucene/util/fst/FSTTester.java
index b68e97f..bf5c8ac 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/util/fst/FSTTester.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/util/fst/FSTTester.java
@@ -38,8 +38,8 @@ import org.apache.lucene.store.IndexOutput;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IntsRef;
 import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.UnicodeUtil;
-import org.apache.lucene.util._TestUtil;
 import org.apache.lucene.util.packed.PackedInts;
 
 import static org.junit.Assert.assertEquals;
@@ -97,7 +97,7 @@ public class FSTTester<T> {
   static String getRandomString(Random random) {
     final String term;
     if (random.nextBoolean()) {
-      term = _TestUtil.randomRealisticUnicodeString(random);
+      term = TestUtil.randomRealisticUnicodeString(random);
     } else {
       // we want to mix in limited-alphabet symbols so
       // we get more sharing of the nodes given how few
@@ -115,7 +115,7 @@ public class FSTTester<T> {
     }
     final char[] buffer = new char[end];
     for (int i = 0; i < end; i++) {
-      buffer[i] = (char) _TestUtil.nextInt(r, 97, 102);
+      buffer[i] = (char) TestUtil.nextInt(r, 97, 102);
     }
     return new String(buffer, 0, end);
   }
@@ -188,10 +188,10 @@ public class FSTTester<T> {
 
     if (testPruning) {
       // simple pruning
-      doTest(_TestUtil.nextInt(random, 1, 1+pairs.size()), 0, true);
+      doTest(TestUtil.nextInt(random, 1, 1 + pairs.size()), 0, true);
         
       // leafy pruning
-      doTest(0, _TestUtil.nextInt(random, 1, 1+pairs.size()), true);
+      doTest(0, TestUtil.nextInt(random, 1, 1 + pairs.size()), true);
     }
   }
 
@@ -285,7 +285,7 @@ public class FSTTester<T> {
                                               prune1, prune2,
                                               prune1==0 && prune2==0,
                                               allowRandomSuffixSharing ? random.nextBoolean() : true,
-                                              allowRandomSuffixSharing ? _TestUtil.nextInt(random, 1, 10) : Integer.MAX_VALUE,
+                                              allowRandomSuffixSharing ? TestUtil.nextInt(random, 1, 10) : Integer.MAX_VALUE,
                                               outputs,
                                               null,
                                               willRewrite,
@@ -434,7 +434,7 @@ public class FSTTester<T> {
 
       final int num = LuceneTestCase.atLeast(random, 100);
       for(int iter=0;iter<num;iter++) {
-        Long v = _TestUtil.nextLong(random, minLong, maxLong);
+        Long v = TestUtil.nextLong(random, minLong, maxLong);
         IntsRef input = Util.getByOutput(fstLong, v);
         assertTrue(validOutputs.contains(v) || input == null);
       }
diff --git a/solr/core/src/test/org/apache/solr/CursorPagingTest.java b/solr/core/src/test/org/apache/solr/CursorPagingTest.java
index 836f0f2..bc25227 100644
--- a/solr/core/src/test/org/apache/solr/CursorPagingTest.java
+++ b/solr/core/src/test/org/apache/solr/CursorPagingTest.java
@@ -17,7 +17,7 @@
 
 package org.apache.solr;
 
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.SentinelIntSet;
 import org.apache.lucene.util.mutable.MutableValueInt;
 import org.apache.solr.core.SolrInfoMBean;
@@ -529,7 +529,7 @@ public class CursorPagingTest extends SolrTestCaseJ4 {
 
     SentinelIntSet ids = assertFullWalkNoDups
       (10, params("q", "*:*",
-                  "rows",""+_TestUtil.nextInt(random(),1,11),
+                  "rows",""+ TestUtil.nextInt(random(), 1, 11),
                   "fq", "-id:[1 TO 2]",
                   "fq", "-id:[6 TO 7]",
                   "fl", "id",
@@ -553,7 +553,7 @@ public class CursorPagingTest extends SolrTestCaseJ4 {
   public void testRandomSortsOnLargeIndex() throws Exception {
     final Collection<String> allFieldNames = getAllSortFieldNames();
 
-    final int initialDocs = _TestUtil.nextInt(random(),100,200);
+    final int initialDocs = TestUtil.nextInt(random(), 100, 200);
     final int totalDocs = atLeast(5000);
 
     // start with a smallish number of documents, and test that we can do a full walk using a 
@@ -568,7 +568,7 @@ public class CursorPagingTest extends SolrTestCaseJ4 {
     for (String f : allFieldNames) {
       for (String order : new String[] {" asc", " desc"}) {
         String sort = f + order + ("id".equals(f) ? "" : ", id" + order);
-        String rows = "" + _TestUtil.nextInt(random(),13,50);
+        String rows = "" + TestUtil.nextInt(random(), 13, 50);
         SentinelIntSet ids = assertFullWalkNoDups(totalDocs, 
                                                   params("q", "*:*",
                                                          "fl","id",
@@ -588,7 +588,7 @@ public class CursorPagingTest extends SolrTestCaseJ4 {
     final int numRandomSorts = atLeast(5);
     for (int i = 0; i < numRandomSorts; i++) {
       final String sort = buildRandomSort(allFieldNames);
-      final String rows = "" + _TestUtil.nextInt(random(),63,113);
+      final String rows = "" + TestUtil.nextInt(random(), 63, 113);
       final String fl = random().nextBoolean() ? "id" : "id,score";
       final boolean matchAll = random().nextBoolean();
       final String q = matchAll ? "*:*" : buildRandomQuery();
@@ -609,12 +609,12 @@ public class CursorPagingTest extends SolrTestCaseJ4 {
    * of test multiplier and nightly status 
    */
   private static boolean useField() {
-    return 0 != _TestUtil.nextInt(random(), 0, 30);
+    return 0 != TestUtil.nextInt(random(), 0, 30);
   }
   
   /** returns likely most (1/10) of the time, otherwise unlikely */
   private static Object skewed(Object likely, Object unlikely) {
-    return (0 == _TestUtil.nextInt(random(), 0, 9)) ? unlikely : likely;
+    return (0 == TestUtil.nextInt(random(), 0, 9)) ? unlikely : likely;
   }
   
   /**
@@ -710,7 +710,7 @@ public class CursorPagingTest extends SolrTestCaseJ4 {
    * test faceting with deep paging
    */
   public void testFacetingWithRandomSorts() throws Exception {
-    final int numDocs = _TestUtil.nextInt(random(), 1000, 3000);
+    final int numDocs = TestUtil.nextInt(random(), 1000, 3000);
     String[] fieldsToFacetOn = { "int", "long", "str" };
     String[] facetMethods = { "enum", "fc", "fcs" };
 
@@ -723,14 +723,14 @@ public class CursorPagingTest extends SolrTestCaseJ4 {
     Collection<String> allFieldNames = getAllSortFieldNames();
     String[] fieldNames = new String[allFieldNames.size()];
     allFieldNames.toArray(fieldNames);
-    String f = fieldNames[_TestUtil.nextInt(random(), 0, fieldNames.length - 1)];
-    String order = 0 == _TestUtil.nextInt(random(), 0, 1) ? " asc" : " desc";
+    String f = fieldNames[TestUtil.nextInt(random(), 0, fieldNames.length - 1)];
+    String order = 0 == TestUtil.nextInt(random(), 0, 1) ? " asc" : " desc";
     String sort = f + order + (f.equals("id") ? "" : ", id" + order);
-    String rows = "" + _TestUtil.nextInt(random(),13,50);
+    String rows = "" + TestUtil.nextInt(random(), 13, 50);
     String facetField = fieldsToFacetOn
-        [_TestUtil.nextInt(random(), 0, fieldsToFacetOn.length - 1)];
+        [TestUtil.nextInt(random(), 0, fieldsToFacetOn.length - 1)];
     String facetMethod = facetMethods
-        [_TestUtil.nextInt(random(), 0, facetMethods.length - 1)];
+        [TestUtil.nextInt(random(), 0, facetMethods.length - 1)];
     SentinelIntSet ids = assertFullWalkNoDupsWithFacets
         (numDocs, params("q", "*:*",
             "fl", "id," + facetField,
@@ -876,11 +876,11 @@ public class CursorPagingTest extends SolrTestCaseJ4 {
     // (hopefully with lots of duplication)
     if (useField()) {
       doc.addField("int", skewed(random().nextInt(), 
-                                 _TestUtil.nextInt(random(), 20, 50)));
+                                 TestUtil.nextInt(random(), 20, 50)));
     }
     if (useField()) {
       doc.addField("long", skewed(random().nextLong(), 
-                                  _TestUtil.nextInt(random(), 5000, 5100)));
+                                  TestUtil.nextInt(random(), 5000, 5100)));
     }
     if (useField()) {
       doc.addField("float", skewed(random().nextFloat() * random().nextInt(), 
@@ -892,11 +892,11 @@ public class CursorPagingTest extends SolrTestCaseJ4 {
     }
     if (useField()) {
       doc.addField("str", skewed(randomUsableUnicodeString(),
-                                 _TestUtil.randomSimpleString(random(),1,1)));
+                                 TestUtil.randomSimpleString(random(), 1, 1)));
 
     }
     if (useField()) {
-      int numBytes = (int) skewed(_TestUtil.nextInt(random(), 20, 50), 2);
+      int numBytes = (int) skewed(TestUtil.nextInt(random(), 20, 50), 2);
       byte[] randBytes = new byte[numBytes];
       random().nextBytes(randBytes);
       doc.addField("bin", ByteBuffer.wrap(randBytes));
@@ -917,8 +917,8 @@ public class CursorPagingTest extends SolrTestCaseJ4 {
       return "{!func}" + numericFields.get(0);
     } else {
       // several SHOULD clauses on range queries
-      int low = _TestUtil.nextInt(random(),-2379,2);
-      int high = _TestUtil.nextInt(random(),4,5713);
+      int low = TestUtil.nextInt(random(), -2379, 2);
+      int high = TestUtil.nextInt(random(), 4, 5713);
       return 
         numericFields.get(0) + ":[* TO 0] " +
         numericFields.get(1) + ":[0 TO *] " +
@@ -931,10 +931,10 @@ public class CursorPagingTest extends SolrTestCaseJ4 {
    * updates use XML we need to ensure we don't get "special" code block.
    */
   private static String randomUsableUnicodeString() {
-    String result = _TestUtil.randomRealisticUnicodeString(random());
+    String result = TestUtil.randomRealisticUnicodeString(random());
     if (result.matches(".*\\p{InSpecials}.*")) {
       // oh well
-      result = _TestUtil.randomSimpleString(random());
+      result = TestUtil.randomSimpleString(random());
     }
     return result;
   }
@@ -958,7 +958,7 @@ public class CursorPagingTest extends SolrTestCaseJ4 {
       // wrap in a function sometimes
       if ( (!"score".equals(field))
            && 
-           (0 == _TestUtil.nextInt(random(), 0, 7)) ) {
+           (0 == TestUtil.nextInt(random(), 0, 7)) ) {
         // specific function doesn't matter, just proving that we can handle the concept.
         // but we do have to be careful with non numeric fields
         if (field.startsWith("str") || field.startsWith("bin")) {
diff --git a/solr/core/src/test/org/apache/solr/TestHighlightDedupGrouping.java b/solr/core/src/test/org/apache/solr/TestHighlightDedupGrouping.java
index 2443757..7529dd9 100644
--- a/solr/core/src/test/org/apache/solr/TestHighlightDedupGrouping.java
+++ b/solr/core/src/test/org/apache/solr/TestHighlightDedupGrouping.java
@@ -17,7 +17,8 @@
 
 package org.apache.solr;
 
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.client.solrj.response.QueryResponse;
 import org.apache.solr.common.SolrInputDocument;
@@ -85,20 +86,20 @@ public class TestHighlightDedupGrouping extends BaseDistributedSearchTestCase {
     handle.put("timestamp", SKIPVAL);
     handle.put("grouped", UNORDERED);   // distrib grouping doesn't guarantee order of top level group commands
 
-    int numDocs = _TestUtil.nextInt(random(), 100, 1000);
-    int numGroups = _TestUtil.nextInt(random(), 1, numDocs / 50);
+    int numDocs = TestUtil.nextInt(random(), 100, 1000);
+    int numGroups = TestUtil.nextInt(random(), 1, numDocs / 50);
     int[] docsInGroup = new int[numGroups + 1];
-    int percentDuplicates = _TestUtil.nextInt(random(), 1, 25);
+    int percentDuplicates = TestUtil.nextInt(random(), 1, 25);
     for (int docid = 0 ; docid < numDocs ; ++docid) {
-      int group = _TestUtil.nextInt(random(), 1, numGroups);
+      int group = TestUtil.nextInt(random(), 1, numGroups);
       ++docsInGroup[group];
-      boolean makeDuplicate = 0 == _TestUtil.nextInt(random(), 0, numDocs / percentDuplicates);
+      boolean makeDuplicate = 0 == TestUtil.nextInt(random(), 0, numDocs / percentDuplicates);
       if (makeDuplicate) {
         for (int shard = 0 ; shard < shardCount ; ++shard) {
           addDoc(docid, group, shard);
         }
       } else {
-        int shard = _TestUtil.nextInt(random(), 0, shardCount - 1);
+        int shard = TestUtil.nextInt(random(), 0, shardCount - 1);
         addDoc(docid, group, shard);
       }
     }
diff --git a/solr/core/src/test/org/apache/solr/TestRandomDVFaceting.java b/solr/core/src/test/org/apache/solr/TestRandomDVFaceting.java
index 13a927f..9f12744 100644
--- a/solr/core/src/test/org/apache/solr/TestRandomDVFaceting.java
+++ b/solr/core/src/test/org/apache/solr/TestRandomDVFaceting.java
@@ -24,7 +24,7 @@ import java.util.Map;
 import java.util.Random;
 
 import org.apache.lucene.search.FieldCache;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.LuceneTestCase.Slow;
 import org.apache.lucene.util.LuceneTestCase.SuppressCodecs;
 import org.apache.solr.common.params.ModifiableSolrParams;
@@ -202,7 +202,7 @@ public class TestRandomDVFaceting extends SolrTestCaseJ4 {
       if ((ftype.vals instanceof SVal) && rand.nextInt(100) < 20) {
         // validate = false;
         String prefix = ftype.createValue().toString();
-        if (rand.nextInt(100) < 5) prefix =  _TestUtil.randomUnicodeString(rand);
+        if (rand.nextInt(100) < 5) prefix =  TestUtil.randomUnicodeString(rand);
         else if (rand.nextInt(100) < 10) prefix = Character.toString((char)rand.nextInt(256));
         else if (prefix.length() > 0) prefix = prefix.substring(0, rand.nextInt(prefix.length()));
         params.add("facet.prefix", prefix);
diff --git a/solr/core/src/test/org/apache/solr/TestRandomFaceting.java b/solr/core/src/test/org/apache/solr/TestRandomFaceting.java
index 04307a7..6ee53a9 100644
--- a/solr/core/src/test/org/apache/solr/TestRandomFaceting.java
+++ b/solr/core/src/test/org/apache/solr/TestRandomFaceting.java
@@ -18,7 +18,7 @@
 package org.apache.solr;
 
 import org.apache.lucene.search.FieldCache;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.LuceneTestCase.Slow;
 import org.apache.solr.common.params.ModifiableSolrParams;
 import org.apache.solr.request.SolrQueryRequest;
@@ -185,7 +185,7 @@ public class TestRandomFaceting extends SolrTestCaseJ4 {
       if ((ftype.vals instanceof SVal) && rand.nextInt(100) < 20) {
         // validate = false;
         String prefix = ftype.createValue().toString();
-        if (rand.nextInt(100) < 5) prefix =  _TestUtil.randomUnicodeString(rand);
+        if (rand.nextInt(100) < 5) prefix =  TestUtil.randomUnicodeString(rand);
         else if (rand.nextInt(100) < 10) prefix = Character.toString((char)rand.nextInt(256));
         else if (prefix.length() > 0) prefix = prefix.substring(0, rand.nextInt(prefix.length()));
         params.add("facet.prefix", prefix);
diff --git a/solr/core/src/test/org/apache/solr/analysis/LegacyHTMLStripCharFilterTest.java b/solr/core/src/test/org/apache/solr/analysis/LegacyHTMLStripCharFilterTest.java
index 218dc0e..7579acc 100644
--- a/solr/core/src/test/org/apache/solr/analysis/LegacyHTMLStripCharFilterTest.java
+++ b/solr/core/src/test/org/apache/solr/analysis/LegacyHTMLStripCharFilterTest.java
@@ -30,7 +30,7 @@ import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.MockTokenizer;
 import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.junit.Ignore;
 
 public class LegacyHTMLStripCharFilterTest extends BaseTokenStreamTestCase {
@@ -277,7 +277,7 @@ public class LegacyHTMLStripCharFilterTest extends BaseTokenStreamTestCase {
 
   public void testRandomBrokenHTML() throws Exception {
     int maxNumElements = 10000;
-    String text = _TestUtil.randomHtmlishString(random(), maxNumElements);
+    String text = TestUtil.randomHtmlishString(random(), maxNumElements);
     Reader reader
         = new LegacyHTMLStripCharFilter(new StringReader(text));
     while (reader.read() != -1);
@@ -289,18 +289,18 @@ public class LegacyHTMLStripCharFilterTest extends BaseTokenStreamTestCase {
     int maxNumWords = 10000;
     int minWordLength = 3;
     int maxWordLength = 20;
-    int numWords = _TestUtil.nextInt(random(), minNumWords, maxNumWords);
-    switch (_TestUtil.nextInt(random(), 0, 4)) {
+    int numWords = TestUtil.nextInt(random(), minNumWords, maxNumWords);
+    switch (TestUtil.nextInt(random(), 0, 4)) {
       case 0: {
         for (int wordNum = 0 ; wordNum < numWords ; ++wordNum) {
-          text.append(_TestUtil.randomUnicodeString(random(), maxWordLength));
+          text.append(TestUtil.randomUnicodeString(random(), maxWordLength));
           text.append(' ');
         }
         break;
       }
       case 1: {
         for (int wordNum = 0 ; wordNum < numWords ; ++wordNum) {
-          text.append(_TestUtil.randomRealisticUnicodeString
+          text.append(TestUtil.randomRealisticUnicodeString
               (random(), minWordLength, maxWordLength));
           text.append(' ');
         }
@@ -308,7 +308,7 @@ public class LegacyHTMLStripCharFilterTest extends BaseTokenStreamTestCase {
       }
       default: { // ASCII 50% of the time
         for (int wordNum = 0 ; wordNum < numWords ; ++wordNum) {
-          text.append(_TestUtil.randomSimpleString(random()));
+          text.append(TestUtil.randomSimpleString(random()));
           text.append(' ');
         }
       }
diff --git a/solr/core/src/test/org/apache/solr/cloud/CollectionsAPIDistributedZkTest.java b/solr/core/src/test/org/apache/solr/cloud/CollectionsAPIDistributedZkTest.java
index 32b80aa..0e7c1ff 100644
--- a/solr/core/src/test/org/apache/solr/cloud/CollectionsAPIDistributedZkTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/CollectionsAPIDistributedZkTest.java
@@ -46,7 +46,7 @@ import javax.management.MBeanServerFactory;
 import javax.management.ObjectName;
 
 import org.apache.lucene.util.LuceneTestCase.Slow;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.solr.SolrTestCaseJ4;
 import org.apache.solr.client.solrj.SolrQuery;
 import org.apache.solr.client.solrj.SolrRequest;
@@ -634,8 +634,8 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
     int cnt = random().nextInt(TEST_NIGHTLY ? 6 : 3) + 1;
     
     for (int i = 0; i < cnt; i++) {
-      int numShards = _TestUtil.nextInt(random(), 0, shardCount) + 1;
-      int replicationFactor = _TestUtil.nextInt(random(), 0, 3) + 1;
+      int numShards = TestUtil.nextInt(random(), 0, shardCount) + 1;
+      int replicationFactor = TestUtil.nextInt(random(), 0, 3) + 1;
       int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrServer()
           .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;
 
@@ -919,8 +919,8 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
         
         for (int i = 0; i < cnt; i++) {
           String collectionName = "awholynewstresscollection_" + name + "_" + i;
-          int numShards = _TestUtil.nextInt(random(), 0, shardCount * 2) + 1;
-          int replicationFactor = _TestUtil.nextInt(random(), 0, 3) + 1;
+          int numShards = TestUtil.nextInt(random(), 0, shardCount * 2) + 1;
+          int replicationFactor = TestUtil.nextInt(random(), 0, 3) + 1;
           int maxShardsPerNode = (((numShards * 2 * replicationFactor) / getCommonCloudSolrServer()
               .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;
           
diff --git a/solr/core/src/test/org/apache/solr/cloud/CustomCollectionTest.java b/solr/core/src/test/org/apache/solr/cloud/CustomCollectionTest.java
index efdc957..1a2ea93 100644
--- a/solr/core/src/test/org/apache/solr/cloud/CustomCollectionTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/CustomCollectionTest.java
@@ -38,9 +38,8 @@ import java.util.concurrent.SynchronousQueue;
 import java.util.concurrent.ThreadPoolExecutor;
 import java.util.concurrent.TimeUnit;
 
-import org.apache.lucene.util.Constants;
 import org.apache.lucene.util.LuceneTestCase.Slow;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.solr.client.solrj.SolrQuery;
 import org.apache.solr.client.solrj.SolrRequest;
 import org.apache.solr.client.solrj.SolrServerException;
@@ -57,13 +56,10 @@ import org.apache.solr.common.cloud.ZkNodeProps;
 import org.apache.solr.common.cloud.ZkStateReader;
 import org.apache.solr.common.params.CollectionParams.CollectionAction;
 import org.apache.solr.common.params.ModifiableSolrParams;
-import org.apache.solr.common.params.ShardParams;
-import org.apache.solr.common.util.NamedList;
 import org.apache.solr.update.DirectUpdateHandler2;
 import org.apache.solr.util.DefaultSolrThreadFactory;
 import org.junit.Before;
 import org.junit.BeforeClass;
-import org.junit.Ignore;
 
 /**
  * Tests the Custom Sharding API.
@@ -147,7 +143,7 @@ public class CustomCollectionTest extends AbstractFullDistribZkTestBase {
 
     // create new collections rapid fire
     Map<String,List<Integer>> collectionInfos = new HashMap<String,List<Integer>>();
-    int replicationFactor = _TestUtil.nextInt(random(), 0, 3) + 2;
+    int replicationFactor = TestUtil.nextInt(random(), 0, 3) + 2;
 
     int cnt = random().nextInt(6) + 1;
 
@@ -297,7 +293,7 @@ public class CustomCollectionTest extends AbstractFullDistribZkTestBase {
 
 
     int numShards = 4;
-    replicationFactor = _TestUtil.nextInt(random(), 0, 3) + 2;
+    replicationFactor = TestUtil.nextInt(random(), 0, 3) + 2;
     int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrServer()
         .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;
 
diff --git a/solr/core/src/test/org/apache/solr/cloud/DistribCursorPagingTest.java b/solr/core/src/test/org/apache/solr/cloud/DistribCursorPagingTest.java
index b5e61ec..e0b310a 100644
--- a/solr/core/src/test/org/apache/solr/cloud/DistribCursorPagingTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/DistribCursorPagingTest.java
@@ -17,7 +17,8 @@
 package org.apache.solr.cloud;
 
 import org.apache.lucene.util.LuceneTestCase.Slow;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.SentinelIntSet;
 import org.apache.solr.CursorPagingTest;
 import org.apache.solr.client.solrj.SolrServer;
@@ -29,7 +30,6 @@ import org.apache.solr.common.SolrDocument;
 import org.apache.solr.common.SolrDocumentList;
 import org.apache.solr.common.SolrException;
 import org.apache.solr.common.SolrException.ErrorCode;
-import org.apache.solr.common.SolrInputField;
 import org.apache.solr.common.util.NamedList;
 import org.apache.solr.common.params.SolrParams;
 import org.apache.solr.common.params.CommonParams;
@@ -46,7 +46,6 @@ import java.io.IOException;
 import java.util.List;
 import java.util.ArrayList;
 import java.util.Collection;
-import java.util.Collections;
 import java.util.Map;
 
 /**
@@ -518,7 +517,7 @@ public class DistribCursorPagingTest extends AbstractFullDistribZkTestBase {
   public void doRandomSortsOnLargeIndex() throws Exception {
     final Collection<String> allFieldNames = getAllSortFieldNames();
 
-    final int numInitialDocs = _TestUtil.nextInt(random(),100,200);
+    final int numInitialDocs = TestUtil.nextInt(random(), 100, 200);
     final int totalDocs = atLeast(5000);
 
     // start with a smallish number of documents, and test that we can do a full walk using a 
@@ -535,7 +534,7 @@ public class DistribCursorPagingTest extends AbstractFullDistribZkTestBase {
     for (String f : allFieldNames) {
       for (String order : new String[] {" asc", " desc"}) {
         String sort = f + order + ("id".equals(f) ? "" : ", id" + order);
-        String rows = "" + _TestUtil.nextInt(random(),13,50);
+        String rows = "" + TestUtil.nextInt(random(), 13, 50);
         SentinelIntSet ids = assertFullWalkNoDups(numInitialDocs,
                                                   params("q", "*:*",
                                                          "fl","id,"+f,
@@ -579,7 +578,7 @@ public class DistribCursorPagingTest extends AbstractFullDistribZkTestBase {
     final int numRandomSorts = atLeast(5);
     for (int i = 0; i < numRandomSorts; i++) {
       final String sort = CursorPagingTest.buildRandomSort(allFieldNames);
-      final String rows = "" + _TestUtil.nextInt(random(),63,113);
+      final String rows = "" + TestUtil.nextInt(random(), 63, 113);
       final String fl = random().nextBoolean() ? "id" : "id,score";
       final boolean matchAll = random().nextBoolean();
       final String q = matchAll ? "*:*" : CursorPagingTest.buildRandomQuery();
diff --git a/solr/core/src/test/org/apache/solr/core/QueryResultKeyTest.java b/solr/core/src/test/org/apache/solr/core/QueryResultKeyTest.java
index 1ffe0de..c97d500 100644
--- a/solr/core/src/test/org/apache/solr/core/QueryResultKeyTest.java
+++ b/solr/core/src/test/org/apache/solr/core/QueryResultKeyTest.java
@@ -28,7 +28,7 @@ import org.apache.lucene.search.Query;
 import org.apache.lucene.search.Sort;
 import org.apache.lucene.search.SortField;
 import org.apache.lucene.search.TermQuery;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.solr.SolrTestCaseJ4;
 import org.apache.solr.search.QueryResultKey;
 import org.junit.Test;
@@ -165,10 +165,10 @@ public class QueryResultKeyTest extends SolrTestCaseJ4 {
    * the array is garunteed to always have at least 1 element
    */
   private int[] smallArrayOfRandomNumbers() {
-    int size = _TestUtil.nextInt(random(), 1, 5);
+    int size = TestUtil.nextInt(random(), 1, 5);
     int[] result = new int[size];
     for (int i=0; i < size; i++) {
-      result[i] = _TestUtil.nextInt(random(), 1, 5);
+      result[i] = TestUtil.nextInt(random(), 1, 5);
     }
     return result;
   }
diff --git a/solr/core/src/test/org/apache/solr/core/ResourceLoaderTest.java b/solr/core/src/test/org/apache/solr/core/ResourceLoaderTest.java
index 48ac471..c9ea6d8 100644
--- a/solr/core/src/test/org/apache/solr/core/ResourceLoaderTest.java
+++ b/solr/core/src/test/org/apache/solr/core/ResourceLoaderTest.java
@@ -22,7 +22,7 @@ import junit.framework.Assert;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.core.KeywordTokenizerFactory;
 import org.apache.lucene.analysis.ngram.NGramFilterFactory;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.solr.SolrTestCaseJ4;
 import org.apache.solr.common.SolrException;
 import org.apache.solr.handler.admin.LukeRequestHandler;
@@ -60,7 +60,7 @@ public class ResourceLoaderTest extends SolrTestCaseJ4
   }
 
   public void testEscapeInstanceDir() throws Exception {
-    File temp = _TestUtil.getTempDir("testEscapeInstanceDir");
+    File temp = TestUtil.getTempDir("testEscapeInstanceDir");
     try {
       temp.mkdirs();
       new File(temp, "dummy.txt").createNewFile();
@@ -76,7 +76,7 @@ public class ResourceLoaderTest extends SolrTestCaseJ4
       }
       loader.close();
     } finally {
-      _TestUtil.rmDir(temp);
+      TestUtil.rmDir(temp);
     }
   }
 
@@ -170,7 +170,7 @@ public class ResourceLoaderTest extends SolrTestCaseJ4
   }
 
   public void testClassLoaderLibs() throws Exception {
-    File tmpRoot = _TestUtil.getTempDir("testClassLoaderLibs");
+    File tmpRoot = TestUtil.getTempDir("testClassLoaderLibs");
 
     File lib = new File(tmpRoot, "lib");
     lib.mkdirs();
diff --git a/solr/core/src/test/org/apache/solr/core/TestCoreContainer.java b/solr/core/src/test/org/apache/solr/core/TestCoreContainer.java
index b66b8f9..25d1e6a 100644
--- a/solr/core/src/test/org/apache/solr/core/TestCoreContainer.java
+++ b/solr/core/src/test/org/apache/solr/core/TestCoreContainer.java
@@ -19,7 +19,7 @@ package org.apache.solr.core;
 
 import org.apache.commons.io.FileUtils;
 import org.apache.lucene.util.IOUtils;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.solr.SolrTestCaseJ4;
 import org.apache.solr.handler.admin.CollectionsHandler;
 import org.apache.solr.handler.admin.CoreAdminHandler;
@@ -240,7 +240,7 @@ public class TestCoreContainer extends SolrTestCaseJ4 {
 
   @Test
   public void testSharedLib() throws Exception {
-    File tmpRoot = _TestUtil.getTempDir("testSharedLib");
+    File tmpRoot = TestUtil.getTempDir("testSharedLib");
 
     File lib = new File(tmpRoot, "lib");
     lib.mkdirs();
diff --git a/solr/core/src/test/org/apache/solr/core/TestSolrXMLSerializer.java b/solr/core/src/test/org/apache/solr/core/TestSolrXMLSerializer.java
index 181bd47..0443f2d 100644
--- a/solr/core/src/test/org/apache/solr/core/TestSolrXMLSerializer.java
+++ b/solr/core/src/test/org/apache/solr/core/TestSolrXMLSerializer.java
@@ -19,7 +19,7 @@ package org.apache.solr.core;
 
 import org.apache.commons.io.FileUtils;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.solr.core.SolrXMLSerializer.SolrCoreXMLDef;
 import org.apache.solr.core.SolrXMLSerializer.SolrXMLDef;
 import org.junit.Test;
@@ -81,7 +81,7 @@ public class TestSolrXMLSerializer extends LuceneTestCase {
     assertResults(((StringWriter) w).getBuffer().toString().getBytes("UTF-8"));
     
     // again with default file
-    File tmpFile = _TestUtil.createTempFile("solr.xml", null, TEMP_DIR);
+    File tmpFile = TestUtil.createTempFile("solr.xml", null, TEMP_DIR);
     
     serializer.persistFile(tmpFile, solrXMLDef);
 
diff --git a/solr/core/src/test/org/apache/solr/handler/TestCSVLoader.java b/solr/core/src/test/org/apache/solr/handler/TestCSVLoader.java
index 1f31d41..a51187c 100644
--- a/solr/core/src/test/org/apache/solr/handler/TestCSVLoader.java
+++ b/solr/core/src/test/org/apache/solr/handler/TestCSVLoader.java
@@ -17,7 +17,7 @@
 
 package org.apache.solr.handler;
 
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.solr.SolrTestCaseJ4;
 import org.apache.solr.request.LocalSolrQueryRequest;
 import org.apache.solr.common.params.CommonParams;
@@ -50,7 +50,7 @@ public class TestCSVLoader extends SolrTestCaseJ4 {
     // if you override setUp or tearDown, you better call
     // the super classes version
     super.setUp();
-    File tempDir = _TestUtil.getTempDir("TestCSVLoader");
+    File tempDir = TestUtil.getTempDir("TestCSVLoader");
     file = new File(tempDir, "solr_tmp.csv");
     filename = file.getPath();
     cleanup();
diff --git a/solr/core/src/test/org/apache/solr/schema/TestCollationField.java b/solr/core/src/test/org/apache/solr/schema/TestCollationField.java
index 08ea28a..71a5733 100644
--- a/solr/core/src/test/org/apache/solr/schema/TestCollationField.java
+++ b/solr/core/src/test/org/apache/solr/schema/TestCollationField.java
@@ -23,7 +23,7 @@ import java.text.Collator;
 import java.text.RuleBasedCollator;
 import java.util.Locale;
 
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 import org.apache.commons.io.FileUtils;
 import org.apache.commons.io.IOUtils;
@@ -63,7 +63,7 @@ public class TestCollationField extends SolrTestCaseJ4 {
    */
   public static String setupSolrHome() throws Exception {
     // make a solr home underneath the test's TEMP_DIR
-    File tmpFile = _TestUtil.getTempDir("collation1");
+    File tmpFile = TestUtil.getTempDir("collation1");
     tmpFile.delete();
     tmpFile.mkdir();
     
diff --git a/solr/core/src/test/org/apache/solr/schema/TestCollationFieldDocValues.java b/solr/core/src/test/org/apache/solr/schema/TestCollationFieldDocValues.java
index 0417fe4..a3f489e 100644
--- a/solr/core/src/test/org/apache/solr/schema/TestCollationFieldDocValues.java
+++ b/solr/core/src/test/org/apache/solr/schema/TestCollationFieldDocValues.java
@@ -23,7 +23,7 @@ import java.text.Collator;
 import java.text.RuleBasedCollator;
 import java.util.Locale;
 
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.LuceneTestCase.SuppressCodecs;
 
 import org.apache.commons.io.FileUtils;
@@ -65,7 +65,7 @@ public class TestCollationFieldDocValues extends SolrTestCaseJ4 {
    */
   public static String setupSolrHome() throws Exception {
     // make a solr home underneath the test's TEMP_DIR
-    File tmpFile = _TestUtil.getTempDir("collation1");
+    File tmpFile = TestUtil.getTempDir("collation1");
     tmpFile.delete();
     tmpFile.mkdir();
     
diff --git a/solr/core/src/test/org/apache/solr/search/CursorMarkTest.java b/solr/core/src/test/org/apache/solr/search/CursorMarkTest.java
index 89dd751..5a82298 100644
--- a/solr/core/src/test/org/apache/solr/search/CursorMarkTest.java
+++ b/solr/core/src/test/org/apache/solr/search/CursorMarkTest.java
@@ -17,7 +17,7 @@
 
 package org.apache.solr.search;
 
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.BytesRef;
 import org.apache.solr.common.SolrException;
 import org.apache.solr.common.SolrException.ErrorCode;
@@ -205,7 +205,7 @@ public class CursorMarkTest extends SolrTestCaseJ4 {
       if (null == sf) {
         // score or function
         results[i] = (Float) random().nextFloat() * random().nextInt(); break;
-      } else if (0 == _TestUtil.nextInt(random(), 0, 7)) {
+      } else if (0 == TestUtil.nextInt(random(), 0, 7)) {
         // emulate missing value for doc
         results[i] = null;
       } else {
@@ -218,11 +218,11 @@ public class CursorMarkTest extends SolrTestCaseJ4 {
 
         Object val = null;
         if (fieldName.equals("id")) {
-          val = sf.getType().unmarshalSortValue(_TestUtil.randomSimpleString(random()));
+          val = sf.getType().unmarshalSortValue(TestUtil.randomSimpleString(random()));
         } else if (fieldName.startsWith("str")) {
-          val = sf.getType().unmarshalSortValue(_TestUtil.randomRealisticUnicodeString(random()));
+          val = sf.getType().unmarshalSortValue(TestUtil.randomRealisticUnicodeString(random()));
         } else if (fieldName.startsWith("bin")) {
-          byte[] randBytes = new byte[_TestUtil.nextInt(random(), 1, 50)];
+          byte[] randBytes = new byte[TestUtil.nextInt(random(), 1, 50)];
           random().nextBytes(randBytes);
           val = new BytesRef(randBytes);
         } else if (fieldName.startsWith("int")) {
diff --git a/solr/core/src/test/org/apache/solr/search/ReturnFieldsTest.java b/solr/core/src/test/org/apache/solr/search/ReturnFieldsTest.java
index 87280b4..311816f 100644
--- a/solr/core/src/test/org/apache/solr/search/ReturnFieldsTest.java
+++ b/solr/core/src/test/org/apache/solr/search/ReturnFieldsTest.java
@@ -17,13 +17,10 @@
 
 package org.apache.solr.search;
 
+import org.apache.lucene.util.TestUtil;
 import org.apache.solr.SolrTestCaseJ4;
-import org.apache.solr.common.params.CommonParams;
-import org.apache.solr.request.SolrQueryRequest;
 import org.apache.solr.response.transform.*;
 
-import org.apache.lucene.util._TestUtil;
-
 import org.junit.BeforeClass;
 import org.junit.Test;
 
@@ -333,14 +330,14 @@ public class ReturnFieldsTest extends SolrTestCaseJ4 {
       final boolean aliasId = r.nextBoolean();
       final boolean aliasFoo = r.nextBoolean();
 
-      final String id = _TestUtil.randomWhitespace(r, 0, 3) + 
+      final String id = TestUtil.randomWhitespace(r, 0, 3) +
         (aliasId ? "aliasId:" : "") +
         "id" + 
-        _TestUtil.randomWhitespace(r, 1, 3);
-      final String foo_i = _TestUtil.randomWhitespace(r, 0, 3) + 
+        TestUtil.randomWhitespace(r, 1, 3);
+      final String foo_i = TestUtil.randomWhitespace(r, 0, 3) +
         (aliasFoo ? "aliasFoo:" : "") +
         "foo_i" + 
-        _TestUtil.randomWhitespace(r, 0, 3);
+        TestUtil.randomWhitespace(r, 0, 3);
 
       final String fl = id + (r.nextBoolean() ? "" : ",") + foo_i;
       ReturnFields rf = new SolrReturnFields(req("fl", fl));
diff --git a/solr/core/src/test/org/apache/solr/search/TestSort.java b/solr/core/src/test/org/apache/solr/search/TestSort.java
index 9c60935..520ee73 100644
--- a/solr/core/src/test/org/apache/solr/search/TestSort.java
+++ b/solr/core/src/test/org/apache/solr/search/TestSort.java
@@ -49,7 +49,7 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.RAMDirectory;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.FixedBitSet;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.solr.SolrTestCaseJ4;
 import org.apache.solr.request.SolrQueryRequest;
 import org.apache.solr.schema.SchemaField;
@@ -96,12 +96,12 @@ public class TestSort extends SolrTestCaseJ4 {
 
     for (int i = 0; i < iters; i++) {
       final StringBuilder input = new StringBuilder();
-      final String[] names = new String[_TestUtil.nextInt(r,1,10)];
+      final String[] names = new String[TestUtil.nextInt(r, 1, 10)];
       final boolean[] reverse = new boolean[names.length];
       for (int j = 0; j < names.length; j++) {
         names[j] = null;
         for (int k = 0; k < nonBlankAttempts && null == names[j]; k++) {
-          names[j] = _TestUtil.randomRealisticUnicodeString(r, 1, 100);
+          names[j] = TestUtil.randomRealisticUnicodeString(r, 1, 100);
 
           // munge anything that might make this a function
           names[j] = names[j].replaceFirst("\\{","\\{\\{");
diff --git a/solr/core/src/test/org/apache/solr/servlet/CacheHeaderTest.java b/solr/core/src/test/org/apache/solr/servlet/CacheHeaderTest.java
index ab62d65..d4f9e1b 100644
--- a/solr/core/src/test/org/apache/solr/servlet/CacheHeaderTest.java
+++ b/solr/core/src/test/org/apache/solr/servlet/CacheHeaderTest.java
@@ -27,7 +27,7 @@ import org.apache.http.Header;
 import org.apache.http.HttpResponse;
 import org.apache.http.client.methods.HttpRequestBase;
 import org.apache.http.impl.cookie.DateUtils;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.solr.common.params.CommonParams;
 import org.junit.AfterClass;
 import org.junit.BeforeClass;
@@ -253,7 +253,7 @@ public class CacheHeaderTest extends CacheHeaderTestBase {
 
   protected File makeFile(String contents, String charset) {
     try {
-      File f = _TestUtil.createTempFile("cachetest_csv", null, TEMP_DIR);
+      File f = TestUtil.createTempFile("cachetest_csv", null, TEMP_DIR);
       Writer out = new OutputStreamWriter(new FileOutputStream(f), charset);
       out.write(contents);
       out.close();
diff --git a/solr/core/src/test/org/apache/solr/spelling/SpellCheckCollatorTest.java b/solr/core/src/test/org/apache/solr/spelling/SpellCheckCollatorTest.java
index 0752648..95bda28 100644
--- a/solr/core/src/test/org/apache/solr/spelling/SpellCheckCollatorTest.java
+++ b/solr/core/src/test/org/apache/solr/spelling/SpellCheckCollatorTest.java
@@ -21,7 +21,7 @@ import java.util.List;
 import java.util.Set;
 
 import org.apache.lucene.util.LuceneTestCase.Slow;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.solr.SolrTestCaseJ4;
 import org.apache.solr.common.params.SolrParams;
 import org.apache.solr.common.params.CommonParams;
@@ -38,7 +38,6 @@ import org.apache.solr.request.SolrQueryRequest;
 import org.apache.solr.request.SolrRequestHandler;
 import org.apache.solr.response.SolrQueryResponse;
 import org.junit.BeforeClass;
-import org.junit.Ignore;
 import org.junit.Test;
 
 @Slow
@@ -502,7 +501,7 @@ public class SpellCheckCollatorTest extends SolrTestCaseJ4 {
     // produce an estimate no more then the total number of docs
     final int iters = atLeast(10);
     for (int iter = 0; iter < iters; iter++) {
-      final int val = _TestUtil.nextInt(random(), 1, 17);
+      final int val = TestUtil.nextInt(random(), 1, 17);
       assertQ(req(reusedParams,
                   CommonParams.Q, "teststop:metnoia",
                   SpellingParams.SPELLCHECK_COLLATE_MAX_COLLECT_DOCS, ""+val)
diff --git a/solr/core/src/test/org/apache/solr/update/TestDocBasedVersionConstraints.java b/solr/core/src/test/org/apache/solr/update/TestDocBasedVersionConstraints.java
index 92aa4f2..21ceaba 100755
--- a/solr/core/src/test/org/apache/solr/update/TestDocBasedVersionConstraints.java
+++ b/solr/core/src/test/org/apache/solr/update/TestDocBasedVersionConstraints.java
@@ -17,7 +17,7 @@
 
 package org.apache.solr.update;
 
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.solr.SolrTestCaseJ4;
 import org.apache.solr.common.SolrException;
 import org.apache.solr.util.DefaultSolrThreadFactory;
@@ -363,17 +363,17 @@ public class TestDocBasedVersionConstraints extends SolrTestCaseJ4 {
     // runner = Executors.newFixedThreadPool(1);    // to test single threaded
     try {
       for (int id = 0; id < NUM_DOCS; id++) {
-        final int numAdds = _TestUtil.nextInt(random(),3,MAX_CONCURENT);
-        final int winner = _TestUtil.nextInt(random(),0,numAdds-1);
+        final int numAdds = TestUtil.nextInt(random(), 3, MAX_CONCURENT);
+        final int winner = TestUtil.nextInt(random(), 0, numAdds - 1);
         final int winnerVersion = atLeast(100);
-        final boolean winnerIsDeleted = (0 == _TestUtil.nextInt(random(),0,4));
+        final boolean winnerIsDeleted = (0 == TestUtil.nextInt(random(), 0, 4));
         List<Callable<Object>> tasks = new ArrayList<Callable<Object>>(numAdds);
         for (int variant = 0; variant < numAdds; variant++) {
           final boolean iShouldWin = (variant==winner);
           final long version = (iShouldWin ? winnerVersion 
-                                : _TestUtil.nextInt(random(),1,winnerVersion-1));
+                                : TestUtil.nextInt(random(), 1, winnerVersion - 1));
           if ((iShouldWin && winnerIsDeleted)
-              || (!iShouldWin && 0 == _TestUtil.nextInt(random(),0,4))) {
+              || (!iShouldWin && 0 == TestUtil.nextInt(random(), 0, 4))) {
             tasks.add(delayedDelete(""+id, ""+version));
           } else {
             tasks.add(delayedAdd("id",""+id,"name","name"+id+"_"+variant,
diff --git a/solr/core/src/test/org/apache/solr/util/TestFastOutputStream.java b/solr/core/src/test/org/apache/solr/util/TestFastOutputStream.java
index 7c17d45..eb8ec60 100644
--- a/solr/core/src/test/org/apache/solr/util/TestFastOutputStream.java
+++ b/solr/core/src/test/org/apache/solr/util/TestFastOutputStream.java
@@ -18,14 +18,9 @@
 package org.apache.solr.util;
 
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
 import org.apache.solr.update.MemOutputStream;
 
-import java.util.HashSet;
-import java.util.Locale;
 import java.util.Random;
-import java.util.Set;
-import java.util.TimeZone;
 
 public class TestFastOutputStream extends LuceneTestCase {
 
diff --git a/solr/core/src/test/org/apache/solr/util/TimeZoneUtilsTest.java b/solr/core/src/test/org/apache/solr/util/TimeZoneUtilsTest.java
index cf6b1c5..e4f695f 100644
--- a/solr/core/src/test/org/apache/solr/util/TimeZoneUtilsTest.java
+++ b/solr/core/src/test/org/apache/solr/util/TimeZoneUtilsTest.java
@@ -18,7 +18,7 @@
 package org.apache.solr.util;
 
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 import java.util.Set;
 import java.util.HashSet;
@@ -117,8 +117,8 @@ public class TimeZoneUtilsTest extends LuceneTestCase {
     final Random r = random();
     final int iters = atLeast(r, 50);
     for (int i = 0; i <= iters; i++) {
-      int hour = _TestUtil.nextInt(r, 0, 23);
-      int min = _TestUtil.nextInt(r, 0, 59);
+      int hour = TestUtil.nextInt(r, 0, 23);
+      int min = TestUtil.nextInt(r, 0, 59);
 
       String hours = String.format(Locale.ROOT, 
                                    (r.nextBoolean() ? ONE_DIGIT : TWO_DIGIT),
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/SolrExampleTests.java b/solr/solrj/src/test/org/apache/solr/client/solrj/SolrExampleTests.java
index 3a1cc4b..86341d0 100644
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/SolrExampleTests.java
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/SolrExampleTests.java
@@ -18,7 +18,6 @@
 package org.apache.solr.client.solrj;
 
 
-import java.io.IOException;
 import java.lang.reflect.Field;
 import java.util.ArrayList;
 import java.util.Arrays;
@@ -27,15 +26,12 @@ import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.Random;
-import java.util.concurrent.atomic.AtomicInteger;
 
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
 
 import junit.framework.Assert;
 
-import org.apache.lucene.util._TestUtil;
-import org.apache.solr.SolrJettyTestBase;
+import org.apache.lucene.util.TestUtil;
 import org.apache.solr.client.solrj.impl.BinaryResponseParser;
 import org.apache.solr.client.solrj.impl.ConcurrentUpdateSolrServer;
 import org.apache.solr.client.solrj.impl.HttpSolrServer;
@@ -52,7 +48,6 @@ import org.apache.solr.client.solrj.response.PivotField;
 import org.apache.solr.client.solrj.response.QueryResponse;
 import org.apache.solr.client.solrj.response.FacetField;
 import org.apache.solr.client.solrj.response.UpdateResponse;
-import org.apache.solr.client.solrj.util.ClientUtils;
 import org.apache.solr.common.SolrDocument;
 import org.apache.solr.common.SolrDocumentList;
 import org.apache.solr.common.SolrException;
@@ -358,7 +353,7 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
           }
         }
 
-        int numDocs = _TestUtil.nextInt(random(), 1, 10*RANDOM_MULTIPLIER);
+        int numDocs = TestUtil.nextInt(random(), 1, 10 * RANDOM_MULTIPLIER);
         
         // Empty the database...
         server.deleteByQuery("*:*");// delete everything!
diff --git a/solr/solrj/src/test/org/apache/solr/common/util/TestJavaBinCodec.java b/solr/solrj/src/test/org/apache/solr/common/util/TestJavaBinCodec.java
index c404e06..1f7eebf 100644
--- a/solr/solrj/src/test/org/apache/solr/common/util/TestJavaBinCodec.java
+++ b/solr/solrj/src/test/org/apache/solr/common/util/TestJavaBinCodec.java
@@ -21,14 +21,14 @@ import java.io.ByteArrayInputStream;
 import java.io.ByteArrayOutputStream;
 
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 
 public class TestJavaBinCodec extends LuceneTestCase {
   
  public void testStrings() throws Exception {
     JavaBinCodec javabin = new JavaBinCodec();
     for (int i = 0; i < 10000*RANDOM_MULTIPLIER; i++) {
-      String s = _TestUtil.randomUnicodeString(random());
+      String s = TestUtil.randomUnicodeString(random());
       ByteArrayOutputStream os = new ByteArrayOutputStream();
       javabin.marshal(s, os);
       ByteArrayInputStream is = new ByteArrayInputStream(os.toByteArray());
diff --git a/solr/test-framework/src/java/org/apache/solr/BaseDistributedSearchTestCase.java b/solr/test-framework/src/java/org/apache/solr/BaseDistributedSearchTestCase.java
index 3ccc5fb..5b96642 100644
--- a/solr/test-framework/src/java/org/apache/solr/BaseDistributedSearchTestCase.java
+++ b/solr/test-framework/src/java/org/apache/solr/BaseDistributedSearchTestCase.java
@@ -37,7 +37,7 @@ import junit.framework.Assert;
 import org.apache.commons.io.FileUtils;
 import org.apache.lucene.search.FieldCache;
 import org.apache.lucene.util.Constants;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.solr.client.solrj.SolrResponse;
 import org.apache.solr.client.solrj.SolrServer;
 import org.apache.solr.client.solrj.SolrServerException;
@@ -103,15 +103,15 @@ public abstract class BaseDistributedSearchTestCase extends SolrTestCaseJ4 {
       // half the time we use the root context, the other half...
 
       // Remember: randomSimpleString might be the empty string
-      hostContext.append(_TestUtil.randomSimpleString(random(), 2));
+      hostContext.append(TestUtil.randomSimpleString(random(), 2));
       if (random().nextBoolean()) {
         hostContext.append("_");
       }
-      hostContext.append(_TestUtil.randomSimpleString(random(), 3));
+      hostContext.append(TestUtil.randomSimpleString(random(), 3));
       if ( ! "/".equals(hostContext.toString())) {
         // if our random string is empty, this might add a trailing slash, 
         // but our code should be ok with that
-        hostContext.append("/").append(_TestUtil.randomSimpleString(random(), 2));
+        hostContext.append("/").append(TestUtil.randomSimpleString(random(), 2));
       } else {
         // we got 'lucky' and still just have the root context,
         // NOOP: don't try to add a subdir to nothing (ie "//" is bad)
diff --git a/solr/test-framework/src/java/org/apache/solr/SolrTestCaseJ4.java b/solr/test-framework/src/java/org/apache/solr/SolrTestCaseJ4.java
index 67641a4..9023c58 100644
--- a/solr/test-framework/src/java/org/apache/solr/SolrTestCaseJ4.java
+++ b/solr/test-framework/src/java/org/apache/solr/SolrTestCaseJ4.java
@@ -49,7 +49,7 @@ import org.apache.lucene.util.Constants;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.QuickPatchThreadsFilter;
-import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.TestUtil;
 import org.apache.solr.client.solrj.impl.HttpClientConfigurer;
 import org.apache.solr.client.solrj.impl.HttpClientUtil;
 import org.apache.solr.client.solrj.util.ClientUtils;
@@ -278,8 +278,8 @@ public abstract class SolrTestCaseJ4 extends LuceneTestCase {
     // don't ask iwc.getMaxThreadStates(), sometimes newIWC uses 
     // RandomDocumentsWriterPerThreadPool and all hell breaks loose
     int maxIndexingThreads = rarely(random())
-      ? _TestUtil.nextInt(random(), 5, 20) // crazy value
-      : _TestUtil.nextInt(random(), 1, 4); // reasonable value
+      ? TestUtil.nextInt(random(), 5, 20) // crazy value
+      : TestUtil.nextInt(random(), 1, 4); // reasonable value
     System.setProperty("solr.tests.maxIndexingThreads", String.valueOf(maxIndexingThreads));
   }
 

