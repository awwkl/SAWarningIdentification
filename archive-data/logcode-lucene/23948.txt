GitDiffStart: 1a56b86b6d368421182d211380d39fe77665fd08 | Thu Feb 2 21:37:12 2006 +0000
diff --git a/src/java/org/apache/solr/analysis/SynonymFilter.java b/src/java/org/apache/solr/analysis/SynonymFilter.java
new file mode 100644
index 0000000..18340f5
--- /dev/null
+++ b/src/java/org/apache/solr/analysis/SynonymFilter.java
@@ -0,0 +1,210 @@
+/**
+ * Copyright 2006 The Apache Software Foundation
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import org.apache.lucene.analysis.Token;
+import org.apache.lucene.analysis.TokenFilter;
+import org.apache.lucene.analysis.TokenStream;
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Iterator;
+import java.util.LinkedList;
+
+/** SynonymFilter handles multi-token synonyms with variable position increment offsets.
+ * <p>
+ * The matched tokens from the input stream may be optionally passed through (includeOrig=true)
+ * or discarded.  If the original tokens are included, the position increments may be modified
+ * to retain absolute positions after merging with the synonym tokenstream.
+ * <p>
+ * Generated synonyms will start at the same position as the first matched source token.
+ *
+ * @author yonik
+ * @version $Id: SynonymFilter.java,v 1.3 2005/12/13 05:14:52 yonik Exp $
+ */
+public class SynonymFilter extends TokenFilter {
+
+  private final SynonymMap map;  // Map<String, SynonymMap>
+  private final boolean ignoreCase;
+  private Iterator replacement;  // iterator over generated tokens
+
+  public SynonymFilter(TokenStream in, SynonymMap map, boolean ignoreCase) {
+    super(in);
+    this.map = map;
+    this.ignoreCase = ignoreCase;
+  }
+
+
+  /*
+   * Need to worry about multiple scenarios:
+   *  - need to go for the longest match
+   *    a b => foo      #shouldn't match if "a b" is followed by "c d"
+   *    a b c d => bar
+   *  - need to backtrack - retry matches for tokens already read
+   *     a b c d => foo
+   *       b c => bar
+   *     If the input stream is "a b c x", one will consume "a b c d"
+   *     trying to match the first rule... all but "a" should be
+   *     pushed back so a match may be made on "b c".
+   *  - don't try and match generated tokens (thus need separate queue)
+   *    matching is not recursive.
+   *  - handle optional generation of original tokens in all these cases,
+   *    merging token streams to preserve token positions.
+   *  - preserve original positionIncrement of first matched token
+   */
+
+
+  public Token next() throws IOException {
+    while (true) {
+      // if there are any generated tokens, return them... don't try any
+      // matches against them, as we specifically don't want recursion.
+      if (replacement!=null && replacement.hasNext()) {
+        return (Token)replacement.next();
+      }
+
+      // common case fast-path of first token not matching anything
+      Token firstTok = nextTok();
+      if (firstTok ==null) return null;
+      String str = ignoreCase ? firstTok.termText().toLowerCase() : firstTok.termText();
+      Object o = map.submap!=null ? map.submap.get(str) : null;
+      if (o == null) return firstTok;
+
+      // OK, we matched a token, so find the longest match.
+
+      // since matched is only used for matches >= 2, defer creation until now
+      if (matched==null) matched=new LinkedList();
+
+      SynonymMap result = match((SynonymMap)o);
+
+      if (result==null) {
+        // no match, simply return the first token read.
+        return firstTok;
+      }
+
+      // reuse, or create new one each time?
+      ArrayList generated = new ArrayList(result.synonyms.length + matched.size() + 1);
+
+      //
+      // there was a match... let's generate the new tokens, merging
+      // in the matched tokens (position increments need adjusting)
+      //
+      Token lastTok = matched.isEmpty() ? firstTok : (Token)matched.getLast();
+      boolean includeOrig = result.includeOrig();
+
+      Token origTok = includeOrig ? firstTok : null;
+      int origPos = firstTok.getPositionIncrement();  // position of origTok in the original stream
+      int repPos=0; // curr position in replacement token stream
+      int pos=0;  // current position in merged token stream
+
+      for (int i=0; i<result.synonyms.length; i++) {
+        Token repTok = result.synonyms[i];
+        Token newTok = new Token(repTok.termText(), firstTok.startOffset(), lastTok.endOffset(), firstTok.type());
+        repPos += repTok.getPositionIncrement();
+        if (i==0) repPos=origPos;  // make position of first token equal to original
+
+        // if necessary, insert original tokens and adjust position increment
+        while (origTok != null && origPos <= repPos) {
+          origTok.setPositionIncrement(origPos-pos);
+          generated.add(origTok);
+          pos += origTok.getPositionIncrement();
+          origTok = matched.isEmpty() ? null : (Token)matched.removeFirst();
+          if (origTok != null) origPos += origTok.getPositionIncrement();
+        }
+
+        newTok.setPositionIncrement(repPos - pos);
+        generated.add(newTok);
+        pos += newTok.getPositionIncrement();
+      }
+
+      // finish up any leftover original tokens
+      while (origTok!=null) {
+        origTok.setPositionIncrement(origPos-pos);
+        generated.add(origTok);
+        pos += origTok.getPositionIncrement();
+        origTok = matched.isEmpty() ? null : (Token)matched.removeFirst();
+        if (origTok != null) origPos += origTok.getPositionIncrement();
+      }
+
+      // what if we replaced a longer sequence with a shorter one?
+      // a/0 b/5 =>  foo/0
+      // should I re-create the gap on the next buffered token?
+
+      replacement = generated.iterator();
+      // Now return to the top of the loop to read and return the first
+      // generated token.. The reason this is done is that we may have generated
+      // nothing at all, and may need to continue with more matching logic.
+    }
+  }
+
+
+  //
+  // Defer creation of the buffer until the first time it is used to
+  // optimize short fields with no matches.
+  //
+  private LinkedList buffer;
+  private LinkedList matched;
+
+  // TODO: use ArrayList for better performance?
+
+  private Token nextTok() throws IOException {
+    if (buffer!=null && !buffer.isEmpty()) {
+      return (Token)buffer.removeFirst();
+    } else {
+      return input.next();
+    }
+  }
+
+  private void pushTok(Token t) {
+    if (buffer==null) buffer=new LinkedList();
+    buffer.addFirst(t);
+  }
+
+
+
+  private SynonymMap match(SynonymMap map) throws IOException {
+    SynonymMap result = null;
+
+    if (map.submap != null) {
+      Token tok = nextTok();
+      if (tok != null) {
+        // check for positionIncrement!=1?  if>1, should not match, if==0, check multiple at this level?
+        String str = ignoreCase ? tok.termText().toLowerCase() : tok.termText();
+
+        SynonymMap subMap = (SynonymMap)map.submap.get(str);
+
+        if (subMap !=null) {
+          // recurse
+          result = match(subMap);
+        }
+        if (result != null) {
+          matched.addFirst(tok);
+        } else {
+          // push back unmatched token
+          pushTok(tok);
+        }
+      }
+    }
+
+    // if no longer sequence matched, so if this node has synonyms, it's the match.
+    if (result==null && map.synonyms!=null) {
+      result = map;
+    }
+
+    return result;
+  }
+
+}
diff --git a/src/java/org/apache/solr/analysis/SynonymFilterFactory.java b/src/java/org/apache/solr/analysis/SynonymFilterFactory.java
index 9aad957..8301dcf 100644
--- a/src/java/org/apache/solr/analysis/SynonymFilterFactory.java
+++ b/src/java/org/apache/solr/analysis/SynonymFilterFactory.java
@@ -17,18 +17,14 @@
 package org.apache.solr.analysis;
 
 import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.SynonymFilter;
-import org.apache.lucene.analysis.SynonymMap;
+import org.apache.solr.core.Config;
+import org.apache.solr.core.SolrCore;
+import org.apache.solr.util.StrUtils;
 
-import java.util.Map;
+import java.io.IOException;
 import java.util.ArrayList;
 import java.util.List;
-import java.io.IOException;
-
-import org.apache.solr.util.StrUtils;
-import org.apache.solr.analysis.BaseTokenFilterFactory;
-import org.apache.solr.core.Config;
-import org.apache.solr.core.SolrCore;
+import java.util.Map;
 /**
  * @author yonik
  * @version $Id$
diff --git a/src/java/org/apache/solr/analysis/SynonymMap.java b/src/java/org/apache/solr/analysis/SynonymMap.java
new file mode 100644
index 0000000..f9d8c61
--- /dev/null
+++ b/src/java/org/apache/solr/analysis/SynonymMap.java
@@ -0,0 +1,145 @@
+/**
+ * Copyright 2006 The Apache Software Foundation
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import org.apache.lucene.analysis.Token;
+
+import java.util.*;
+
+/** Mapping rules for use with {@link org.apache.solr.analysis.SynonymFilter}
+ *
+ * @author yonik
+ * @version $Id: SynonymMap.java,v 1.2 2005/12/13 05:15:08 yonik Exp $
+ */
+public class SynonymMap {
+  Map submap; // recursive: Map<String, SynonymMap>
+  Token[] synonyms;
+  int flags;
+
+  static final int INCLUDE_ORIG=0x01;
+
+  public boolean includeOrig() { return (flags & INCLUDE_ORIG) != 0; }
+
+  /**
+   * @param singleMatch  List<String>, the sequence of strings to match
+   * @param replacement  List<Token> the list of tokens to use on a match
+   * @param includeOrig  sets a flag on this mapping signaling the generation of matched tokens in addition to the replacement tokens
+   * @param mergeExisting merge the replacement tokens with any other mappings that exist
+   */
+  public void add(List singleMatch, List replacement, boolean includeOrig, boolean mergeExisting) {
+    SynonymMap currMap = this;
+    for (Iterator iter = singleMatch.iterator(); iter.hasNext();) {
+      String str = (String)iter.next();
+      if (currMap.submap==null) {
+        currMap.submap = new HashMap(1);
+      }
+
+      SynonymMap map = (SynonymMap)currMap.submap.get(str);
+      if (map==null) {
+        map = new SynonymMap();
+        currMap.submap.put(str, map);
+      }
+
+      currMap = map;
+    }
+
+    if (currMap.synonyms != null && !mergeExisting) {
+      throw new RuntimeException("SynonymFilter: there is already a mapping for " + singleMatch);
+    }
+    List superset = currMap.synonyms==null ? replacement :
+          mergeTokens(Arrays.asList(currMap.synonyms), replacement);
+    currMap.synonyms = (Token[])superset.toArray(new Token[superset.size()]);
+    if (includeOrig) currMap.flags |= INCLUDE_ORIG;
+  }
+
+
+  public String toString() {
+    StringBuffer sb = new StringBuffer("<");
+    if (synonyms!=null) {
+      sb.append("[");
+      for (int i=0; i<synonyms.length; i++) {
+        if (i!=0) sb.append(',');
+        sb.append(synonyms[i]);
+      }
+      if ((flags & INCLUDE_ORIG)!=0) {
+        sb.append(",ORIG");
+      }
+      sb.append("],");
+    }
+    sb.append(submap);
+    sb.append(">");
+    return sb.toString();
+  }
+
+
+
+  /** Produces a List<Token> from a List<String> */
+  public static List makeTokens(List strings) {
+    List ret = new ArrayList(strings.size());
+    for (Iterator iter = strings.iterator(); iter.hasNext();) {
+      Token newTok = new Token((String)iter.next(),0,0,"SYNONYM");
+      ret.add(newTok);
+    }
+    return ret;
+  }
+
+
+  /**
+   * Merge two lists of tokens, producing a single list with manipulated positionIncrements so that
+   * the tokens end up at the same position.
+   *
+   * Example:  [a b] merged with [c d] produces [a/b c/d]  ('/' denotes tokens in the same position)
+   * Example:  [a,5 b,2] merged with [c d,4 e,4] produces [c a,5/d b,2 e,2]  (a,n means a has posInc=n)
+   *
+   */
+  public static List mergeTokens(List lst1, List lst2) {
+    ArrayList result = new ArrayList();
+    if (lst1 ==null || lst2 ==null) {
+      if (lst2 != null) result.addAll(lst2);
+      if (lst1 != null) result.addAll(lst1);
+      return result;
+    }
+
+    int pos=0;
+    Iterator iter1=lst1.iterator();
+    Iterator iter2=lst2.iterator();
+    Token tok1 = iter1.hasNext() ? (Token)iter1.next() : null;
+    Token tok2 = iter2.hasNext() ? (Token)iter2.next() : null;
+    int pos1 = tok1!=null ? tok1.getPositionIncrement() : 0;
+    int pos2 = tok2!=null ? tok2.getPositionIncrement() : 0;
+    while(tok1!=null || tok2!=null) {
+      while (tok1 != null && (pos1 <= pos2 || tok2==null)) {
+        Token tok = new Token(tok1.termText(), tok1.startOffset(), tok1.endOffset(), tok1.type());
+        tok.setPositionIncrement(pos1-pos);
+        result.add(tok);
+        pos=pos1;
+        tok1 = iter1.hasNext() ? (Token)iter1.next() : null;
+        pos1 += tok1!=null ? tok1.getPositionIncrement() : 0;
+      }
+      while (tok2 != null && (pos2 <= pos1 || tok1==null)) {
+        Token tok = new Token(tok2.termText(), tok2.startOffset(), tok2.endOffset(), tok2.type());
+        tok.setPositionIncrement(pos2-pos);
+        result.add(tok);
+        pos=pos2;
+        tok2 = iter2.hasNext() ? (Token)iter2.next() : null;
+        pos2 += tok2!=null ? tok2.getPositionIncrement() : 0;
+      }
+    }
+    return result;
+  }
+
+}
diff --git a/src/lucene_extras/org/apache/lucene/analysis/SynonymFilter.java b/src/lucene_extras/org/apache/lucene/analysis/SynonymFilter.java
deleted file mode 100644
index b9e3178..0000000
--- a/src/lucene_extras/org/apache/lucene/analysis/SynonymFilter.java
+++ /dev/null
@@ -1,204 +0,0 @@
-/**
- * Copyright 2006 The Apache Software Foundation
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.lucene.analysis;
-
-import java.io.IOException;
-import java.util.*;
-
-/** SynonymFilter handles multi-token synonyms with variable position increment offsets.
- * <p>
- * The matched tokens from the input stream may be optionally passed through (includeOrig=true)
- * or discarded.  If the original tokens are included, the position increments may be modified
- * to retain absolute positions after merging with the synonym tokenstream.
- * <p>
- * Generated synonyms will start at the same position as the first matched source token.
- *
- * @author yonik
- * @version $Id: SynonymFilter.java,v 1.3 2005/12/13 05:14:52 yonik Exp $
- */
-public class SynonymFilter extends TokenFilter {
-
-  private final SynonymMap map;  // Map<String, SynonymMap>
-  private final boolean ignoreCase;
-  private Iterator replacement;  // iterator over generated tokens
-
-  public SynonymFilter(TokenStream in, SynonymMap map, boolean ignoreCase) {
-    super(in);
-    this.map = map;
-    this.ignoreCase = ignoreCase;
-  }
-
-
-  /*
-   * Need to worry about multiple scenarios:
-   *  - need to go for the longest match
-   *    a b => foo      #shouldn't match if "a b" is followed by "c d"
-   *    a b c d => bar
-   *  - need to backtrack - retry matches for tokens already read
-   *     a b c d => foo
-   *       b c => bar
-   *     If the input stream is "a b c x", one will consume "a b c d"
-   *     trying to match the first rule... all but "a" should be
-   *     pushed back so a match may be made on "b c".
-   *  - don't try and match generated tokens (thus need separate queue)
-   *    matching is not recursive.
-   *  - handle optional generation of original tokens in all these cases,
-   *    merging token streams to preserve token positions.
-   *  - preserve original positionIncrement of first matched token
-   */
-
-
-  public Token next() throws IOException {
-    while (true) {
-      // if there are any generated tokens, return them... don't try any
-      // matches against them, as we specifically don't want recursion.
-      if (replacement!=null && replacement.hasNext()) {
-        return (Token)replacement.next();
-      }
-
-      // common case fast-path of first token not matching anything
-      Token firstTok = nextTok();
-      if (firstTok ==null) return null;
-      String str = ignoreCase ? firstTok.termText.toLowerCase() : firstTok.termText;
-      Object o = map.submap!=null ? map.submap.get(str) : null;
-      if (o == null) return firstTok;
-
-      // OK, we matched a token, so find the longest match.
-
-      // since matched is only used for matches >= 2, defer creation until now
-      if (matched==null) matched=new LinkedList();
-
-      SynonymMap result = match((SynonymMap)o);
-
-      if (result==null) {
-        // no match, simply return the first token read.
-        return firstTok;
-      }
-
-      // reuse, or create new one each time?
-      ArrayList generated = new ArrayList(result.synonyms.length + matched.size() + 1);
-
-      //
-      // there was a match... let's generate the new tokens, merging
-      // in the matched tokens (position increments need adjusting)
-      //
-      Token lastTok = matched.isEmpty() ? firstTok : (Token)matched.getLast();
-      boolean includeOrig = result.includeOrig();
-
-      Token origTok = includeOrig ? firstTok : null;
-      int origPos = firstTok.getPositionIncrement();  // position of origTok in the original stream
-      int repPos=0; // curr position in replacement token stream
-      int pos=0;  // current position in merged token stream
-
-      for (int i=0; i<result.synonyms.length; i++) {
-        Token repTok = result.synonyms[i];
-        Token newTok = new Token(repTok.termText, firstTok.startOffset, lastTok.endOffset, firstTok.type);
-        repPos += repTok.getPositionIncrement();
-        if (i==0) repPos=origPos;  // make position of first token equal to original
-
-        // if necessary, insert original tokens and adjust position increment
-        while (origTok != null && origPos <= repPos) {
-          origTok.setPositionIncrement(origPos-pos);
-          generated.add(origTok);
-          pos += origTok.getPositionIncrement();
-          origTok = matched.isEmpty() ? null : (Token)matched.removeFirst();
-          if (origTok != null) origPos += origTok.getPositionIncrement();
-        }
-
-        newTok.setPositionIncrement(repPos - pos);
-        generated.add(newTok);
-        pos += newTok.getPositionIncrement();
-      }
-
-      // finish up any leftover original tokens
-      while (origTok!=null) {
-        origTok.setPositionIncrement(origPos-pos);
-        generated.add(origTok);
-        pos += origTok.getPositionIncrement();
-        origTok = matched.isEmpty() ? null : (Token)matched.removeFirst();
-        if (origTok != null) origPos += origTok.getPositionIncrement();
-      }
-
-      // what if we replaced a longer sequence with a shorter one?
-      // a/0 b/5 =>  foo/0
-      // should I re-create the gap on the next buffered token?
-
-      replacement = generated.iterator();
-      // Now return to the top of the loop to read and return the first
-      // generated token.. The reason this is done is that we may have generated
-      // nothing at all, and may need to continue with more matching logic.
-    }
-  }
-
-
-  //
-  // Defer creation of the buffer until the first time it is used to
-  // optimize short fields with no matches.
-  //
-  private LinkedList buffer;
-  private LinkedList matched;
-
-  // TODO: use ArrayList for better performance?
-
-  private Token nextTok() throws IOException {
-    if (buffer!=null && !buffer.isEmpty()) {
-      return (Token)buffer.removeFirst();
-    } else {
-      return input.next();
-    }
-  }
-
-  private void pushTok(Token t) {
-    if (buffer==null) buffer=new LinkedList();
-    buffer.addFirst(t);
-  }
-
-
-
-  private SynonymMap match(SynonymMap map) throws IOException {
-    SynonymMap result = null;
-
-    if (map.submap != null) {
-      Token tok = nextTok();
-      if (tok != null) {
-        // check for positionIncrement!=1?  if>1, should not match, if==0, check multiple at this level?
-        String str = ignoreCase ? tok.termText.toLowerCase() : tok.termText;
-
-        SynonymMap subMap = (SynonymMap)map.submap.get(str);
-
-        if (subMap !=null) {
-          // recurse
-          result = match(subMap);
-        }
-        if (result != null) {
-          matched.addFirst(tok);
-        } else {
-          // push back unmatched token
-          pushTok(tok);
-        }
-      }
-    }
-
-    // if no longer sequence matched, so if this node has synonyms, it's the match.
-    if (result==null && map.synonyms!=null) {
-      result = map;
-    }
-
-    return result;
-  }
-
-}
diff --git a/src/lucene_extras/org/apache/lucene/analysis/SynonymMap.java b/src/lucene_extras/org/apache/lucene/analysis/SynonymMap.java
deleted file mode 100644
index b560968..0000000
--- a/src/lucene_extras/org/apache/lucene/analysis/SynonymMap.java
+++ /dev/null
@@ -1,143 +0,0 @@
-/**
- * Copyright 2006 The Apache Software Foundation
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.lucene.analysis;
-
-import java.util.*;
-
-/** Mapping rules for use with {@link SynonymFilter}
- *
- * @author yonik
- * @version $Id: SynonymMap.java,v 1.2 2005/12/13 05:15:08 yonik Exp $
- */
-public class SynonymMap {
-  Map submap; // recursive: Map<String, SynonymMap>
-  Token[] synonyms;
-  int flags;
-
-  static final int INCLUDE_ORIG=0x01;
-
-  public boolean includeOrig() { return (flags & INCLUDE_ORIG) != 0; }
-
-  /**
-   * @param singleMatch  List<String>, the sequence of strings to match
-   * @param replacement  List<Token> the list of tokens to use on a match
-   * @param includeOrig  sets a flag on this mapping signaling the generation of matched tokens in addition to the replacement tokens
-   * @param mergeExisting merge the replacement tokens with any other mappings that exist
-   */
-  public void add(List singleMatch, List replacement, boolean includeOrig, boolean mergeExisting) {
-    SynonymMap currMap = this;
-    for (Iterator iter = singleMatch.iterator(); iter.hasNext();) {
-      String str = (String)iter.next();
-      if (currMap.submap==null) {
-        currMap.submap = new HashMap(1);
-      }
-
-      SynonymMap map = (SynonymMap)currMap.submap.get(str);
-      if (map==null) {
-        map = new SynonymMap();
-        currMap.submap.put(str, map);
-      }
-
-      currMap = map;
-    }
-
-    if (currMap.synonyms != null && !mergeExisting) {
-      throw new RuntimeException("SynonymFilter: there is already a mapping for " + singleMatch);
-    }
-    List superset = currMap.synonyms==null ? replacement :
-          mergeTokens(Arrays.asList(currMap.synonyms), replacement);
-    currMap.synonyms = (Token[])superset.toArray(new Token[superset.size()]);
-    if (includeOrig) currMap.flags |= INCLUDE_ORIG;
-  }
-
-
-  public String toString() {
-    StringBuffer sb = new StringBuffer("<");
-    if (synonyms!=null) {
-      sb.append("[");
-      for (int i=0; i<synonyms.length; i++) {
-        if (i!=0) sb.append(',');
-        sb.append(synonyms[i]);
-      }
-      if ((flags & INCLUDE_ORIG)!=0) {
-        sb.append(",ORIG");
-      }
-      sb.append("],");
-    }
-    sb.append(submap);
-    sb.append(">");
-    return sb.toString();
-  }
-
-
-
-  /** Produces a List<Token> from a List<String> */
-  public static List makeTokens(List strings) {
-    List ret = new ArrayList(strings.size());
-    for (Iterator iter = strings.iterator(); iter.hasNext();) {
-      Token newTok = new Token((String)iter.next(),0,0,"SYNONYM");
-      ret.add(newTok);
-    }
-    return ret;
-  }
-
-
-  /**
-   * Merge two lists of tokens, producing a single list with manipulated positionIncrements so that
-   * the tokens end up at the same position.
-   *
-   * Example:  [a b] merged with [c d] produces [a/b c/d]  ('/' denotes tokens in the same position)
-   * Example:  [a,5 b,2] merged with [c d,4 e,4] produces [c a,5/d b,2 e,2]  (a,n means a has posInc=n)
-   *
-   */
-  public static List mergeTokens(List lst1, List lst2) {
-    ArrayList result = new ArrayList();
-    if (lst1 ==null || lst2 ==null) {
-      if (lst2 != null) result.addAll(lst2);
-      if (lst1 != null) result.addAll(lst1);
-      return result;
-    }
-
-    int pos=0;
-    Iterator iter1=lst1.iterator();
-    Iterator iter2=lst2.iterator();
-    Token tok1 = iter1.hasNext() ? (Token)iter1.next() : null;
-    Token tok2 = iter2.hasNext() ? (Token)iter2.next() : null;
-    int pos1 = tok1!=null ? tok1.getPositionIncrement() : 0;
-    int pos2 = tok2!=null ? tok2.getPositionIncrement() : 0;
-    while(tok1!=null || tok2!=null) {
-      while (tok1 != null && (pos1 <= pos2 || tok2==null)) {
-        Token tok = new Token(tok1.termText, tok1.startOffset, tok1.endOffset, tok1.type);
-        tok.setPositionIncrement(pos1-pos);
-        result.add(tok);
-        pos=pos1;
-        tok1 = iter1.hasNext() ? (Token)iter1.next() : null;
-        pos1 += tok1!=null ? tok1.getPositionIncrement() : 0;
-      }
-      while (tok2 != null && (pos2 <= pos1 || tok1==null)) {
-        Token tok = new Token(tok2.termText, tok2.startOffset, tok2.endOffset, tok2.type);
-        tok.setPositionIncrement(pos2-pos);
-        result.add(tok);
-        pos=pos2;
-        tok2 = iter2.hasNext() ? (Token)iter2.next() : null;
-        pos2 += tok2!=null ? tok2.getPositionIncrement() : 0;
-      }
-    }
-    return result;
-  }
-
-}
diff --git a/src/test/org/apache/solr/analysis/TestSynonymFilter.java b/src/test/org/apache/solr/analysis/TestSynonymFilter.java
index b13f2f4..0dde20f 100644
--- a/src/test/org/apache/solr/analysis/TestSynonymFilter.java
+++ b/src/test/org/apache/solr/analysis/TestSynonymFilter.java
@@ -17,6 +17,8 @@
 package org.apache.solr.analysis;
 
 import junit.framework.TestCase;
+import org.apache.lucene.analysis.Token;
+import org.apache.lucene.analysis.TokenStream;
 
 import java.io.IOException;
 import java.util.ArrayList;

