GitDiffStart: e646cf5f4f36f2074323fd495fb00675ab623d6a | Thu Jan 10 17:30:18 2013 +0000
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41Codec.java b/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41Codec.java
index 4bfa259..aff6a6f 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41Codec.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41Codec.java
@@ -26,6 +26,7 @@ import org.apache.lucene.codecs.NormsFormat;
 import org.apache.lucene.codecs.PostingsFormat;
 import org.apache.lucene.codecs.SegmentInfoFormat;
 import org.apache.lucene.codecs.SimpleDocValuesFormat;
+import org.apache.lucene.codecs.SimpleNormsFormat;
 import org.apache.lucene.codecs.StoredFieldsFormat;
 import org.apache.lucene.codecs.TermVectorsFormat;
 import org.apache.lucene.codecs.lucene40.Lucene40DocValuesFormat;
@@ -145,5 +146,10 @@ public class Lucene41Codec extends Codec {
   // nocommit
   private final SimpleDocValuesFormat defaultDVFormat = SimpleDocValuesFormat.forName("Lucene41");
 
-  // nocommit need simpleNormsFormat
+  private final SimpleNormsFormat simpleNormsFormat = new Lucene41SimpleNormsFormat();
+
+  @Override
+  public SimpleNormsFormat simpleNormsFormat() {
+    return simpleNormsFormat;
+  }
 }
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41SimpleDocValuesConsumer.java b/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41SimpleDocValuesConsumer.java
index 5961978..bd6ebc5 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41SimpleDocValuesConsumer.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41SimpleDocValuesConsumer.java
@@ -31,6 +31,7 @@ import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.packed.PackedInts;
 import org.apache.lucene.util.packed.PackedInts.FormatAndBits;
 
+// nocommit fix exception handling (make sure tests find problems first)
 class Lucene41SimpleDocValuesConsumer extends SimpleDVConsumer {
   final IndexOutput data, meta;
   final int maxDoc;
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41SimpleNormsConsumer.java b/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41SimpleNormsConsumer.java
new file mode 100644
index 0000000..70086e3
--- /dev/null
+++ b/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41SimpleNormsConsumer.java
@@ -0,0 +1,184 @@
+package org.apache.lucene.codecs.lucene41;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Iterator;
+
+import org.apache.lucene.codecs.CodecUtil;
+import org.apache.lucene.codecs.SimpleDVConsumer;
+import org.apache.lucene.index.FieldInfo;
+import org.apache.lucene.index.IndexFileNames;
+import org.apache.lucene.index.SegmentWriteState;
+import org.apache.lucene.store.IndexOutput;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.packed.PackedInts;
+import org.apache.lucene.util.packed.PackedInts.FormatAndBits;
+
+/**
+ * Writes norms one of two ways:
+ * 1. packed ints as deltas from minValue
+ * 2. packed ints as ordinals to a table (if the number of values is small, e.g. <= 256)
+ * 
+ * the latter is typically much smaller with lucene's sims, as only some byte values are used,
+ * but its often a nonlinear mapping, especially if you dont use crazy boosts.
+ */
+class Lucene41SimpleNormsConsumer extends SimpleDVConsumer {
+  final IndexOutput data, meta;
+  final int maxDoc;
+  
+  Lucene41SimpleNormsConsumer(SegmentWriteState state) throws IOException {
+    boolean success = false;
+    try {
+      String dataName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, "nvd");
+      data = state.directory.createOutput(dataName, state.context);
+      CodecUtil.writeHeader(data, Lucene41SimpleNormsFormat.DATA_CODEC, 
+                                  Lucene41SimpleNormsFormat.VERSION_CURRENT);
+      String metaName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, "nvm");
+      meta = state.directory.createOutput(metaName, state.context);
+      CodecUtil.writeHeader(meta, Lucene41SimpleNormsFormat.METADATA_CODEC, 
+                                  Lucene41SimpleNormsFormat.VERSION_CURRENT);
+      maxDoc = state.segmentInfo.getDocCount();
+      success = true;
+    } finally {
+      if (!success) {
+        IOUtils.closeWhileHandlingException(this);
+      }
+    }
+  }
+  
+  @Override
+  public void addNumericField(FieldInfo field, Iterable<Number> values) throws IOException {
+    meta.writeVInt(field.number);
+    meta.writeLong(data.getFilePointer());
+    long minValue = Long.MAX_VALUE;
+    long maxValue = Long.MIN_VALUE;
+    int count = 0;
+    // TODO: more efficient?
+    HashSet<Long> uniqueValues = new HashSet<Long>();
+    for(Number nv : values) {
+      long v = nv.longValue();
+      minValue = Math.min(minValue, v);
+      maxValue = Math.max(maxValue, v);
+      count++;
+      if (uniqueValues != null) {
+        if (uniqueValues.add(v)) {
+          if (uniqueValues.size() > 256) {
+            uniqueValues = null;
+          }
+        }
+      }
+    }
+
+    long delta = maxValue - minValue;
+    final int bitsPerValue;
+    if (delta < 0) {
+      bitsPerValue = 64;
+      meta.writeByte((byte)0); // delta-compressed
+    } else if (uniqueValues != null && PackedInts.bitsRequired(uniqueValues.size()-1) < PackedInts.bitsRequired(delta)) {
+      // smaller to tableize
+      bitsPerValue = PackedInts.bitsRequired(uniqueValues.size()-1);
+      minValue = 0; // we will write indexes into the table instead of values
+      meta.writeByte((byte)1); // table-compressed
+      Long[] decode = uniqueValues.toArray(new Long[uniqueValues.size()]);
+      final HashMap<Long,Integer> encode = new HashMap<Long,Integer>();
+      data.writeVInt(decode.length);
+      for (int i = 0; i < decode.length; i++) {
+        data.writeLong(decode[i]);
+        encode.put(decode[i], i);
+      }
+      final Iterable<Number> original = values;
+      values = new Iterable<Number>() {
+        @Override
+        public Iterator<Number> iterator() {
+          final Iterator<Number> inner = original.iterator();
+          return new Iterator<Number>() {
+            @Override
+            public boolean hasNext() {
+              return inner.hasNext();
+            }
+
+            @Override
+            public Number next() {
+              return encode.get(inner.next());
+            }
+
+            @Override
+            public void remove() { throw new UnsupportedOperationException(); }
+          };
+        }
+      };
+    } else {
+      bitsPerValue = PackedInts.bitsRequired(delta);
+      meta.writeByte((byte)0); // delta-compressed
+    }
+
+    data.writeLong(minValue);
+
+    FormatAndBits formatAndBits = PackedInts.fastestFormatAndBits(count, bitsPerValue, PackedInts.COMPACT);
+    
+    // nocommit: refactor this crap in PackedInts.java
+    // e.g. Header.load()/save() or something rather than how it works now.
+    CodecUtil.writeHeader(data, PackedInts.CODEC_NAME, PackedInts.VERSION_CURRENT);
+    data.writeVInt(bitsPerValue);
+    data.writeVInt(count);
+    data.writeVInt(formatAndBits.format.getId());
+    
+    final PackedInts.Writer writer = PackedInts.getWriterNoHeader(data, formatAndBits.format, count, formatAndBits.bitsPerValue, 0);
+    for(Number nv : values) {
+      writer.add(nv.longValue() - minValue);
+    }
+    writer.finish();
+  }
+  
+  @Override
+  public void close() throws IOException {
+    // nocommit: just write this to a RAMfile or something and flush it here, with #fields first.
+    // this meta is a tiny file so this hurts nobody
+    boolean success = false;
+    try {
+      if (meta != null) {
+        meta.writeVInt(-1);
+      }
+      success = true;
+    } finally {
+      if (success) {
+        IOUtils.close(data, meta);
+      } else {
+        IOUtils.closeWhileHandlingException(data, meta);
+      }
+    }
+  }
+
+  // nocommit: have SimpleDVConsumer extend SimpleNormsConsumer?
+  @Override
+  public void addBinaryField(FieldInfo field, Iterable<BytesRef> values) throws IOException {
+    throw new AssertionError();
+  }
+
+  @Override
+  public void addSortedField(FieldInfo field, Iterable<BytesRef> values, Iterable<Number> docToOrd) throws IOException {
+    throw new AssertionError();
+  }
+  
+  // nocommit: can/should we make override merge + make it smarter to pull the values 
+  // directly from disk for fields that arent already loaded up in ram?
+}
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41SimpleNormsFormat.java b/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41SimpleNormsFormat.java
new file mode 100644
index 0000000..c7a74f5
--- /dev/null
+++ b/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41SimpleNormsFormat.java
@@ -0,0 +1,44 @@
+package org.apache.lucene.codecs.lucene41;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.codecs.SimpleDVConsumer;
+import org.apache.lucene.codecs.SimpleDVProducer;
+import org.apache.lucene.codecs.SimpleNormsFormat;
+import org.apache.lucene.index.SegmentReadState;
+import org.apache.lucene.index.SegmentWriteState;
+
+public class Lucene41SimpleNormsFormat extends SimpleNormsFormat {
+
+  @Override
+  public SimpleDVConsumer normsConsumer(SegmentWriteState state) throws IOException {
+    return new Lucene41SimpleNormsConsumer(state);
+  }
+  
+  @Override
+  public SimpleDVProducer normsProducer(SegmentReadState state) throws IOException {
+    return new Lucene41SimpleNormsProducer(state);
+  }
+  
+  static final String DATA_CODEC = "Lucene41NormsData";
+  static final String METADATA_CODEC = "Lucene41DocValuesMetadata";
+  static final int VERSION_START = 0;
+  static final int VERSION_CURRENT = VERSION_START;
+}
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41SimpleNormsProducer.java b/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41SimpleNormsProducer.java
new file mode 100644
index 0000000..b2eeaae
--- /dev/null
+++ b/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41SimpleNormsProducer.java
@@ -0,0 +1,146 @@
+package org.apache.lucene.codecs.lucene41;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.lucene.codecs.CodecUtil;
+import org.apache.lucene.codecs.SimpleDVProducer;
+import org.apache.lucene.index.BinaryDocValues;
+import org.apache.lucene.index.FieldInfo;
+import org.apache.lucene.index.FieldInfos;
+import org.apache.lucene.index.IndexFileNames;
+import org.apache.lucene.index.NumericDocValues;
+import org.apache.lucene.index.SegmentReadState;
+import org.apache.lucene.index.SortedDocValues;
+import org.apache.lucene.store.IndexInput;
+import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.packed.PackedInts;
+
+class Lucene41SimpleNormsProducer extends SimpleDVProducer {
+  private final Map<Integer,NumericEntry> numerics;
+  private final IndexInput data;
+  
+  // ram instances we have already loaded
+  private final Map<Integer,NumericDocValues> ramInstances = 
+      new HashMap<Integer,NumericDocValues>();
+  
+  Lucene41SimpleNormsProducer(SegmentReadState state) throws IOException {
+    String metaName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, "nvm");
+    // read in the entries from the metadata file.
+    IndexInput in = state.directory.openInput(metaName, state.context);
+    boolean success = false;
+    try {
+      CodecUtil.checkHeader(in, Lucene41SimpleNormsFormat.METADATA_CODEC, 
+                                Lucene41SimpleNormsFormat.VERSION_START,
+                                Lucene41SimpleNormsFormat.VERSION_START);
+      numerics = new HashMap<Integer,NumericEntry>();
+      readFields(in, state.fieldInfos);
+      success = true;
+    } finally {
+      if (success) {
+        IOUtils.close(in);
+      } else {
+        IOUtils.closeWhileHandlingException(in);
+      }
+    }
+    
+    String dataName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, "nvd");
+    data = state.directory.openInput(dataName, state.context);
+    CodecUtil.checkHeader(data, Lucene41SimpleNormsFormat.DATA_CODEC, 
+                                Lucene41SimpleNormsFormat.VERSION_START,
+                                Lucene41SimpleNormsFormat.VERSION_START);
+  }
+  
+  private void readFields(IndexInput meta, FieldInfos infos) throws IOException {
+    int fieldNumber = meta.readVInt();
+    while (fieldNumber != -1) {
+      NumericEntry entry = new NumericEntry();
+      entry.offset = meta.readLong();
+      entry.tableized = meta.readByte() != 0;
+      numerics.put(fieldNumber, entry);
+      fieldNumber = meta.readVInt();
+    }
+  }
+
+  @Override
+  public synchronized NumericDocValues getNumeric(FieldInfo field) throws IOException {
+    NumericDocValues instance = ramInstances.get(field.number);
+    if (instance == null) {
+      instance = loadNumeric(field);
+      ramInstances.put(field.number, instance);
+    }
+    return instance;
+  }
+  
+  private NumericDocValues loadNumeric(FieldInfo field) throws IOException {
+    NumericEntry entry = numerics.get(field.number);
+    final IndexInput data = this.data.clone();
+    data.seek(entry.offset);
+    if (entry.tableized) {
+      int size = data.readVInt();
+      final long decode[] = new long[size];
+      for (int i = 0; i < decode.length; i++) {
+        decode[i] = data.readLong();
+      }
+      final long minValue = data.readLong();
+      assert minValue == 0;
+      PackedInts.Header header = PackedInts.readHeader(data);
+      final PackedInts.Reader reader = PackedInts.getReaderNoHeader(data, header);
+      return new NumericDocValues() {
+        @Override
+        public long get(int docID) {
+          return decode[(int)reader.get(docID)];
+        }
+      };
+    } else {
+      final long minValue = data.readLong();
+      PackedInts.Header header = PackedInts.readHeader(data);
+      final PackedInts.Reader reader = PackedInts.getReaderNoHeader(data, header);
+      return new NumericDocValues() {
+        @Override
+        public long get(int docID) {
+          return minValue + reader.get(docID);
+        }
+      };
+    }
+  }
+
+  @Override
+  public BinaryDocValues getBinary(FieldInfo field) throws IOException {
+    throw new AssertionError();
+  }
+
+  @Override
+  public SortedDocValues getSorted(FieldInfo field) throws IOException {
+    throw new AssertionError();
+  }
+
+  @Override
+  public void close() throws IOException {
+    data.close();
+  }
+  
+  static class NumericEntry {
+    long offset;
+    boolean tableized;
+  }
+
+}
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestDuelingCodecs.java b/lucene/core/src/test/org/apache/lucene/index/TestDuelingCodecs.java
index c41a307..0ec2d35 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestDuelingCodecs.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestDuelingCodecs.java
@@ -537,6 +537,8 @@ public class TestDuelingCodecs extends LuceneTestCase {
       if (leftNorms != null && rightNorms != null) {
         assertDocValues(leftReader.maxDoc(), leftNorms, rightNorms);
       } else {
+        // nocommit: figure out WTF is going on here, maybe a bug in MultiSimpleDocValues?
+        // ant test  -Dtestcase=TestDuelingCodecs -Dtests.method=testEquals -Dtests.seed=CCA808E6ADF64354 -Dtests.slow=true -Dtests.codec=Lucene41 -Dtests.locale=en_GB -Dtests.timezone=Asia/Pyongyang -Dtests.file.encoding=US-ASCII
         assertNull(leftNorms);
         assertNull(rightNorms);
       }
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriter.java b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriter.java
index 4bf27a4..692eaaa 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriter.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriter.java
@@ -1149,6 +1149,7 @@ public class TestIndexWriter extends LuceneTestCase {
     }
   }
 
+  //nocommit: make this tests DV2.0
   public void testThreadInterruptDeadlock() throws Exception {
     IndexerThreadInterrupt t = new IndexerThreadInterrupt();
     t.setDaemon(true);
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete.java b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete.java
index 889f401..6807a18 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete.java
@@ -43,6 +43,7 @@ import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util._TestUtil;
 
+//nocommit: make sure disk full etc tests here test DV2.0
 public class TestIndexWriterDelete extends LuceneTestCase {
 
   // test the simple case
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java
index 1642e2a..5df259c 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java
@@ -49,6 +49,7 @@ import org.apache.lucene.util.InfoStream;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util._TestUtil;
 
+//nocommit: make this tests DV2.0
 public class TestIndexWriterExceptions extends LuceneTestCase {
 
   private static class DocCopyIterator implements Iterable<Document> {
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull.java b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull.java
index 3c86b9e..401f5fb 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull.java
@@ -40,6 +40,7 @@ import static org.apache.lucene.index.TestIndexWriter.assertNoUnreferencedFiles;
 /**
  * Tests for IndexWriter when the disk runs out of space
  */
+//nocommit: make sure disk full etc tests here test DV2.0
 public class TestIndexWriterOnDiskFull extends LuceneTestCase {
 
   /*
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterWithThreads.java b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterWithThreads.java
index 770b69c..486096c 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterWithThreads.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterWithThreads.java
@@ -46,6 +46,7 @@ import org.apache.lucene.util.LuceneTestCase.Slow;
 /**
  * MultiThreaded IndexWriter tests
  */
+// nocommit: make sure disk full etc tests here test DV2.0
 @Slow
 public class TestIndexWriterWithThreads extends LuceneTestCase {
 

