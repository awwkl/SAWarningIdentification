GitDiffStart: 1b075c0ee80b5c2e230a0e2d4ec1097dcac8c1b9 | Sat Oct 4 15:18:05 2014 +0000
diff --git a/lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer.java b/lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer.java
index ef60d58..284ad17 100644
--- a/lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer.java
+++ b/lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer.java
@@ -73,17 +73,16 @@ import org.apache.lucene.util.packed.MonotonicBlockPackedReader;
  */
 @Deprecated
 class Lucene49DocValuesProducer extends DocValuesProducer implements Closeable {
-  private final Map<String,NumericEntry> numerics;
-  private final Map<String,BinaryEntry> binaries;
-  private final Map<String,SortedSetEntry> sortedSets;
-  private final Map<String,SortedSetEntry> sortedNumerics;
-  private final Map<String,NumericEntry> ords;
-  private final Map<String,NumericEntry> ordIndexes;
+  private final Map<String,NumericEntry> numerics = new HashMap<>();
+  private final Map<String,BinaryEntry> binaries = new HashMap<>();
+  private final Map<String,SortedSetEntry> sortedSets = new HashMap<>();
+  private final Map<String,SortedSetEntry> sortedNumerics = new HashMap<>();
+  private final Map<String,NumericEntry> ords = new HashMap<>();
+  private final Map<String,NumericEntry> ordIndexes = new HashMap<>();
   private final AtomicLong ramBytesUsed;
   private final IndexInput data;
   private final int numFields;
   private final int maxDoc;
-  private final int version;
 
   // memory-resident structures
   private final Map<String,MonotonicBlockPackedReader> addressInstances = new HashMap<>();
@@ -94,17 +93,16 @@ class Lucene49DocValuesProducer extends DocValuesProducer implements Closeable {
   // clone for merge: when merging we don't do any instances.put()s
   Lucene49DocValuesProducer(Lucene49DocValuesProducer original) throws IOException {
     assert Thread.holdsLock(original);
-    numerics = original.numerics;
-    binaries = original.binaries;
-    sortedSets = original.sortedSets;
-    sortedNumerics = original.sortedNumerics;
-    ords = original.ords;
-    ordIndexes = original.ordIndexes;
+    numerics.putAll(original.numerics);
+    binaries.putAll(original.binaries);
+    sortedSets.putAll(original.sortedSets);
+    sortedNumerics.putAll(original.sortedNumerics);
+    ords.putAll(original.ords);
+    ordIndexes.putAll(original.ordIndexes);
     ramBytesUsed = new AtomicLong(original.ramBytesUsed());
     data = original.data.clone();
     numFields = original.numFields;
     maxDoc = original.maxDoc;
-    version = original.version;
     addressInstances.putAll(original.addressInstances);
     ordIndexInstances.putAll(original.ordIndexInstances);
     merging = true;
@@ -113,36 +111,31 @@ class Lucene49DocValuesProducer extends DocValuesProducer implements Closeable {
   /** expert: instantiates a new reader */
   Lucene49DocValuesProducer(SegmentReadState state, String dataCodec, String dataExtension, String metaCodec, String metaExtension) throws IOException {
     String metaName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, metaExtension);
-    // read in the entries from the metadata file.
-    ChecksumIndexInput in = state.directory.openChecksumInput(metaName, state.context);
     this.maxDoc = state.segmentInfo.getDocCount();
     merging = false;
-    boolean success = false;
-    try {
-      version = CodecUtil.checkHeader(in, metaCodec, 
-                                      Lucene49DocValuesFormat.VERSION_START,
-                                      Lucene49DocValuesFormat.VERSION_CURRENT);
-      numerics = new HashMap<>();
-      ords = new HashMap<>();
-      ordIndexes = new HashMap<>();
-      binaries = new HashMap<>();
-      sortedSets = new HashMap<>();
-      sortedNumerics = new HashMap<>();
-      numFields = readFields(in, state.fieldInfos);
-
-      CodecUtil.checkFooter(in);
-      success = true;
-    } finally {
-      if (success) {
-        IOUtils.close(in);
-      } else {
-        IOUtils.closeWhileHandlingException(in);
+    
+    int version = -1;
+    int numFields = -1;
+    
+    // read in the entries from the metadata file.
+    try (ChecksumIndexInput in = state.directory.openChecksumInput(metaName, state.context)) {
+      Throwable priorE = null;
+      try {
+        version = CodecUtil.checkHeader(in, metaCodec, 
+                                            Lucene49DocValuesFormat.VERSION_START,
+                                            Lucene49DocValuesFormat.VERSION_CURRENT);
+        numFields = readFields(in, state.fieldInfos);
+      } catch (Throwable exception) {
+        priorE = exception;
+      } finally {
+        CodecUtil.checkFooter(in, priorE);
       }
     }
+    this.numFields = numFields;
 
     String dataName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, dataExtension);
     this.data = state.directory.openInput(dataName, state.context);
-    success = false;
+    boolean success = false;
     try {
       final int version2 = CodecUtil.checkHeader(data, dataCodec, 
                                                  Lucene49DocValuesFormat.VERSION_START,

