GitDiffStart: 7da175b0b6b4185ee6b5df852e59b93d9a9a1c86 | Fri Dec 11 21:13:41 2015 +0000
diff --git a/lucene/CHANGES.txt b/lucene/CHANGES.txt
index 55a7d85..c269d21 100644
--- a/lucene/CHANGES.txt
+++ b/lucene/CHANGES.txt
@@ -86,6 +86,9 @@ API Changes
   IndexOutput.getName returns its name (Dawid Weiss, Robert Muir, Mike
   McCandless)
 
+* LUCENE-6917: Deprecate and rename NumericXXX classes to
+  LegacyNumericXXX in favor of dimensional values (Mike McCandless)
+
 Optimizations
 
 * LUCENE-6891: Use prefix coding when writing dimensional values in 
diff --git a/lucene/MIGRATE.txt b/lucene/MIGRATE.txt
index 98d7bc1..3cd20bd 100644
--- a/lucene/MIGRATE.txt
+++ b/lucene/MIGRATE.txt
@@ -80,3 +80,11 @@ would be equivalent to the following code with the old setBoost API:
   Query q = ...;
   float boost = ...;
   q.setBoost(q.getBoost() * boost);
+
+## DimensionalValues replaces NumericField (LUCENE-6917)
+
+DimensionalValues provides faster indexing and searching, a smaller
+index size, and less heap used at search time.  The numeric fields
+(IntField, FloatField, LongField, DoubleField) and NumericRangeQuery
+have been moved to the backward-codecs module and prefixed with
+Legacy.
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestTypeTokenFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestTypeTokenFilterFactory.java
index a8d9156..7fad96e 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestTypeTokenFilterFactory.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestTypeTokenFilterFactory.java
@@ -17,12 +17,12 @@ package org.apache.lucene.analysis.core;
  * limitations under the License.
  */
 
-import org.apache.lucene.analysis.NumericTokenStream;
+import java.util.Set;
+
+import org.apache.lucene.analysis.CannedTokenStream;
 import org.apache.lucene.analysis.util.BaseTokenStreamFactoryTestCase;
 import org.apache.lucene.analysis.util.TokenFilterFactory;
 
-import java.util.Set;
-
 /**
  * Testcase for {@link TypeTokenFilterFactory}
  */
@@ -46,8 +46,7 @@ public class TestTypeTokenFilterFactory extends BaseTokenStreamFactoryTestCase {
   public void testCreationWithBlackList() throws Exception {
     TokenFilterFactory factory = tokenFilterFactory("Type",
         "types", "stoptypes-1.txt, stoptypes-2.txt");
-    NumericTokenStream input = new NumericTokenStream();
-    input.setIntValue(123);
+    CannedTokenStream input = new CannedTokenStream();
     factory.create(input);
   }
   
@@ -55,8 +54,7 @@ public class TestTypeTokenFilterFactory extends BaseTokenStreamFactoryTestCase {
     TokenFilterFactory factory = tokenFilterFactory("Type",
         "types", "stoptypes-1.txt, stoptypes-2.txt",
         "useWhitelist", "true");
-    NumericTokenStream input = new NumericTokenStream();
-    input.setIntValue(123);
+    CannedTokenStream input = new CannedTokenStream();
     factory.create(input);
   }
 
diff --git a/lucene/backward-codecs/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java b/lucene/backward-codecs/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java
index 106584c..3cce87a 100644
--- a/lucene/backward-codecs/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java
+++ b/lucene/backward-codecs/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java
@@ -43,8 +43,8 @@ import org.apache.lucene.document.DoubleDocValuesField;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.FieldType;
 import org.apache.lucene.document.FloatDocValuesField;
-import org.apache.lucene.document.IntField;
-import org.apache.lucene.document.LongField;
+import org.apache.lucene.document.LegacyIntField;
+import org.apache.lucene.document.LegacyLongField;
 import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.document.SortedDocValuesField;
 import org.apache.lucene.document.SortedNumericDocValuesField;
@@ -54,7 +54,7 @@ import org.apache.lucene.document.TextField;
 import org.apache.lucene.index.IndexWriterConfig.OpenMode;
 import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.NumericRangeQuery;
+import org.apache.lucene.search.LegacyNumericRangeQuery;
 import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.store.BaseDirectoryWrapper;
@@ -68,9 +68,9 @@ import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.InfoStream;
+import org.apache.lucene.util.LegacyNumericUtils;
 import org.apache.lucene.util.LineFileDocs;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util.NumericUtils;
 import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.Version;
 import org.junit.AfterClass;
@@ -939,8 +939,8 @@ public class TestBackwardsCompatibility extends LuceneTestCase {
     doc.add(new Field("content2", "here is more content with aaa aaa aaa", customType2));
     doc.add(new Field("fie\u2C77ld", "field with non-ascii name", customType2));
     // add numeric fields, to test if flex preserves encoding
-    doc.add(new IntField("trieInt", id, Field.Store.NO));
-    doc.add(new LongField("trieLong", (long) id, Field.Store.NO));
+    doc.add(new LegacyIntField("trieInt", id, Field.Store.NO));
+    doc.add(new LegacyLongField("trieLong", (long) id, Field.Store.NO));
     // add docvalues fields
     doc.add(new NumericDocValuesField("dvByte", (byte) id));
     byte bytes[] = new byte[] {
@@ -1103,36 +1103,36 @@ public class TestBackwardsCompatibility extends LuceneTestCase {
       IndexSearcher searcher = newSearcher(reader);
       
       for (int id=10; id<15; id++) {
-        ScoreDoc[] hits = searcher.search(NumericRangeQuery.newIntRange("trieInt", NumericUtils.PRECISION_STEP_DEFAULT_32, Integer.valueOf(id), Integer.valueOf(id), true, true), 100).scoreDocs;
+        ScoreDoc[] hits = searcher.search(LegacyNumericRangeQuery.newIntRange("trieInt", LegacyNumericUtils.PRECISION_STEP_DEFAULT_32, Integer.valueOf(id), Integer.valueOf(id), true, true), 100).scoreDocs;
         assertEquals("wrong number of hits", 1, hits.length);
         StoredDocument d = searcher.doc(hits[0].doc);
         assertEquals(String.valueOf(id), d.get("id"));
         
-        hits = searcher.search(NumericRangeQuery.newLongRange("trieLong", NumericUtils.PRECISION_STEP_DEFAULT, Long.valueOf(id), Long.valueOf(id), true, true), 100).scoreDocs;
+        hits = searcher.search(LegacyNumericRangeQuery.newLongRange("trieLong", LegacyNumericUtils.PRECISION_STEP_DEFAULT, Long.valueOf(id), Long.valueOf(id), true, true), 100).scoreDocs;
         assertEquals("wrong number of hits", 1, hits.length);
         d = searcher.doc(hits[0].doc);
         assertEquals(String.valueOf(id), d.get("id"));
       }
       
       // check that also lower-precision fields are ok
-      ScoreDoc[] hits = searcher.search(NumericRangeQuery.newIntRange("trieInt", NumericUtils.PRECISION_STEP_DEFAULT_32, Integer.MIN_VALUE, Integer.MAX_VALUE, false, false), 100).scoreDocs;
+      ScoreDoc[] hits = searcher.search(LegacyNumericRangeQuery.newIntRange("trieInt", LegacyNumericUtils.PRECISION_STEP_DEFAULT_32, Integer.MIN_VALUE, Integer.MAX_VALUE, false, false), 100).scoreDocs;
       assertEquals("wrong number of hits", 34, hits.length);
       
-      hits = searcher.search(NumericRangeQuery.newLongRange("trieLong", NumericUtils.PRECISION_STEP_DEFAULT, Long.MIN_VALUE, Long.MAX_VALUE, false, false), 100).scoreDocs;
+      hits = searcher.search(LegacyNumericRangeQuery.newLongRange("trieLong", LegacyNumericUtils.PRECISION_STEP_DEFAULT, Long.MIN_VALUE, Long.MAX_VALUE, false, false), 100).scoreDocs;
       assertEquals("wrong number of hits", 34, hits.length);
       
       // check decoding of terms
       Terms terms = MultiFields.getTerms(searcher.getIndexReader(), "trieInt");
-      TermsEnum termsEnum = NumericUtils.filterPrefixCodedInts(terms.iterator());
+      TermsEnum termsEnum = LegacyNumericUtils.filterPrefixCodedInts(terms.iterator());
       while (termsEnum.next() != null) {
-        int val = NumericUtils.prefixCodedToInt(termsEnum.term());
+        int val = LegacyNumericUtils.prefixCodedToInt(termsEnum.term());
         assertTrue("value in id bounds", val >= 0 && val < 35);
       }
       
       terms = MultiFields.getTerms(searcher.getIndexReader(), "trieLong");
-      termsEnum = NumericUtils.filterPrefixCodedLongs(terms.iterator());
+      termsEnum = LegacyNumericUtils.filterPrefixCodedLongs(terms.iterator());
       while (termsEnum.next() != null) {
-        long val = NumericUtils.prefixCodedToLong(termsEnum.term());
+        long val = LegacyNumericUtils.prefixCodedToLong(termsEnum.term());
         assertTrue("value in id bounds", val >= 0L && val < 35L);
       }
       
diff --git a/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker.java b/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker.java
index 4c3de6d..bca057b 100644
--- a/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker.java
+++ b/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker.java
@@ -36,12 +36,12 @@ import java.util.concurrent.atomic.AtomicInteger;
 import org.apache.lucene.benchmark.byTask.utils.Config;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
-import org.apache.lucene.document.FieldType.NumericType;
+import org.apache.lucene.document.FieldType.LegacyNumericType;
 import org.apache.lucene.document.FieldType;
-import org.apache.lucene.document.IntField;
-import org.apache.lucene.document.LongField;
-import org.apache.lucene.document.FloatField;
-import org.apache.lucene.document.DoubleField;
+import org.apache.lucene.document.LegacyIntField;
+import org.apache.lucene.document.LegacyDoubleField;
+import org.apache.lucene.document.LegacyLongField;
+import org.apache.lucene.document.LegacyFloatField;
 import org.apache.lucene.document.StringField;
 import org.apache.lucene.document.TextField;
 
@@ -119,8 +119,8 @@ public class DocMaker implements Closeable {
         fields.put(ID_FIELD, new StringField(ID_FIELD, "", Field.Store.YES));
         fields.put(NAME_FIELD, new Field(NAME_FIELD, "", ft));
 
-        numericFields.put(DATE_MSEC_FIELD, new LongField(DATE_MSEC_FIELD, 0L, Field.Store.NO));
-        numericFields.put(TIME_SEC_FIELD, new IntField(TIME_SEC_FIELD, 0, Field.Store.NO));
+        numericFields.put(DATE_MSEC_FIELD, new LegacyLongField(DATE_MSEC_FIELD, 0L, Field.Store.NO));
+        numericFields.put(TIME_SEC_FIELD, new LegacyIntField(TIME_SEC_FIELD, 0, Field.Store.NO));
         
         doc = new Document();
       } else {
@@ -148,7 +148,7 @@ public class DocMaker implements Closeable {
       return f;
     }
 
-    Field getNumericField(String name, NumericType type) {
+    Field getNumericField(String name, LegacyNumericType type) {
       Field f;
       if (reuseFields) {
         f = numericFields.get(name);
@@ -159,16 +159,16 @@ public class DocMaker implements Closeable {
       if (f == null) {
         switch(type) {
         case INT:
-          f = new IntField(name, 0, Field.Store.NO);
+          f = new LegacyIntField(name, 0, Field.Store.NO);
           break;
         case LONG:
-          f = new LongField(name, 0L, Field.Store.NO);
+          f = new LegacyLongField(name, 0L, Field.Store.NO);
           break;
         case FLOAT:
-          f = new FloatField(name, 0.0F, Field.Store.NO);
+          f = new LegacyFloatField(name, 0.0F, Field.Store.NO);
           break;
         case DOUBLE:
-          f = new DoubleField(name, 0.0, Field.Store.NO);
+          f = new LegacyDoubleField(name, 0.0, Field.Store.NO);
           break;
         default:
           throw new AssertionError("Cannot get here");
@@ -278,14 +278,14 @@ public class DocMaker implements Closeable {
       date = new Date();
     }
 
-    Field dateField = ds.getNumericField(DATE_MSEC_FIELD, NumericType.LONG);
+    Field dateField = ds.getNumericField(DATE_MSEC_FIELD, FieldType.LegacyNumericType.LONG);
     dateField.setLongValue(date.getTime());
     doc.add(dateField);
 
     util.cal.setTime(date);
     final int sec = util.cal.get(Calendar.HOUR_OF_DAY)*3600 + util.cal.get(Calendar.MINUTE)*60 + util.cal.get(Calendar.SECOND);
 
-    Field timeSecField = ds.getNumericField(TIME_SEC_FIELD, NumericType.INT);
+    Field timeSecField = ds.getNumericField(TIME_SEC_FIELD, LegacyNumericType.INT);
     timeSecField.setIntValue(sec);
     doc.add(timeSecField);
     
diff --git a/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTokensTask.java b/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTokensTask.java
index 57c206e..8a919a4 100644
--- a/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTokensTask.java
+++ b/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTokensTask.java
@@ -27,11 +27,10 @@ import org.apache.lucene.benchmark.byTask.PerfRunData;
 import org.apache.lucene.benchmark.byTask.feeds.DocMaker;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
-import org.apache.lucene.document.IntField;
-import org.apache.lucene.document.LongField;
-import org.apache.lucene.document.FloatField;
-import org.apache.lucene.document.DoubleField;
-import org.apache.lucene.index.IndexableField;
+import org.apache.lucene.document.LegacyFloatField;
+import org.apache.lucene.document.LegacyIntField;
+import org.apache.lucene.document.LegacyDoubleField;
+import org.apache.lucene.document.LegacyLongField;
 
 /**
  * Simple task to test performance of tokenizers.  It just
@@ -74,10 +73,10 @@ public class ReadTokensTask extends PerfTask {
     int tokenCount = 0;
     for(final Field field : fields) {
       if (!field.fieldType().tokenized() ||
-          field instanceof IntField ||
-          field instanceof LongField ||
-          field instanceof FloatField ||
-          field instanceof DoubleField) {
+          field instanceof LegacyIntField ||
+          field instanceof LegacyLongField ||
+          field instanceof LegacyFloatField ||
+          field instanceof LegacyDoubleField) {
         continue;
       }
       
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/LegacyNumericTokenStream.java b/lucene/core/src/java/org/apache/lucene/analysis/LegacyNumericTokenStream.java
new file mode 100644
index 0000000..1a7077d
--- /dev/null
+++ b/lucene/core/src/java/org/apache/lucene/analysis/LegacyNumericTokenStream.java
@@ -0,0 +1,355 @@
+package org.apache.lucene.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.util.Objects;
+
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
+import org.apache.lucene.analysis.tokenattributes.TermToBytesRefAttribute;
+import org.apache.lucene.analysis.tokenattributes.TypeAttribute;
+import org.apache.lucene.index.DimensionalValues;
+import org.apache.lucene.util.Attribute;
+import org.apache.lucene.util.AttributeFactory;
+import org.apache.lucene.util.AttributeImpl;
+import org.apache.lucene.util.AttributeReflector;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.BytesRefBuilder;
+import org.apache.lucene.util.LegacyNumericUtils;
+
+/**
+ * <b>Expert:</b> This class provides a {@link TokenStream}
+ * for indexing numeric values that can be used by {@link
+ * org.apache.lucene.search.LegacyNumericRangeQuery}.
+ *
+ * <p>Note that for simple usage, {@link org.apache.lucene.document.LegacyIntField}, {@link
+ * org.apache.lucene.document.LegacyLongField}, {@link org.apache.lucene.document.LegacyFloatField} or {@link org.apache.lucene.document.LegacyDoubleField} is
+ * recommended.  These fields disable norms and
+ * term freqs, as they are not usually needed during
+ * searching.  If you need to change these settings, you
+ * should use this class.
+ *
+ * <p>Here's an example usage, for an <code>int</code> field:
+ *
+ * <pre class="prettyprint">
+ *  FieldType fieldType = new FieldType(TextField.TYPE_NOT_STORED);
+ *  fieldType.setOmitNorms(true);
+ *  fieldType.setIndexOptions(IndexOptions.DOCS_ONLY);
+ *  Field field = new Field(name, new LegacyNumericTokenStream(precisionStep).setIntValue(value), fieldType);
+ *  document.add(field);
+ * </pre>
+ *
+ * <p>For optimal performance, re-use the TokenStream and Field instance
+ * for more than one document:
+ *
+ * <pre class="prettyprint">
+ *  LegacyNumericTokenStream stream = new LegacyNumericTokenStream(precisionStep);
+ *  FieldType fieldType = new FieldType(TextField.TYPE_NOT_STORED);
+ *  fieldType.setOmitNorms(true);
+ *  fieldType.setIndexOptions(IndexOptions.DOCS_ONLY);
+ *  Field field = new Field(name, stream, fieldType);
+ *  Document document = new Document();
+ *  document.add(field);
+ *
+ *  for(all documents) {
+ *    stream.setIntValue(value)
+ *    writer.addDocument(document);
+ *  }
+ * </pre>
+ *
+ * <p>This stream is not intended to be used in analyzers;
+ * it's more for iterating the different precisions during
+ * indexing a specific numeric value.</p>
+
+ * <p><b>NOTE</b>: as token streams are only consumed once
+ * the document is added to the index, if you index more
+ * than one numeric field, use a separate <code>LegacyNumericTokenStream</code>
+ * instance for each.</p>
+ *
+ * <p>See {@link org.apache.lucene.search.LegacyNumericRangeQuery} for more details on the
+ * <a
+ * href="../search/LegacyNumericRangeQuery.html#precisionStepDesc"><code>precisionStep</code></a>
+ * parameter as well as how numeric fields work under the hood.</p>
+ *
+ * @deprecated Please switch to {@link DimensionalValues} instead
+ *
+ * @since 2.9
+ */
+@Deprecated
+public final class LegacyNumericTokenStream extends TokenStream {
+
+  /** The full precision token gets this token type assigned. */
+  public static final String TOKEN_TYPE_FULL_PREC  = "fullPrecNumeric";
+
+  /** The lower precision tokens gets this token type assigned. */
+  public static final String TOKEN_TYPE_LOWER_PREC = "lowerPrecNumeric";
+  
+  /** <b>Expert:</b> Use this attribute to get the details of the currently generated token.
+   * @lucene.experimental
+   * @since 4.0
+   */
+  public interface LegacyNumericTermAttribute extends Attribute {
+    /** Returns current shift value, undefined before first token */
+    int getShift();
+    /** Returns current token's raw value as {@code long} with all {@link #getShift} applied, undefined before first token */
+    long getRawValue();
+    /** Returns value size in bits (32 for {@code float}, {@code int}; 64 for {@code double}, {@code long}) */
+    int getValueSize();
+    
+    /** <em>Don't call this method!</em>
+      * @lucene.internal */
+    void init(long value, int valSize, int precisionStep, int shift);
+
+    /** <em>Don't call this method!</em>
+      * @lucene.internal */
+    void setShift(int shift);
+
+    /** <em>Don't call this method!</em>
+      * @lucene.internal */
+    int incShift();
+  }
+  
+  // just a wrapper to prevent adding CTA
+  private static final class NumericAttributeFactory extends AttributeFactory {
+    private final AttributeFactory delegate;
+
+    NumericAttributeFactory(AttributeFactory delegate) {
+      this.delegate = delegate;
+    }
+  
+    @Override
+    public AttributeImpl createAttributeInstance(Class<? extends Attribute> attClass) {
+      if (CharTermAttribute.class.isAssignableFrom(attClass))
+        throw new IllegalArgumentException("LegacyNumericTokenStream does not support CharTermAttribute.");
+      return delegate.createAttributeInstance(attClass);
+    }
+  }
+
+  /** Implementation of {@link org.apache.lucene.analysis.LegacyNumericTokenStream.LegacyNumericTermAttribute}.
+   * @lucene.internal
+   * @since 4.0
+   */
+  public static final class LegacyNumericTermAttributeImpl extends AttributeImpl implements LegacyNumericTermAttribute,TermToBytesRefAttribute {
+    private long value = 0L;
+    private int valueSize = 0, shift = 0, precisionStep = 0;
+    private BytesRefBuilder bytes = new BytesRefBuilder();
+    
+    /** 
+     * Creates, but does not yet initialize this attribute instance
+     * @see #init(long, int, int, int)
+     */
+    public LegacyNumericTermAttributeImpl() {}
+
+    @Override
+    public BytesRef getBytesRef() {
+      assert valueSize == 64 || valueSize == 32;
+      if (valueSize == 64) {
+        LegacyNumericUtils.longToPrefixCoded(value, shift, bytes);
+      } else {
+        LegacyNumericUtils.intToPrefixCoded((int) value, shift, bytes);
+      }
+      return bytes.get();
+    }
+
+    @Override
+    public int getShift() { return shift; }
+    @Override
+    public void setShift(int shift) { this.shift = shift; }
+    @Override
+    public int incShift() {
+      return (shift += precisionStep);
+    }
+
+    @Override
+    public long getRawValue() { return value  & ~((1L << shift) - 1L); }
+    @Override
+    public int getValueSize() { return valueSize; }
+
+    @Override
+    public void init(long value, int valueSize, int precisionStep, int shift) {
+      this.value = value;
+      this.valueSize = valueSize;
+      this.precisionStep = precisionStep;
+      this.shift = shift;
+    }
+
+    @Override
+    public void clear() {
+      // this attribute has no contents to clear!
+      // we keep it untouched as it's fully controlled by outer class.
+    }
+    
+    @Override
+    public void reflectWith(AttributeReflector reflector) {
+      reflector.reflect(TermToBytesRefAttribute.class, "bytes", getBytesRef());
+      reflector.reflect(LegacyNumericTermAttribute.class, "shift", shift);
+      reflector.reflect(LegacyNumericTermAttribute.class, "rawValue", getRawValue());
+      reflector.reflect(LegacyNumericTermAttribute.class, "valueSize", valueSize);
+    }
+  
+    @Override
+    public void copyTo(AttributeImpl target) {
+      final LegacyNumericTermAttribute a = (LegacyNumericTermAttribute) target;
+      a.init(value, valueSize, precisionStep, shift);
+    }
+    
+    @Override
+    public LegacyNumericTermAttributeImpl clone() {
+      LegacyNumericTermAttributeImpl t = (LegacyNumericTermAttributeImpl)super.clone();
+      // Do a deep clone
+      t.bytes = new BytesRefBuilder();
+      t.bytes.copyBytes(getBytesRef());
+      return t;
+    }
+
+    @Override
+    public int hashCode() {
+      return Objects.hash(precisionStep, shift, value, valueSize);
+    }
+
+    @Override
+    public boolean equals(Object obj) {
+      if (this == obj) return true;
+      if (obj == null) return false;
+      if (getClass() != obj.getClass()) return false;
+      LegacyNumericTermAttributeImpl other = (LegacyNumericTermAttributeImpl) obj;
+      if (precisionStep != other.precisionStep) return false;
+      if (shift != other.shift) return false;
+      if (value != other.value) return false;
+      if (valueSize != other.valueSize) return false;
+      return true;
+    }
+  }
+  
+  /**
+   * Creates a token stream for numeric values using the default <code>precisionStep</code>
+   * {@link org.apache.lucene.util.LegacyNumericUtils#PRECISION_STEP_DEFAULT} (16). The stream is not yet initialized,
+   * before using set a value using the various set<em>???</em>Value() methods.
+   */
+  public LegacyNumericTokenStream() {
+    this(AttributeFactory.DEFAULT_ATTRIBUTE_FACTORY, LegacyNumericUtils.PRECISION_STEP_DEFAULT);
+  }
+  
+  /**
+   * Creates a token stream for numeric values with the specified
+   * <code>precisionStep</code>. The stream is not yet initialized,
+   * before using set a value using the various set<em>???</em>Value() methods.
+   */
+  public LegacyNumericTokenStream(final int precisionStep) {
+    this(AttributeFactory.DEFAULT_ATTRIBUTE_FACTORY, precisionStep);
+  }
+
+  /**
+   * Expert: Creates a token stream for numeric values with the specified
+   * <code>precisionStep</code> using the given
+   * {@link org.apache.lucene.util.AttributeFactory}.
+   * The stream is not yet initialized,
+   * before using set a value using the various set<em>???</em>Value() methods.
+   */
+  public LegacyNumericTokenStream(AttributeFactory factory, final int precisionStep) {
+    super(new NumericAttributeFactory(factory));
+    if (precisionStep < 1)
+      throw new IllegalArgumentException("precisionStep must be >=1");
+    this.precisionStep = precisionStep;
+    numericAtt.setShift(-precisionStep);
+  }
+
+  /**
+   * Initializes the token stream with the supplied <code>long</code> value.
+   * @param value the value, for which this TokenStream should enumerate tokens.
+   * @return this instance, because of this you can use it the following way:
+   * <code>new Field(name, new LegacyNumericTokenStream(precisionStep).setLongValue(value))</code>
+   */
+  public LegacyNumericTokenStream setLongValue(final long value) {
+    numericAtt.init(value, valSize = 64, precisionStep, -precisionStep);
+    return this;
+  }
+  
+  /**
+   * Initializes the token stream with the supplied <code>int</code> value.
+   * @param value the value, for which this TokenStream should enumerate tokens.
+   * @return this instance, because of this you can use it the following way:
+   * <code>new Field(name, new LegacyNumericTokenStream(precisionStep).setIntValue(value))</code>
+   */
+  public LegacyNumericTokenStream setIntValue(final int value) {
+    numericAtt.init(value, valSize = 32, precisionStep, -precisionStep);
+    return this;
+  }
+  
+  /**
+   * Initializes the token stream with the supplied <code>double</code> value.
+   * @param value the value, for which this TokenStream should enumerate tokens.
+   * @return this instance, because of this you can use it the following way:
+   * <code>new Field(name, new LegacyNumericTokenStream(precisionStep).setDoubleValue(value))</code>
+   */
+  public LegacyNumericTokenStream setDoubleValue(final double value) {
+    numericAtt.init(LegacyNumericUtils.doubleToSortableLong(value), valSize = 64, precisionStep, -precisionStep);
+    return this;
+  }
+  
+  /**
+   * Initializes the token stream with the supplied <code>float</code> value.
+   * @param value the value, for which this TokenStream should enumerate tokens.
+   * @return this instance, because of this you can use it the following way:
+   * <code>new Field(name, new LegacyNumericTokenStream(precisionStep).setFloatValue(value))</code>
+   */
+  public LegacyNumericTokenStream setFloatValue(final float value) {
+    numericAtt.init(LegacyNumericUtils.floatToSortableInt(value), valSize = 32, precisionStep, -precisionStep);
+    return this;
+  }
+  
+  @Override
+  public void reset() {
+    if (valSize == 0)
+      throw new IllegalStateException("call set???Value() before usage");
+    numericAtt.setShift(-precisionStep);
+  }
+
+  @Override
+  public boolean incrementToken() {
+    if (valSize == 0)
+      throw new IllegalStateException("call set???Value() before usage");
+    
+    // this will only clear all other attributes in this TokenStream
+    clearAttributes();
+
+    final int shift = numericAtt.incShift();
+    typeAtt.setType((shift == 0) ? TOKEN_TYPE_FULL_PREC : TOKEN_TYPE_LOWER_PREC);
+    posIncrAtt.setPositionIncrement((shift == 0) ? 1 : 0);
+    return (shift < valSize);
+  }
+
+  /** Returns the precision step. */
+  public int getPrecisionStep() {
+    return precisionStep;
+  }
+
+  @Override
+  public String toString() {
+    // We override default because it can throw cryptic "illegal shift value":
+    return getClass().getSimpleName() + "(precisionStep=" + precisionStep + " valueSize=" + numericAtt.getValueSize() + " shift=" + numericAtt.getShift() + ")";
+  }
+  
+  // members
+  private final LegacyNumericTermAttribute numericAtt = addAttribute(LegacyNumericTermAttribute.class);
+  private final TypeAttribute typeAtt = addAttribute(TypeAttribute.class);
+  private final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);
+  
+  private int valSize = 0; // valSize==0 means not initialized
+  private final int precisionStep;
+}
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/NumericTokenStream.java b/lucene/core/src/java/org/apache/lucene/analysis/NumericTokenStream.java
deleted file mode 100644
index d3210f6..0000000
--- a/lucene/core/src/java/org/apache/lucene/analysis/NumericTokenStream.java
+++ /dev/null
@@ -1,356 +0,0 @@
-package org.apache.lucene.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.util.Objects;
-
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
-import org.apache.lucene.analysis.tokenattributes.TermToBytesRefAttribute;
-import org.apache.lucene.analysis.tokenattributes.TypeAttribute;
-import org.apache.lucene.document.DoubleField; // for javadocs
-import org.apache.lucene.document.FloatField; // for javadocs
-import org.apache.lucene.document.IntField; // for javadocs
-import org.apache.lucene.document.LongField; // for javadocs
-import org.apache.lucene.search.NumericRangeQuery;
-import org.apache.lucene.util.Attribute;
-import org.apache.lucene.util.AttributeFactory;
-import org.apache.lucene.util.AttributeImpl;
-import org.apache.lucene.util.AttributeReflector;
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.BytesRefBuilder;
-import org.apache.lucene.util.NumericUtils;
-
-/**
- * <b>Expert:</b> This class provides a {@link TokenStream}
- * for indexing numeric values that can be used by {@link
- * NumericRangeQuery}.
- *
- * <p>Note that for simple usage, {@link IntField}, {@link
- * LongField}, {@link FloatField} or {@link DoubleField} is
- * recommended.  These fields disable norms and
- * term freqs, as they are not usually needed during
- * searching.  If you need to change these settings, you
- * should use this class.
- *
- * <p>Here's an example usage, for an <code>int</code> field:
- *
- * <pre class="prettyprint">
- *  FieldType fieldType = new FieldType(TextField.TYPE_NOT_STORED);
- *  fieldType.setOmitNorms(true);
- *  fieldType.setIndexOptions(IndexOptions.DOCS_ONLY);
- *  Field field = new Field(name, new NumericTokenStream(precisionStep).setIntValue(value), fieldType);
- *  document.add(field);
- * </pre>
- *
- * <p>For optimal performance, re-use the TokenStream and Field instance
- * for more than one document:
- *
- * <pre class="prettyprint">
- *  NumericTokenStream stream = new NumericTokenStream(precisionStep);
- *  FieldType fieldType = new FieldType(TextField.TYPE_NOT_STORED);
- *  fieldType.setOmitNorms(true);
- *  fieldType.setIndexOptions(IndexOptions.DOCS_ONLY);
- *  Field field = new Field(name, stream, fieldType);
- *  Document document = new Document();
- *  document.add(field);
- *
- *  for(all documents) {
- *    stream.setIntValue(value)
- *    writer.addDocument(document);
- *  }
- * </pre>
- *
- * <p>This stream is not intended to be used in analyzers;
- * it's more for iterating the different precisions during
- * indexing a specific numeric value.</p>
-
- * <p><b>NOTE</b>: as token streams are only consumed once
- * the document is added to the index, if you index more
- * than one numeric field, use a separate <code>NumericTokenStream</code>
- * instance for each.</p>
- *
- * <p>See {@link NumericRangeQuery} for more details on the
- * <a
- * href="../search/NumericRangeQuery.html#precisionStepDesc"><code>precisionStep</code></a>
- * parameter as well as how numeric fields work under the hood.</p>
- *
- * @since 2.9
- */
-public final class NumericTokenStream extends TokenStream {
-
-  /** The full precision token gets this token type assigned. */
-  public static final String TOKEN_TYPE_FULL_PREC  = "fullPrecNumeric";
-
-  /** The lower precision tokens gets this token type assigned. */
-  public static final String TOKEN_TYPE_LOWER_PREC = "lowerPrecNumeric";
-  
-  /** <b>Expert:</b> Use this attribute to get the details of the currently generated token.
-   * @lucene.experimental
-   * @since 4.0
-   */
-  public interface NumericTermAttribute extends Attribute {
-    /** Returns current shift value, undefined before first token */
-    int getShift();
-    /** Returns current token's raw value as {@code long} with all {@link #getShift} applied, undefined before first token */
-    long getRawValue();
-    /** Returns value size in bits (32 for {@code float}, {@code int}; 64 for {@code double}, {@code long}) */
-    int getValueSize();
-    
-    /** <em>Don't call this method!</em>
-      * @lucene.internal */
-    void init(long value, int valSize, int precisionStep, int shift);
-
-    /** <em>Don't call this method!</em>
-      * @lucene.internal */
-    void setShift(int shift);
-
-    /** <em>Don't call this method!</em>
-      * @lucene.internal */
-    int incShift();
-  }
-  
-  // just a wrapper to prevent adding CTA
-  private static final class NumericAttributeFactory extends AttributeFactory {
-    private final AttributeFactory delegate;
-
-    NumericAttributeFactory(AttributeFactory delegate) {
-      this.delegate = delegate;
-    }
-  
-    @Override
-    public AttributeImpl createAttributeInstance(Class<? extends Attribute> attClass) {
-      if (CharTermAttribute.class.isAssignableFrom(attClass))
-        throw new IllegalArgumentException("NumericTokenStream does not support CharTermAttribute.");
-      return delegate.createAttributeInstance(attClass);
-    }
-  }
-
-  /** Implementation of {@link NumericTermAttribute}.
-   * @lucene.internal
-   * @since 4.0
-   */
-  public static final class NumericTermAttributeImpl extends AttributeImpl implements NumericTermAttribute,TermToBytesRefAttribute {
-    private long value = 0L;
-    private int valueSize = 0, shift = 0, precisionStep = 0;
-    private BytesRefBuilder bytes = new BytesRefBuilder();
-    
-    /** 
-     * Creates, but does not yet initialize this attribute instance
-     * @see #init(long, int, int, int)
-     */
-    public NumericTermAttributeImpl() {}
-
-    @Override
-    public BytesRef getBytesRef() {
-      assert valueSize == 64 || valueSize == 32;
-      if (valueSize == 64) {
-        NumericUtils.longToPrefixCoded(value, shift, bytes);
-      } else {
-        NumericUtils.intToPrefixCoded((int) value, shift, bytes);
-      }
-      return bytes.get();
-    }
-
-    @Override
-    public int getShift() { return shift; }
-    @Override
-    public void setShift(int shift) { this.shift = shift; }
-    @Override
-    public int incShift() {
-      return (shift += precisionStep);
-    }
-
-    @Override
-    public long getRawValue() { return value  & ~((1L << shift) - 1L); }
-    @Override
-    public int getValueSize() { return valueSize; }
-
-    @Override
-    public void init(long value, int valueSize, int precisionStep, int shift) {
-      this.value = value;
-      this.valueSize = valueSize;
-      this.precisionStep = precisionStep;
-      this.shift = shift;
-    }
-
-    @Override
-    public void clear() {
-      // this attribute has no contents to clear!
-      // we keep it untouched as it's fully controlled by outer class.
-    }
-    
-    @Override
-    public void reflectWith(AttributeReflector reflector) {
-      reflector.reflect(TermToBytesRefAttribute.class, "bytes", getBytesRef());
-      reflector.reflect(NumericTermAttribute.class, "shift", shift);
-      reflector.reflect(NumericTermAttribute.class, "rawValue", getRawValue());
-      reflector.reflect(NumericTermAttribute.class, "valueSize", valueSize);
-    }
-  
-    @Override
-    public void copyTo(AttributeImpl target) {
-      final NumericTermAttribute a = (NumericTermAttribute) target;
-      a.init(value, valueSize, precisionStep, shift);
-    }
-    
-    @Override
-    public NumericTermAttributeImpl clone() {
-      NumericTermAttributeImpl t = (NumericTermAttributeImpl)super.clone();
-      // Do a deep clone
-      t.bytes = new BytesRefBuilder();
-      t.bytes.copyBytes(getBytesRef());
-      return t;
-    }
-
-    @Override
-    public int hashCode() {
-      return Objects.hash(precisionStep, shift, value, valueSize);
-    }
-
-    @Override
-    public boolean equals(Object obj) {
-      if (this == obj) return true;
-      if (obj == null) return false;
-      if (getClass() != obj.getClass()) return false;
-      NumericTermAttributeImpl other = (NumericTermAttributeImpl) obj;
-      if (precisionStep != other.precisionStep) return false;
-      if (shift != other.shift) return false;
-      if (value != other.value) return false;
-      if (valueSize != other.valueSize) return false;
-      return true;
-    }
-  }
-  
-  /**
-   * Creates a token stream for numeric values using the default <code>precisionStep</code>
-   * {@link NumericUtils#PRECISION_STEP_DEFAULT} (16). The stream is not yet initialized,
-   * before using set a value using the various set<em>???</em>Value() methods.
-   */
-  public NumericTokenStream() {
-    this(AttributeFactory.DEFAULT_ATTRIBUTE_FACTORY, NumericUtils.PRECISION_STEP_DEFAULT);
-  }
-  
-  /**
-   * Creates a token stream for numeric values with the specified
-   * <code>precisionStep</code>. The stream is not yet initialized,
-   * before using set a value using the various set<em>???</em>Value() methods.
-   */
-  public NumericTokenStream(final int precisionStep) {
-    this(AttributeFactory.DEFAULT_ATTRIBUTE_FACTORY, precisionStep);
-  }
-
-  /**
-   * Expert: Creates a token stream for numeric values with the specified
-   * <code>precisionStep</code> using the given
-   * {@link org.apache.lucene.util.AttributeFactory}.
-   * The stream is not yet initialized,
-   * before using set a value using the various set<em>???</em>Value() methods.
-   */
-  public NumericTokenStream(AttributeFactory factory, final int precisionStep) {
-    super(new NumericAttributeFactory(factory));
-    if (precisionStep < 1)
-      throw new IllegalArgumentException("precisionStep must be >=1");
-    this.precisionStep = precisionStep;
-    numericAtt.setShift(-precisionStep);
-  }
-
-  /**
-   * Initializes the token stream with the supplied <code>long</code> value.
-   * @param value the value, for which this TokenStream should enumerate tokens.
-   * @return this instance, because of this you can use it the following way:
-   * <code>new Field(name, new NumericTokenStream(precisionStep).setLongValue(value))</code>
-   */
-  public NumericTokenStream setLongValue(final long value) {
-    numericAtt.init(value, valSize = 64, precisionStep, -precisionStep);
-    return this;
-  }
-  
-  /**
-   * Initializes the token stream with the supplied <code>int</code> value.
-   * @param value the value, for which this TokenStream should enumerate tokens.
-   * @return this instance, because of this you can use it the following way:
-   * <code>new Field(name, new NumericTokenStream(precisionStep).setIntValue(value))</code>
-   */
-  public NumericTokenStream setIntValue(final int value) {
-    numericAtt.init(value, valSize = 32, precisionStep, -precisionStep);
-    return this;
-  }
-  
-  /**
-   * Initializes the token stream with the supplied <code>double</code> value.
-   * @param value the value, for which this TokenStream should enumerate tokens.
-   * @return this instance, because of this you can use it the following way:
-   * <code>new Field(name, new NumericTokenStream(precisionStep).setDoubleValue(value))</code>
-   */
-  public NumericTokenStream setDoubleValue(final double value) {
-    numericAtt.init(NumericUtils.doubleToSortableLong(value), valSize = 64, precisionStep, -precisionStep);
-    return this;
-  }
-  
-  /**
-   * Initializes the token stream with the supplied <code>float</code> value.
-   * @param value the value, for which this TokenStream should enumerate tokens.
-   * @return this instance, because of this you can use it the following way:
-   * <code>new Field(name, new NumericTokenStream(precisionStep).setFloatValue(value))</code>
-   */
-  public NumericTokenStream setFloatValue(final float value) {
-    numericAtt.init(NumericUtils.floatToSortableInt(value), valSize = 32, precisionStep, -precisionStep);
-    return this;
-  }
-  
-  @Override
-  public void reset() {
-    if (valSize == 0)
-      throw new IllegalStateException("call set???Value() before usage");
-    numericAtt.setShift(-precisionStep);
-  }
-
-  @Override
-  public boolean incrementToken() {
-    if (valSize == 0)
-      throw new IllegalStateException("call set???Value() before usage");
-    
-    // this will only clear all other attributes in this TokenStream
-    clearAttributes();
-
-    final int shift = numericAtt.incShift();
-    typeAtt.setType((shift == 0) ? TOKEN_TYPE_FULL_PREC : TOKEN_TYPE_LOWER_PREC);
-    posIncrAtt.setPositionIncrement((shift == 0) ? 1 : 0);
-    return (shift < valSize);
-  }
-
-  /** Returns the precision step. */
-  public int getPrecisionStep() {
-    return precisionStep;
-  }
-
-  @Override
-  public String toString() {
-    // We override default because it can throw cryptic "illegal shift value":
-    return getClass().getSimpleName() + "(precisionStep=" + precisionStep + " valueSize=" + numericAtt.getValueSize() + " shift=" + numericAtt.getShift() + ")";
-  }
-  
-  // members
-  private final NumericTermAttribute numericAtt = addAttribute(NumericTermAttribute.class);
-  private final TypeAttribute typeAtt = addAttribute(TypeAttribute.class);
-  private final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);
-  
-  private int valSize = 0; // valSize==0 means not initialized
-  private final int precisionStep;
-}
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/lucene60/Lucene60FieldInfosFormat.java b/lucene/core/src/java/org/apache/lucene/codecs/lucene60/Lucene60FieldInfosFormat.java
index cb4d6f7..0c105f8 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/lucene60/Lucene60FieldInfosFormat.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/lucene60/Lucene60FieldInfosFormat.java
@@ -24,7 +24,7 @@ import java.util.Map;
 import org.apache.lucene.codecs.CodecUtil;
 import org.apache.lucene.codecs.DocValuesFormat;
 import org.apache.lucene.codecs.FieldInfosFormat;
-import org.apache.lucene.document.DimensionalField;
+import org.apache.lucene.document.DimensionalLongField;
 import org.apache.lucene.index.CorruptIndexException;
 import org.apache.lucene.index.DocValuesType;
 import org.apache.lucene.index.FieldInfo;
@@ -97,7 +97,7 @@ import org.apache.lucene.store.IndexOutput;
  *       are updates stored by {@link DocValuesFormat}.</li>
  *   <li>Attributes: a key-value map of codec-private attributes.</li>
  *   <li>DimensionCount, DimensionNumBytes: these are non-zero only if the field is
- *       indexed dimensionally using {@link DimensionalField}</li>
+ *       indexed dimensionally, e.g. using {@link DimensionalLongField}</li>
  * </ul>
  *
  * @lucene.experimental
diff --git a/lucene/core/src/java/org/apache/lucene/document/DateTools.java b/lucene/core/src/java/org/apache/lucene/document/DateTools.java
index 6df73f1..e8f6622 100644
--- a/lucene/core/src/java/org/apache/lucene/document/DateTools.java
+++ b/lucene/core/src/java/org/apache/lucene/document/DateTools.java
@@ -17,11 +17,6 @@ package org.apache.lucene.document;
  * limitations under the License.
  */
 
-import org.apache.lucene.search.NumericRangeQuery; // for javadocs
-import org.apache.lucene.search.PrefixQuery;
-import org.apache.lucene.search.TermRangeQuery;
-import org.apache.lucene.util.NumericUtils;        // for javadocs
-
 import java.text.ParseException;
 import java.text.SimpleDateFormat;
 import java.util.Calendar;
@@ -29,6 +24,10 @@ import java.util.Date;
 import java.util.Locale;
 import java.util.TimeZone;
 
+import org.apache.lucene.search.DimensionalRangeQuery;
+import org.apache.lucene.search.PrefixQuery;
+import org.apache.lucene.search.TermRangeQuery;
+
 /**
  * Provides support for converting dates to strings and vice-versa.
  * The strings are structured so that lexicographic sorting orders 
@@ -40,13 +39,12 @@ import java.util.TimeZone;
  * {@link TermRangeQuery} and {@link PrefixQuery} will require more memory and become slower.
  * 
  * <P>
- * Another approach is {@link NumericUtils}, which provides
- * a sortable binary representation (prefix encoded) of numeric values, which
- * date/time are.
+ * Another approach is {@link DimensionalLongField}, which indexes the
+ * values in sorted order.
  * For indexing a {@link Date} or {@link Calendar}, just get the unix timestamp as
  * <code>long</code> using {@link Date#getTime} or {@link Calendar#getTimeInMillis} and
- * index this as a numeric value with {@link LongField}
- * and use {@link NumericRangeQuery} to query it.
+ * index this as a numeric value with {@link DimensionalLongField}
+ * and use {@link DimensionalRangeQuery} to query it.
  */
 public class DateTools {
   
diff --git a/lucene/core/src/java/org/apache/lucene/document/DimensionalBinaryField.java b/lucene/core/src/java/org/apache/lucene/document/DimensionalBinaryField.java
new file mode 100644
index 0000000..718a101
--- /dev/null
+++ b/lucene/core/src/java/org/apache/lucene/document/DimensionalBinaryField.java
@@ -0,0 +1,110 @@
+package org.apache.lucene.document;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.util.BytesRef;
+
+/** A binary field that is indexed dimensionally such that finding
+ *  all documents within an N-dimensional shape or range at search time is
+ *  efficient.  Muliple values for the same field in one documents
+ *  is allowed. */
+
+public final class DimensionalBinaryField extends Field {
+
+  private static FieldType getType(byte[][] point) {
+    if (point == null) {
+      throw new IllegalArgumentException("point cannot be null");
+    }
+    if (point.length == 0) {
+      throw new IllegalArgumentException("point cannot be 0 dimensions");
+    }
+    int bytesPerDim = -1;
+    for(int i=0;i<point.length;i++) {
+      byte[] oneDim = point[i];
+      if (oneDim == null) {
+        throw new IllegalArgumentException("point cannot have null values");
+      }
+      if (oneDim.length == 0) {
+        throw new IllegalArgumentException("point cannot have 0-length values");
+      }
+      if (bytesPerDim == -1) {
+        bytesPerDim = oneDim.length;
+      } else if (bytesPerDim != oneDim.length) {
+        throw new IllegalArgumentException("all dimensions must have same bytes length; got " + bytesPerDim + " and " + oneDim.length);
+      }
+    }
+    return getType(point.length, bytesPerDim);
+  }
+
+  private static FieldType getType(int numDims, int bytesPerDim) {
+    FieldType type = new FieldType();
+    type.setDimensions(numDims, bytesPerDim);
+    type.freeze();
+    return type;
+  }
+
+  private static BytesRef pack(byte[]... point) {
+    if (point == null) {
+      throw new IllegalArgumentException("point cannot be null");
+    }
+    if (point.length == 0) {
+      throw new IllegalArgumentException("point cannot be 0 dimensions");
+    }
+    if (point.length == 1) {
+      return new BytesRef(point[0]);
+    }
+    int bytesPerDim = -1;
+    for(byte[] dim : point) {
+      if (dim == null) {
+        throw new IllegalArgumentException("point cannot have null values");
+      }
+      if (bytesPerDim == -1) {
+        if (dim.length == 0) {
+          throw new IllegalArgumentException("point cannot have 0-length values");
+        }
+        bytesPerDim = dim.length;
+      } else if (dim.length != bytesPerDim) {
+        throw new IllegalArgumentException("all dimensions must have same bytes length; got " + bytesPerDim + " and " + dim.length);
+      }
+    }
+    byte[] packed = new byte[bytesPerDim*point.length];
+    for(int i=0;i<point.length;i++) {
+      System.arraycopy(point[i], 0, packed, i*bytesPerDim, bytesPerDim);
+    }
+    return new BytesRef(packed);
+  }
+
+  /** General purpose API: creates a new DimensionalField, indexing the
+   *  provided N-dimensional binary point.
+   *
+   *  @param name field name
+   *  @param point byte[][] value
+   *  @throws IllegalArgumentException if the field name or value is null.
+   */
+  public DimensionalBinaryField(String name, byte[]... point) {
+    super(name, pack(point), getType(point));
+  }
+
+  /** Expert API */
+  public DimensionalBinaryField(String name, byte[] packedPoint, FieldType type) {
+    super(name, packedPoint, type);
+    if (packedPoint.length != type.dimensionCount() * type.dimensionNumBytes()) {
+      throw new IllegalArgumentException("packedPoint is length=" + packedPoint.length + " but type.dimensionCount()=" + type.dimensionCount() + " and type.dimensionNumBytes()=" + type.dimensionNumBytes());
+    }
+  }
+}
diff --git a/lucene/core/src/java/org/apache/lucene/document/DimensionalDoubleField.java b/lucene/core/src/java/org/apache/lucene/document/DimensionalDoubleField.java
new file mode 100644
index 0000000..db93cd4
--- /dev/null
+++ b/lucene/core/src/java/org/apache/lucene/document/DimensionalDoubleField.java
@@ -0,0 +1,86 @@
+package org.apache.lucene.document;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.NumericUtils;
+import org.apache.lucene.util.RamUsageEstimator;
+
+/** A double field that is indexed dimensionally such that finding
+ *  all documents within an N-dimensional shape or range at search time is
+ *  efficient.  Muliple values for the same field in one documents
+ *  is allowed. */
+
+public final class DimensionalDoubleField extends Field {
+
+  private static FieldType getType(int numDims) {
+    FieldType type = new FieldType();
+    type.setDimensions(numDims, RamUsageEstimator.NUM_BYTES_LONG);
+    type.freeze();
+    return type;
+  }
+
+  @Override
+  public void setDoubleValue(double value) {
+    setDoubleValues(value);
+  }
+
+  /** Change the values of this field */
+  public void setDoubleValues(double... point) {
+    fieldsData = pack(point);
+  }
+
+  @Override
+  public void setBytesValue(BytesRef bytes) {
+    throw new IllegalArgumentException("cannot change value type from double to BytesRef");
+  }
+
+  @Override
+  public Number numericValue() {
+    BytesRef bytes = (BytesRef) fieldsData;
+    assert bytes.length == RamUsageEstimator.NUM_BYTES_LONG;
+    return NumericUtils.sortableLongToDouble(NumericUtils.bytesToLongDirect(bytes.bytes, bytes.offset));
+  }
+
+  private static BytesRef pack(double... point) {
+    if (point == null) {
+      throw new IllegalArgumentException("point cannot be null");
+    }
+    if (point.length == 0) {
+      throw new IllegalArgumentException("point cannot be 0 dimensions");
+    }
+    byte[] packed = new byte[point.length * RamUsageEstimator.NUM_BYTES_LONG];
+    
+    for(int dim=0;dim<point.length;dim++) {
+      NumericUtils.longToBytesDirect(NumericUtils.doubleToSortableLong(point[dim]), packed, dim);
+    }
+
+    return new BytesRef(packed);
+  }
+
+  /** Creates a new DimensionalDoubleField, indexing the
+   *  provided N-dimensional int point.
+   *
+   *  @param name field name
+   *  @param point double[] value
+   *  @throws IllegalArgumentException if the field name or value is null.
+   */
+  public DimensionalDoubleField(String name, double... point) {
+    super(name, pack(point), getType(point.length));
+  }
+}
diff --git a/lucene/core/src/java/org/apache/lucene/document/DimensionalField.java b/lucene/core/src/java/org/apache/lucene/document/DimensionalField.java
deleted file mode 100644
index 5e95d01..0000000
--- a/lucene/core/src/java/org/apache/lucene/document/DimensionalField.java
+++ /dev/null
@@ -1,139 +0,0 @@
-package org.apache.lucene.document;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.RamUsageEstimator;
-import org.apache.lucene.util.bkd.BKDUtil;
-
-/** A field that is indexed dimensionally such that finding
- *  all documents within an N-dimensional at search time is
- *  efficient.  Muliple values for the same field in one documents
- *  is allowed. */
-
-public final class DimensionalField extends Field {
-
-  private static FieldType getType(byte[][] point) {
-    if (point == null) {
-      throw new IllegalArgumentException("point cannot be null");
-    }
-    if (point.length == 0) {
-      throw new IllegalArgumentException("point cannot be 0 dimensions");
-    }
-    int bytesPerDim = -1;
-    for(int i=0;i<point.length;i++) {
-      byte[] oneDim = point[i];
-      if (oneDim == null) {
-        throw new IllegalArgumentException("point cannot have null values");
-      }
-      if (oneDim.length == 0) {
-        throw new IllegalArgumentException("point cannot have 0-length values");
-      }
-      if (bytesPerDim == -1) {
-        bytesPerDim = oneDim.length;
-      } else if (bytesPerDim != oneDim.length) {
-        throw new IllegalArgumentException("all dimensions must have same bytes length; got " + bytesPerDim + " and " + oneDim.length);
-      }
-    }
-    return getType(point.length, bytesPerDim);
-  }
-
-  private static FieldType getType(int numDims, int bytesPerDim) {
-    FieldType type = new FieldType();
-    type.setDimensions(numDims, bytesPerDim);
-    type.freeze();
-    return type;
-  }
-
-  private static BytesRef pack(byte[]... point) {
-    if (point == null) {
-      throw new IllegalArgumentException("point cannot be null");
-    }
-    if (point.length == 0) {
-      throw new IllegalArgumentException("point cannot be 0 dimensions");
-    }
-    if (point.length == 1) {
-      return new BytesRef(point[0]);
-    }
-    int bytesPerDim = -1;
-    for(byte[] dim : point) {
-      if (dim == null) {
-        throw new IllegalArgumentException("point cannot have null values");
-      }
-      if (bytesPerDim == -1) {
-        if (dim.length == 0) {
-          throw new IllegalArgumentException("point cannot have 0-length values");
-        }
-        bytesPerDim = dim.length;
-      } else if (dim.length != bytesPerDim) {
-        throw new IllegalArgumentException("all dimensions must have same bytes length; got " + bytesPerDim + " and " + dim.length);
-      }
-    }
-    byte[] packed = new byte[bytesPerDim*point.length];
-    for(int i=0;i<point.length;i++) {
-      System.arraycopy(point[i], 0, packed, i*bytesPerDim, bytesPerDim);
-    }
-    return new BytesRef(packed);
-  }
-
-  private static BytesRef pack(long... point) {
-    if (point == null) {
-      throw new IllegalArgumentException("point cannot be null");
-    }
-    if (point.length == 0) {
-      throw new IllegalArgumentException("point cannot be 0 dimensions");
-    }
-    byte[] packed = new byte[point.length * RamUsageEstimator.NUM_BYTES_LONG];
-    
-    for(int dim=0;dim<point.length;dim++) {
-      BKDUtil.longToBytes(point[dim], packed, dim);
-    }
-
-    return new BytesRef(packed);
-  }
-
-  /** General purpose API: creates a new DimensionalField, indexing the
-   *  provided N-dimensional binary point.
-   *
-   *  @param name field name
-   *  @param point byte[][] value
-   *  @throws IllegalArgumentException if the field name or value is null.
-   */
-  public DimensionalField(String name, byte[]... point) {
-    super(name, pack(point), getType(point));
-  }
-
-  /** General purpose API: creates a new DimensionalField, indexing the
-   *  provided N-dimensional long point.
-   *
-   *  @param name field name
-   *  @param point long[] value
-   *  @throws IllegalArgumentException if the field name or value is null.
-   */
-  public DimensionalField(String name, long... point) {
-    super(name, pack(point), getType(point.length, RamUsageEstimator.NUM_BYTES_LONG));
-  }
-
-  /** Expert API */
-  public DimensionalField(String name, byte[] packedPoint, FieldType type) {
-    super(name, packedPoint, type);
-    if (packedPoint.length != type.dimensionCount() * type.dimensionNumBytes()) {
-      throw new IllegalArgumentException("packedPoint is length=" + packedPoint.length + " but type.dimensionCount()=" + type.dimensionCount() + " and type.dimensionNumBytes()=" + type.dimensionNumBytes());
-    }
-  }
-}
diff --git a/lucene/core/src/java/org/apache/lucene/document/DimensionalFloatField.java b/lucene/core/src/java/org/apache/lucene/document/DimensionalFloatField.java
new file mode 100644
index 0000000..1fd6ea8
--- /dev/null
+++ b/lucene/core/src/java/org/apache/lucene/document/DimensionalFloatField.java
@@ -0,0 +1,86 @@
+package org.apache.lucene.document;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.NumericUtils;
+import org.apache.lucene.util.RamUsageEstimator;
+
+/** A field that is indexed dimensionally such that finding
+ *  all documents within an N-dimensional at search time is
+ *  efficient.  Muliple values for the same field in one documents
+ *  is allowed. */
+
+public final class DimensionalFloatField extends Field {
+
+  private static FieldType getType(int numDims) {
+    FieldType type = new FieldType();
+    type.setDimensions(numDims, RamUsageEstimator.NUM_BYTES_INT);
+    type.freeze();
+    return type;
+  }
+
+  @Override
+  public void setFloatValue(float value) {
+    setFloatValues(value);
+  }
+
+  /** Change the values of this field */
+  public void setFloatValues(float... point) {
+    fieldsData = pack(point);
+  }
+
+  @Override
+  public void setBytesValue(BytesRef bytes) {
+    throw new IllegalArgumentException("cannot change value type from float to BytesRef");
+  }
+
+  @Override
+  public Number numericValue() {
+    BytesRef bytes = (BytesRef) fieldsData;
+    assert bytes.length == RamUsageEstimator.NUM_BYTES_INT;
+    return NumericUtils.sortableIntToFloat(NumericUtils.bytesToIntDirect(bytes.bytes, bytes.offset));
+  }
+
+  private static BytesRef pack(float... point) {
+    if (point == null) {
+      throw new IllegalArgumentException("point cannot be null");
+    }
+    if (point.length == 0) {
+      throw new IllegalArgumentException("point cannot be 0 dimensions");
+    }
+    byte[] packed = new byte[point.length * RamUsageEstimator.NUM_BYTES_INT];
+    
+    for(int dim=0;dim<point.length;dim++) {
+      NumericUtils.intToBytesDirect(NumericUtils.floatToSortableInt(point[dim]), packed, dim);
+    }
+
+    return new BytesRef(packed);
+  }
+
+  /** Creates a new DimensionalFloatField, indexing the
+   *  provided N-dimensional float point.
+   *
+   *  @param name field name
+   *  @param point int[] value
+   *  @throws IllegalArgumentException if the field name or value is null.
+   */
+  public DimensionalFloatField(String name, float... point) {
+    super(name, pack(point), getType(point.length));
+  }
+}
diff --git a/lucene/core/src/java/org/apache/lucene/document/DimensionalIntField.java b/lucene/core/src/java/org/apache/lucene/document/DimensionalIntField.java
new file mode 100644
index 0000000..83604a9
--- /dev/null
+++ b/lucene/core/src/java/org/apache/lucene/document/DimensionalIntField.java
@@ -0,0 +1,86 @@
+package org.apache.lucene.document;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.NumericUtils;
+import org.apache.lucene.util.RamUsageEstimator;
+
+/** An int field that is indexed dimensionally such that finding
+ *  all documents within an N-dimensional shape or range at search time is
+ *  efficient.  Muliple values for the same field in one documents
+ *  is allowed. */
+
+public final class DimensionalIntField extends Field {
+
+  private static FieldType getType(int numDims) {
+    FieldType type = new FieldType();
+    type.setDimensions(numDims, RamUsageEstimator.NUM_BYTES_INT);
+    type.freeze();
+    return type;
+  }
+
+  @Override
+  public void setIntValue(int value) {
+    setIntValues(value);
+  }
+
+  /** Change the values of this field */
+  public void setIntValues(int... point) {
+    fieldsData = pack(point);
+  }
+
+  @Override
+  public void setBytesValue(BytesRef bytes) {
+    throw new IllegalArgumentException("cannot change value type from int to BytesRef");
+  }
+
+  @Override
+  public Number numericValue() {
+    BytesRef bytes = (BytesRef) fieldsData;
+    assert bytes.length == RamUsageEstimator.NUM_BYTES_INT;
+    return NumericUtils.bytesToInt(bytes.bytes, bytes.offset);
+  }
+
+  private static BytesRef pack(int... point) {
+    if (point == null) {
+      throw new IllegalArgumentException("point cannot be null");
+    }
+    if (point.length == 0) {
+      throw new IllegalArgumentException("point cannot be 0 dimensions");
+    }
+    byte[] packed = new byte[point.length * RamUsageEstimator.NUM_BYTES_INT];
+    
+    for(int dim=0;dim<point.length;dim++) {
+      NumericUtils.intToBytes(point[dim], packed, dim);
+    }
+
+    return new BytesRef(packed);
+  }
+
+  /** Creates a new DimensionalIntField, indexing the
+   *  provided N-dimensional int point.
+   *
+   *  @param name field name
+   *  @param point int[] value
+   *  @throws IllegalArgumentException if the field name or value is null.
+   */
+  public DimensionalIntField(String name, int... point) {
+    super(name, pack(point), getType(point.length));
+  }
+}
diff --git a/lucene/core/src/java/org/apache/lucene/document/DimensionalLongField.java b/lucene/core/src/java/org/apache/lucene/document/DimensionalLongField.java
new file mode 100644
index 0000000..752adef
--- /dev/null
+++ b/lucene/core/src/java/org/apache/lucene/document/DimensionalLongField.java
@@ -0,0 +1,86 @@
+package org.apache.lucene.document;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.NumericUtils;
+import org.apache.lucene.util.RamUsageEstimator;
+
+/** A long field that is indexed dimensionally such that finding
+ *  all documents within an N-dimensional shape or range at search time is
+ *  efficient.  Muliple values for the same field in one documents
+ *  is allowed. */
+
+public final class DimensionalLongField extends Field {
+
+  private static FieldType getType(int numDims) {
+    FieldType type = new FieldType();
+    type.setDimensions(numDims, RamUsageEstimator.NUM_BYTES_LONG);
+    type.freeze();
+    return type;
+  }
+
+  @Override
+  public void setLongValue(long value) {
+    setLongValues(value);
+  }
+
+  /** Change the values of this field */
+  public void setLongValues(long... point) {
+    fieldsData = pack(point);
+  }
+
+  @Override
+  public void setBytesValue(BytesRef bytes) {
+    throw new IllegalArgumentException("cannot change value type from long to BytesRef");
+  }
+
+  @Override
+  public Number numericValue() {
+    BytesRef bytes = (BytesRef) fieldsData;
+    assert bytes.length == RamUsageEstimator.NUM_BYTES_LONG;
+    return NumericUtils.bytesToLong(bytes.bytes, bytes.offset);
+  }
+
+  private static BytesRef pack(long... point) {
+    if (point == null) {
+      throw new IllegalArgumentException("point cannot be null");
+    }
+    if (point.length == 0) {
+      throw new IllegalArgumentException("point cannot be 0 dimensions");
+    }
+    byte[] packed = new byte[point.length * RamUsageEstimator.NUM_BYTES_LONG];
+    
+    for(int dim=0;dim<point.length;dim++) {
+      NumericUtils.longToBytes(point[dim], packed, dim);
+    }
+
+    return new BytesRef(packed);
+  }
+
+  /** Creates a new DimensionalLongField, indexing the
+   *  provided N-dimensional int point.
+   *
+   *  @param name field name
+   *  @param point int[] value
+   *  @throws IllegalArgumentException if the field name or value is null.
+   */
+  public DimensionalLongField(String name, long... point) {
+    super(name, pack(point), getType(point.length));
+  }
+}
diff --git a/lucene/core/src/java/org/apache/lucene/document/Document.java b/lucene/core/src/java/org/apache/lucene/document/Document.java
index 71f661c..b19a2f2 100644
--- a/lucene/core/src/java/org/apache/lucene/document/Document.java
+++ b/lucene/core/src/java/org/apache/lucene/document/Document.java
@@ -229,8 +229,8 @@ public final class Document implements IndexDocument {
    * Returns an array of values of the field specified as the method parameter.
    * This method returns an empty array when there are no
    * matching fields.  It never returns null.
-   * For {@link IntField}, {@link LongField}, {@link
-   * FloatField} and {@link DoubleField} it returns the string value of the number. If you want
+   * For {@link LegacyIntField}, {@link LegacyLongField}, {@link
+   * LegacyFloatField} and {@link LegacyDoubleField} it returns the string value of the number. If you want
    * the actual numeric field instances back, use {@link #getFields}.
    * @param name the name of the field
    * @return a <code>String[]</code> of field values
@@ -256,8 +256,8 @@ public final class Document implements IndexDocument {
    * this document, or null.  If multiple fields exist with this name, this
    * method returns the first value added. If only binary fields with this name
    * exist, returns null.
-   * For {@link IntField}, {@link LongField}, {@link
-   * FloatField} and {@link DoubleField} it returns the string value of the number. If you want
+   * For {@link LegacyIntField}, {@link LegacyLongField}, {@link
+   * LegacyFloatField} and {@link LegacyDoubleField} it returns the string value of the number. If you want
    * the actual numeric field instance back, use {@link #getField}.
    */
   public final String get(String name) {
diff --git a/lucene/core/src/java/org/apache/lucene/document/DoubleField.java b/lucene/core/src/java/org/apache/lucene/document/DoubleField.java
deleted file mode 100644
index 04ffeff..0000000
--- a/lucene/core/src/java/org/apache/lucene/document/DoubleField.java
+++ /dev/null
@@ -1,171 +0,0 @@
-package org.apache.lucene.document;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.NumericTokenStream; // javadocs
-import org.apache.lucene.index.IndexOptions;
-import org.apache.lucene.search.NumericRangeQuery; // javadocs
-import org.apache.lucene.util.NumericUtils;
-
-/**
- * <p>
- * Field that indexes <code>double</code> values
- * for efficient range filtering and sorting. Here's an example usage:
- * 
- * <pre class="prettyprint">
- * document.add(new DoubleField(name, 6.0, Field.Store.NO));
- * </pre>
- * 
- * For optimal performance, re-use the <code>DoubleField</code> and
- * {@link Document} instance for more than one document:
- * 
- * <pre class="prettyprint">
- *  DoubleField field = new DoubleField(name, 0.0, Field.Store.NO);
- *  Document document = new Document();
- *  document.add(field);
- * 
- *  for(all documents) {
- *    ...
- *    field.setDoubleValue(value)
- *    writer.addDocument(document);
- *    ...
- *  }
- * </pre>
- *
- * See also {@link IntField}, {@link LongField}, {@link
- * FloatField}.
- *
- * <p>To perform range querying or filtering against a
- * <code>DoubleField</code>, use {@link NumericRangeQuery}.
- * To sort according to a
- * <code>DoubleField</code>, use the normal numeric sort types, eg
- * {@link org.apache.lucene.search.SortField.Type#DOUBLE}. <code>DoubleField</code> 
- * values can also be loaded directly from {@link org.apache.lucene.index.LeafReader#getNumericDocValues}.</p>
- *
- * <p>You may add the same field name as an <code>DoubleField</code> to
- * the same document more than once.  Range querying and
- * filtering will be the logical OR of all values; so a range query
- * will hit all documents that have at least one value in
- * the range. However sort behavior is not defined.  If you need to sort,
- * you should separately index a single-valued <code>DoubleField</code>.</p>
- *
- * <p>A <code>DoubleField</code> will consume somewhat more disk space
- * in the index than an ordinary single-valued field.
- * However, for a typical index that includes substantial
- * textual content per document, this increase will likely
- * be in the noise. </p>
- *
- * <p>Within Lucene, each numeric value is indexed as a
- * <em>trie</em> structure, where each term is logically
- * assigned to larger and larger pre-defined brackets (which
- * are simply lower-precision representations of the value).
- * The step size between each successive bracket is called the
- * <code>precisionStep</code>, measured in bits.  Smaller
- * <code>precisionStep</code> values result in larger number
- * of brackets, which consumes more disk space in the index
- * but may result in faster range search performance.  The
- * default value, 16, was selected for a reasonable tradeoff
- * of disk space consumption versus performance.  You can
- * create a custom {@link FieldType} and invoke the {@link
- * FieldType#setNumericPrecisionStep} method if you'd
- * like to change the value.  Note that you must also
- * specify a congruent value when creating {@link
- * NumericRangeQuery}.
- * For low cardinality fields larger precision steps are good.
- * If the cardinality is &lt; 100, it is fair
- * to use {@link Integer#MAX_VALUE}, which produces one
- * term per value.
- *
- * <p>For more information on the internals of numeric trie
- * indexing, including the <a
- * href="../search/NumericRangeQuery.html#precisionStepDesc"><code>precisionStep</code></a>
- * configuration, see {@link NumericRangeQuery}. The format of
- * indexed values is described in {@link NumericUtils}.
- *
- * <p>If you only need to sort by numeric value, and never
- * run range querying/filtering, you can index using a
- * <code>precisionStep</code> of {@link Integer#MAX_VALUE}.
- * This will minimize disk space consumed. </p>
- *
- * <p>More advanced users can instead use {@link
- * NumericTokenStream} directly, when indexing numbers. This
- * class is a wrapper around this token stream type for
- * easier, more intuitive usage.</p>
- *
- * @since 2.9
- */
-
-public final class DoubleField extends Field {
-  
-  /** 
-   * Type for a DoubleField that is not stored:
-   * normalization factors, frequencies, and positions are omitted.
-   */
-  public static final FieldType TYPE_NOT_STORED = new FieldType();
-  static {
-    TYPE_NOT_STORED.setTokenized(true);
-    TYPE_NOT_STORED.setOmitNorms(true);
-    TYPE_NOT_STORED.setIndexOptions(IndexOptions.DOCS);
-    TYPE_NOT_STORED.setNumericType(FieldType.NumericType.DOUBLE);
-    TYPE_NOT_STORED.freeze();
-  }
-
-  /** 
-   * Type for a stored DoubleField:
-   * normalization factors, frequencies, and positions are omitted.
-   */
-  public static final FieldType TYPE_STORED = new FieldType();
-  static {
-    TYPE_STORED.setTokenized(true);
-    TYPE_STORED.setOmitNorms(true);
-    TYPE_STORED.setIndexOptions(IndexOptions.DOCS);
-    TYPE_STORED.setNumericType(FieldType.NumericType.DOUBLE);
-    TYPE_STORED.setStored(true);
-    TYPE_STORED.freeze();
-  }
-
-  /** Creates a stored or un-stored DoubleField with the provided value
-   *  and default <code>precisionStep</code> {@link
-   *  NumericUtils#PRECISION_STEP_DEFAULT} (16). 
-   *  @param name field name
-   *  @param value 64-bit double value
-   *  @param stored Store.YES if the content should also be stored
-   *  @throws IllegalArgumentException if the field name is null. 
-   */
-  public DoubleField(String name, double value, Store stored) {
-    super(name, stored == Store.YES ? TYPE_STORED : TYPE_NOT_STORED);
-    fieldsData = Double.valueOf(value);
-  }
-  
-  /** Expert: allows you to customize the {@link
-   *  FieldType}. 
-   *  @param name field name
-   *  @param value 64-bit double value
-   *  @param type customized field type: must have {@link FieldType#numericType()}
-   *         of {@link FieldType.NumericType#DOUBLE}.
-   *  @throws IllegalArgumentException if the field name or type is null, or
-   *          if the field type does not have a DOUBLE numericType()
-   */
-  public DoubleField(String name, double value, FieldType type) {
-    super(name, type);
-    if (type.numericType() != FieldType.NumericType.DOUBLE) {
-      throw new IllegalArgumentException("type.numericType() must be DOUBLE but got " + type.numericType());
-    }
-    fieldsData = Double.valueOf(value);
-  }
-}
diff --git a/lucene/core/src/java/org/apache/lucene/document/Field.java b/lucene/core/src/java/org/apache/lucene/document/Field.java
index d0ca60e..ad4fc1c 100644
--- a/lucene/core/src/java/org/apache/lucene/document/Field.java
+++ b/lucene/core/src/java/org/apache/lucene/document/Field.java
@@ -21,12 +21,11 @@ import java.io.IOException;
 import java.io.Reader;
 
 import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.NumericTokenStream;
+import org.apache.lucene.analysis.LegacyNumericTokenStream;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.tokenattributes.BytesTermAttribute;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
 import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
-import org.apache.lucene.document.FieldType.NumericType;
 import org.apache.lucene.index.IndexOptions;
 import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.index.IndexableFieldType;
@@ -36,8 +35,8 @@ import org.apache.lucene.util.BytesRef;
 /**
  * Expert: directly create a field for a document.  Most
  * users should use one of the sugar subclasses: {@link
- * IntField}, {@link LongField}, {@link FloatField}, {@link
- * DoubleField}, {@link BinaryDocValuesField}, {@link
+ * LegacyIntField}, {@link LegacyLongField}, {@link LegacyFloatField}, {@link
+ * LegacyDoubleField}, {@link BinaryDocValuesField}, {@link
  * NumericDocValuesField}, {@link SortedDocValuesField}, {@link
  * StringField}, {@link TextField}, {@link StoredField}.
  *
@@ -504,14 +503,14 @@ public class Field implements IndexableField, StorableField {
       return null;
     }
 
-    final NumericType numericType = fieldType().numericType();
+    final FieldType.LegacyNumericType numericType = fieldType().numericType();
     if (numericType != null) {
-      if (!(reuse instanceof NumericTokenStream && ((NumericTokenStream)reuse).getPrecisionStep() == type.numericPrecisionStep())) {
+      if (!(reuse instanceof LegacyNumericTokenStream && ((LegacyNumericTokenStream)reuse).getPrecisionStep() == type.numericPrecisionStep())) {
         // lazy init the TokenStream as it is heavy to instantiate
         // (attributes,...) if not needed (stored field loading)
-        reuse = new NumericTokenStream(type.numericPrecisionStep());
+        reuse = new LegacyNumericTokenStream(type.numericPrecisionStep());
       }
-      final NumericTokenStream nts = (NumericTokenStream) reuse;
+      final LegacyNumericTokenStream nts = (LegacyNumericTokenStream) reuse;
       // initialize value in TokenStream
       final Number val = (Number) fieldsData;
       switch (numericType) {
diff --git a/lucene/core/src/java/org/apache/lucene/document/FieldType.java b/lucene/core/src/java/org/apache/lucene/document/FieldType.java
index ab7416b..f6921e7 100644
--- a/lucene/core/src/java/org/apache/lucene/document/FieldType.java
+++ b/lucene/core/src/java/org/apache/lucene/document/FieldType.java
@@ -21,8 +21,7 @@ import org.apache.lucene.analysis.Analyzer; // javadocs
 import org.apache.lucene.index.DocValuesType;
 import org.apache.lucene.index.IndexOptions;
 import org.apache.lucene.index.IndexableFieldType;
-import org.apache.lucene.search.NumericRangeQuery; // javadocs
-import org.apache.lucene.util.NumericUtils;
+import org.apache.lucene.util.LegacyNumericUtils;
 
 /**
  * Describes the properties of a field.
@@ -32,7 +31,7 @@ public class FieldType implements IndexableFieldType  {
   /** Data type of the numeric value
    * @since 3.2
    */
-  public enum NumericType {
+  public enum LegacyNumericType {
     /** 32-bit integer numeric type */
     INT, 
     /** 64-bit long numeric type */
@@ -51,9 +50,9 @@ public class FieldType implements IndexableFieldType  {
   private boolean storeTermVectorPayloads;
   private boolean omitNorms;
   private IndexOptions indexOptions = IndexOptions.NONE;
-  private NumericType numericType;
+  private LegacyNumericType numericType;
   private boolean frozen;
-  private int numericPrecisionStep = NumericUtils.PRECISION_STEP_DEFAULT;
+  private int numericPrecisionStep = LegacyNumericUtils.PRECISION_STEP_DEFAULT;
   private DocValuesType docValuesType = DocValuesType.NONE;
   private int dimensionCount;
   private int dimensionNumBytes;
@@ -301,20 +300,20 @@ public class FieldType implements IndexableFieldType  {
    *         future modifications.
    * @see #numericType()
    */
-  public void setNumericType(NumericType type) {
+  public void setNumericType(LegacyNumericType type) {
     checkIfFrozen();
     numericType = type;
   }
 
   /** 
-   * NumericType: if non-null then the field's value will be indexed
-   * numerically so that {@link NumericRangeQuery} can be used at 
+   * LegacyNumericType: if non-null then the field's value will be indexed
+   * numerically so that {@link org.apache.lucene.search.LegacyNumericRangeQuery} can be used at
    * search time. 
    * <p>
    * The default is <code>null</code> (no numeric type) 
-   * @see #setNumericType(NumericType)
+   * @see #setNumericType(org.apache.lucene.document.FieldType.LegacyNumericType)
    */
-  public NumericType numericType() {
+  public LegacyNumericType numericType() {
     return numericType;
   }
 
@@ -339,7 +338,7 @@ public class FieldType implements IndexableFieldType  {
    * <p>
    * This has no effect if {@link #numericType()} returns null.
    * <p>
-   * The default is {@link NumericUtils#PRECISION_STEP_DEFAULT}
+   * The default is {@link org.apache.lucene.util.LegacyNumericUtils#PRECISION_STEP_DEFAULT}
    * @see #setNumericPrecisionStep(int)
    */
   public int numericPrecisionStep() {
diff --git a/lucene/core/src/java/org/apache/lucene/document/FloatField.java b/lucene/core/src/java/org/apache/lucene/document/FloatField.java
deleted file mode 100644
index d678c79..0000000
--- a/lucene/core/src/java/org/apache/lucene/document/FloatField.java
+++ /dev/null
@@ -1,173 +0,0 @@
-package org.apache.lucene.document;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.NumericTokenStream; // javadocs
-import org.apache.lucene.index.IndexOptions;
-import org.apache.lucene.search.NumericRangeQuery; // javadocs
-import org.apache.lucene.util.NumericUtils;
-
-/**
- * <p>
- * Field that indexes <code>float</code> values
- * for efficient range filtering and sorting. Here's an example usage:
- * 
- * <pre class="prettyprint">
- * document.add(new FloatField(name, 6.0F, Field.Store.NO));
- * </pre>
- * 
- * For optimal performance, re-use the <code>FloatField</code> and
- * {@link Document} instance for more than one document:
- * 
- * <pre class="prettyprint">
- *  FloatField field = new FloatField(name, 0.0F, Field.Store.NO);
- *  Document document = new Document();
- *  document.add(field);
- * 
- *  for(all documents) {
- *    ...
- *    field.setFloatValue(value)
- *    writer.addDocument(document);
- *    ...
- *  }
- * </pre>
- *
- * See also {@link IntField}, {@link LongField}, {@link
- * DoubleField}.
- *
- * <p>To perform range querying or filtering against a
- * <code>FloatField</code>, use {@link NumericRangeQuery}.
- * To sort according to a
- * <code>FloatField</code>, use the normal numeric sort types, eg
- * {@link org.apache.lucene.search.SortField.Type#FLOAT}. <code>FloatField</code> 
- * values can also be loaded directly from {@link org.apache.lucene.index.LeafReader#getNumericDocValues}.</p>
- *
- * <p>You may add the same field name as an <code>FloatField</code> to
- * the same document more than once.  Range querying and
- * filtering will be the logical OR of all values; so a range query
- * will hit all documents that have at least one value in
- * the range. However sort behavior is not defined.  If you need to sort,
- * you should separately index a single-valued <code>FloatField</code>.</p>
- *
- * <p>A <code>FloatField</code> will consume somewhat more disk space
- * in the index than an ordinary single-valued field.
- * However, for a typical index that includes substantial
- * textual content per document, this increase will likely
- * be in the noise. </p>
- *
- * <p>Within Lucene, each numeric value is indexed as a
- * <em>trie</em> structure, where each term is logically
- * assigned to larger and larger pre-defined brackets (which
- * are simply lower-precision representations of the value).
- * The step size between each successive bracket is called the
- * <code>precisionStep</code>, measured in bits.  Smaller
- * <code>precisionStep</code> values result in larger number
- * of brackets, which consumes more disk space in the index
- * but may result in faster range search performance.  The
- * default value, 8, was selected for a reasonable tradeoff
- * of disk space consumption versus performance.  You can
- * create a custom {@link FieldType} and invoke the {@link
- * FieldType#setNumericPrecisionStep} method if you'd
- * like to change the value.  Note that you must also
- * specify a congruent value when creating {@link
- * NumericRangeQuery}.
- * For low cardinality fields larger precision steps are good.
- * If the cardinality is &lt; 100, it is fair
- * to use {@link Integer#MAX_VALUE}, which produces one
- * term per value.
- *
- * <p>For more information on the internals of numeric trie
- * indexing, including the <a
- * href="../search/NumericRangeQuery.html#precisionStepDesc"><code>precisionStep</code></a>
- * configuration, see {@link NumericRangeQuery}. The format of
- * indexed values is described in {@link NumericUtils}.
- *
- * <p>If you only need to sort by numeric value, and never
- * run range querying/filtering, you can index using a
- * <code>precisionStep</code> of {@link Integer#MAX_VALUE}.
- * This will minimize disk space consumed. </p>
- *
- * <p>More advanced users can instead use {@link
- * NumericTokenStream} directly, when indexing numbers. This
- * class is a wrapper around this token stream type for
- * easier, more intuitive usage.</p>
- *
- * @since 2.9
- */
-
-public final class FloatField extends Field {
-  
-  /** 
-   * Type for a FloatField that is not stored:
-   * normalization factors, frequencies, and positions are omitted.
-   */
-  public static final FieldType TYPE_NOT_STORED = new FieldType();
-  static {
-    TYPE_NOT_STORED.setTokenized(true);
-    TYPE_NOT_STORED.setOmitNorms(true);
-    TYPE_NOT_STORED.setIndexOptions(IndexOptions.DOCS);
-    TYPE_NOT_STORED.setNumericType(FieldType.NumericType.FLOAT);
-    TYPE_NOT_STORED.setNumericPrecisionStep(NumericUtils.PRECISION_STEP_DEFAULT_32);
-    TYPE_NOT_STORED.freeze();
-  }
-
-  /** 
-   * Type for a stored FloatField:
-   * normalization factors, frequencies, and positions are omitted.
-   */
-  public static final FieldType TYPE_STORED = new FieldType();
-  static {
-    TYPE_STORED.setTokenized(true);
-    TYPE_STORED.setOmitNorms(true);
-    TYPE_STORED.setIndexOptions(IndexOptions.DOCS);
-    TYPE_STORED.setNumericType(FieldType.NumericType.FLOAT);
-    TYPE_STORED.setNumericPrecisionStep(NumericUtils.PRECISION_STEP_DEFAULT_32);
-    TYPE_STORED.setStored(true);
-    TYPE_STORED.freeze();
-  }
-
-  /** Creates a stored or un-stored FloatField with the provided value
-   *  and default <code>precisionStep</code> {@link
-   *  NumericUtils#PRECISION_STEP_DEFAULT_32} (8). 
-   *  @param name field name
-   *  @param value 32-bit double value
-   *  @param stored Store.YES if the content should also be stored
-   *  @throws IllegalArgumentException if the field name is null.
-   */
-  public FloatField(String name, float value, Store stored) {
-    super(name, stored == Store.YES ? TYPE_STORED : TYPE_NOT_STORED);
-    fieldsData = Float.valueOf(value);
-  }
-  
-  /** Expert: allows you to customize the {@link
-   *  FieldType}. 
-   *  @param name field name
-   *  @param value 32-bit float value
-   *  @param type customized field type: must have {@link FieldType#numericType()}
-   *         of {@link FieldType.NumericType#FLOAT}.
-   *  @throws IllegalArgumentException if the field name or type is null, or
-   *          if the field type does not have a FLOAT numericType()
-   */
-  public FloatField(String name, float value, FieldType type) {
-    super(name, type);
-    if (type.numericType() != FieldType.NumericType.FLOAT) {
-      throw new IllegalArgumentException("type.numericType() must be FLOAT but got " + type.numericType());
-    }
-    fieldsData = Float.valueOf(value);
-  }
-}
diff --git a/lucene/core/src/java/org/apache/lucene/document/IntField.java b/lucene/core/src/java/org/apache/lucene/document/IntField.java
deleted file mode 100644
index bb8114d..0000000
--- a/lucene/core/src/java/org/apache/lucene/document/IntField.java
+++ /dev/null
@@ -1,173 +0,0 @@
-package org.apache.lucene.document;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.NumericTokenStream; // javadocs
-import org.apache.lucene.index.IndexOptions;
-import org.apache.lucene.search.NumericRangeQuery; // javadocs
-import org.apache.lucene.util.NumericUtils;
-
-/**
- * <p>
- * Field that indexes <code>int</code> values
- * for efficient range filtering and sorting. Here's an example usage:
- * 
- * <pre class="prettyprint">
- * document.add(new IntField(name, 6, Field.Store.NO));
- * </pre>
- * 
- * For optimal performance, re-use the <code>IntField</code> and
- * {@link Document} instance for more than one document:
- * 
- * <pre class="prettyprint">
- *  IntField field = new IntField(name, 6, Field.Store.NO);
- *  Document document = new Document();
- *  document.add(field);
- * 
- *  for(all documents) {
- *    ...
- *    field.setIntValue(value)
- *    writer.addDocument(document);
- *    ...
- *  }
- * </pre>
- *
- * See also {@link LongField}, {@link FloatField}, {@link
- * DoubleField}.
- *
- * <p>To perform range querying or filtering against a
- * <code>IntField</code>, use {@link NumericRangeQuery}.
- * To sort according to a
- * <code>IntField</code>, use the normal numeric sort types, eg
- * {@link org.apache.lucene.search.SortField.Type#INT}. <code>IntField</code> 
- * values can also be loaded directly from {@link org.apache.lucene.index.LeafReader#getNumericDocValues}.</p>
- *
- * <p>You may add the same field name as an <code>IntField</code> to
- * the same document more than once.  Range querying and
- * filtering will be the logical OR of all values; so a range query
- * will hit all documents that have at least one value in
- * the range. However sort behavior is not defined.  If you need to sort,
- * you should separately index a single-valued <code>IntField</code>.</p>
- *
- * <p>An <code>IntField</code> will consume somewhat more disk space
- * in the index than an ordinary single-valued field.
- * However, for a typical index that includes substantial
- * textual content per document, this increase will likely
- * be in the noise. </p>
- *
- * <p>Within Lucene, each numeric value is indexed as a
- * <em>trie</em> structure, where each term is logically
- * assigned to larger and larger pre-defined brackets (which
- * are simply lower-precision representations of the value).
- * The step size between each successive bracket is called the
- * <code>precisionStep</code>, measured in bits.  Smaller
- * <code>precisionStep</code> values result in larger number
- * of brackets, which consumes more disk space in the index
- * but may result in faster range search performance.  The
- * default value, 8, was selected for a reasonable tradeoff
- * of disk space consumption versus performance.  You can
- * create a custom {@link FieldType} and invoke the {@link
- * FieldType#setNumericPrecisionStep} method if you'd
- * like to change the value.  Note that you must also
- * specify a congruent value when creating {@link
- * NumericRangeQuery}.
- * For low cardinality fields larger precision steps are good.
- * If the cardinality is &lt; 100, it is fair
- * to use {@link Integer#MAX_VALUE}, which produces one
- * term per value.
- *
- * <p>For more information on the internals of numeric trie
- * indexing, including the <a
- * href="../search/NumericRangeQuery.html#precisionStepDesc"><code>precisionStep</code></a>
- * configuration, see {@link NumericRangeQuery}. The format of
- * indexed values is described in {@link NumericUtils}.
- *
- * <p>If you only need to sort by numeric value, and never
- * run range querying/filtering, you can index using a
- * <code>precisionStep</code> of {@link Integer#MAX_VALUE}.
- * This will minimize disk space consumed. </p>
- *
- * <p>More advanced users can instead use {@link
- * NumericTokenStream} directly, when indexing numbers. This
- * class is a wrapper around this token stream type for
- * easier, more intuitive usage.</p>
- *
- * @since 2.9
- */
-
-public final class IntField extends Field {
-  
-  /** 
-   * Type for an IntField that is not stored:
-   * normalization factors, frequencies, and positions are omitted.
-   */
-  public static final FieldType TYPE_NOT_STORED = new FieldType();
-  static {
-    TYPE_NOT_STORED.setTokenized(true);
-    TYPE_NOT_STORED.setOmitNorms(true);
-    TYPE_NOT_STORED.setIndexOptions(IndexOptions.DOCS);
-    TYPE_NOT_STORED.setNumericType(FieldType.NumericType.INT);
-    TYPE_NOT_STORED.setNumericPrecisionStep(NumericUtils.PRECISION_STEP_DEFAULT_32);
-    TYPE_NOT_STORED.freeze();
-  }
-
-  /** 
-   * Type for a stored IntField:
-   * normalization factors, frequencies, and positions are omitted.
-   */
-  public static final FieldType TYPE_STORED = new FieldType();
-  static {
-    TYPE_STORED.setTokenized(true);
-    TYPE_STORED.setOmitNorms(true);
-    TYPE_STORED.setIndexOptions(IndexOptions.DOCS);
-    TYPE_STORED.setNumericType(FieldType.NumericType.INT);
-    TYPE_STORED.setNumericPrecisionStep(NumericUtils.PRECISION_STEP_DEFAULT_32);
-    TYPE_STORED.setStored(true);
-    TYPE_STORED.freeze();
-  }
-
-  /** Creates a stored or un-stored IntField with the provided value
-   *  and default <code>precisionStep</code> {@link
-   *  NumericUtils#PRECISION_STEP_DEFAULT_32} (8). 
-   *  @param name field name
-   *  @param value 32-bit integer value
-   *  @param stored Store.YES if the content should also be stored
-   *  @throws IllegalArgumentException if the field name is null.
-   */
-  public IntField(String name, int value, Store stored) {
-    super(name, stored == Store.YES ? TYPE_STORED : TYPE_NOT_STORED);
-    fieldsData = Integer.valueOf(value);
-  }
-  
-  /** Expert: allows you to customize the {@link
-   *  FieldType}. 
-   *  @param name field name
-   *  @param value 32-bit integer value
-   *  @param type customized field type: must have {@link FieldType#numericType()}
-   *         of {@link FieldType.NumericType#INT}.
-   *  @throws IllegalArgumentException if the field name or type is null, or
-   *          if the field type does not have a INT numericType()
-   */
-  public IntField(String name, int value, FieldType type) {
-    super(name, type);
-    if (type.numericType() != FieldType.NumericType.INT) {
-      throw new IllegalArgumentException("type.numericType() must be INT but got " + type.numericType());
-    }
-    fieldsData = Integer.valueOf(value);
-  }
-}
diff --git a/lucene/core/src/java/org/apache/lucene/document/LegacyDoubleField.java b/lucene/core/src/java/org/apache/lucene/document/LegacyDoubleField.java
new file mode 100644
index 0000000..ed4b2ef
--- /dev/null
+++ b/lucene/core/src/java/org/apache/lucene/document/LegacyDoubleField.java
@@ -0,0 +1,172 @@
+package org.apache.lucene.document;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.index.IndexOptions;
+
+
+/**
+ * <p>
+ * Field that indexes <code>double</code> values
+ * for efficient range filtering and sorting. Here's an example usage:
+ * 
+ * <pre class="prettyprint">
+ * document.add(new LegacyDoubleField(name, 6.0, Field.Store.NO));
+ * </pre>
+ * 
+ * For optimal performance, re-use the <code>LegacyDoubleField</code> and
+ * {@link Document} instance for more than one document:
+ * 
+ * <pre class="prettyprint">
+ *  LegacyDoubleField field = new LegacyDoubleField(name, 0.0, Field.Store.NO);
+ *  Document document = new Document();
+ *  document.add(field);
+ * 
+ *  for(all documents) {
+ *    ...
+ *    field.setDoubleValue(value)
+ *    writer.addDocument(document);
+ *    ...
+ *  }
+ * </pre>
+ *
+ * See also {@link LegacyIntField}, {@link LegacyLongField}, {@link
+ * LegacyFloatField}.
+ *
+ * <p>To perform range querying or filtering against a
+ * <code>LegacyDoubleField</code>, use {@link org.apache.lucene.search.LegacyNumericRangeQuery}.
+ * To sort according to a
+ * <code>LegacyDoubleField</code>, use the normal numeric sort types, eg
+ * {@link org.apache.lucene.search.SortField.Type#DOUBLE}. <code>LegacyDoubleField</code>
+ * values can also be loaded directly from {@link org.apache.lucene.index.LeafReader#getNumericDocValues}.</p>
+ *
+ * <p>You may add the same field name as an <code>LegacyDoubleField</code> to
+ * the same document more than once.  Range querying and
+ * filtering will be the logical OR of all values; so a range query
+ * will hit all documents that have at least one value in
+ * the range. However sort behavior is not defined.  If you need to sort,
+ * you should separately index a single-valued <code>LegacyDoubleField</code>.</p>
+ *
+ * <p>A <code>LegacyDoubleField</code> will consume somewhat more disk space
+ * in the index than an ordinary single-valued field.
+ * However, for a typical index that includes substantial
+ * textual content per document, this increase will likely
+ * be in the noise. </p>
+ *
+ * <p>Within Lucene, each numeric value is indexed as a
+ * <em>trie</em> structure, where each term is logically
+ * assigned to larger and larger pre-defined brackets (which
+ * are simply lower-precision representations of the value).
+ * The step size between each successive bracket is called the
+ * <code>precisionStep</code>, measured in bits.  Smaller
+ * <code>precisionStep</code> values result in larger number
+ * of brackets, which consumes more disk space in the index
+ * but may result in faster range search performance.  The
+ * default value, 16, was selected for a reasonable tradeoff
+ * of disk space consumption versus performance.  You can
+ * create a custom {@link FieldType} and invoke the {@link
+ * FieldType#setNumericPrecisionStep} method if you'd
+ * like to change the value.  Note that you must also
+ * specify a congruent value when creating {@link
+ * org.apache.lucene.search.LegacyNumericRangeQuery}.
+ * For low cardinality fields larger precision steps are good.
+ * If the cardinality is &lt; 100, it is fair
+ * to use {@link Integer#MAX_VALUE}, which produces one
+ * term per value.
+ *
+ * <p>For more information on the internals of numeric trie
+ * indexing, including the <a
+ * href="../search/LegacyNumericRangeQuery.html#precisionStepDesc"><code>precisionStep</code></a>
+ * configuration, see {@link org.apache.lucene.search.LegacyNumericRangeQuery}. The format of
+ * indexed values is described in {@link org.apache.lucene.util.LegacyNumericUtils}.
+ *
+ * <p>If you only need to sort by numeric value, and never
+ * run range querying/filtering, you can index using a
+ * <code>precisionStep</code> of {@link Integer#MAX_VALUE}.
+ * This will minimize disk space consumed. </p>
+ *
+ * <p>More advanced users can instead use {@link
+ * org.apache.lucene.analysis.LegacyNumericTokenStream} directly, when indexing numbers. This
+ * class is a wrapper around this token stream type for
+ * easier, more intuitive usage.</p>
+ *
+ * @deprecated Please use {@link DimensionalDoubleField} instead
+ *
+ * @since 2.9
+ */
+
+@Deprecated
+public final class LegacyDoubleField extends Field {
+  
+  /** 
+   * Type for a LegacyDoubleField that is not stored:
+   * normalization factors, frequencies, and positions are omitted.
+   */
+  public static final FieldType TYPE_NOT_STORED = new FieldType();
+  static {
+    TYPE_NOT_STORED.setTokenized(true);
+    TYPE_NOT_STORED.setOmitNorms(true);
+    TYPE_NOT_STORED.setIndexOptions(IndexOptions.DOCS);
+    TYPE_NOT_STORED.setNumericType(FieldType.LegacyNumericType.DOUBLE);
+    TYPE_NOT_STORED.freeze();
+  }
+
+  /** 
+   * Type for a stored LegacyDoubleField:
+   * normalization factors, frequencies, and positions are omitted.
+   */
+  public static final FieldType TYPE_STORED = new FieldType();
+  static {
+    TYPE_STORED.setTokenized(true);
+    TYPE_STORED.setOmitNorms(true);
+    TYPE_STORED.setIndexOptions(IndexOptions.DOCS);
+    TYPE_STORED.setNumericType(FieldType.LegacyNumericType.DOUBLE);
+    TYPE_STORED.setStored(true);
+    TYPE_STORED.freeze();
+  }
+
+  /** Creates a stored or un-stored LegacyDoubleField with the provided value
+   *  and default <code>precisionStep</code> {@link
+   *  org.apache.lucene.util.LegacyNumericUtils#PRECISION_STEP_DEFAULT} (16).
+   *  @param name field name
+   *  @param value 64-bit double value
+   *  @param stored Store.YES if the content should also be stored
+   *  @throws IllegalArgumentException if the field name is null. 
+   */
+  public LegacyDoubleField(String name, double value, Store stored) {
+    super(name, stored == Store.YES ? TYPE_STORED : TYPE_NOT_STORED);
+    fieldsData = Double.valueOf(value);
+  }
+  
+  /** Expert: allows you to customize the {@link
+   *  FieldType}. 
+   *  @param name field name
+   *  @param value 64-bit double value
+   *  @param type customized field type: must have {@link FieldType#numericType()}
+   *         of {@link org.apache.lucene.document.FieldType.LegacyNumericType#DOUBLE}.
+   *  @throws IllegalArgumentException if the field name or type is null, or
+   *          if the field type does not have a DOUBLE numericType()
+   */
+  public LegacyDoubleField(String name, double value, FieldType type) {
+    super(name, type);
+    if (type.numericType() != FieldType.LegacyNumericType.DOUBLE) {
+      throw new IllegalArgumentException("type.numericType() must be DOUBLE but got " + type.numericType());
+    }
+    fieldsData = Double.valueOf(value);
+  }
+}
diff --git a/lucene/core/src/java/org/apache/lucene/document/LegacyFloatField.java b/lucene/core/src/java/org/apache/lucene/document/LegacyFloatField.java
new file mode 100644
index 0000000..cda1aa4
--- /dev/null
+++ b/lucene/core/src/java/org/apache/lucene/document/LegacyFloatField.java
@@ -0,0 +1,174 @@
+package org.apache.lucene.document;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.index.IndexOptions;
+import org.apache.lucene.util.LegacyNumericUtils;
+
+/**
+ * <p>
+ * Field that indexes <code>float</code> values
+ * for efficient range filtering and sorting. Here's an example usage:
+ * 
+ * <pre class="prettyprint">
+ * document.add(new LegacyFloatField(name, 6.0F, Field.Store.NO));
+ * </pre>
+ * 
+ * For optimal performance, re-use the <code>LegacyFloatField</code> and
+ * {@link Document} instance for more than one document:
+ * 
+ * <pre class="prettyprint">
+ *  LegacyFloatField field = new LegacyFloatField(name, 0.0F, Field.Store.NO);
+ *  Document document = new Document();
+ *  document.add(field);
+ * 
+ *  for(all documents) {
+ *    ...
+ *    field.setFloatValue(value)
+ *    writer.addDocument(document);
+ *    ...
+ *  }
+ * </pre>
+ *
+ * See also {@link LegacyIntField}, {@link LegacyLongField}, {@link
+ * LegacyDoubleField}.
+ *
+ * <p>To perform range querying or filtering against a
+ * <code>LegacyFloatField</code>, use {@link org.apache.lucene.search.LegacyNumericRangeQuery}.
+ * To sort according to a
+ * <code>LegacyFloatField</code>, use the normal numeric sort types, eg
+ * {@link org.apache.lucene.search.SortField.Type#FLOAT}. <code>LegacyFloatField</code>
+ * values can also be loaded directly from {@link org.apache.lucene.index.LeafReader#getNumericDocValues}.</p>
+ *
+ * <p>You may add the same field name as an <code>LegacyFloatField</code> to
+ * the same document more than once.  Range querying and
+ * filtering will be the logical OR of all values; so a range query
+ * will hit all documents that have at least one value in
+ * the range. However sort behavior is not defined.  If you need to sort,
+ * you should separately index a single-valued <code>LegacyFloatField</code>.</p>
+ *
+ * <p>A <code>LegacyFloatField</code> will consume somewhat more disk space
+ * in the index than an ordinary single-valued field.
+ * However, for a typical index that includes substantial
+ * textual content per document, this increase will likely
+ * be in the noise. </p>
+ *
+ * <p>Within Lucene, each numeric value is indexed as a
+ * <em>trie</em> structure, where each term is logically
+ * assigned to larger and larger pre-defined brackets (which
+ * are simply lower-precision representations of the value).
+ * The step size between each successive bracket is called the
+ * <code>precisionStep</code>, measured in bits.  Smaller
+ * <code>precisionStep</code> values result in larger number
+ * of brackets, which consumes more disk space in the index
+ * but may result in faster range search performance.  The
+ * default value, 8, was selected for a reasonable tradeoff
+ * of disk space consumption versus performance.  You can
+ * create a custom {@link FieldType} and invoke the {@link
+ * FieldType#setNumericPrecisionStep} method if you'd
+ * like to change the value.  Note that you must also
+ * specify a congruent value when creating {@link
+ * org.apache.lucene.search.LegacyNumericRangeQuery}.
+ * For low cardinality fields larger precision steps are good.
+ * If the cardinality is &lt; 100, it is fair
+ * to use {@link Integer#MAX_VALUE}, which produces one
+ * term per value.
+ *
+ * <p>For more information on the internals of numeric trie
+ * indexing, including the <a
+ * href="../search/LegacyNumericRangeQuery.html#precisionStepDesc"><code>precisionStep</code></a>
+ * configuration, see {@link org.apache.lucene.search.LegacyNumericRangeQuery}. The format of
+ * indexed values is described in {@link org.apache.lucene.util.LegacyNumericUtils}.
+ *
+ * <p>If you only need to sort by numeric value, and never
+ * run range querying/filtering, you can index using a
+ * <code>precisionStep</code> of {@link Integer#MAX_VALUE}.
+ * This will minimize disk space consumed. </p>
+ *
+ * <p>More advanced users can instead use {@link
+ * org.apache.lucene.analysis.LegacyNumericTokenStream} directly, when indexing numbers. This
+ * class is a wrapper around this token stream type for
+ * easier, more intuitive usage.</p>
+ *
+ * @deprecated Please use {@link DimensionalFloatField} instead
+ *
+ * @since 2.9
+ */
+
+@Deprecated
+public final class LegacyFloatField extends Field {
+  
+  /** 
+   * Type for a LegacyFloatField that is not stored:
+   * normalization factors, frequencies, and positions are omitted.
+   */
+  public static final FieldType TYPE_NOT_STORED = new FieldType();
+  static {
+    TYPE_NOT_STORED.setTokenized(true);
+    TYPE_NOT_STORED.setOmitNorms(true);
+    TYPE_NOT_STORED.setIndexOptions(IndexOptions.DOCS);
+    TYPE_NOT_STORED.setNumericType(FieldType.LegacyNumericType.FLOAT);
+    TYPE_NOT_STORED.setNumericPrecisionStep(LegacyNumericUtils.PRECISION_STEP_DEFAULT_32);
+    TYPE_NOT_STORED.freeze();
+  }
+
+  /** 
+   * Type for a stored LegacyFloatField:
+   * normalization factors, frequencies, and positions are omitted.
+   */
+  public static final FieldType TYPE_STORED = new FieldType();
+  static {
+    TYPE_STORED.setTokenized(true);
+    TYPE_STORED.setOmitNorms(true);
+    TYPE_STORED.setIndexOptions(IndexOptions.DOCS);
+    TYPE_STORED.setNumericType(FieldType.LegacyNumericType.FLOAT);
+    TYPE_STORED.setNumericPrecisionStep(LegacyNumericUtils.PRECISION_STEP_DEFAULT_32);
+    TYPE_STORED.setStored(true);
+    TYPE_STORED.freeze();
+  }
+
+  /** Creates a stored or un-stored LegacyFloatField with the provided value
+   *  and default <code>precisionStep</code> {@link
+   *  org.apache.lucene.util.LegacyNumericUtils#PRECISION_STEP_DEFAULT_32} (8).
+   *  @param name field name
+   *  @param value 32-bit double value
+   *  @param stored Store.YES if the content should also be stored
+   *  @throws IllegalArgumentException if the field name is null.
+   */
+  public LegacyFloatField(String name, float value, Store stored) {
+    super(name, stored == Store.YES ? TYPE_STORED : TYPE_NOT_STORED);
+    fieldsData = Float.valueOf(value);
+  }
+  
+  /** Expert: allows you to customize the {@link
+   *  FieldType}. 
+   *  @param name field name
+   *  @param value 32-bit float value
+   *  @param type customized field type: must have {@link FieldType#numericType()}
+   *         of {@link org.apache.lucene.document.FieldType.LegacyNumericType#FLOAT}.
+   *  @throws IllegalArgumentException if the field name or type is null, or
+   *          if the field type does not have a FLOAT numericType()
+   */
+  public LegacyFloatField(String name, float value, FieldType type) {
+    super(name, type);
+    if (type.numericType() != FieldType.LegacyNumericType.FLOAT) {
+      throw new IllegalArgumentException("type.numericType() must be FLOAT but got " + type.numericType());
+    }
+    fieldsData = Float.valueOf(value);
+  }
+}
diff --git a/lucene/core/src/java/org/apache/lucene/document/LegacyIntField.java b/lucene/core/src/java/org/apache/lucene/document/LegacyIntField.java
new file mode 100644
index 0000000..b937f9f
--- /dev/null
+++ b/lucene/core/src/java/org/apache/lucene/document/LegacyIntField.java
@@ -0,0 +1,174 @@
+package org.apache.lucene.document;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.index.IndexOptions;
+import org.apache.lucene.util.LegacyNumericUtils;
+
+/**
+ * <p>
+ * Field that indexes <code>int</code> values
+ * for efficient range filtering and sorting. Here's an example usage:
+ * 
+ * <pre class="prettyprint">
+ * document.add(new LegacyIntField(name, 6, Field.Store.NO));
+ * </pre>
+ * 
+ * For optimal performance, re-use the <code>LegacyIntField</code> and
+ * {@link Document} instance for more than one document:
+ * 
+ * <pre class="prettyprint">
+ *  LegacyIntField field = new LegacyIntField(name, 6, Field.Store.NO);
+ *  Document document = new Document();
+ *  document.add(field);
+ * 
+ *  for(all documents) {
+ *    ...
+ *    field.setIntValue(value)
+ *    writer.addDocument(document);
+ *    ...
+ *  }
+ * </pre>
+ *
+ * See also {@link LegacyLongField}, {@link LegacyFloatField}, {@link
+ * LegacyDoubleField}.
+ *
+ * <p>To perform range querying or filtering against a
+ * <code>LegacyIntField</code>, use {@link org.apache.lucene.search.LegacyNumericRangeQuery}.
+ * To sort according to a
+ * <code>LegacyIntField</code>, use the normal numeric sort types, eg
+ * {@link org.apache.lucene.search.SortField.Type#INT}. <code>LegacyIntField</code>
+ * values can also be loaded directly from {@link org.apache.lucene.index.LeafReader#getNumericDocValues}.</p>
+ *
+ * <p>You may add the same field name as an <code>LegacyIntField</code> to
+ * the same document more than once.  Range querying and
+ * filtering will be the logical OR of all values; so a range query
+ * will hit all documents that have at least one value in
+ * the range. However sort behavior is not defined.  If you need to sort,
+ * you should separately index a single-valued <code>LegacyIntField</code>.</p>
+ *
+ * <p>An <code>LegacyIntField</code> will consume somewhat more disk space
+ * in the index than an ordinary single-valued field.
+ * However, for a typical index that includes substantial
+ * textual content per document, this increase will likely
+ * be in the noise. </p>
+ *
+ * <p>Within Lucene, each numeric value is indexed as a
+ * <em>trie</em> structure, where each term is logically
+ * assigned to larger and larger pre-defined brackets (which
+ * are simply lower-precision representations of the value).
+ * The step size between each successive bracket is called the
+ * <code>precisionStep</code>, measured in bits.  Smaller
+ * <code>precisionStep</code> values result in larger number
+ * of brackets, which consumes more disk space in the index
+ * but may result in faster range search performance.  The
+ * default value, 8, was selected for a reasonable tradeoff
+ * of disk space consumption versus performance.  You can
+ * create a custom {@link FieldType} and invoke the {@link
+ * FieldType#setNumericPrecisionStep} method if you'd
+ * like to change the value.  Note that you must also
+ * specify a congruent value when creating {@link
+ * org.apache.lucene.search.LegacyNumericRangeQuery}.
+ * For low cardinality fields larger precision steps are good.
+ * If the cardinality is &lt; 100, it is fair
+ * to use {@link Integer#MAX_VALUE}, which produces one
+ * term per value.
+ *
+ * <p>For more information on the internals of numeric trie
+ * indexing, including the <a
+ * href="../search/LegacyNumericRangeQuery.html#precisionStepDesc"><code>precisionStep</code></a>
+ * configuration, see {@link org.apache.lucene.search.LegacyNumericRangeQuery}. The format of
+ * indexed values is described in {@link org.apache.lucene.util.LegacyNumericUtils}.
+ *
+ * <p>If you only need to sort by numeric value, and never
+ * run range querying/filtering, you can index using a
+ * <code>precisionStep</code> of {@link Integer#MAX_VALUE}.
+ * This will minimize disk space consumed. </p>
+ *
+ * <p>More advanced users can instead use {@link
+ * org.apache.lucene.analysis.LegacyNumericTokenStream} directly, when indexing numbers. This
+ * class is a wrapper around this token stream type for
+ * easier, more intuitive usage.</p>
+ *
+ * @deprecated Please use {@link DimensionalIntField} instead
+ *
+ * @since 2.9
+ */
+
+@Deprecated
+public final class LegacyIntField extends Field {
+  
+  /** 
+   * Type for an LegacyIntField that is not stored:
+   * normalization factors, frequencies, and positions are omitted.
+   */
+  public static final FieldType TYPE_NOT_STORED = new FieldType();
+  static {
+    TYPE_NOT_STORED.setTokenized(true);
+    TYPE_NOT_STORED.setOmitNorms(true);
+    TYPE_NOT_STORED.setIndexOptions(IndexOptions.DOCS);
+    TYPE_NOT_STORED.setNumericType(FieldType.LegacyNumericType.INT);
+    TYPE_NOT_STORED.setNumericPrecisionStep(LegacyNumericUtils.PRECISION_STEP_DEFAULT_32);
+    TYPE_NOT_STORED.freeze();
+  }
+
+  /** 
+   * Type for a stored LegacyIntField:
+   * normalization factors, frequencies, and positions are omitted.
+   */
+  public static final FieldType TYPE_STORED = new FieldType();
+  static {
+    TYPE_STORED.setTokenized(true);
+    TYPE_STORED.setOmitNorms(true);
+    TYPE_STORED.setIndexOptions(IndexOptions.DOCS);
+    TYPE_STORED.setNumericType(FieldType.LegacyNumericType.INT);
+    TYPE_STORED.setNumericPrecisionStep(LegacyNumericUtils.PRECISION_STEP_DEFAULT_32);
+    TYPE_STORED.setStored(true);
+    TYPE_STORED.freeze();
+  }
+
+  /** Creates a stored or un-stored LegacyIntField with the provided value
+   *  and default <code>precisionStep</code> {@link
+   *  org.apache.lucene.util.LegacyNumericUtils#PRECISION_STEP_DEFAULT_32} (8).
+   *  @param name field name
+   *  @param value 32-bit integer value
+   *  @param stored Store.YES if the content should also be stored
+   *  @throws IllegalArgumentException if the field name is null.
+   */
+  public LegacyIntField(String name, int value, Store stored) {
+    super(name, stored == Store.YES ? TYPE_STORED : TYPE_NOT_STORED);
+    fieldsData = Integer.valueOf(value);
+  }
+  
+  /** Expert: allows you to customize the {@link
+   *  FieldType}. 
+   *  @param name field name
+   *  @param value 32-bit integer value
+   *  @param type customized field type: must have {@link FieldType#numericType()}
+   *         of {@link org.apache.lucene.document.FieldType.LegacyNumericType#INT}.
+   *  @throws IllegalArgumentException if the field name or type is null, or
+   *          if the field type does not have a INT numericType()
+   */
+  public LegacyIntField(String name, int value, FieldType type) {
+    super(name, type);
+    if (type.numericType() != FieldType.LegacyNumericType.INT) {
+      throw new IllegalArgumentException("type.numericType() must be INT but got " + type.numericType());
+    }
+    fieldsData = Integer.valueOf(value);
+  }
+}
diff --git a/lucene/core/src/java/org/apache/lucene/document/LegacyLongField.java b/lucene/core/src/java/org/apache/lucene/document/LegacyLongField.java
new file mode 100644
index 0000000..e478766
--- /dev/null
+++ b/lucene/core/src/java/org/apache/lucene/document/LegacyLongField.java
@@ -0,0 +1,182 @@
+package org.apache.lucene.document;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.index.IndexOptions;
+
+
+/**
+ * <p>
+ * Field that indexes <code>long</code> values
+ * for efficient range filtering and sorting. Here's an example usage:
+ * 
+ * <pre class="prettyprint">
+ * document.add(new LegacyLongField(name, 6L, Field.Store.NO));
+ * </pre>
+ * 
+ * For optimal performance, re-use the <code>LegacyLongField</code> and
+ * {@link Document} instance for more than one document:
+ * 
+ * <pre class="prettyprint">
+ *  LegacyLongField field = new LegacyLongField(name, 0L, Field.Store.NO);
+ *  Document document = new Document();
+ *  document.add(field);
+ * 
+ *  for(all documents) {
+ *    ...
+ *    field.setLongValue(value)
+ *    writer.addDocument(document);
+ *    ...
+ *  }
+ * </pre>
+ *
+ * See also {@link LegacyIntField}, {@link LegacyFloatField}, {@link
+ * LegacyDoubleField}.
+ *
+ * Any type that can be converted to long can also be
+ * indexed.  For example, date/time values represented by a
+ * {@link java.util.Date} can be translated into a long
+ * value using the {@link java.util.Date#getTime} method.  If you
+ * don't need millisecond precision, you can quantize the
+ * value, either by dividing the result of
+ * {@link java.util.Date#getTime} or using the separate getters
+ * (for year, month, etc.) to construct an <code>int</code> or
+ * <code>long</code> value.
+ *
+ * <p>To perform range querying or filtering against a
+ * <code>LegacyLongField</code>, use {@link org.apache.lucene.search.LegacyNumericRangeQuery}.
+ * To sort according to a
+ * <code>LegacyLongField</code>, use the normal numeric sort types, eg
+ * {@link org.apache.lucene.search.SortField.Type#LONG}. <code>LegacyLongField</code>
+ * values can also be loaded directly from {@link org.apache.lucene.index.LeafReader#getNumericDocValues}.
+ *
+ * <p>You may add the same field name as an <code>LegacyLongField</code> to
+ * the same document more than once.  Range querying and
+ * filtering will be the logical OR of all values; so a range query
+ * will hit all documents that have at least one value in
+ * the range. However sort behavior is not defined.  If you need to sort,
+ * you should separately index a single-valued <code>LegacyLongField</code>.
+ *
+ * <p>A <code>LegacyLongField</code> will consume somewhat more disk space
+ * in the index than an ordinary single-valued field.
+ * However, for a typical index that includes substantial
+ * textual content per document, this increase will likely
+ * be in the noise. </p>
+ *
+ * <p>Within Lucene, each numeric value is indexed as a
+ * <em>trie</em> structure, where each term is logically
+ * assigned to larger and larger pre-defined brackets (which
+ * are simply lower-precision representations of the value).
+ * The step size between each successive bracket is called the
+ * <code>precisionStep</code>, measured in bits.  Smaller
+ * <code>precisionStep</code> values result in larger number
+ * of brackets, which consumes more disk space in the index
+ * but may result in faster range search performance.  The
+ * default value, 16, was selected for a reasonable tradeoff
+ * of disk space consumption versus performance.  You can
+ * create a custom {@link FieldType} and invoke the {@link
+ * FieldType#setNumericPrecisionStep} method if you'd
+ * like to change the value.  Note that you must also
+ * specify a congruent value when creating {@link
+ * org.apache.lucene.search.LegacyNumericRangeQuery}.
+ * For low cardinality fields larger precision steps are good.
+ * If the cardinality is &lt; 100, it is fair
+ * to use {@link Integer#MAX_VALUE}, which produces one
+ * term per value.
+ *
+ * <p>For more information on the internals of numeric trie
+ * indexing, including the <a
+ * href="../search/LegacyNumericRangeQuery.html#precisionStepDesc"><code>precisionStep</code></a>
+ * configuration, see {@link org.apache.lucene.search.LegacyNumericRangeQuery}. The format of
+ * indexed values is described in {@link org.apache.lucene.util.LegacyNumericUtils}.
+ *
+ * <p>If you only need to sort by numeric value, and never
+ * run range querying/filtering, you can index using a
+ * <code>precisionStep</code> of {@link Integer#MAX_VALUE}.
+ * This will minimize disk space consumed.
+ *
+ * <p>More advanced users can instead use {@link
+ * org.apache.lucene.analysis.LegacyNumericTokenStream} directly, when indexing numbers. This
+ * class is a wrapper around this token stream type for
+ * easier, more intuitive usage.</p>
+ *
+ * @deprecated Please use {@link DimensionalLongField} instead
+ *
+ * @since 2.9
+ */
+
+@Deprecated
+public final class LegacyLongField extends Field {
+  
+  /** 
+   * Type for a LegacyLongField that is not stored:
+   * normalization factors, frequencies, and positions are omitted.
+   */
+  public static final FieldType TYPE_NOT_STORED = new FieldType();
+  static {
+    TYPE_NOT_STORED.setTokenized(true);
+    TYPE_NOT_STORED.setOmitNorms(true);
+    TYPE_NOT_STORED.setIndexOptions(IndexOptions.DOCS);
+    TYPE_NOT_STORED.setNumericType(FieldType.LegacyNumericType.LONG);
+    TYPE_NOT_STORED.freeze();
+  }
+
+  /** 
+   * Type for a stored LegacyLongField:
+   * normalization factors, frequencies, and positions are omitted.
+   */
+  public static final FieldType TYPE_STORED = new FieldType();
+  static {
+    TYPE_STORED.setTokenized(true);
+    TYPE_STORED.setOmitNorms(true);
+    TYPE_STORED.setIndexOptions(IndexOptions.DOCS);
+    TYPE_STORED.setNumericType(FieldType.LegacyNumericType.LONG);
+    TYPE_STORED.setStored(true);
+    TYPE_STORED.freeze();
+  }
+
+  /** Creates a stored or un-stored LegacyLongField with the provided value
+   *  and default <code>precisionStep</code> {@link
+   *  org.apache.lucene.util.LegacyNumericUtils#PRECISION_STEP_DEFAULT} (16).
+   *  @param name field name
+   *  @param value 64-bit long value
+   *  @param stored Store.YES if the content should also be stored
+   *  @throws IllegalArgumentException if the field name is null.
+   */
+  public LegacyLongField(String name, long value, Store stored) {
+    super(name, stored == Store.YES ? TYPE_STORED : TYPE_NOT_STORED);
+    fieldsData = Long.valueOf(value);
+  }
+  
+  /** Expert: allows you to customize the {@link
+   *  FieldType}. 
+   *  @param name field name
+   *  @param value 64-bit long value
+   *  @param type customized field type: must have {@link FieldType#numericType()}
+   *         of {@link org.apache.lucene.document.FieldType.LegacyNumericType#LONG}.
+   *  @throws IllegalArgumentException if the field name or type is null, or
+   *          if the field type does not have a LONG numericType()
+   */
+  public LegacyLongField(String name, long value, FieldType type) {
+    super(name, type);
+    if (type.numericType() != FieldType.LegacyNumericType.LONG) {
+      throw new IllegalArgumentException("type.numericType() must be LONG but got " + type.numericType());
+    }
+    fieldsData = Long.valueOf(value);
+  }
+}
diff --git a/lucene/core/src/java/org/apache/lucene/document/LongField.java b/lucene/core/src/java/org/apache/lucene/document/LongField.java
deleted file mode 100644
index ff1e1bd..0000000
--- a/lucene/core/src/java/org/apache/lucene/document/LongField.java
+++ /dev/null
@@ -1,181 +0,0 @@
-package org.apache.lucene.document;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.NumericTokenStream; // javadocs
-import org.apache.lucene.index.IndexOptions;
-import org.apache.lucene.search.NumericRangeQuery; // javadocs
-import org.apache.lucene.util.NumericUtils;
-
-/**
- * <p>
- * Field that indexes <code>long</code> values
- * for efficient range filtering and sorting. Here's an example usage:
- * 
- * <pre class="prettyprint">
- * document.add(new LongField(name, 6L, Field.Store.NO));
- * </pre>
- * 
- * For optimal performance, re-use the <code>LongField</code> and
- * {@link Document} instance for more than one document:
- * 
- * <pre class="prettyprint">
- *  LongField field = new LongField(name, 0L, Field.Store.NO);
- *  Document document = new Document();
- *  document.add(field);
- * 
- *  for(all documents) {
- *    ...
- *    field.setLongValue(value)
- *    writer.addDocument(document);
- *    ...
- *  }
- * </pre>
- *
- * See also {@link IntField}, {@link FloatField}, {@link
- * DoubleField}.
- *
- * Any type that can be converted to long can also be
- * indexed.  For example, date/time values represented by a
- * {@link java.util.Date} can be translated into a long
- * value using the {@link java.util.Date#getTime} method.  If you
- * don't need millisecond precision, you can quantize the
- * value, either by dividing the result of
- * {@link java.util.Date#getTime} or using the separate getters
- * (for year, month, etc.) to construct an <code>int</code> or
- * <code>long</code> value.
- *
- * <p>To perform range querying or filtering against a
- * <code>LongField</code>, use {@link NumericRangeQuery}.
- * To sort according to a
- * <code>LongField</code>, use the normal numeric sort types, eg
- * {@link org.apache.lucene.search.SortField.Type#LONG}. <code>LongField</code> 
- * values can also be loaded directly from {@link org.apache.lucene.index.LeafReader#getNumericDocValues}.
- *
- * <p>You may add the same field name as an <code>LongField</code> to
- * the same document more than once.  Range querying and
- * filtering will be the logical OR of all values; so a range query
- * will hit all documents that have at least one value in
- * the range. However sort behavior is not defined.  If you need to sort,
- * you should separately index a single-valued <code>LongField</code>.
- *
- * <p>A <code>LongField</code> will consume somewhat more disk space
- * in the index than an ordinary single-valued field.
- * However, for a typical index that includes substantial
- * textual content per document, this increase will likely
- * be in the noise. </p>
- *
- * <p>Within Lucene, each numeric value is indexed as a
- * <em>trie</em> structure, where each term is logically
- * assigned to larger and larger pre-defined brackets (which
- * are simply lower-precision representations of the value).
- * The step size between each successive bracket is called the
- * <code>precisionStep</code>, measured in bits.  Smaller
- * <code>precisionStep</code> values result in larger number
- * of brackets, which consumes more disk space in the index
- * but may result in faster range search performance.  The
- * default value, 16, was selected for a reasonable tradeoff
- * of disk space consumption versus performance.  You can
- * create a custom {@link FieldType} and invoke the {@link
- * FieldType#setNumericPrecisionStep} method if you'd
- * like to change the value.  Note that you must also
- * specify a congruent value when creating {@link
- * NumericRangeQuery}.
- * For low cardinality fields larger precision steps are good.
- * If the cardinality is &lt; 100, it is fair
- * to use {@link Integer#MAX_VALUE}, which produces one
- * term per value.
- *
- * <p>For more information on the internals of numeric trie
- * indexing, including the <a
- * href="../search/NumericRangeQuery.html#precisionStepDesc"><code>precisionStep</code></a>
- * configuration, see {@link NumericRangeQuery}. The format of
- * indexed values is described in {@link NumericUtils}.
- *
- * <p>If you only need to sort by numeric value, and never
- * run range querying/filtering, you can index using a
- * <code>precisionStep</code> of {@link Integer#MAX_VALUE}.
- * This will minimize disk space consumed.
- *
- * <p>More advanced users can instead use {@link
- * NumericTokenStream} directly, when indexing numbers. This
- * class is a wrapper around this token stream type for
- * easier, more intuitive usage.</p>
- *
- * @since 2.9
- */
-
-public final class LongField extends Field {
-  
-  /** 
-   * Type for a LongField that is not stored:
-   * normalization factors, frequencies, and positions are omitted.
-   */
-  public static final FieldType TYPE_NOT_STORED = new FieldType();
-  static {
-    TYPE_NOT_STORED.setTokenized(true);
-    TYPE_NOT_STORED.setOmitNorms(true);
-    TYPE_NOT_STORED.setIndexOptions(IndexOptions.DOCS);
-    TYPE_NOT_STORED.setNumericType(FieldType.NumericType.LONG);
-    TYPE_NOT_STORED.freeze();
-  }
-
-  /** 
-   * Type for a stored LongField:
-   * normalization factors, frequencies, and positions are omitted.
-   */
-  public static final FieldType TYPE_STORED = new FieldType();
-  static {
-    TYPE_STORED.setTokenized(true);
-    TYPE_STORED.setOmitNorms(true);
-    TYPE_STORED.setIndexOptions(IndexOptions.DOCS);
-    TYPE_STORED.setNumericType(FieldType.NumericType.LONG);
-    TYPE_STORED.setStored(true);
-    TYPE_STORED.freeze();
-  }
-
-  /** Creates a stored or un-stored LongField with the provided value
-   *  and default <code>precisionStep</code> {@link
-   *  NumericUtils#PRECISION_STEP_DEFAULT} (16). 
-   *  @param name field name
-   *  @param value 64-bit long value
-   *  @param stored Store.YES if the content should also be stored
-   *  @throws IllegalArgumentException if the field name is null.
-   */
-  public LongField(String name, long value, Store stored) {
-    super(name, stored == Store.YES ? TYPE_STORED : TYPE_NOT_STORED);
-    fieldsData = Long.valueOf(value);
-  }
-  
-  /** Expert: allows you to customize the {@link
-   *  FieldType}. 
-   *  @param name field name
-   *  @param value 64-bit long value
-   *  @param type customized field type: must have {@link FieldType#numericType()}
-   *         of {@link FieldType.NumericType#LONG}.
-   *  @throws IllegalArgumentException if the field name or type is null, or
-   *          if the field type does not have a LONG numericType()
-   */
-  public LongField(String name, long value, FieldType type) {
-    super(name, type);
-    if (type.numericType() != FieldType.NumericType.LONG) {
-      throw new IllegalArgumentException("type.numericType() must be LONG but got " + type.numericType());
-    }
-    fieldsData = Long.valueOf(value);
-  }
-}
diff --git a/lucene/core/src/java/org/apache/lucene/document/SortedNumericDocValuesField.java b/lucene/core/src/java/org/apache/lucene/document/SortedNumericDocValuesField.java
index 772e830..4b66e6c 100644
--- a/lucene/core/src/java/org/apache/lucene/document/SortedNumericDocValuesField.java
+++ b/lucene/core/src/java/org/apache/lucene/document/SortedNumericDocValuesField.java
@@ -18,7 +18,6 @@ package org.apache.lucene.document;
  */
 
 import org.apache.lucene.index.DocValuesType;
-import org.apache.lucene.util.NumericUtils;
 
 /**
  * <p>
@@ -32,10 +31,10 @@ import org.apache.lucene.util.NumericUtils;
  * 
  * <p>
  * Note that if you want to encode doubles or floats with proper sort order,
- * you will need to encode them with {@link NumericUtils}:
+ * you will need to encode them with {@link org.apache.lucene.util.LegacyNumericUtils}:
  * 
  * <pre class="prettyprint">
- *   document.add(new SortedNumericDocValuesField(name, NumericUtils.floatToSortableInt(-5.3f)));
+ *   document.add(new SortedNumericDocValuesField(name, LegacyNumericUtils.floatToSortableInt(-5.3f)));
  * </pre>
  * 
  * <p>
diff --git a/lucene/core/src/java/org/apache/lucene/document/package-info.java b/lucene/core/src/java/org/apache/lucene/document/package-info.java
index 41a530a..901d57c 100644
--- a/lucene/core/src/java/org/apache/lucene/document/package-info.java
+++ b/lucene/core/src/java/org/apache/lucene/document/package-info.java
@@ -34,10 +34,9 @@
  *   How this is done is completely up to you.  That being said, there are many tools available in other projects that can make
  *   the process of taking a file and converting it into a Lucene {@link org.apache.lucene.document.Document}.
  * </p>
- * <p>The {@link org.apache.lucene.document.DateTools} is a utility class to make dates and times searchable
- * (remember, Lucene only searches text). {@link org.apache.lucene.document.IntField}, {@link org.apache.lucene.document.LongField},
- * {@link org.apache.lucene.document.FloatField} and {@link org.apache.lucene.document.DoubleField} are a special helper class
- * to simplify indexing of numeric values (and also dates) for fast range range queries with {@link org.apache.lucene.search.NumericRangeQuery}
- * (using a special sortable string representation of numeric values).</p>
+ * <p>The {@link org.apache.lucene.document.DateTools} is a utility class to make dates and times searchable. {@link
+ * org.apache.lucene.document.DimensionalIntField}, {@link org.apache.lucene.document.DimensionalLongField},
+ * {@link org.apache.lucene.document.DimensionalFloatField} and {@link org.apache.lucene.document.DimensionalDoubleField} enable indexing
+ * of numeric values (and also dates) for fast range queries using {@link org.apache.lucene.search.DimensionalRangeQuery}</p>
  */
 package org.apache.lucene.document;
diff --git a/lucene/core/src/java/org/apache/lucene/index/DimensionalValues.java b/lucene/core/src/java/org/apache/lucene/index/DimensionalValues.java
index 4f7b72a..112ac69 100644
--- a/lucene/core/src/java/org/apache/lucene/index/DimensionalValues.java
+++ b/lucene/core/src/java/org/apache/lucene/index/DimensionalValues.java
@@ -2,6 +2,13 @@ package org.apache.lucene.index;
 
 import java.io.IOException;
 
+import org.apache.lucene.document.DimensionalBinaryField;
+import org.apache.lucene.document.DimensionalDoubleField;
+import org.apache.lucene.document.DimensionalFloatField;
+import org.apache.lucene.document.DimensionalIntField;
+import org.apache.lucene.document.DimensionalLongField;
+import org.apache.lucene.util.bkd.BKDWriter;
+
 /*
  * Licensed to the Apache Software Foundation (ASF) under one or more
  * contributor license agreements.  See the NOTICE file distributed with
@@ -19,11 +26,19 @@ import java.io.IOException;
  * limitations under the License.
  */
 
-/** Allows recursively visiting indexed dimensional values
+/** Allows recursively visiting dimensional values indexed with {@link DimensionalIntField},
+ *  {@link DimensionalFloatField}, {@link DimensionalLongField}, {@link DimensionalDoubleField}
+ *  or {@link DimensionalBinaryField}.
  *
  *  @lucene.experimental */
 public abstract class DimensionalValues {
 
+  /** Maximum number of bytes for each dimension */
+  public static final int MAX_NUM_BYTES = 16;
+
+  /** Maximum number of dimensions */
+  public static final int MAX_DIMENSIONS = BKDWriter.MAX_DIMS;
+
   /** Defautl constructor */
   protected DimensionalValues() {
   }
diff --git a/lucene/core/src/java/org/apache/lucene/index/FieldInfo.java b/lucene/core/src/java/org/apache/lucene/index/FieldInfo.java
index 015dc51..ea5f844 100644
--- a/lucene/core/src/java/org/apache/lucene/index/FieldInfo.java
+++ b/lucene/core/src/java/org/apache/lucene/index/FieldInfo.java
@@ -171,9 +171,15 @@ public final class FieldInfo {
     if (count <= 0) {
       throw new IllegalArgumentException("dimension count must be >= 0; got " + count + " for field=\"" + name + "\"");
     }
+    if (count > DimensionalValues.MAX_DIMENSIONS) {
+      throw new IllegalArgumentException("dimension count must be < DimensionalValues.MAX_DIMENSIONS (= " + DimensionalValues.MAX_DIMENSIONS + "); got " + count + " for field=\"" + name + "\"");
+    }
     if (numBytes <= 0) {
       throw new IllegalArgumentException("dimension numBytes must be >= 0; got " + numBytes + " for field=\"" + name + "\"");
     }
+    if (numBytes > DimensionalValues.MAX_NUM_BYTES) {
+      throw new IllegalArgumentException("dimension numBytes must be <= DimensionalValues.MAX_NUM_BYTES (= " + DimensionalValues.MAX_NUM_BYTES + "); got " + numBytes + " for field=\"" + name + "\"");
+    }
     if (dimensionCount != 0 && dimensionCount != count) {
       throw new IllegalArgumentException("cannot change dimension count from " + dimensionCount + " to " + count + " for field=\"" + name + "\"");
     }
diff --git a/lucene/core/src/java/org/apache/lucene/index/FieldInfos.java b/lucene/core/src/java/org/apache/lucene/index/FieldInfos.java
index 5b3c9e7..86da865 100644
--- a/lucene/core/src/java/org/apache/lucene/index/FieldInfos.java
+++ b/lucene/core/src/java/org/apache/lucene/index/FieldInfos.java
@@ -337,6 +337,12 @@ public class FieldInfos implements Iterable<FieldInfo> {
     }
 
     synchronized void setDimensions(int number, String name, int dimensionCount, int dimensionNumBytes) {
+      if (dimensionNumBytes > DimensionalValues.MAX_NUM_BYTES) {
+        throw new IllegalArgumentException("dimension numBytes must be <= DimensionalValues.MAX_NUM_BYTES (= " + DimensionalValues.MAX_NUM_BYTES + "); got " + dimensionNumBytes + " for field=\"" + name + "\"");
+      }
+      if (dimensionCount > DimensionalValues.MAX_DIMENSIONS) {
+        throw new IllegalArgumentException("dimensionCount must be <= DimensionalValues.MAX_DIMENSIONS (= " + DimensionalValues.MAX_DIMENSIONS + "); got " + dimensionCount + " for field=\"" + name + "\"");
+      }
       verifyConsistentDimensions(number, name, dimensionCount, dimensionNumBytes);
       dimensions.put(name, new FieldDimensions(dimensionCount, dimensionNumBytes));
     }
diff --git a/lucene/core/src/java/org/apache/lucene/index/StoredDocument.java b/lucene/core/src/java/org/apache/lucene/index/StoredDocument.java
index b79c6b6..5bd48f8 100644
--- a/lucene/core/src/java/org/apache/lucene/index/StoredDocument.java
+++ b/lucene/core/src/java/org/apache/lucene/index/StoredDocument.java
@@ -21,10 +21,6 @@ import java.util.ArrayList;
 import java.util.Iterator;
 import java.util.List;
 
-import org.apache.lucene.document.DoubleField;
-import org.apache.lucene.document.FloatField;
-import org.apache.lucene.document.IntField;
-import org.apache.lucene.document.LongField;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.util.BytesRef;
 
@@ -151,8 +147,8 @@ public class StoredDocument implements Iterable<StorableField> {
     * Returns an array of values of the field specified as the method parameter.
     * This method returns an empty array when there are no
     * matching fields.  It never returns null.
-    * For {@link IntField}, {@link LongField}, {@link
-    * FloatField} and {@link DoubleField} it returns the string value of the number. If you want
+    * For {@link org.apache.lucene.document.LegacyIntField}, {@link org.apache.lucene.document.LegacyLongField}, {@link
+    * org.apache.lucene.document.LegacyFloatField} and {@link org.apache.lucene.document.LegacyDoubleField} it returns the string value of the number. If you want
     * the actual numeric field instances back, use {@link #getFields}.
     * @param name the name of the field
     * @return a <code>String[]</code> of field values
@@ -176,8 +172,8 @@ public class StoredDocument implements Iterable<StorableField> {
     * this document, or null.  If multiple fields exist with this name, this
     * method returns the first value added. If only binary fields with this name
     * exist, returns null.
-    * For {@link IntField}, {@link LongField}, {@link
-    * FloatField} and {@link DoubleField} it returns the string value of the number. If you want
+    * For {@link org.apache.lucene.document.LegacyIntField}, {@link org.apache.lucene.document.LegacyLongField}, {@link
+    * org.apache.lucene.document.LegacyFloatField} and {@link org.apache.lucene.document.LegacyDoubleField} it returns the string value of the number. If you want
     * the actual numeric field instance back, use {@link #getField}.
     */
    public final String get(String name) {
diff --git a/lucene/core/src/java/org/apache/lucene/search/DimensionalRangeQuery.java b/lucene/core/src/java/org/apache/lucene/search/DimensionalRangeQuery.java
index 0e8d340..864a65e 100644
--- a/lucene/core/src/java/org/apache/lucene/search/DimensionalRangeQuery.java
+++ b/lucene/core/src/java/org/apache/lucene/search/DimensionalRangeQuery.java
@@ -21,7 +21,11 @@ import java.io.IOException;
 import java.util.Arrays;
 import java.util.Objects;
 
-import org.apache.lucene.document.DimensionalField;
+import org.apache.lucene.document.DimensionalBinaryField;
+import org.apache.lucene.document.DimensionalDoubleField;
+import org.apache.lucene.document.DimensionalFloatField;
+import org.apache.lucene.document.DimensionalIntField;
+import org.apache.lucene.document.DimensionalLongField;
 import org.apache.lucene.index.DimensionalValues;
 import org.apache.lucene.index.DimensionalValues.IntersectVisitor;
 import org.apache.lucene.index.DimensionalValues.Relation;
@@ -29,12 +33,13 @@ import org.apache.lucene.index.FieldInfo;
 import org.apache.lucene.index.LeafReader;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.util.DocIdSetBuilder;
+import org.apache.lucene.util.NumericUtils;
 import org.apache.lucene.util.RamUsageEstimator;
 import org.apache.lucene.util.StringHelper;
-import org.apache.lucene.util.bkd.BKDUtil;
 
-/** Searches for ranges in fields previously indexed using {@link DimensionalField}.  In
- *  a 1D field this is a simple range query; in a multi-dimensional field it's a box shape. */
+/** Searches for ranges in fields previously indexed using dimensional
+ *  fields, e.g. {@link DimensionalLongField}.  In a 1D field this is
+ *  a simple range query; in a multi-dimensional field it's a box shape. */
 
 public class DimensionalRangeQuery extends Query {
   final String field;
@@ -91,14 +96,29 @@ public class DimensionalRangeQuery extends Query {
     }
   }
 
-  /** Sugar constructor: use in the 1D case when you indexed 1D long values using {@link DimensionalField} */
-  public DimensionalRangeQuery(String field, Long lowerValue, boolean lowerInclusive, Long upperValue, boolean upperInclusive) {
-    this(field, pack(lowerValue), new boolean[] {lowerInclusive}, pack(upperValue), new boolean[] {upperInclusive});
+  /** Use in the 1D case when you indexed 1D int values using {@link DimensionalIntField} */
+  public static DimensionalRangeQuery new1DIntRange(String field, Integer lowerValue, boolean lowerInclusive, Integer upperValue, boolean upperInclusive) {
+    return new DimensionalRangeQuery(field, pack(lowerValue), new boolean[] {lowerInclusive}, pack(upperValue), new boolean[] {upperInclusive});
   }
 
-  /** Sugar constructor: use in the 1D case when you indexed binary values using {@link DimensionalField} */
-  public DimensionalRangeQuery(String field, byte[] lowerValue, boolean lowerInclusive, byte[] upperValue, boolean upperInclusive) {
-    this(field, new byte[][] {lowerValue}, new boolean[] {lowerInclusive}, new byte[][] {upperValue}, new boolean[] {upperInclusive});
+  /** Use in the 1D case when you indexed 1D long values using {@link DimensionalLongField} */
+  public static DimensionalRangeQuery new1DLongRange(String field, Long lowerValue, boolean lowerInclusive, Long upperValue, boolean upperInclusive) {
+    return new DimensionalRangeQuery(field, pack(lowerValue), new boolean[] {lowerInclusive}, pack(upperValue), new boolean[] {upperInclusive});
+  }
+
+  /** Use in the 1D case when you indexed 1D float values using {@link DimensionalFloatField} */
+  public static DimensionalRangeQuery new1DFloatRange(String field, Float lowerValue, boolean lowerInclusive, Float upperValue, boolean upperInclusive) {
+    return new DimensionalRangeQuery(field, pack(lowerValue), new boolean[] {lowerInclusive}, pack(upperValue), new boolean[] {upperInclusive});
+  }
+
+  /** Use in the 1D case when you indexed 1D double values using {@link DimensionalDoubleField} */
+  public static DimensionalRangeQuery new1DDoubleRange(String field, Double lowerValue, boolean lowerInclusive, Double upperValue, boolean upperInclusive) {
+    return new DimensionalRangeQuery(field, pack(lowerValue), new boolean[] {lowerInclusive}, pack(upperValue), new boolean[] {upperInclusive});
+  }
+
+  /** Use in the 1D case when you indexed binary values using {@link DimensionalBinaryField} */
+  public static DimensionalRangeQuery new1DBinaryRange(String field, byte[] lowerValue, boolean lowerInclusive, byte[] upperValue, boolean upperInclusive) {
+    return new DimensionalRangeQuery(field, new byte[][] {lowerValue}, new boolean[] {lowerInclusive}, new byte[][] {upperValue}, new boolean[] {upperInclusive});
   }
 
   private static byte[][] pack(Long value) {
@@ -107,7 +127,37 @@ public class DimensionalRangeQuery extends Query {
       return new byte[1][];
     }
     byte[][] result = new byte[][] {new byte[RamUsageEstimator.NUM_BYTES_LONG]};
-    BKDUtil.longToBytes(value, result[0], 0);
+    NumericUtils.longToBytes(value, result[0], 0);
+    return result;
+  }
+
+  private static byte[][] pack(Double value) {
+    if (value == null) {
+      // OK: open ended range
+      return new byte[1][];
+    }
+    byte[][] result = new byte[][] {new byte[RamUsageEstimator.NUM_BYTES_LONG]};
+    NumericUtils.longToBytesDirect(NumericUtils.doubleToSortableLong(value), result[0], 0);
+    return result;
+  }
+
+  private static byte[][] pack(Integer value) {
+    if (value == null) {
+      // OK: open ended range
+      return new byte[1][];
+    }
+    byte[][] result = new byte[][] {new byte[RamUsageEstimator.NUM_BYTES_INT]};
+    NumericUtils.intToBytes(value, result[0], 0);
+    return result;
+  }
+
+  private static byte[][] pack(Float value) {
+    if (value == null) {
+      // OK: open ended range
+      return new byte[1][];
+    }
+    byte[][] result = new byte[][] {new byte[RamUsageEstimator.NUM_BYTES_INT]};
+    NumericUtils.intToBytesDirect(NumericUtils.floatToSortableInt(value), result[0], 0);
     return result;
   }
 
@@ -158,7 +208,7 @@ public class DimensionalRangeQuery extends Query {
                 return null;
               } else {
                 byte[] value = new byte[bytesPerDim];
-                BKDUtil.add(bytesPerDim, 0, lowerPoint[dim], one, value);
+                NumericUtils.add(bytesPerDim, 0, lowerPoint[dim], one, value);
                 System.arraycopy(value, 0, packedLowerIncl, dim*bytesPerDim, bytesPerDim);
               }
             } else {
@@ -174,7 +224,7 @@ public class DimensionalRangeQuery extends Query {
                 return null;
               } else {
                 byte[] value = new byte[bytesPerDim];
-                BKDUtil.subtract(bytesPerDim, 0, upperPoint[dim], one, value);
+                NumericUtils.subtract(bytesPerDim, 0, upperPoint[dim], one, value);
                 System.arraycopy(value, 0, packedUpperIncl, dim*bytesPerDim, bytesPerDim);
               }
             } else {
diff --git a/lucene/core/src/java/org/apache/lucene/search/LegacyNumericRangeQuery.java b/lucene/core/src/java/org/apache/lucene/search/LegacyNumericRangeQuery.java
new file mode 100644
index 0000000..be1bf68
--- /dev/null
+++ b/lucene/core/src/java/org/apache/lucene/search/LegacyNumericRangeQuery.java
@@ -0,0 +1,525 @@
+package org.apache.lucene.search;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.LinkedList;
+import java.util.Objects;
+
+import org.apache.lucene.document.FieldType;
+import org.apache.lucene.document.FieldType.LegacyNumericType;
+import org.apache.lucene.index.FilteredTermsEnum;
+import org.apache.lucene.index.Terms;
+import org.apache.lucene.index.TermsEnum;
+import org.apache.lucene.util.AttributeSource;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.LegacyNumericUtils;
+import org.apache.lucene.index.Term; // for javadocs
+
+/**
+ * <p>A {@link Query} that matches numeric values within a
+ * specified range.  To use this, you must first index the
+ * numeric values using {@link org.apache.lucene.document.LegacyIntField}, {@link
+ * org.apache.lucene.document.LegacyFloatField}, {@link org.apache.lucene.document.LegacyLongField} or {@link org.apache.lucene.document.LegacyDoubleField} (expert: {@link
+ * org.apache.lucene.analysis.LegacyNumericTokenStream}).  If your terms are instead textual,
+ * you should use {@link TermRangeQuery}.</p>
+ *
+ * <p>You create a new LegacyNumericRangeQuery with the static
+ * factory methods, eg:
+ *
+ * <pre class="prettyprint">
+ * Query q = LegacyNumericRangeQuery.newFloatRange("weight", 0.03f, 0.10f, true, true);
+ * </pre>
+ *
+ * matches all documents whose float valued "weight" field
+ * ranges from 0.03 to 0.10, inclusive.
+ *
+ * <p>The performance of LegacyNumericRangeQuery is much better
+ * than the corresponding {@link TermRangeQuery} because the
+ * number of terms that must be searched is usually far
+ * fewer, thanks to trie indexing, described below.</p>
+ *
+ * <p>You can optionally specify a <a
+ * href="#precisionStepDesc"><code>precisionStep</code></a>
+ * when creating this query.  This is necessary if you've
+ * changed this configuration from its default (4) during
+ * indexing.  Lower values consume more disk space but speed
+ * up searching.  Suitable values are between <b>1</b> and
+ * <b>8</b>. A good starting point to test is <b>4</b>,
+ * which is the default value for all <code>Numeric*</code>
+ * classes.  See <a href="#precisionStepDesc">below</a> for
+ * details.
+ *
+ * <p>This query defaults to {@linkplain
+ * MultiTermQuery#CONSTANT_SCORE_REWRITE}.
+ * With precision steps of &le;4, this query can be run with
+ * one of the BooleanQuery rewrite methods without changing
+ * BooleanQuery's default max clause count.
+ *
+ * <br><h3>How it works</h3>
+ *
+ * <p>See the publication about <a target="_blank" href="http://www.panfmp.org">panFMP</a>,
+ * where this algorithm was described (referred to as <code>TrieRangeQuery</code>):
+ *
+ * <blockquote><strong>Schindler, U, Diepenbroek, M</strong>, 2008.
+ * <em>Generic XML-based Framework for Metadata Portals.</em>
+ * Computers &amp; Geosciences 34 (12), 1947-1955.
+ * <a href="http://dx.doi.org/10.1016/j.cageo.2008.02.023"
+ * target="_blank">doi:10.1016/j.cageo.2008.02.023</a></blockquote>
+ *
+ * <p><em>A quote from this paper:</em> Because Apache Lucene is a full-text
+ * search engine and not a conventional database, it cannot handle numerical ranges
+ * (e.g., field value is inside user defined bounds, even dates are numerical values).
+ * We have developed an extension to Apache Lucene that stores
+ * the numerical values in a special string-encoded format with variable precision
+ * (all numerical values like doubles, longs, floats, and ints are converted to
+ * lexicographic sortable string representations and stored with different precisions
+ * (for a more detailed description of how the values are stored,
+ * see {@link org.apache.lucene.util.LegacyNumericUtils}). A range is then divided recursively into multiple intervals for searching:
+ * The center of the range is searched only with the lowest possible precision in the <em>trie</em>,
+ * while the boundaries are matched more exactly. This reduces the number of terms dramatically.</p>
+ *
+ * <p>For the variant that stores long values in 8 different precisions (each reduced by 8 bits) that
+ * uses a lowest precision of 1 byte, the index contains only a maximum of 256 distinct values in the
+ * lowest precision. Overall, a range could consist of a theoretical maximum of
+ * <code>7*255*2 + 255 = 3825</code> distinct terms (when there is a term for every distinct value of an
+ * 8-byte-number in the index and the range covers almost all of them; a maximum of 255 distinct values is used
+ * because it would always be possible to reduce the full 256 values to one term with degraded precision).
+ * In practice, we have seen up to 300 terms in most cases (index with 500,000 metadata records
+ * and a uniform value distribution).</p>
+ *
+ * <h3><a name="precisionStepDesc">Precision Step</a></h3>
+ * <p>You can choose any <code>precisionStep</code> when encoding values.
+ * Lower step values mean more precisions and so more terms in index (and index gets larger). The number
+ * of indexed terms per value is (those are generated by {@link org.apache.lucene.analysis.LegacyNumericTokenStream}):
+ * <p style="font-family:serif">
+ * &nbsp;&nbsp;indexedTermsPerValue = <b>ceil</b><big>(</big>bitsPerValue / precisionStep<big>)</big>
+ * </p>
+ * As the lower precision terms are shared by many values, the additional terms only
+ * slightly grow the term dictionary (approx. 7% for <code>precisionStep=4</code>), but have a larger
+ * impact on the postings (the postings file will have  more entries, as every document is linked to
+ * <code>indexedTermsPerValue</code> terms instead of one). The formula to estimate the growth
+ * of the term dictionary in comparison to one term per value:
+ * <p>
+ * <!-- the formula in the alt attribute was transformed from latex to PNG with http://1.618034.com/latex.php (with 110 dpi): -->
+ * &nbsp;&nbsp;<img src="doc-files/nrq-formula-1.png" alt="\mathrm{termDictOverhead} = \sum\limits_{i=0}^{\mathrm{indexedTermsPerValue}-1} \frac{1}{2^{\mathrm{precisionStep}\cdot i}}">
+ * </p>
+ * <p>On the other hand, if the <code>precisionStep</code> is smaller, the maximum number of terms to match reduces,
+ * which optimizes query speed. The formula to calculate the maximum number of terms that will be visited while
+ * executing the query is:
+ * <p>
+ * <!-- the formula in the alt attribute was transformed from latex to PNG with http://1.618034.com/latex.php (with 110 dpi): -->
+ * &nbsp;&nbsp;<img src="doc-files/nrq-formula-2.png" alt="\mathrm{maxQueryTerms} = \left[ \left( \mathrm{indexedTermsPerValue} - 1 \right) \cdot \left(2^\mathrm{precisionStep} - 1 \right) \cdot 2 \right] + \left( 2^\mathrm{precisionStep} - 1 \right)">
+ * </p>
+ * <p>For longs stored using a precision step of 4, <code>maxQueryTerms = 15*15*2 + 15 = 465</code>, and for a precision
+ * step of 2, <code>maxQueryTerms = 31*3*2 + 3 = 189</code>. But the faster search speed is reduced by more seeking
+ * in the term enum of the index. Because of this, the ideal <code>precisionStep</code> value can only
+ * be found out by testing. <b>Important:</b> You can index with a lower precision step value and test search speed
+ * using a multiple of the original step value.</p>
+ *
+ * <p>Good values for <code>precisionStep</code> are depending on usage and data type:
+ * <ul>
+ *  <li>The default for all data types is <b>4</b>, which is used, when no <code>precisionStep</code> is given.
+ *  <li>Ideal value in most cases for <em>64 bit</em> data types <em>(long, double)</em> is <b>6</b> or <b>8</b>.
+ *  <li>Ideal value in most cases for <em>32 bit</em> data types <em>(int, float)</em> is <b>4</b>.
+ *  <li>For low cardinality fields larger precision steps are good. If the cardinality is &lt; 100, it is
+ *  fair to use {@link Integer#MAX_VALUE} (see below).
+ *  <li>Steps <b>&ge;64</b> for <em>long/double</em> and <b>&ge;32</b> for <em>int/float</em> produces one token
+ *  per value in the index and querying is as slow as a conventional {@link TermRangeQuery}. But it can be used
+ *  to produce fields, that are solely used for sorting (in this case simply use {@link Integer#MAX_VALUE} as
+ *  <code>precisionStep</code>). Using {@link org.apache.lucene.document.LegacyIntField},
+ *  {@link org.apache.lucene.document.LegacyLongField}, {@link org.apache.lucene.document.LegacyFloatField} or {@link org.apache.lucene.document.LegacyDoubleField} for sorting
+ *  is ideal, because building the field cache is much faster than with text-only numbers.
+ *  These fields have one term per value and therefore also work with term enumeration for building distinct lists
+ *  (e.g. facets / preselected values to search for).
+ *  Sorting is also possible with range query optimized fields using one of the above <code>precisionSteps</code>.
+ * </ul>
+ *
+ * <p>Comparisons of the different types of RangeQueries on an index with about 500,000 docs showed
+ * that {@link TermRangeQuery} in boolean rewrite mode (with raised {@link BooleanQuery} clause count)
+ * took about 30-40 secs to complete, {@link TermRangeQuery} in constant score filter rewrite mode took 5 secs
+ * and executing this class took &lt;100ms to complete (on an Opteron64 machine, Java 1.5, 8 bit
+ * precision step). This query type was developed for a geographic portal, where the performance for
+ * e.g. bounding boxes or exact date/time stamps is important.</p>
+ *
+ * @deprecated Please use {@link DimensionalRangeQuery} instead
+ *
+ * @since 2.9
+ **/
+
+@Deprecated
+public final class LegacyNumericRangeQuery<T extends Number> extends MultiTermQuery {
+
+  private LegacyNumericRangeQuery(final String field, final int precisionStep, final LegacyNumericType dataType,
+                                  T min, T max, final boolean minInclusive, final boolean maxInclusive) {
+    super(field);
+    if (precisionStep < 1)
+      throw new IllegalArgumentException("precisionStep must be >=1");
+    this.precisionStep = precisionStep;
+    this.dataType = Objects.requireNonNull(dataType, "LegacyNumericType must not be null");
+    this.min = min;
+    this.max = max;
+    this.minInclusive = minInclusive;
+    this.maxInclusive = maxInclusive;
+  }
+  
+  /**
+   * Factory that creates a <code>LegacyNumericRangeQuery</code>, that queries a <code>long</code>
+   * range using the given <a href="#precisionStepDesc"><code>precisionStep</code></a>.
+   * You can have half-open ranges (which are in fact &lt;/&le; or &gt;/&ge; queries)
+   * by setting the min or max value to <code>null</code>. By setting inclusive to false, it will
+   * match all documents excluding the bounds, with inclusive on, the boundaries are hits, too.
+   */
+  public static LegacyNumericRangeQuery<Long> newLongRange(final String field, final int precisionStep,
+    Long min, Long max, final boolean minInclusive, final boolean maxInclusive
+  ) {
+    return new LegacyNumericRangeQuery<>(field, precisionStep, FieldType.LegacyNumericType.LONG, min, max, minInclusive, maxInclusive);
+  }
+  
+  /**
+   * Factory that creates a <code>LegacyNumericRangeQuery</code>, that queries a <code>long</code>
+   * range using the default <code>precisionStep</code> {@link org.apache.lucene.util.LegacyNumericUtils#PRECISION_STEP_DEFAULT} (16).
+   * You can have half-open ranges (which are in fact &lt;/&le; or &gt;/&ge; queries)
+   * by setting the min or max value to <code>null</code>. By setting inclusive to false, it will
+   * match all documents excluding the bounds, with inclusive on, the boundaries are hits, too.
+   */
+  public static LegacyNumericRangeQuery<Long> newLongRange(final String field,
+    Long min, Long max, final boolean minInclusive, final boolean maxInclusive
+  ) {
+    return new LegacyNumericRangeQuery<>(field, LegacyNumericUtils.PRECISION_STEP_DEFAULT, FieldType.LegacyNumericType.LONG, min, max, minInclusive, maxInclusive);
+  }
+  
+  /**
+   * Factory that creates a <code>LegacyNumericRangeQuery</code>, that queries a <code>int</code>
+   * range using the given <a href="#precisionStepDesc"><code>precisionStep</code></a>.
+   * You can have half-open ranges (which are in fact &lt;/&le; or &gt;/&ge; queries)
+   * by setting the min or max value to <code>null</code>. By setting inclusive to false, it will
+   * match all documents excluding the bounds, with inclusive on, the boundaries are hits, too.
+   */
+  public static LegacyNumericRangeQuery<Integer> newIntRange(final String field, final int precisionStep,
+    Integer min, Integer max, final boolean minInclusive, final boolean maxInclusive
+  ) {
+    return new LegacyNumericRangeQuery<>(field, precisionStep, FieldType.LegacyNumericType.INT, min, max, minInclusive, maxInclusive);
+  }
+  
+  /**
+   * Factory that creates a <code>LegacyNumericRangeQuery</code>, that queries a <code>int</code>
+   * range using the default <code>precisionStep</code> {@link org.apache.lucene.util.LegacyNumericUtils#PRECISION_STEP_DEFAULT_32} (8).
+   * You can have half-open ranges (which are in fact &lt;/&le; or &gt;/&ge; queries)
+   * by setting the min or max value to <code>null</code>. By setting inclusive to false, it will
+   * match all documents excluding the bounds, with inclusive on, the boundaries are hits, too.
+   */
+  public static LegacyNumericRangeQuery<Integer> newIntRange(final String field,
+    Integer min, Integer max, final boolean minInclusive, final boolean maxInclusive
+  ) {
+    return new LegacyNumericRangeQuery<>(field, LegacyNumericUtils.PRECISION_STEP_DEFAULT_32, FieldType.LegacyNumericType.INT, min, max, minInclusive, maxInclusive);
+  }
+  
+  /**
+   * Factory that creates a <code>LegacyNumericRangeQuery</code>, that queries a <code>double</code>
+   * range using the given <a href="#precisionStepDesc"><code>precisionStep</code></a>.
+   * You can have half-open ranges (which are in fact &lt;/&le; or &gt;/&ge; queries)
+   * by setting the min or max value to <code>null</code>.
+   * {@link Double#NaN} will never match a half-open range, to hit {@code NaN} use a query
+   * with {@code min == max == Double.NaN}.  By setting inclusive to false, it will
+   * match all documents excluding the bounds, with inclusive on, the boundaries are hits, too.
+   */
+  public static LegacyNumericRangeQuery<Double> newDoubleRange(final String field, final int precisionStep,
+    Double min, Double max, final boolean minInclusive, final boolean maxInclusive
+  ) {
+    return new LegacyNumericRangeQuery<>(field, precisionStep, FieldType.LegacyNumericType.DOUBLE, min, max, minInclusive, maxInclusive);
+  }
+  
+  /**
+   * Factory that creates a <code>LegacyNumericRangeQuery</code>, that queries a <code>double</code>
+   * range using the default <code>precisionStep</code> {@link org.apache.lucene.util.LegacyNumericUtils#PRECISION_STEP_DEFAULT} (16).
+   * You can have half-open ranges (which are in fact &lt;/&le; or &gt;/&ge; queries)
+   * by setting the min or max value to <code>null</code>.
+   * {@link Double#NaN} will never match a half-open range, to hit {@code NaN} use a query
+   * with {@code min == max == Double.NaN}.  By setting inclusive to false, it will
+   * match all documents excluding the bounds, with inclusive on, the boundaries are hits, too.
+   */
+  public static LegacyNumericRangeQuery<Double> newDoubleRange(final String field,
+    Double min, Double max, final boolean minInclusive, final boolean maxInclusive
+  ) {
+    return new LegacyNumericRangeQuery<>(field, LegacyNumericUtils.PRECISION_STEP_DEFAULT, FieldType.LegacyNumericType.DOUBLE, min, max, minInclusive, maxInclusive);
+  }
+  
+  /**
+   * Factory that creates a <code>LegacyNumericRangeQuery</code>, that queries a <code>float</code>
+   * range using the given <a href="#precisionStepDesc"><code>precisionStep</code></a>.
+   * You can have half-open ranges (which are in fact &lt;/&le; or &gt;/&ge; queries)
+   * by setting the min or max value to <code>null</code>.
+   * {@link Float#NaN} will never match a half-open range, to hit {@code NaN} use a query
+   * with {@code min == max == Float.NaN}.  By setting inclusive to false, it will
+   * match all documents excluding the bounds, with inclusive on, the boundaries are hits, too.
+   */
+  public static LegacyNumericRangeQuery<Float> newFloatRange(final String field, final int precisionStep,
+    Float min, Float max, final boolean minInclusive, final boolean maxInclusive
+  ) {
+    return new LegacyNumericRangeQuery<>(field, precisionStep, FieldType.LegacyNumericType.FLOAT, min, max, minInclusive, maxInclusive);
+  }
+  
+  /**
+   * Factory that creates a <code>LegacyNumericRangeQuery</code>, that queries a <code>float</code>
+   * range using the default <code>precisionStep</code> {@link org.apache.lucene.util.LegacyNumericUtils#PRECISION_STEP_DEFAULT_32} (8).
+   * You can have half-open ranges (which are in fact &lt;/&le; or &gt;/&ge; queries)
+   * by setting the min or max value to <code>null</code>.
+   * {@link Float#NaN} will never match a half-open range, to hit {@code NaN} use a query
+   * with {@code min == max == Float.NaN}.  By setting inclusive to false, it will
+   * match all documents excluding the bounds, with inclusive on, the boundaries are hits, too.
+   */
+  public static LegacyNumericRangeQuery<Float> newFloatRange(final String field,
+    Float min, Float max, final boolean minInclusive, final boolean maxInclusive
+  ) {
+    return new LegacyNumericRangeQuery<>(field, LegacyNumericUtils.PRECISION_STEP_DEFAULT_32, FieldType.LegacyNumericType.FLOAT, min, max, minInclusive, maxInclusive);
+  }
+
+  @Override @SuppressWarnings("unchecked")
+  protected TermsEnum getTermsEnum(final Terms terms, AttributeSource atts) throws IOException {
+    // very strange: java.lang.Number itself is not Comparable, but all subclasses used here are
+    if (min != null && max != null && ((Comparable<T>) min).compareTo(max) > 0) {
+      return TermsEnum.EMPTY;
+    }
+    return new NumericRangeTermsEnum(terms.iterator());
+  }
+
+  /** Returns <code>true</code> if the lower endpoint is inclusive */
+  public boolean includesMin() { return minInclusive; }
+  
+  /** Returns <code>true</code> if the upper endpoint is inclusive */
+  public boolean includesMax() { return maxInclusive; }
+
+  /** Returns the lower value of this range query */
+  public T getMin() { return min; }
+
+  /** Returns the upper value of this range query */
+  public T getMax() { return max; }
+  
+  /** Returns the precision step. */
+  public int getPrecisionStep() { return precisionStep; }
+  
+  @Override
+  public String toString(final String field) {
+    final StringBuilder sb = new StringBuilder();
+    if (!getField().equals(field)) sb.append(getField()).append(':');
+    return sb.append(minInclusive ? '[' : '{')
+      .append((min == null) ? "*" : min.toString())
+      .append(" TO ")
+      .append((max == null) ? "*" : max.toString())
+      .append(maxInclusive ? ']' : '}')
+      .toString();
+  }
+
+  @Override
+  @SuppressWarnings({"unchecked","rawtypes"})
+  public final boolean equals(final Object o) {
+    if (o==this) return true;
+    if (!super.equals(o))
+      return false;
+    if (o instanceof LegacyNumericRangeQuery) {
+      final LegacyNumericRangeQuery q=(LegacyNumericRangeQuery)o;
+      return (
+        (q.min == null ? min == null : q.min.equals(min)) &&
+        (q.max == null ? max == null : q.max.equals(max)) &&
+        minInclusive == q.minInclusive &&
+        maxInclusive == q.maxInclusive &&
+        precisionStep == q.precisionStep
+      );
+    }
+    return false;
+  }
+
+  @Override
+  public final int hashCode() {
+    int hash = super.hashCode();
+    hash += precisionStep^0x64365465;
+    if (min != null) hash += min.hashCode()^0x14fa55fb;
+    if (max != null) hash += max.hashCode()^0x733fa5fe;
+    return hash +
+      (Boolean.valueOf(minInclusive).hashCode()^0x14fa55fb)+
+      (Boolean.valueOf(maxInclusive).hashCode()^0x733fa5fe);
+  }
+
+  // members (package private, to be also fast accessible by NumericRangeTermEnum)
+  final int precisionStep;
+  final FieldType.LegacyNumericType dataType;
+  final T min, max;
+  final boolean minInclusive,maxInclusive;
+
+  // used to handle float/double infinity correcty
+  static final long LONG_NEGATIVE_INFINITY =
+    LegacyNumericUtils.doubleToSortableLong(Double.NEGATIVE_INFINITY);
+  static final long LONG_POSITIVE_INFINITY =
+    LegacyNumericUtils.doubleToSortableLong(Double.POSITIVE_INFINITY);
+  static final int INT_NEGATIVE_INFINITY =
+    LegacyNumericUtils.floatToSortableInt(Float.NEGATIVE_INFINITY);
+  static final int INT_POSITIVE_INFINITY =
+    LegacyNumericUtils.floatToSortableInt(Float.POSITIVE_INFINITY);
+
+  /**
+   * Subclass of FilteredTermsEnum for enumerating all terms that match the
+   * sub-ranges for trie range queries, using flex API.
+   * <p>
+   * WARNING: This term enumeration is not guaranteed to be always ordered by
+   * {@link Term#compareTo}.
+   * The ordering depends on how {@link org.apache.lucene.util.LegacyNumericUtils#splitLongRange} and
+   * {@link org.apache.lucene.util.LegacyNumericUtils#splitIntRange} generates the sub-ranges. For
+   * {@link MultiTermQuery} ordering is not relevant.
+   */
+  private final class NumericRangeTermsEnum extends FilteredTermsEnum {
+
+    private BytesRef currentLowerBound, currentUpperBound;
+
+    private final LinkedList<BytesRef> rangeBounds = new LinkedList<>();
+
+    NumericRangeTermsEnum(final TermsEnum tenum) {
+      super(tenum);
+      switch (dataType) {
+        case LONG:
+        case DOUBLE: {
+          // lower
+          long minBound;
+          if (dataType == FieldType.LegacyNumericType.LONG) {
+            minBound = (min == null) ? Long.MIN_VALUE : min.longValue();
+          } else {
+            assert dataType == FieldType.LegacyNumericType.DOUBLE;
+            minBound = (min == null) ? LONG_NEGATIVE_INFINITY
+              : LegacyNumericUtils.doubleToSortableLong(min.doubleValue());
+          }
+          if (!minInclusive && min != null) {
+            if (minBound == Long.MAX_VALUE) break;
+            minBound++;
+          }
+          
+          // upper
+          long maxBound;
+          if (dataType == FieldType.LegacyNumericType.LONG) {
+            maxBound = (max == null) ? Long.MAX_VALUE : max.longValue();
+          } else {
+            assert dataType == FieldType.LegacyNumericType.DOUBLE;
+            maxBound = (max == null) ? LONG_POSITIVE_INFINITY
+              : LegacyNumericUtils.doubleToSortableLong(max.doubleValue());
+          }
+          if (!maxInclusive && max != null) {
+            if (maxBound == Long.MIN_VALUE) break;
+            maxBound--;
+          }
+          
+          LegacyNumericUtils.splitLongRange(new LegacyNumericUtils.LongRangeBuilder() {
+            @Override
+            public final void addRange(BytesRef minPrefixCoded, BytesRef maxPrefixCoded) {
+              rangeBounds.add(minPrefixCoded);
+              rangeBounds.add(maxPrefixCoded);
+            }
+          }, precisionStep, minBound, maxBound);
+          break;
+        }
+          
+        case INT:
+        case FLOAT: {
+          // lower
+          int minBound;
+          if (dataType == FieldType.LegacyNumericType.INT) {
+            minBound = (min == null) ? Integer.MIN_VALUE : min.intValue();
+          } else {
+            assert dataType == FieldType.LegacyNumericType.FLOAT;
+            minBound = (min == null) ? INT_NEGATIVE_INFINITY
+              : LegacyNumericUtils.floatToSortableInt(min.floatValue());
+          }
+          if (!minInclusive && min != null) {
+            if (minBound == Integer.MAX_VALUE) break;
+            minBound++;
+          }
+          
+          // upper
+          int maxBound;
+          if (dataType == LegacyNumericType.INT) {
+            maxBound = (max == null) ? Integer.MAX_VALUE : max.intValue();
+          } else {
+            assert dataType == FieldType.LegacyNumericType.FLOAT;
+            maxBound = (max == null) ? INT_POSITIVE_INFINITY
+              : LegacyNumericUtils.floatToSortableInt(max.floatValue());
+          }
+          if (!maxInclusive && max != null) {
+            if (maxBound == Integer.MIN_VALUE) break;
+            maxBound--;
+          }
+          
+          LegacyNumericUtils.splitIntRange(new LegacyNumericUtils.IntRangeBuilder() {
+            @Override
+            public final void addRange(BytesRef minPrefixCoded, BytesRef maxPrefixCoded) {
+              rangeBounds.add(minPrefixCoded);
+              rangeBounds.add(maxPrefixCoded);
+            }
+          }, precisionStep, minBound, maxBound);
+          break;
+        }
+          
+        default:
+          // should never happen
+          throw new IllegalArgumentException("Invalid LegacyNumericType");
+      }
+    }
+    
+    private void nextRange() {
+      assert rangeBounds.size() % 2 == 0;
+
+      currentLowerBound = rangeBounds.removeFirst();
+      assert currentUpperBound == null || currentUpperBound.compareTo(currentLowerBound) <= 0 :
+        "The current upper bound must be <= the new lower bound";
+      
+      currentUpperBound = rangeBounds.removeFirst();
+    }
+    
+    @Override
+    protected final BytesRef nextSeekTerm(BytesRef term) {
+      while (rangeBounds.size() >= 2) {
+        nextRange();
+        
+        // if the new upper bound is before the term parameter, the sub-range is never a hit
+        if (term != null && term.compareTo(currentUpperBound) > 0)
+          continue;
+        // never seek backwards, so use current term if lower bound is smaller
+        return (term != null && term.compareTo(currentLowerBound) > 0) ?
+          term : currentLowerBound;
+      }
+      
+      // no more sub-range enums available
+      assert rangeBounds.isEmpty();
+      currentLowerBound = currentUpperBound = null;
+      return null;
+    }
+    
+    @Override
+    protected final AcceptStatus accept(BytesRef term) {
+      while (currentUpperBound == null || term.compareTo(currentUpperBound) > 0) {
+        if (rangeBounds.isEmpty())
+          return AcceptStatus.END;
+        // peek next sub-range, only seek if the current term is smaller than next lower bound
+        if (term.compareTo(rangeBounds.getFirst()) < 0)
+          return AcceptStatus.NO_AND_SEEK;
+        // step forward to next range without seeking, as next lower range bound is less or equal current term
+        nextRange();
+      }
+      return AcceptStatus.YES;
+    }
+
+  }
+  
+}
diff --git a/lucene/core/src/java/org/apache/lucene/search/NumericRangeQuery.java b/lucene/core/src/java/org/apache/lucene/search/NumericRangeQuery.java
deleted file mode 100644
index ce413b5..0000000
--- a/lucene/core/src/java/org/apache/lucene/search/NumericRangeQuery.java
+++ /dev/null
@@ -1,525 +0,0 @@
-package org.apache.lucene.search;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.util.LinkedList;
-import java.util.Objects;
-
-import org.apache.lucene.analysis.NumericTokenStream; // for javadocs
-import org.apache.lucene.document.DoubleField; // for javadocs
-import org.apache.lucene.document.FloatField; // for javadocs
-import org.apache.lucene.document.IntField; // for javadocs
-import org.apache.lucene.document.LongField; // for javadocs
-import org.apache.lucene.document.FieldType.NumericType;
-import org.apache.lucene.index.FilteredTermsEnum;
-import org.apache.lucene.index.Terms;
-import org.apache.lucene.index.TermsEnum;
-import org.apache.lucene.util.AttributeSource;
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.NumericUtils;
-import org.apache.lucene.index.Term; // for javadocs
-
-/**
- * <p>A {@link Query} that matches numeric values within a
- * specified range.  To use this, you must first index the
- * numeric values using {@link IntField}, {@link
- * FloatField}, {@link LongField} or {@link DoubleField} (expert: {@link
- * NumericTokenStream}).  If your terms are instead textual,
- * you should use {@link TermRangeQuery}.</p>
- *
- * <p>You create a new NumericRangeQuery with the static
- * factory methods, eg:
- *
- * <pre class="prettyprint">
- * Query q = NumericRangeQuery.newFloatRange("weight", 0.03f, 0.10f, true, true);
- * </pre>
- *
- * matches all documents whose float valued "weight" field
- * ranges from 0.03 to 0.10, inclusive.
- *
- * <p>The performance of NumericRangeQuery is much better
- * than the corresponding {@link TermRangeQuery} because the
- * number of terms that must be searched is usually far
- * fewer, thanks to trie indexing, described below.</p>
- *
- * <p>You can optionally specify a <a
- * href="#precisionStepDesc"><code>precisionStep</code></a>
- * when creating this query.  This is necessary if you've
- * changed this configuration from its default (4) during
- * indexing.  Lower values consume more disk space but speed
- * up searching.  Suitable values are between <b>1</b> and
- * <b>8</b>. A good starting point to test is <b>4</b>,
- * which is the default value for all <code>Numeric*</code>
- * classes.  See <a href="#precisionStepDesc">below</a> for
- * details.
- *
- * <p>This query defaults to {@linkplain
- * MultiTermQuery#CONSTANT_SCORE_REWRITE}.
- * With precision steps of &le;4, this query can be run with
- * one of the BooleanQuery rewrite methods without changing
- * BooleanQuery's default max clause count.
- *
- * <br><h3>How it works</h3>
- *
- * <p>See the publication about <a target="_blank" href="http://www.panfmp.org">panFMP</a>,
- * where this algorithm was described (referred to as <code>TrieRangeQuery</code>):
- *
- * <blockquote><strong>Schindler, U, Diepenbroek, M</strong>, 2008.
- * <em>Generic XML-based Framework for Metadata Portals.</em>
- * Computers &amp; Geosciences 34 (12), 1947-1955.
- * <a href="http://dx.doi.org/10.1016/j.cageo.2008.02.023"
- * target="_blank">doi:10.1016/j.cageo.2008.02.023</a></blockquote>
- *
- * <p><em>A quote from this paper:</em> Because Apache Lucene is a full-text
- * search engine and not a conventional database, it cannot handle numerical ranges
- * (e.g., field value is inside user defined bounds, even dates are numerical values).
- * We have developed an extension to Apache Lucene that stores
- * the numerical values in a special string-encoded format with variable precision
- * (all numerical values like doubles, longs, floats, and ints are converted to
- * lexicographic sortable string representations and stored with different precisions
- * (for a more detailed description of how the values are stored,
- * see {@link NumericUtils}). A range is then divided recursively into multiple intervals for searching:
- * The center of the range is searched only with the lowest possible precision in the <em>trie</em>,
- * while the boundaries are matched more exactly. This reduces the number of terms dramatically.</p>
- *
- * <p>For the variant that stores long values in 8 different precisions (each reduced by 8 bits) that
- * uses a lowest precision of 1 byte, the index contains only a maximum of 256 distinct values in the
- * lowest precision. Overall, a range could consist of a theoretical maximum of
- * <code>7*255*2 + 255 = 3825</code> distinct terms (when there is a term for every distinct value of an
- * 8-byte-number in the index and the range covers almost all of them; a maximum of 255 distinct values is used
- * because it would always be possible to reduce the full 256 values to one term with degraded precision).
- * In practice, we have seen up to 300 terms in most cases (index with 500,000 metadata records
- * and a uniform value distribution).</p>
- *
- * <h3><a name="precisionStepDesc">Precision Step</a></h3>
- * <p>You can choose any <code>precisionStep</code> when encoding values.
- * Lower step values mean more precisions and so more terms in index (and index gets larger). The number
- * of indexed terms per value is (those are generated by {@link NumericTokenStream}):
- * <p style="font-family:serif">
- * &nbsp;&nbsp;indexedTermsPerValue = <b>ceil</b><big>(</big>bitsPerValue / precisionStep<big>)</big>
- * </p>
- * As the lower precision terms are shared by many values, the additional terms only
- * slightly grow the term dictionary (approx. 7% for <code>precisionStep=4</code>), but have a larger
- * impact on the postings (the postings file will have  more entries, as every document is linked to
- * <code>indexedTermsPerValue</code> terms instead of one). The formula to estimate the growth
- * of the term dictionary in comparison to one term per value:
- * <p>
- * <!-- the formula in the alt attribute was transformed from latex to PNG with http://1.618034.com/latex.php (with 110 dpi): -->
- * &nbsp;&nbsp;<img src="doc-files/nrq-formula-1.png" alt="\mathrm{termDictOverhead} = \sum\limits_{i=0}^{\mathrm{indexedTermsPerValue}-1} \frac{1}{2^{\mathrm{precisionStep}\cdot i}}">
- * </p>
- * <p>On the other hand, if the <code>precisionStep</code> is smaller, the maximum number of terms to match reduces,
- * which optimizes query speed. The formula to calculate the maximum number of terms that will be visited while
- * executing the query is:
- * <p>
- * <!-- the formula in the alt attribute was transformed from latex to PNG with http://1.618034.com/latex.php (with 110 dpi): -->
- * &nbsp;&nbsp;<img src="doc-files/nrq-formula-2.png" alt="\mathrm{maxQueryTerms} = \left[ \left( \mathrm{indexedTermsPerValue} - 1 \right) \cdot \left(2^\mathrm{precisionStep} - 1 \right) \cdot 2 \right] + \left( 2^\mathrm{precisionStep} - 1 \right)">
- * </p>
- * <p>For longs stored using a precision step of 4, <code>maxQueryTerms = 15*15*2 + 15 = 465</code>, and for a precision
- * step of 2, <code>maxQueryTerms = 31*3*2 + 3 = 189</code>. But the faster search speed is reduced by more seeking
- * in the term enum of the index. Because of this, the ideal <code>precisionStep</code> value can only
- * be found out by testing. <b>Important:</b> You can index with a lower precision step value and test search speed
- * using a multiple of the original step value.</p>
- *
- * <p>Good values for <code>precisionStep</code> are depending on usage and data type:
- * <ul>
- *  <li>The default for all data types is <b>4</b>, which is used, when no <code>precisionStep</code> is given.
- *  <li>Ideal value in most cases for <em>64 bit</em> data types <em>(long, double)</em> is <b>6</b> or <b>8</b>.
- *  <li>Ideal value in most cases for <em>32 bit</em> data types <em>(int, float)</em> is <b>4</b>.
- *  <li>For low cardinality fields larger precision steps are good. If the cardinality is &lt; 100, it is
- *  fair to use {@link Integer#MAX_VALUE} (see below).
- *  <li>Steps <b>&ge;64</b> for <em>long/double</em> and <b>&ge;32</b> for <em>int/float</em> produces one token
- *  per value in the index and querying is as slow as a conventional {@link TermRangeQuery}. But it can be used
- *  to produce fields, that are solely used for sorting (in this case simply use {@link Integer#MAX_VALUE} as
- *  <code>precisionStep</code>). Using {@link IntField},
- *  {@link LongField}, {@link FloatField} or {@link DoubleField} for sorting
- *  is ideal, because building the field cache is much faster than with text-only numbers.
- *  These fields have one term per value and therefore also work with term enumeration for building distinct lists
- *  (e.g. facets / preselected values to search for).
- *  Sorting is also possible with range query optimized fields using one of the above <code>precisionSteps</code>.
- * </ul>
- *
- * <p>Comparisons of the different types of RangeQueries on an index with about 500,000 docs showed
- * that {@link TermRangeQuery} in boolean rewrite mode (with raised {@link BooleanQuery} clause count)
- * took about 30-40 secs to complete, {@link TermRangeQuery} in constant score filter rewrite mode took 5 secs
- * and executing this class took &lt;100ms to complete (on an Opteron64 machine, Java 1.5, 8 bit
- * precision step). This query type was developed for a geographic portal, where the performance for
- * e.g. bounding boxes or exact date/time stamps is important.</p>
- *
- * @since 2.9
- **/
-public final class NumericRangeQuery<T extends Number> extends MultiTermQuery {
-
-  private NumericRangeQuery(final String field, final int precisionStep, final NumericType dataType,
-    T min, T max, final boolean minInclusive, final boolean maxInclusive) {
-    super(field);
-    if (precisionStep < 1)
-      throw new IllegalArgumentException("precisionStep must be >=1");
-    this.precisionStep = precisionStep;
-    this.dataType = Objects.requireNonNull(dataType, "NumericType must not be null");
-    this.min = min;
-    this.max = max;
-    this.minInclusive = minInclusive;
-    this.maxInclusive = maxInclusive;
-  }
-  
-  /**
-   * Factory that creates a <code>NumericRangeQuery</code>, that queries a <code>long</code>
-   * range using the given <a href="#precisionStepDesc"><code>precisionStep</code></a>.
-   * You can have half-open ranges (which are in fact &lt;/&le; or &gt;/&ge; queries)
-   * by setting the min or max value to <code>null</code>. By setting inclusive to false, it will
-   * match all documents excluding the bounds, with inclusive on, the boundaries are hits, too.
-   */
-  public static NumericRangeQuery<Long> newLongRange(final String field, final int precisionStep,
-    Long min, Long max, final boolean minInclusive, final boolean maxInclusive
-  ) {
-    return new NumericRangeQuery<>(field, precisionStep, NumericType.LONG, min, max, minInclusive, maxInclusive);
-  }
-  
-  /**
-   * Factory that creates a <code>NumericRangeQuery</code>, that queries a <code>long</code>
-   * range using the default <code>precisionStep</code> {@link NumericUtils#PRECISION_STEP_DEFAULT} (16).
-   * You can have half-open ranges (which are in fact &lt;/&le; or &gt;/&ge; queries)
-   * by setting the min or max value to <code>null</code>. By setting inclusive to false, it will
-   * match all documents excluding the bounds, with inclusive on, the boundaries are hits, too.
-   */
-  public static NumericRangeQuery<Long> newLongRange(final String field,
-    Long min, Long max, final boolean minInclusive, final boolean maxInclusive
-  ) {
-    return new NumericRangeQuery<>(field, NumericUtils.PRECISION_STEP_DEFAULT, NumericType.LONG, min, max, minInclusive, maxInclusive);
-  }
-  
-  /**
-   * Factory that creates a <code>NumericRangeQuery</code>, that queries a <code>int</code>
-   * range using the given <a href="#precisionStepDesc"><code>precisionStep</code></a>.
-   * You can have half-open ranges (which are in fact &lt;/&le; or &gt;/&ge; queries)
-   * by setting the min or max value to <code>null</code>. By setting inclusive to false, it will
-   * match all documents excluding the bounds, with inclusive on, the boundaries are hits, too.
-   */
-  public static NumericRangeQuery<Integer> newIntRange(final String field, final int precisionStep,
-    Integer min, Integer max, final boolean minInclusive, final boolean maxInclusive
-  ) {
-    return new NumericRangeQuery<>(field, precisionStep, NumericType.INT, min, max, minInclusive, maxInclusive);
-  }
-  
-  /**
-   * Factory that creates a <code>NumericRangeQuery</code>, that queries a <code>int</code>
-   * range using the default <code>precisionStep</code> {@link NumericUtils#PRECISION_STEP_DEFAULT_32} (8).
-   * You can have half-open ranges (which are in fact &lt;/&le; or &gt;/&ge; queries)
-   * by setting the min or max value to <code>null</code>. By setting inclusive to false, it will
-   * match all documents excluding the bounds, with inclusive on, the boundaries are hits, too.
-   */
-  public static NumericRangeQuery<Integer> newIntRange(final String field,
-    Integer min, Integer max, final boolean minInclusive, final boolean maxInclusive
-  ) {
-    return new NumericRangeQuery<>(field, NumericUtils.PRECISION_STEP_DEFAULT_32, NumericType.INT, min, max, minInclusive, maxInclusive);
-  }
-  
-  /**
-   * Factory that creates a <code>NumericRangeQuery</code>, that queries a <code>double</code>
-   * range using the given <a href="#precisionStepDesc"><code>precisionStep</code></a>.
-   * You can have half-open ranges (which are in fact &lt;/&le; or &gt;/&ge; queries)
-   * by setting the min or max value to <code>null</code>.
-   * {@link Double#NaN} will never match a half-open range, to hit {@code NaN} use a query
-   * with {@code min == max == Double.NaN}.  By setting inclusive to false, it will
-   * match all documents excluding the bounds, with inclusive on, the boundaries are hits, too.
-   */
-  public static NumericRangeQuery<Double> newDoubleRange(final String field, final int precisionStep,
-    Double min, Double max, final boolean minInclusive, final boolean maxInclusive
-  ) {
-    return new NumericRangeQuery<>(field, precisionStep, NumericType.DOUBLE, min, max, minInclusive, maxInclusive);
-  }
-  
-  /**
-   * Factory that creates a <code>NumericRangeQuery</code>, that queries a <code>double</code>
-   * range using the default <code>precisionStep</code> {@link NumericUtils#PRECISION_STEP_DEFAULT} (16).
-   * You can have half-open ranges (which are in fact &lt;/&le; or &gt;/&ge; queries)
-   * by setting the min or max value to <code>null</code>.
-   * {@link Double#NaN} will never match a half-open range, to hit {@code NaN} use a query
-   * with {@code min == max == Double.NaN}.  By setting inclusive to false, it will
-   * match all documents excluding the bounds, with inclusive on, the boundaries are hits, too.
-   */
-  public static NumericRangeQuery<Double> newDoubleRange(final String field,
-    Double min, Double max, final boolean minInclusive, final boolean maxInclusive
-  ) {
-    return new NumericRangeQuery<>(field, NumericUtils.PRECISION_STEP_DEFAULT, NumericType.DOUBLE, min, max, minInclusive, maxInclusive);
-  }
-  
-  /**
-   * Factory that creates a <code>NumericRangeQuery</code>, that queries a <code>float</code>
-   * range using the given <a href="#precisionStepDesc"><code>precisionStep</code></a>.
-   * You can have half-open ranges (which are in fact &lt;/&le; or &gt;/&ge; queries)
-   * by setting the min or max value to <code>null</code>.
-   * {@link Float#NaN} will never match a half-open range, to hit {@code NaN} use a query
-   * with {@code min == max == Float.NaN}.  By setting inclusive to false, it will
-   * match all documents excluding the bounds, with inclusive on, the boundaries are hits, too.
-   */
-  public static NumericRangeQuery<Float> newFloatRange(final String field, final int precisionStep,
-    Float min, Float max, final boolean minInclusive, final boolean maxInclusive
-  ) {
-    return new NumericRangeQuery<>(field, precisionStep, NumericType.FLOAT, min, max, minInclusive, maxInclusive);
-  }
-  
-  /**
-   * Factory that creates a <code>NumericRangeQuery</code>, that queries a <code>float</code>
-   * range using the default <code>precisionStep</code> {@link NumericUtils#PRECISION_STEP_DEFAULT_32} (8).
-   * You can have half-open ranges (which are in fact &lt;/&le; or &gt;/&ge; queries)
-   * by setting the min or max value to <code>null</code>.
-   * {@link Float#NaN} will never match a half-open range, to hit {@code NaN} use a query
-   * with {@code min == max == Float.NaN}.  By setting inclusive to false, it will
-   * match all documents excluding the bounds, with inclusive on, the boundaries are hits, too.
-   */
-  public static NumericRangeQuery<Float> newFloatRange(final String field,
-    Float min, Float max, final boolean minInclusive, final boolean maxInclusive
-  ) {
-    return new NumericRangeQuery<>(field, NumericUtils.PRECISION_STEP_DEFAULT_32, NumericType.FLOAT, min, max, minInclusive, maxInclusive);
-  }
-
-  @Override @SuppressWarnings("unchecked")
-  protected TermsEnum getTermsEnum(final Terms terms, AttributeSource atts) throws IOException {
-    // very strange: java.lang.Number itself is not Comparable, but all subclasses used here are
-    if (min != null && max != null && ((Comparable<T>) min).compareTo(max) > 0) {
-      return TermsEnum.EMPTY;
-    }
-    return new NumericRangeTermsEnum(terms.iterator());
-  }
-
-  /** Returns <code>true</code> if the lower endpoint is inclusive */
-  public boolean includesMin() { return minInclusive; }
-  
-  /** Returns <code>true</code> if the upper endpoint is inclusive */
-  public boolean includesMax() { return maxInclusive; }
-
-  /** Returns the lower value of this range query */
-  public T getMin() { return min; }
-
-  /** Returns the upper value of this range query */
-  public T getMax() { return max; }
-  
-  /** Returns the precision step. */
-  public int getPrecisionStep() { return precisionStep; }
-  
-  @Override
-  public String toString(final String field) {
-    final StringBuilder sb = new StringBuilder();
-    if (!getField().equals(field)) sb.append(getField()).append(':');
-    return sb.append(minInclusive ? '[' : '{')
-      .append((min == null) ? "*" : min.toString())
-      .append(" TO ")
-      .append((max == null) ? "*" : max.toString())
-      .append(maxInclusive ? ']' : '}')
-      .toString();
-  }
-
-  @Override
-  @SuppressWarnings({"unchecked","rawtypes"})
-  public final boolean equals(final Object o) {
-    if (o==this) return true;
-    if (!super.equals(o))
-      return false;
-    if (o instanceof NumericRangeQuery) {
-      final NumericRangeQuery q=(NumericRangeQuery)o;
-      return (
-        (q.min == null ? min == null : q.min.equals(min)) &&
-        (q.max == null ? max == null : q.max.equals(max)) &&
-        minInclusive == q.minInclusive &&
-        maxInclusive == q.maxInclusive &&
-        precisionStep == q.precisionStep
-      );
-    }
-    return false;
-  }
-
-  @Override
-  public final int hashCode() {
-    int hash = super.hashCode();
-    hash += precisionStep^0x64365465;
-    if (min != null) hash += min.hashCode()^0x14fa55fb;
-    if (max != null) hash += max.hashCode()^0x733fa5fe;
-    return hash +
-      (Boolean.valueOf(minInclusive).hashCode()^0x14fa55fb)+
-      (Boolean.valueOf(maxInclusive).hashCode()^0x733fa5fe);
-  }
-
-  // members (package private, to be also fast accessible by NumericRangeTermEnum)
-  final int precisionStep;
-  final NumericType dataType;
-  final T min, max;
-  final boolean minInclusive,maxInclusive;
-
-  // used to handle float/double infinity correcty
-  static final long LONG_NEGATIVE_INFINITY =
-    NumericUtils.doubleToSortableLong(Double.NEGATIVE_INFINITY);
-  static final long LONG_POSITIVE_INFINITY =
-    NumericUtils.doubleToSortableLong(Double.POSITIVE_INFINITY);
-  static final int INT_NEGATIVE_INFINITY =
-    NumericUtils.floatToSortableInt(Float.NEGATIVE_INFINITY);
-  static final int INT_POSITIVE_INFINITY =
-    NumericUtils.floatToSortableInt(Float.POSITIVE_INFINITY);
-
-  /**
-   * Subclass of FilteredTermsEnum for enumerating all terms that match the
-   * sub-ranges for trie range queries, using flex API.
-   * <p>
-   * WARNING: This term enumeration is not guaranteed to be always ordered by
-   * {@link Term#compareTo}.
-   * The ordering depends on how {@link NumericUtils#splitLongRange} and
-   * {@link NumericUtils#splitIntRange} generates the sub-ranges. For
-   * {@link MultiTermQuery} ordering is not relevant.
-   */
-  private final class NumericRangeTermsEnum extends FilteredTermsEnum {
-
-    private BytesRef currentLowerBound, currentUpperBound;
-
-    private final LinkedList<BytesRef> rangeBounds = new LinkedList<>();
-
-    NumericRangeTermsEnum(final TermsEnum tenum) {
-      super(tenum);
-      switch (dataType) {
-        case LONG:
-        case DOUBLE: {
-          // lower
-          long minBound;
-          if (dataType == NumericType.LONG) {
-            minBound = (min == null) ? Long.MIN_VALUE : min.longValue();
-          } else {
-            assert dataType == NumericType.DOUBLE;
-            minBound = (min == null) ? LONG_NEGATIVE_INFINITY
-              : NumericUtils.doubleToSortableLong(min.doubleValue());
-          }
-          if (!minInclusive && min != null) {
-            if (minBound == Long.MAX_VALUE) break;
-            minBound++;
-          }
-          
-          // upper
-          long maxBound;
-          if (dataType == NumericType.LONG) {
-            maxBound = (max == null) ? Long.MAX_VALUE : max.longValue();
-          } else {
-            assert dataType == NumericType.DOUBLE;
-            maxBound = (max == null) ? LONG_POSITIVE_INFINITY
-              : NumericUtils.doubleToSortableLong(max.doubleValue());
-          }
-          if (!maxInclusive && max != null) {
-            if (maxBound == Long.MIN_VALUE) break;
-            maxBound--;
-          }
-          
-          NumericUtils.splitLongRange(new NumericUtils.LongRangeBuilder() {
-            @Override
-            public final void addRange(BytesRef minPrefixCoded, BytesRef maxPrefixCoded) {
-              rangeBounds.add(minPrefixCoded);
-              rangeBounds.add(maxPrefixCoded);
-            }
-          }, precisionStep, minBound, maxBound);
-          break;
-        }
-          
-        case INT:
-        case FLOAT: {
-          // lower
-          int minBound;
-          if (dataType == NumericType.INT) {
-            minBound = (min == null) ? Integer.MIN_VALUE : min.intValue();
-          } else {
-            assert dataType == NumericType.FLOAT;
-            minBound = (min == null) ? INT_NEGATIVE_INFINITY
-              : NumericUtils.floatToSortableInt(min.floatValue());
-          }
-          if (!minInclusive && min != null) {
-            if (minBound == Integer.MAX_VALUE) break;
-            minBound++;
-          }
-          
-          // upper
-          int maxBound;
-          if (dataType == NumericType.INT) {
-            maxBound = (max == null) ? Integer.MAX_VALUE : max.intValue();
-          } else {
-            assert dataType == NumericType.FLOAT;
-            maxBound = (max == null) ? INT_POSITIVE_INFINITY
-              : NumericUtils.floatToSortableInt(max.floatValue());
-          }
-          if (!maxInclusive && max != null) {
-            if (maxBound == Integer.MIN_VALUE) break;
-            maxBound--;
-          }
-          
-          NumericUtils.splitIntRange(new NumericUtils.IntRangeBuilder() {
-            @Override
-            public final void addRange(BytesRef minPrefixCoded, BytesRef maxPrefixCoded) {
-              rangeBounds.add(minPrefixCoded);
-              rangeBounds.add(maxPrefixCoded);
-            }
-          }, precisionStep, minBound, maxBound);
-          break;
-        }
-          
-        default:
-          // should never happen
-          throw new IllegalArgumentException("Invalid NumericType");
-      }
-    }
-    
-    private void nextRange() {
-      assert rangeBounds.size() % 2 == 0;
-
-      currentLowerBound = rangeBounds.removeFirst();
-      assert currentUpperBound == null || currentUpperBound.compareTo(currentLowerBound) <= 0 :
-        "The current upper bound must be <= the new lower bound";
-      
-      currentUpperBound = rangeBounds.removeFirst();
-    }
-    
-    @Override
-    protected final BytesRef nextSeekTerm(BytesRef term) {
-      while (rangeBounds.size() >= 2) {
-        nextRange();
-        
-        // if the new upper bound is before the term parameter, the sub-range is never a hit
-        if (term != null && term.compareTo(currentUpperBound) > 0)
-          continue;
-        // never seek backwards, so use current term if lower bound is smaller
-        return (term != null && term.compareTo(currentLowerBound) > 0) ?
-          term : currentLowerBound;
-      }
-      
-      // no more sub-range enums available
-      assert rangeBounds.isEmpty();
-      currentLowerBound = currentUpperBound = null;
-      return null;
-    }
-    
-    @Override
-    protected final AcceptStatus accept(BytesRef term) {
-      while (currentUpperBound == null || term.compareTo(currentUpperBound) > 0) {
-        if (rangeBounds.isEmpty())
-          return AcceptStatus.END;
-        // peek next sub-range, only seek if the current term is smaller than next lower bound
-        if (term.compareTo(rangeBounds.getFirst()) < 0)
-          return AcceptStatus.NO_AND_SEEK;
-        // step forward to next range without seeking, as next lower range bound is less or equal current term
-        nextRange();
-      }
-      return AcceptStatus.YES;
-    }
-
-  }
-  
-}
diff --git a/lucene/core/src/java/org/apache/lucene/search/Query.java b/lucene/core/src/java/org/apache/lucene/search/Query.java
index bf5a573..09db16a 100644
--- a/lucene/core/src/java/org/apache/lucene/search/Query.java
+++ b/lucene/core/src/java/org/apache/lucene/search/Query.java
@@ -33,7 +33,7 @@ import org.apache.lucene.index.IndexReader;
     <li> {@link FuzzyQuery}
     <li> {@link RegexpQuery}
     <li> {@link TermRangeQuery}
-    <li> {@link NumericRangeQuery}
+    <li> {@link DimensionalRangeQuery}
     <li> {@link ConstantScoreQuery}
     <li> {@link DisjunctionMaxQuery}
     <li> {@link MatchAllDocsQuery}
diff --git a/lucene/core/src/java/org/apache/lucene/search/SortedNumericSelector.java b/lucene/core/src/java/org/apache/lucene/search/SortedNumericSelector.java
index e3f275a..b2bc0cd 100644
--- a/lucene/core/src/java/org/apache/lucene/search/SortedNumericSelector.java
+++ b/lucene/core/src/java/org/apache/lucene/search/SortedNumericSelector.java
@@ -20,7 +20,7 @@ package org.apache.lucene.search;
 import org.apache.lucene.index.DocValues;
 import org.apache.lucene.index.NumericDocValues;
 import org.apache.lucene.index.SortedNumericDocValues;
-import org.apache.lucene.util.NumericUtils;
+import org.apache.lucene.util.LegacyNumericUtils;
 
 /** 
  * Selects a value from the document's list to use as the representative value 
@@ -81,14 +81,14 @@ public class SortedNumericSelector {
         return new NumericDocValues() {
           @Override
           public long get(int docID) {
-            return NumericUtils.sortableFloatBits((int) view.get(docID));
+            return LegacyNumericUtils.sortableFloatBits((int) view.get(docID));
           }
         };
       case DOUBLE:
         return new NumericDocValues() {
           @Override
           public long get(int docID) {
-            return NumericUtils.sortableDoubleBits(view.get(docID));
+            return LegacyNumericUtils.sortableDoubleBits(view.get(docID));
           }
         };
       default:
diff --git a/lucene/core/src/java/org/apache/lucene/search/UsageTrackingQueryCachingPolicy.java b/lucene/core/src/java/org/apache/lucene/search/UsageTrackingQueryCachingPolicy.java
index c6bd687..3c5e997 100644
--- a/lucene/core/src/java/org/apache/lucene/search/UsageTrackingQueryCachingPolicy.java
+++ b/lucene/core/src/java/org/apache/lucene/search/UsageTrackingQueryCachingPolicy.java
@@ -22,7 +22,6 @@ import java.io.IOException;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.util.FrequencyTrackingRingBuffer;
 
-
 /**
  * A {@link QueryCachingPolicy} that tracks usage statistics of recently-used
  * filters in order to decide on which filters are worth caching.
@@ -43,7 +42,8 @@ public final class UsageTrackingQueryCachingPolicy implements QueryCachingPolicy
     // already have the DocIdSetIterator#cost API) but the cost to build the
     // DocIdSet in the first place
     return query instanceof MultiTermQuery ||
-        query instanceof MultiTermQueryConstantScoreWrapper;
+        query instanceof MultiTermQueryConstantScoreWrapper ||
+        query instanceof DimensionalRangeQuery;
   }
 
   static boolean isCheap(Query query) {
diff --git a/lucene/core/src/java/org/apache/lucene/search/package-info.java b/lucene/core/src/java/org/apache/lucene/search/package-info.java
index 02ca3b8..efaeca6 100644
--- a/lucene/core/src/java/org/apache/lucene/search/package-info.java
+++ b/lucene/core/src/java/org/apache/lucene/search/package-info.java
@@ -160,22 +160,22 @@
  *     and an upper
  *     {@link org.apache.lucene.index.Term Term}
  *     according to {@link org.apache.lucene.util.BytesRef#compareTo BytesRef.compareTo()}. It is not intended
- *     for numerical ranges; use {@link org.apache.lucene.search.NumericRangeQuery NumericRangeQuery} instead.
+ *     for numerical ranges; use {@link org.apache.lucene.search.DimensionalRangeQuery DimensionalRangeQuery} instead.
  * 
  *     For example, one could find all documents
  *     that have terms beginning with the letters <tt>a</tt> through <tt>c</tt>.
  * 
  * <h3>
- *     {@link org.apache.lucene.search.NumericRangeQuery NumericRangeQuery}
+ *     {@link org.apache.lucene.search.DimensionalRangeQuery DimensionalRangeQuery}
  * </h3>
  * 
  * <p>The
- *     {@link org.apache.lucene.search.NumericRangeQuery NumericRangeQuery}
+ *     {@link org.apache.lucene.search.DimensionalRangeQuery DimensionalRangeQuery}
  *     matches all documents that occur in a numeric range.
- *     For NumericRangeQuery to work, you must index the values
- *     using a one of the numeric fields ({@link org.apache.lucene.document.IntField IntField},
- *     {@link org.apache.lucene.document.LongField LongField}, {@link org.apache.lucene.document.FloatField FloatField},
- *     or {@link org.apache.lucene.document.DoubleField DoubleField}).
+ *     For DimensionalRangeQuery to work, you must index the values
+ *     using a one of the numeric fields ({@link org.apache.lucene.document.DimensionalIntField DimensionalIntField},
+ *     {@link org.apache.lucene.document.DimensionalLongField DimensionalLongField}, {@link org.apache.lucene.document.DimensionalFloatField DimensionalFloatField},
+ *     or {@link org.apache.lucene.document.DimensionalDoubleField DimensionalDoubleField}).
  * 
  * <h3>
  *     {@link org.apache.lucene.search.PrefixQuery PrefixQuery},
diff --git a/lucene/core/src/java/org/apache/lucene/util/LegacyNumericUtils.java b/lucene/core/src/java/org/apache/lucene/util/LegacyNumericUtils.java
new file mode 100644
index 0000000..e367082
--- /dev/null
+++ b/lucene/core/src/java/org/apache/lucene/util/LegacyNumericUtils.java
@@ -0,0 +1,597 @@
+package org.apache.lucene.util;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.index.DimensionalValues;
+import org.apache.lucene.index.FilterLeafReader;
+import org.apache.lucene.index.FilteredTermsEnum;
+import org.apache.lucene.index.Terms;
+import org.apache.lucene.index.TermsEnum;
+
+/**
+ * This is a helper class to generate prefix-encoded representations for numerical values
+ * and supplies converters to represent float/double values as sortable integers/longs.
+ *
+ * <p>To quickly execute range queries in Apache Lucene, a range is divided recursively
+ * into multiple intervals for searching: The center of the range is searched only with
+ * the lowest possible precision in the trie, while the boundaries are matched
+ * more exactly. This reduces the number of terms dramatically.
+ *
+ * <p>This class generates terms to achieve this: First the numerical integer values need to
+ * be converted to bytes. For that integer values (32 bit or 64 bit) are made unsigned
+ * and the bits are converted to ASCII chars with each 7 bit. The resulting byte[] is
+ * sortable like the original integer value (even using UTF-8 sort order). Each value is also
+ * prefixed (in the first char) by the <code>shift</code> value (number of bits removed) used
+ * during encoding.
+ *
+ * <p>To also index floating point numbers, this class supplies two methods to convert them
+ * to integer values by changing their bit layout: {@link #doubleToSortableLong},
+ * {@link #floatToSortableInt}. You will have no precision loss by
+ * converting floating point numbers to integers and back (only that the integer form
+ * is not usable). Other data types like dates can easily converted to longs or ints (e.g.
+ * date to long: {@link java.util.Date#getTime}).
+ *
+ * <p>For easy usage, the trie algorithm is implemented for indexing inside
+ * {@link org.apache.lucene.analysis.LegacyNumericTokenStream} that can index <code>int</code>, <code>long</code>,
+ * <code>float</code>, and <code>double</code>. For querying,
+ * {@link org.apache.lucene.search.LegacyNumericRangeQuery} implements the query part
+ * for the same data types.
+ *
+ * <p>This class can also be used, to generate lexicographically sortable (according to
+ * {@link BytesRef#getUTF8SortedAsUTF16Comparator()}) representations of numeric data
+ * types for other usages (e.g. sorting).
+ *
+ * @lucene.internal
+ *
+ * @deprecated Please use {@link DimensionalValues} instead.
+ *
+ * @since 2.9, API changed non backwards-compliant in 4.0
+ */
+
+@Deprecated
+public final class LegacyNumericUtils {
+
+  private LegacyNumericUtils() {} // no instance!
+  
+  /**
+   * The default precision step used by {@link org.apache.lucene.document.LegacyLongField},
+   * {@link org.apache.lucene.document.LegacyDoubleField}, {@link org.apache.lucene.analysis.LegacyNumericTokenStream}, {@link
+   * org.apache.lucene.search.LegacyNumericRangeQuery}.
+   */
+  public static final int PRECISION_STEP_DEFAULT = 16;
+  
+  /**
+   * The default precision step used by {@link org.apache.lucene.document.LegacyIntField} and
+   * {@link org.apache.lucene.document.LegacyFloatField}.
+   */
+  public static final int PRECISION_STEP_DEFAULT_32 = 8;
+  
+  /**
+   * Longs are stored at lower precision by shifting off lower bits. The shift count is
+   * stored as <code>SHIFT_START_LONG+shift</code> in the first byte
+   */
+  public static final byte SHIFT_START_LONG = 0x20;
+
+  /**
+   * The maximum term length (used for <code>byte[]</code> buffer size)
+   * for encoding <code>long</code> values.
+   * @see #longToPrefixCodedBytes
+   */
+  public static final int BUF_SIZE_LONG = 63/7 + 2;
+
+  /**
+   * Integers are stored at lower precision by shifting off lower bits. The shift count is
+   * stored as <code>SHIFT_START_INT+shift</code> in the first byte
+   */
+  public static final byte SHIFT_START_INT  = 0x60;
+
+  /**
+   * The maximum term length (used for <code>byte[]</code> buffer size)
+   * for encoding <code>int</code> values.
+   * @see #intToPrefixCodedBytes
+   */
+  public static final int BUF_SIZE_INT = 31/7 + 2;
+
+  /**
+   * Returns prefix coded bits after reducing the precision by <code>shift</code> bits.
+   * This is method is used by {@link org.apache.lucene.analysis.LegacyNumericTokenStream}.
+   * After encoding, {@code bytes.offset} will always be 0. 
+   * @param val the numeric value
+   * @param shift how many bits to strip from the right
+   * @param bytes will contain the encoded value
+   */
+  public static void longToPrefixCoded(final long val, final int shift, final BytesRefBuilder bytes) {
+    longToPrefixCodedBytes(val, shift, bytes);
+  }
+
+  /**
+   * Returns prefix coded bits after reducing the precision by <code>shift</code> bits.
+   * This is method is used by {@link org.apache.lucene.analysis.LegacyNumericTokenStream}.
+   * After encoding, {@code bytes.offset} will always be 0.
+   * @param val the numeric value
+   * @param shift how many bits to strip from the right
+   * @param bytes will contain the encoded value
+   */
+  public static void intToPrefixCoded(final int val, final int shift, final BytesRefBuilder bytes) {
+    intToPrefixCodedBytes(val, shift, bytes);
+  }
+
+  /**
+   * Returns prefix coded bits after reducing the precision by <code>shift</code> bits.
+   * This is method is used by {@link org.apache.lucene.analysis.LegacyNumericTokenStream}.
+   * After encoding, {@code bytes.offset} will always be 0.
+   * @param val the numeric value
+   * @param shift how many bits to strip from the right
+   * @param bytes will contain the encoded value
+   */
+  public static void longToPrefixCodedBytes(final long val, final int shift, final BytesRefBuilder bytes) {
+    // ensure shift is 0..63
+    if ((shift & ~0x3f) != 0) {
+      throw new IllegalArgumentException("Illegal shift value, must be 0..63; got shift=" + shift);
+    }
+    int nChars = (((63-shift)*37)>>8) + 1;    // i/7 is the same as (i*37)>>8 for i in 0..63
+    bytes.setLength(nChars+1);   // one extra for the byte that contains the shift info
+    bytes.grow(BUF_SIZE_LONG);
+    bytes.setByteAt(0, (byte)(SHIFT_START_LONG + shift));
+    long sortableBits = val ^ 0x8000000000000000L;
+    sortableBits >>>= shift;
+    while (nChars > 0) {
+      // Store 7 bits per byte for compatibility
+      // with UTF-8 encoding of terms
+      bytes.setByteAt(nChars--, (byte)(sortableBits & 0x7f));
+      sortableBits >>>= 7;
+    }
+  }
+
+
+  /**
+   * Returns prefix coded bits after reducing the precision by <code>shift</code> bits.
+   * This is method is used by {@link org.apache.lucene.analysis.LegacyNumericTokenStream}.
+   * After encoding, {@code bytes.offset} will always be 0. 
+   * @param val the numeric value
+   * @param shift how many bits to strip from the right
+   * @param bytes will contain the encoded value
+   */
+  public static void intToPrefixCodedBytes(final int val, final int shift, final BytesRefBuilder bytes) {
+    // ensure shift is 0..31
+    if ((shift & ~0x1f) != 0) {
+      throw new IllegalArgumentException("Illegal shift value, must be 0..31; got shift=" + shift);
+    }
+    int nChars = (((31-shift)*37)>>8) + 1;    // i/7 is the same as (i*37)>>8 for i in 0..63
+    bytes.setLength(nChars+1);   // one extra for the byte that contains the shift info
+    bytes.grow(LegacyNumericUtils.BUF_SIZE_LONG);  // use the max
+    bytes.setByteAt(0, (byte)(SHIFT_START_INT + shift));
+    int sortableBits = val ^ 0x80000000;
+    sortableBits >>>= shift;
+    while (nChars > 0) {
+      // Store 7 bits per byte for compatibility
+      // with UTF-8 encoding of terms
+      bytes.setByteAt(nChars--, (byte)(sortableBits & 0x7f));
+      sortableBits >>>= 7;
+    }
+  }
+
+
+  /**
+   * Returns the shift value from a prefix encoded {@code long}.
+   * @throws NumberFormatException if the supplied {@link BytesRef} is
+   * not correctly prefix encoded.
+   */
+  public static int getPrefixCodedLongShift(final BytesRef val) {
+    final int shift = val.bytes[val.offset] - SHIFT_START_LONG;
+    if (shift > 63 || shift < 0)
+      throw new NumberFormatException("Invalid shift value (" + shift + ") in prefixCoded bytes (is encoded value really an INT?)");
+    return shift;
+  }
+
+  /**
+   * Returns the shift value from a prefix encoded {@code int}.
+   * @throws NumberFormatException if the supplied {@link BytesRef} is
+   * not correctly prefix encoded.
+   */
+  public static int getPrefixCodedIntShift(final BytesRef val) {
+    final int shift = val.bytes[val.offset] - SHIFT_START_INT;
+    if (shift > 31 || shift < 0)
+      throw new NumberFormatException("Invalid shift value in prefixCoded bytes (is encoded value really an INT?)");
+    return shift;
+  }
+
+  /**
+   * Returns a long from prefixCoded bytes.
+   * Rightmost bits will be zero for lower precision codes.
+   * This method can be used to decode a term's value.
+   * @throws NumberFormatException if the supplied {@link BytesRef} is
+   * not correctly prefix encoded.
+   * @see #longToPrefixCodedBytes
+   */
+  public static long prefixCodedToLong(final BytesRef val) {
+    long sortableBits = 0L;
+    for (int i=val.offset+1, limit=val.offset+val.length; i<limit; i++) {
+      sortableBits <<= 7;
+      final byte b = val.bytes[i];
+      if (b < 0) {
+        throw new NumberFormatException(
+          "Invalid prefixCoded numerical value representation (byte "+
+          Integer.toHexString(b&0xff)+" at position "+(i-val.offset)+" is invalid)"
+        );
+      }
+      sortableBits |= b;
+    }
+    return (sortableBits << getPrefixCodedLongShift(val)) ^ 0x8000000000000000L;
+  }
+
+  /**
+   * Returns an int from prefixCoded bytes.
+   * Rightmost bits will be zero for lower precision codes.
+   * This method can be used to decode a term's value.
+   * @throws NumberFormatException if the supplied {@link BytesRef} is
+   * not correctly prefix encoded.
+   * @see #intToPrefixCodedBytes
+   */
+  public static int prefixCodedToInt(final BytesRef val) {
+    int sortableBits = 0;
+    for (int i=val.offset+1, limit=val.offset+val.length; i<limit; i++) {
+      sortableBits <<= 7;
+      final byte b = val.bytes[i];
+      if (b < 0) {
+        throw new NumberFormatException(
+          "Invalid prefixCoded numerical value representation (byte "+
+          Integer.toHexString(b&0xff)+" at position "+(i-val.offset)+" is invalid)"
+        );
+      }
+      sortableBits |= b;
+    }
+    return (sortableBits << getPrefixCodedIntShift(val)) ^ 0x80000000;
+  }
+
+  /**
+   * Converts a <code>double</code> value to a sortable signed <code>long</code>.
+   * The value is converted by getting their IEEE 754 floating-point &quot;double format&quot;
+   * bit layout and then some bits are swapped, to be able to compare the result as long.
+   * By this the precision is not reduced, but the value can easily used as a long.
+   * The sort order (including {@link Double#NaN}) is defined by
+   * {@link Double#compareTo}; {@code NaN} is greater than positive infinity.
+   * @see #sortableLongToDouble
+   */
+  public static long doubleToSortableLong(double val) {
+    return sortableDoubleBits(Double.doubleToLongBits(val));
+  }
+
+  /**
+   * Converts a sortable <code>long</code> back to a <code>double</code>.
+   * @see #doubleToSortableLong
+   */
+  public static double sortableLongToDouble(long val) {
+    return Double.longBitsToDouble(sortableDoubleBits(val));
+  }
+
+  /**
+   * Converts a <code>float</code> value to a sortable signed <code>int</code>.
+   * The value is converted by getting their IEEE 754 floating-point &quot;float format&quot;
+   * bit layout and then some bits are swapped, to be able to compare the result as int.
+   * By this the precision is not reduced, but the value can easily used as an int.
+   * The sort order (including {@link Float#NaN}) is defined by
+   * {@link Float#compareTo}; {@code NaN} is greater than positive infinity.
+   * @see #sortableIntToFloat
+   */
+  public static int floatToSortableInt(float val) {
+    return sortableFloatBits(Float.floatToIntBits(val));
+  }
+
+  /**
+   * Converts a sortable <code>int</code> back to a <code>float</code>.
+   * @see #floatToSortableInt
+   */
+  public static float sortableIntToFloat(int val) {
+    return Float.intBitsToFloat(sortableFloatBits(val));
+  }
+  
+  /** Converts IEEE 754 representation of a double to sortable order (or back to the original) */
+  public static long sortableDoubleBits(long bits) {
+    return bits ^ (bits >> 63) & 0x7fffffffffffffffL;
+  }
+  
+  /** Converts IEEE 754 representation of a float to sortable order (or back to the original) */
+  public static int sortableFloatBits(int bits) {
+    return bits ^ (bits >> 31) & 0x7fffffff;
+  }
+
+  /**
+   * Splits a long range recursively.
+   * You may implement a builder that adds clauses to a
+   * {@link org.apache.lucene.search.BooleanQuery} for each call to its
+   * {@link LongRangeBuilder#addRange(BytesRef,BytesRef)}
+   * method.
+   * <p>This method is used by {@link org.apache.lucene.search.LegacyNumericRangeQuery}.
+   */
+  public static void splitLongRange(final LongRangeBuilder builder,
+    final int precisionStep,  final long minBound, final long maxBound
+  ) {
+    splitRange(builder, 64, precisionStep, minBound, maxBound);
+  }
+  
+  /**
+   * Splits an int range recursively.
+   * You may implement a builder that adds clauses to a
+   * {@link org.apache.lucene.search.BooleanQuery} for each call to its
+   * {@link IntRangeBuilder#addRange(BytesRef,BytesRef)}
+   * method.
+   * <p>This method is used by {@link org.apache.lucene.search.LegacyNumericRangeQuery}.
+   */
+  public static void splitIntRange(final IntRangeBuilder builder,
+    final int precisionStep,  final int minBound, final int maxBound
+  ) {
+    splitRange(builder, 32, precisionStep, minBound, maxBound);
+  }
+  
+  /** This helper does the splitting for both 32 and 64 bit. */
+  private static void splitRange(
+    final Object builder, final int valSize,
+    final int precisionStep, long minBound, long maxBound
+  ) {
+    if (precisionStep < 1)
+      throw new IllegalArgumentException("precisionStep must be >=1");
+    if (minBound > maxBound) return;
+    for (int shift=0; ; shift += precisionStep) {
+      // calculate new bounds for inner precision
+      final long diff = 1L << (shift+precisionStep),
+        mask = ((1L<<precisionStep) - 1L) << shift;
+      final boolean
+        hasLower = (minBound & mask) != 0L,
+        hasUpper = (maxBound & mask) != mask;
+      final long
+        nextMinBound = (hasLower ? (minBound + diff) : minBound) & ~mask,
+        nextMaxBound = (hasUpper ? (maxBound - diff) : maxBound) & ~mask;
+      final boolean
+        lowerWrapped = nextMinBound < minBound,
+        upperWrapped = nextMaxBound > maxBound;
+      
+      if (shift+precisionStep>=valSize || nextMinBound>nextMaxBound || lowerWrapped || upperWrapped) {
+        // We are in the lowest precision or the next precision is not available.
+        addRange(builder, valSize, minBound, maxBound, shift);
+        // exit the split recursion loop
+        break;
+      }
+      
+      if (hasLower)
+        addRange(builder, valSize, minBound, minBound | mask, shift);
+      if (hasUpper)
+        addRange(builder, valSize, maxBound & ~mask, maxBound, shift);
+      
+      // recurse to next precision
+      minBound = nextMinBound;
+      maxBound = nextMaxBound;
+    }
+  }
+  
+  /** Helper that delegates to correct range builder */
+  private static void addRange(
+    final Object builder, final int valSize,
+    long minBound, long maxBound,
+    final int shift
+  ) {
+    // for the max bound set all lower bits (that were shifted away):
+    // this is important for testing or other usages of the splitted range
+    // (e.g. to reconstruct the full range). The prefixEncoding will remove
+    // the bits anyway, so they do not hurt!
+    maxBound |= (1L << shift) - 1L;
+    // delegate to correct range builder
+    switch(valSize) {
+      case 64:
+        ((LongRangeBuilder)builder).addRange(minBound, maxBound, shift);
+        break;
+      case 32:
+        ((IntRangeBuilder)builder).addRange((int)minBound, (int)maxBound, shift);
+        break;
+      default:
+        // Should not happen!
+        throw new IllegalArgumentException("valSize must be 32 or 64.");
+    }
+  }
+
+  /**
+   * Callback for {@link #splitLongRange}.
+   * You need to overwrite only one of the methods.
+   * @lucene.internal
+   * @since 2.9, API changed non backwards-compliant in 4.0
+   */
+  public static abstract class LongRangeBuilder {
+    
+    /**
+     * Overwrite this method, if you like to receive the already prefix encoded range bounds.
+     * You can directly build classical (inclusive) range queries from them.
+     */
+    public void addRange(BytesRef minPrefixCoded, BytesRef maxPrefixCoded) {
+      throw new UnsupportedOperationException();
+    }
+    
+    /**
+     * Overwrite this method, if you like to receive the raw long range bounds.
+     * You can use this for e.g. debugging purposes (print out range bounds).
+     */
+    public void addRange(final long min, final long max, final int shift) {
+      final BytesRefBuilder minBytes = new BytesRefBuilder(), maxBytes = new BytesRefBuilder();
+      longToPrefixCodedBytes(min, shift, minBytes);
+      longToPrefixCodedBytes(max, shift, maxBytes);
+      addRange(minBytes.get(), maxBytes.get());
+    }
+  
+  }
+  
+  /**
+   * Callback for {@link #splitIntRange}.
+   * You need to overwrite only one of the methods.
+   * @lucene.internal
+   * @since 2.9, API changed non backwards-compliant in 4.0
+   */
+  public static abstract class IntRangeBuilder {
+    
+    /**
+     * Overwrite this method, if you like to receive the already prefix encoded range bounds.
+     * You can directly build classical range (inclusive) queries from them.
+     */
+    public void addRange(BytesRef minPrefixCoded, BytesRef maxPrefixCoded) {
+      throw new UnsupportedOperationException();
+    }
+    
+    /**
+     * Overwrite this method, if you like to receive the raw int range bounds.
+     * You can use this for e.g. debugging purposes (print out range bounds).
+     */
+    public void addRange(final int min, final int max, final int shift) {
+      final BytesRefBuilder minBytes = new BytesRefBuilder(), maxBytes = new BytesRefBuilder();
+      intToPrefixCodedBytes(min, shift, minBytes);
+      intToPrefixCodedBytes(max, shift, maxBytes);
+      addRange(minBytes.get(), maxBytes.get());
+    }
+  
+  }
+  
+  /**
+   * Filters the given {@link TermsEnum} by accepting only prefix coded 64 bit
+   * terms with a shift value of <tt>0</tt>.
+   * 
+   * @param termsEnum
+   *          the terms enum to filter
+   * @return a filtered {@link TermsEnum} that only returns prefix coded 64 bit
+   *         terms with a shift value of <tt>0</tt>.
+   */
+  public static TermsEnum filterPrefixCodedLongs(TermsEnum termsEnum) {
+    return new SeekingNumericFilteredTermsEnum(termsEnum) {
+
+      @Override
+      protected AcceptStatus accept(BytesRef term) {
+        return LegacyNumericUtils.getPrefixCodedLongShift(term) == 0 ? AcceptStatus.YES : AcceptStatus.END;
+      }
+    };
+  }
+
+  /**
+   * Filters the given {@link TermsEnum} by accepting only prefix coded 32 bit
+   * terms with a shift value of <tt>0</tt>.
+   * 
+   * @param termsEnum
+   *          the terms enum to filter
+   * @return a filtered {@link TermsEnum} that only returns prefix coded 32 bit
+   *         terms with a shift value of <tt>0</tt>.
+   */
+  public static TermsEnum filterPrefixCodedInts(TermsEnum termsEnum) {
+    return new SeekingNumericFilteredTermsEnum(termsEnum) {
+      
+      @Override
+      protected AcceptStatus accept(BytesRef term) {
+        return LegacyNumericUtils.getPrefixCodedIntShift(term) == 0 ? AcceptStatus.YES : AcceptStatus.END;
+      }
+    };
+  }
+
+  /** Just like FilteredTermsEnum, except it adds a limited
+   *  seekCeil implementation that only works with {@link
+   *  #filterPrefixCodedInts} and {@link
+   *  #filterPrefixCodedLongs}. */
+  private static abstract class SeekingNumericFilteredTermsEnum extends FilteredTermsEnum {
+    public SeekingNumericFilteredTermsEnum(final TermsEnum tenum) {
+      super(tenum, false);
+    }
+
+    @Override
+    @SuppressWarnings("fallthrough")
+    public SeekStatus seekCeil(BytesRef term) throws IOException {
+
+      // NOTE: This is not general!!  It only handles YES
+      // and END, because that's all we need for the numeric
+      // case here
+
+      SeekStatus status = tenum.seekCeil(term);
+      if (status == SeekStatus.END) {
+        return SeekStatus.END;
+      }
+
+      actualTerm = tenum.term();
+
+      if (accept(actualTerm) == AcceptStatus.YES) {
+        return status;
+      } else {
+        return SeekStatus.END;
+      }
+    }
+  }
+
+  private static Terms intTerms(Terms terms) {
+    return new FilterLeafReader.FilterTerms(terms) {
+        @Override
+        public TermsEnum iterator() throws IOException {
+          return filterPrefixCodedInts(in.iterator());
+        }
+      };
+  }
+
+  private static Terms longTerms(Terms terms) {
+    return new FilterLeafReader.FilterTerms(terms) {
+        @Override
+        public TermsEnum iterator() throws IOException {
+          return filterPrefixCodedLongs(in.iterator());
+        }
+      };
+  }
+    
+  /**
+   * Returns the minimum int value indexed into this
+   * numeric field or null if no terms exist.
+   */
+  public static Integer getMinInt(Terms terms) throws IOException {
+    // All shift=0 terms are sorted first, so we don't need
+    // to filter the incoming terms; we can just get the
+    // min:
+    BytesRef min = terms.getMin();
+    return (min != null) ? LegacyNumericUtils.prefixCodedToInt(min) : null;
+  }
+
+  /**
+   * Returns the maximum int value indexed into this
+   * numeric field or null if no terms exist.
+   */
+  public static Integer getMaxInt(Terms terms) throws IOException {
+    BytesRef max = intTerms(terms).getMax();
+    return (max != null) ? LegacyNumericUtils.prefixCodedToInt(max) : null;
+  }
+
+  /**
+   * Returns the minimum long value indexed into this
+   * numeric field or null if no terms exist.
+   */
+  public static Long getMinLong(Terms terms) throws IOException {
+    // All shift=0 terms are sorted first, so we don't need
+    // to filter the incoming terms; we can just get the
+    // min:
+    BytesRef min = terms.getMin();
+    return (min != null) ? LegacyNumericUtils.prefixCodedToLong(min) : null;
+  }
+
+  /**
+   * Returns the maximum long value indexed into this
+   * numeric field or null if no terms exist.
+   */
+  public static Long getMaxLong(Terms terms) throws IOException {
+    BytesRef max = longTerms(terms).getMax();
+    return (max != null) ? LegacyNumericUtils.prefixCodedToLong(max) : null;
+  }
+  
+}
diff --git a/lucene/core/src/java/org/apache/lucene/util/NumericUtils.java b/lucene/core/src/java/org/apache/lucene/util/NumericUtils.java
index 6579a66..6d1ab2d 100644
--- a/lucene/core/src/java/org/apache/lucene/util/NumericUtils.java
+++ b/lucene/core/src/java/org/apache/lucene/util/NumericUtils.java
@@ -17,251 +17,19 @@ package org.apache.lucene.util;
  * limitations under the License.
  */
 
-import java.io.IOException;
-
-import org.apache.lucene.analysis.NumericTokenStream;
-import org.apache.lucene.document.DoubleField; // javadocs
-import org.apache.lucene.document.FloatField; // javadocs
-import org.apache.lucene.document.IntField; // javadocs
-import org.apache.lucene.document.LongField; // javadocs
-import org.apache.lucene.index.FilterLeafReader;
-import org.apache.lucene.index.FilteredTermsEnum;
-import org.apache.lucene.index.Terms;
-import org.apache.lucene.index.TermsEnum;
-import org.apache.lucene.search.NumericRangeQuery; // for javadocs
+import java.math.BigInteger;
+import java.util.Arrays;
 
 /**
- * This is a helper class to generate prefix-encoded representations for numerical values
- * and supplies converters to represent float/double values as sortable integers/longs.
- *
- * <p>To quickly execute range queries in Apache Lucene, a range is divided recursively
- * into multiple intervals for searching: The center of the range is searched only with
- * the lowest possible precision in the trie, while the boundaries are matched
- * more exactly. This reduces the number of terms dramatically.
- *
- * <p>This class generates terms to achieve this: First the numerical integer values need to
- * be converted to bytes. For that integer values (32 bit or 64 bit) are made unsigned
- * and the bits are converted to ASCII chars with each 7 bit. The resulting byte[] is
- * sortable like the original integer value (even using UTF-8 sort order). Each value is also
- * prefixed (in the first char) by the <code>shift</code> value (number of bits removed) used
- * during encoding.
- *
- * <p>To also index floating point numbers, this class supplies two methods to convert them
- * to integer values by changing their bit layout: {@link #doubleToSortableLong},
- * {@link #floatToSortableInt}. You will have no precision loss by
- * converting floating point numbers to integers and back (only that the integer form
- * is not usable). Other data types like dates can easily converted to longs or ints (e.g.
- * date to long: {@link java.util.Date#getTime}).
- *
- * <p>For easy usage, the trie algorithm is implemented for indexing inside
- * {@link NumericTokenStream} that can index <code>int</code>, <code>long</code>,
- * <code>float</code>, and <code>double</code>. For querying,
- * {@link NumericRangeQuery} implements the query part
- * for the same data types.
- *
- * <p>This class can also be used, to generate lexicographically sortable (according to
- * {@link BytesRef#getUTF8SortedAsUTF16Comparator()}) representations of numeric data
- * types for other usages (e.g. sorting).
+ * Helper APIs to encode numeric values as sortable bytes and vice-versa.
  *
  * @lucene.internal
- * @since 2.9, API changed non backwards-compliant in 4.0
  */
 public final class NumericUtils {
 
   private NumericUtils() {} // no instance!
   
   /**
-   * The default precision step used by {@link LongField},
-   * {@link DoubleField}, {@link NumericTokenStream}, {@link
-   * NumericRangeQuery}.
-   */
-  public static final int PRECISION_STEP_DEFAULT = 16;
-  
-  /**
-   * The default precision step used by {@link IntField} and
-   * {@link FloatField}.
-   */
-  public static final int PRECISION_STEP_DEFAULT_32 = 8;
-  
-  /**
-   * Longs are stored at lower precision by shifting off lower bits. The shift count is
-   * stored as <code>SHIFT_START_LONG+shift</code> in the first byte
-   */
-  public static final byte SHIFT_START_LONG = 0x20;
-
-  /**
-   * The maximum term length (used for <code>byte[]</code> buffer size)
-   * for encoding <code>long</code> values.
-   * @see #longToPrefixCodedBytes
-   */
-  public static final int BUF_SIZE_LONG = 63/7 + 2;
-
-  /**
-   * Integers are stored at lower precision by shifting off lower bits. The shift count is
-   * stored as <code>SHIFT_START_INT+shift</code> in the first byte
-   */
-  public static final byte SHIFT_START_INT  = 0x60;
-
-  /**
-   * The maximum term length (used for <code>byte[]</code> buffer size)
-   * for encoding <code>int</code> values.
-   * @see #intToPrefixCodedBytes
-   */
-  public static final int BUF_SIZE_INT = 31/7 + 2;
-
-  /**
-   * Returns prefix coded bits after reducing the precision by <code>shift</code> bits.
-   * This is method is used by {@link NumericTokenStream}.
-   * After encoding, {@code bytes.offset} will always be 0. 
-   * @param val the numeric value
-   * @param shift how many bits to strip from the right
-   * @param bytes will contain the encoded value
-   */
-  public static void longToPrefixCoded(final long val, final int shift, final BytesRefBuilder bytes) {
-    longToPrefixCodedBytes(val, shift, bytes);
-  }
-
-  /**
-   * Returns prefix coded bits after reducing the precision by <code>shift</code> bits.
-   * This is method is used by {@link NumericTokenStream}.
-   * After encoding, {@code bytes.offset} will always be 0.
-   * @param val the numeric value
-   * @param shift how many bits to strip from the right
-   * @param bytes will contain the encoded value
-   */
-  public static void intToPrefixCoded(final int val, final int shift, final BytesRefBuilder bytes) {
-    intToPrefixCodedBytes(val, shift, bytes);
-  }
-
-  /**
-   * Returns prefix coded bits after reducing the precision by <code>shift</code> bits.
-   * This is method is used by {@link NumericTokenStream}.
-   * After encoding, {@code bytes.offset} will always be 0.
-   * @param val the numeric value
-   * @param shift how many bits to strip from the right
-   * @param bytes will contain the encoded value
-   */
-  public static void longToPrefixCodedBytes(final long val, final int shift, final BytesRefBuilder bytes) {
-    // ensure shift is 0..63
-    if ((shift & ~0x3f) != 0) {
-      throw new IllegalArgumentException("Illegal shift value, must be 0..63; got shift=" + shift);
-    }
-    int nChars = (((63-shift)*37)>>8) + 1;    // i/7 is the same as (i*37)>>8 for i in 0..63
-    bytes.setLength(nChars+1);   // one extra for the byte that contains the shift info
-    bytes.grow(BUF_SIZE_LONG);
-    bytes.setByteAt(0, (byte)(SHIFT_START_LONG + shift));
-    long sortableBits = val ^ 0x8000000000000000L;
-    sortableBits >>>= shift;
-    while (nChars > 0) {
-      // Store 7 bits per byte for compatibility
-      // with UTF-8 encoding of terms
-      bytes.setByteAt(nChars--, (byte)(sortableBits & 0x7f));
-      sortableBits >>>= 7;
-    }
-  }
-
-
-  /**
-   * Returns prefix coded bits after reducing the precision by <code>shift</code> bits.
-   * This is method is used by {@link NumericTokenStream}.
-   * After encoding, {@code bytes.offset} will always be 0. 
-   * @param val the numeric value
-   * @param shift how many bits to strip from the right
-   * @param bytes will contain the encoded value
-   */
-  public static void intToPrefixCodedBytes(final int val, final int shift, final BytesRefBuilder bytes) {
-    // ensure shift is 0..31
-    if ((shift & ~0x1f) != 0) {
-      throw new IllegalArgumentException("Illegal shift value, must be 0..31; got shift=" + shift);
-    }
-    int nChars = (((31-shift)*37)>>8) + 1;    // i/7 is the same as (i*37)>>8 for i in 0..63
-    bytes.setLength(nChars+1);   // one extra for the byte that contains the shift info
-    bytes.grow(NumericUtils.BUF_SIZE_LONG);  // use the max
-    bytes.setByteAt(0, (byte)(SHIFT_START_INT + shift));
-    int sortableBits = val ^ 0x80000000;
-    sortableBits >>>= shift;
-    while (nChars > 0) {
-      // Store 7 bits per byte for compatibility
-      // with UTF-8 encoding of terms
-      bytes.setByteAt(nChars--, (byte)(sortableBits & 0x7f));
-      sortableBits >>>= 7;
-    }
-  }
-
-
-  /**
-   * Returns the shift value from a prefix encoded {@code long}.
-   * @throws NumberFormatException if the supplied {@link BytesRef} is
-   * not correctly prefix encoded.
-   */
-  public static int getPrefixCodedLongShift(final BytesRef val) {
-    final int shift = val.bytes[val.offset] - SHIFT_START_LONG;
-    if (shift > 63 || shift < 0)
-      throw new NumberFormatException("Invalid shift value (" + shift + ") in prefixCoded bytes (is encoded value really an INT?)");
-    return shift;
-  }
-
-  /**
-   * Returns the shift value from a prefix encoded {@code int}.
-   * @throws NumberFormatException if the supplied {@link BytesRef} is
-   * not correctly prefix encoded.
-   */
-  public static int getPrefixCodedIntShift(final BytesRef val) {
-    final int shift = val.bytes[val.offset] - SHIFT_START_INT;
-    if (shift > 31 || shift < 0)
-      throw new NumberFormatException("Invalid shift value in prefixCoded bytes (is encoded value really an INT?)");
-    return shift;
-  }
-
-  /**
-   * Returns a long from prefixCoded bytes.
-   * Rightmost bits will be zero for lower precision codes.
-   * This method can be used to decode a term's value.
-   * @throws NumberFormatException if the supplied {@link BytesRef} is
-   * not correctly prefix encoded.
-   * @see #longToPrefixCodedBytes
-   */
-  public static long prefixCodedToLong(final BytesRef val) {
-    long sortableBits = 0L;
-    for (int i=val.offset+1, limit=val.offset+val.length; i<limit; i++) {
-      sortableBits <<= 7;
-      final byte b = val.bytes[i];
-      if (b < 0) {
-        throw new NumberFormatException(
-          "Invalid prefixCoded numerical value representation (byte "+
-          Integer.toHexString(b&0xff)+" at position "+(i-val.offset)+" is invalid)"
-        );
-      }
-      sortableBits |= b;
-    }
-    return (sortableBits << getPrefixCodedLongShift(val)) ^ 0x8000000000000000L;
-  }
-
-  /**
-   * Returns an int from prefixCoded bytes.
-   * Rightmost bits will be zero for lower precision codes.
-   * This method can be used to decode a term's value.
-   * @throws NumberFormatException if the supplied {@link BytesRef} is
-   * not correctly prefix encoded.
-   * @see #intToPrefixCodedBytes
-   */
-  public static int prefixCodedToInt(final BytesRef val) {
-    int sortableBits = 0;
-    for (int i=val.offset+1, limit=val.offset+val.length; i<limit; i++) {
-      sortableBits <<= 7;
-      final byte b = val.bytes[i];
-      if (b < 0) {
-        throw new NumberFormatException(
-          "Invalid prefixCoded numerical value representation (byte "+
-          Integer.toHexString(b&0xff)+" at position "+(i-val.offset)+" is invalid)"
-        );
-      }
-      sortableBits |= b;
-    }
-    return (sortableBits << getPrefixCodedIntShift(val)) ^ 0x80000000;
-  }
-
-  /**
    * Converts a <code>double</code> value to a sortable signed <code>long</code>.
    * The value is converted by getting their IEEE 754 floating-point &quot;double format&quot;
    * bit layout and then some bits are swapped, to be able to compare the result as long.
@@ -313,285 +81,178 @@ public final class NumericUtils {
     return bits ^ (bits >> 31) & 0x7fffffff;
   }
 
-  /**
-   * Splits a long range recursively.
-   * You may implement a builder that adds clauses to a
-   * {@link org.apache.lucene.search.BooleanQuery} for each call to its
-   * {@link LongRangeBuilder#addRange(BytesRef,BytesRef)}
-   * method.
-   * <p>This method is used by {@link NumericRangeQuery}.
-   */
-  public static void splitLongRange(final LongRangeBuilder builder,
-    final int precisionStep,  final long minBound, final long maxBound
-  ) {
-    splitRange(builder, 64, precisionStep, minBound, maxBound);
-  }
-  
-  /**
-   * Splits an int range recursively.
-   * You may implement a builder that adds clauses to a
-   * {@link org.apache.lucene.search.BooleanQuery} for each call to its
-   * {@link IntRangeBuilder#addRange(BytesRef,BytesRef)}
-   * method.
-   * <p>This method is used by {@link NumericRangeQuery}.
-   */
-  public static void splitIntRange(final IntRangeBuilder builder,
-    final int precisionStep,  final int minBound, final int maxBound
-  ) {
-    splitRange(builder, 32, precisionStep, minBound, maxBound);
-  }
-  
-  /** This helper does the splitting for both 32 and 64 bit. */
-  private static void splitRange(
-    final Object builder, final int valSize,
-    final int precisionStep, long minBound, long maxBound
-  ) {
-    if (precisionStep < 1)
-      throw new IllegalArgumentException("precisionStep must be >=1");
-    if (minBound > maxBound) return;
-    for (int shift=0; ; shift += precisionStep) {
-      // calculate new bounds for inner precision
-      final long diff = 1L << (shift+precisionStep),
-        mask = ((1L<<precisionStep) - 1L) << shift;
-      final boolean
-        hasLower = (minBound & mask) != 0L,
-        hasUpper = (maxBound & mask) != mask;
-      final long
-        nextMinBound = (hasLower ? (minBound + diff) : minBound) & ~mask,
-        nextMaxBound = (hasUpper ? (maxBound - diff) : maxBound) & ~mask;
-      final boolean
-        lowerWrapped = nextMinBound < minBound,
-        upperWrapped = nextMaxBound > maxBound;
-      
-      if (shift+precisionStep>=valSize || nextMinBound>nextMaxBound || lowerWrapped || upperWrapped) {
-        // We are in the lowest precision or the next precision is not available.
-        addRange(builder, valSize, minBound, maxBound, shift);
-        // exit the split recursion loop
-        break;
+
+  /** Result = a - b, where a &gt;= b, else {@code IllegalArgumentException} is thrown.  */
+  public static void subtract(int bytesPerDim, int dim, byte[] a, byte[] b, byte[] result) {
+    int start = dim * bytesPerDim;
+    int end = start + bytesPerDim;
+    int borrow = 0;
+    for(int i=end-1;i>=start;i--) {
+      int diff = (a[i]&0xff) - (b[i]&0xff) - borrow;
+      if (diff < 0) {
+        diff += 256;
+        borrow = 1;
+      } else {
+        borrow = 0;
       }
-      
-      if (hasLower)
-        addRange(builder, valSize, minBound, minBound | mask, shift);
-      if (hasUpper)
-        addRange(builder, valSize, maxBound & ~mask, maxBound, shift);
-      
-      // recurse to next precision
-      minBound = nextMinBound;
-      maxBound = nextMaxBound;
+      result[i-start] = (byte) diff;
     }
-  }
-  
-  /** Helper that delegates to correct range builder */
-  private static void addRange(
-    final Object builder, final int valSize,
-    long minBound, long maxBound,
-    final int shift
-  ) {
-    // for the max bound set all lower bits (that were shifted away):
-    // this is important for testing or other usages of the splitted range
-    // (e.g. to reconstruct the full range). The prefixEncoding will remove
-    // the bits anyway, so they do not hurt!
-    maxBound |= (1L << shift) - 1L;
-    // delegate to correct range builder
-    switch(valSize) {
-      case 64:
-        ((LongRangeBuilder)builder).addRange(minBound, maxBound, shift);
-        break;
-      case 32:
-        ((IntRangeBuilder)builder).addRange((int)minBound, (int)maxBound, shift);
-        break;
-      default:
-        // Should not happen!
-        throw new IllegalArgumentException("valSize must be 32 or 64.");
+    if (borrow != 0) {
+      throw new IllegalArgumentException("a < b");
     }
   }
 
-  /**
-   * Callback for {@link #splitLongRange}.
-   * You need to overwrite only one of the methods.
-   * @lucene.internal
-   * @since 2.9, API changed non backwards-compliant in 4.0
-   */
-  public static abstract class LongRangeBuilder {
-    
-    /**
-     * Overwrite this method, if you like to receive the already prefix encoded range bounds.
-     * You can directly build classical (inclusive) range queries from them.
-     */
-    public void addRange(BytesRef minPrefixCoded, BytesRef maxPrefixCoded) {
-      throw new UnsupportedOperationException();
-    }
-    
-    /**
-     * Overwrite this method, if you like to receive the raw long range bounds.
-     * You can use this for e.g. debugging purposes (print out range bounds).
-     */
-    public void addRange(final long min, final long max, final int shift) {
-      final BytesRefBuilder minBytes = new BytesRefBuilder(), maxBytes = new BytesRefBuilder();
-      longToPrefixCodedBytes(min, shift, minBytes);
-      longToPrefixCodedBytes(max, shift, maxBytes);
-      addRange(minBytes.get(), maxBytes.get());
-    }
-  
-  }
-  
-  /**
-   * Callback for {@link #splitIntRange}.
-   * You need to overwrite only one of the methods.
-   * @lucene.internal
-   * @since 2.9, API changed non backwards-compliant in 4.0
-   */
-  public static abstract class IntRangeBuilder {
-    
-    /**
-     * Overwrite this method, if you like to receive the already prefix encoded range bounds.
-     * You can directly build classical range (inclusive) queries from them.
-     */
-    public void addRange(BytesRef minPrefixCoded, BytesRef maxPrefixCoded) {
-      throw new UnsupportedOperationException();
+  /** Result = a + b, where a and b are unsigned.  If there is an overflow, {@code IllegalArgumentException} is thrown. */
+  public static void add(int bytesPerDim, int dim, byte[] a, byte[] b, byte[] result) {
+    int start = dim * bytesPerDim;
+    int end = start + bytesPerDim;
+    int carry = 0;
+    for(int i=end-1;i>=start;i--) {
+      int digitSum = (a[i]&0xff) + (b[i]&0xff) + carry;
+      if (digitSum > 255) {
+        digitSum -= 256;
+        carry = 1;
+      } else {
+        carry = 0;
+      }
+      result[i-start] = (byte) digitSum;
     }
-    
-    /**
-     * Overwrite this method, if you like to receive the raw int range bounds.
-     * You can use this for e.g. debugging purposes (print out range bounds).
-     */
-    public void addRange(final int min, final int max, final int shift) {
-      final BytesRefBuilder minBytes = new BytesRefBuilder(), maxBytes = new BytesRefBuilder();
-      intToPrefixCodedBytes(min, shift, minBytes);
-      intToPrefixCodedBytes(max, shift, maxBytes);
-      addRange(minBytes.get(), maxBytes.get());
+    if (carry != 0) {
+      throw new IllegalArgumentException("a + b overflows bytesPerDim=" + bytesPerDim);
     }
-  
   }
-  
-  /**
-   * Filters the given {@link TermsEnum} by accepting only prefix coded 64 bit
-   * terms with a shift value of <tt>0</tt>.
-   * 
-   * @param termsEnum
-   *          the terms enum to filter
-   * @return a filtered {@link TermsEnum} that only returns prefix coded 64 bit
-   *         terms with a shift value of <tt>0</tt>.
-   */
-  public static TermsEnum filterPrefixCodedLongs(TermsEnum termsEnum) {
-    return new SeekingNumericFilteredTermsEnum(termsEnum) {
 
-      @Override
-      protected AcceptStatus accept(BytesRef term) {
-        return NumericUtils.getPrefixCodedLongShift(term) == 0 ? AcceptStatus.YES : AcceptStatus.END;
+  /** Returns positive int if a &gt; b, negative int if a &lt; b and 0 if a == b */
+  public static int compare(int bytesPerDim, byte[] a, int aIndex, byte[] b, int bIndex) {
+    assert aIndex >= 0;
+    assert bIndex >= 0;
+    int aOffset = aIndex*bytesPerDim;
+    int bOffset = bIndex*bytesPerDim;
+    for(int i=0;i<bytesPerDim;i++) {
+      int cmp = (a[aOffset+i]&0xff) - (b[bOffset+i]&0xff);
+      if (cmp != 0) {
+        return cmp;
       }
-    };
-  }
+    }
 
-  /**
-   * Filters the given {@link TermsEnum} by accepting only prefix coded 32 bit
-   * terms with a shift value of <tt>0</tt>.
-   * 
-   * @param termsEnum
-   *          the terms enum to filter
-   * @return a filtered {@link TermsEnum} that only returns prefix coded 32 bit
-   *         terms with a shift value of <tt>0</tt>.
-   */
-  public static TermsEnum filterPrefixCodedInts(TermsEnum termsEnum) {
-    return new SeekingNumericFilteredTermsEnum(termsEnum) {
-      
-      @Override
-      protected AcceptStatus accept(BytesRef term) {
-        return NumericUtils.getPrefixCodedIntShift(term) == 0 ? AcceptStatus.YES : AcceptStatus.END;
-      }
-    };
+    return 0;
   }
 
-  /** Just like FilteredTermsEnum, except it adds a limited
-   *  seekCeil implementation that only works with {@link
-   *  #filterPrefixCodedInts} and {@link
-   *  #filterPrefixCodedLongs}. */
-  private static abstract class SeekingNumericFilteredTermsEnum extends FilteredTermsEnum {
-    public SeekingNumericFilteredTermsEnum(final TermsEnum tenum) {
-      super(tenum, false);
+  /** Returns true if N-dim rect A contains N-dim rect B */
+  public static boolean contains(int bytesPerDim,
+                                 byte[] minPackedA, byte[] maxPackedA,
+                                 byte[] minPackedB, byte[] maxPackedB) {
+    int dims = minPackedA.length / bytesPerDim;
+    for(int dim=0;dim<dims;dim++) {
+      if (compare(bytesPerDim, minPackedA, dim, minPackedB, dim) > 0) {
+        return false;
+      }
+      if (compare(bytesPerDim, maxPackedA, dim, maxPackedB, dim) < 0) {
+        return false;
+      }
     }
 
-    @Override
-    @SuppressWarnings("fallthrough")
-    public SeekStatus seekCeil(BytesRef term) throws IOException {
+    return true;
+  }
 
-      // NOTE: This is not general!!  It only handles YES
-      // and END, because that's all we need for the numeric
-      // case here
+  public static void intToBytes(int x, byte[] dest, int index) {
+    // Flip the sign bit, so negative ints sort before positive ints correctly:
+    x ^= 0x80000000;
+    intToBytesDirect(x, dest, index);
+  }
 
-      SeekStatus status = tenum.seekCeil(term);
-      if (status == SeekStatus.END) {
-        return SeekStatus.END;
-      }
+  public static void intToBytesDirect(int x, byte[] dest, int index) {
+    // Flip the sign bit, so negative ints sort before positive ints correctly:
+    for(int i=0;i<4;i++) {
+      dest[4*index+i] = (byte) (x >> 24-i*8);
+    }
+  }
 
-      actualTerm = tenum.term();
+  public static int bytesToInt(byte[] src, int index) {
+    int x = bytesToIntDirect(src, index);
+    // Re-flip the sign bit to restore the original value:
+    return x ^ 0x80000000;
+  }
 
-      if (accept(actualTerm) == AcceptStatus.YES) {
-        return status;
-      } else {
-        return SeekStatus.END;
-      }
+  public static int bytesToIntDirect(byte[] src, int index) {
+    int x = 0;
+    for(int i=0;i<4;i++) {
+      x |= (src[4*index+i] & 0xff) << (24-i*8);
     }
+    return x;
   }
 
-  private static Terms intTerms(Terms terms) {
-    return new FilterLeafReader.FilterTerms(terms) {
-        @Override
-        public TermsEnum iterator() throws IOException {
-          return filterPrefixCodedInts(in.iterator());
-        }
-      };
+  public static void longToBytes(long v, byte[] bytes, int dim) {
+    // Flip the sign bit so negative longs sort before positive longs:
+    v ^= 0x8000000000000000L;
+    longToBytesDirect(v, bytes, dim);
   }
 
-  private static Terms longTerms(Terms terms) {
-    return new FilterLeafReader.FilterTerms(terms) {
-        @Override
-        public TermsEnum iterator() throws IOException {
-          return filterPrefixCodedLongs(in.iterator());
-        }
-      };
+  public static void longToBytesDirect(long v, byte[] bytes, int dim) {
+    int offset = 8 * dim;
+    bytes[offset] = (byte) (v >> 56);
+    bytes[offset+1] = (byte) (v >> 48);
+    bytes[offset+2] = (byte) (v >> 40);
+    bytes[offset+3] = (byte) (v >> 32);
+    bytes[offset+4] = (byte) (v >> 24);
+    bytes[offset+5] = (byte) (v >> 16);
+    bytes[offset+6] = (byte) (v >> 8);
+    bytes[offset+7] = (byte) v;
   }
-    
-  /**
-   * Returns the minimum int value indexed into this
-   * numeric field or null if no terms exist.
-   */
-  public static Integer getMinInt(Terms terms) throws IOException {
-    // All shift=0 terms are sorted first, so we don't need
-    // to filter the incoming terms; we can just get the
-    // min:
-    BytesRef min = terms.getMin();
-    return (min != null) ? NumericUtils.prefixCodedToInt(min) : null;
+
+  public static long bytesToLong(byte[] bytes, int index) {
+    long v = bytesToLongDirect(bytes, index);
+    // Flip the sign bit back
+    v ^= 0x8000000000000000L;
+    return v;
   }
 
-  /**
-   * Returns the maximum int value indexed into this
-   * numeric field or null if no terms exist.
-   */
-  public static Integer getMaxInt(Terms terms) throws IOException {
-    BytesRef max = intTerms(terms).getMax();
-    return (max != null) ? NumericUtils.prefixCodedToInt(max) : null;
+  public static long bytesToLongDirect(byte[] bytes, int index) {
+    int offset = 8 * index;
+    long v = ((bytes[offset] & 0xffL) << 56) |
+      ((bytes[offset+1] & 0xffL) << 48) |
+      ((bytes[offset+2] & 0xffL) << 40) |
+      ((bytes[offset+3] & 0xffL) << 32) |
+      ((bytes[offset+4] & 0xffL) << 24) |
+      ((bytes[offset+5] & 0xffL) << 16) |
+      ((bytes[offset+6] & 0xffL) << 8) |
+      (bytes[offset+7] & 0xffL);
+    return v;
   }
 
-  /**
-   * Returns the minimum long value indexed into this
-   * numeric field or null if no terms exist.
-   */
-  public static Long getMinLong(Terms terms) throws IOException {
-    // All shift=0 terms are sorted first, so we don't need
-    // to filter the incoming terms; we can just get the
-    // min:
-    BytesRef min = terms.getMin();
-    return (min != null) ? NumericUtils.prefixCodedToLong(min) : null;
+  public static void sortableBigIntBytes(byte[] bytes) {
+    bytes[0] ^= 0x80;
+    for(int i=1;i<bytes.length;i++)  {
+      bytes[i] ^= 0;
+    }
   }
 
-  /**
-   * Returns the maximum long value indexed into this
-   * numeric field or null if no terms exist.
-   */
-  public static Long getMaxLong(Terms terms) throws IOException {
-    BytesRef max = longTerms(terms).getMax();
-    return (max != null) ? NumericUtils.prefixCodedToLong(max) : null;
+  public static void bigIntToBytes(BigInteger bigInt, byte[] result, int dim, int numBytesPerDim) {
+    byte[] bigIntBytes = bigInt.toByteArray();
+    byte[] fullBigIntBytes;
+
+    if (bigIntBytes.length < numBytesPerDim) {
+      fullBigIntBytes = new byte[numBytesPerDim];
+      System.arraycopy(bigIntBytes, 0, fullBigIntBytes, numBytesPerDim-bigIntBytes.length, bigIntBytes.length);
+      if ((bigIntBytes[0] & 0x80) != 0) {
+        // sign extend
+        Arrays.fill(fullBigIntBytes, 0, numBytesPerDim-bigIntBytes.length, (byte) 0xff);
+      }
+    } else {
+      assert bigIntBytes.length == numBytesPerDim;
+      fullBigIntBytes = bigIntBytes;
+    }
+    sortableBigIntBytes(fullBigIntBytes);
+
+    System.arraycopy(fullBigIntBytes, 0, result, dim * numBytesPerDim, numBytesPerDim);
+
+    assert bytesToBigInt(result, dim, numBytesPerDim).equals(bigInt): "bigInt=" + bigInt + " converted=" + bytesToBigInt(result, dim, numBytesPerDim);
+  }
+
+  public static BigInteger bytesToBigInt(byte[] bytes, int dim, int numBytesPerDim) {
+    byte[] bigIntBytes = new byte[numBytesPerDim];
+    System.arraycopy(bytes, dim*numBytesPerDim, bigIntBytes, 0, numBytesPerDim);
+    sortableBigIntBytes(bigIntBytes);
+    return new BigInteger(bigIntBytes);
   }
-  
 }
diff --git a/lucene/core/src/java/org/apache/lucene/util/bkd/BKDReader.java b/lucene/core/src/java/org/apache/lucene/util/bkd/BKDReader.java
index 659bc3a..23035f1 100644
--- a/lucene/core/src/java/org/apache/lucene/util/bkd/BKDReader.java
+++ b/lucene/core/src/java/org/apache/lucene/util/bkd/BKDReader.java
@@ -26,6 +26,7 @@ import org.apache.lucene.index.DimensionalValues.Relation;
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.util.Accountable;
 import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.NumericUtils;
 import org.apache.lucene.util.RamUsageEstimator;
 import org.apache.lucene.util.StringHelper;
 
@@ -163,7 +164,7 @@ public class BKDReader implements Accountable {
         // With only 1D, all values should always be in sorted order
         if (lastPackedValue == null) {
           lastPackedValue = Arrays.copyOf(packedValue, packedValue.length);
-        } else if (BKDUtil.compare(bytesPerDim, lastPackedValue, 0, packedValue, 0) > 0) {
+        } else if (NumericUtils.compare(bytesPerDim, lastPackedValue, 0, packedValue, 0) > 0) {
           throw new RuntimeException("value=" + new BytesRef(packedValue) + " for docID=" + docID + " dim=0" + " sorts before last value=" + new BytesRef(lastPackedValue));
         } else {
           System.arraycopy(packedValue, 0, lastPackedValue, 0, bytesPerDim);
diff --git a/lucene/core/src/java/org/apache/lucene/util/bkd/BKDUtil.java b/lucene/core/src/java/org/apache/lucene/util/bkd/BKDUtil.java
deleted file mode 100644
index 8578ef4..0000000
--- a/lucene/core/src/java/org/apache/lucene/util/bkd/BKDUtil.java
+++ /dev/null
@@ -1,185 +0,0 @@
-package org.apache.lucene.util.bkd;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.math.BigInteger;
-import java.util.Arrays;
-
-/** Utility methods to convert to/from N-dimensional packed byte[] as unsigned numbers */
-public final class BKDUtil {
-
-  private BKDUtil() {
-    // No instance
-  }
-
-  /** Result = a - b, where a &gt;= b, else {@code IllegalArgumentException} is thrown.  */
-  public static void subtract(int bytesPerDim, int dim, byte[] a, byte[] b, byte[] result) {
-    int start = dim * bytesPerDim;
-    int end = start + bytesPerDim;
-    int borrow = 0;
-    for(int i=end-1;i>=start;i--) {
-      int diff = (a[i]&0xff) - (b[i]&0xff) - borrow;
-      if (diff < 0) {
-        diff += 256;
-        borrow = 1;
-      } else {
-        borrow = 0;
-      }
-      result[i-start] = (byte) diff;
-    }
-    if (borrow != 0) {
-      throw new IllegalArgumentException("a < b");
-    }
-  }
-
-  /** Result = a + b, where a and b are unsigned.  If there is an overflow, {@code IllegalArgumentException} is thrown. */
-  public static void add(int bytesPerDim, int dim, byte[] a, byte[] b, byte[] result) {
-    int start = dim * bytesPerDim;
-    int end = start + bytesPerDim;
-    int carry = 0;
-    for(int i=end-1;i>=start;i--) {
-      int digitSum = (a[i]&0xff) + (b[i]&0xff) + carry;
-      if (digitSum > 255) {
-        digitSum -= 256;
-        carry = 1;
-      } else {
-        carry = 0;
-      }
-      result[i-start] = (byte) digitSum;
-    }
-    if (carry != 0) {
-      throw new IllegalArgumentException("a + b overflows bytesPerDim=" + bytesPerDim);
-    }
-  }
-
-  /** Returns positive int if a &gt; b, negative int if a &lt; b and 0 if a == b */
-  public static int compare(int bytesPerDim, byte[] a, int aIndex, byte[] b, int bIndex) {
-    assert aIndex >= 0;
-    assert bIndex >= 0;
-    int aOffset = aIndex*bytesPerDim;
-    int bOffset = bIndex*bytesPerDim;
-    for(int i=0;i<bytesPerDim;i++) {
-      int cmp = (a[aOffset+i]&0xff) - (b[bOffset+i]&0xff);
-      if (cmp != 0) {
-        return cmp;
-      }
-    }
-
-    return 0;
-  }
-
-  /** Returns true if N-dim rect A contains N-dim rect B */
-  public static boolean contains(int bytesPerDim,
-                                 byte[] minPackedA, byte[] maxPackedA,
-                                 byte[] minPackedB, byte[] maxPackedB) {
-    int dims = minPackedA.length / bytesPerDim;
-    for(int dim=0;dim<dims;dim++) {
-      if (compare(bytesPerDim, minPackedA, dim, minPackedB, dim) > 0) {
-        return false;
-      }
-      if (compare(bytesPerDim, maxPackedA, dim, maxPackedB, dim) < 0) {
-        return false;
-      }
-    }
-
-    return true;
-  }
-
-  public static void intToBytes(int x, byte[] dest, int index) {
-    // Flip the sign bit, so negative ints sort before positive ints correctly:
-    x ^= 0x80000000;
-    for(int i=0;i<4;i++) {
-      dest[4*index+i] = (byte) (x >> 24-i*8);
-    }
-  }
-
-  public static int bytesToInt(byte[] src, int index) {
-    int x = 0;
-    for(int i=0;i<4;i++) {
-      x |= (src[4*index+i] & 0xff) << (24-i*8);
-    }
-    // Re-flip the sign bit to restore the original value:
-    return x ^ 0x80000000;
-  }
-
-  public static void longToBytes(long v, byte[] bytes, int dim) {
-    // Flip the sign bit so negative longs sort before positive longs:
-    v ^= 0x8000000000000000L;
-    int offset = 8 * dim;
-    bytes[offset] = (byte) (v >> 56);
-    bytes[offset+1] = (byte) (v >> 48);
-    bytes[offset+2] = (byte) (v >> 40);
-    bytes[offset+3] = (byte) (v >> 32);
-    bytes[offset+4] = (byte) (v >> 24);
-    bytes[offset+5] = (byte) (v >> 16);
-    bytes[offset+6] = (byte) (v >> 8);
-    bytes[offset+7] = (byte) v;
-  }
-
-  public static long bytesToLong(byte[] bytes, int index) {
-    int offset = 8 * index;
-    long v = ((bytes[offset] & 0xffL) << 56) |
-      ((bytes[offset+1] & 0xffL) << 48) |
-      ((bytes[offset+2] & 0xffL) << 40) |
-      ((bytes[offset+3] & 0xffL) << 32) |
-      ((bytes[offset+4] & 0xffL) << 24) |
-      ((bytes[offset+5] & 0xffL) << 16) |
-      ((bytes[offset+6] & 0xffL) << 8) |
-      (bytes[offset+7] & 0xffL);
-
-    // Flip the sign bit back
-    v ^= 0x8000000000000000L;
-    return v;
-  }
-
-  public static void sortableBigIntBytes(byte[] bytes) {
-    bytes[0] ^= 0x80;
-    for(int i=1;i<bytes.length;i++)  {
-      bytes[i] ^= 0;
-    }
-  }
-
-  public static void bigIntToBytes(BigInteger bigInt, byte[] result, int dim, int numBytesPerDim) {
-    byte[] bigIntBytes = bigInt.toByteArray();
-    byte[] fullBigIntBytes;
-
-    if (bigIntBytes.length < numBytesPerDim) {
-      fullBigIntBytes = new byte[numBytesPerDim];
-      System.arraycopy(bigIntBytes, 0, fullBigIntBytes, numBytesPerDim-bigIntBytes.length, bigIntBytes.length);
-      if ((bigIntBytes[0] & 0x80) != 0) {
-        // sign extend
-        Arrays.fill(fullBigIntBytes, 0, numBytesPerDim-bigIntBytes.length, (byte) 0xff);
-      }
-    } else {
-      assert bigIntBytes.length == numBytesPerDim;
-      fullBigIntBytes = bigIntBytes;
-    }
-    sortableBigIntBytes(fullBigIntBytes);
-
-    System.arraycopy(fullBigIntBytes, 0, result, dim * numBytesPerDim, numBytesPerDim);
-
-    assert bytesToBigInt(result, dim, numBytesPerDim).equals(bigInt): "bigInt=" + bigInt + " converted=" + bytesToBigInt(result, dim, numBytesPerDim);
-  }
-
-  public static BigInteger bytesToBigInt(byte[] bytes, int dim, int numBytesPerDim) {
-    byte[] bigIntBytes = new byte[numBytesPerDim];
-    System.arraycopy(bytes, dim*numBytesPerDim, bigIntBytes, 0, numBytesPerDim);
-    sortableBigIntBytes(bigIntBytes);
-    return new BigInteger(bigIntBytes);
-  }
-}
diff --git a/lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter.java b/lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter.java
index 35b3939..7680996 100644
--- a/lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter.java
+++ b/lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter.java
@@ -38,8 +38,9 @@ import org.apache.lucene.util.BytesRefBuilder;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.IntroSorter;
 import org.apache.lucene.util.LongBitSet;
-import org.apache.lucene.util.OfflineSorter.ByteSequencesWriter;
+import org.apache.lucene.util.NumericUtils;
 import org.apache.lucene.util.OfflineSorter;
+import org.apache.lucene.util.OfflineSorter.ByteSequencesWriter;
 import org.apache.lucene.util.PriorityQueue;
 import org.apache.lucene.util.RamUsageEstimator;
 import org.apache.lucene.util.StringHelper;
@@ -91,7 +92,7 @@ public class BKDWriter implements Closeable {
   public static final float DEFAULT_MAX_MB_SORT_IN_HEAP = 16.0f;
 
   /** Maximum number of dimensions */
-  public static final int MAX_DIMS = 255;
+  public static final int MAX_DIMS = 8;
 
   /** How many dimensions we are indexing */
   protected final int numDims;
@@ -534,7 +535,7 @@ public class BKDWriter implements Closeable {
         int block = j / writer.valuesPerBlock;
         int index = j % writer.valuesPerBlock;
         assert index >= 0: "index=" + index + " j=" + j;
-        int cmp = BKDUtil.compare(bytesPerDim, pivotPackedValue, 0, writer.blocks.get(block), index*numDims+dim);
+        int cmp = NumericUtils.compare(bytesPerDim, pivotPackedValue, 0, writer.blocks.get(block), index*numDims+dim);
         if (cmp != 0) {
           return cmp;
         }
@@ -578,7 +579,7 @@ public class BKDWriter implements Closeable {
         int dimI = i % writer.valuesPerBlock;
         int blockJ = j / writer.valuesPerBlock;
         int dimJ = j % writer.valuesPerBlock;
-        int cmp = BKDUtil.compare(bytesPerDim, writer.blocks.get(blockI), dimI*numDims+dim, writer.blocks.get(blockJ), dimJ*numDims+dim);
+        int cmp = NumericUtils.compare(bytesPerDim, writer.blocks.get(blockI), dimI*numDims+dim, writer.blocks.get(blockJ), dimJ*numDims+dim);
         if (cmp != 0) {
           return cmp;
         }
@@ -641,7 +642,7 @@ public class BKDWriter implements Closeable {
           final int docIDB = reader.readVInt();
           final long ordB = reader.readVLong();
 
-          int cmp = BKDUtil.compare(bytesPerDim, scratch1, dim, scratch2, dim);
+          int cmp = NumericUtils.compare(bytesPerDim, scratch1, dim, scratch2, dim);
 
           if (cmp != 0) {
             return cmp;
@@ -919,10 +920,10 @@ public class BKDWriter implements Closeable {
   /** Called only in assert */
   private boolean valueInBounds(byte[] packedValue, byte[] minPackedValue, byte[] maxPackedValue) {
     for(int dim=0;dim<numDims;dim++) {
-      if (BKDUtil.compare(bytesPerDim, packedValue, dim, minPackedValue, dim) < 0) {
+      if (NumericUtils.compare(bytesPerDim, packedValue, dim, minPackedValue, dim) < 0) {
         return false;
       }
-      if (BKDUtil.compare(bytesPerDim, packedValue, dim, maxPackedValue, dim) > 0) {
+      if (NumericUtils.compare(bytesPerDim, packedValue, dim, maxPackedValue, dim) > 0) {
         return false;
       }
     }
@@ -935,8 +936,8 @@ public class BKDWriter implements Closeable {
     // Find which dim has the largest span so we can split on it:
     int splitDim = -1;
     for(int dim=0;dim<numDims;dim++) {
-      BKDUtil.subtract(bytesPerDim, dim, maxPackedValue, minPackedValue, scratchDiff);
-      if (splitDim == -1 || BKDUtil.compare(bytesPerDim, scratchDiff, 0, scratch1, 0) > 0) {
+      NumericUtils.subtract(bytesPerDim, dim, maxPackedValue, minPackedValue, scratchDiff);
+      if (splitDim == -1 || NumericUtils.compare(bytesPerDim, scratchDiff, 0, scratch1, 0) > 0) {
         System.arraycopy(scratchDiff, 0, scratch1, 0, bytesPerDim);
         splitDim = dim;
       }
@@ -1145,7 +1146,7 @@ public class BKDWriter implements Closeable {
 
   // only called from assert
   private boolean valueInOrder(long ord, byte[] lastPackedValue, byte[] packedValue) {
-    if (ord > 0 && BKDUtil.compare(bytesPerDim, lastPackedValue, 0, packedValue, 0) > 0) {
+    if (ord > 0 && NumericUtils.compare(bytesPerDim, lastPackedValue, 0, packedValue, 0) > 0) {
       throw new AssertionError("values out of order: last value=" + new BytesRef(lastPackedValue) + " current value=" + new BytesRef(packedValue) + " ord=" + ord);
     }
     System.arraycopy(packedValue, 0, lastPackedValue, 0, bytesPerDim);
diff --git a/lucene/core/src/test/org/apache/lucene/TestSearch.java b/lucene/core/src/test/org/apache/lucene/TestSearch.java
index ccf1898..668e7c2 100644
--- a/lucene/core/src/test/org/apache/lucene/TestSearch.java
+++ b/lucene/core/src/test/org/apache/lucene/TestSearch.java
@@ -17,18 +17,18 @@ package org.apache.lucene;
  * limitations under the License.
  */
 
+import java.io.PrintWriter;
+import java.io.StringWriter;
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Random;
-import java.io.PrintWriter;
-import java.io.StringWriter;
 
-import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.store.*;
-import org.apache.lucene.document.*;
 import org.apache.lucene.analysis.*;
+import org.apache.lucene.document.*;
 import org.apache.lucene.index.*;
 import org.apache.lucene.search.*;
+import org.apache.lucene.store.*;
+import org.apache.lucene.util.LuceneTestCase;
 
 /** JUnit adaptation of an older test case SearchTest. */
 public class TestSearch extends LuceneTestCase {
@@ -125,7 +125,6 @@ public class TestSearch extends LuceneTestCase {
       for (int j = 0; j < docs.length; j++) {
         Document d = new Document();
         d.add(newTextField("contents", docs[j], Field.Store.YES));
-        d.add(new IntField("id", j, Field.Store.NO));
         d.add(new NumericDocValuesField("id", j));
         writer.addDocument(d);
       }
diff --git a/lucene/core/src/test/org/apache/lucene/TestSearchForDuplicates.java b/lucene/core/src/test/org/apache/lucene/TestSearchForDuplicates.java
index a5c7d1d..104172e 100644
--- a/lucene/core/src/test/org/apache/lucene/TestSearchForDuplicates.java
+++ b/lucene/core/src/test/org/apache/lucene/TestSearchForDuplicates.java
@@ -26,8 +26,8 @@ import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
-import org.apache.lucene.document.IntField;
 import org.apache.lucene.document.NumericDocValuesField;
+import org.apache.lucene.document.StoredField;
 import org.apache.lucene.index.DirectoryReader;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexWriter;
@@ -98,7 +98,7 @@ public class TestSearchForDuplicates extends LuceneTestCase {
       for (int j = 0; j < MAX_DOCS; j++) {
         Document d = new Document();
         d.add(newTextField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES));
-        d.add(new IntField(ID_FIELD, j, Field.Store.YES));
+        d.add(new StoredField(ID_FIELD, j));
         d.add(new NumericDocValuesField(ID_FIELD, j));
         writer.addDocument(d);
       }
diff --git a/lucene/core/src/test/org/apache/lucene/analysis/TestNumericTokenStream.java b/lucene/core/src/test/org/apache/lucene/analysis/TestNumericTokenStream.java
index 331a70c..0d5d8a1 100644
--- a/lucene/core/src/test/org/apache/lucene/analysis/TestNumericTokenStream.java
+++ b/lucene/core/src/test/org/apache/lucene/analysis/TestNumericTokenStream.java
@@ -17,8 +17,8 @@ package org.apache.lucene.analysis;
  * limitations under the License.
  */
 
-import org.apache.lucene.util.NumericUtils;
-import org.apache.lucene.analysis.NumericTokenStream.NumericTermAttributeImpl;
+import org.apache.lucene.util.LegacyNumericUtils;
+import org.apache.lucene.analysis.LegacyNumericTokenStream.LegacyNumericTermAttributeImpl;
 import org.apache.lucene.analysis.tokenattributes.TermToBytesRefAttribute;
 import org.apache.lucene.analysis.tokenattributes.TestCharTermAttributeImpl;
 import org.apache.lucene.analysis.tokenattributes.TypeAttribute;
@@ -32,21 +32,21 @@ public class TestNumericTokenStream extends BaseTokenStreamTestCase {
 
   public void testLongStream() throws Exception {
     @SuppressWarnings("resource")
-    final NumericTokenStream stream=new NumericTokenStream().setLongValue(lvalue);
+    final LegacyNumericTokenStream stream=new LegacyNumericTokenStream().setLongValue(lvalue);
     final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);
     assertNotNull(bytesAtt);
     final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);
     assertNotNull(typeAtt);
-    final NumericTokenStream.NumericTermAttribute numericAtt = stream.getAttribute(NumericTokenStream.NumericTermAttribute.class);
+    final LegacyNumericTokenStream.LegacyNumericTermAttribute numericAtt = stream.getAttribute(LegacyNumericTokenStream.LegacyNumericTermAttribute.class);
     assertNotNull(numericAtt);
     stream.reset();
     assertEquals(64, numericAtt.getValueSize());
-    for (int shift=0; shift<64; shift+=NumericUtils.PRECISION_STEP_DEFAULT) {
+    for (int shift=0; shift<64; shift+= LegacyNumericUtils.PRECISION_STEP_DEFAULT) {
       assertTrue("New token is available", stream.incrementToken());
       assertEquals("Shift value wrong", shift, numericAtt.getShift());
-      assertEquals("Term is incorrectly encoded", lvalue & ~((1L << shift) - 1L), NumericUtils.prefixCodedToLong(bytesAtt.getBytesRef()));
+      assertEquals("Term is incorrectly encoded", lvalue & ~((1L << shift) - 1L), LegacyNumericUtils.prefixCodedToLong(bytesAtt.getBytesRef()));
       assertEquals("Term raw value is incorrectly encoded", lvalue & ~((1L << shift) - 1L), numericAtt.getRawValue());
-      assertEquals("Type incorrect", (shift == 0) ? NumericTokenStream.TOKEN_TYPE_FULL_PREC : NumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());
+      assertEquals("Type incorrect", (shift == 0) ? LegacyNumericTokenStream.TOKEN_TYPE_FULL_PREC : LegacyNumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());
     }
     assertFalse("More tokens available", stream.incrementToken());
     stream.end();
@@ -55,21 +55,21 @@ public class TestNumericTokenStream extends BaseTokenStreamTestCase {
 
   public void testIntStream() throws Exception {
     @SuppressWarnings("resource")
-    final NumericTokenStream stream=new NumericTokenStream().setIntValue(ivalue);
+    final LegacyNumericTokenStream stream=new LegacyNumericTokenStream().setIntValue(ivalue);
     final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);
     assertNotNull(bytesAtt);
     final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);
     assertNotNull(typeAtt);
-    final NumericTokenStream.NumericTermAttribute numericAtt = stream.getAttribute(NumericTokenStream.NumericTermAttribute.class);
+    final LegacyNumericTokenStream.LegacyNumericTermAttribute numericAtt = stream.getAttribute(LegacyNumericTokenStream.LegacyNumericTermAttribute.class);
     assertNotNull(numericAtt);
     stream.reset();
     assertEquals(32, numericAtt.getValueSize());
-    for (int shift=0; shift<32; shift+=NumericUtils.PRECISION_STEP_DEFAULT) {
+    for (int shift=0; shift<32; shift+= LegacyNumericUtils.PRECISION_STEP_DEFAULT) {
       assertTrue("New token is available", stream.incrementToken());
       assertEquals("Shift value wrong", shift, numericAtt.getShift());
-      assertEquals("Term is incorrectly encoded", ivalue & ~((1 << shift) - 1), NumericUtils.prefixCodedToInt(bytesAtt.getBytesRef()));
+      assertEquals("Term is incorrectly encoded", ivalue & ~((1 << shift) - 1), LegacyNumericUtils.prefixCodedToInt(bytesAtt.getBytesRef()));
       assertEquals("Term raw value is incorrectly encoded", ((long) ivalue) & ~((1L << shift) - 1L), numericAtt.getRawValue());
-      assertEquals("Type incorrect", (shift == 0) ? NumericTokenStream.TOKEN_TYPE_FULL_PREC : NumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());
+      assertEquals("Type incorrect", (shift == 0) ? LegacyNumericTokenStream.TOKEN_TYPE_FULL_PREC : LegacyNumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());
     }
     assertFalse("More tokens available", stream.incrementToken());
     stream.end();
@@ -77,7 +77,7 @@ public class TestNumericTokenStream extends BaseTokenStreamTestCase {
   }
   
   public void testNotInitialized() throws Exception {
-    final NumericTokenStream stream=new NumericTokenStream();
+    final LegacyNumericTokenStream stream=new LegacyNumericTokenStream();
     
     try {
       stream.reset();
@@ -100,28 +100,28 @@ public class TestNumericTokenStream extends BaseTokenStreamTestCase {
   public static class TestAttributeImpl extends CharTermAttributeImpl implements TestAttribute {}
   
   public void testCTA() throws Exception {
-    final NumericTokenStream stream=new NumericTokenStream();
+    final LegacyNumericTokenStream stream=new LegacyNumericTokenStream();
     try {
       stream.addAttribute(CharTermAttribute.class);
       fail("Succeeded to add CharTermAttribute.");
     } catch (IllegalArgumentException iae) {
-      assertTrue(iae.getMessage().startsWith("NumericTokenStream does not support"));
+      assertTrue(iae.getMessage().startsWith("LegacyNumericTokenStream does not support"));
     }
     try {
       stream.addAttribute(TestAttribute.class);
       fail("Succeeded to add TestAttribute.");
     } catch (IllegalArgumentException iae) {
-      assertTrue(iae.getMessage().startsWith("NumericTokenStream does not support"));
+      assertTrue(iae.getMessage().startsWith("LegacyNumericTokenStream does not support"));
     }
     stream.close();
   }
   
   public void testAttributeClone() throws Exception {
-    NumericTermAttributeImpl att = new NumericTermAttributeImpl();
+    LegacyNumericTermAttributeImpl att = new LegacyNumericTermAttributeImpl();
     att.init(1234L, 64, 8, 0); // set some value, to make getBytesRef() work
-    NumericTermAttributeImpl copy = TestCharTermAttributeImpl.assertCloneIsEqual(att);
+    LegacyNumericTermAttributeImpl copy = TestCharTermAttributeImpl.assertCloneIsEqual(att);
     assertNotSame(att.getBytesRef(), copy.getBytesRef());
-    NumericTermAttributeImpl copy2 = TestCharTermAttributeImpl.assertCopyIsEqual(att);
+    LegacyNumericTermAttributeImpl copy2 = TestCharTermAttributeImpl.assertCopyIsEqual(att);
     assertNotSame(att.getBytesRef(), copy2.getBytesRef());
   }
   
diff --git a/lucene/core/src/test/org/apache/lucene/document/TestDocument.java b/lucene/core/src/test/org/apache/lucene/document/TestDocument.java
index 5161e4d..4303dbb 100644
--- a/lucene/core/src/test/org/apache/lucene/document/TestDocument.java
+++ b/lucene/core/src/test/org/apache/lucene/document/TestDocument.java
@@ -360,10 +360,10 @@ public class TestDocument extends LuceneTestCase {
   
   public void testNumericFieldAsString() throws Exception {
     Document doc = new Document();
-    doc.add(new IntField("int", 5, Field.Store.YES));
+    doc.add(new LegacyIntField("int", 5, Field.Store.YES));
     assertEquals("5", doc.get("int"));
     assertNull(doc.get("somethingElse"));
-    doc.add(new IntField("int", 4, Field.Store.YES));
+    doc.add(new LegacyIntField("int", 4, Field.Store.YES));
     assertArrayEquals(new String[] { "5", "4" }, doc.getValues("int"));
     
     Directory dir = newDirectory();
diff --git a/lucene/core/src/test/org/apache/lucene/document/TestField.java b/lucene/core/src/test/org/apache/lucene/document/TestField.java
index 92cde76..cd58b1a 100644
--- a/lucene/core/src/test/org/apache/lucene/document/TestField.java
+++ b/lucene/core/src/test/org/apache/lucene/document/TestField.java
@@ -38,8 +38,8 @@ public class TestField extends LuceneTestCase {
   
   public void testDoubleField() throws Exception {
     Field fields[] = new Field[] {
-        new DoubleField("foo", 5d, Field.Store.NO),
-        new DoubleField("foo", 5d, Field.Store.YES)
+        new LegacyDoubleField("foo", 5d, Field.Store.NO),
+        new LegacyDoubleField("foo", 5d, Field.Store.YES)
     };
 
     for (Field field : fields) {
@@ -100,8 +100,8 @@ public class TestField extends LuceneTestCase {
   
   public void testFloatField() throws Exception {
     Field fields[] = new Field[] {
-        new FloatField("foo", 5f, Field.Store.NO),
-        new FloatField("foo", 5f, Field.Store.YES)
+        new LegacyFloatField("foo", 5f, Field.Store.NO),
+        new LegacyFloatField("foo", 5f, Field.Store.YES)
     };
 
     for (Field field : fields) {
@@ -124,8 +124,8 @@ public class TestField extends LuceneTestCase {
   
   public void testIntField() throws Exception {
     Field fields[] = new Field[] {
-        new IntField("foo", 5, Field.Store.NO),
-        new IntField("foo", 5, Field.Store.YES)
+        new LegacyIntField("foo", 5, Field.Store.NO),
+        new LegacyIntField("foo", 5, Field.Store.YES)
     };
 
     for (Field field : fields) {
@@ -167,8 +167,8 @@ public class TestField extends LuceneTestCase {
   
   public void testLongField() throws Exception {
     Field fields[] = new Field[] {
-        new LongField("foo", 5L, Field.Store.NO),
-        new LongField("foo", 5L, Field.Store.YES)
+        new LegacyLongField("foo", 5L, Field.Store.NO),
+        new LegacyLongField("foo", 5L, Field.Store.YES)
     };
 
     for (Field field : fields) {
diff --git a/lucene/core/src/test/org/apache/lucene/document/TestFieldType.java b/lucene/core/src/test/org/apache/lucene/document/TestFieldType.java
index 782187f..96eb42e 100644
--- a/lucene/core/src/test/org/apache/lucene/document/TestFieldType.java
+++ b/lucene/core/src/test/org/apache/lucene/document/TestFieldType.java
@@ -20,7 +20,7 @@ package org.apache.lucene.document;
 import java.lang.reflect.Method;
 import java.lang.reflect.Modifier;
 
-import org.apache.lucene.document.FieldType.NumericType;
+import org.apache.lucene.document.FieldType.LegacyNumericType;
 import org.apache.lucene.index.DocValuesType;
 import org.apache.lucene.index.IndexOptions;
 import org.apache.lucene.util.LuceneTestCase;
@@ -60,7 +60,7 @@ public class TestFieldType extends LuceneTestCase {
     assertFalse(ft7.equals(ft));
     
     FieldType ft8 = new FieldType();
-    ft8.setNumericType(NumericType.DOUBLE);
+    ft8.setNumericType(LegacyNumericType.DOUBLE);
     assertFalse(ft8.equals(ft));
     
     FieldType ft9 = new FieldType();
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader.java b/lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader.java
index 02e5af4..fa72fe9 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader.java
@@ -32,13 +32,13 @@ import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.atomic.AtomicLong;
 import java.util.regex.Pattern;
 
+import org.apache.lucene.document.DimensionalLongField;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
-import org.apache.lucene.document.LongField;
 import org.apache.lucene.document.NumericDocValuesField;
+import org.apache.lucene.search.DimensionalRangeQuery;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.MatchAllDocsQuery;
-import org.apache.lucene.search.NumericRangeQuery;
 import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.Sort;
 import org.apache.lucene.search.SortField;
@@ -681,7 +681,7 @@ public class TestDemoParallelLeafReader extends LuceneTestCase {
           Document newDoc = new Document();
           long value = Long.parseLong(oldDoc.get("text").split(" ")[1]);
           newDoc.add(new NumericDocValuesField("number", value));
-          newDoc.add(new LongField("number", value, Field.Store.NO));
+          newDoc.add(new DimensionalLongField("number", value));
           w.addDocument(newDoc);
         }
 
@@ -737,7 +737,7 @@ public class TestDemoParallelLeafReader extends LuceneTestCase {
             Document newDoc = new Document();
             long value = Long.parseLong(oldDoc.get("text").split(" ")[1]);
             newDoc.add(new NumericDocValuesField("number_" + newSchemaGen, value));
-            newDoc.add(new LongField("number", value, Field.Store.NO));
+            newDoc.add(new DimensionalLongField("number", value));
             w.addDocument(newDoc);
           }
         } else {
@@ -832,7 +832,7 @@ public class TestDemoParallelLeafReader extends LuceneTestCase {
             Document newDoc = new Document();
             long value = Long.parseLong(oldDoc.get("text").split(" ")[1]);
             newDoc.add(new NumericDocValuesField("number", newSchemaGen*value));
-            newDoc.add(new LongField("number", value, Field.Store.NO));
+            newDoc.add(new DimensionalLongField("number", value));
             w.addDocument(newDoc);
           }
         } else {
@@ -1168,7 +1168,7 @@ public class TestDemoParallelLeafReader extends LuceneTestCase {
       checkAllNumberDVs(r);
       IndexSearcher s = newSearcher(r);
       testNumericDVSort(s);
-      testNumericRangeQuery(s);
+      testDimensionalRangeQuery(s);
     } finally {
       reindexer.mgr.release(r);
     }
@@ -1190,7 +1190,7 @@ public class TestDemoParallelLeafReader extends LuceneTestCase {
       checkAllNumberDVs(r);
       IndexSearcher s = newSearcher(r);
       testNumericDVSort(s);
-      testNumericRangeQuery(s);
+      testDimensionalRangeQuery(s);
     } finally {
       reindexer.mgr.release(r);
     }
@@ -1209,7 +1209,7 @@ public class TestDemoParallelLeafReader extends LuceneTestCase {
       checkAllNumberDVs(r);
       IndexSearcher s = newSearcher(r);
       testNumericDVSort(s);
-      testNumericRangeQuery(s);
+      testDimensionalRangeQuery(s);
     } finally {
       reindexer.mgr.release(r);
     }
@@ -1261,7 +1261,7 @@ public class TestDemoParallelLeafReader extends LuceneTestCase {
           checkAllNumberDVs(r);
           IndexSearcher s = newSearcher(r);
           testNumericDVSort(s);
-          testNumericRangeQuery(s);
+          testDimensionalRangeQuery(s);
         } finally {
           reindexer.mgr.release(r);
         }
@@ -1340,7 +1340,7 @@ public class TestDemoParallelLeafReader extends LuceneTestCase {
     }
   }
 
-  private static void testNumericRangeQuery(IndexSearcher s) throws IOException {
+  private static void testDimensionalRangeQuery(IndexSearcher s) throws IOException {
     NumericDocValues numbers = MultiDocValues.getNumericValues(s.getIndexReader(), "number");
     for(int i=0;i<100;i++) {
       // Confirm we can range search by the new indexed (numeric) field:
@@ -1352,7 +1352,7 @@ public class TestDemoParallelLeafReader extends LuceneTestCase {
         max = x;
       }
 
-      TopDocs hits = s.search(NumericRangeQuery.newLongRange("number", min, max, true, true), 100);
+      TopDocs hits = s.search(DimensionalRangeQuery.new1DLongRange("number", min, true, max, true), 100);
       for(ScoreDoc scoreDoc : hits.scoreDocs) {
         long value = Long.parseLong(s.doc(scoreDoc.doc).get("text").split(" ")[1]);
         assertTrue(value >= min);
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestDimensionalValues.java b/lucene/core/src/test/org/apache/lucene/index/TestDimensionalValues.java
index 1bb6da1..05dd3a9 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestDimensionalValues.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestDimensionalValues.java
@@ -31,7 +31,8 @@ import org.apache.lucene.codecs.DimensionalWriter;
 import org.apache.lucene.codecs.FilterCodec;
 import org.apache.lucene.codecs.lucene60.Lucene60DimensionalReader;
 import org.apache.lucene.codecs.lucene60.Lucene60DimensionalWriter;
-import org.apache.lucene.document.DimensionalField;
+import org.apache.lucene.document.DimensionalBinaryField;
+import org.apache.lucene.document.DimensionalIntField;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.NumericDocValuesField;
@@ -44,9 +45,8 @@ import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.NumericUtils;
 import org.apache.lucene.util.TestUtil;
-import org.apache.lucene.util.bkd.BKDUtil;
-import org.apache.lucene.util.bkd.BKDWriter;
 
 // TODO: factor out a BaseTestDimensionFormat
 
@@ -60,8 +60,8 @@ public class TestDimensionalValues extends LuceneTestCase {
     byte[] point = new byte[4];
     for(int i=0;i<20;i++) {
       Document doc = new Document();
-      BKDUtil.intToBytes(i, point, 0);
-      doc.add(new DimensionalField("dim", point));
+      NumericUtils.intToBytes(i, point, 0);
+      doc.add(new DimensionalBinaryField("dim", point));
       w.addDocument(doc);
     }
     w.forceMerge(1);
@@ -84,7 +84,7 @@ public class TestDimensionalValues extends LuceneTestCase {
                        }
                        public void visit(int docID, byte[] packedValue) {
                          seen.set(docID);
-                         assertEquals(docID, BKDUtil.bytesToInt(packedValue, 0));
+                         assertEquals(docID, NumericUtils.bytesToInt(packedValue, 0));
                        }
                      });
     assertEquals(20, seen.cardinality());
@@ -99,8 +99,8 @@ public class TestDimensionalValues extends LuceneTestCase {
     byte[] point = new byte[4];
     for(int i=0;i<20;i++) {
       Document doc = new Document();
-      BKDUtil.intToBytes(i, point, 0);
-      doc.add(new DimensionalField("dim", point));
+      NumericUtils.intToBytes(i, point, 0);
+      doc.add(new DimensionalBinaryField("dim", point));
       w.addDocument(doc);
       if (i == 10) {
         w.commit();
@@ -126,7 +126,7 @@ public class TestDimensionalValues extends LuceneTestCase {
                        }
                        public void visit(int docID, byte[] packedValue) {
                          seen.set(docID);
-                         assertEquals(docID, BKDUtil.bytesToInt(packedValue, 0));
+                         assertEquals(docID, NumericUtils.bytesToInt(packedValue, 0));
                        }
                      });
     assertEquals(20, seen.cardinality());
@@ -140,8 +140,8 @@ public class TestDimensionalValues extends LuceneTestCase {
     byte[] point = new byte[4];
     for(int i=0;i<10;i++) {
       Document doc = new Document();
-      BKDUtil.intToBytes(i, point, 0);
-      doc.add(new DimensionalField("dim", point));
+      NumericUtils.intToBytes(i, point, 0);
+      doc.add(new DimensionalBinaryField("dim", point));
       doc.add(new NumericDocValuesField("id", i));
       doc.add(newStringField("x", "x", Field.Store.NO));
       w.addDocument(doc);
@@ -173,7 +173,7 @@ public class TestDimensionalValues extends LuceneTestCase {
                            if (liveDocs.get(docID)) {
                              seen.set(docID);
                            }
-                           assertEquals(idValues.get(docID), BKDUtil.bytesToInt(packedValue, 0));
+                           assertEquals(idValues.get(docID), NumericUtils.bytesToInt(packedValue, 0));
                          }
                        });
       assertEquals(0, seen.cardinality());
@@ -184,8 +184,8 @@ public class TestDimensionalValues extends LuceneTestCase {
   /** Make sure we close open files, delete temp files, etc., on exception */
   public void testWithExceptions() throws Exception {
     int numDocs = atLeast(10000);
-    int numBytesPerDim = TestUtil.nextInt(random(), 2, 30);
-    int numDims = TestUtil.nextInt(random(), 1, 5);
+    int numBytesPerDim = TestUtil.nextInt(random(), 2, DimensionalValues.MAX_NUM_BYTES);
+    int numDims = TestUtil.nextInt(random(), 1, DimensionalValues.MAX_DIMENSIONS);
 
     byte[][][] docValues = new byte[numDocs][][];
 
@@ -244,8 +244,8 @@ public class TestDimensionalValues extends LuceneTestCase {
   }
 
   public void testMultiValued() throws Exception {
-    int numBytesPerDim = TestUtil.nextInt(random(), 2, 30);
-    int numDims = TestUtil.nextInt(random(), 1, 5);
+    int numBytesPerDim = TestUtil.nextInt(random(), 2, DimensionalValues.MAX_NUM_BYTES);
+    int numDims = TestUtil.nextInt(random(), 1, DimensionalValues.MAX_DIMENSIONS);
 
     int numDocs = atLeast(1000);
     List<byte[][]> docValues = new ArrayList<>();
@@ -274,8 +274,8 @@ public class TestDimensionalValues extends LuceneTestCase {
   }
 
   public void testAllEqual() throws Exception {
-    int numBytesPerDim = TestUtil.nextInt(random(), 2, 30);
-    int numDims = TestUtil.nextInt(random(), 1, 5);
+    int numBytesPerDim = TestUtil.nextInt(random(), 2, DimensionalValues.MAX_NUM_BYTES);
+    int numDims = TestUtil.nextInt(random(), 1, DimensionalValues.MAX_DIMENSIONS);
 
     int numDocs = atLeast(1000);
     byte[][][] docValues = new byte[numDocs][][];
@@ -297,8 +297,8 @@ public class TestDimensionalValues extends LuceneTestCase {
   }
 
   public void testOneDimEqual() throws Exception {
-    int numBytesPerDim = TestUtil.nextInt(random(), 2, 30);
-    int numDims = TestUtil.nextInt(random(), 1, 5);
+    int numBytesPerDim = TestUtil.nextInt(random(), 2, DimensionalValues.MAX_NUM_BYTES);
+    int numDims = TestUtil.nextInt(random(), 1, DimensionalValues.MAX_DIMENSIONS);
 
     int numDocs = atLeast(1000);
     int theEqualDim = random().nextInt(numDims);
@@ -324,8 +324,8 @@ public class TestDimensionalValues extends LuceneTestCase {
 
     int numDocs = atLeast(1000);
     try (Directory dir = getDirectory(numDocs)) {
-      int numBytesPerDim = TestUtil.nextInt(random(), 2, 30);
-      int numDims = TestUtil.nextInt(random(), 1, 5);
+      int numBytesPerDim = TestUtil.nextInt(random(), 2, DimensionalValues.MAX_NUM_BYTES);
+      int numDims = TestUtil.nextInt(random(), 1, DimensionalValues.MAX_DIMENSIONS);
       IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));
       // We rely on docIDs not changing:
       iwc.setMergePolicy(newLogMergePolicy());
@@ -341,14 +341,14 @@ public class TestDimensionalValues extends LuceneTestCase {
         for(int dim=0;dim<numDims;dim++) {
           values[dim] = randomBigInt(numBytesPerDim);
           bytes[dim] = new byte[numBytesPerDim];
-          BKDUtil.bigIntToBytes(values[dim], bytes[dim], 0, numBytesPerDim);
+          NumericUtils.bigIntToBytes(values[dim], bytes[dim], 0, numBytesPerDim);
           if (VERBOSE) {
             System.out.println("    " + dim + " -> " + values[dim]);
           }
         }
         docs[docID] = values;
         Document doc = new Document();
-        doc.add(new DimensionalField("field", bytes));
+        doc.add(new DimensionalBinaryField("field", bytes));
         w.addDocument(doc);
       }
 
@@ -391,7 +391,7 @@ public class TestDimensionalValues extends LuceneTestCase {
             public void visit(int docID, byte[] packedValue) {
               //System.out.println("visit check docID=" + docID);
               for(int dim=0;dim<numDims;dim++) {
-                BigInteger x = BKDUtil.bytesToBigInt(packedValue, dim, numBytesPerDim);
+                BigInteger x = NumericUtils.bytesToBigInt(packedValue, dim, numBytesPerDim);
                 if (x.compareTo(queryMin[dim]) < 0 || x.compareTo(queryMax[dim]) > 0) {
                   //System.out.println("  no");
                   return;
@@ -406,8 +406,8 @@ public class TestDimensionalValues extends LuceneTestCase {
             public Relation compare(byte[] minPacked, byte[] maxPacked) {
               boolean crosses = false;
               for(int dim=0;dim<numDims;dim++) {
-                BigInteger min = BKDUtil.bytesToBigInt(minPacked, dim, numBytesPerDim);
-                BigInteger max = BKDUtil.bytesToBigInt(maxPacked, dim, numBytesPerDim);
+                BigInteger min = NumericUtils.bytesToBigInt(minPacked, dim, numBytesPerDim);
+                BigInteger max = NumericUtils.bytesToBigInt(maxPacked, dim, numBytesPerDim);
                 assert max.compareTo(min) >= 0;
 
                 if (max.compareTo(queryMin[dim]) < 0 || min.compareTo(queryMax[dim]) > 0) {
@@ -469,7 +469,7 @@ public class TestDimensionalValues extends LuceneTestCase {
     
     iwc = newIndexWriterConfig();
     w = new IndexWriter(dir, iwc);
-    doc.add(new DimensionalField("dim", new byte[4]));
+    doc.add(new DimensionalBinaryField("dim", new byte[4]));
     w.close();
     dir.close();
   }
@@ -481,8 +481,8 @@ public class TestDimensionalValues extends LuceneTestCase {
     IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));
     IndexWriter w = new IndexWriter(dir, iwc);
     Document doc = new Document();
-    doc.add(new DimensionalField("dim", new byte[4]));
-    doc.add(new DimensionalField("dim", new byte[4], new byte[4]));
+    doc.add(new DimensionalBinaryField("dim", new byte[4]));
+    doc.add(new DimensionalBinaryField("dim", new byte[4], new byte[4]));
     try {
       w.addDocument(doc);
     } catch (IllegalArgumentException iae) {
@@ -498,10 +498,10 @@ public class TestDimensionalValues extends LuceneTestCase {
     IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));
     IndexWriter w = new IndexWriter(dir, iwc);
     Document doc = new Document();
-    doc.add(new DimensionalField("dim", new byte[4]));
+    doc.add(new DimensionalBinaryField("dim", new byte[4]));
     w.addDocument(doc);
     doc = new Document();
-    doc.add(new DimensionalField("dim", new byte[4], new byte[4]));
+    doc.add(new DimensionalBinaryField("dim", new byte[4], new byte[4]));
     try {
       w.addDocument(doc);
     } catch (IllegalArgumentException iae) {
@@ -517,11 +517,11 @@ public class TestDimensionalValues extends LuceneTestCase {
     IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));
     IndexWriter w = new IndexWriter(dir, iwc);
     Document doc = new Document();
-    doc.add(new DimensionalField("dim", new byte[4]));
+    doc.add(new DimensionalBinaryField("dim", new byte[4]));
     w.addDocument(doc);
     w.commit();
     doc = new Document();
-    doc.add(new DimensionalField("dim", new byte[4], new byte[4]));
+    doc.add(new DimensionalBinaryField("dim", new byte[4], new byte[4]));
     try {
       w.addDocument(doc);
     } catch (IllegalArgumentException iae) {
@@ -537,13 +537,13 @@ public class TestDimensionalValues extends LuceneTestCase {
     IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));
     IndexWriter w = new IndexWriter(dir, iwc);
     Document doc = new Document();
-    doc.add(new DimensionalField("dim", new byte[4]));
+    doc.add(new DimensionalBinaryField("dim", new byte[4]));
     w.addDocument(doc);
     w.close();
     iwc = new IndexWriterConfig(new MockAnalyzer(random()));
     w = new IndexWriter(dir, iwc);
     doc = new Document();
-    doc.add(new DimensionalField("dim", new byte[4], new byte[4]));
+    doc.add(new DimensionalBinaryField("dim", new byte[4], new byte[4]));
     try {
       w.addDocument(doc);
     } catch (IllegalArgumentException iae) {
@@ -559,7 +559,7 @@ public class TestDimensionalValues extends LuceneTestCase {
     IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));
     IndexWriter w = new IndexWriter(dir, iwc);
     Document doc = new Document();
-    doc.add(new DimensionalField("dim", new byte[4]));
+    doc.add(new DimensionalBinaryField("dim", new byte[4]));
     w.addDocument(doc);
     w.close();
 
@@ -567,7 +567,7 @@ public class TestDimensionalValues extends LuceneTestCase {
     iwc = new IndexWriterConfig(new MockAnalyzer(random()));
     w = new IndexWriter(dir2, iwc);
     doc = new Document();
-    doc.add(new DimensionalField("dim", new byte[4], new byte[4]));
+    doc.add(new DimensionalBinaryField("dim", new byte[4], new byte[4]));
     w.addDocument(doc);
     try {
       w.addIndexes(new Directory[] {dir});
@@ -582,7 +582,7 @@ public class TestDimensionalValues extends LuceneTestCase {
     IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));
     IndexWriter w = new IndexWriter(dir, iwc);
     Document doc = new Document();
-    doc.add(new DimensionalField("dim", new byte[4]));
+    doc.add(new DimensionalBinaryField("dim", new byte[4]));
     w.addDocument(doc);
     w.close();
 
@@ -590,7 +590,7 @@ public class TestDimensionalValues extends LuceneTestCase {
     iwc = new IndexWriterConfig(new MockAnalyzer(random()));
     w = new IndexWriter(dir2, iwc);
     doc = new Document();
-    doc.add(new DimensionalField("dim", new byte[4], new byte[4]));
+    doc.add(new DimensionalBinaryField("dim", new byte[4], new byte[4]));
     w.addDocument(doc);
     DirectoryReader r = DirectoryReader.open(dir);
     try {
@@ -606,7 +606,7 @@ public class TestDimensionalValues extends LuceneTestCase {
     IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));
     IndexWriter w = new IndexWriter(dir, iwc);
     Document doc = new Document();
-    doc.add(new DimensionalField("dim", new byte[4]));
+    doc.add(new DimensionalBinaryField("dim", new byte[4]));
     w.addDocument(doc);
     w.close();
 
@@ -614,7 +614,7 @@ public class TestDimensionalValues extends LuceneTestCase {
     iwc = new IndexWriterConfig(new MockAnalyzer(random()));
     w = new IndexWriter(dir2, iwc);
     doc = new Document();
-    doc.add(new DimensionalField("dim", new byte[4], new byte[4]));
+    doc.add(new DimensionalBinaryField("dim", new byte[4], new byte[4]));
     w.addDocument(doc);
     DirectoryReader r = DirectoryReader.open(dir);
     try {
@@ -625,33 +625,13 @@ public class TestDimensionalValues extends LuceneTestCase {
     IOUtils.close(r, w, dir, dir2);
   }
 
-  public void testIllegalTooManyDimensions() throws Exception {
-    Directory dir = getDirectory(1);
-    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));
-    IndexWriter w = new IndexWriter(dir, iwc);
-    Document doc = new Document();
-    byte[][] values = new byte[BKDWriter.MAX_DIMS+1][];
-    for(int i=0;i<values.length;i++) {
-      values[i] = new byte[4];
-    }
-    doc.add(new DimensionalField("dim", values));
-    w.addDocument(doc);
-    try {
-      w.close();
-    } catch (IllegalArgumentException iae) {
-      // expected
-      assertEquals("numDims must be 1 .. 255 (got: 256)", iae.getMessage());
-    }
-    dir.close();
-  }
-
   public void testIllegalNumBytesChangeOneDoc() throws Exception {
     Directory dir = getDirectory(1);
     IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));
     IndexWriter w = new IndexWriter(dir, iwc);
     Document doc = new Document();
-    doc.add(new DimensionalField("dim", new byte[4]));
-    doc.add(new DimensionalField("dim", new byte[6]));
+    doc.add(new DimensionalBinaryField("dim", new byte[4]));
+    doc.add(new DimensionalBinaryField("dim", new byte[6]));
     try {
       w.addDocument(doc);
     } catch (IllegalArgumentException iae) {
@@ -667,10 +647,10 @@ public class TestDimensionalValues extends LuceneTestCase {
     IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));
     IndexWriter w = new IndexWriter(dir, iwc);
     Document doc = new Document();
-    doc.add(new DimensionalField("dim", new byte[4]));
+    doc.add(new DimensionalBinaryField("dim", new byte[4]));
     w.addDocument(doc);
     doc = new Document();
-    doc.add(new DimensionalField("dim", new byte[6]));
+    doc.add(new DimensionalBinaryField("dim", new byte[6]));
     try {
       w.addDocument(doc);
     } catch (IllegalArgumentException iae) {
@@ -686,11 +666,11 @@ public class TestDimensionalValues extends LuceneTestCase {
     IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));
     IndexWriter w = new IndexWriter(dir, iwc);
     Document doc = new Document();
-    doc.add(new DimensionalField("dim", new byte[4]));
+    doc.add(new DimensionalBinaryField("dim", new byte[4]));
     w.addDocument(doc);
     w.commit();
     doc = new Document();
-    doc.add(new DimensionalField("dim", new byte[6]));
+    doc.add(new DimensionalBinaryField("dim", new byte[6]));
     try {
       w.addDocument(doc);
     } catch (IllegalArgumentException iae) {
@@ -706,13 +686,13 @@ public class TestDimensionalValues extends LuceneTestCase {
     IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));
     IndexWriter w = new IndexWriter(dir, iwc);
     Document doc = new Document();
-    doc.add(new DimensionalField("dim", new byte[4]));
+    doc.add(new DimensionalBinaryField("dim", new byte[4]));
     w.addDocument(doc);
     w.close();
     iwc = new IndexWriterConfig(new MockAnalyzer(random()));
     w = new IndexWriter(dir, iwc);
     doc = new Document();
-    doc.add(new DimensionalField("dim", new byte[6]));
+    doc.add(new DimensionalBinaryField("dim", new byte[6]));
     try {
       w.addDocument(doc);
     } catch (IllegalArgumentException iae) {
@@ -728,7 +708,7 @@ public class TestDimensionalValues extends LuceneTestCase {
     IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));
     IndexWriter w = new IndexWriter(dir, iwc);
     Document doc = new Document();
-    doc.add(new DimensionalField("dim", new byte[4]));
+    doc.add(new DimensionalBinaryField("dim", new byte[4]));
     w.addDocument(doc);
     w.close();
 
@@ -736,7 +716,7 @@ public class TestDimensionalValues extends LuceneTestCase {
     iwc = new IndexWriterConfig(new MockAnalyzer(random()));
     w = new IndexWriter(dir2, iwc);
     doc = new Document();
-    doc.add(new DimensionalField("dim", new byte[6]));
+    doc.add(new DimensionalBinaryField("dim", new byte[6]));
     w.addDocument(doc);
     try {
       w.addIndexes(new Directory[] {dir});
@@ -751,7 +731,7 @@ public class TestDimensionalValues extends LuceneTestCase {
     IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));
     IndexWriter w = new IndexWriter(dir, iwc);
     Document doc = new Document();
-    doc.add(new DimensionalField("dim", new byte[4]));
+    doc.add(new DimensionalBinaryField("dim", new byte[4]));
     w.addDocument(doc);
     w.close();
 
@@ -759,7 +739,7 @@ public class TestDimensionalValues extends LuceneTestCase {
     iwc = new IndexWriterConfig(new MockAnalyzer(random()));
     w = new IndexWriter(dir2, iwc);
     doc = new Document();
-    doc.add(new DimensionalField("dim", new byte[6]));
+    doc.add(new DimensionalBinaryField("dim", new byte[6]));
     w.addDocument(doc);
     DirectoryReader r = DirectoryReader.open(dir);
     try {
@@ -775,7 +755,7 @@ public class TestDimensionalValues extends LuceneTestCase {
     IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));
     IndexWriter w = new IndexWriter(dir, iwc);
     Document doc = new Document();
-    doc.add(new DimensionalField("dim", new byte[4]));
+    doc.add(new DimensionalBinaryField("dim", new byte[4]));
     w.addDocument(doc);
     w.close();
 
@@ -783,7 +763,7 @@ public class TestDimensionalValues extends LuceneTestCase {
     iwc = new IndexWriterConfig(new MockAnalyzer(random()));
     w = new IndexWriter(dir2, iwc);
     doc = new Document();
-    doc.add(new DimensionalField("dim", new byte[6]));
+    doc.add(new DimensionalBinaryField("dim", new byte[6]));
     w.addDocument(doc);
     DirectoryReader r = DirectoryReader.open(dir);
     try {
@@ -794,10 +774,52 @@ public class TestDimensionalValues extends LuceneTestCase {
     IOUtils.close(r, w, dir, dir2);
   }
 
+  public void testIllegalTooManyBytes() throws Exception {
+    Directory dir = getDirectory(1);
+    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));
+    IndexWriter w = new IndexWriter(dir, iwc);
+    Document doc = new Document();
+    doc.add(new DimensionalBinaryField("dim", new byte[DimensionalValues.MAX_NUM_BYTES+1]));
+    try {
+      w.addDocument(doc);
+      fail("did not hit exception");
+    } catch (IllegalArgumentException iae) {
+      // expected
+    }
+    doc = new Document();
+    doc.add(new DimensionalIntField("dim", 17));
+    w.addDocument(doc);
+    w.close();
+    dir.close();
+  }
+
+  public void testIllegalTooManyDimensions() throws Exception {
+    Directory dir = getDirectory(1);
+    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));
+    IndexWriter w = new IndexWriter(dir, iwc);
+    Document doc = new Document();
+    byte[][] values = new byte[DimensionalValues.MAX_DIMENSIONS+1][];
+    for(int i=0;i<values.length;i++) {
+      values[i] = new byte[4];
+    }
+    doc.add(new DimensionalBinaryField("dim", values));
+    try {
+      w.addDocument(doc);
+      fail("did not hit exception");
+    } catch (IllegalArgumentException iae) {
+      // expected
+    }
+    doc = new Document();
+    doc.add(new DimensionalIntField("dim", 17));
+    w.addDocument(doc);
+    w.close();
+    dir.close();
+  }
+
   private void doTestRandomBinary(int count) throws Exception {
     int numDocs = TestUtil.nextInt(random(), count, count*2);
-    int numBytesPerDim = TestUtil.nextInt(random(), 2, 30);
-    int numDims = TestUtil.nextInt(random(), 1, 5);
+    int numBytesPerDim = TestUtil.nextInt(random(), 2, DimensionalValues.MAX_NUM_BYTES);
+    int numDims = TestUtil.nextInt(random(), 1, DimensionalValues.MAX_DIMENSIONS);
 
     byte[][][] docValues = new byte[numDocs][][];
 
@@ -935,7 +957,7 @@ public class TestDimensionalValues extends LuceneTestCase {
           doc = new Document();
           doc.add(new NumericDocValuesField("id", id));
         }
-        doc.add(new DimensionalField("field", docValues[ord]));
+        doc.add(new DimensionalBinaryField("field", docValues[ord]));
         lastID = id;
 
         if (random().nextInt(30) == 17) {
@@ -953,7 +975,7 @@ public class TestDimensionalValues extends LuceneTestCase {
         if (random().nextInt(30) == 17) {
           // randomly index some documents with this field, but we will delete them:
           Document xdoc = new Document();
-          xdoc.add(new DimensionalField("field", docValues[ord]));
+          xdoc.add(new DimensionalBinaryField("field", docValues[ord]));
           xdoc.add(new StringField("nukeme", "yes", Field.Store.NO));
           if (useRealWriter) {
             w.w.addDocument(xdoc);
@@ -1028,7 +1050,7 @@ public class TestDimensionalValues extends LuceneTestCase {
           random().nextBytes(queryMin[dim]);
           queryMax[dim] = new byte[numBytesPerDim];
           random().nextBytes(queryMax[dim]);
-          if (BKDUtil.compare(numBytesPerDim, queryMin[dim], 0, queryMax[dim], 0) > 0) {
+          if (NumericUtils.compare(numBytesPerDim, queryMin[dim], 0, queryMax[dim], 0) > 0) {
             byte[] x = queryMin[dim];
             queryMin[dim] = queryMax[dim];
             queryMax[dim] = x;
@@ -1060,8 +1082,8 @@ public class TestDimensionalValues extends LuceneTestCase {
               //System.out.println("visit check docID=" + docID + " id=" + idValues.get(docID));
               for(int dim=0;dim<numDims;dim++) {
                 //System.out.println("  dim=" + dim + " value=" + new BytesRef(packedValue, dim*numBytesPerDim, numBytesPerDim));
-                if (BKDUtil.compare(numBytesPerDim, packedValue, dim, queryMin[dim], 0) < 0 ||
-                    BKDUtil.compare(numBytesPerDim, packedValue, dim, queryMax[dim], 0) > 0) {
+                if (NumericUtils.compare(numBytesPerDim, packedValue, dim, queryMin[dim], 0) < 0 ||
+                    NumericUtils.compare(numBytesPerDim, packedValue, dim, queryMax[dim], 0) > 0) {
                   //System.out.println("  no");
                   return;
                 }
@@ -1076,12 +1098,12 @@ public class TestDimensionalValues extends LuceneTestCase {
               boolean crosses = false;
               //System.out.println("compare");
               for(int dim=0;dim<numDims;dim++) {
-                if (BKDUtil.compare(numBytesPerDim, maxPacked, dim, queryMin[dim], 0) < 0 ||
-                    BKDUtil.compare(numBytesPerDim, minPacked, dim, queryMax[dim], 0) > 0) {
+                if (NumericUtils.compare(numBytesPerDim, maxPacked, dim, queryMin[dim], 0) < 0 ||
+                    NumericUtils.compare(numBytesPerDim, minPacked, dim, queryMax[dim], 0) > 0) {
                   //System.out.println("  query_outside_cell");
                   return Relation.CELL_OUTSIDE_QUERY;
-                } else if (BKDUtil.compare(numBytesPerDim, minPacked, dim, queryMin[dim], 0) < 0 ||
-                           BKDUtil.compare(numBytesPerDim, maxPacked, dim, queryMax[dim], 0) > 0) {
+                } else if (NumericUtils.compare(numBytesPerDim, minPacked, dim, queryMin[dim], 0) < 0 ||
+                           NumericUtils.compare(numBytesPerDim, maxPacked, dim, queryMax[dim], 0) > 0) {
                   crosses = true;
                 }
               }
@@ -1101,8 +1123,8 @@ public class TestDimensionalValues extends LuceneTestCase {
           boolean matches = true;
           for(int dim=0;dim<numDims;dim++) {
             byte[] x = docValues[ord][dim];
-            if (BKDUtil.compare(numBytesPerDim, x, 0, queryMin[dim], 0) < 0 ||
-                BKDUtil.compare(numBytesPerDim, x, 0, queryMax[dim], 0) > 0) {
+            if (NumericUtils.compare(numBytesPerDim, x, 0, queryMin[dim], 0) < 0 ||
+                NumericUtils.compare(numBytesPerDim, x, 0, queryMax[dim], 0) > 0) {
               matches = false;
               break;
             }
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestFieldReuse.java b/lucene/core/src/test/org/apache/lucene/index/TestFieldReuse.java
index 68cd6a8..10d8000 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestFieldReuse.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestFieldReuse.java
@@ -23,15 +23,15 @@ import java.util.Collections;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.CannedTokenStream;
-import org.apache.lucene.analysis.NumericTokenStream;
-import org.apache.lucene.analysis.NumericTokenStream.NumericTermAttribute;
+import org.apache.lucene.analysis.LegacyNumericTokenStream;
+import org.apache.lucene.analysis.LegacyNumericTokenStream.LegacyNumericTermAttribute;
 import org.apache.lucene.analysis.Token;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.document.Field;
-import org.apache.lucene.document.IntField;
+import org.apache.lucene.document.LegacyIntField;
 import org.apache.lucene.document.StringField;
 import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.NumericUtils;
+import org.apache.lucene.util.LegacyNumericUtils;
 
 /** test tokenstream reuse by DefaultIndexingChain */
 public class TestFieldReuse extends BaseTokenStreamTestCase {
@@ -59,7 +59,7 @@ public class TestFieldReuse extends BaseTokenStreamTestCase {
     
     // pass a bogus stream and ensure it's still ok
     stringField = new StringField("foo", "beer", Field.Store.NO);
-    TokenStream bogus = new NumericTokenStream();
+    TokenStream bogus = new LegacyNumericTokenStream();
     ts = stringField.tokenStream(null, bogus);
     assertNotSame(ts, bogus);
     assertTokenStreamContents(ts, 
@@ -70,32 +70,32 @@ public class TestFieldReuse extends BaseTokenStreamTestCase {
   }
   
   public void testNumericReuse() throws IOException {
-    IntField intField = new IntField("foo", 5, Field.Store.NO);
+    LegacyIntField legacyIntField = new LegacyIntField("foo", 5, Field.Store.NO);
     
     // passing null
-    TokenStream ts = intField.tokenStream(null, null);
-    assertTrue(ts instanceof NumericTokenStream);
-    assertEquals(NumericUtils.PRECISION_STEP_DEFAULT_32, ((NumericTokenStream)ts).getPrecisionStep());
+    TokenStream ts = legacyIntField.tokenStream(null, null);
+    assertTrue(ts instanceof LegacyNumericTokenStream);
+    assertEquals(LegacyNumericUtils.PRECISION_STEP_DEFAULT_32, ((LegacyNumericTokenStream)ts).getPrecisionStep());
     assertNumericContents(5, ts);
 
     // now reuse previous stream
-    intField = new IntField("foo", 20, Field.Store.NO);
-    TokenStream ts2 = intField.tokenStream(null, ts);
+    legacyIntField = new LegacyIntField("foo", 20, Field.Store.NO);
+    TokenStream ts2 = legacyIntField.tokenStream(null, ts);
     assertSame(ts, ts2);
     assertNumericContents(20, ts);
     
     // pass a bogus stream and ensure it's still ok
-    intField = new IntField("foo", 2343, Field.Store.NO);
+    legacyIntField = new LegacyIntField("foo", 2343, Field.Store.NO);
     TokenStream bogus = new CannedTokenStream(new Token("bogus", 0, 5));
-    ts = intField.tokenStream(null, bogus);
+    ts = legacyIntField.tokenStream(null, bogus);
     assertNotSame(bogus, ts);
     assertNumericContents(2343, ts);
     
     // pass another bogus stream (numeric, but different precision step!)
-    intField = new IntField("foo", 42, Field.Store.NO);
-    assert 3 != NumericUtils.PRECISION_STEP_DEFAULT;
-    bogus = new NumericTokenStream(3);
-    ts = intField.tokenStream(null, bogus);
+    legacyIntField = new LegacyIntField("foo", 42, Field.Store.NO);
+    assert 3 != LegacyNumericUtils.PRECISION_STEP_DEFAULT;
+    bogus = new LegacyNumericTokenStream(3);
+    ts = legacyIntField.tokenStream(null, bogus);
     assertNotSame(bogus, ts);
     assertNumericContents(42, ts);
   }
@@ -161,8 +161,8 @@ public class TestFieldReuse extends BaseTokenStreamTestCase {
   }
   
   private void assertNumericContents(int value, TokenStream ts) throws IOException {
-    assertTrue(ts instanceof NumericTokenStream);
-    NumericTermAttribute numericAtt = ts.getAttribute(NumericTermAttribute.class);
+    assertTrue(ts instanceof LegacyNumericTokenStream);
+    LegacyNumericTermAttribute numericAtt = ts.getAttribute(LegacyNumericTermAttribute.class);
     ts.reset();
     boolean seen = false;
     while (ts.incrementToken()) {
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets.java b/lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets.java
index 9b995f3..d81225c 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets.java
@@ -33,7 +33,6 @@ import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.FieldType;
-import org.apache.lucene.document.IntField;
 import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.document.StringField;
 import org.apache.lucene.document.TextField;
@@ -239,7 +238,6 @@ public class TestPostingsOffsets extends LuceneTestCase {
 
     for(int docCount=0;docCount<numDocs;docCount++) {
       Document doc = new Document();
-      doc.add(new IntField("id", docCount, Field.Store.YES));
       doc.add(new NumericDocValuesField("id", docCount));
       List<Token> tokens = new ArrayList<>();
       final int numTokens = atLeast(100);
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestTerms.java b/lucene/core/src/test/org/apache/lucene/index/TestTerms.java
index 617ec34..23f83e0 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestTerms.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestTerms.java
@@ -17,20 +17,18 @@ package org.apache.lucene.index;
  * limitations under the License.
  */
 
-import java.util.*;
-
 import org.apache.lucene.analysis.CannedBinaryTokenStream;
 import org.apache.lucene.document.Document;
-import org.apache.lucene.document.DoubleField;
+import org.apache.lucene.document.LegacyDoubleField;
 import org.apache.lucene.document.Field;
-import org.apache.lucene.document.FloatField;
-import org.apache.lucene.document.IntField;
-import org.apache.lucene.document.LongField;
+import org.apache.lucene.document.LegacyFloatField;
+import org.apache.lucene.document.LegacyIntField;
+import org.apache.lucene.document.LegacyLongField;
 import org.apache.lucene.document.TextField;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.LegacyNumericUtils;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util.NumericUtils;
 import org.apache.lucene.util.TestUtil;
 
 public class TestTerms extends LuceneTestCase {
@@ -92,8 +90,8 @@ public class TestTerms extends LuceneTestCase {
   }
 
   public void testEmptyIntFieldMinMax() throws Exception {
-    assertNull(NumericUtils.getMinInt(EMPTY_TERMS));
-    assertNull(NumericUtils.getMaxInt(EMPTY_TERMS));
+    assertNull(LegacyNumericUtils.getMinInt(EMPTY_TERMS));
+    assertNull(LegacyNumericUtils.getMaxInt(EMPTY_TERMS));
   }
   
   public void testIntFieldMinMax() throws Exception {
@@ -107,14 +105,14 @@ public class TestTerms extends LuceneTestCase {
       int num = random().nextInt();
       minValue = Math.min(num, minValue);
       maxValue = Math.max(num, maxValue);
-      doc.add(new IntField("field", num, Field.Store.NO));
+      doc.add(new LegacyIntField("field", num, Field.Store.NO));
       w.addDocument(doc);
     }
     
     IndexReader r = w.getReader();
     Terms terms = MultiFields.getTerms(r, "field");
-    assertEquals(new Integer(minValue), NumericUtils.getMinInt(terms));
-    assertEquals(new Integer(maxValue), NumericUtils.getMaxInt(terms));
+    assertEquals(new Integer(minValue), LegacyNumericUtils.getMinInt(terms));
+    assertEquals(new Integer(maxValue), LegacyNumericUtils.getMaxInt(terms));
 
     r.close();
     w.close();
@@ -122,8 +120,8 @@ public class TestTerms extends LuceneTestCase {
   }
 
   public void testEmptyLongFieldMinMax() throws Exception {
-    assertNull(NumericUtils.getMinLong(EMPTY_TERMS));
-    assertNull(NumericUtils.getMaxLong(EMPTY_TERMS));
+    assertNull(LegacyNumericUtils.getMinLong(EMPTY_TERMS));
+    assertNull(LegacyNumericUtils.getMaxLong(EMPTY_TERMS));
   }
   
   public void testLongFieldMinMax() throws Exception {
@@ -137,15 +135,15 @@ public class TestTerms extends LuceneTestCase {
       long num = random().nextLong();
       minValue = Math.min(num, minValue);
       maxValue = Math.max(num, maxValue);
-      doc.add(new LongField("field", num, Field.Store.NO));
+      doc.add(new LegacyLongField("field", num, Field.Store.NO));
       w.addDocument(doc);
     }
     
     IndexReader r = w.getReader();
 
     Terms terms = MultiFields.getTerms(r, "field");
-    assertEquals(new Long(minValue), NumericUtils.getMinLong(terms));
-    assertEquals(new Long(maxValue), NumericUtils.getMaxLong(terms));
+    assertEquals(new Long(minValue), LegacyNumericUtils.getMinLong(terms));
+    assertEquals(new Long(maxValue), LegacyNumericUtils.getMaxLong(terms));
 
     r.close();
     w.close();
@@ -163,14 +161,14 @@ public class TestTerms extends LuceneTestCase {
       float num = random().nextFloat();
       minValue = Math.min(num, minValue);
       maxValue = Math.max(num, maxValue);
-      doc.add(new FloatField("field", num, Field.Store.NO));
+      doc.add(new LegacyFloatField("field", num, Field.Store.NO));
       w.addDocument(doc);
     }
     
     IndexReader r = w.getReader();
     Terms terms = MultiFields.getTerms(r, "field");
-    assertEquals(minValue, NumericUtils.sortableIntToFloat(NumericUtils.getMinInt(terms)), 0.0f);
-    assertEquals(maxValue, NumericUtils.sortableIntToFloat(NumericUtils.getMaxInt(terms)), 0.0f);
+    assertEquals(minValue, LegacyNumericUtils.sortableIntToFloat(LegacyNumericUtils.getMinInt(terms)), 0.0f);
+    assertEquals(maxValue, LegacyNumericUtils.sortableIntToFloat(LegacyNumericUtils.getMaxInt(terms)), 0.0f);
 
     r.close();
     w.close();
@@ -188,7 +186,7 @@ public class TestTerms extends LuceneTestCase {
       double num = random().nextDouble();
       minValue = Math.min(num, minValue);
       maxValue = Math.max(num, maxValue);
-      doc.add(new DoubleField("field", num, Field.Store.NO));
+      doc.add(new LegacyDoubleField("field", num, Field.Store.NO));
       w.addDocument(doc);
     }
     
@@ -196,8 +194,8 @@ public class TestTerms extends LuceneTestCase {
 
     Terms terms = MultiFields.getTerms(r, "field");
 
-    assertEquals(minValue, NumericUtils.sortableLongToDouble(NumericUtils.getMinLong(terms)), 0.0);
-    assertEquals(maxValue, NumericUtils.sortableLongToDouble(NumericUtils.getMaxLong(terms)), 0.0);
+    assertEquals(minValue, LegacyNumericUtils.sortableLongToDouble(LegacyNumericUtils.getMinLong(terms)), 0.0);
+    assertEquals(maxValue, LegacyNumericUtils.sortableLongToDouble(LegacyNumericUtils.getMaxLong(terms)), 0.0);
 
     r.close();
     w.close();
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestTermsEnum.java b/lucene/core/src/test/org/apache/lucene/index/TestTermsEnum.java
index fc2a3af..e900885 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestTermsEnum.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestTermsEnum.java
@@ -23,7 +23,6 @@ import java.util.*;
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
-import org.apache.lucene.document.IntField;
 import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.store.Directory;
@@ -158,7 +157,6 @@ public class TestTermsEnum extends LuceneTestCase {
 
   private void addDoc(RandomIndexWriter w, Collection<String> terms, Map<BytesRef,Integer> termToID, int id) throws IOException {
     Document doc = new Document();
-    doc.add(new IntField("id", id, Field.Store.YES));
     doc.add(new NumericDocValuesField("id", id));
     if (VERBOSE) {
       System.out.println("TEST: addDoc id:" + id + " terms=" + terms);
diff --git a/lucene/core/src/test/org/apache/lucene/search/BaseTestRangeFilter.java b/lucene/core/src/test/org/apache/lucene/search/BaseTestRangeFilter.java
index 46d2bfd..6943ce2 100644
--- a/lucene/core/src/test/org/apache/lucene/search/BaseTestRangeFilter.java
+++ b/lucene/core/src/test/org/apache/lucene/search/BaseTestRangeFilter.java
@@ -21,13 +21,16 @@ import java.io.IOException;
 import java.util.Random;
 
 import org.apache.lucene.analysis.MockAnalyzer;
+import org.apache.lucene.document.DimensionalDoubleField;
+import org.apache.lucene.document.DimensionalFloatField;
+import org.apache.lucene.document.DimensionalIntField;
+import org.apache.lucene.document.DimensionalLongField;
 import org.apache.lucene.document.Document;
-import org.apache.lucene.document.DoubleField;
 import org.apache.lucene.document.Field;
-import org.apache.lucene.document.Field.Store;
-import org.apache.lucene.document.FloatField;
-import org.apache.lucene.document.IntField;
-import org.apache.lucene.document.LongField;
+import org.apache.lucene.document.LegacyDoubleField;
+import org.apache.lucene.document.LegacyFloatField;
+import org.apache.lucene.document.LegacyIntField;
+import org.apache.lucene.document.LegacyLongField;
 import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.document.SortedDocValuesField;
 import org.apache.lucene.index.IndexReader;
@@ -124,13 +127,13 @@ public class BaseTestRangeFilter extends LuceneTestCase {
     Document doc = new Document();
     Field idField = newStringField(random, "id", "", Field.Store.YES);
     Field idDVField = new SortedDocValuesField("id", new BytesRef());
-    Field intIdField = new IntField("id_int", 0, Store.YES);
+    Field intIdField = new DimensionalIntField("id_int", 0);
     Field intDVField = new NumericDocValuesField("id_int", 0);
-    Field floatIdField = new FloatField("id_float", 0, Store.YES);
+    Field floatIdField = new DimensionalFloatField("id_float", 0);
     Field floatDVField = new NumericDocValuesField("id_float", 0);
-    Field longIdField = new LongField("id_long", 0, Store.YES);
+    Field longIdField = new DimensionalLongField("id_long", 0);
     Field longDVField = new NumericDocValuesField("id_long", 0);
-    Field doubleIdField = new DoubleField("id_double", 0, Store.YES);
+    Field doubleIdField = new DimensionalDoubleField("id_double", 0);
     Field doubleDVField = new NumericDocValuesField("id_double", 0);
     Field randField = newStringField(random, "rand", "", Field.Store.YES);
     Field randDVField = new SortedDocValuesField("rand", new BytesRef());
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestDimensionalRangeQuery.java b/lucene/core/src/test/org/apache/lucene/search/TestDimensionalRangeQuery.java
index 10651bb..d401339 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestDimensionalRangeQuery.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestDimensionalRangeQuery.java
@@ -33,11 +33,13 @@ import org.apache.lucene.codecs.DimensionalWriter;
 import org.apache.lucene.codecs.FilterCodec;
 import org.apache.lucene.codecs.lucene60.Lucene60DimensionalReader;
 import org.apache.lucene.codecs.lucene60.Lucene60DimensionalWriter;
-import org.apache.lucene.document.DimensionalField;
+import org.apache.lucene.document.DimensionalBinaryField;
+import org.apache.lucene.document.DimensionalLongField;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.document.SortedNumericDocValuesField;
+import org.apache.lucene.index.DimensionalValues;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexWriterConfig;
 import org.apache.lucene.index.LeafReaderContext;
@@ -52,8 +54,8 @@ import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.NumericUtils;
 import org.apache.lucene.util.TestUtil;
-import org.apache.lucene.util.bkd.BKDUtil;
 import org.junit.BeforeClass;
 
 public class TestDimensionalRangeQuery extends LuceneTestCase {
@@ -149,8 +151,8 @@ public class TestDimensionalRangeQuery extends LuceneTestCase {
     for(int i=0;i<10000;i++) {
       long v = random().nextLong();
       byte[] tmp = new byte[8];
-      BKDUtil.longToBytes(v, tmp, 0);
-      long v2 = BKDUtil.bytesToLong(tmp, 0);
+      NumericUtils.longToBytes(v, tmp, 0);
+      long v2 = NumericUtils.bytesToLong(tmp, 0);
       assertEquals("got bytes=" + Arrays.toString(tmp), v, v2);
     }
   }
@@ -221,10 +223,10 @@ public class TestDimensionalRangeQuery extends LuceneTestCase {
       }
 
       if (missing.get(id) == false) {
-        doc.add(new DimensionalField("sn_value", values[id]));
+        doc.add(new DimensionalLongField("sn_value", values[id]));
         byte[] bytes = new byte[8];
-        BKDUtil.longToBytes(values[id], bytes, 0);
-        doc.add(new DimensionalField("ss_value", bytes));
+        NumericUtils.longToBytes(values[id], bytes, 0);
+        doc.add(new DimensionalBinaryField("ss_value", bytes));
       }
     }
 
@@ -287,33 +289,33 @@ public class TestDimensionalRangeQuery extends LuceneTestCase {
                 System.out.println("\n" + Thread.currentThread().getName() + ": TEST: iter=" + iter + " value=" + lower + " (inclusive?=" + includeLower + ") TO " + upper + " (inclusive?=" + includeUpper + ")");
                 byte[] tmp = new byte[8];
                 if (lower != null) {
-                  BKDUtil.longToBytes(lower, tmp, 0);
+                  NumericUtils.longToBytes(lower, tmp, 0);
                   System.out.println("  lower bytes=" + Arrays.toString(tmp));
                 }
                 if (upper != null) {
-                  BKDUtil.longToBytes(upper, tmp, 0);
+                  NumericUtils.longToBytes(upper, tmp, 0);
                   System.out.println("  upper bytes=" + Arrays.toString(tmp));
                 }
               }
 
               if (random().nextBoolean()) {
-                query = new DimensionalRangeQuery("sn_value", lower, includeLower, upper, includeUpper);
+                query = DimensionalRangeQuery.new1DLongRange("sn_value", lower, includeLower, upper, includeUpper);
               } else {
                 byte[] lowerBytes;
                 if (lower == null) {
                   lowerBytes = null;
                 } else {
                   lowerBytes = new byte[8];
-                  BKDUtil.longToBytes(lower, lowerBytes, 0);
+                  NumericUtils.longToBytes(lower, lowerBytes, 0);
                 }
                 byte[] upperBytes;
                 if (upper == null) {
                   upperBytes = null;
                 } else {
                   upperBytes = new byte[8];
-                  BKDUtil.longToBytes(upper, upperBytes, 0);
+                  NumericUtils.longToBytes(upper, upperBytes, 0);
                 }
-                query = new DimensionalRangeQuery("ss_value", lowerBytes, includeLower, upperBytes, includeUpper);
+                query = DimensionalRangeQuery.new1DBinaryRange("ss_value", lowerBytes, includeLower, upperBytes, includeUpper);
               }
 
               if (VERBOSE) {
@@ -382,8 +384,8 @@ public class TestDimensionalRangeQuery extends LuceneTestCase {
 
   private void doTestRandomBinary(int count) throws Exception {
     int numValues = TestUtil.nextInt(random(), count, count*2);
-    int numBytesPerDim = TestUtil.nextInt(random(), 2, 30);
-    int numDims = TestUtil.nextInt(random(), 1, 5);
+    int numBytesPerDim = TestUtil.nextInt(random(), 2, DimensionalValues.MAX_NUM_BYTES);
+    int numDims = TestUtil.nextInt(random(), 1, DimensionalValues.MAX_DIMENSIONS);
 
     int sameValuePct = random().nextInt(100);
 
@@ -485,7 +487,7 @@ public class TestDimensionalRangeQuery extends LuceneTestCase {
       }
 
       if (missing.get(id) == false) {
-        doc.add(new DimensionalField("value", docValues[ord]));
+        doc.add(new DimensionalBinaryField("value", docValues[ord]));
         if (VERBOSE) {
           System.out.println("id=" + id);
           for(int dim=0;dim<numDims;dim++) {
@@ -558,7 +560,7 @@ public class TestDimensionalRangeQuery extends LuceneTestCase {
                   // open-ended on the upper bound
                 }
 
-                if (lower[dim] != null && upper[dim] != null && BKDUtil.compare(bytesPerDim, lower[dim], 0, upper[dim], 0) > 0) {
+                if (lower[dim] != null && upper[dim] != null && NumericUtils.compare(bytesPerDim, lower[dim], 0, upper[dim], 0) > 0) {
                   byte[] x = lower[dim];
                   lower[dim] = upper[dim];
                   upper[dim] = x;
@@ -677,7 +679,7 @@ public class TestDimensionalRangeQuery extends LuceneTestCase {
       if (lower[dim] == null) {
         cmp = 1;
       } else {
-        cmp = BKDUtil.compare(bytesPerDim, value[dim], 0, lower[dim], 0);
+        cmp = NumericUtils.compare(bytesPerDim, value[dim], 0, lower[dim], 0);
       }
 
       if (cmp < 0 || (cmp == 0 && includeLower[dim] == false)) {
@@ -688,7 +690,7 @@ public class TestDimensionalRangeQuery extends LuceneTestCase {
       if (upper[dim] == null) {
         cmp = -1;
       } else {
-        cmp = BKDUtil.compare(bytesPerDim, value[dim], 0, upper[dim], 0);
+        cmp = NumericUtils.compare(bytesPerDim, value[dim], 0, upper[dim], 0);
       }
 
       if (cmp > 0 || (cmp == 0 && includeUpper[dim] == false)) {
@@ -718,20 +720,20 @@ public class TestDimensionalRangeQuery extends LuceneTestCase {
     iwc.setCodec(getCodec());
     RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);
     Document doc = new Document();
-    doc.add(new DimensionalField("value", Long.MIN_VALUE));
+    doc.add(new DimensionalLongField("value", Long.MIN_VALUE));
     w.addDocument(doc);
 
     doc = new Document();
-    doc.add(new DimensionalField("value", Long.MAX_VALUE));
+    doc.add(new DimensionalLongField("value", Long.MAX_VALUE));
     w.addDocument(doc);
 
     IndexReader r = w.getReader();
 
     IndexSearcher s = newSearcher(r);
 
-    assertEquals(1, s.count(new DimensionalRangeQuery("value", Long.MIN_VALUE, true, 0L, true)));
-    assertEquals(1, s.count(new DimensionalRangeQuery("value", 0L, true, Long.MAX_VALUE, true)));
-    assertEquals(2, s.count(new DimensionalRangeQuery("value", Long.MIN_VALUE, true, Long.MAX_VALUE, true)));
+    assertEquals(1, s.count(DimensionalRangeQuery.new1DLongRange("value", Long.MIN_VALUE, true, 0L, true)));
+    assertEquals(1, s.count(DimensionalRangeQuery.new1DLongRange("value", 0L, true, Long.MAX_VALUE, true)));
+    assertEquals(2, s.count(DimensionalRangeQuery.new1DLongRange("value", Long.MIN_VALUE, true, Long.MAX_VALUE, true)));
 
     IOUtils.close(r, w, dir);
   }
@@ -757,61 +759,61 @@ public class TestDimensionalRangeQuery extends LuceneTestCase {
     iwc.setCodec(getCodec());
     RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);
     Document doc = new Document();
-    doc.add(new DimensionalField("value", toUTF8("abc")));
+    doc.add(new DimensionalBinaryField("value", toUTF8("abc")));
     w.addDocument(doc);
     doc = new Document();
-    doc.add(new DimensionalField("value", toUTF8("def")));
+    doc.add(new DimensionalBinaryField("value", toUTF8("def")));
     w.addDocument(doc);
 
     IndexReader r = w.getReader();
 
     IndexSearcher s = newSearcher(r);
 
-    assertEquals(1, s.count(new DimensionalRangeQuery("value",
-                                                      toUTF8("aaa"),
-                                                      true,
-                                                      toUTF8("bbb"),
-                                                      true)));
-    assertEquals(1, s.count(new DimensionalRangeQuery("value",
-                                                      toUTF8("c", 3),
-                                                      true,
-                                                      toUTF8("e", 3),
-                                                      true)));
-    assertEquals(2, s.count(new DimensionalRangeQuery("value",
-                                                      toUTF8("a", 3),
-                                                      true,
-                                                      toUTF8("z", 3),
-                                                      true)));
-    assertEquals(1, s.count(new DimensionalRangeQuery("value",
-                                                      null,
-                                                      true,
-                                                      toUTF8("abc"),
-                                                      true)));
-    assertEquals(1, s.count(new DimensionalRangeQuery("value",
-                                                      toUTF8("a", 3),
-                                                      true,
-                                                      toUTF8("abc"),
-                                                      true)));
-    assertEquals(0, s.count(new DimensionalRangeQuery("value",
-                                                      toUTF8("a", 3),
-                                                      true,
-                                                      toUTF8("abc"),
-                                                      false)));
-    assertEquals(1, s.count(new DimensionalRangeQuery("value",
-                                                      toUTF8("def"),
-                                                      true,
-                                                      null,
-                                                      false)));
-    assertEquals(1, s.count(new DimensionalRangeQuery("value",
-                                                      toUTF8(("def")),
-                                                      true,
-                                                      toUTF8("z", 3),
-                                                      true)));
-    assertEquals(0, s.count(new DimensionalRangeQuery("value",
-                                                      toUTF8("def"),
-                                                      false,
-                                                      toUTF8("z", 3),
-                                                      true)));
+    assertEquals(1, s.count(DimensionalRangeQuery.new1DBinaryRange("value",
+                                                                   toUTF8("aaa"),
+                                                                   true,
+                                                                   toUTF8("bbb"),
+                                                                   true)));
+    assertEquals(1, s.count(DimensionalRangeQuery.new1DBinaryRange("value",
+                                                                   toUTF8("c", 3),
+                                                                   true,
+                                                                   toUTF8("e", 3),
+                                                                   true)));
+    assertEquals(2, s.count(DimensionalRangeQuery.new1DBinaryRange("value",
+                                                                   toUTF8("a", 3),
+                                                                   true,
+                                                                   toUTF8("z", 3),
+                                                                   true)));
+    assertEquals(1, s.count(DimensionalRangeQuery.new1DBinaryRange("value",
+                                                                   null,
+                                                                   true,
+                                                                   toUTF8("abc"),
+                                                                   true)));
+    assertEquals(1, s.count(DimensionalRangeQuery.new1DBinaryRange("value",
+                                                                   toUTF8("a", 3),
+                                                                   true,
+                                                                   toUTF8("abc"),
+                                                                   true)));
+    assertEquals(0, s.count(DimensionalRangeQuery.new1DBinaryRange("value",
+                                                                   toUTF8("a", 3),
+                                                                   true,
+                                                                   toUTF8("abc"),
+                                                                   false)));
+    assertEquals(1, s.count(DimensionalRangeQuery.new1DBinaryRange("value",
+                                                                   toUTF8("def"),
+                                                                   true,
+                                                                   null,
+                                                                   false)));
+    assertEquals(1, s.count(DimensionalRangeQuery.new1DBinaryRange("value",
+                                                                   toUTF8(("def")),
+                                                                   true,
+                                                                   toUTF8("z", 3),
+                                                                   true)));
+    assertEquals(0, s.count(DimensionalRangeQuery.new1DBinaryRange("value",
+                                                                   toUTF8("def"),
+                                                                   false,
+                                                                   toUTF8("z", 3),
+                                                                   true)));
 
     IOUtils.close(r, w, dir);
   }
@@ -822,22 +824,22 @@ public class TestDimensionalRangeQuery extends LuceneTestCase {
     iwc.setCodec(getCodec());
     RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);
     Document doc = new Document();
-    doc.add(new DimensionalField("value", Long.MIN_VALUE));
+    doc.add(new DimensionalLongField("value", Long.MIN_VALUE));
     w.addDocument(doc);
     doc = new Document();
-    doc.add(new DimensionalField("value", Long.MAX_VALUE));
+    doc.add(new DimensionalLongField("value", Long.MAX_VALUE));
     w.addDocument(doc);
 
     IndexReader r = w.getReader();
 
     IndexSearcher s = newSearcher(r);
 
-    assertEquals(2, s.count(new DimensionalRangeQuery("value", Long.MIN_VALUE, true, Long.MAX_VALUE, true)));
-    assertEquals(1, s.count(new DimensionalRangeQuery("value", Long.MIN_VALUE, true, Long.MAX_VALUE, false)));
-    assertEquals(1, s.count(new DimensionalRangeQuery("value", Long.MIN_VALUE, false, Long.MAX_VALUE, true)));
-    assertEquals(0, s.count(new DimensionalRangeQuery("value", Long.MIN_VALUE, false, Long.MAX_VALUE, false)));
+    assertEquals(2, s.count(DimensionalRangeQuery.new1DLongRange("value", Long.MIN_VALUE, true, Long.MAX_VALUE, true)));
+    assertEquals(1, s.count(DimensionalRangeQuery.new1DLongRange("value", Long.MIN_VALUE, true, Long.MAX_VALUE, false)));
+    assertEquals(1, s.count(DimensionalRangeQuery.new1DLongRange("value", Long.MIN_VALUE, false, Long.MAX_VALUE, true)));
+    assertEquals(0, s.count(DimensionalRangeQuery.new1DLongRange("value", Long.MIN_VALUE, false, Long.MAX_VALUE, false)));
 
-    assertEquals(2, s.count(new DimensionalRangeQuery("value", (byte[]) null, true, null, true)));
+    assertEquals(2, s.count(DimensionalRangeQuery.new1DBinaryRange("value", (byte[]) null, true, null, true)));
 
     IOUtils.close(r, w, dir);
   }
@@ -848,10 +850,10 @@ public class TestDimensionalRangeQuery extends LuceneTestCase {
     iwc.setCodec(getCodec());
     RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);
     Document doc = new Document();
-    doc.add(new DimensionalField("value", Long.MIN_VALUE));
+    doc.add(new DimensionalLongField("value", Long.MIN_VALUE));
     w.addDocument(doc);
     doc = new Document();
-    doc.add(new DimensionalField("value", Long.MAX_VALUE));
+    doc.add(new DimensionalLongField("value", Long.MAX_VALUE));
     w.addDocument(doc);
 
     IndexReader r = w.getReader();
@@ -859,12 +861,12 @@ public class TestDimensionalRangeQuery extends LuceneTestCase {
     // We can't wrap with "exotic" readers because the query must see the RangeTreeDVFormat:
     IndexSearcher s = newSearcher(r, false);
 
-    assertEquals(2, s.count(new DimensionalRangeQuery("value", Long.MIN_VALUE, true, Long.MAX_VALUE, true)));
-    assertEquals(1, s.count(new DimensionalRangeQuery("value", Long.MIN_VALUE, true, Long.MAX_VALUE, false)));
-    assertEquals(1, s.count(new DimensionalRangeQuery("value", Long.MIN_VALUE, false, Long.MAX_VALUE, true)));
-    assertEquals(0, s.count(new DimensionalRangeQuery("value", Long.MIN_VALUE, false, Long.MAX_VALUE, false)));
+    assertEquals(2, s.count(DimensionalRangeQuery.new1DLongRange("value", Long.MIN_VALUE, true, Long.MAX_VALUE, true)));
+    assertEquals(1, s.count(DimensionalRangeQuery.new1DLongRange("value", Long.MIN_VALUE, true, Long.MAX_VALUE, false)));
+    assertEquals(1, s.count(DimensionalRangeQuery.new1DLongRange("value", Long.MIN_VALUE, false, Long.MAX_VALUE, true)));
+    assertEquals(0, s.count(DimensionalRangeQuery.new1DLongRange("value", Long.MIN_VALUE, false, Long.MAX_VALUE, false)));
 
-    assertEquals(2, s.count(new DimensionalRangeQuery("value", (Long) null, true, null, true)));
+    assertEquals(2, s.count(DimensionalRangeQuery.new1DLongRange("value", (Long) null, true, null, true)));
 
     IOUtils.close(r, w, dir);
   }
@@ -875,18 +877,18 @@ public class TestDimensionalRangeQuery extends LuceneTestCase {
     iwc.setCodec(getCodec());
     RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);
     Document doc = new Document();
-    doc.add(new DimensionalField("value", toUTF8("a")));
+    doc.add(new DimensionalBinaryField("value", toUTF8("a")));
     w.addDocument(doc);
     doc = new Document();
-    doc.add(new DimensionalField("value", toUTF8("z")));
+    doc.add(new DimensionalBinaryField("value", toUTF8("z")));
     w.addDocument(doc);
 
     IndexReader r = w.getReader();
 
     IndexSearcher s = newSearcher(r);
-    assertEquals(0, s.count(new DimensionalRangeQuery("value", toUTF8("m"), true, toUTF8("n"), false)));
+    assertEquals(0, s.count(DimensionalRangeQuery.new1DBinaryRange("value", toUTF8("m"), true, toUTF8("n"), false)));
 
-    assertEquals(2, s.count(new DimensionalRangeQuery("value", (byte[]) null, true, null, true)));
+    assertEquals(2, s.count(DimensionalRangeQuery.new1DBinaryRange("value", (byte[]) null, true, null, true)));
 
     IOUtils.close(r, w, dir);
   }
@@ -906,7 +908,7 @@ public class TestDimensionalRangeQuery extends LuceneTestCase {
     IndexReader r = w.getReader();
 
     IndexSearcher s = new IndexSearcher(r);
-    assertEquals(0, s.count(new DimensionalRangeQuery("value", 17L, true, 13L, false)));
+    assertEquals(0, s.count(DimensionalRangeQuery.new1DLongRange("value", 17L, true, 13L, false)));
 
     IOUtils.close(r, w, dir);
   }
@@ -921,7 +923,7 @@ public class TestDimensionalRangeQuery extends LuceneTestCase {
     IndexReader r = w.getReader();
 
     IndexSearcher s = newSearcher(r);
-    assertEquals(0, s.count(new DimensionalRangeQuery("value", 17L, true, 13L, false)));
+    assertEquals(0, s.count(DimensionalRangeQuery.new1DLongRange("value", 17L, true, 13L, false)));
 
     IOUtils.close(r, w, dir);
   }
@@ -932,7 +934,7 @@ public class TestDimensionalRangeQuery extends LuceneTestCase {
     iwc.setCodec(getCodec());
     RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);
     Document doc = new Document();
-    doc.add(new DimensionalField("value", Long.MIN_VALUE));
+    doc.add(new DimensionalLongField("value", Long.MIN_VALUE));
     w.addDocument(doc);
 
     IndexReader r = w.getReader();
@@ -955,7 +957,7 @@ public class TestDimensionalRangeQuery extends LuceneTestCase {
     iwc.setCodec(getCodec());
     RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);
     Document doc = new Document();
-    doc.add(new DimensionalField("value", Long.MIN_VALUE));
+    doc.add(new DimensionalLongField("value", Long.MIN_VALUE));
     w.addDocument(doc);
 
     IndexReader r = w.getReader();
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestLiveFieldValues.java b/lucene/core/src/test/org/apache/lucene/search/TestLiveFieldValues.java
index 600446a..70bfc31 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestLiveFieldValues.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestLiveFieldValues.java
@@ -30,7 +30,7 @@ import java.util.concurrent.CountDownLatch;
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
-import org.apache.lucene.document.IntField;
+import org.apache.lucene.document.StoredField;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.IndexWriterConfig;
@@ -109,7 +109,7 @@ public class TestLiveFieldValues extends LuceneTestCase {
                   String id = String.format(Locale.ROOT, "%d_%04x", threadID, threadRandom.nextInt(idCount));
                   Integer field = threadRandom.nextInt(Integer.MAX_VALUE);
                   doc.add(newStringField("id", new BytesRef(id), Field.Store.YES));
-                  doc.add(new IntField("field", field.intValue(), Field.Store.YES));
+                  doc.add(new StoredField("field", field.intValue()));
                   w.updateDocument(new Term("id", id), doc);
                   rt.add(id, field);
                   if (values.put(id, field) == null) {
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestMultiValuedNumericRangeQuery.java b/lucene/core/src/test/org/apache/lucene/search/TestMultiValuedNumericRangeQuery.java
index ffd231a..47c259a 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestMultiValuedNumericRangeQuery.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestMultiValuedNumericRangeQuery.java
@@ -24,7 +24,7 @@ import java.text.DecimalFormatSymbols;
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
-import org.apache.lucene.document.IntField;
+import org.apache.lucene.document.LegacyIntField;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.store.Directory;
@@ -33,9 +33,9 @@ import org.apache.lucene.util.TestUtil;
 
 public class TestMultiValuedNumericRangeQuery extends LuceneTestCase {
 
-  /** Tests NumericRangeQuery on a multi-valued field (multiple numeric values per document).
+  /** Tests LegacyNumericRangeQuery on a multi-valued field (multiple numeric values per document).
    * This test ensures, that a classical TermRangeQuery returns exactly the same document numbers as
-   * NumericRangeQuery (see SOLR-1322 for discussion) and the multiple precision terms per numeric value
+   * LegacyNumericRangeQuery (see SOLR-1322 for discussion) and the multiple precision terms per numeric value
    * do not interfere with multiple numeric values.
    */
   public void testMultiValuedNRQ() throws Exception {
@@ -52,7 +52,7 @@ public class TestMultiValuedNumericRangeQuery extends LuceneTestCase {
       for (int m=0, c=random().nextInt(10); m<=c; m++) {
         int value = random().nextInt(Integer.MAX_VALUE);
         doc.add(newStringField("asc", format.format(value), Field.Store.NO));
-        doc.add(new IntField("trie", value, Field.Store.NO));
+        doc.add(new LegacyIntField("trie", value, Field.Store.NO));
       }
       writer.addDocument(doc);
     }
@@ -68,10 +68,10 @@ public class TestMultiValuedNumericRangeQuery extends LuceneTestCase {
         int a=lower; lower=upper; upper=a;
       }
       TermRangeQuery cq=TermRangeQuery.newStringRange("asc", format.format(lower), format.format(upper), true, true);
-      NumericRangeQuery<Integer> tq=NumericRangeQuery.newIntRange("trie", lower, upper, true, true);
+      LegacyNumericRangeQuery<Integer> tq= LegacyNumericRangeQuery.newIntRange("trie", lower, upper, true, true);
       TopDocs trTopDocs = searcher.search(cq, 1);
       TopDocs nrTopDocs = searcher.search(tq, 1);
-      assertEquals("Returned count for NumericRangeQuery and TermRangeQuery must be equal", trTopDocs.totalHits, nrTopDocs.totalHits );
+      assertEquals("Returned count for LegacyNumericRangeQuery and TermRangeQuery must be equal", trTopDocs.totalHits, nrTopDocs.totalHits );
     }
     reader.close();
     directory.close();
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestNumericRangeQuery32.java b/lucene/core/src/test/org/apache/lucene/search/TestNumericRangeQuery32.java
index a00c4bc..912522e 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestNumericRangeQuery32.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestNumericRangeQuery32.java
@@ -21,23 +21,21 @@ import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.FieldType;
-import org.apache.lucene.document.FloatField;
-import org.apache.lucene.document.IntField;
-import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.document.LegacyFloatField;
+import org.apache.lucene.document.LegacyIntField;
 import org.apache.lucene.index.DirectoryReader;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.MultiFields;
 import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.SlowCompositeReaderWrapper;
 import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.Terms;
 import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
+import org.apache.lucene.util.LegacyNumericUtils;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util.NumericUtils;
-import org.apache.lucene.util.TestNumericUtils; // NaN arrays
+import org.apache.lucene.util.TestLegacyNumericUtils; // NaN arrays
 import org.apache.lucene.util.TestUtil;
 import org.junit.AfterClass;
 import org.junit.BeforeClass;
@@ -65,7 +63,7 @@ public class TestNumericRangeQuery32 extends LuceneTestCase {
         .setMaxBufferedDocs(TestUtil.nextInt(random(), 100, 1000))
         .setMergePolicy(newLogMergePolicy()));
     
-    final FieldType storedInt = new FieldType(IntField.TYPE_NOT_STORED);
+    final FieldType storedInt = new FieldType(LegacyIntField.TYPE_NOT_STORED);
     storedInt.setStored(true);
     storedInt.freeze();
 
@@ -81,7 +79,7 @@ public class TestNumericRangeQuery32 extends LuceneTestCase {
     final FieldType storedIntNone = new FieldType(storedInt);
     storedIntNone.setNumericPrecisionStep(Integer.MAX_VALUE);
 
-    final FieldType unstoredInt = IntField.TYPE_NOT_STORED;
+    final FieldType unstoredInt = LegacyIntField.TYPE_NOT_STORED;
 
     final FieldType unstoredInt8 = new FieldType(unstoredInt);
     unstoredInt8.setNumericPrecisionStep(8);
@@ -92,14 +90,14 @@ public class TestNumericRangeQuery32 extends LuceneTestCase {
     final FieldType unstoredInt2 = new FieldType(unstoredInt);
     unstoredInt2.setNumericPrecisionStep(2);
 
-    IntField
-      field8 = new IntField("field8", 0, storedInt8),
-      field4 = new IntField("field4", 0, storedInt4),
-      field2 = new IntField("field2", 0, storedInt2),
-      fieldNoTrie = new IntField("field"+Integer.MAX_VALUE, 0, storedIntNone),
-      ascfield8 = new IntField("ascfield8", 0, unstoredInt8),
-      ascfield4 = new IntField("ascfield4", 0, unstoredInt4),
-      ascfield2 = new IntField("ascfield2", 0, unstoredInt2);
+    LegacyIntField
+      field8 = new LegacyIntField("field8", 0, storedInt8),
+      field4 = new LegacyIntField("field4", 0, storedInt4),
+      field2 = new LegacyIntField("field2", 0, storedInt2),
+      fieldNoTrie = new LegacyIntField("field"+Integer.MAX_VALUE, 0, storedIntNone),
+      ascfield8 = new LegacyIntField("ascfield8", 0, unstoredInt8),
+      ascfield4 = new LegacyIntField("ascfield4", 0, unstoredInt4),
+      ascfield2 = new LegacyIntField("ascfield2", 0, unstoredInt2);
     
     Document doc = new Document();
     // add fields, that have a distance to test general functionality
@@ -149,7 +147,7 @@ public class TestNumericRangeQuery32 extends LuceneTestCase {
     String field="field"+precisionStep;
     int count=3000;
     int lower=(distance*3/2)+startOffset, upper=lower + count*distance + (distance/3);
-    NumericRangeQuery<Integer> q = NumericRangeQuery.newIntRange(field, precisionStep, lower, upper, true, true);
+    LegacyNumericRangeQuery<Integer> q = LegacyNumericRangeQuery.newIntRange(field, precisionStep, lower, upper, true, true);
     for (byte i=0; i<2; i++) {
       TopDocs topDocs;
       String type;
@@ -194,7 +192,7 @@ public class TestNumericRangeQuery32 extends LuceneTestCase {
   
   @Test
   public void testOneMatchQuery() throws Exception {
-    NumericRangeQuery<Integer> q = NumericRangeQuery.newIntRange("ascfield8", 8, 1000, 1000, true, true);
+    LegacyNumericRangeQuery<Integer> q = LegacyNumericRangeQuery.newIntRange("ascfield8", 8, 1000, 1000, true, true);
     TopDocs topDocs = searcher.search(q, noDocs);
     ScoreDoc[] sd = topDocs.scoreDocs;
     assertNotNull(sd);
@@ -205,7 +203,7 @@ public class TestNumericRangeQuery32 extends LuceneTestCase {
     String field="field"+precisionStep;
     int count=3000;
     int upper=(count-1)*distance + (distance/3) + startOffset;
-    NumericRangeQuery<Integer> q=NumericRangeQuery.newIntRange(field, precisionStep, null, upper, true, true);
+    LegacyNumericRangeQuery<Integer> q= LegacyNumericRangeQuery.newIntRange(field, precisionStep, null, upper, true, true);
     TopDocs topDocs = searcher.search(q, noDocs, Sort.INDEXORDER);
     ScoreDoc[] sd = topDocs.scoreDocs;
     assertNotNull(sd);
@@ -215,7 +213,7 @@ public class TestNumericRangeQuery32 extends LuceneTestCase {
     doc=searcher.doc(sd[sd.length-1].doc);
     assertEquals("Last doc", (count-1)*distance+startOffset, doc.getField(field).numericValue().intValue());
     
-    q=NumericRangeQuery.newIntRange(field, precisionStep, null, upper, false, true);
+    q= LegacyNumericRangeQuery.newIntRange(field, precisionStep, null, upper, false, true);
     topDocs = searcher.search(q, noDocs, Sort.INDEXORDER);
     sd = topDocs.scoreDocs;
     assertNotNull(sd);
@@ -245,7 +243,7 @@ public class TestNumericRangeQuery32 extends LuceneTestCase {
     String field="field"+precisionStep;
     int count=3000;
     int lower=(count-1)*distance + (distance/3) +startOffset;
-    NumericRangeQuery<Integer> q=NumericRangeQuery.newIntRange(field, precisionStep, lower, null, true, true);
+    LegacyNumericRangeQuery<Integer> q= LegacyNumericRangeQuery.newIntRange(field, precisionStep, lower, null, true, true);
     TopDocs topDocs = searcher.search(q, noDocs, Sort.INDEXORDER);
     ScoreDoc[] sd = topDocs.scoreDocs;
     assertNotNull(sd);
@@ -255,7 +253,7 @@ public class TestNumericRangeQuery32 extends LuceneTestCase {
     doc=searcher.doc(sd[sd.length-1].doc);
     assertEquals("Last doc", (noDocs-1)*distance+startOffset, doc.getField(field).numericValue().intValue());
 
-    q=NumericRangeQuery.newIntRange(field, precisionStep, lower, null, true, false);
+    q= LegacyNumericRangeQuery.newIntRange(field, precisionStep, lower, null, true, false);
     topDocs = searcher.search(q, noDocs, Sort.INDEXORDER);
     sd = topDocs.scoreDocs;
     assertNotNull(sd);
@@ -287,23 +285,23 @@ public class TestNumericRangeQuery32 extends LuceneTestCase {
     RandomIndexWriter writer = new RandomIndexWriter(random(), dir,
       newIndexWriterConfig(new MockAnalyzer(random())));
     Document doc = new Document();
-    doc.add(new FloatField("float", Float.NEGATIVE_INFINITY, Field.Store.NO));
-    doc.add(new IntField("int", Integer.MIN_VALUE, Field.Store.NO));
+    doc.add(new LegacyFloatField("float", Float.NEGATIVE_INFINITY, Field.Store.NO));
+    doc.add(new LegacyIntField("int", Integer.MIN_VALUE, Field.Store.NO));
     writer.addDocument(doc);
     
     doc = new Document();
-    doc.add(new FloatField("float", Float.POSITIVE_INFINITY, Field.Store.NO));
-    doc.add(new IntField("int", Integer.MAX_VALUE, Field.Store.NO));
+    doc.add(new LegacyFloatField("float", Float.POSITIVE_INFINITY, Field.Store.NO));
+    doc.add(new LegacyIntField("int", Integer.MAX_VALUE, Field.Store.NO));
     writer.addDocument(doc);
     
     doc = new Document();
-    doc.add(new FloatField("float", 0.0f, Field.Store.NO));
-    doc.add(new IntField("int", 0, Field.Store.NO));
+    doc.add(new LegacyFloatField("float", 0.0f, Field.Store.NO));
+    doc.add(new LegacyIntField("int", 0, Field.Store.NO));
     writer.addDocument(doc);
     
-    for (float f : TestNumericUtils.FLOAT_NANs) {
+    for (float f : TestLegacyNumericUtils.FLOAT_NANs) {
       doc = new Document();
-      doc.add(new FloatField("float", f, Field.Store.NO));
+      doc.add(new LegacyFloatField("float", f, Field.Store.NO));
       writer.addDocument(doc);
     }
     
@@ -312,41 +310,41 @@ public class TestNumericRangeQuery32 extends LuceneTestCase {
     IndexReader r = DirectoryReader.open(dir);
     IndexSearcher s = newSearcher(r);
     
-    Query q=NumericRangeQuery.newIntRange("int", null, null, true, true);
+    Query q= LegacyNumericRangeQuery.newIntRange("int", null, null, true, true);
     TopDocs topDocs = s.search(q, 10);
     assertEquals("Score doc count", 3,  topDocs.scoreDocs.length );
     
-    q=NumericRangeQuery.newIntRange("int", null, null, false, false);
+    q= LegacyNumericRangeQuery.newIntRange("int", null, null, false, false);
     topDocs = s.search(q, 10);
     assertEquals("Score doc count", 3,  topDocs.scoreDocs.length );
 
-    q=NumericRangeQuery.newIntRange("int", Integer.MIN_VALUE, Integer.MAX_VALUE, true, true);
+    q= LegacyNumericRangeQuery.newIntRange("int", Integer.MIN_VALUE, Integer.MAX_VALUE, true, true);
     topDocs = s.search(q, 10);
     assertEquals("Score doc count", 3,  topDocs.scoreDocs.length );
     
-    q=NumericRangeQuery.newIntRange("int", Integer.MIN_VALUE, Integer.MAX_VALUE, false, false);
+    q= LegacyNumericRangeQuery.newIntRange("int", Integer.MIN_VALUE, Integer.MAX_VALUE, false, false);
     topDocs = s.search(q, 10);
     assertEquals("Score doc count", 1,  topDocs.scoreDocs.length );
 
-    q=NumericRangeQuery.newFloatRange("float", null, null, true, true);
+    q= LegacyNumericRangeQuery.newFloatRange("float", null, null, true, true);
     topDocs = s.search(q, 10);
     assertEquals("Score doc count", 3,  topDocs.scoreDocs.length );
 
-    q=NumericRangeQuery.newFloatRange("float", null, null, false, false);
+    q= LegacyNumericRangeQuery.newFloatRange("float", null, null, false, false);
     topDocs = s.search(q, 10);
     assertEquals("Score doc count", 3,  topDocs.scoreDocs.length );
 
-    q=NumericRangeQuery.newFloatRange("float", Float.NEGATIVE_INFINITY, Float.POSITIVE_INFINITY, true, true);
+    q= LegacyNumericRangeQuery.newFloatRange("float", Float.NEGATIVE_INFINITY, Float.POSITIVE_INFINITY, true, true);
     topDocs = s.search(q, 10);
     assertEquals("Score doc count", 3,  topDocs.scoreDocs.length );
 
-    q=NumericRangeQuery.newFloatRange("float", Float.NEGATIVE_INFINITY, Float.POSITIVE_INFINITY, false, false);
+    q= LegacyNumericRangeQuery.newFloatRange("float", Float.NEGATIVE_INFINITY, Float.POSITIVE_INFINITY, false, false);
     topDocs = s.search(q, 10);
     assertEquals("Score doc count", 1,  topDocs.scoreDocs.length );
 
-    q=NumericRangeQuery.newFloatRange("float", Float.NaN, Float.NaN, true, true);
+    q= LegacyNumericRangeQuery.newFloatRange("float", Float.NaN, Float.NaN, true, true);
     topDocs = s.search(q, 10);
-    assertEquals("Score doc count", TestNumericUtils.FLOAT_NANs.length,  topDocs.scoreDocs.length );
+    assertEquals("Score doc count", TestLegacyNumericUtils.FLOAT_NANs.length,  topDocs.scoreDocs.length );
 
     r.close();
     dir.close();
@@ -364,44 +362,44 @@ public class TestNumericRangeQuery32 extends LuceneTestCase {
       }
       final BytesRef lowerBytes, upperBytes;
       BytesRefBuilder b = new BytesRefBuilder();
-      NumericUtils.intToPrefixCodedBytes(lower, 0, b);
+      LegacyNumericUtils.intToPrefixCodedBytes(lower, 0, b);
       lowerBytes = b.toBytesRef();
-      NumericUtils.intToPrefixCodedBytes(upper, 0, b);
+      LegacyNumericUtils.intToPrefixCodedBytes(upper, 0, b);
       upperBytes = b.toBytesRef();
 
       // test inclusive range
-      NumericRangeQuery<Integer> tq=NumericRangeQuery.newIntRange(field, precisionStep, lower, upper, true, true);
+      LegacyNumericRangeQuery<Integer> tq= LegacyNumericRangeQuery.newIntRange(field, precisionStep, lower, upper, true, true);
       TermRangeQuery cq=new TermRangeQuery(field, lowerBytes, upperBytes, true, true);
       TopDocs tTopDocs = searcher.search(tq, 1);
       TopDocs cTopDocs = searcher.search(cq, 1);
-      assertEquals("Returned count for NumericRangeQuery and TermRangeQuery must be equal", cTopDocs.totalHits, tTopDocs.totalHits );
+      assertEquals("Returned count for LegacyNumericRangeQuery and TermRangeQuery must be equal", cTopDocs.totalHits, tTopDocs.totalHits );
       totalTermCountT += termCountT = countTerms(tq);
       totalTermCountC += termCountC = countTerms(cq);
       checkTermCounts(precisionStep, termCountT, termCountC);
       // test exclusive range
-      tq=NumericRangeQuery.newIntRange(field, precisionStep, lower, upper, false, false);
+      tq= LegacyNumericRangeQuery.newIntRange(field, precisionStep, lower, upper, false, false);
       cq=new TermRangeQuery(field, lowerBytes, upperBytes, false, false);
       tTopDocs = searcher.search(tq, 1);
       cTopDocs = searcher.search(cq, 1);
-      assertEquals("Returned count for NumericRangeQuery and TermRangeQuery must be equal", cTopDocs.totalHits, tTopDocs.totalHits );
+      assertEquals("Returned count for LegacyNumericRangeQuery and TermRangeQuery must be equal", cTopDocs.totalHits, tTopDocs.totalHits );
       totalTermCountT += termCountT = countTerms(tq);
       totalTermCountC += termCountC = countTerms(cq);
       checkTermCounts(precisionStep, termCountT, termCountC);
       // test left exclusive range
-      tq=NumericRangeQuery.newIntRange(field, precisionStep, lower, upper, false, true);
+      tq= LegacyNumericRangeQuery.newIntRange(field, precisionStep, lower, upper, false, true);
       cq=new TermRangeQuery(field, lowerBytes, upperBytes, false, true);
       tTopDocs = searcher.search(tq, 1);
       cTopDocs = searcher.search(cq, 1);
-      assertEquals("Returned count for NumericRangeQuery and TermRangeQuery must be equal", cTopDocs.totalHits, tTopDocs.totalHits );
+      assertEquals("Returned count for LegacyNumericRangeQuery and TermRangeQuery must be equal", cTopDocs.totalHits, tTopDocs.totalHits );
       totalTermCountT += termCountT = countTerms(tq);
       totalTermCountC += termCountC = countTerms(cq);
       checkTermCounts(precisionStep, termCountT, termCountC);
       // test right exclusive range
-      tq=NumericRangeQuery.newIntRange(field, precisionStep, lower, upper, true, false);
+      tq= LegacyNumericRangeQuery.newIntRange(field, precisionStep, lower, upper, true, false);
       cq=new TermRangeQuery(field, lowerBytes, upperBytes, true, false);
       tTopDocs = searcher.search(tq, 1);
       cTopDocs = searcher.search(cq, 1);
-      assertEquals("Returned count for NumericRangeQuery and TermRangeQuery must be equal", cTopDocs.totalHits, tTopDocs.totalHits );
+      assertEquals("Returned count for LegacyNumericRangeQuery and TermRangeQuery must be equal", cTopDocs.totalHits, tTopDocs.totalHits );
       totalTermCountT += termCountT = countTerms(tq);
       totalTermCountC += termCountC = countTerms(cq);
       checkTermCounts(precisionStep, termCountT, termCountC);
@@ -421,13 +419,13 @@ public class TestNumericRangeQuery32 extends LuceneTestCase {
     int lower=(distance*3/2)+startOffset, upper=lower + count*distance + (distance/3);
     // test empty enum
     assert lower < upper;
-    assertTrue(0 < countTerms(NumericRangeQuery.newIntRange("field4", 4, lower, upper, true, true)));
-    assertEquals(0, countTerms(NumericRangeQuery.newIntRange("field4", 4, upper, lower, true, true)));
+    assertTrue(0 < countTerms(LegacyNumericRangeQuery.newIntRange("field4", 4, lower, upper, true, true)));
+    assertEquals(0, countTerms(LegacyNumericRangeQuery.newIntRange("field4", 4, upper, lower, true, true)));
     // test empty enum outside of bounds
     lower = distance*noDocs+startOffset;
     upper = 2 * lower;
     assert lower < upper;
-    assertEquals(0, countTerms(NumericRangeQuery.newIntRange("field4", 4, lower, upper, true, true)));
+    assertEquals(0, countTerms(LegacyNumericRangeQuery.newIntRange("field4", 4, lower, upper, true, true)));
   }
   
   private int countTerms(MultiTermQuery q) throws Exception {
@@ -489,19 +487,19 @@ public class TestNumericRangeQuery32 extends LuceneTestCase {
         int a=lower; lower=upper; upper=a;
       }
       // test inclusive range
-      Query tq=NumericRangeQuery.newIntRange(field, precisionStep, lower, upper, true, true);
+      Query tq= LegacyNumericRangeQuery.newIntRange(field, precisionStep, lower, upper, true, true);
       TopDocs tTopDocs = searcher.search(tq, 1);
       assertEquals("Returned count of range query must be equal to inclusive range length", upper-lower+1, tTopDocs.totalHits );
       // test exclusive range
-      tq=NumericRangeQuery.newIntRange(field, precisionStep, lower, upper, false, false);
+      tq= LegacyNumericRangeQuery.newIntRange(field, precisionStep, lower, upper, false, false);
       tTopDocs = searcher.search(tq, 1);
       assertEquals("Returned count of range query must be equal to exclusive range length", Math.max(upper-lower-1, 0), tTopDocs.totalHits );
       // test left exclusive range
-      tq=NumericRangeQuery.newIntRange(field, precisionStep, lower, upper, false, true);
+      tq= LegacyNumericRangeQuery.newIntRange(field, precisionStep, lower, upper, false, true);
       tTopDocs = searcher.search(tq, 1);
       assertEquals("Returned count of range query must be equal to half exclusive range length", upper-lower, tTopDocs.totalHits );
       // test right exclusive range
-      tq=NumericRangeQuery.newIntRange(field, precisionStep, lower, upper, true, false);
+      tq= LegacyNumericRangeQuery.newIntRange(field, precisionStep, lower, upper, true, false);
       tTopDocs = searcher.search(tq, 1);
       assertEquals("Returned count of range query must be equal to half exclusive range length", upper-lower, tTopDocs.totalHits );
     }
@@ -522,13 +520,13 @@ public class TestNumericRangeQuery32 extends LuceneTestCase {
     testRangeSplit(2);
   }
   
-  /** we fake a float test using int2float conversion of NumericUtils */
+  /** we fake a float test using int2float conversion of LegacyNumericUtils */
   private void testFloatRange(int precisionStep) throws Exception {
     final String field="ascfield"+precisionStep;
     final int lower=-1000, upper=+2000;
     
-    Query tq=NumericRangeQuery.newFloatRange(field, precisionStep,
-      NumericUtils.sortableIntToFloat(lower), NumericUtils.sortableIntToFloat(upper), true, true);
+    Query tq= LegacyNumericRangeQuery.newFloatRange(field, precisionStep,
+        LegacyNumericUtils.sortableIntToFloat(lower), LegacyNumericUtils.sortableIntToFloat(upper), true, true);
     TopDocs tTopDocs = searcher.search(tq, 1);
     assertEquals("Returned count of range query must be equal to inclusive range length", upper-lower+1, tTopDocs.totalHits );
   }
@@ -550,40 +548,40 @@ public class TestNumericRangeQuery32 extends LuceneTestCase {
   
   @Test
   public void testEqualsAndHash() throws Exception {
-    QueryUtils.checkHashEquals(NumericRangeQuery.newIntRange("test1", 4, 10, 20, true, true));
-    QueryUtils.checkHashEquals(NumericRangeQuery.newIntRange("test2", 4, 10, 20, false, true));
-    QueryUtils.checkHashEquals(NumericRangeQuery.newIntRange("test3", 4, 10, 20, true, false));
-    QueryUtils.checkHashEquals(NumericRangeQuery.newIntRange("test4", 4, 10, 20, false, false));
-    QueryUtils.checkHashEquals(NumericRangeQuery.newIntRange("test5", 4, 10, null, true, true));
-    QueryUtils.checkHashEquals(NumericRangeQuery.newIntRange("test6", 4, null, 20, true, true));
-    QueryUtils.checkHashEquals(NumericRangeQuery.newIntRange("test7", 4, null, null, true, true));
+    QueryUtils.checkHashEquals(LegacyNumericRangeQuery.newIntRange("test1", 4, 10, 20, true, true));
+    QueryUtils.checkHashEquals(LegacyNumericRangeQuery.newIntRange("test2", 4, 10, 20, false, true));
+    QueryUtils.checkHashEquals(LegacyNumericRangeQuery.newIntRange("test3", 4, 10, 20, true, false));
+    QueryUtils.checkHashEquals(LegacyNumericRangeQuery.newIntRange("test4", 4, 10, 20, false, false));
+    QueryUtils.checkHashEquals(LegacyNumericRangeQuery.newIntRange("test5", 4, 10, null, true, true));
+    QueryUtils.checkHashEquals(LegacyNumericRangeQuery.newIntRange("test6", 4, null, 20, true, true));
+    QueryUtils.checkHashEquals(LegacyNumericRangeQuery.newIntRange("test7", 4, null, null, true, true));
     QueryUtils.checkEqual(
-      NumericRangeQuery.newIntRange("test8", 4, 10, 20, true, true), 
-      NumericRangeQuery.newIntRange("test8", 4, 10, 20, true, true)
+      LegacyNumericRangeQuery.newIntRange("test8", 4, 10, 20, true, true),
+      LegacyNumericRangeQuery.newIntRange("test8", 4, 10, 20, true, true)
     );
     QueryUtils.checkUnequal(
-      NumericRangeQuery.newIntRange("test9", 4, 10, 20, true, true), 
-      NumericRangeQuery.newIntRange("test9", 8, 10, 20, true, true)
+      LegacyNumericRangeQuery.newIntRange("test9", 4, 10, 20, true, true),
+      LegacyNumericRangeQuery.newIntRange("test9", 8, 10, 20, true, true)
     );
     QueryUtils.checkUnequal(
-      NumericRangeQuery.newIntRange("test10a", 4, 10, 20, true, true), 
-      NumericRangeQuery.newIntRange("test10b", 4, 10, 20, true, true)
+      LegacyNumericRangeQuery.newIntRange("test10a", 4, 10, 20, true, true),
+      LegacyNumericRangeQuery.newIntRange("test10b", 4, 10, 20, true, true)
     );
     QueryUtils.checkUnequal(
-      NumericRangeQuery.newIntRange("test11", 4, 10, 20, true, true), 
-      NumericRangeQuery.newIntRange("test11", 4, 20, 10, true, true)
+      LegacyNumericRangeQuery.newIntRange("test11", 4, 10, 20, true, true),
+      LegacyNumericRangeQuery.newIntRange("test11", 4, 20, 10, true, true)
     );
     QueryUtils.checkUnequal(
-      NumericRangeQuery.newIntRange("test12", 4, 10, 20, true, true), 
-      NumericRangeQuery.newIntRange("test12", 4, 10, 20, false, true)
+      LegacyNumericRangeQuery.newIntRange("test12", 4, 10, 20, true, true),
+      LegacyNumericRangeQuery.newIntRange("test12", 4, 10, 20, false, true)
     );
     QueryUtils.checkUnequal(
-      NumericRangeQuery.newIntRange("test13", 4, 10, 20, true, true), 
-      NumericRangeQuery.newFloatRange("test13", 4, 10f, 20f, true, true)
+      LegacyNumericRangeQuery.newIntRange("test13", 4, 10, 20, true, true),
+      LegacyNumericRangeQuery.newFloatRange("test13", 4, 10f, 20f, true, true)
     );
     // the following produces a hash collision, because Long and Integer have the same hashcode, so only test equality:
-    Query q1 = NumericRangeQuery.newIntRange("test14", 4, 10, 20, true, true);
-    Query q2 = NumericRangeQuery.newLongRange("test14", 4, 10L, 20L, true, true);
+    Query q1 = LegacyNumericRangeQuery.newIntRange("test14", 4, 10, 20, true, true);
+    Query q2 = LegacyNumericRangeQuery.newLongRange("test14", 4, 10L, 20L, true, true);
     assertFalse(q1.equals(q2));
     assertFalse(q2.equals(q1));
   }
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestNumericRangeQuery64.java b/lucene/core/src/test/org/apache/lucene/search/TestNumericRangeQuery64.java
index e05a68f..8dfe311 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestNumericRangeQuery64.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestNumericRangeQuery64.java
@@ -19,25 +19,23 @@ package org.apache.lucene.search;
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
-import org.apache.lucene.document.DoubleField;
+import org.apache.lucene.document.LegacyDoubleField;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.FieldType;
-import org.apache.lucene.document.LongField;
-import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.document.LegacyLongField;
 import org.apache.lucene.index.DirectoryReader;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.MultiFields;
 import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.SlowCompositeReaderWrapper;
 import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.Terms;
 import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
+import org.apache.lucene.util.LegacyNumericUtils;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util.NumericUtils;
-import org.apache.lucene.util.TestNumericUtils; // NaN arrays
+import org.apache.lucene.util.TestLegacyNumericUtils;
 import org.apache.lucene.util.TestUtil;
 import org.junit.AfterClass;
 import org.junit.BeforeClass;
@@ -65,7 +63,7 @@ public class TestNumericRangeQuery64 extends LuceneTestCase {
         .setMaxBufferedDocs(TestUtil.nextInt(random(), 100, 1000))
         .setMergePolicy(newLogMergePolicy()));
 
-    final FieldType storedLong = new FieldType(LongField.TYPE_NOT_STORED);
+    final FieldType storedLong = new FieldType(LegacyLongField.TYPE_NOT_STORED);
     storedLong.setStored(true);
     storedLong.freeze();
 
@@ -84,7 +82,7 @@ public class TestNumericRangeQuery64 extends LuceneTestCase {
     final FieldType storedLongNone = new FieldType(storedLong);
     storedLongNone.setNumericPrecisionStep(Integer.MAX_VALUE);
 
-    final FieldType unstoredLong = LongField.TYPE_NOT_STORED;
+    final FieldType unstoredLong = LegacyLongField.TYPE_NOT_STORED;
 
     final FieldType unstoredLong8 = new FieldType(unstoredLong);
     unstoredLong8.setNumericPrecisionStep(8);
@@ -98,16 +96,16 @@ public class TestNumericRangeQuery64 extends LuceneTestCase {
     final FieldType unstoredLong2 = new FieldType(unstoredLong);
     unstoredLong2.setNumericPrecisionStep(2);
 
-    LongField
-      field8 = new LongField("field8", 0L, storedLong8),
-      field6 = new LongField("field6", 0L, storedLong6),
-      field4 = new LongField("field4", 0L, storedLong4),
-      field2 = new LongField("field2", 0L, storedLong2),
-      fieldNoTrie = new LongField("field"+Integer.MAX_VALUE, 0L, storedLongNone),
-      ascfield8 = new LongField("ascfield8", 0L, unstoredLong8),
-      ascfield6 = new LongField("ascfield6", 0L, unstoredLong6),
-      ascfield4 = new LongField("ascfield4", 0L, unstoredLong4),
-      ascfield2 = new LongField("ascfield2", 0L, unstoredLong2);
+    LegacyLongField
+      field8 = new LegacyLongField("field8", 0L, storedLong8),
+      field6 = new LegacyLongField("field6", 0L, storedLong6),
+      field4 = new LegacyLongField("field4", 0L, storedLong4),
+      field2 = new LegacyLongField("field2", 0L, storedLong2),
+      fieldNoTrie = new LegacyLongField("field"+Integer.MAX_VALUE, 0L, storedLongNone),
+      ascfield8 = new LegacyLongField("ascfield8", 0L, unstoredLong8),
+      ascfield6 = new LegacyLongField("ascfield6", 0L, unstoredLong6),
+      ascfield4 = new LegacyLongField("ascfield4", 0L, unstoredLong4),
+      ascfield2 = new LegacyLongField("ascfield2", 0L, unstoredLong2);
 
     Document doc = new Document();
     // add fields, that have a distance to test general functionality
@@ -158,7 +156,7 @@ public class TestNumericRangeQuery64 extends LuceneTestCase {
     String field="field"+precisionStep;
     int count=3000;
     long lower=(distance*3/2)+startOffset, upper=lower + count*distance + (distance/3);
-    NumericRangeQuery<Long> q = NumericRangeQuery.newLongRange(field, precisionStep, lower, upper, true, true);
+    LegacyNumericRangeQuery<Long> q = LegacyNumericRangeQuery.newLongRange(field, precisionStep, lower, upper, true, true);
     for (byte i=0; i<2; i++) {
       TopDocs topDocs;
       String type;
@@ -208,7 +206,7 @@ public class TestNumericRangeQuery64 extends LuceneTestCase {
   
   @Test
   public void testOneMatchQuery() throws Exception {
-    NumericRangeQuery<Long> q = NumericRangeQuery.newLongRange("ascfield8", 8, 1000L, 1000L, true, true);
+    LegacyNumericRangeQuery<Long> q = LegacyNumericRangeQuery.newLongRange("ascfield8", 8, 1000L, 1000L, true, true);
     TopDocs topDocs = searcher.search(q, noDocs);
     ScoreDoc[] sd = topDocs.scoreDocs;
     assertNotNull(sd);
@@ -219,7 +217,7 @@ public class TestNumericRangeQuery64 extends LuceneTestCase {
     String field="field"+precisionStep;
     int count=3000;
     long upper=(count-1)*distance + (distance/3) + startOffset;
-    NumericRangeQuery<Long> q=NumericRangeQuery.newLongRange(field, precisionStep, null, upper, true, true);
+    LegacyNumericRangeQuery<Long> q= LegacyNumericRangeQuery.newLongRange(field, precisionStep, null, upper, true, true);
     TopDocs topDocs = searcher.search(q, noDocs, Sort.INDEXORDER);
     ScoreDoc[] sd = topDocs.scoreDocs;
     assertNotNull(sd);
@@ -229,7 +227,7 @@ public class TestNumericRangeQuery64 extends LuceneTestCase {
     doc=searcher.doc(sd[sd.length-1].doc);
     assertEquals("Last doc", (count-1)*distance+startOffset, doc.getField(field).numericValue().longValue() );
 
-    q=NumericRangeQuery.newLongRange(field, precisionStep, null, upper, false, true);
+    q= LegacyNumericRangeQuery.newLongRange(field, precisionStep, null, upper, false, true);
     topDocs = searcher.search(q, noDocs, Sort.INDEXORDER);
     sd = topDocs.scoreDocs;
     assertNotNull(sd);
@@ -264,7 +262,7 @@ public class TestNumericRangeQuery64 extends LuceneTestCase {
     String field="field"+precisionStep;
     int count=3000;
     long lower=(count-1)*distance + (distance/3) +startOffset;
-    NumericRangeQuery<Long> q=NumericRangeQuery.newLongRange(field, precisionStep, lower, null, true, true);
+    LegacyNumericRangeQuery<Long> q= LegacyNumericRangeQuery.newLongRange(field, precisionStep, lower, null, true, true);
     TopDocs topDocs = searcher.search(q, noDocs, Sort.INDEXORDER);
     ScoreDoc[] sd = topDocs.scoreDocs;
     assertNotNull(sd);
@@ -274,7 +272,7 @@ public class TestNumericRangeQuery64 extends LuceneTestCase {
     doc=searcher.doc(sd[sd.length-1].doc);
     assertEquals("Last doc", (noDocs-1)*distance+startOffset, doc.getField(field).numericValue().longValue() );
 
-    q=NumericRangeQuery.newLongRange(field, precisionStep, lower, null, true, false);
+    q= LegacyNumericRangeQuery.newLongRange(field, precisionStep, lower, null, true, false);
     topDocs = searcher.search(q, noDocs, Sort.INDEXORDER);
     sd = topDocs.scoreDocs;
     assertNotNull(sd);
@@ -311,23 +309,23 @@ public class TestNumericRangeQuery64 extends LuceneTestCase {
     RandomIndexWriter writer = new RandomIndexWriter(random(), dir,
       newIndexWriterConfig(new MockAnalyzer(random())));
     Document doc = new Document();
-    doc.add(new DoubleField("double", Double.NEGATIVE_INFINITY, Field.Store.NO));
-    doc.add(new LongField("long", Long.MIN_VALUE, Field.Store.NO));
+    doc.add(new LegacyDoubleField("double", Double.NEGATIVE_INFINITY, Field.Store.NO));
+    doc.add(new LegacyLongField("long", Long.MIN_VALUE, Field.Store.NO));
     writer.addDocument(doc);
     
     doc = new Document();
-    doc.add(new DoubleField("double", Double.POSITIVE_INFINITY, Field.Store.NO));
-    doc.add(new LongField("long", Long.MAX_VALUE, Field.Store.NO));
+    doc.add(new LegacyDoubleField("double", Double.POSITIVE_INFINITY, Field.Store.NO));
+    doc.add(new LegacyLongField("long", Long.MAX_VALUE, Field.Store.NO));
     writer.addDocument(doc);
     
     doc = new Document();
-    doc.add(new DoubleField("double", 0.0, Field.Store.NO));
-    doc.add(new LongField("long", 0L, Field.Store.NO));
+    doc.add(new LegacyDoubleField("double", 0.0, Field.Store.NO));
+    doc.add(new LegacyLongField("long", 0L, Field.Store.NO));
     writer.addDocument(doc);
     
-    for (double d : TestNumericUtils.DOUBLE_NANs) {
+    for (double d : TestLegacyNumericUtils.DOUBLE_NANs) {
       doc = new Document();
-      doc.add(new DoubleField("double", d, Field.Store.NO));
+      doc.add(new LegacyDoubleField("double", d, Field.Store.NO));
       writer.addDocument(doc);
     }
     
@@ -336,41 +334,41 @@ public class TestNumericRangeQuery64 extends LuceneTestCase {
     IndexReader r = DirectoryReader.open(dir);
     IndexSearcher s = newSearcher(r);
     
-    Query q=NumericRangeQuery.newLongRange("long", null, null, true, true);
+    Query q= LegacyNumericRangeQuery.newLongRange("long", null, null, true, true);
     TopDocs topDocs = s.search(q, 10);
     assertEquals("Score doc count", 3,  topDocs.scoreDocs.length );
     
-    q=NumericRangeQuery.newLongRange("long", null, null, false, false);
+    q= LegacyNumericRangeQuery.newLongRange("long", null, null, false, false);
     topDocs = s.search(q, 10);
     assertEquals("Score doc count", 3,  topDocs.scoreDocs.length );
 
-    q=NumericRangeQuery.newLongRange("long", Long.MIN_VALUE, Long.MAX_VALUE, true, true);
+    q= LegacyNumericRangeQuery.newLongRange("long", Long.MIN_VALUE, Long.MAX_VALUE, true, true);
     topDocs = s.search(q, 10);
     assertEquals("Score doc count", 3,  topDocs.scoreDocs.length );
     
-    q=NumericRangeQuery.newLongRange("long", Long.MIN_VALUE, Long.MAX_VALUE, false, false);
+    q= LegacyNumericRangeQuery.newLongRange("long", Long.MIN_VALUE, Long.MAX_VALUE, false, false);
     topDocs = s.search(q, 10);
     assertEquals("Score doc count", 1,  topDocs.scoreDocs.length );
 
-    q=NumericRangeQuery.newDoubleRange("double", null, null, true, true);
+    q= LegacyNumericRangeQuery.newDoubleRange("double", null, null, true, true);
     topDocs = s.search(q, 10);
     assertEquals("Score doc count", 3,  topDocs.scoreDocs.length );
 
-    q=NumericRangeQuery.newDoubleRange("double", null, null, false, false);
+    q= LegacyNumericRangeQuery.newDoubleRange("double", null, null, false, false);
     topDocs = s.search(q, 10);
     assertEquals("Score doc count", 3,  topDocs.scoreDocs.length );
 
-    q=NumericRangeQuery.newDoubleRange("double", Double.NEGATIVE_INFINITY, Double.POSITIVE_INFINITY, true, true);
+    q= LegacyNumericRangeQuery.newDoubleRange("double", Double.NEGATIVE_INFINITY, Double.POSITIVE_INFINITY, true, true);
     topDocs = s.search(q, 10);
     assertEquals("Score doc count", 3,  topDocs.scoreDocs.length );
 
-    q=NumericRangeQuery.newDoubleRange("double", Double.NEGATIVE_INFINITY, Double.POSITIVE_INFINITY, false, false);
+    q= LegacyNumericRangeQuery.newDoubleRange("double", Double.NEGATIVE_INFINITY, Double.POSITIVE_INFINITY, false, false);
     topDocs = s.search(q, 10);
     assertEquals("Score doc count", 1,  topDocs.scoreDocs.length );
 
-    q=NumericRangeQuery.newDoubleRange("double", Double.NaN, Double.NaN, true, true);
+    q= LegacyNumericRangeQuery.newDoubleRange("double", Double.NaN, Double.NaN, true, true);
     topDocs = s.search(q, 10);
-    assertEquals("Score doc count", TestNumericUtils.DOUBLE_NANs.length,  topDocs.scoreDocs.length );
+    assertEquals("Score doc count", TestLegacyNumericUtils.DOUBLE_NANs.length,  topDocs.scoreDocs.length );
 
     r.close();
     dir.close();
@@ -388,44 +386,44 @@ public class TestNumericRangeQuery64 extends LuceneTestCase {
       }
       final BytesRef lowerBytes, upperBytes;
       BytesRefBuilder b = new BytesRefBuilder();
-      NumericUtils.longToPrefixCodedBytes(lower, 0, b);
+      LegacyNumericUtils.longToPrefixCodedBytes(lower, 0, b);
       lowerBytes = b.toBytesRef();
-      NumericUtils.longToPrefixCodedBytes(upper, 0, b);
+      LegacyNumericUtils.longToPrefixCodedBytes(upper, 0, b);
       upperBytes = b.toBytesRef();
       
       // test inclusive range
-      NumericRangeQuery<Long> tq=NumericRangeQuery.newLongRange(field, precisionStep, lower, upper, true, true);
+      LegacyNumericRangeQuery<Long> tq= LegacyNumericRangeQuery.newLongRange(field, precisionStep, lower, upper, true, true);
       TermRangeQuery cq=new TermRangeQuery(field, lowerBytes, upperBytes, true, true);
       TopDocs tTopDocs = searcher.search(tq, 1);
       TopDocs cTopDocs = searcher.search(cq, 1);
-      assertEquals("Returned count for NumericRangeQuery and TermRangeQuery must be equal", cTopDocs.totalHits, tTopDocs.totalHits );
+      assertEquals("Returned count for LegacyNumericRangeQuery and TermRangeQuery must be equal", cTopDocs.totalHits, tTopDocs.totalHits );
       totalTermCountT += termCountT = countTerms(tq);
       totalTermCountC += termCountC = countTerms(cq);
       checkTermCounts(precisionStep, termCountT, termCountC);
       // test exclusive range
-      tq=NumericRangeQuery.newLongRange(field, precisionStep, lower, upper, false, false);
+      tq= LegacyNumericRangeQuery.newLongRange(field, precisionStep, lower, upper, false, false);
       cq=new TermRangeQuery(field, lowerBytes, upperBytes, false, false);
       tTopDocs = searcher.search(tq, 1);
       cTopDocs = searcher.search(cq, 1);
-      assertEquals("Returned count for NumericRangeQuery and TermRangeQuery must be equal", cTopDocs.totalHits, tTopDocs.totalHits );
+      assertEquals("Returned count for LegacyNumericRangeQuery and TermRangeQuery must be equal", cTopDocs.totalHits, tTopDocs.totalHits );
       totalTermCountT += termCountT = countTerms(tq);
       totalTermCountC += termCountC = countTerms(cq);
       checkTermCounts(precisionStep, termCountT, termCountC);
       // test left exclusive range
-      tq=NumericRangeQuery.newLongRange(field, precisionStep, lower, upper, false, true);
+      tq= LegacyNumericRangeQuery.newLongRange(field, precisionStep, lower, upper, false, true);
       cq=new TermRangeQuery(field, lowerBytes, upperBytes, false, true);
       tTopDocs = searcher.search(tq, 1);
       cTopDocs = searcher.search(cq, 1);
-      assertEquals("Returned count for NumericRangeQuery and TermRangeQuery must be equal", cTopDocs.totalHits, tTopDocs.totalHits );
+      assertEquals("Returned count for LegacyNumericRangeQuery and TermRangeQuery must be equal", cTopDocs.totalHits, tTopDocs.totalHits );
       totalTermCountT += termCountT = countTerms(tq);
       totalTermCountC += termCountC = countTerms(cq);
       checkTermCounts(precisionStep, termCountT, termCountC);
       // test right exclusive range
-      tq=NumericRangeQuery.newLongRange(field, precisionStep, lower, upper, true, false);
+      tq= LegacyNumericRangeQuery.newLongRange(field, precisionStep, lower, upper, true, false);
       cq=new TermRangeQuery(field, lowerBytes, upperBytes, true, false);
       tTopDocs = searcher.search(tq, 1);
       cTopDocs = searcher.search(cq, 1);
-      assertEquals("Returned count for NumericRangeQuery and TermRangeQuery must be equal", cTopDocs.totalHits, tTopDocs.totalHits );
+      assertEquals("Returned count for LegacyNumericRangeQuery and TermRangeQuery must be equal", cTopDocs.totalHits, tTopDocs.totalHits );
       totalTermCountT += termCountT = countTerms(tq);
       totalTermCountC += termCountC = countTerms(cq);
       checkTermCounts(precisionStep, termCountT, termCountC);
@@ -445,13 +443,13 @@ public class TestNumericRangeQuery64 extends LuceneTestCase {
     long lower=(distance*3/2)+startOffset, upper=lower + count*distance + (distance/3);
     // test empty enum
     assert lower < upper;
-    assertTrue(0 < countTerms(NumericRangeQuery.newLongRange("field4", 4, lower, upper, true, true)));
-    assertEquals(0, countTerms(NumericRangeQuery.newLongRange("field4", 4, upper, lower, true, true)));
+    assertTrue(0 < countTerms(LegacyNumericRangeQuery.newLongRange("field4", 4, lower, upper, true, true)));
+    assertEquals(0, countTerms(LegacyNumericRangeQuery.newLongRange("field4", 4, upper, lower, true, true)));
     // test empty enum outside of bounds
     lower = distance*noDocs+startOffset;
     upper = 2L * lower;
     assert lower < upper;
-    assertEquals(0, countTerms(NumericRangeQuery.newLongRange("field4", 4, lower, upper, true, true)));
+    assertEquals(0, countTerms(LegacyNumericRangeQuery.newLongRange("field4", 4, lower, upper, true, true)));
   }
   
   private int countTerms(MultiTermQuery q) throws Exception {
@@ -518,19 +516,19 @@ public class TestNumericRangeQuery64 extends LuceneTestCase {
         long a=lower; lower=upper; upper=a;
       }
       // test inclusive range
-      Query tq=NumericRangeQuery.newLongRange(field, precisionStep, lower, upper, true, true);
+      Query tq= LegacyNumericRangeQuery.newLongRange(field, precisionStep, lower, upper, true, true);
       TopDocs tTopDocs = searcher.search(tq, 1);
       assertEquals("Returned count of range query must be equal to inclusive range length", upper-lower+1, tTopDocs.totalHits );
       // test exclusive range
-      tq=NumericRangeQuery.newLongRange(field, precisionStep, lower, upper, false, false);
+      tq= LegacyNumericRangeQuery.newLongRange(field, precisionStep, lower, upper, false, false);
       tTopDocs = searcher.search(tq, 1);
       assertEquals("Returned count of range query must be equal to exclusive range length", Math.max(upper-lower-1, 0), tTopDocs.totalHits );
       // test left exclusive range
-      tq=NumericRangeQuery.newLongRange(field, precisionStep, lower, upper, false, true);
+      tq= LegacyNumericRangeQuery.newLongRange(field, precisionStep, lower, upper, false, true);
       tTopDocs = searcher.search(tq, 1);
       assertEquals("Returned count of range query must be equal to half exclusive range length", upper-lower, tTopDocs.totalHits );
       // test right exclusive range
-      tq=NumericRangeQuery.newLongRange(field, precisionStep, lower, upper, true, false);
+      tq= LegacyNumericRangeQuery.newLongRange(field, precisionStep, lower, upper, true, false);
       tTopDocs = searcher.search(tq, 1);
       assertEquals("Returned count of range query must be equal to half exclusive range length", upper-lower, tTopDocs.totalHits );
     }
@@ -556,13 +554,13 @@ public class TestNumericRangeQuery64 extends LuceneTestCase {
     testRangeSplit(2);
   }
   
-  /** we fake a double test using long2double conversion of NumericUtils */
+  /** we fake a double test using long2double conversion of LegacyNumericUtils */
   private void testDoubleRange(int precisionStep) throws Exception {
     final String field="ascfield"+precisionStep;
     final long lower=-1000L, upper=+2000L;
     
-    Query tq=NumericRangeQuery.newDoubleRange(field, precisionStep,
-      NumericUtils.sortableLongToDouble(lower), NumericUtils.sortableLongToDouble(upper), true, true);
+    Query tq= LegacyNumericRangeQuery.newDoubleRange(field, precisionStep,
+        LegacyNumericUtils.sortableLongToDouble(lower), LegacyNumericUtils.sortableLongToDouble(upper), true, true);
     TopDocs tTopDocs = searcher.search(tq, 1);
     assertEquals("Returned count of range query must be equal to inclusive range length", upper-lower+1, tTopDocs.totalHits );
   }
@@ -589,36 +587,36 @@ public class TestNumericRangeQuery64 extends LuceneTestCase {
   
   @Test
   public void testEqualsAndHash() throws Exception {
-    QueryUtils.checkHashEquals(NumericRangeQuery.newLongRange("test1", 4, 10L, 20L, true, true));
-    QueryUtils.checkHashEquals(NumericRangeQuery.newLongRange("test2", 4, 10L, 20L, false, true));
-    QueryUtils.checkHashEquals(NumericRangeQuery.newLongRange("test3", 4, 10L, 20L, true, false));
-    QueryUtils.checkHashEquals(NumericRangeQuery.newLongRange("test4", 4, 10L, 20L, false, false));
-    QueryUtils.checkHashEquals(NumericRangeQuery.newLongRange("test5", 4, 10L, null, true, true));
-    QueryUtils.checkHashEquals(NumericRangeQuery.newLongRange("test6", 4, null, 20L, true, true));
-    QueryUtils.checkHashEquals(NumericRangeQuery.newLongRange("test7", 4, null, null, true, true));
+    QueryUtils.checkHashEquals(LegacyNumericRangeQuery.newLongRange("test1", 4, 10L, 20L, true, true));
+    QueryUtils.checkHashEquals(LegacyNumericRangeQuery.newLongRange("test2", 4, 10L, 20L, false, true));
+    QueryUtils.checkHashEquals(LegacyNumericRangeQuery.newLongRange("test3", 4, 10L, 20L, true, false));
+    QueryUtils.checkHashEquals(LegacyNumericRangeQuery.newLongRange("test4", 4, 10L, 20L, false, false));
+    QueryUtils.checkHashEquals(LegacyNumericRangeQuery.newLongRange("test5", 4, 10L, null, true, true));
+    QueryUtils.checkHashEquals(LegacyNumericRangeQuery.newLongRange("test6", 4, null, 20L, true, true));
+    QueryUtils.checkHashEquals(LegacyNumericRangeQuery.newLongRange("test7", 4, null, null, true, true));
     QueryUtils.checkEqual(
-      NumericRangeQuery.newLongRange("test8", 4, 10L, 20L, true, true), 
-      NumericRangeQuery.newLongRange("test8", 4, 10L, 20L, true, true)
+      LegacyNumericRangeQuery.newLongRange("test8", 4, 10L, 20L, true, true),
+      LegacyNumericRangeQuery.newLongRange("test8", 4, 10L, 20L, true, true)
     );
     QueryUtils.checkUnequal(
-      NumericRangeQuery.newLongRange("test9", 4, 10L, 20L, true, true), 
-      NumericRangeQuery.newLongRange("test9", 8, 10L, 20L, true, true)
+      LegacyNumericRangeQuery.newLongRange("test9", 4, 10L, 20L, true, true),
+      LegacyNumericRangeQuery.newLongRange("test9", 8, 10L, 20L, true, true)
     );
     QueryUtils.checkUnequal(
-      NumericRangeQuery.newLongRange("test10a", 4, 10L, 20L, true, true), 
-      NumericRangeQuery.newLongRange("test10b", 4, 10L, 20L, true, true)
+      LegacyNumericRangeQuery.newLongRange("test10a", 4, 10L, 20L, true, true),
+      LegacyNumericRangeQuery.newLongRange("test10b", 4, 10L, 20L, true, true)
     );
     QueryUtils.checkUnequal(
-      NumericRangeQuery.newLongRange("test11", 4, 10L, 20L, true, true), 
-      NumericRangeQuery.newLongRange("test11", 4, 20L, 10L, true, true)
+      LegacyNumericRangeQuery.newLongRange("test11", 4, 10L, 20L, true, true),
+      LegacyNumericRangeQuery.newLongRange("test11", 4, 20L, 10L, true, true)
     );
     QueryUtils.checkUnequal(
-      NumericRangeQuery.newLongRange("test12", 4, 10L, 20L, true, true), 
-      NumericRangeQuery.newLongRange("test12", 4, 10L, 20L, false, true)
+      LegacyNumericRangeQuery.newLongRange("test12", 4, 10L, 20L, true, true),
+      LegacyNumericRangeQuery.newLongRange("test12", 4, 10L, 20L, false, true)
     );
     QueryUtils.checkUnequal(
-      NumericRangeQuery.newLongRange("test13", 4, 10L, 20L, true, true), 
-      NumericRangeQuery.newFloatRange("test13", 4, 10f, 20f, true, true)
+      LegacyNumericRangeQuery.newLongRange("test13", 4, 10L, 20L, true, true),
+      LegacyNumericRangeQuery.newFloatRange("test13", 4, 10f, 20f, true, true)
     );
      // difference to int range is tested in TestNumericRangeQuery32
   }
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestSortedNumericSortField.java b/lucene/core/src/test/org/apache/lucene/search/TestSortedNumericSortField.java
index 2a9d63e..ecdce26 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestSortedNumericSortField.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestSortedNumericSortField.java
@@ -25,8 +25,8 @@ import org.apache.lucene.index.MultiReader;
 import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.LegacyNumericUtils;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util.NumericUtils;
 
 /** Simple tests for SortedNumericSortField */
 public class TestSortedNumericSortField extends LuceneTestCase {
@@ -223,12 +223,12 @@ public class TestSortedNumericSortField extends LuceneTestCase {
     Directory dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random(), dir);
     Document doc = new Document();
-    doc.add(new SortedNumericDocValuesField("value", NumericUtils.floatToSortableInt(-3f)));
+    doc.add(new SortedNumericDocValuesField("value", LegacyNumericUtils.floatToSortableInt(-3f)));
     doc.add(newStringField("id", "2", Field.Store.YES));
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new SortedNumericDocValuesField("value", NumericUtils.floatToSortableInt(-5f)));
-    doc.add(new SortedNumericDocValuesField("value", NumericUtils.floatToSortableInt(7f)));
+    doc.add(new SortedNumericDocValuesField("value", LegacyNumericUtils.floatToSortableInt(-5f)));
+    doc.add(new SortedNumericDocValuesField("value", LegacyNumericUtils.floatToSortableInt(7f)));
     doc.add(newStringField("id", "1", Field.Store.YES));
     writer.addDocument(doc);
     IndexReader ir = writer.getReader();
@@ -251,12 +251,12 @@ public class TestSortedNumericSortField extends LuceneTestCase {
     Directory dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random(), dir);
     Document doc = new Document();
-    doc.add(new SortedNumericDocValuesField("value", NumericUtils.doubleToSortableLong(-3d)));
+    doc.add(new SortedNumericDocValuesField("value", LegacyNumericUtils.doubleToSortableLong(-3d)));
     doc.add(newStringField("id", "2", Field.Store.YES));
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new SortedNumericDocValuesField("value", NumericUtils.doubleToSortableLong(-5d)));
-    doc.add(new SortedNumericDocValuesField("value", NumericUtils.doubleToSortableLong(7d)));
+    doc.add(new SortedNumericDocValuesField("value", LegacyNumericUtils.doubleToSortableLong(-5d)));
+    doc.add(new SortedNumericDocValuesField("value", LegacyNumericUtils.doubleToSortableLong(7d)));
     doc.add(newStringField("id", "1", Field.Store.YES));
     writer.addDocument(doc);
     IndexReader ir = writer.getReader();
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestUsageTrackingFilterCachingPolicy.java b/lucene/core/src/test/org/apache/lucene/search/TestUsageTrackingFilterCachingPolicy.java
index fbbca92..d41f57d 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestUsageTrackingFilterCachingPolicy.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestUsageTrackingFilterCachingPolicy.java
@@ -26,7 +26,7 @@ public class TestUsageTrackingFilterCachingPolicy extends LuceneTestCase {
 
   public void testCostlyFilter() {
     assertTrue(UsageTrackingQueryCachingPolicy.isCostly(new PrefixQuery(new Term("field", "prefix"))));
-    assertTrue(UsageTrackingQueryCachingPolicy.isCostly(NumericRangeQuery.newIntRange("intField", 8, 1, 1000, true, true)));
+    assertTrue(UsageTrackingQueryCachingPolicy.isCostly(DimensionalRangeQuery.new1DIntRange("intField", 1, true, 1000, true)));
     assertFalse(UsageTrackingQueryCachingPolicy.isCostly(new TermQuery(new Term("field", "value"))));
   }
 
diff --git a/lucene/core/src/test/org/apache/lucene/util/TestLegacyNumericUtils.java b/lucene/core/src/test/org/apache/lucene/util/TestLegacyNumericUtils.java
new file mode 100644
index 0000000..cab77e5
--- /dev/null
+++ b/lucene/core/src/test/org/apache/lucene/util/TestLegacyNumericUtils.java
@@ -0,0 +1,568 @@
+package org.apache.lucene.util;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.util.Arrays;
+import java.util.Collections;
+import java.util.Iterator;
+import java.util.Random;
+
+public class TestLegacyNumericUtils extends LuceneTestCase {
+
+  public void testLongConversionAndOrdering() throws Exception {
+    // generate a series of encoded longs, each numerical one bigger than the one before
+    BytesRefBuilder last = new BytesRefBuilder();
+    BytesRefBuilder act = new BytesRefBuilder();
+    for (long l=-100000L; l<100000L; l++) {
+      LegacyNumericUtils.longToPrefixCodedBytes(l, 0, act);
+      if (last!=null) {
+        // test if smaller
+        assertTrue("actual bigger than last (BytesRef)", last.get().compareTo(act.get()) < 0 );
+        assertTrue("actual bigger than last (as String)", last.get().utf8ToString().compareTo(act.get().utf8ToString()) < 0 );
+      }
+      // test is back and forward conversion works
+      assertEquals("forward and back conversion should generate same long", l, LegacyNumericUtils.prefixCodedToLong(act.get()));
+      // next step
+      last.copyBytes(act);
+    }
+  }
+
+  public void testIntConversionAndOrdering() throws Exception {
+    // generate a series of encoded ints, each numerical one bigger than the one before
+    BytesRefBuilder act = new BytesRefBuilder();
+    BytesRefBuilder last = new BytesRefBuilder();
+    for (int i=-100000; i<100000; i++) {
+      LegacyNumericUtils.intToPrefixCodedBytes(i, 0, act);
+      if (last!=null) {
+        // test if smaller
+        assertTrue("actual bigger than last (BytesRef)", last.get().compareTo(act.get()) < 0 );
+        assertTrue("actual bigger than last (as String)", last.get().utf8ToString().compareTo(act.get().utf8ToString()) < 0 );
+      }
+      // test is back and forward conversion works
+      assertEquals("forward and back conversion should generate same int", i, LegacyNumericUtils.prefixCodedToInt(act.get()));
+      // next step
+      last.copyBytes(act.get());
+    }
+  }
+
+  public void testLongSpecialValues() throws Exception {
+    long[] vals=new long[]{
+      Long.MIN_VALUE, Long.MIN_VALUE+1, Long.MIN_VALUE+2, -5003400000000L,
+      -4000L, -3000L, -2000L, -1000L, -1L, 0L, 1L, 10L, 300L, 50006789999999999L, Long.MAX_VALUE-2, Long.MAX_VALUE-1, Long.MAX_VALUE
+    };
+    BytesRefBuilder[] prefixVals = new BytesRefBuilder[vals.length];
+    
+    for (int i=0; i<vals.length; i++) {
+      prefixVals[i] = new BytesRefBuilder();
+      LegacyNumericUtils.longToPrefixCodedBytes(vals[i], 0, prefixVals[i]);
+      
+      // check forward and back conversion
+      assertEquals( "forward and back conversion should generate same long", vals[i], LegacyNumericUtils.prefixCodedToLong(prefixVals[i].get()) );
+
+      // test if decoding values as int fails correctly
+      try {
+        LegacyNumericUtils.prefixCodedToInt(prefixVals[i].get());
+        fail("decoding a prefix coded long value as int should fail");
+      } catch (NumberFormatException e) {
+        // worked
+      }
+    }
+    
+    // check sort order (prefixVals should be ascending)
+    for (int i=1; i<prefixVals.length; i++) {
+      assertTrue( "check sort order", prefixVals[i-1].get().compareTo(prefixVals[i].get()) < 0 );
+    }
+        
+    // check the prefix encoding, lower precision should have the difference to original value equal to the lower removed bits
+    final BytesRefBuilder ref = new BytesRefBuilder();
+    for (int i=0; i<vals.length; i++) {
+      for (int j=0; j<64; j++) {
+        LegacyNumericUtils.longToPrefixCodedBytes(vals[i], j, ref);
+        long prefixVal= LegacyNumericUtils.prefixCodedToLong(ref.get());
+        long mask=(1L << j) - 1L;
+        assertEquals( "difference between prefix val and original value for "+vals[i]+" with shift="+j, vals[i] & mask, vals[i]-prefixVal );
+      }
+    }
+  }
+
+  public void testIntSpecialValues() throws Exception {
+    int[] vals=new int[]{
+      Integer.MIN_VALUE, Integer.MIN_VALUE+1, Integer.MIN_VALUE+2, -64765767,
+      -4000, -3000, -2000, -1000, -1, 0, 1, 10, 300, 765878989, Integer.MAX_VALUE-2, Integer.MAX_VALUE-1, Integer.MAX_VALUE
+    };
+    BytesRefBuilder[] prefixVals=new BytesRefBuilder[vals.length];
+    
+    for (int i=0; i<vals.length; i++) {
+      prefixVals[i] = new BytesRefBuilder();
+      LegacyNumericUtils.intToPrefixCodedBytes(vals[i], 0, prefixVals[i]);
+      
+      // check forward and back conversion
+      assertEquals( "forward and back conversion should generate same int", vals[i], LegacyNumericUtils.prefixCodedToInt(prefixVals[i].get()) );
+      
+      // test if decoding values as long fails correctly
+      try {
+        LegacyNumericUtils.prefixCodedToLong(prefixVals[i].get());
+        fail("decoding a prefix coded int value as long should fail");
+      } catch (NumberFormatException e) {
+        // worked
+      }
+    }
+    
+    // check sort order (prefixVals should be ascending)
+    for (int i=1; i<prefixVals.length; i++) {
+      assertTrue( "check sort order", prefixVals[i-1].get().compareTo(prefixVals[i].get()) < 0 );
+    }
+    
+    // check the prefix encoding, lower precision should have the difference to original value equal to the lower removed bits
+    final BytesRefBuilder ref = new BytesRefBuilder();
+    for (int i=0; i<vals.length; i++) {
+      for (int j=0; j<32; j++) {
+        LegacyNumericUtils.intToPrefixCodedBytes(vals[i], j, ref);
+        int prefixVal= LegacyNumericUtils.prefixCodedToInt(ref.get());
+        int mask=(1 << j) - 1;
+        assertEquals( "difference between prefix val and original value for "+vals[i]+" with shift="+j, vals[i] & mask, vals[i]-prefixVal );
+      }
+    }
+  }
+
+  public void testDoubles() throws Exception {
+    double[] vals=new double[]{
+      Double.NEGATIVE_INFINITY, -2.3E25, -1.0E15, -1.0, -1.0E-1, -1.0E-2, -0.0, 
+      +0.0, 1.0E-2, 1.0E-1, 1.0, 1.0E15, 2.3E25, Double.POSITIVE_INFINITY, Double.NaN
+    };
+    long[] longVals=new long[vals.length];
+    
+    // check forward and back conversion
+    for (int i=0; i<vals.length; i++) {
+      longVals[i]= LegacyNumericUtils.doubleToSortableLong(vals[i]);
+      assertTrue( "forward and back conversion should generate same double", Double.compare(vals[i], LegacyNumericUtils.sortableLongToDouble(longVals[i]))==0 );
+    }
+    
+    // check sort order (prefixVals should be ascending)
+    for (int i=1; i<longVals.length; i++) {
+      assertTrue( "check sort order", longVals[i-1] < longVals[i] );
+    }
+  }
+
+  public static final double[] DOUBLE_NANs = {
+    Double.NaN,
+    Double.longBitsToDouble(0x7ff0000000000001L),
+    Double.longBitsToDouble(0x7fffffffffffffffL),
+    Double.longBitsToDouble(0xfff0000000000001L),
+    Double.longBitsToDouble(0xffffffffffffffffL)
+  };
+
+  public void testSortableDoubleNaN() {
+    final long plusInf = LegacyNumericUtils.doubleToSortableLong(Double.POSITIVE_INFINITY);
+    for (double nan : DOUBLE_NANs) {
+      assertTrue(Double.isNaN(nan));
+      final long sortable = LegacyNumericUtils.doubleToSortableLong(nan);
+      assertTrue("Double not sorted correctly: " + nan + ", long repr: " 
+          + sortable + ", positive inf.: " + plusInf, sortable > plusInf);
+    }
+  }
+  
+  public void testFloats() throws Exception {
+    float[] vals=new float[]{
+      Float.NEGATIVE_INFINITY, -2.3E25f, -1.0E15f, -1.0f, -1.0E-1f, -1.0E-2f, -0.0f, 
+      +0.0f, 1.0E-2f, 1.0E-1f, 1.0f, 1.0E15f, 2.3E25f, Float.POSITIVE_INFINITY, Float.NaN
+    };
+    int[] intVals=new int[vals.length];
+    
+    // check forward and back conversion
+    for (int i=0; i<vals.length; i++) {
+      intVals[i]= LegacyNumericUtils.floatToSortableInt(vals[i]);
+      assertTrue( "forward and back conversion should generate same double", Float.compare(vals[i], LegacyNumericUtils.sortableIntToFloat(intVals[i]))==0 );
+    }
+    
+    // check sort order (prefixVals should be ascending)
+    for (int i=1; i<intVals.length; i++) {
+      assertTrue( "check sort order", intVals[i-1] < intVals[i] );
+    }
+  }
+
+  public static final float[] FLOAT_NANs = {
+    Float.NaN,
+    Float.intBitsToFloat(0x7f800001),
+    Float.intBitsToFloat(0x7fffffff),
+    Float.intBitsToFloat(0xff800001),
+    Float.intBitsToFloat(0xffffffff)
+  };
+
+  public void testSortableFloatNaN() {
+    final int plusInf = LegacyNumericUtils.floatToSortableInt(Float.POSITIVE_INFINITY);
+    for (float nan : FLOAT_NANs) {
+      assertTrue(Float.isNaN(nan));
+      final int sortable = LegacyNumericUtils.floatToSortableInt(nan);
+      assertTrue("Float not sorted correctly: " + nan + ", int repr: " 
+          + sortable + ", positive inf.: " + plusInf, sortable > plusInf);
+    }
+  }
+
+  // INFO: Tests for trieCodeLong()/trieCodeInt() not needed because implicitely tested by range filter tests
+  
+  /** Note: The neededBounds Iterable must be unsigned (easier understanding what's happening) */
+  private void assertLongRangeSplit(final long lower, final long upper, int precisionStep,
+    final boolean useBitSet, final Iterable<Long> expectedBounds, final Iterable<Integer> expectedShifts
+  ) {
+    // Cannot use FixedBitSet since the range could be long:
+    final LongBitSet bits=useBitSet ? new LongBitSet(upper-lower+1) : null;
+    final Iterator<Long> neededBounds = (expectedBounds == null) ? null : expectedBounds.iterator();
+    final Iterator<Integer> neededShifts = (expectedShifts == null) ? null : expectedShifts.iterator();
+
+    LegacyNumericUtils.splitLongRange(new LegacyNumericUtils.LongRangeBuilder() {
+      @Override
+      public void addRange(long min, long max, int shift) {
+        assertTrue("min, max should be inside bounds", min >= lower && min <= upper && max >= lower && max <= upper);
+        if (useBitSet) for (long l = min; l <= max; l++) {
+          assertFalse("ranges should not overlap", bits.getAndSet(l - lower));
+          // extra exit condition to prevent overflow on MAX_VALUE
+          if (l == max) break;
+        }
+        if (neededBounds == null || neededShifts == null)
+          return;
+        // make unsigned longs for easier display and understanding
+        min ^= 0x8000000000000000L;
+        max ^= 0x8000000000000000L;
+        //System.out.println("0x"+Long.toHexString(min>>>shift)+"L,0x"+Long.toHexString(max>>>shift)+"L)/*shift="+shift+"*/,");
+        assertEquals("shift", neededShifts.next().intValue(), shift);
+        assertEquals("inner min bound", neededBounds.next().longValue(), min >>> shift);
+        assertEquals("inner max bound", neededBounds.next().longValue(), max >>> shift);
+      }
+    }, precisionStep, lower, upper);
+    
+    if (useBitSet) {
+      // after flipping all bits in the range, the cardinality should be zero
+      bits.flip(0,upper-lower+1);
+      assertEquals("The sub-range concenated should match the whole range", 0, bits.cardinality());
+    }
+  }
+  
+  /** LUCENE-2541: LegacyNumericRangeQuery errors with endpoints near long min and max values */
+  public void testLongExtremeValues() throws Exception {
+    // upper end extremes
+    assertLongRangeSplit(Long.MAX_VALUE, Long.MAX_VALUE, 1, true, Arrays.asList(
+      0xffffffffffffffffL,0xffffffffffffffffL
+    ), Arrays.asList(
+      0
+    ));
+    assertLongRangeSplit(Long.MAX_VALUE, Long.MAX_VALUE, 2, true, Arrays.asList(
+      0xffffffffffffffffL,0xffffffffffffffffL
+    ), Arrays.asList(
+      0
+    ));
+    assertLongRangeSplit(Long.MAX_VALUE, Long.MAX_VALUE, 4, true, Arrays.asList(
+      0xffffffffffffffffL,0xffffffffffffffffL
+    ), Arrays.asList(
+      0
+    ));
+    assertLongRangeSplit(Long.MAX_VALUE, Long.MAX_VALUE, 6, true, Arrays.asList(
+      0xffffffffffffffffL,0xffffffffffffffffL
+    ), Arrays.asList(
+      0
+    ));
+    assertLongRangeSplit(Long.MAX_VALUE, Long.MAX_VALUE, 8, true, Arrays.asList(
+      0xffffffffffffffffL,0xffffffffffffffffL
+    ), Arrays.asList(
+      0
+    ));
+    assertLongRangeSplit(Long.MAX_VALUE, Long.MAX_VALUE, 64, true, Arrays.asList(
+      0xffffffffffffffffL,0xffffffffffffffffL
+    ), Arrays.asList(
+      0
+    ));
+
+    assertLongRangeSplit(Long.MAX_VALUE-0xfL, Long.MAX_VALUE, 4, true, Arrays.asList(
+      0xfffffffffffffffL,0xfffffffffffffffL
+    ), Arrays.asList(
+      4
+    ));
+    assertLongRangeSplit(Long.MAX_VALUE-0x10L, Long.MAX_VALUE, 4, true, Arrays.asList(
+      0xffffffffffffffefL,0xffffffffffffffefL,
+      0xfffffffffffffffL,0xfffffffffffffffL
+    ), Arrays.asList(
+      0, 4
+    ));
+
+    // lower end extremes
+    assertLongRangeSplit(Long.MIN_VALUE, Long.MIN_VALUE, 1, true, Arrays.asList(
+      0x0000000000000000L,0x0000000000000000L
+    ), Arrays.asList(
+      0
+    ));
+    assertLongRangeSplit(Long.MIN_VALUE, Long.MIN_VALUE, 2, true, Arrays.asList(
+      0x0000000000000000L,0x0000000000000000L
+    ), Arrays.asList(
+      0
+    ));
+    assertLongRangeSplit(Long.MIN_VALUE, Long.MIN_VALUE, 4, true, Arrays.asList(
+      0x0000000000000000L,0x0000000000000000L
+    ), Arrays.asList(
+      0
+    ));
+    assertLongRangeSplit(Long.MIN_VALUE, Long.MIN_VALUE, 6, true, Arrays.asList(
+      0x0000000000000000L,0x0000000000000000L
+    ), Arrays.asList(
+      0
+    ));
+    assertLongRangeSplit(Long.MIN_VALUE, Long.MIN_VALUE, 8, true, Arrays.asList(
+      0x0000000000000000L,0x0000000000000000L
+    ), Arrays.asList(
+      0
+    ));
+    assertLongRangeSplit(Long.MIN_VALUE, Long.MIN_VALUE, 64, true, Arrays.asList(
+      0x0000000000000000L,0x0000000000000000L
+    ), Arrays.asList(
+      0
+    ));
+
+    assertLongRangeSplit(Long.MIN_VALUE, Long.MIN_VALUE+0xfL, 4, true, Arrays.asList(
+      0x000000000000000L,0x000000000000000L
+    ), Arrays.asList(
+      4
+    ));
+    assertLongRangeSplit(Long.MIN_VALUE, Long.MIN_VALUE+0x10L, 4, true, Arrays.asList(
+      0x0000000000000010L,0x0000000000000010L,
+      0x000000000000000L,0x000000000000000L
+    ), Arrays.asList(
+      0, 4
+    ));
+  }
+  
+  public void testRandomSplit() throws Exception {
+    long num = (long) atLeast(10);
+    for (long i=0; i < num; i++) {
+      executeOneRandomSplit(random());
+    }
+  }
+  
+  private void executeOneRandomSplit(final Random random) throws Exception {
+    long lower = randomLong(random);
+    long len = random.nextInt(16384*1024); // not too large bitsets, else OOME!
+    while (lower + len < lower) { // overflow
+      lower >>= 1;
+    }
+    assertLongRangeSplit(lower, lower + len, random.nextInt(64) + 1, true, null, null);
+  }
+  
+  private long randomLong(final Random random) {
+    long val;
+    switch(random.nextInt(4)) {
+      case 0:
+        val = 1L << (random.nextInt(63)); //  patterns like 0x000000100000 (-1 yields patterns like 0x0000fff)
+        break;
+      case 1:
+        val = -1L << (random.nextInt(63)); // patterns like 0xfffff00000
+        break;
+      default:
+        val = random.nextLong();
+    }
+
+    val += random.nextInt(5)-2;
+
+    if (random.nextBoolean()) {
+      if (random.nextBoolean()) val += random.nextInt(100)-50;
+      if (random.nextBoolean()) val = ~val;
+      if (random.nextBoolean()) val = val<<1;
+      if (random.nextBoolean()) val = val>>>1;
+    }
+
+    return val;
+  }
+  
+  public void testSplitLongRange() throws Exception {
+    // a hard-coded "standard" range
+    assertLongRangeSplit(-5000L, 9500L, 4, true, Arrays.asList(
+      0x7fffffffffffec78L,0x7fffffffffffec7fL,
+      0x8000000000002510L,0x800000000000251cL,
+      0x7fffffffffffec8L, 0x7fffffffffffecfL,
+      0x800000000000250L, 0x800000000000250L,
+      0x7fffffffffffedL,  0x7fffffffffffefL,
+      0x80000000000020L,  0x80000000000024L,
+      0x7ffffffffffffL,   0x8000000000001L
+    ), Arrays.asList(
+      0, 0,
+      4, 4,
+      8, 8,
+      12
+    ));
+    
+    // the same with no range splitting
+    assertLongRangeSplit(-5000L, 9500L, 64, true, Arrays.asList(
+      0x7fffffffffffec78L,0x800000000000251cL
+    ), Arrays.asList(
+      0
+    ));
+    
+    // this tests optimized range splitting, if one of the inner bounds
+    // is also the bound of the next lower precision, it should be used completely
+    assertLongRangeSplit(0L, 1024L+63L, 4, true, Arrays.asList(
+      0x800000000000040L, 0x800000000000043L,
+      0x80000000000000L,  0x80000000000003L
+    ), Arrays.asList(
+      4, 8
+    ));
+    
+    // the full long range should only consist of a lowest precision range; no bitset testing here, as too much memory needed :-)
+    assertLongRangeSplit(Long.MIN_VALUE, Long.MAX_VALUE, 8, false, Arrays.asList(
+      0x00L,0xffL
+    ), Arrays.asList(
+      56
+    ));
+
+    // the same with precisionStep=4
+    assertLongRangeSplit(Long.MIN_VALUE, Long.MAX_VALUE, 4, false, Arrays.asList(
+      0x0L,0xfL
+    ), Arrays.asList(
+      60
+    ));
+
+    // the same with precisionStep=2
+    assertLongRangeSplit(Long.MIN_VALUE, Long.MAX_VALUE, 2, false, Arrays.asList(
+      0x0L,0x3L
+    ), Arrays.asList(
+      62
+    ));
+
+    // the same with precisionStep=1
+    assertLongRangeSplit(Long.MIN_VALUE, Long.MAX_VALUE, 1, false, Arrays.asList(
+      0x0L,0x1L
+    ), Arrays.asList(
+      63
+    ));
+
+    // a inverse range should produce no sub-ranges
+    assertLongRangeSplit(9500L, -5000L, 4, false, Collections.<Long>emptyList(), Collections.<Integer>emptyList());    
+
+    // a 0-length range should reproduce the range itself
+    assertLongRangeSplit(9500L, 9500L, 4, false, Arrays.asList(
+      0x800000000000251cL,0x800000000000251cL
+    ), Arrays.asList(
+      0
+    ));
+  }
+
+  /** Note: The neededBounds Iterable must be unsigned (easier understanding what's happening) */
+  private void assertIntRangeSplit(final int lower, final int upper, int precisionStep,
+    final boolean useBitSet, final Iterable<Integer> expectedBounds, final Iterable<Integer> expectedShifts
+  ) {
+    final FixedBitSet bits=useBitSet ? new FixedBitSet(upper-lower+1) : null;
+    final Iterator<Integer> neededBounds = (expectedBounds == null) ? null : expectedBounds.iterator();
+    final Iterator<Integer> neededShifts = (expectedShifts == null) ? null : expectedShifts.iterator();
+    
+    LegacyNumericUtils.splitIntRange(new LegacyNumericUtils.IntRangeBuilder() {
+      @Override
+      public void addRange(int min, int max, int shift) {
+        assertTrue("min, max should be inside bounds", min >= lower && min <= upper && max >= lower && max <= upper);
+        if (useBitSet) for (int i = min; i <= max; i++) {
+          assertFalse("ranges should not overlap", bits.getAndSet(i - lower));
+          // extra exit condition to prevent overflow on MAX_VALUE
+          if (i == max) break;
+        }
+        if (neededBounds == null)
+          return;
+        // make unsigned ints for easier display and understanding
+        min ^= 0x80000000;
+        max ^= 0x80000000;
+        //System.out.println("0x"+Integer.toHexString(min>>>shift)+",0x"+Integer.toHexString(max>>>shift)+")/*shift="+shift+"*/,");
+        assertEquals("shift", neededShifts.next().intValue(), shift);
+        assertEquals("inner min bound", neededBounds.next().intValue(), min >>> shift);
+        assertEquals("inner max bound", neededBounds.next().intValue(), max >>> shift);
+      }
+    }, precisionStep, lower, upper);
+    
+    if (useBitSet) {
+      // after flipping all bits in the range, the cardinality should be zero
+      bits.flip(0, upper-lower+1);
+      assertEquals("The sub-range concenated should match the whole range", 0, bits.cardinality());
+    }
+  }
+  
+  public void testSplitIntRange() throws Exception {
+    // a hard-coded "standard" range
+    assertIntRangeSplit(-5000, 9500, 4, true, Arrays.asList(
+      0x7fffec78,0x7fffec7f,
+      0x80002510,0x8000251c,
+      0x7fffec8, 0x7fffecf,
+      0x8000250, 0x8000250,
+      0x7fffed,  0x7fffef,
+      0x800020,  0x800024,
+      0x7ffff,   0x80001
+    ), Arrays.asList(
+      0, 0,
+      4, 4,
+      8, 8,
+      12
+    ));
+    
+    // the same with no range splitting
+    assertIntRangeSplit(-5000, 9500, 32, true, Arrays.asList(
+      0x7fffec78,0x8000251c
+    ), Arrays.asList(
+      0
+    ));
+    
+    // this tests optimized range splitting, if one of the inner bounds
+    // is also the bound of the next lower precision, it should be used completely
+    assertIntRangeSplit(0, 1024+63, 4, true, Arrays.asList(
+      0x8000040, 0x8000043,
+      0x800000,  0x800003
+    ), Arrays.asList(
+      4, 8
+    ));
+    
+    // the full int range should only consist of a lowest precision range; no bitset testing here, as too much memory needed :-)
+    assertIntRangeSplit(Integer.MIN_VALUE, Integer.MAX_VALUE, 8, false, Arrays.asList(
+      0x00,0xff
+    ), Arrays.asList(
+      24
+    ));
+
+    // the same with precisionStep=4
+    assertIntRangeSplit(Integer.MIN_VALUE, Integer.MAX_VALUE, 4, false, Arrays.asList(
+      0x0,0xf
+    ), Arrays.asList(
+      28
+    ));
+
+    // the same with precisionStep=2
+    assertIntRangeSplit(Integer.MIN_VALUE, Integer.MAX_VALUE, 2, false, Arrays.asList(
+      0x0,0x3
+    ), Arrays.asList(
+      30
+    ));
+
+    // the same with precisionStep=1
+    assertIntRangeSplit(Integer.MIN_VALUE, Integer.MAX_VALUE, 1, false, Arrays.asList(
+      0x0,0x1
+    ), Arrays.asList(
+      31
+    ));
+
+    // a inverse range should produce no sub-ranges
+    assertIntRangeSplit(9500, -5000, 4, false, Collections.<Integer>emptyList(), Collections.<Integer>emptyList());    
+
+    // a 0-length range should reproduce the range itself
+    assertIntRangeSplit(9500, 9500, 4, false, Arrays.asList(
+      0x8000251c,0x8000251c
+    ), Arrays.asList(
+      0
+    ));
+  }
+
+}
diff --git a/lucene/core/src/test/org/apache/lucene/util/TestNumericUtils.java b/lucene/core/src/test/org/apache/lucene/util/TestNumericUtils.java
deleted file mode 100644
index e28165f..0000000
--- a/lucene/core/src/test/org/apache/lucene/util/TestNumericUtils.java
+++ /dev/null
@@ -1,568 +0,0 @@
-package org.apache.lucene.util;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.util.Arrays;
-import java.util.Collections;
-import java.util.Iterator;
-import java.util.Random;
-
-public class TestNumericUtils extends LuceneTestCase {
-
-  public void testLongConversionAndOrdering() throws Exception {
-    // generate a series of encoded longs, each numerical one bigger than the one before
-    BytesRefBuilder last = new BytesRefBuilder();
-    BytesRefBuilder act = new BytesRefBuilder();
-    for (long l=-100000L; l<100000L; l++) {
-      NumericUtils.longToPrefixCodedBytes(l, 0, act);
-      if (last!=null) {
-        // test if smaller
-        assertTrue("actual bigger than last (BytesRef)", last.get().compareTo(act.get()) < 0 );
-        assertTrue("actual bigger than last (as String)", last.get().utf8ToString().compareTo(act.get().utf8ToString()) < 0 );
-      }
-      // test is back and forward conversion works
-      assertEquals("forward and back conversion should generate same long", l, NumericUtils.prefixCodedToLong(act.get()));
-      // next step
-      last.copyBytes(act);
-    }
-  }
-
-  public void testIntConversionAndOrdering() throws Exception {
-    // generate a series of encoded ints, each numerical one bigger than the one before
-    BytesRefBuilder act = new BytesRefBuilder();
-    BytesRefBuilder last = new BytesRefBuilder();
-    for (int i=-100000; i<100000; i++) {
-      NumericUtils.intToPrefixCodedBytes(i, 0, act);
-      if (last!=null) {
-        // test if smaller
-        assertTrue("actual bigger than last (BytesRef)", last.get().compareTo(act.get()) < 0 );
-        assertTrue("actual bigger than last (as String)", last.get().utf8ToString().compareTo(act.get().utf8ToString()) < 0 );
-      }
-      // test is back and forward conversion works
-      assertEquals("forward and back conversion should generate same int", i, NumericUtils.prefixCodedToInt(act.get()));
-      // next step
-      last.copyBytes(act.get());
-    }
-  }
-
-  public void testLongSpecialValues() throws Exception {
-    long[] vals=new long[]{
-      Long.MIN_VALUE, Long.MIN_VALUE+1, Long.MIN_VALUE+2, -5003400000000L,
-      -4000L, -3000L, -2000L, -1000L, -1L, 0L, 1L, 10L, 300L, 50006789999999999L, Long.MAX_VALUE-2, Long.MAX_VALUE-1, Long.MAX_VALUE
-    };
-    BytesRefBuilder[] prefixVals = new BytesRefBuilder[vals.length];
-    
-    for (int i=0; i<vals.length; i++) {
-      prefixVals[i] = new BytesRefBuilder();
-      NumericUtils.longToPrefixCodedBytes(vals[i], 0, prefixVals[i]);
-      
-      // check forward and back conversion
-      assertEquals( "forward and back conversion should generate same long", vals[i], NumericUtils.prefixCodedToLong(prefixVals[i].get()) );
-
-      // test if decoding values as int fails correctly
-      try {
-        NumericUtils.prefixCodedToInt(prefixVals[i].get());
-        fail("decoding a prefix coded long value as int should fail");
-      } catch (NumberFormatException e) {
-        // worked
-      }
-    }
-    
-    // check sort order (prefixVals should be ascending)
-    for (int i=1; i<prefixVals.length; i++) {
-      assertTrue( "check sort order", prefixVals[i-1].get().compareTo(prefixVals[i].get()) < 0 );
-    }
-        
-    // check the prefix encoding, lower precision should have the difference to original value equal to the lower removed bits
-    final BytesRefBuilder ref = new BytesRefBuilder();
-    for (int i=0; i<vals.length; i++) {
-      for (int j=0; j<64; j++) {
-        NumericUtils.longToPrefixCodedBytes(vals[i], j, ref);
-        long prefixVal=NumericUtils.prefixCodedToLong(ref.get());
-        long mask=(1L << j) - 1L;
-        assertEquals( "difference between prefix val and original value for "+vals[i]+" with shift="+j, vals[i] & mask, vals[i]-prefixVal );
-      }
-    }
-  }
-
-  public void testIntSpecialValues() throws Exception {
-    int[] vals=new int[]{
-      Integer.MIN_VALUE, Integer.MIN_VALUE+1, Integer.MIN_VALUE+2, -64765767,
-      -4000, -3000, -2000, -1000, -1, 0, 1, 10, 300, 765878989, Integer.MAX_VALUE-2, Integer.MAX_VALUE-1, Integer.MAX_VALUE
-    };
-    BytesRefBuilder[] prefixVals=new BytesRefBuilder[vals.length];
-    
-    for (int i=0; i<vals.length; i++) {
-      prefixVals[i] = new BytesRefBuilder();
-      NumericUtils.intToPrefixCodedBytes(vals[i], 0, prefixVals[i]);
-      
-      // check forward and back conversion
-      assertEquals( "forward and back conversion should generate same int", vals[i], NumericUtils.prefixCodedToInt(prefixVals[i].get()) );
-      
-      // test if decoding values as long fails correctly
-      try {
-        NumericUtils.prefixCodedToLong(prefixVals[i].get());
-        fail("decoding a prefix coded int value as long should fail");
-      } catch (NumberFormatException e) {
-        // worked
-      }
-    }
-    
-    // check sort order (prefixVals should be ascending)
-    for (int i=1; i<prefixVals.length; i++) {
-      assertTrue( "check sort order", prefixVals[i-1].get().compareTo(prefixVals[i].get()) < 0 );
-    }
-    
-    // check the prefix encoding, lower precision should have the difference to original value equal to the lower removed bits
-    final BytesRefBuilder ref = new BytesRefBuilder();
-    for (int i=0; i<vals.length; i++) {
-      for (int j=0; j<32; j++) {
-        NumericUtils.intToPrefixCodedBytes(vals[i], j, ref);
-        int prefixVal=NumericUtils.prefixCodedToInt(ref.get());
-        int mask=(1 << j) - 1;
-        assertEquals( "difference between prefix val and original value for "+vals[i]+" with shift="+j, vals[i] & mask, vals[i]-prefixVal );
-      }
-    }
-  }
-
-  public void testDoubles() throws Exception {
-    double[] vals=new double[]{
-      Double.NEGATIVE_INFINITY, -2.3E25, -1.0E15, -1.0, -1.0E-1, -1.0E-2, -0.0, 
-      +0.0, 1.0E-2, 1.0E-1, 1.0, 1.0E15, 2.3E25, Double.POSITIVE_INFINITY, Double.NaN
-    };
-    long[] longVals=new long[vals.length];
-    
-    // check forward and back conversion
-    for (int i=0; i<vals.length; i++) {
-      longVals[i]=NumericUtils.doubleToSortableLong(vals[i]);
-      assertTrue( "forward and back conversion should generate same double", Double.compare(vals[i], NumericUtils.sortableLongToDouble(longVals[i]))==0 );
-    }
-    
-    // check sort order (prefixVals should be ascending)
-    for (int i=1; i<longVals.length; i++) {
-      assertTrue( "check sort order", longVals[i-1] < longVals[i] );
-    }
-  }
-
-  public static final double[] DOUBLE_NANs = {
-    Double.NaN,
-    Double.longBitsToDouble(0x7ff0000000000001L),
-    Double.longBitsToDouble(0x7fffffffffffffffL),
-    Double.longBitsToDouble(0xfff0000000000001L),
-    Double.longBitsToDouble(0xffffffffffffffffL)
-  };
-
-  public void testSortableDoubleNaN() {
-    final long plusInf = NumericUtils.doubleToSortableLong(Double.POSITIVE_INFINITY);
-    for (double nan : DOUBLE_NANs) {
-      assertTrue(Double.isNaN(nan));
-      final long sortable = NumericUtils.doubleToSortableLong(nan);
-      assertTrue("Double not sorted correctly: " + nan + ", long repr: " 
-          + sortable + ", positive inf.: " + plusInf, sortable > plusInf);
-    }
-  }
-  
-  public void testFloats() throws Exception {
-    float[] vals=new float[]{
-      Float.NEGATIVE_INFINITY, -2.3E25f, -1.0E15f, -1.0f, -1.0E-1f, -1.0E-2f, -0.0f, 
-      +0.0f, 1.0E-2f, 1.0E-1f, 1.0f, 1.0E15f, 2.3E25f, Float.POSITIVE_INFINITY, Float.NaN
-    };
-    int[] intVals=new int[vals.length];
-    
-    // check forward and back conversion
-    for (int i=0; i<vals.length; i++) {
-      intVals[i]=NumericUtils.floatToSortableInt(vals[i]);
-      assertTrue( "forward and back conversion should generate same double", Float.compare(vals[i], NumericUtils.sortableIntToFloat(intVals[i]))==0 );
-    }
-    
-    // check sort order (prefixVals should be ascending)
-    for (int i=1; i<intVals.length; i++) {
-      assertTrue( "check sort order", intVals[i-1] < intVals[i] );
-    }
-  }
-
-  public static final float[] FLOAT_NANs = {
-    Float.NaN,
-    Float.intBitsToFloat(0x7f800001),
-    Float.intBitsToFloat(0x7fffffff),
-    Float.intBitsToFloat(0xff800001),
-    Float.intBitsToFloat(0xffffffff)
-  };
-
-  public void testSortableFloatNaN() {
-    final int plusInf = NumericUtils.floatToSortableInt(Float.POSITIVE_INFINITY);
-    for (float nan : FLOAT_NANs) {
-      assertTrue(Float.isNaN(nan));
-      final int sortable = NumericUtils.floatToSortableInt(nan);
-      assertTrue("Float not sorted correctly: " + nan + ", int repr: " 
-          + sortable + ", positive inf.: " + plusInf, sortable > plusInf);
-    }
-  }
-
-  // INFO: Tests for trieCodeLong()/trieCodeInt() not needed because implicitely tested by range filter tests
-  
-  /** Note: The neededBounds Iterable must be unsigned (easier understanding what's happening) */
-  private void assertLongRangeSplit(final long lower, final long upper, int precisionStep,
-    final boolean useBitSet, final Iterable<Long> expectedBounds, final Iterable<Integer> expectedShifts
-  ) {
-    // Cannot use FixedBitSet since the range could be long:
-    final LongBitSet bits=useBitSet ? new LongBitSet(upper-lower+1) : null;
-    final Iterator<Long> neededBounds = (expectedBounds == null) ? null : expectedBounds.iterator();
-    final Iterator<Integer> neededShifts = (expectedShifts == null) ? null : expectedShifts.iterator();
-
-    NumericUtils.splitLongRange(new NumericUtils.LongRangeBuilder() {
-      @Override
-      public void addRange(long min, long max, int shift) {
-        assertTrue("min, max should be inside bounds", min>=lower && min<=upper && max>=lower && max<=upper);
-        if (useBitSet) for (long l=min; l<=max; l++) {
-          assertFalse("ranges should not overlap", bits.getAndSet(l-lower) );
-          // extra exit condition to prevent overflow on MAX_VALUE
-          if (l == max) break;
-        }
-        if (neededBounds == null || neededShifts == null)
-          return;
-        // make unsigned longs for easier display and understanding
-        min ^= 0x8000000000000000L;
-        max ^= 0x8000000000000000L;
-        //System.out.println("0x"+Long.toHexString(min>>>shift)+"L,0x"+Long.toHexString(max>>>shift)+"L)/*shift="+shift+"*/,");
-        assertEquals( "shift", neededShifts.next().intValue(), shift);
-        assertEquals( "inner min bound", neededBounds.next().longValue(), min>>>shift);
-        assertEquals( "inner max bound", neededBounds.next().longValue(), max>>>shift);
-      }
-    }, precisionStep, lower, upper);
-    
-    if (useBitSet) {
-      // after flipping all bits in the range, the cardinality should be zero
-      bits.flip(0,upper-lower+1);
-      assertEquals("The sub-range concenated should match the whole range", 0, bits.cardinality());
-    }
-  }
-  
-  /** LUCENE-2541: NumericRangeQuery errors with endpoints near long min and max values */
-  public void testLongExtremeValues() throws Exception {
-    // upper end extremes
-    assertLongRangeSplit(Long.MAX_VALUE, Long.MAX_VALUE, 1, true, Arrays.asList(
-      0xffffffffffffffffL,0xffffffffffffffffL
-    ), Arrays.asList(
-      0
-    ));
-    assertLongRangeSplit(Long.MAX_VALUE, Long.MAX_VALUE, 2, true, Arrays.asList(
-      0xffffffffffffffffL,0xffffffffffffffffL
-    ), Arrays.asList(
-      0
-    ));
-    assertLongRangeSplit(Long.MAX_VALUE, Long.MAX_VALUE, 4, true, Arrays.asList(
-      0xffffffffffffffffL,0xffffffffffffffffL
-    ), Arrays.asList(
-      0
-    ));
-    assertLongRangeSplit(Long.MAX_VALUE, Long.MAX_VALUE, 6, true, Arrays.asList(
-      0xffffffffffffffffL,0xffffffffffffffffL
-    ), Arrays.asList(
-      0
-    ));
-    assertLongRangeSplit(Long.MAX_VALUE, Long.MAX_VALUE, 8, true, Arrays.asList(
-      0xffffffffffffffffL,0xffffffffffffffffL
-    ), Arrays.asList(
-      0
-    ));
-    assertLongRangeSplit(Long.MAX_VALUE, Long.MAX_VALUE, 64, true, Arrays.asList(
-      0xffffffffffffffffL,0xffffffffffffffffL
-    ), Arrays.asList(
-      0
-    ));
-
-    assertLongRangeSplit(Long.MAX_VALUE-0xfL, Long.MAX_VALUE, 4, true, Arrays.asList(
-      0xfffffffffffffffL,0xfffffffffffffffL
-    ), Arrays.asList(
-      4
-    ));
-    assertLongRangeSplit(Long.MAX_VALUE-0x10L, Long.MAX_VALUE, 4, true, Arrays.asList(
-      0xffffffffffffffefL,0xffffffffffffffefL,
-      0xfffffffffffffffL,0xfffffffffffffffL
-    ), Arrays.asList(
-      0, 4
-    ));
-
-    // lower end extremes
-    assertLongRangeSplit(Long.MIN_VALUE, Long.MIN_VALUE, 1, true, Arrays.asList(
-      0x0000000000000000L,0x0000000000000000L
-    ), Arrays.asList(
-      0
-    ));
-    assertLongRangeSplit(Long.MIN_VALUE, Long.MIN_VALUE, 2, true, Arrays.asList(
-      0x0000000000000000L,0x0000000000000000L
-    ), Arrays.asList(
-      0
-    ));
-    assertLongRangeSplit(Long.MIN_VALUE, Long.MIN_VALUE, 4, true, Arrays.asList(
-      0x0000000000000000L,0x0000000000000000L
-    ), Arrays.asList(
-      0
-    ));
-    assertLongRangeSplit(Long.MIN_VALUE, Long.MIN_VALUE, 6, true, Arrays.asList(
-      0x0000000000000000L,0x0000000000000000L
-    ), Arrays.asList(
-      0
-    ));
-    assertLongRangeSplit(Long.MIN_VALUE, Long.MIN_VALUE, 8, true, Arrays.asList(
-      0x0000000000000000L,0x0000000000000000L
-    ), Arrays.asList(
-      0
-    ));
-    assertLongRangeSplit(Long.MIN_VALUE, Long.MIN_VALUE, 64, true, Arrays.asList(
-      0x0000000000000000L,0x0000000000000000L
-    ), Arrays.asList(
-      0
-    ));
-
-    assertLongRangeSplit(Long.MIN_VALUE, Long.MIN_VALUE+0xfL, 4, true, Arrays.asList(
-      0x000000000000000L,0x000000000000000L
-    ), Arrays.asList(
-      4
-    ));
-    assertLongRangeSplit(Long.MIN_VALUE, Long.MIN_VALUE+0x10L, 4, true, Arrays.asList(
-      0x0000000000000010L,0x0000000000000010L,
-      0x000000000000000L,0x000000000000000L
-    ), Arrays.asList(
-      0, 4
-    ));
-  }
-  
-  public void testRandomSplit() throws Exception {
-    long num = (long) atLeast(10);
-    for (long i=0; i < num; i++) {
-      executeOneRandomSplit(random());
-    }
-  }
-  
-  private void executeOneRandomSplit(final Random random) throws Exception {
-    long lower = randomLong(random);
-    long len = random.nextInt(16384*1024); // not too large bitsets, else OOME!
-    while (lower + len < lower) { // overflow
-      lower >>= 1;
-    }
-    assertLongRangeSplit(lower, lower + len, random.nextInt(64) + 1, true, null, null);
-  }
-  
-  private long randomLong(final Random random) {
-    long val;
-    switch(random.nextInt(4)) {
-      case 0:
-        val = 1L << (random.nextInt(63)); //  patterns like 0x000000100000 (-1 yields patterns like 0x0000fff)
-        break;
-      case 1:
-        val = -1L << (random.nextInt(63)); // patterns like 0xfffff00000
-        break;
-      default:
-        val = random.nextLong();
-    }
-
-    val += random.nextInt(5)-2;
-
-    if (random.nextBoolean()) {
-      if (random.nextBoolean()) val += random.nextInt(100)-50;
-      if (random.nextBoolean()) val = ~val;
-      if (random.nextBoolean()) val = val<<1;
-      if (random.nextBoolean()) val = val>>>1;
-    }
-
-    return val;
-  }
-  
-  public void testSplitLongRange() throws Exception {
-    // a hard-coded "standard" range
-    assertLongRangeSplit(-5000L, 9500L, 4, true, Arrays.asList(
-      0x7fffffffffffec78L,0x7fffffffffffec7fL,
-      0x8000000000002510L,0x800000000000251cL,
-      0x7fffffffffffec8L, 0x7fffffffffffecfL,
-      0x800000000000250L, 0x800000000000250L,
-      0x7fffffffffffedL,  0x7fffffffffffefL,
-      0x80000000000020L,  0x80000000000024L,
-      0x7ffffffffffffL,   0x8000000000001L
-    ), Arrays.asList(
-      0, 0,
-      4, 4,
-      8, 8,
-      12
-    ));
-    
-    // the same with no range splitting
-    assertLongRangeSplit(-5000L, 9500L, 64, true, Arrays.asList(
-      0x7fffffffffffec78L,0x800000000000251cL
-    ), Arrays.asList(
-      0
-    ));
-    
-    // this tests optimized range splitting, if one of the inner bounds
-    // is also the bound of the next lower precision, it should be used completely
-    assertLongRangeSplit(0L, 1024L+63L, 4, true, Arrays.asList(
-      0x800000000000040L, 0x800000000000043L,
-      0x80000000000000L,  0x80000000000003L
-    ), Arrays.asList(
-      4, 8
-    ));
-    
-    // the full long range should only consist of a lowest precision range; no bitset testing here, as too much memory needed :-)
-    assertLongRangeSplit(Long.MIN_VALUE, Long.MAX_VALUE, 8, false, Arrays.asList(
-      0x00L,0xffL
-    ), Arrays.asList(
-      56
-    ));
-
-    // the same with precisionStep=4
-    assertLongRangeSplit(Long.MIN_VALUE, Long.MAX_VALUE, 4, false, Arrays.asList(
-      0x0L,0xfL
-    ), Arrays.asList(
-      60
-    ));
-
-    // the same with precisionStep=2
-    assertLongRangeSplit(Long.MIN_VALUE, Long.MAX_VALUE, 2, false, Arrays.asList(
-      0x0L,0x3L
-    ), Arrays.asList(
-      62
-    ));
-
-    // the same with precisionStep=1
-    assertLongRangeSplit(Long.MIN_VALUE, Long.MAX_VALUE, 1, false, Arrays.asList(
-      0x0L,0x1L
-    ), Arrays.asList(
-      63
-    ));
-
-    // a inverse range should produce no sub-ranges
-    assertLongRangeSplit(9500L, -5000L, 4, false, Collections.<Long>emptyList(), Collections.<Integer>emptyList());    
-
-    // a 0-length range should reproduce the range itself
-    assertLongRangeSplit(9500L, 9500L, 4, false, Arrays.asList(
-      0x800000000000251cL,0x800000000000251cL
-    ), Arrays.asList(
-      0
-    ));
-  }
-
-  /** Note: The neededBounds Iterable must be unsigned (easier understanding what's happening) */
-  private void assertIntRangeSplit(final int lower, final int upper, int precisionStep,
-    final boolean useBitSet, final Iterable<Integer> expectedBounds, final Iterable<Integer> expectedShifts
-  ) {
-    final FixedBitSet bits=useBitSet ? new FixedBitSet(upper-lower+1) : null;
-    final Iterator<Integer> neededBounds = (expectedBounds == null) ? null : expectedBounds.iterator();
-    final Iterator<Integer> neededShifts = (expectedShifts == null) ? null : expectedShifts.iterator();
-    
-    NumericUtils.splitIntRange(new NumericUtils.IntRangeBuilder() {
-      @Override
-      public void addRange(int min, int max, int shift) {
-        assertTrue("min, max should be inside bounds", min>=lower && min<=upper && max>=lower && max<=upper);
-        if (useBitSet) for (int i=min; i<=max; i++) {
-          assertFalse("ranges should not overlap", bits.getAndSet(i-lower) );
-          // extra exit condition to prevent overflow on MAX_VALUE
-          if (i == max) break;
-        }
-        if (neededBounds == null)
-          return;
-        // make unsigned ints for easier display and understanding
-        min ^= 0x80000000;
-        max ^= 0x80000000;
-        //System.out.println("0x"+Integer.toHexString(min>>>shift)+",0x"+Integer.toHexString(max>>>shift)+")/*shift="+shift+"*/,");
-        assertEquals( "shift", neededShifts.next().intValue(), shift);
-        assertEquals( "inner min bound", neededBounds.next().intValue(), min>>>shift);
-        assertEquals( "inner max bound", neededBounds.next().intValue(), max>>>shift);
-      }
-    }, precisionStep, lower, upper);
-    
-    if (useBitSet) {
-      // after flipping all bits in the range, the cardinality should be zero
-      bits.flip(0, upper-lower+1);
-      assertEquals("The sub-range concenated should match the whole range", 0, bits.cardinality());
-    }
-  }
-  
-  public void testSplitIntRange() throws Exception {
-    // a hard-coded "standard" range
-    assertIntRangeSplit(-5000, 9500, 4, true, Arrays.asList(
-      0x7fffec78,0x7fffec7f,
-      0x80002510,0x8000251c,
-      0x7fffec8, 0x7fffecf,
-      0x8000250, 0x8000250,
-      0x7fffed,  0x7fffef,
-      0x800020,  0x800024,
-      0x7ffff,   0x80001
-    ), Arrays.asList(
-      0, 0,
-      4, 4,
-      8, 8,
-      12
-    ));
-    
-    // the same with no range splitting
-    assertIntRangeSplit(-5000, 9500, 32, true, Arrays.asList(
-      0x7fffec78,0x8000251c
-    ), Arrays.asList(
-      0
-    ));
-    
-    // this tests optimized range splitting, if one of the inner bounds
-    // is also the bound of the next lower precision, it should be used completely
-    assertIntRangeSplit(0, 1024+63, 4, true, Arrays.asList(
-      0x8000040, 0x8000043,
-      0x800000,  0x800003
-    ), Arrays.asList(
-      4, 8
-    ));
-    
-    // the full int range should only consist of a lowest precision range; no bitset testing here, as too much memory needed :-)
-    assertIntRangeSplit(Integer.MIN_VALUE, Integer.MAX_VALUE, 8, false, Arrays.asList(
-      0x00,0xff
-    ), Arrays.asList(
-      24
-    ));
-
-    // the same with precisionStep=4
-    assertIntRangeSplit(Integer.MIN_VALUE, Integer.MAX_VALUE, 4, false, Arrays.asList(
-      0x0,0xf
-    ), Arrays.asList(
-      28
-    ));
-
-    // the same with precisionStep=2
-    assertIntRangeSplit(Integer.MIN_VALUE, Integer.MAX_VALUE, 2, false, Arrays.asList(
-      0x0,0x3
-    ), Arrays.asList(
-      30
-    ));
-
-    // the same with precisionStep=1
-    assertIntRangeSplit(Integer.MIN_VALUE, Integer.MAX_VALUE, 1, false, Arrays.asList(
-      0x0,0x1
-    ), Arrays.asList(
-      31
-    ));
-
-    // a inverse range should produce no sub-ranges
-    assertIntRangeSplit(9500, -5000, 4, false, Collections.<Integer>emptyList(), Collections.<Integer>emptyList());    
-
-    // a 0-length range should reproduce the range itself
-    assertIntRangeSplit(9500, 9500, 4, false, Arrays.asList(
-      0x8000251c,0x8000251c
-    ), Arrays.asList(
-      0
-    ));
-  }
-
-}
diff --git a/lucene/core/src/test/org/apache/lucene/util/bkd/TestBKD.java b/lucene/core/src/test/org/apache/lucene/util/bkd/TestBKD.java
index ad5c2f6..9676d62 100644
--- a/lucene/core/src/test/org/apache/lucene/util/bkd/TestBKD.java
+++ b/lucene/core/src/test/org/apache/lucene/util/bkd/TestBKD.java
@@ -34,6 +34,7 @@ import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.NumericUtils;
 import org.apache.lucene.util.TestUtil;
 
 public class TestBKD extends LuceneTestCase {
@@ -43,7 +44,7 @@ public class TestBKD extends LuceneTestCase {
       BKDWriter w = new BKDWriter(dir, "tmp", 1, 4, 2, 1.0f);
       byte[] scratch = new byte[4];
       for(int docID=0;docID<100;docID++) {
-        BKDUtil.intToBytes(docID, scratch, 0);
+        NumericUtils.intToBytes(docID, scratch, 0);
         w.add(scratch, docID);
       }
 
@@ -72,7 +73,7 @@ public class TestBKD extends LuceneTestCase {
 
             @Override
             public void visit(int docID, byte[] packedValue) {
-              int x = BKDUtil.bytesToInt(packedValue, 0);
+              int x = NumericUtils.bytesToInt(packedValue, 0);
               if (VERBOSE) {
                 System.out.println("visit docID=" + docID + " x=" + x);
               }
@@ -83,8 +84,8 @@ public class TestBKD extends LuceneTestCase {
 
             @Override
             public Relation compare(byte[] minPacked, byte[] maxPacked) {
-              int min = BKDUtil.bytesToInt(minPacked, 0);
-              int max = BKDUtil.bytesToInt(maxPacked, 0);
+              int min = NumericUtils.bytesToInt(minPacked, 0);
+              int max = NumericUtils.bytesToInt(maxPacked, 0);
               assert max >= min;
               if (VERBOSE) {
                 System.out.println("compare: min=" + min + " max=" + max + " vs queryMin=" + queryMin + " queryMax=" + queryMax);
@@ -129,7 +130,7 @@ public class TestBKD extends LuceneTestCase {
         }
         for(int dim=0;dim<numDims;dim++) {
           values[dim] = random().nextInt();
-          BKDUtil.intToBytes(values[dim], scratch, dim);
+          NumericUtils.intToBytes(values[dim], scratch, dim);
           if (VERBOSE) {
             System.out.println("    " + dim + " -> " + values[dim]);
           }
@@ -178,7 +179,7 @@ public class TestBKD extends LuceneTestCase {
             public void visit(int docID, byte[] packedValue) {
               //System.out.println("visit check docID=" + docID);
               for(int dim=0;dim<numDims;dim++) {
-                int x = BKDUtil.bytesToInt(packedValue, dim);
+                int x = NumericUtils.bytesToInt(packedValue, dim);
                 if (x < queryMin[dim] || x > queryMax[dim]) {
                   //System.out.println("  no");
                   return;
@@ -193,8 +194,8 @@ public class TestBKD extends LuceneTestCase {
             public Relation compare(byte[] minPacked, byte[] maxPacked) {
               boolean crosses = false;
               for(int dim=0;dim<numDims;dim++) {
-                int min = BKDUtil.bytesToInt(minPacked, dim);
-                int max = BKDUtil.bytesToInt(maxPacked, dim);
+                int min = NumericUtils.bytesToInt(minPacked, dim);
+                int max = NumericUtils.bytesToInt(maxPacked, dim);
                 assert max >= min;
 
                 if (max < queryMin[dim] || min > queryMax[dim]) {
@@ -250,7 +251,7 @@ public class TestBKD extends LuceneTestCase {
         }
         for(int dim=0;dim<numDims;dim++) {
           values[dim] = randomBigInt(numBytesPerDim);
-          BKDUtil.bigIntToBytes(values[dim], scratch, dim, numBytesPerDim);
+          NumericUtils.bigIntToBytes(values[dim], scratch, dim, numBytesPerDim);
           if (VERBOSE) {
             System.out.println("    " + dim + " -> " + values[dim]);
           }
@@ -299,7 +300,7 @@ public class TestBKD extends LuceneTestCase {
             public void visit(int docID, byte[] packedValue) {
               //System.out.println("visit check docID=" + docID);
               for(int dim=0;dim<numDims;dim++) {
-                BigInteger x = BKDUtil.bytesToBigInt(packedValue, dim, numBytesPerDim);
+                BigInteger x = NumericUtils.bytesToBigInt(packedValue, dim, numBytesPerDim);
                 if (x.compareTo(queryMin[dim]) < 0 || x.compareTo(queryMax[dim]) > 0) {
                   //System.out.println("  no");
                   return;
@@ -314,8 +315,8 @@ public class TestBKD extends LuceneTestCase {
             public Relation compare(byte[] minPacked, byte[] maxPacked) {
               boolean crosses = false;
               for(int dim=0;dim<numDims;dim++) {
-                BigInteger min = BKDUtil.bytesToBigInt(minPacked, dim, numBytesPerDim);
-                BigInteger max = BKDUtil.bytesToBigInt(maxPacked, dim, numBytesPerDim);
+                BigInteger min = NumericUtils.bytesToBigInt(minPacked, dim, numBytesPerDim);
+                BigInteger max = NumericUtils.bytesToBigInt(maxPacked, dim, numBytesPerDim);
                 assert max.compareTo(min) >= 0;
 
                 if (max.compareTo(queryMin[dim]) < 0 || min.compareTo(queryMax[dim]) > 0) {
@@ -518,7 +519,7 @@ public class TestBKD extends LuceneTestCase {
     verify(docValuesArray, docIDsArray, numDims, numBytesPerDim);
   }
 
-  public void testBKDUtilAdd() throws Exception {
+  public void testNumericUtilsAdd() throws Exception {
     int iters = atLeast(10000);
     int numBytes = TestUtil.nextInt(random(), 1, 100);
     for(int iter=0;iter<iters;iter++) {
@@ -536,26 +537,26 @@ public class TestBKD extends LuceneTestCase {
       System.arraycopy(v2RawBytes, 0, v2Bytes, v2Bytes.length-v2RawBytes.length, v2RawBytes.length);
 
       byte[] result = new byte[numBytes];
-      BKDUtil.add(numBytes, 0, v1Bytes, v2Bytes, result);
+      NumericUtils.add(numBytes, 0, v1Bytes, v2Bytes, result);
 
       BigInteger sum = v1.add(v2);
       assertTrue("sum=" + sum + " v1=" + v1 + " v2=" + v2 + " but result=" + new BigInteger(1, result), sum.equals(new BigInteger(1, result)));
     }
   }
 
-  public void testIllegalBKDUtilAdd() throws Exception {
+  public void testIllegalNumericUtilsAdd() throws Exception {
     byte[] bytes = new byte[4];
     Arrays.fill(bytes, (byte) 0xff);
     byte[] one = new byte[4];
     one[3] = 1;
     try {
-      BKDUtil.add(4, 0, bytes, one, new byte[4]);
+      NumericUtils.add(4, 0, bytes, one, new byte[4]);
     } catch (IllegalArgumentException iae) {
       assertEquals("a + b overflows bytesPerDim=4", iae.getMessage());
     }
   }
   
-  public void testBKDUtilSubtract() throws Exception {
+  public void testNumericUtilsSubtract() throws Exception {
     int iters = atLeast(10000);
     int numBytes = TestUtil.nextInt(random(), 1, 100);
     for(int iter=0;iter<iters;iter++) {
@@ -579,7 +580,7 @@ public class TestBKD extends LuceneTestCase {
       System.arraycopy(v2RawBytes, 0, v2Bytes, v2Bytes.length-v2RawBytes.length, v2RawBytes.length);
 
       byte[] result = new byte[numBytes];
-      BKDUtil.subtract(numBytes, 0, v1Bytes, v2Bytes, result);
+      NumericUtils.subtract(numBytes, 0, v1Bytes, v2Bytes, result);
 
       BigInteger diff = v1.subtract(v2);
 
@@ -587,13 +588,13 @@ public class TestBKD extends LuceneTestCase {
     }
   }
 
-  public void testIllegalBKDUtilSubtract() throws Exception {
+  public void testIllegalNumericUtilsSubtract() throws Exception {
     byte[] v1 = new byte[4];
     v1[3] = (byte) 0xf0;
     byte[] v2 = new byte[4];
     v2[3] = (byte) 0xf1;
     try {
-      BKDUtil.subtract(4, 0, v1, v2, new byte[4]);
+      NumericUtils.subtract(4, 0, v1, v2, new byte[4]);
     } catch (IllegalArgumentException iae) {
       assertEquals("a < b", iae.getMessage());
     }
@@ -722,7 +723,7 @@ public class TestBKD extends LuceneTestCase {
           random().nextBytes(queryMin[dim]);
           queryMax[dim] = new byte[numBytesPerDim];
           random().nextBytes(queryMax[dim]);
-          if (BKDUtil.compare(numBytesPerDim, queryMin[dim], 0, queryMax[dim], 0) > 0) {
+          if (NumericUtils.compare(numBytesPerDim, queryMin[dim], 0, queryMax[dim], 0) > 0) {
             byte[] x = queryMin[dim];
             queryMin[dim] = queryMax[dim];
             queryMax[dim] = x;
@@ -741,8 +742,8 @@ public class TestBKD extends LuceneTestCase {
             public void visit(int docID, byte[] packedValue) {
               //System.out.println("visit check docID=" + docID);
               for(int dim=0;dim<numDims;dim++) {
-                if (BKDUtil.compare(numBytesPerDim, packedValue, dim, queryMin[dim], 0) < 0 ||
-                    BKDUtil.compare(numBytesPerDim, packedValue, dim, queryMax[dim], 0) > 0) {
+                if (NumericUtils.compare(numBytesPerDim, packedValue, dim, queryMin[dim], 0) < 0 ||
+                    NumericUtils.compare(numBytesPerDim, packedValue, dim, queryMax[dim], 0) > 0) {
                   //System.out.println("  no");
                   return;
                 }
@@ -756,11 +757,11 @@ public class TestBKD extends LuceneTestCase {
             public Relation compare(byte[] minPacked, byte[] maxPacked) {
               boolean crosses = false;
               for(int dim=0;dim<numDims;dim++) {
-                if (BKDUtil.compare(numBytesPerDim, maxPacked, dim, queryMin[dim], 0) < 0 ||
-                    BKDUtil.compare(numBytesPerDim, minPacked, dim, queryMax[dim], 0) > 0) {
+                if (NumericUtils.compare(numBytesPerDim, maxPacked, dim, queryMin[dim], 0) < 0 ||
+                    NumericUtils.compare(numBytesPerDim, minPacked, dim, queryMax[dim], 0) > 0) {
                   return Relation.CELL_OUTSIDE_QUERY;
-                } else if (BKDUtil.compare(numBytesPerDim, minPacked, dim, queryMin[dim], 0) < 0 ||
-                           BKDUtil.compare(numBytesPerDim, maxPacked, dim, queryMax[dim], 0) > 0) {
+                } else if (NumericUtils.compare(numBytesPerDim, minPacked, dim, queryMin[dim], 0) < 0 ||
+                           NumericUtils.compare(numBytesPerDim, maxPacked, dim, queryMax[dim], 0) > 0) {
                   crosses = true;
                 }
               }
@@ -778,8 +779,8 @@ public class TestBKD extends LuceneTestCase {
           boolean matches = true;
           for(int dim=0;dim<numDims;dim++) {
             byte[] x = docValues[ord][dim];
-            if (BKDUtil.compare(numBytesPerDim, x, 0, queryMin[dim], 0) < 0 ||
-                BKDUtil.compare(numBytesPerDim, x, 0, queryMax[dim], 0) > 0) {
+            if (NumericUtils.compare(numBytesPerDim, x, 0, queryMin[dim], 0) < 0 ||
+                NumericUtils.compare(numBytesPerDim, x, 0, queryMax[dim], 0) > 0) {
               matches = false;
               break;
             }
diff --git a/lucene/demo/src/java/org/apache/lucene/demo/IndexFiles.java b/lucene/demo/src/java/org/apache/lucene/demo/IndexFiles.java
index 8c324b7..69ad8de 100644
--- a/lucene/demo/src/java/org/apache/lucene/demo/IndexFiles.java
+++ b/lucene/demo/src/java/org/apache/lucene/demo/IndexFiles.java
@@ -17,20 +17,6 @@ package org.apache.lucene.demo;
  * limitations under the License.
  */
 
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.standard.StandardAnalyzer;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.document.LongField;
-import org.apache.lucene.document.StringField;
-import org.apache.lucene.document.TextField;
-import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.IndexWriterConfig.OpenMode;
-import org.apache.lucene.index.IndexWriterConfig;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.store.FSDirectory;
-
 import java.io.BufferedReader;
 import java.io.IOException;
 import java.io.InputStream;
@@ -44,6 +30,20 @@ import java.nio.file.SimpleFileVisitor;
 import java.nio.file.attribute.BasicFileAttributes;
 import java.util.Date;
 
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.standard.StandardAnalyzer;
+import org.apache.lucene.document.DimensionalLongField;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.document.StringField;
+import org.apache.lucene.document.TextField;
+import org.apache.lucene.index.IndexWriter;
+import org.apache.lucene.index.IndexWriterConfig.OpenMode;
+import org.apache.lucene.index.IndexWriterConfig;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.store.FSDirectory;
+
 /** Index all text files under a directory.
  * <p>
  * This is a command-line application demonstrating simple Lucene indexing.
@@ -178,13 +178,13 @@ public class IndexFiles {
       doc.add(pathField);
       
       // Add the last modified date of the file a field named "modified".
-      // Use a LongField that is indexed (i.e. efficiently filterable with
-      // NumericRangeFilter).  This indexes to milli-second resolution, which
+      // Use a DimensionalLongField that is indexed (i.e. efficiently filterable with
+      // DimensionalRangeQuery).  This indexes to milli-second resolution, which
       // is often too fine.  You could instead create a number based on
       // year/month/day/hour/minutes/seconds, down the resolution you require.
       // For example the long value 2011021714 would mean
       // February 17, 2011, 2-3 PM.
-      doc.add(new LongField("modified", lastModified, Field.Store.NO));
+      doc.add(new DimensionalLongField("modified", lastModified));
       
       // Add the contents of the file to a field named "contents".  Specify a Reader,
       // so that the text of the file is tokenized and indexed, but not stored.
diff --git a/lucene/demo/src/java/org/apache/lucene/demo/facet/DistanceFacetsExample.java b/lucene/demo/src/java/org/apache/lucene/demo/facet/DistanceFacetsExample.java
index 2da93db..ea1905c 100644
--- a/lucene/demo/src/java/org/apache/lucene/demo/facet/DistanceFacetsExample.java
+++ b/lucene/demo/src/java/org/apache/lucene/demo/facet/DistanceFacetsExample.java
@@ -17,14 +17,9 @@ package org.apache.lucene.demo.facet;
  * limitations under the License.
  */
 
-import java.io.Closeable;
-import java.io.IOException;
-import java.text.ParseException;
-
 import org.apache.lucene.analysis.core.WhitespaceAnalyzer;
+import org.apache.lucene.document.DimensionalDoubleField;
 import org.apache.lucene.document.Document;
-import org.apache.lucene.document.DoubleField;
-import org.apache.lucene.document.Field;
 import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.expressions.Expression;
 import org.apache.lucene.expressions.SimpleBindings;
@@ -45,9 +40,9 @@ import org.apache.lucene.index.IndexWriterConfig.OpenMode;
 import org.apache.lucene.queries.function.ValueSource;
 import org.apache.lucene.search.BooleanClause;
 import org.apache.lucene.search.BooleanQuery;
+import org.apache.lucene.search.DimensionalRangeQuery;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.MatchAllDocsQuery;
-import org.apache.lucene.search.NumericRangeQuery;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.SortField;
 import org.apache.lucene.search.TopDocs;
@@ -55,6 +50,10 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.RAMDirectory;
 import org.apache.lucene.util.SloppyMath;
 
+import java.io.Closeable;
+import java.io.IOException;
+import java.text.ParseException;
+
 /** Shows simple usage of dynamic range faceting, using the
  *  expressions module to calculate distance. */
 public class DistanceFacetsExample implements Closeable {
@@ -92,25 +91,25 @@ public class DistanceFacetsExample implements Closeable {
     // TODO: we could index in radians instead ... saves all the conversions in getBoundingBoxFilter
 
     // Add documents with latitude/longitude location:
-    // we index these both as DoubleFields (for bounding box/ranges) and as NumericDocValuesFields (for scoring)
+    // we index these both as DimensionalDoubleFields (for bounding box/ranges) and as NumericDocValuesFields (for scoring)
     Document doc = new Document();
-    doc.add(new DoubleField("latitude", 40.759011, Field.Store.NO));
+    doc.add(new DimensionalDoubleField("latitude", 40.759011));
     doc.add(new NumericDocValuesField("latitude", Double.doubleToRawLongBits(40.759011)));
-    doc.add(new DoubleField("longitude", -73.9844722, Field.Store.NO));
+    doc.add(new DimensionalDoubleField("longitude", -73.9844722));
     doc.add(new NumericDocValuesField("longitude", Double.doubleToRawLongBits(-73.9844722)));
     writer.addDocument(doc);
     
     doc = new Document();
-    doc.add(new DoubleField("latitude", 40.718266, Field.Store.NO));
+    doc.add(new DimensionalDoubleField("latitude", 40.718266));
     doc.add(new NumericDocValuesField("latitude", Double.doubleToRawLongBits(40.718266)));
-    doc.add(new DoubleField("longitude", -74.007819, Field.Store.NO));
+    doc.add(new DimensionalDoubleField("longitude", -74.007819));
     doc.add(new NumericDocValuesField("longitude", Double.doubleToRawLongBits(-74.007819)));
     writer.addDocument(doc);
     
     doc = new Document();
-    doc.add(new DoubleField("latitude", 40.7051157, Field.Store.NO));
+    doc.add(new DimensionalDoubleField("latitude", 40.7051157));
     doc.add(new NumericDocValuesField("latitude", Double.doubleToRawLongBits(40.7051157)));
-    doc.add(new DoubleField("longitude", -74.0088305, Field.Store.NO));
+    doc.add(new DimensionalDoubleField("longitude", -74.0088305));
     doc.add(new NumericDocValuesField("longitude", Double.doubleToRawLongBits(-74.0088305)));
     writer.addDocument(doc);
 
@@ -182,7 +181,7 @@ public class DistanceFacetsExample implements Closeable {
     BooleanQuery.Builder f = new BooleanQuery.Builder();
 
     // Add latitude range filter:
-    f.add(NumericRangeQuery.newDoubleRange("latitude", Math.toDegrees(minLat), Math.toDegrees(maxLat), true, true),
+    f.add(DimensionalRangeQuery.new1DDoubleRange("latitude", Math.toDegrees(minLat), true, Math.toDegrees(maxLat), true),
           BooleanClause.Occur.FILTER);
 
     // Add longitude range filter:
@@ -190,13 +189,13 @@ public class DistanceFacetsExample implements Closeable {
       // The bounding box crosses the international date
       // line:
       BooleanQuery.Builder lonF = new BooleanQuery.Builder();
-      lonF.add(NumericRangeQuery.newDoubleRange("longitude", Math.toDegrees(minLng), null, true, true),
+      lonF.add(DimensionalRangeQuery.new1DDoubleRange("longitude", Math.toDegrees(minLng), true, null,  true),
                BooleanClause.Occur.SHOULD);
-      lonF.add(NumericRangeQuery.newDoubleRange("longitude", null, Math.toDegrees(maxLng), true, true),
+      lonF.add(DimensionalRangeQuery.new1DDoubleRange("longitude", null, true, Math.toDegrees(maxLng), true),
                BooleanClause.Occur.SHOULD);
       f.add(lonF.build(), BooleanClause.Occur.MUST);
     } else {
-      f.add(NumericRangeQuery.newDoubleRange("longitude", Math.toDegrees(minLng), Math.toDegrees(maxLng), true, true),
+      f.add(DimensionalRangeQuery.new1DDoubleRange("longitude", Math.toDegrees(minLng), true, Math.toDegrees(maxLng), true),
             BooleanClause.Occur.FILTER);
     }
 
diff --git a/lucene/demo/src/java/org/apache/lucene/demo/facet/RangeFacetsExample.java b/lucene/demo/src/java/org/apache/lucene/demo/facet/RangeFacetsExample.java
index 2f9180c..ea858e6 100644
--- a/lucene/demo/src/java/org/apache/lucene/demo/facet/RangeFacetsExample.java
+++ b/lucene/demo/src/java/org/apache/lucene/demo/facet/RangeFacetsExample.java
@@ -17,13 +17,9 @@ package org.apache.lucene.demo.facet;
  * limitations under the License.
  */
 
-import java.io.Closeable;
-import java.io.IOException;
-
 import org.apache.lucene.analysis.core.WhitespaceAnalyzer;
+import org.apache.lucene.document.DimensionalLongField;
 import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.document.LongField;
 import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.facet.DrillDownQuery;
 import org.apache.lucene.facet.FacetResult;
@@ -36,13 +32,16 @@ import org.apache.lucene.index.DirectoryReader;
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.IndexWriterConfig;
 import org.apache.lucene.index.IndexWriterConfig.OpenMode;
+import org.apache.lucene.search.DimensionalRangeQuery;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.MatchAllDocsQuery;
-import org.apache.lucene.search.NumericRangeQuery;
 import org.apache.lucene.search.TopDocs;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.RAMDirectory;
 
+import java.io.Closeable;
+import java.io.IOException;
+
 /** Shows simple usage of dynamic range faceting. */
 public class RangeFacetsExample implements Closeable {
 
@@ -70,7 +69,7 @@ public class RangeFacetsExample implements Closeable {
       // Add as doc values field, so we can compute range facets:
       doc.add(new NumericDocValuesField("timestamp", then));
       // Add as numeric field so we can drill-down:
-      doc.add(new LongField("timestamp", then, Field.Store.NO));
+      doc.add(new DimensionalLongField("timestamp", then));
       indexWriter.addDocument(doc);
     }
 
@@ -108,7 +107,7 @@ public class RangeFacetsExample implements Closeable {
     // documents ("browse only"):
     DrillDownQuery q = new DrillDownQuery(getConfig());
 
-    q.add("timestamp", NumericRangeQuery.newLongRange("timestamp", range.min, range.max, range.minInclusive, range.maxInclusive));
+    q.add("timestamp", DimensionalRangeQuery.new1DLongRange("timestamp", range.min, range.minInclusive, range.max, range.maxInclusive));
 
     return searcher.search(q, 10);
   }
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/range/DoubleRange.java b/lucene/facet/src/java/org/apache/lucene/facet/range/DoubleRange.java
index e39401c..415efe4 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/range/DoubleRange.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/range/DoubleRange.java
@@ -33,7 +33,7 @@ import org.apache.lucene.search.Query;
 import org.apache.lucene.search.Scorer;
 import org.apache.lucene.search.TwoPhaseIterator;
 import org.apache.lucene.search.Weight;
-import org.apache.lucene.util.NumericUtils;
+import org.apache.lucene.util.LegacyNumericUtils;
 
 /** Represents a range over double values.
  *
@@ -63,7 +63,7 @@ public final class DoubleRange extends Range {
     this.maxInclusive = maxInclusive;
 
     // TODO: if DoubleDocValuesField used
-    // NumericUtils.doubleToSortableLong format (instead of
+    // LegacyNumericUtils.doubleToSortableLong format (instead of
     // Double.doubleToRawLongBits) we could do comparisons
     // in long space 
 
@@ -97,8 +97,8 @@ public final class DoubleRange extends Range {
 
   LongRange toLongRange() {
     return new LongRange(label,
-                         NumericUtils.doubleToSortableLong(minIncl), true,
-                         NumericUtils.doubleToSortableLong(maxIncl), true);
+                         LegacyNumericUtils.doubleToSortableLong(minIncl), true,
+                         LegacyNumericUtils.doubleToSortableLong(maxIncl), true);
   }
 
   @Override
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/range/DoubleRangeFacetCounts.java b/lucene/facet/src/java/org/apache/lucene/facet/range/DoubleRangeFacetCounts.java
index 469bdf0..485a8d6 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/range/DoubleRangeFacetCounts.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/range/DoubleRangeFacetCounts.java
@@ -38,7 +38,7 @@ import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.Scorer;
 import org.apache.lucene.search.Weight;
-import org.apache.lucene.util.NumericUtils;
+import org.apache.lucene.util.LegacyNumericUtils;
 
 /** {@link Facets} implementation that computes counts for
  *  dynamic double ranges from a provided {@link
@@ -89,8 +89,8 @@ public class DoubleRangeFacetCounts extends RangeFacetCounts {
     for(int i=0;i<ranges.length;i++) {
       DoubleRange range = ranges[i];
       longRanges[i] =  new LongRange(range.label,
-                                     NumericUtils.doubleToSortableLong(range.minIncl), true,
-                                     NumericUtils.doubleToSortableLong(range.maxIncl), true);
+                                     LegacyNumericUtils.doubleToSortableLong(range.minIncl), true,
+                                     LegacyNumericUtils.doubleToSortableLong(range.maxIncl), true);
     }
 
     LongRangeCounter counter = new LongRangeCounter(longRanges);
@@ -131,7 +131,7 @@ public class DoubleRangeFacetCounts extends RangeFacetCounts {
         }
         // Skip missing docs:
         if (fv.exists(doc)) {
-          counter.add(NumericUtils.doubleToSortableLong(fv.doubleVal(doc)));
+          counter.add(LegacyNumericUtils.doubleToSortableLong(fv.doubleVal(doc)));
         } else {
           missingCount++;
         }
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/range/Range.java b/lucene/facet/src/java/org/apache/lucene/facet/range/Range.java
index 3ee580c..7e6b746 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/range/Range.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/range/Range.java
@@ -19,7 +19,7 @@ package org.apache.lucene.facet.range;
 
 import org.apache.lucene.facet.DrillDownQuery; // javadocs
 import org.apache.lucene.queries.function.ValueSource;
-import org.apache.lucene.search.NumericRangeQuery;
+import org.apache.lucene.search.DimensionalRangeQuery; // javadocs
 import org.apache.lucene.search.Query;
 
 /** Base class for a single labeled range.
@@ -46,7 +46,7 @@ public abstract class Range {
    *  or when intersected with another query that can lead the
    *  iteration.  If the {@link ValueSource} is static, e.g. an
    *  indexed numeric field, then it may be more efficient to use
-   *  {@link NumericRangeQuery}. The provided fastMatchQuery,
+   *  {@link DimensionalRangeQuery}. The provided fastMatchQuery,
    *  if non-null, will first be consulted, and only if
    *  that is set for each document will the range then be
    *  checked. */
@@ -60,7 +60,7 @@ public abstract class Range {
    *  or when intersected with another query that can lead the
    *  iteration.  If the {@link ValueSource} is static, e.g. an
    *  indexed numeric field, then it may be more efficient to
-   *  use {@link NumericRangeQuery}. */
+   *  use {@link DimensionalRangeQuery}. */
   public Query getQuery(ValueSource valueSource) {
     return getQuery(null, valueSource);
   }
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/range/TestRangeFacetCounts.java b/lucene/facet/src/test/org/apache/lucene/facet/range/TestRangeFacetCounts.java
index e46348b..69f613c 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/range/TestRangeFacetCounts.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/range/TestRangeFacetCounts.java
@@ -23,13 +23,12 @@ import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.atomic.AtomicBoolean;
 
+import org.apache.lucene.document.DimensionalDoubleField;
+import org.apache.lucene.document.DimensionalFloatField;
+import org.apache.lucene.document.DimensionalLongField;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.DoubleDocValuesField;
-import org.apache.lucene.document.DoubleField;
-import org.apache.lucene.document.Field;
 import org.apache.lucene.document.FloatDocValuesField;
-import org.apache.lucene.document.FloatField;
-import org.apache.lucene.document.LongField;
 import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.facet.DrillDownQuery;
 import org.apache.lucene.facet.DrillSideways;
@@ -56,10 +55,10 @@ import org.apache.lucene.queries.function.docvalues.DoubleDocValues;
 import org.apache.lucene.queries.function.valuesource.DoubleFieldSource;
 import org.apache.lucene.queries.function.valuesource.FloatFieldSource;
 import org.apache.lucene.queries.function.valuesource.LongFieldSource;
+import org.apache.lucene.search.DimensionalRangeQuery;
 import org.apache.lucene.search.Explanation;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.MatchAllDocsQuery;
-import org.apache.lucene.search.NumericRangeQuery;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.Scorer;
 import org.apache.lucene.search.Weight;
@@ -67,7 +66,6 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.TestUtil;
 
-
 public class TestRangeFacetCounts extends FacetTestCase {
 
   public void testBasicLong() throws Exception {
@@ -221,7 +219,7 @@ public class TestRangeFacetCounts extends FacetTestCase {
       // For computing range facet counts:
       doc.add(new NumericDocValuesField("field", l));
       // For drill down by numeric range:
-      doc.add(new LongField("field", l, Field.Store.NO));
+      doc.add(new DimensionalLongField("field", l));
 
       if ((l&3) == 0) {
         doc.add(new FacetField("dim", "a"));
@@ -297,7 +295,7 @@ public class TestRangeFacetCounts extends FacetTestCase {
 
     // Third search, drill down on "less than or equal to 10":
     ddq = new DrillDownQuery(config);
-    ddq.add("field", NumericRangeQuery.newLongRange("field", 0L, 10L, true, true));
+    ddq.add("field", DimensionalRangeQuery.new1DLongRange("field", 0L, true, 10L, true));
     dsr = ds.search(null, ddq, 10);
 
     assertEquals(11, dsr.hits.totalHits);
@@ -385,7 +383,7 @@ public class TestRangeFacetCounts extends FacetTestCase {
       long v = random().nextLong();
       values[i] = v;
       doc.add(new NumericDocValuesField("field", v));
-      doc.add(new LongField("field", v, Field.Store.NO));
+      doc.add(new DimensionalLongField("field", v));
       w.addDocument(doc);
       minValue = Math.min(minValue, v);
       maxValue = Math.max(maxValue, v);
@@ -477,9 +475,9 @@ public class TestRangeFacetCounts extends FacetTestCase {
       Query fastMatchQuery;
       if (random().nextBoolean()) {
         if (random().nextBoolean()) {
-          fastMatchQuery = NumericRangeQuery.newLongRange("field", minValue, maxValue, true, true);
+          fastMatchQuery = DimensionalRangeQuery.new1DLongRange("field", minValue, true, maxValue, true);
         } else {
-          fastMatchQuery = NumericRangeQuery.newLongRange("field", minAcceptedValue, maxAcceptedValue, true, true);
+          fastMatchQuery = DimensionalRangeQuery.new1DLongRange("field", minAcceptedValue, true, maxAcceptedValue, true);
         }
       } else {
         fastMatchQuery = null;
@@ -501,7 +499,7 @@ public class TestRangeFacetCounts extends FacetTestCase {
         // Test drill-down:
         DrillDownQuery ddq = new DrillDownQuery(config);
         if (random().nextBoolean()) {
-          ddq.add("field", NumericRangeQuery.newLongRange("field", range.min, range.max, range.minInclusive, range.maxInclusive));
+          ddq.add("field", DimensionalRangeQuery.new1DLongRange("field", range.min, range.minInclusive, range.max, range.maxInclusive));
         } else {
           ddq.add("field", range.getQuery(fastMatchQuery, vs));
         }
@@ -526,7 +524,7 @@ public class TestRangeFacetCounts extends FacetTestCase {
       float v = random().nextFloat();
       values[i] = v;
       doc.add(new FloatDocValuesField("field", v));
-      doc.add(new FloatField("field", v, Field.Store.NO));
+      doc.add(new DimensionalFloatField("field", v));
       w.addDocument(doc);
       minValue = Math.min(minValue, v);
       maxValue = Math.max(maxValue, v);
@@ -632,9 +630,9 @@ public class TestRangeFacetCounts extends FacetTestCase {
       Query fastMatchQuery;
       if (random().nextBoolean()) {
         if (random().nextBoolean()) {
-          fastMatchQuery = NumericRangeQuery.newFloatRange("field", minValue, maxValue, true, true);
+          fastMatchQuery = DimensionalRangeQuery.new1DFloatRange("field", minValue, true, maxValue, true);
         } else {
-          fastMatchQuery = NumericRangeQuery.newFloatRange("field", minAcceptedValue, maxAcceptedValue, true, true);
+          fastMatchQuery = DimensionalRangeQuery.new1DFloatRange("field", minAcceptedValue, true, maxAcceptedValue, true);
         }
       } else {
         fastMatchQuery = null;
@@ -656,7 +654,7 @@ public class TestRangeFacetCounts extends FacetTestCase {
         // Test drill-down:
         DrillDownQuery ddq = new DrillDownQuery(config);
         if (random().nextBoolean()) {
-          ddq.add("field", NumericRangeQuery.newFloatRange("field", (float) range.min, (float) range.max, range.minInclusive, range.maxInclusive));
+          ddq.add("field", DimensionalRangeQuery.new1DFloatRange("field", (float) range.min, range.minInclusive, (float) range.max, range.maxInclusive));
         } else {
           ddq.add("field", range.getQuery(fastMatchQuery, vs));
         }
@@ -681,7 +679,7 @@ public class TestRangeFacetCounts extends FacetTestCase {
       double v = random().nextDouble();
       values[i] = v;
       doc.add(new DoubleDocValuesField("field", v));
-      doc.add(new DoubleField("field", v, Field.Store.NO));
+      doc.add(new DimensionalDoubleField("field", v));
       w.addDocument(doc);
       minValue = Math.min(minValue, v);
       maxValue = Math.max(maxValue, v);
@@ -771,9 +769,9 @@ public class TestRangeFacetCounts extends FacetTestCase {
       Query fastMatchFilter;
       if (random().nextBoolean()) {
         if (random().nextBoolean()) {
-          fastMatchFilter = NumericRangeQuery.newDoubleRange("field", minValue, maxValue, true, true);
+          fastMatchFilter = DimensionalRangeQuery.new1DDoubleRange("field", minValue, true, maxValue, true);
         } else {
-          fastMatchFilter = NumericRangeQuery.newDoubleRange("field", minAcceptedValue, maxAcceptedValue, true, true);
+          fastMatchFilter = DimensionalRangeQuery.new1DDoubleRange("field", minAcceptedValue, true, maxAcceptedValue, true);
         }
       } else {
         fastMatchFilter = null;
@@ -795,7 +793,7 @@ public class TestRangeFacetCounts extends FacetTestCase {
         // Test drill-down:
         DrillDownQuery ddq = new DrillDownQuery(config);
         if (random().nextBoolean()) {
-          ddq.add("field", NumericRangeQuery.newDoubleRange("field", range.min, range.max, range.minInclusive, range.maxInclusive));
+          ddq.add("field", DimensionalRangeQuery.new1DDoubleRange("field", range.min, range.minInclusive, range.max, range.maxInclusive));
         } else {
           ddq.add("field", range.getQuery(fastMatchFilter, vs));
         }
diff --git a/lucene/grouping/src/test/org/apache/lucene/search/grouping/AllGroupHeadsCollectorTest.java b/lucene/grouping/src/test/org/apache/lucene/search/grouping/AllGroupHeadsCollectorTest.java
index d5fc31a..b3e2c40 100644
--- a/lucene/grouping/src/test/org/apache/lucene/search/grouping/AllGroupHeadsCollectorTest.java
+++ b/lucene/grouping/src/test/org/apache/lucene/search/grouping/AllGroupHeadsCollectorTest.java
@@ -31,7 +31,6 @@ import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.BinaryDocValuesField;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
-import org.apache.lucene.document.IntField;
 import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.document.SortedDocValuesField;
 import org.apache.lucene.index.DirectoryReader;
@@ -237,9 +236,6 @@ public class AllGroupHeadsCollectorTest extends LuceneTestCase {
       Field content = newTextField("content", "", Field.Store.NO);
       doc.add(content);
       docNoGroup.add(content);
-      IntField id = new IntField("id", 0, Field.Store.NO);
-      doc.add(id);
-      docNoGroup.add(id);
       NumericDocValuesField idDV = new NumericDocValuesField("id", 0);
       doc.add(idDV);
       docNoGroup.add(idDV);
@@ -275,7 +271,6 @@ public class AllGroupHeadsCollectorTest extends LuceneTestCase {
         sort2.setBytesValue(groupDoc.sort2);
         sort3.setBytesValue(groupDoc.sort3);
         content.setStringValue(groupDoc.content);
-        id.setIntValue(groupDoc.id);
         idDV.setLongValue(groupDoc.id);
         if (groupDoc.group == null) {
           w.addDocument(docNoGroup);
diff --git a/lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping.java b/lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping.java
index 0fad22e..1634678 100644
--- a/lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping.java
+++ b/lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping.java
@@ -33,7 +33,6 @@ import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.FieldType;
-import org.apache.lucene.document.IntField;
 import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.document.SortedDocValuesField;
 import org.apache.lucene.document.StringField;
@@ -597,7 +596,6 @@ public class TestGrouping extends LuceneTestCase {
         doc.add(new SortedDocValuesField("sort1", BytesRef.deepCopyOf(groupValue.sort1)));
         doc.add(newStringField("sort2", groupValue.sort2.utf8ToString(), Field.Store.NO));
         doc.add(new SortedDocValuesField("sort2", BytesRef.deepCopyOf(groupValue.sort2)));
-        doc.add(new IntField("id", groupValue.id, Field.Store.NO));
         doc.add(new NumericDocValuesField("id", groupValue.id));
         doc.add(newTextField("content", groupValue.content, Field.Store.NO));
         //System.out.println("TEST:     doc content=" + groupValue.content + " group=" + (groupValue.group == null ? "null" : groupValue.group.utf8ToString()) + " sort1=" + groupValue.sort1.utf8ToString() + " id=" + groupValue.id);
@@ -712,11 +710,8 @@ public class TestGrouping extends LuceneTestCase {
       Field content = newTextField("content", "", Field.Store.NO);
       doc.add(content);
       docNoGroup.add(content);
-      IntField id = new IntField("id", 0, Field.Store.NO);
-      doc.add(id);
       NumericDocValuesField idDV = new NumericDocValuesField("id", 0);
       doc.add(idDV);
-      docNoGroup.add(id);
       docNoGroup.add(idDV);
       final GroupDoc[] groupDocs = new GroupDoc[numDocs];
       for(int i=0;i<numDocs;i++) {
@@ -751,7 +746,6 @@ public class TestGrouping extends LuceneTestCase {
         sort1.setBytesValue(BytesRef.deepCopyOf(groupDoc.sort1));
         sort2.setBytesValue(BytesRef.deepCopyOf(groupDoc.sort2));
         content.setStringValue(groupDoc.content);
-        id.setIntValue(groupDoc.id);
         idDV.setLongValue(groupDoc.id);
         if (groupDoc.group == null) {
           w.addDocument(docNoGroup);
diff --git a/lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java b/lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java
index ce05eed..1e51e19 100644
--- a/lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java
+++ b/lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java
@@ -17,8 +17,6 @@ package org.apache.lucene.search.highlight;
  * limitations under the License.
  */
 
-import javax.xml.parsers.DocumentBuilder;
-import javax.xml.parsers.DocumentBuilderFactory;
 import java.io.ByteArrayInputStream;
 import java.io.IOException;
 import java.nio.charset.StandardCharsets;
@@ -31,6 +29,9 @@ import java.util.List;
 import java.util.Map;
 import java.util.StringTokenizer;
 
+import javax.xml.parsers.DocumentBuilder;
+import javax.xml.parsers.DocumentBuilderFactory;
+
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.CachingTokenFilter;
@@ -44,10 +45,10 @@ import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
 import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
 import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
+import org.apache.lucene.document.DimensionalIntField;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.FieldType;
-import org.apache.lucene.document.IntField;
 import org.apache.lucene.document.StoredField;
 import org.apache.lucene.document.TextField;
 import org.apache.lucene.index.DirectoryReader;
@@ -59,14 +60,15 @@ import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.queries.CommonTermsQuery;
 import org.apache.lucene.queries.CustomScoreQuery;
+import org.apache.lucene.queries.payloads.SpanPayloadCheckQuery;
 import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.ConstantScoreQuery;
+import org.apache.lucene.search.DimensionalRangeQuery;
 import org.apache.lucene.search.FuzzyQuery;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.MultiPhraseQuery;
 import org.apache.lucene.search.MultiTermQuery;
-import org.apache.lucene.search.NumericRangeQuery;
 import org.apache.lucene.search.PhraseQuery;
 import org.apache.lucene.search.PhraseQuery.Builder;
 import org.apache.lucene.search.PrefixQuery;
@@ -82,7 +84,6 @@ import org.apache.lucene.search.join.QueryBitSetProducer;
 import org.apache.lucene.search.join.ScoreMode;
 import org.apache.lucene.search.join.ToChildBlockJoinQuery;
 import org.apache.lucene.search.join.ToParentBlockJoinQuery;
-import org.apache.lucene.queries.payloads.SpanPayloadCheckQuery;
 import org.apache.lucene.search.spans.SpanMultiTermQueryWrapper;
 import org.apache.lucene.search.spans.SpanNearQuery;
 import org.apache.lucene.search.spans.SpanNotQuery;
@@ -558,9 +559,9 @@ public class HighlighterTest extends BaseTokenStreamTestCase implements Formatte
         numHighlights == 5);
   }
   
-  public void testNumericRangeQuery() throws Exception {
+  public void testDimensionalRangeQuery() throws Exception {
     // doesn't currently highlight, but make sure it doesn't cause exception either
-    query = NumericRangeQuery.newIntRange(NUMERIC_FIELD_NAME, 2, 6, true, true);
+    query = DimensionalRangeQuery.new1DIntRange(NUMERIC_FIELD_NAME, 2, true, 6, true);
     searcher = newSearcher(reader);
     hits = searcher.search(query, 100);
     int maxNumFragmentsRequired = 2;
@@ -2051,22 +2052,22 @@ public class HighlighterTest extends BaseTokenStreamTestCase implements Formatte
 
     // a few tests need other docs...:
     Document doc = new Document();
-    doc.add(new IntField(NUMERIC_FIELD_NAME, 1, Field.Store.NO));
+    doc.add(new DimensionalIntField(NUMERIC_FIELD_NAME, 1));
     doc.add(new StoredField(NUMERIC_FIELD_NAME, 1));
     writer.addDocument(doc);
 
     doc = new Document();
-    doc.add(new IntField(NUMERIC_FIELD_NAME, 3, Field.Store.NO));
+    doc.add(new DimensionalIntField(NUMERIC_FIELD_NAME, 3));
     doc.add(new StoredField(NUMERIC_FIELD_NAME, 3));
     writer.addDocument(doc);
 
     doc = new Document();
-    doc.add(new IntField(NUMERIC_FIELD_NAME, 5, Field.Store.NO));
+    doc.add(new DimensionalIntField(NUMERIC_FIELD_NAME, 5));
     doc.add(new StoredField(NUMERIC_FIELD_NAME, 5));
     writer.addDocument(doc);
 
     doc = new Document();
-    doc.add(new IntField(NUMERIC_FIELD_NAME, 7, Field.Store.NO));
+    doc.add(new DimensionalIntField(NUMERIC_FIELD_NAME, 7));
     doc.add(new StoredField(NUMERIC_FIELD_NAME, 7));
     writer.addDocument(doc);
 
diff --git a/lucene/join/src/java/org/apache/lucene/search/join/DocValuesTermsCollector.java b/lucene/join/src/java/org/apache/lucene/search/join/DocValuesTermsCollector.java
index cdf853d..2f1f1c6 100644
--- a/lucene/join/src/java/org/apache/lucene/search/join/DocValuesTermsCollector.java
+++ b/lucene/join/src/java/org/apache/lucene/search/join/DocValuesTermsCollector.java
@@ -3,7 +3,8 @@ package org.apache.lucene.search.join;
 import java.io.IOException;
 import java.util.function.LongConsumer;
 
-import org.apache.lucene.document.FieldType.NumericType;
+import org.apache.lucene.document.FieldType;
+import org.apache.lucene.document.FieldType.LegacyNumericType;
 import org.apache.lucene.index.BinaryDocValues;
 import org.apache.lucene.index.DocValues;
 import org.apache.lucene.index.LeafReader;
@@ -14,7 +15,7 @@ import org.apache.lucene.index.SortedSetDocValues;
 import org.apache.lucene.search.SimpleCollector;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
-import org.apache.lucene.util.NumericUtils;
+import org.apache.lucene.util.LegacyNumericUtils;
 
 /*
  * Licensed to the Apache Software Foundation (ASF) under one or more
@@ -59,7 +60,7 @@ abstract class DocValuesTermsCollector<DV> extends SimpleCollector {
     return (ctx) -> DocValues.getSortedSet(ctx, field);
   }
   
-  static Function<BinaryDocValues> numericAsBinaryDocValues(String field, NumericType numTyp) {
+  static Function<BinaryDocValues> numericAsBinaryDocValues(String field, LegacyNumericType numTyp) {
     return (ctx) -> {
       final NumericDocValues numeric = DocValues.getNumeric(ctx, field);
       final BytesRefBuilder bytes = new BytesRefBuilder();
@@ -77,21 +78,21 @@ abstract class DocValuesTermsCollector<DV> extends SimpleCollector {
     };
   }
   
-  static LongConsumer coder(BytesRefBuilder bytes, NumericType type, String fieldName){
+  static LongConsumer coder(BytesRefBuilder bytes, LegacyNumericType type, String fieldName){
     switch(type){
       case INT: 
-        return (l) -> NumericUtils.intToPrefixCoded((int)l, 0, bytes);
+        return (l) -> LegacyNumericUtils.intToPrefixCoded((int) l, 0, bytes);
       case LONG: 
-        return (l) -> NumericUtils.longToPrefixCoded(l, 0, bytes);
+        return (l) -> LegacyNumericUtils.longToPrefixCoded(l, 0, bytes);
       default:
         throw new IllegalArgumentException("Unsupported "+type+
-            ". Only "+NumericType.INT+" and "+NumericType.LONG+" are supported."
+            ". Only "+ LegacyNumericType.INT+" and "+ FieldType.LegacyNumericType.LONG+" are supported."
             + "Field "+fieldName );
     }
   }
   
   /** this adapter is quite weird. ords are per doc index, don't use ords across different docs*/
-  static Function<SortedSetDocValues> sortedNumericAsSortedSetDocValues(String field, NumericType numTyp) {
+  static Function<SortedSetDocValues> sortedNumericAsSortedSetDocValues(String field, FieldType.LegacyNumericType numTyp) {
     return (ctx) -> {
       final SortedNumericDocValues numerics = DocValues.getSortedNumeric(ctx, field);
       final BytesRefBuilder bytes = new BytesRefBuilder();
diff --git a/lucene/join/src/java/org/apache/lucene/search/join/JoinUtil.java b/lucene/join/src/java/org/apache/lucene/search/join/JoinUtil.java
index 6505906..c36591b 100644
--- a/lucene/join/src/java/org/apache/lucene/search/join/JoinUtil.java
+++ b/lucene/join/src/java/org/apache/lucene/search/join/JoinUtil.java
@@ -3,9 +3,7 @@ package org.apache.lucene.search.join;
 import java.io.IOException;
 import java.util.Locale;
 
-import org.apache.lucene.document.FieldType.NumericType;
-import org.apache.lucene.document.IntField;
-import org.apache.lucene.document.LongField;
+import org.apache.lucene.document.FieldType.LegacyNumericType;
 import org.apache.lucene.index.BinaryDocValues;
 import org.apache.lucene.index.DocValuesType;
 
@@ -106,8 +104,8 @@ public final class JoinUtil {
    * @param multipleValuesPerDocument Whether the from field has multiple terms per document
    *                                  when true fromField might be {@link DocValuesType#SORTED_NUMERIC},
    *                                  otherwise fromField should be {@link DocValuesType#NUMERIC}
-   * @param toField                   The to field to join to, should be {@link IntField} or {@link LongField}
-   * @param numericType               either {@link NumericType#INT} or {@link NumericType#LONG}, it should correspond to fromField and toField types
+   * @param toField                   The to field to join to, should be {@link org.apache.lucene.document.LegacyIntField} or {@link org.apache.lucene.document.LegacyLongField}
+   * @param numericType               either {@link org.apache.lucene.document.FieldType.LegacyNumericType#INT} or {@link org.apache.lucene.document.FieldType.LegacyNumericType#LONG}, it should correspond to fromField and toField types
    * @param fromQuery                 The query to match documents on the from side
    * @param fromSearcher              The searcher that executed the specified fromQuery
    * @param scoreMode                 Instructs how scores from the fromQuery are mapped to the returned query
@@ -118,7 +116,7 @@ public final class JoinUtil {
   
   public static Query createJoinQuery(String fromField,
       boolean multipleValuesPerDocument,
-      String toField, NumericType numericType,
+      String toField, LegacyNumericType numericType,
       Query fromQuery,
       IndexSearcher fromSearcher,
       ScoreMode scoreMode) throws IOException {
diff --git a/lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery.java b/lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery.java
index 6e002c0..3490d06 100644
--- a/lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery.java
+++ b/lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery.java
@@ -38,7 +38,7 @@ import org.apache.lucene.util.BitSetIterator;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefHash;
 import org.apache.lucene.util.FixedBitSet;
-import org.apache.lucene.util.NumericUtils;
+import org.apache.lucene.util.LegacyNumericUtils;
 
 class TermsIncludingScoreQuery extends Query {
 
@@ -267,10 +267,10 @@ class TermsIncludingScoreQuery extends Query {
       terms.get(ords[i], ref);
       out.print(ref+" "+ref.utf8ToString()+" ");
       try {
-        out.print(Long.toHexString(NumericUtils.prefixCodedToLong(ref))+"L");
+        out.print(Long.toHexString(LegacyNumericUtils.prefixCodedToLong(ref))+"L");
       } catch (Exception e) {
         try {
-          out.print(Integer.toHexString(NumericUtils.prefixCodedToInt(ref))+"i");
+          out.print(Integer.toHexString(LegacyNumericUtils.prefixCodedToInt(ref))+"i");
         } catch (Exception ee) {
         }
       }
diff --git a/lucene/join/src/java/org/apache/lucene/search/join/ToParentBlockJoinSortField.java b/lucene/join/src/java/org/apache/lucene/search/join/ToParentBlockJoinSortField.java
index 8590a75..5623c6e 100644
--- a/lucene/join/src/java/org/apache/lucene/search/join/ToParentBlockJoinSortField.java
+++ b/lucene/join/src/java/org/apache/lucene/search/join/ToParentBlockJoinSortField.java
@@ -27,7 +27,7 @@ import org.apache.lucene.search.FieldComparator;
 import org.apache.lucene.search.SortField;
 import org.apache.lucene.util.BitSet;
 import org.apache.lucene.util.Bits;
-import org.apache.lucene.util.NumericUtils;
+import org.apache.lucene.util.LegacyNumericUtils;
 
 import java.io.IOException;
 
@@ -199,7 +199,7 @@ public class ToParentBlockJoinSortField extends SortField {
         return new NumericDocValues() {
           @Override
           public long get(int docID) {
-            return NumericUtils.sortableFloatBits((int) view.get(docID));
+            return LegacyNumericUtils.sortableFloatBits((int) view.get(docID));
           }
         };
       }
@@ -224,7 +224,7 @@ public class ToParentBlockJoinSortField extends SortField {
         return new NumericDocValues() {
           @Override
           public long get(int docID) {
-            return NumericUtils.sortableDoubleBits(view.get(docID));
+            return LegacyNumericUtils.sortableDoubleBits(view.get(docID));
           }
         };
       }
diff --git a/lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoin.java b/lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoin.java
index b7e9583..598d4d7 100644
--- a/lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoin.java
+++ b/lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoin.java
@@ -26,9 +26,9 @@ import java.util.Locale;
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
 import org.apache.lucene.document.Field.Store;
-import org.apache.lucene.document.IntField;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.document.LegacyIntField;
 import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.document.SortedDocValuesField;
 import org.apache.lucene.document.StoredField;
@@ -46,18 +46,18 @@ import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.index.ReaderUtil;
 import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.Term;
-import org.apache.lucene.search.BooleanClause;
 import org.apache.lucene.search.BooleanClause.Occur;
+import org.apache.lucene.search.BooleanClause;
 import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.BoostQuery;
 import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.search.Explanation;
 import org.apache.lucene.search.FieldDoc;
 import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.LegacyNumericRangeQuery;
 import org.apache.lucene.search.MatchAllDocsQuery;
 import org.apache.lucene.search.MatchNoDocsQuery;
 import org.apache.lucene.search.MultiTermQuery;
-import org.apache.lucene.search.NumericRangeQuery;
 import org.apache.lucene.search.PrefixQuery;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.QueryUtils;
@@ -76,8 +76,8 @@ import org.apache.lucene.util.BitSet;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
+import org.apache.lucene.util.LegacyNumericUtils;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util.NumericUtils;
 import org.apache.lucene.util.TestUtil;
 
 public class TestBlockJoin extends LuceneTestCase {
@@ -95,7 +95,7 @@ public class TestBlockJoin extends LuceneTestCase {
   private Document makeJob(String skill, int year) {
     Document job = new Document();
     job.add(newStringField("skill", skill, Field.Store.YES));
-    job.add(new IntField("year", year, Field.Store.NO));
+    job.add(new LegacyIntField("year", year, Field.Store.NO));
     job.add(new StoredField("year", year));
     return job;
   }
@@ -104,7 +104,7 @@ public class TestBlockJoin extends LuceneTestCase {
   private Document makeQualification(String qualification, int year) {
     Document job = new Document();
     job.add(newStringField("qualification", qualification, Field.Store.YES));
-    job.add(new IntField("year", year, Field.Store.NO));
+    job.add(new LegacyIntField("year", year, Field.Store.NO));
     return job;
   }
   
@@ -137,7 +137,7 @@ public class TestBlockJoin extends LuceneTestCase {
 
     BooleanQuery.Builder childQuery = new BooleanQuery.Builder();
     childQuery.add(new BooleanClause(new TermQuery(new Term("skill", "java")), Occur.MUST));
-    childQuery.add(new BooleanClause(NumericRangeQuery.newIntRange("year", 2006, 2011, true, true), Occur.MUST));
+    childQuery.add(new BooleanClause(LegacyNumericRangeQuery.newIntRange("year", 2006, 2011, true, true), Occur.MUST));
 
     ToParentBlockJoinQuery childJoinQuery = new ToParentBlockJoinQuery(childQuery.build(), parentsFilter, ScoreMode.Avg);
 
@@ -191,7 +191,7 @@ public class TestBlockJoin extends LuceneTestCase {
     // Define child document criteria (finds an example of relevant work experience)
     BooleanQuery.Builder childQuery = new BooleanQuery.Builder();
     childQuery.add(new BooleanClause(new TermQuery(new Term("skill", "java")), Occur.MUST));
-    childQuery.add(new BooleanClause(NumericRangeQuery.newIntRange("year", 2006, 2011, true, true), Occur.MUST));
+    childQuery.add(new BooleanClause(LegacyNumericRangeQuery.newIntRange("year", 2006, 2011, true, true), Occur.MUST));
 
     // Define parent document criteria (find a resident in the UK)
     Query parentQuery = new TermQuery(new Term("country", "United Kingdom"));
@@ -271,7 +271,7 @@ public class TestBlockJoin extends LuceneTestCase {
     w.close();
     IndexSearcher s = newSearcher(r);
 
-    MultiTermQuery qc = NumericRangeQuery.newIntRange("year", 2007, 2007, true, true);
+    MultiTermQuery qc = LegacyNumericRangeQuery.newIntRange("year", 2007, 2007, true, true);
     // Hacky: this causes the query to need 2 rewrite
     // iterations: 
     qc.setRewriteMethod(MultiTermQuery.CONSTANT_SCORE_BOOLEAN_REWRITE);
@@ -344,7 +344,7 @@ public class TestBlockJoin extends LuceneTestCase {
     // Define child document criteria (finds an example of relevant work experience)
     BooleanQuery.Builder childQuery = new BooleanQuery.Builder();
     childQuery.add(new BooleanClause(new TermQuery(new Term("skill", "java")), Occur.MUST));
-    childQuery.add(new BooleanClause(NumericRangeQuery.newIntRange("year", 2006, 2011, true, true), Occur.MUST));
+    childQuery.add(new BooleanClause(LegacyNumericRangeQuery.newIntRange("year", 2006, 2011, true, true), Occur.MUST));
 
     // Define parent document criteria (find a resident in the UK)
     Query parentQuery = new TermQuery(new Term("country", "United Kingdom"));
@@ -518,7 +518,7 @@ public class TestBlockJoin extends LuceneTestCase {
     for(int parentDocID=0;parentDocID<numParentDocs;parentDocID++) {
       Document parentDoc = new Document();
       Document parentJoinDoc = new Document();
-      Field id = new IntField("parentID", parentDocID, Field.Store.YES);
+      Field id = new LegacyIntField("parentID", parentDocID, Field.Store.YES);
       parentDoc.add(id);
       parentJoinDoc.add(id);
       parentJoinDoc.add(newStringField("isParent", "x", Field.Store.NO));
@@ -540,8 +540,8 @@ public class TestBlockJoin extends LuceneTestCase {
       }
 
       if (doDeletes) {
-        parentDoc.add(new IntField("blockID", parentDocID, Field.Store.NO));
-        parentJoinDoc.add(new IntField("blockID", parentDocID, Field.Store.NO));
+        parentDoc.add(new LegacyIntField("blockID", parentDocID, Field.Store.NO));
+        parentJoinDoc.add(new LegacyIntField("blockID", parentDocID, Field.Store.NO));
       }
 
       final List<Document> joinDocs = new ArrayList<>();
@@ -565,7 +565,7 @@ public class TestBlockJoin extends LuceneTestCase {
         Document joinChildDoc = new Document();
         joinDocs.add(joinChildDoc);
 
-        Field childID = new IntField("childID", childDocID, Field.Store.YES);
+        Field childID = new LegacyIntField("childID", childDocID, Field.Store.YES);
         childDoc.add(childID);
         joinChildDoc.add(childID);
         childID = new NumericDocValuesField("childID", childDocID);
@@ -598,7 +598,7 @@ public class TestBlockJoin extends LuceneTestCase {
         }
 
         if (doDeletes) {
-          joinChildDoc.add(new IntField("blockID", parentDocID, Field.Store.NO));
+          joinChildDoc.add(new LegacyIntField("blockID", parentDocID, Field.Store.NO));
         }
 
         w.addDocument(childDoc);
@@ -618,7 +618,7 @@ public class TestBlockJoin extends LuceneTestCase {
       if (VERBOSE) {
         System.out.println("DELETE parentID=" + deleteID);
       }
-      NumericUtils.intToPrefixCodedBytes(deleteID, 0, term);
+      LegacyNumericUtils.intToPrefixCodedBytes(deleteID, 0, term);
       w.deleteDocuments(new Term("blockID", term.toBytesRef()));
       joinW.deleteDocuments(new Term("blockID", term.toBytesRef()));
     }
@@ -1063,11 +1063,11 @@ public class TestBlockJoin extends LuceneTestCase {
     // Define child document criteria (finds an example of relevant work experience)
     BooleanQuery.Builder childJobQuery = new BooleanQuery.Builder();
     childJobQuery.add(new BooleanClause(new TermQuery(new Term("skill", "java")), Occur.MUST));
-    childJobQuery.add(new BooleanClause(NumericRangeQuery.newIntRange("year", 2006, 2011, true, true), Occur.MUST));
+    childJobQuery.add(new BooleanClause(LegacyNumericRangeQuery.newIntRange("year", 2006, 2011, true, true), Occur.MUST));
 
     BooleanQuery.Builder childQualificationQuery = new BooleanQuery.Builder();
     childQualificationQuery.add(new BooleanClause(new TermQuery(new Term("qualification", "maths")), Occur.MUST));
-    childQualificationQuery.add(new BooleanClause(NumericRangeQuery.newIntRange("year", 1980, 2000, true, true), Occur.MUST));
+    childQualificationQuery.add(new BooleanClause(LegacyNumericRangeQuery.newIntRange("year", 1980, 2000, true, true), Occur.MUST));
 
 
     // Define parent document criteria (find a resident in the UK)
@@ -1212,7 +1212,7 @@ public class TestBlockJoin extends LuceneTestCase {
     // Define child document criteria (finds an example of relevant work experience)
     BooleanQuery.Builder childQuery = new BooleanQuery.Builder();
     childQuery.add(new BooleanClause(new TermQuery(new Term("skill", "java")), Occur.MUST));
-    childQuery.add(new BooleanClause(NumericRangeQuery.newIntRange("year", 2006, 2011, true, true), Occur.MUST));
+    childQuery.add(new BooleanClause(LegacyNumericRangeQuery.newIntRange("year", 2006, 2011, true, true), Occur.MUST));
 
     // Wrap the child document query to 'join' any matches
     // up to corresponding parent:
@@ -1711,7 +1711,7 @@ public class TestBlockJoin extends LuceneTestCase {
       Query resumeQuery = new ToChildBlockJoinQuery(new TermQuery(new Term("country","rv" + qrv)),
                                                     resumeFilter);
       
-      Query jobQuery = new ToChildBlockJoinQuery(NumericRangeQuery.newIntRange("year", qjv, qjv, true, true),
+      Query jobQuery = new ToChildBlockJoinQuery(LegacyNumericRangeQuery.newIntRange("year", qjv, qjv, true, true),
                                                  jobFilter);
       
       BooleanQuery.Builder fullQuery = new BooleanQuery.Builder();
diff --git a/lucene/join/src/test/org/apache/lucene/search/join/TestJoinUtil.java b/lucene/join/src/test/org/apache/lucene/search/join/TestJoinUtil.java
index 8170c67..816a8fc 100644
--- a/lucene/join/src/test/org/apache/lucene/search/join/TestJoinUtil.java
+++ b/lucene/join/src/test/org/apache/lucene/search/join/TestJoinUtil.java
@@ -19,9 +19,9 @@ import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.analysis.MockTokenizer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
-import org.apache.lucene.document.FieldType.NumericType;
-import org.apache.lucene.document.IntField;
-import org.apache.lucene.document.LongField;
+import org.apache.lucene.document.FieldType.LegacyNumericType;
+import org.apache.lucene.document.LegacyIntField;
+import org.apache.lucene.document.LegacyLongField;
 import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.document.SortedDocValuesField;
 import org.apache.lucene.document.SortedNumericDocValuesField;
@@ -863,7 +863,7 @@ public class TestJoinUtil extends LuceneTestCase {
           final String toField = from ? "to":"from"; 
           
           if (random().nextBoolean()) { // numbers
-            final NumericType numType = random().nextBoolean() ? NumericType.INT: NumericType.LONG ;
+            final LegacyNumericType numType = random().nextBoolean() ? LegacyNumericType.INT: LegacyNumericType.LONG ;
             joinQuery = JoinUtil.createJoinQuery(fromField+numType, muliValsQuery, toField+numType, numType, actualQuery, indexSearcher, scoreMode);
           } else {
             joinQuery = JoinUtil.createJoinQuery(fromField, muliValsQuery, toField, actualQuery, indexSearcher, scoreMode);
@@ -1204,19 +1204,19 @@ public class TestJoinUtil extends LuceneTestCase {
     document.add(newTextField(random, fieldName, linkValue, Field.Store.NO));
 
     final int linkInt = Integer.parseUnsignedInt(linkValue,16);
-    document.add(new IntField(fieldName+NumericType.INT, linkInt, Field.Store.NO));
+    document.add(new LegacyIntField(fieldName+ LegacyNumericType.INT, linkInt, Field.Store.NO));
 
     final long linkLong = linkInt<<32 | linkInt;
-    document.add(new LongField(fieldName+NumericType.LONG, linkLong, Field.Store.NO));
+    document.add(new LegacyLongField(fieldName+ LegacyNumericType.LONG, linkLong, Field.Store.NO));
 
     if (multipleValuesPerDocument) {
       document.add(new SortedSetDocValuesField(fieldName, new BytesRef(linkValue)));
-      document.add(new SortedNumericDocValuesField(fieldName+NumericType.INT, linkInt));
-      document.add(new SortedNumericDocValuesField(fieldName+NumericType.LONG, linkLong));
+      document.add(new SortedNumericDocValuesField(fieldName+ LegacyNumericType.INT, linkInt));
+      document.add(new SortedNumericDocValuesField(fieldName+ LegacyNumericType.LONG, linkLong));
     } else {
       document.add(new SortedDocValuesField(fieldName, new BytesRef(linkValue)));
-      document.add(new NumericDocValuesField(fieldName+NumericType.INT, linkInt));
-      document.add(new NumericDocValuesField(fieldName+NumericType.LONG, linkLong));
+      document.add(new NumericDocValuesField(fieldName+ LegacyNumericType.INT, linkInt));
+      document.add(new NumericDocValuesField(fieldName+ LegacyNumericType.LONG, linkLong));
     }
     if (globalOrdinalJoin) {
       document.add(new SortedDocValuesField("join_field", new BytesRef(linkValue)));
diff --git a/lucene/misc/src/java/org/apache/lucene/uninverting/FieldCache.java b/lucene/misc/src/java/org/apache/lucene/uninverting/FieldCache.java
index c05f23f..8647da2 100644
--- a/lucene/misc/src/java/org/apache/lucene/uninverting/FieldCache.java
+++ b/lucene/misc/src/java/org/apache/lucene/uninverting/FieldCache.java
@@ -20,11 +20,6 @@ package org.apache.lucene.uninverting;
 import java.io.IOException;
 import java.io.PrintStream;
 
-import org.apache.lucene.analysis.NumericTokenStream;
-import org.apache.lucene.document.DoubleField;
-import org.apache.lucene.document.FloatField;
-import org.apache.lucene.document.IntField;
-import org.apache.lucene.document.LongField;
 import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.index.LeafReader;
 import org.apache.lucene.index.BinaryDocValues;
@@ -37,7 +32,7 @@ import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.util.Accountable;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.NumericUtils;
+import org.apache.lucene.util.LegacyNumericUtils;
 import org.apache.lucene.util.RamUsageEstimator;
 
 /**
@@ -88,18 +83,18 @@ interface FieldCache {
   public static FieldCache DEFAULT = new FieldCacheImpl();
 
   /**
-   * A parser instance for int values encoded by {@link NumericUtils}, e.g. when indexed
-   * via {@link IntField}/{@link NumericTokenStream}.
+   * A parser instance for int values encoded by {@link org.apache.lucene.util.LegacyNumericUtils}, e.g. when indexed
+   * via {@link org.apache.lucene.document.LegacyIntField}/{@link org.apache.lucene.analysis.LegacyNumericTokenStream}.
    */
   public static final Parser NUMERIC_UTILS_INT_PARSER = new Parser() {
     @Override
     public long parseValue(BytesRef term) {
-      return NumericUtils.prefixCodedToInt(term);
+      return LegacyNumericUtils.prefixCodedToInt(term);
     }
     
     @Override
     public TermsEnum termsEnum(Terms terms) throws IOException {
-      return NumericUtils.filterPrefixCodedInts(terms.iterator());
+      return LegacyNumericUtils.filterPrefixCodedInts(terms.iterator());
     }
     
     @Override
@@ -109,13 +104,13 @@ interface FieldCache {
   };
 
   /**
-   * A parser instance for float values encoded with {@link NumericUtils}, e.g. when indexed
-   * via {@link FloatField}/{@link NumericTokenStream}.
+   * A parser instance for float values encoded with {@link org.apache.lucene.util.LegacyNumericUtils}, e.g. when indexed
+   * via {@link org.apache.lucene.document.LegacyFloatField}/{@link org.apache.lucene.analysis.LegacyNumericTokenStream}.
    */
   public static final Parser NUMERIC_UTILS_FLOAT_PARSER = new Parser() {
     @Override
     public long parseValue(BytesRef term) {
-      int val = NumericUtils.prefixCodedToInt(term);
+      int val = LegacyNumericUtils.prefixCodedToInt(term);
       if (val<0) val ^= 0x7fffffff;
       return val;
     }
@@ -127,18 +122,18 @@ interface FieldCache {
     
     @Override
     public TermsEnum termsEnum(Terms terms) throws IOException {
-      return NumericUtils.filterPrefixCodedInts(terms.iterator());
+      return LegacyNumericUtils.filterPrefixCodedInts(terms.iterator());
     }
   };
 
   /**
-   * A parser instance for long values encoded by {@link NumericUtils}, e.g. when indexed
-   * via {@link LongField}/{@link NumericTokenStream}.
+   * A parser instance for long values encoded by {@link org.apache.lucene.util.LegacyNumericUtils}, e.g. when indexed
+   * via {@link org.apache.lucene.document.LegacyLongField}/{@link org.apache.lucene.analysis.LegacyNumericTokenStream}.
    */
   public static final Parser NUMERIC_UTILS_LONG_PARSER = new Parser() {
     @Override
     public long parseValue(BytesRef term) {
-      return NumericUtils.prefixCodedToLong(term);
+      return LegacyNumericUtils.prefixCodedToLong(term);
     }
     @Override
     public String toString() { 
@@ -147,18 +142,18 @@ interface FieldCache {
     
     @Override
     public TermsEnum termsEnum(Terms terms) throws IOException {
-      return NumericUtils.filterPrefixCodedLongs(terms.iterator());
+      return LegacyNumericUtils.filterPrefixCodedLongs(terms.iterator());
     }
   };
 
   /**
-   * A parser instance for double values encoded with {@link NumericUtils}, e.g. when indexed
-   * via {@link DoubleField}/{@link NumericTokenStream}.
+   * A parser instance for double values encoded with {@link org.apache.lucene.util.LegacyNumericUtils}, e.g. when indexed
+   * via {@link org.apache.lucene.document.LegacyDoubleField}/{@link org.apache.lucene.analysis.LegacyNumericTokenStream}.
    */
   public static final Parser NUMERIC_UTILS_DOUBLE_PARSER = new Parser() {
     @Override
     public long parseValue(BytesRef term) {
-      long val = NumericUtils.prefixCodedToLong(term);
+      long val = LegacyNumericUtils.prefixCodedToLong(term);
       if (val<0) val ^= 0x7fffffffffffffffL;
       return val;
     }
@@ -169,7 +164,7 @@ interface FieldCache {
     
     @Override
     public TermsEnum termsEnum(Terms terms) throws IOException {
-      return NumericUtils.filterPrefixCodedLongs(terms.iterator());
+      return LegacyNumericUtils.filterPrefixCodedLongs(terms.iterator());
     }
   };
   
@@ -196,7 +191,7 @@ interface FieldCache {
    * @param parser
    *          Computes long for string values. May be {@code null} if the
    *          requested field was indexed as {@link NumericDocValuesField} or
-   *          {@link LongField}.
+   *          {@link org.apache.lucene.document.LegacyLongField}.
    * @param setDocsWithField
    *          If true then {@link #getDocsWithField} will also be computed and
    *          stored in the FieldCache.
@@ -247,9 +242,9 @@ interface FieldCache {
   public SortedDocValues getTermsIndex(LeafReader reader, String field, float acceptableOverheadRatio) throws IOException;
 
   /** Can be passed to {@link #getDocTermOrds} to filter for 32-bit numeric terms */
-  public static final BytesRef INT32_TERM_PREFIX = new BytesRef(new byte[] { NumericUtils.SHIFT_START_INT });
+  public static final BytesRef INT32_TERM_PREFIX = new BytesRef(new byte[] { LegacyNumericUtils.SHIFT_START_INT });
   /** Can be passed to {@link #getDocTermOrds} to filter for 64-bit numeric terms */
-  public static final BytesRef INT64_TERM_PREFIX = new BytesRef(new byte[] { NumericUtils.SHIFT_START_LONG });
+  public static final BytesRef INT64_TERM_PREFIX = new BytesRef(new byte[] { LegacyNumericUtils.SHIFT_START_LONG });
   
   /**
    * Checks the internal cache for an appropriate entry, and if none is found, reads the term values
diff --git a/lucene/misc/src/java/org/apache/lucene/uninverting/UninvertingReader.java b/lucene/misc/src/java/org/apache/lucene/uninverting/UninvertingReader.java
index 9b65d0c..a91bd3f 100644
--- a/lucene/misc/src/java/org/apache/lucene/uninverting/UninvertingReader.java
+++ b/lucene/misc/src/java/org/apache/lucene/uninverting/UninvertingReader.java
@@ -23,10 +23,6 @@ import java.util.Collections;
 import java.util.Map;
 
 import org.apache.lucene.document.BinaryDocValuesField; // javadocs
-import org.apache.lucene.document.DoubleField; // javadocs
-import org.apache.lucene.document.FloatField; // javadocs
-import org.apache.lucene.document.IntField; // javadocs
-import org.apache.lucene.document.LongField; // javadocs
 import org.apache.lucene.document.NumericDocValuesField; // javadocs
 import org.apache.lucene.document.SortedDocValuesField; // javadocs
 import org.apache.lucene.document.SortedSetDocValuesField; // javadocs
@@ -64,28 +60,28 @@ public class UninvertingReader extends FilterLeafReader {
    */
   public static enum Type {
     /** 
-     * Single-valued Integer, (e.g. indexed with {@link IntField})
+     * Single-valued Integer, (e.g. indexed with {@link org.apache.lucene.document.LegacyIntField})
      * <p>
      * Fields with this type act as if they were indexed with
      * {@link NumericDocValuesField}.
      */
     INTEGER,
     /** 
-     * Single-valued Long, (e.g. indexed with {@link LongField}) 
+     * Single-valued Long, (e.g. indexed with {@link org.apache.lucene.document.LegacyLongField})
      * <p>
      * Fields with this type act as if they were indexed with
      * {@link NumericDocValuesField}.
      */
     LONG,
     /** 
-     * Single-valued Float, (e.g. indexed with {@link FloatField}) 
+     * Single-valued Float, (e.g. indexed with {@link org.apache.lucene.document.LegacyFloatField})
      * <p>
      * Fields with this type act as if they were indexed with
      * {@link NumericDocValuesField}.
      */
     FLOAT,
     /** 
-     * Single-valued Double, (e.g. indexed with {@link DoubleField}) 
+     * Single-valued Double, (e.g. indexed with {@link org.apache.lucene.document.LegacyDoubleField})
      * <p>
      * Fields with this type act as if they were indexed with
      * {@link NumericDocValuesField}.
@@ -113,28 +109,28 @@ public class UninvertingReader extends FilterLeafReader {
      */
     SORTED_SET_BINARY,
     /** 
-     * Multi-valued Integer, (e.g. indexed with {@link IntField}) 
+     * Multi-valued Integer, (e.g. indexed with {@link org.apache.lucene.document.LegacyIntField})
      * <p>
      * Fields with this type act as if they were indexed with
      * {@link SortedSetDocValuesField}.
      */
     SORTED_SET_INTEGER,
     /** 
-     * Multi-valued Float, (e.g. indexed with {@link FloatField}) 
+     * Multi-valued Float, (e.g. indexed with {@link org.apache.lucene.document.LegacyFloatField})
      * <p>
      * Fields with this type act as if they were indexed with
      * {@link SortedSetDocValuesField}.
      */
     SORTED_SET_FLOAT,
     /** 
-     * Multi-valued Long, (e.g. indexed with {@link LongField}) 
+     * Multi-valued Long, (e.g. indexed with {@link org.apache.lucene.document.LegacyLongField})
      * <p>
      * Fields with this type act as if they were indexed with
      * {@link SortedSetDocValuesField}.
      */
     SORTED_SET_LONG,
     /** 
-     * Multi-valued Double, (e.g. indexed with {@link DoubleField}) 
+     * Multi-valued Double, (e.g. indexed with {@link org.apache.lucene.document.LegacyDoubleField})
      * <p>
      * Fields with this type act as if they were indexed with
      * {@link SortedSetDocValuesField}.
diff --git a/lucene/misc/src/test/org/apache/lucene/index/SorterTestBase.java b/lucene/misc/src/test/org/apache/lucene/index/SorterTestBase.java
index c341db8..76f54bf 100644
--- a/lucene/misc/src/test/org/apache/lucene/index/SorterTestBase.java
+++ b/lucene/misc/src/test/org/apache/lucene/index/SorterTestBase.java
@@ -30,10 +30,10 @@ import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
 import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
 import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;
 import org.apache.lucene.document.BinaryDocValuesField;
-import org.apache.lucene.document.DimensionalField;
+import org.apache.lucene.document.DimensionalBinaryField;
 import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
 import org.apache.lucene.document.Field.Store;
+import org.apache.lucene.document.Field;
 import org.apache.lucene.document.FieldType;
 import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.document.SortedDocValuesField;
@@ -54,8 +54,8 @@ import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.NumericUtils;
 import org.apache.lucene.util.TestUtil;
-import org.apache.lucene.util.bkd.BKDUtil;
 import org.junit.AfterClass;
 import org.junit.BeforeClass;
 
@@ -174,8 +174,8 @@ public abstract class SorterTestBase extends LuceneTestCase {
     doc.add(new SortedNumericDocValuesField(SORTED_NUMERIC_DV_FIELD, id + 1));
     doc.add(new Field(TERM_VECTORS_FIELD, Integer.toString(id), TERM_VECTORS_TYPE));
     byte[] bytes = new byte[4];
-    BKDUtil.intToBytes(id, bytes, 0);
-    doc.add(new DimensionalField(DIMENSIONAL_FIELD, bytes));
+    NumericUtils.intToBytes(id, bytes, 0);
+    doc.add(new DimensionalBinaryField(DIMENSIONAL_FIELD, bytes));
     return doc;
   }
 
@@ -390,7 +390,7 @@ public abstract class SorterTestBase extends LuceneTestCase {
 
                        @Override
                        public void visit(int docID, byte[] packedValues) {
-                         assertEquals(sortedValues[docID].intValue(), BKDUtil.bytesToInt(packedValues, 0));
+                         assertEquals(sortedValues[docID].intValue(), NumericUtils.bytesToInt(packedValues, 0));
                        }
 
                        @Override
diff --git a/lucene/misc/src/test/org/apache/lucene/search/TestDiversifiedTopDocsCollector.java b/lucene/misc/src/test/org/apache/lucene/search/TestDiversifiedTopDocsCollector.java
index 853ccb2..26296b6 100644
--- a/lucene/misc/src/test/org/apache/lucene/search/TestDiversifiedTopDocsCollector.java
+++ b/lucene/misc/src/test/org/apache/lucene/search/TestDiversifiedTopDocsCollector.java
@@ -25,7 +25,7 @@ import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.Field.Store;
 import org.apache.lucene.document.FloatDocValuesField;
-import org.apache.lucene.document.FloatField;
+import org.apache.lucene.document.LegacyFloatField;
 import org.apache.lucene.document.SortedDocValuesField;
 import org.apache.lucene.index.BinaryDocValues;
 import org.apache.lucene.index.DocValues;
@@ -334,7 +334,7 @@ public class TestDiversifiedTopDocsCollector extends LuceneTestCase {
         new BytesRef(""));
     Field weeksAtNumberOneField = new FloatDocValuesField("weeksAtNumberOne",
         0.0F);
-    Field weeksStoredField = new FloatField("weeks", 0.0F, Store.YES);
+    Field weeksStoredField = new LegacyFloatField("weeks", 0.0F, Store.YES);
     Field idField = newStringField("id", "", Field.Store.YES);
     Field songField = newTextField("song", "", Field.Store.NO);
     Field storedArtistField = newTextField("artistName", "", Field.Store.NO);
diff --git a/lucene/misc/src/test/org/apache/lucene/uninverting/TestDocTermOrds.java b/lucene/misc/src/test/org/apache/lucene/uninverting/TestDocTermOrds.java
index c8a7123..f00c518 100644
--- a/lucene/misc/src/test/org/apache/lucene/uninverting/TestDocTermOrds.java
+++ b/lucene/misc/src/test/org/apache/lucene/uninverting/TestDocTermOrds.java
@@ -29,8 +29,8 @@ import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.codecs.Codec;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
-import org.apache.lucene.document.IntField;
-import org.apache.lucene.document.LongField;
+import org.apache.lucene.document.LegacyIntField;
+import org.apache.lucene.document.LegacyLongField;
 import org.apache.lucene.document.StringField;
 import org.apache.lucene.index.LeafReader;
 import org.apache.lucene.index.LeafReaderContext;
@@ -51,7 +51,7 @@ import org.apache.lucene.index.TermsEnum.SeekStatus;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util.NumericUtils;
+import org.apache.lucene.util.LegacyNumericUtils;
 import org.apache.lucene.util.StringHelper;
 import org.apache.lucene.util.TestUtil;
 
@@ -171,7 +171,7 @@ public class TestDocTermOrds extends LuceneTestCase {
     for(int id=0;id<NUM_DOCS;id++) {
       Document doc = new Document();
 
-      doc.add(new IntField("id", id, Field.Store.YES));
+      doc.add(new LegacyIntField("id", id, Field.Store.YES));
       
       final int termCount = TestUtil.nextInt(random(), 0, 20 * RANDOM_MULTIPLIER);
       while(ordsForDocSet.size() < termCount) {
@@ -269,7 +269,7 @@ public class TestDocTermOrds extends LuceneTestCase {
     for(int id=0;id<NUM_DOCS;id++) {
       Document doc = new Document();
 
-      doc.add(new IntField("id", id, Field.Store.YES));
+      doc.add(new LegacyIntField("id", id, Field.Store.YES));
       
       final int termCount = TestUtil.nextInt(random(), 0, 20 * RANDOM_MULTIPLIER);
       while(ordsForDocSet.size() < termCount) {
@@ -462,12 +462,12 @@ public class TestDocTermOrds extends LuceneTestCase {
     IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(null));
     
     Document doc = new Document();
-    doc.add(new IntField("foo", 5, Field.Store.NO));
+    doc.add(new LegacyIntField("foo", 5, Field.Store.NO));
     iw.addDocument(doc);
     
     doc = new Document();
-    doc.add(new IntField("foo", 5, Field.Store.NO));
-    doc.add(new IntField("foo", -3, Field.Store.NO));
+    doc.add(new LegacyIntField("foo", 5, Field.Store.NO));
+    doc.add(new LegacyIntField("foo", -3, Field.Store.NO));
     iw.addDocument(doc);
     
     iw.forceMerge(1);
@@ -489,10 +489,10 @@ public class TestDocTermOrds extends LuceneTestCase {
     assertEquals(SortedSetDocValues.NO_MORE_ORDS, v.nextOrd());
     
     BytesRef value = v.lookupOrd(0);
-    assertEquals(-3, NumericUtils.prefixCodedToInt(value));
+    assertEquals(-3, LegacyNumericUtils.prefixCodedToInt(value));
     
     value = v.lookupOrd(1);
-    assertEquals(5, NumericUtils.prefixCodedToInt(value));
+    assertEquals(5, LegacyNumericUtils.prefixCodedToInt(value));
     
     ir.close();
     dir.close();
@@ -503,12 +503,12 @@ public class TestDocTermOrds extends LuceneTestCase {
     IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(null));
     
     Document doc = new Document();
-    doc.add(new LongField("foo", 5, Field.Store.NO));
+    doc.add(new LegacyLongField("foo", 5, Field.Store.NO));
     iw.addDocument(doc);
     
     doc = new Document();
-    doc.add(new LongField("foo", 5, Field.Store.NO));
-    doc.add(new LongField("foo", -3, Field.Store.NO));
+    doc.add(new LegacyLongField("foo", 5, Field.Store.NO));
+    doc.add(new LegacyLongField("foo", -3, Field.Store.NO));
     iw.addDocument(doc);
     
     iw.forceMerge(1);
@@ -530,10 +530,10 @@ public class TestDocTermOrds extends LuceneTestCase {
     assertEquals(SortedSetDocValues.NO_MORE_ORDS, v.nextOrd());
     
     BytesRef value = v.lookupOrd(0);
-    assertEquals(-3, NumericUtils.prefixCodedToLong(value));
+    assertEquals(-3, LegacyNumericUtils.prefixCodedToLong(value));
     
     value = v.lookupOrd(1);
-    assertEquals(5, NumericUtils.prefixCodedToLong(value));
+    assertEquals(5, LegacyNumericUtils.prefixCodedToLong(value));
     
     ir.close();
     dir.close();
diff --git a/lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCache.java b/lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCache.java
index 40a796e..64f2f9d 100644
--- a/lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCache.java
+++ b/lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCache.java
@@ -30,12 +30,12 @@ import java.util.concurrent.atomic.AtomicInteger;
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.BinaryDocValuesField;
 import org.apache.lucene.document.Document;
-import org.apache.lucene.document.DoubleField;
+import org.apache.lucene.document.LegacyDoubleField;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.Field.Store;
-import org.apache.lucene.document.FloatField;
-import org.apache.lucene.document.IntField;
-import org.apache.lucene.document.LongField;
+import org.apache.lucene.document.LegacyFloatField;
+import org.apache.lucene.document.LegacyIntField;
+import org.apache.lucene.document.LegacyLongField;
 import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.document.SortedDocValuesField;
 import org.apache.lucene.document.SortedSetDocValuesField;
@@ -57,8 +57,8 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.LegacyNumericUtils;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util.NumericUtils;
 import org.apache.lucene.util.TestUtil;
 import org.junit.AfterClass;
 import org.junit.BeforeClass;
@@ -88,16 +88,16 @@ public class TestFieldCache extends LuceneTestCase {
     }
     for (int i = 0; i < NUM_DOCS; i++){
       Document doc = new Document();
-      doc.add(new LongField("theLong", theLong--, Field.Store.NO));
-      doc.add(new DoubleField("theDouble", theDouble--, Field.Store.NO));
-      doc.add(new IntField("theInt", theInt--, Field.Store.NO));
-      doc.add(new FloatField("theFloat", theFloat--, Field.Store.NO));
+      doc.add(new LegacyLongField("theLong", theLong--, Field.Store.NO));
+      doc.add(new LegacyDoubleField("theDouble", theDouble--, Field.Store.NO));
+      doc.add(new LegacyIntField("theInt", theInt--, Field.Store.NO));
+      doc.add(new LegacyFloatField("theFloat", theFloat--, Field.Store.NO));
       if (i%2 == 0) {
-        doc.add(new IntField("sparse", i, Field.Store.NO));
+        doc.add(new LegacyIntField("sparse", i, Field.Store.NO));
       }
 
       if (i%2 == 0) {
-        doc.add(new IntField("numInt", i, Field.Store.NO));
+        doc.add(new LegacyIntField("numInt", i, Field.Store.NO));
       }
 
       // sometimes skip the field:
@@ -142,11 +142,11 @@ public class TestFieldCache extends LuceneTestCase {
       cache.getNumerics(reader, "theDouble", new FieldCache.Parser() {
         @Override
         public TermsEnum termsEnum(Terms terms) throws IOException {
-          return NumericUtils.filterPrefixCodedLongs(terms.iterator());
+          return LegacyNumericUtils.filterPrefixCodedLongs(terms.iterator());
         }
         @Override
         public long parseValue(BytesRef term) {
-          int val = (int) NumericUtils.prefixCodedToLong(term);
+          int val = (int) LegacyNumericUtils.prefixCodedToLong(term);
           if (val<0) val ^= 0x7fffffff;
           return val;
         }
@@ -672,7 +672,7 @@ public class TestFieldCache extends LuceneTestCase {
     cfg.setMergePolicy(newLogMergePolicy());
     RandomIndexWriter iw = new RandomIndexWriter(random(), dir, cfg);
     Document doc = new Document();
-    LongField field = new LongField("f", 0L, Store.YES);
+    LegacyLongField field = new LegacyLongField("f", 0L, Store.YES);
     doc.add(field);
     final long[] values = new long[TestUtil.nextInt(random(), 1, 10)];
     for (int i = 0; i < values.length; ++i) {
@@ -718,7 +718,7 @@ public class TestFieldCache extends LuceneTestCase {
     cfg.setMergePolicy(newLogMergePolicy());
     RandomIndexWriter iw = new RandomIndexWriter(random(), dir, cfg);
     Document doc = new Document();
-    IntField field = new IntField("f", 0, Store.YES);
+    LegacyIntField field = new LegacyIntField("f", 0, Store.YES);
     doc.add(field);
     final int[] values = new int[TestUtil.nextInt(random(), 1, 10)];
     for (int i = 0; i < values.length; ++i) {
diff --git a/lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheReopen.java b/lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheReopen.java
index b8ab53d..c10ec13 100644
--- a/lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheReopen.java
+++ b/lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheReopen.java
@@ -20,7 +20,7 @@ package org.apache.lucene.uninverting;
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
-import org.apache.lucene.document.IntField;
+import org.apache.lucene.document.LegacyIntField;
 import org.apache.lucene.index.LeafReader;
 import org.apache.lucene.index.DirectoryReader;
 import org.apache.lucene.index.IndexWriter;
@@ -43,7 +43,7 @@ public class TestFieldCacheReopen extends LuceneTestCase {
             setMergePolicy(newLogMergePolicy(10))
     );
     Document doc = new Document();
-    doc.add(new IntField("number", 17, Field.Store.NO));
+    doc.add(new LegacyIntField("number", 17, Field.Store.NO));
     writer.addDocument(doc);
     writer.commit();
   
diff --git a/lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheSanityChecker.java b/lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheSanityChecker.java
index fb3fd57..b6e83df 100644
--- a/lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheSanityChecker.java
+++ b/lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheSanityChecker.java
@@ -20,11 +20,11 @@ import java.io.IOException;
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
-import org.apache.lucene.document.DoubleField;
+import org.apache.lucene.document.LegacyDoubleField;
 import org.apache.lucene.document.Field;
-import org.apache.lucene.document.FloatField;
-import org.apache.lucene.document.IntField;
-import org.apache.lucene.document.LongField;
+import org.apache.lucene.document.LegacyFloatField;
+import org.apache.lucene.document.LegacyIntField;
+import org.apache.lucene.document.LegacyLongField;
 import org.apache.lucene.index.LeafReader;
 import org.apache.lucene.index.DirectoryReader;
 import org.apache.lucene.index.IndexWriter;
@@ -59,10 +59,10 @@ public class TestFieldCacheSanityChecker extends LuceneTestCase {
     float theFloat = Float.MAX_VALUE;
     for (int i = 0; i < NUM_DOCS; i++){
       Document doc = new Document();
-      doc.add(new LongField("theLong", theLong--, Field.Store.NO));
-      doc.add(new DoubleField("theDouble", theDouble--, Field.Store.NO));
-      doc.add(new IntField("theInt", theInt--, Field.Store.NO));
-      doc.add(new FloatField("theFloat", theFloat--, Field.Store.NO));
+      doc.add(new LegacyLongField("theLong", theLong--, Field.Store.NO));
+      doc.add(new LegacyDoubleField("theDouble", theDouble--, Field.Store.NO));
+      doc.add(new LegacyIntField("theInt", theInt--, Field.Store.NO));
+      doc.add(new LegacyFloatField("theFloat", theFloat--, Field.Store.NO));
       if (0 == i % 3) {
         wA.addDocument(doc);
       } else {
diff --git a/lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheSort.java b/lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheSort.java
index 6580ade..a29201a 100644
--- a/lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheSort.java
+++ b/lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheSort.java
@@ -24,11 +24,11 @@ import java.util.Map;
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
-import org.apache.lucene.document.DoubleField;
+import org.apache.lucene.document.LegacyDoubleField;
 import org.apache.lucene.document.Field;
-import org.apache.lucene.document.FloatField;
-import org.apache.lucene.document.IntField;
-import org.apache.lucene.document.LongField;
+import org.apache.lucene.document.LegacyFloatField;
+import org.apache.lucene.document.LegacyIntField;
+import org.apache.lucene.document.LegacyLongField;
 import org.apache.lucene.document.StringField;
 import org.apache.lucene.index.DirectoryReader;
 import org.apache.lucene.index.IndexReader;
@@ -450,13 +450,13 @@ public class TestFieldCacheSort extends LuceneTestCase {
     Directory dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random(), dir);
     Document doc = new Document();
-    doc.add(new IntField("value", 300000, Field.Store.YES));
+    doc.add(new LegacyIntField("value", 300000, Field.Store.YES));
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new IntField("value", -1, Field.Store.YES));
+    doc.add(new LegacyIntField("value", -1, Field.Store.YES));
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new IntField("value", 4, Field.Store.YES));
+    doc.add(new LegacyIntField("value", 4, Field.Store.YES));
     writer.addDocument(doc);
     IndexReader ir = UninvertingReader.wrap(writer.getReader(), 
                      Collections.singletonMap("value", Type.INTEGER));
@@ -483,10 +483,10 @@ public class TestFieldCacheSort extends LuceneTestCase {
     Document doc = new Document();
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new IntField("value", -1, Field.Store.YES));
+    doc.add(new LegacyIntField("value", -1, Field.Store.YES));
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new IntField("value", 4, Field.Store.YES));
+    doc.add(new LegacyIntField("value", 4, Field.Store.YES));
     writer.addDocument(doc);
     IndexReader ir = UninvertingReader.wrap(writer.getReader(), 
                      Collections.singletonMap("value", Type.INTEGER));
@@ -513,10 +513,10 @@ public class TestFieldCacheSort extends LuceneTestCase {
     Document doc = new Document();
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new IntField("value", -1, Field.Store.YES));
+    doc.add(new LegacyIntField("value", -1, Field.Store.YES));
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new IntField("value", 4, Field.Store.YES));
+    doc.add(new LegacyIntField("value", 4, Field.Store.YES));
     writer.addDocument(doc);
     IndexReader ir = UninvertingReader.wrap(writer.getReader(), 
                      Collections.singletonMap("value", Type.INTEGER));
@@ -543,13 +543,13 @@ public class TestFieldCacheSort extends LuceneTestCase {
     Directory dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random(), dir);
     Document doc = new Document();
-    doc.add(new IntField("value", 300000, Field.Store.YES));
+    doc.add(new LegacyIntField("value", 300000, Field.Store.YES));
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new IntField("value", -1, Field.Store.YES));
+    doc.add(new LegacyIntField("value", -1, Field.Store.YES));
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new IntField("value", 4, Field.Store.YES));
+    doc.add(new LegacyIntField("value", 4, Field.Store.YES));
     writer.addDocument(doc);
     IndexReader ir = UninvertingReader.wrap(writer.getReader(), 
                      Collections.singletonMap("value", Type.INTEGER));
@@ -574,13 +574,13 @@ public class TestFieldCacheSort extends LuceneTestCase {
     Directory dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random(), dir);
     Document doc = new Document();
-    doc.add(new LongField("value", 3000000000L, Field.Store.YES));
+    doc.add(new LegacyLongField("value", 3000000000L, Field.Store.YES));
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new LongField("value", -1, Field.Store.YES));
+    doc.add(new LegacyLongField("value", -1, Field.Store.YES));
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new LongField("value", 4, Field.Store.YES));
+    doc.add(new LegacyLongField("value", 4, Field.Store.YES));
     writer.addDocument(doc);
     IndexReader ir = UninvertingReader.wrap(writer.getReader(), 
                      Collections.singletonMap("value", Type.LONG));
@@ -607,10 +607,10 @@ public class TestFieldCacheSort extends LuceneTestCase {
     Document doc = new Document();
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new LongField("value", -1, Field.Store.YES));
+    doc.add(new LegacyLongField("value", -1, Field.Store.YES));
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new LongField("value", 4, Field.Store.YES));
+    doc.add(new LegacyLongField("value", 4, Field.Store.YES));
     writer.addDocument(doc);
     IndexReader ir = UninvertingReader.wrap(writer.getReader(), 
                      Collections.singletonMap("value", Type.LONG));
@@ -637,10 +637,10 @@ public class TestFieldCacheSort extends LuceneTestCase {
     Document doc = new Document();
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new LongField("value", -1, Field.Store.YES));
+    doc.add(new LegacyLongField("value", -1, Field.Store.YES));
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new LongField("value", 4, Field.Store.YES));
+    doc.add(new LegacyLongField("value", 4, Field.Store.YES));
     writer.addDocument(doc);
     IndexReader ir = UninvertingReader.wrap(writer.getReader(), 
                      Collections.singletonMap("value", Type.LONG));
@@ -667,13 +667,13 @@ public class TestFieldCacheSort extends LuceneTestCase {
     Directory dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random(), dir);
     Document doc = new Document();
-    doc.add(new LongField("value", 3000000000L, Field.Store.YES));
+    doc.add(new LegacyLongField("value", 3000000000L, Field.Store.YES));
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new LongField("value", -1, Field.Store.YES));
+    doc.add(new LegacyLongField("value", -1, Field.Store.YES));
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new LongField("value", 4, Field.Store.YES));
+    doc.add(new LegacyLongField("value", 4, Field.Store.YES));
     writer.addDocument(doc);
     IndexReader ir = UninvertingReader.wrap(writer.getReader(), 
                      Collections.singletonMap("value", Type.LONG));
@@ -698,13 +698,13 @@ public class TestFieldCacheSort extends LuceneTestCase {
     Directory dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random(), dir);
     Document doc = new Document();
-    doc.add(new FloatField("value", 30.1f, Field.Store.YES));
+    doc.add(new LegacyFloatField("value", 30.1f, Field.Store.YES));
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new FloatField("value", -1.3f, Field.Store.YES));
+    doc.add(new LegacyFloatField("value", -1.3f, Field.Store.YES));
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new FloatField("value", 4.2f, Field.Store.YES));
+    doc.add(new LegacyFloatField("value", 4.2f, Field.Store.YES));
     writer.addDocument(doc);
     IndexReader ir = UninvertingReader.wrap(writer.getReader(), 
                      Collections.singletonMap("value", Type.FLOAT));
@@ -731,10 +731,10 @@ public class TestFieldCacheSort extends LuceneTestCase {
     Document doc = new Document();
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new FloatField("value", -1.3f, Field.Store.YES));
+    doc.add(new LegacyFloatField("value", -1.3f, Field.Store.YES));
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new FloatField("value", 4.2f, Field.Store.YES));
+    doc.add(new LegacyFloatField("value", 4.2f, Field.Store.YES));
     writer.addDocument(doc);
     IndexReader ir = UninvertingReader.wrap(writer.getReader(), 
                      Collections.singletonMap("value", Type.FLOAT));
@@ -761,10 +761,10 @@ public class TestFieldCacheSort extends LuceneTestCase {
     Document doc = new Document();
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new FloatField("value", -1.3f, Field.Store.YES));
+    doc.add(new LegacyFloatField("value", -1.3f, Field.Store.YES));
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new FloatField("value", 4.2f, Field.Store.YES));
+    doc.add(new LegacyFloatField("value", 4.2f, Field.Store.YES));
     writer.addDocument(doc);
     IndexReader ir = UninvertingReader.wrap(writer.getReader(), 
                      Collections.singletonMap("value", Type.FLOAT));
@@ -791,13 +791,13 @@ public class TestFieldCacheSort extends LuceneTestCase {
     Directory dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random(), dir);
     Document doc = new Document();
-    doc.add(new FloatField("value", 30.1f, Field.Store.YES));
+    doc.add(new LegacyFloatField("value", 30.1f, Field.Store.YES));
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new FloatField("value", -1.3f, Field.Store.YES));
+    doc.add(new LegacyFloatField("value", -1.3f, Field.Store.YES));
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new FloatField("value", 4.2f, Field.Store.YES));
+    doc.add(new LegacyFloatField("value", 4.2f, Field.Store.YES));
     writer.addDocument(doc);
     IndexReader ir = UninvertingReader.wrap(writer.getReader(), 
                      Collections.singletonMap("value", Type.FLOAT));
@@ -822,16 +822,16 @@ public class TestFieldCacheSort extends LuceneTestCase {
     Directory dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random(), dir);
     Document doc = new Document();
-    doc.add(new DoubleField("value", 30.1, Field.Store.YES));
+    doc.add(new LegacyDoubleField("value", 30.1, Field.Store.YES));
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new DoubleField("value", -1.3, Field.Store.YES));
+    doc.add(new LegacyDoubleField("value", -1.3, Field.Store.YES));
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new DoubleField("value", 4.2333333333333, Field.Store.YES));
+    doc.add(new LegacyDoubleField("value", 4.2333333333333, Field.Store.YES));
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new DoubleField("value", 4.2333333333332, Field.Store.YES));
+    doc.add(new LegacyDoubleField("value", 4.2333333333332, Field.Store.YES));
     writer.addDocument(doc);
     IndexReader ir = UninvertingReader.wrap(writer.getReader(), 
                      Collections.singletonMap("value", Type.DOUBLE));
@@ -857,10 +857,10 @@ public class TestFieldCacheSort extends LuceneTestCase {
     Directory dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random(), dir);
     Document doc = new Document();
-    doc.add(new DoubleField("value", +0d, Field.Store.YES));
+    doc.add(new LegacyDoubleField("value", +0d, Field.Store.YES));
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new DoubleField("value", -0d, Field.Store.YES));
+    doc.add(new LegacyDoubleField("value", -0d, Field.Store.YES));
     writer.addDocument(doc);
     doc = new Document();
     IndexReader ir = UninvertingReader.wrap(writer.getReader(), 
@@ -892,13 +892,13 @@ public class TestFieldCacheSort extends LuceneTestCase {
     Document doc = new Document();
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new DoubleField("value", -1.3, Field.Store.YES));
+    doc.add(new LegacyDoubleField("value", -1.3, Field.Store.YES));
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new DoubleField("value", 4.2333333333333, Field.Store.YES));
+    doc.add(new LegacyDoubleField("value", 4.2333333333333, Field.Store.YES));
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new DoubleField("value", 4.2333333333332, Field.Store.YES));
+    doc.add(new LegacyDoubleField("value", 4.2333333333332, Field.Store.YES));
     writer.addDocument(doc);
     IndexReader ir = UninvertingReader.wrap(writer.getReader(), 
                      Collections.singletonMap("value", Type.DOUBLE));
@@ -926,13 +926,13 @@ public class TestFieldCacheSort extends LuceneTestCase {
     Document doc = new Document();
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new DoubleField("value", -1.3, Field.Store.YES));
+    doc.add(new LegacyDoubleField("value", -1.3, Field.Store.YES));
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new DoubleField("value", 4.2333333333333, Field.Store.YES));
+    doc.add(new LegacyDoubleField("value", 4.2333333333333, Field.Store.YES));
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new DoubleField("value", 4.2333333333332, Field.Store.YES));
+    doc.add(new LegacyDoubleField("value", 4.2333333333332, Field.Store.YES));
     writer.addDocument(doc);
     IndexReader ir = UninvertingReader.wrap(writer.getReader(), 
                      Collections.singletonMap("value", Type.DOUBLE));
@@ -960,16 +960,16 @@ public class TestFieldCacheSort extends LuceneTestCase {
     Directory dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random(), dir);
     Document doc = new Document();
-    doc.add(new DoubleField("value", 30.1, Field.Store.YES));
+    doc.add(new LegacyDoubleField("value", 30.1, Field.Store.YES));
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new DoubleField("value", -1.3, Field.Store.YES));
+    doc.add(new LegacyDoubleField("value", -1.3, Field.Store.YES));
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new DoubleField("value", 4.2333333333333, Field.Store.YES));
+    doc.add(new LegacyDoubleField("value", 4.2333333333333, Field.Store.YES));
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new DoubleField("value", 4.2333333333332, Field.Store.YES));
+    doc.add(new LegacyDoubleField("value", 4.2333333333332, Field.Store.YES));
     writer.addDocument(doc);
     IndexReader ir = UninvertingReader.wrap(writer.getReader(), 
                      Collections.singletonMap("value", Type.DOUBLE));
@@ -1050,7 +1050,7 @@ public class TestFieldCacheSort extends LuceneTestCase {
     for(int seg=0;seg<2;seg++) {
       for(int docIDX=0;docIDX<10;docIDX++) {
         Document doc = new Document();
-        doc.add(new IntField("id", docIDX, Field.Store.YES));
+        doc.add(new LegacyIntField("id", docIDX, Field.Store.YES));
         StringBuilder sb = new StringBuilder();
         for(int i=0;i<id;i++) {
           sb.append(' ');
diff --git a/lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheSortRandom.java b/lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheSortRandom.java
index 1c9b7d7..a6961c8 100644
--- a/lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheSortRandom.java
+++ b/lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheSortRandom.java
@@ -31,7 +31,7 @@ import java.util.Set;
 
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
-import org.apache.lucene.document.IntField;
+import org.apache.lucene.document.LegacyIntField;
 import org.apache.lucene.document.StringField;
 import org.apache.lucene.index.DocValues;
 import org.apache.lucene.index.IndexReader;
@@ -119,7 +119,7 @@ public class TestFieldCacheSortRandom extends LuceneTestCase {
         docValues.add(null);
       }
 
-      doc.add(new IntField("id", numDocs, Field.Store.YES));
+      doc.add(new LegacyIntField("id", numDocs, Field.Store.YES));
       writer.addDocument(doc);
       numDocs++;
 
diff --git a/lucene/misc/src/test/org/apache/lucene/uninverting/TestNumericTerms32.java b/lucene/misc/src/test/org/apache/lucene/uninverting/TestNumericTerms32.java
index 1cbaea1..0400f5f 100644
--- a/lucene/misc/src/test/org/apache/lucene/uninverting/TestNumericTerms32.java
+++ b/lucene/misc/src/test/org/apache/lucene/uninverting/TestNumericTerms32.java
@@ -23,11 +23,11 @@ import java.util.Map;
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.FieldType;
-import org.apache.lucene.document.IntField;
+import org.apache.lucene.document.LegacyIntField;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.NumericRangeQuery;
+import org.apache.lucene.search.LegacyNumericRangeQuery;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.Sort;
@@ -63,7 +63,7 @@ public class TestNumericTerms32 extends LuceneTestCase {
         .setMaxBufferedDocs(TestUtil.nextInt(random(), 100, 1000))
         .setMergePolicy(newLogMergePolicy()));
     
-    final FieldType storedInt = new FieldType(IntField.TYPE_NOT_STORED);
+    final FieldType storedInt = new FieldType(LegacyIntField.TYPE_NOT_STORED);
     storedInt.setStored(true);
     storedInt.freeze();
 
@@ -76,10 +76,10 @@ public class TestNumericTerms32 extends LuceneTestCase {
     final FieldType storedInt2 = new FieldType(storedInt);
     storedInt2.setNumericPrecisionStep(2);
 
-    IntField
-      field8 = new IntField("field8", 0, storedInt8),
-      field4 = new IntField("field4", 0, storedInt4),
-      field2 = new IntField("field2", 0, storedInt2);
+    LegacyIntField
+      field8 = new LegacyIntField("field8", 0, storedInt8),
+      field4 = new LegacyIntField("field4", 0, storedInt4),
+      field2 = new LegacyIntField("field2", 0, storedInt2);
     
     Document doc = new Document();
     // add fields, that have a distance to test general functionality
@@ -126,7 +126,7 @@ public class TestNumericTerms32 extends LuceneTestCase {
       if (lower>upper) {
         int a=lower; lower=upper; upper=a;
       }
-      Query tq=NumericRangeQuery.newIntRange(field, precisionStep, lower, upper, true, true);
+      Query tq= LegacyNumericRangeQuery.newIntRange(field, precisionStep, lower, upper, true, true);
       TopDocs topDocs = searcher.search(tq, noDocs, new Sort(new SortField(field, SortField.Type.INT, true)));
       if (topDocs.totalHits==0) continue;
       ScoreDoc[] sd = topDocs.scoreDocs;
diff --git a/lucene/misc/src/test/org/apache/lucene/uninverting/TestNumericTerms64.java b/lucene/misc/src/test/org/apache/lucene/uninverting/TestNumericTerms64.java
index db66c0e..abc8933 100644
--- a/lucene/misc/src/test/org/apache/lucene/uninverting/TestNumericTerms64.java
+++ b/lucene/misc/src/test/org/apache/lucene/uninverting/TestNumericTerms64.java
@@ -23,11 +23,11 @@ import java.util.Map;
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.FieldType;
-import org.apache.lucene.document.LongField;
+import org.apache.lucene.document.LegacyLongField;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.NumericRangeQuery;
+import org.apache.lucene.search.LegacyNumericRangeQuery;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.Sort;
@@ -63,7 +63,7 @@ public class TestNumericTerms64 extends LuceneTestCase {
         .setMaxBufferedDocs(TestUtil.nextInt(random(), 100, 1000))
         .setMergePolicy(newLogMergePolicy()));
 
-    final FieldType storedLong = new FieldType(LongField.TYPE_NOT_STORED);
+    final FieldType storedLong = new FieldType(LegacyLongField.TYPE_NOT_STORED);
     storedLong.setStored(true);
     storedLong.freeze();
 
@@ -79,11 +79,11 @@ public class TestNumericTerms64 extends LuceneTestCase {
     final FieldType storedLong2 = new FieldType(storedLong);
     storedLong2.setNumericPrecisionStep(2);
 
-    LongField
-      field8 = new LongField("field8", 0L, storedLong8),
-      field6 = new LongField("field6", 0L, storedLong6),
-      field4 = new LongField("field4", 0L, storedLong4),
-      field2 = new LongField("field2", 0L, storedLong2);
+    LegacyLongField
+      field8 = new LegacyLongField("field8", 0L, storedLong8),
+      field6 = new LegacyLongField("field6", 0L, storedLong6),
+      field4 = new LegacyLongField("field4", 0L, storedLong4),
+      field2 = new LegacyLongField("field2", 0L, storedLong2);
 
     Document doc = new Document();
     // add fields, that have a distance to test general functionality
@@ -131,7 +131,7 @@ public class TestNumericTerms64 extends LuceneTestCase {
       if (lower>upper) {
         long a=lower; lower=upper; upper=a;
       }
-      Query tq=NumericRangeQuery.newLongRange(field, precisionStep, lower, upper, true, true);
+      Query tq= LegacyNumericRangeQuery.newLongRange(field, precisionStep, lower, upper, true, true);
       TopDocs topDocs = searcher.search(tq, noDocs, new Sort(new SortField(field, SortField.Type.LONG, true)));
       if (topDocs.totalHits==0) continue;
       ScoreDoc[] sd = topDocs.scoreDocs;
diff --git a/lucene/misc/src/test/org/apache/lucene/uninverting/TestUninvertingReader.java b/lucene/misc/src/test/org/apache/lucene/uninverting/TestUninvertingReader.java
index 6300f18..ad0a58f 100644
--- a/lucene/misc/src/test/org/apache/lucene/uninverting/TestUninvertingReader.java
+++ b/lucene/misc/src/test/org/apache/lucene/uninverting/TestUninvertingReader.java
@@ -28,8 +28,8 @@ import java.util.Collections;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.FieldType;
-import org.apache.lucene.document.IntField;
-import org.apache.lucene.document.LongField;
+import org.apache.lucene.document.LegacyIntField;
+import org.apache.lucene.document.LegacyLongField;
 import org.apache.lucene.index.DocValues;
 import org.apache.lucene.index.LeafReader;
 import org.apache.lucene.index.LeafReaderContext;
@@ -41,7 +41,7 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.uninverting.UninvertingReader.Type;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util.NumericUtils;
+import org.apache.lucene.util.LegacyNumericUtils;
 import org.apache.lucene.util.TestUtil;
 
 public class TestUninvertingReader extends LuceneTestCase {
@@ -51,12 +51,12 @@ public class TestUninvertingReader extends LuceneTestCase {
     IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(null));
     
     Document doc = new Document();
-    doc.add(new IntField("foo", 5, Field.Store.NO));
+    doc.add(new LegacyIntField("foo", 5, Field.Store.NO));
     iw.addDocument(doc);
     
     doc = new Document();
-    doc.add(new IntField("foo", 5, Field.Store.NO));
-    doc.add(new IntField("foo", -3, Field.Store.NO));
+    doc.add(new LegacyIntField("foo", 5, Field.Store.NO));
+    doc.add(new LegacyIntField("foo", -3, Field.Store.NO));
     iw.addDocument(doc);
     
     iw.forceMerge(1);
@@ -78,10 +78,10 @@ public class TestUninvertingReader extends LuceneTestCase {
     assertEquals(SortedSetDocValues.NO_MORE_ORDS, v.nextOrd());
     
     BytesRef value = v.lookupOrd(0);
-    assertEquals(-3, NumericUtils.prefixCodedToInt(value));
+    assertEquals(-3, LegacyNumericUtils.prefixCodedToInt(value));
     
     value = v.lookupOrd(1);
-    assertEquals(5, NumericUtils.prefixCodedToInt(value));
+    assertEquals(5, LegacyNumericUtils.prefixCodedToInt(value));
     TestUtil.checkReader(ir);
     ir.close();
     dir.close();
@@ -92,12 +92,12 @@ public class TestUninvertingReader extends LuceneTestCase {
     IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(null));
     
     Document doc = new Document();
-    doc.add(new IntField("foo", Float.floatToRawIntBits(5f), Field.Store.NO));
+    doc.add(new LegacyIntField("foo", Float.floatToRawIntBits(5f), Field.Store.NO));
     iw.addDocument(doc);
     
     doc = new Document();
-    doc.add(new IntField("foo", Float.floatToRawIntBits(5f), Field.Store.NO));
-    doc.add(new IntField("foo", Float.floatToRawIntBits(-3f), Field.Store.NO));
+    doc.add(new LegacyIntField("foo", Float.floatToRawIntBits(5f), Field.Store.NO));
+    doc.add(new LegacyIntField("foo", Float.floatToRawIntBits(-3f), Field.Store.NO));
     iw.addDocument(doc);
     
     iw.forceMerge(1);
@@ -120,10 +120,10 @@ public class TestUninvertingReader extends LuceneTestCase {
     assertEquals(SortedSetDocValues.NO_MORE_ORDS, v.nextOrd());
     
     BytesRef value = v.lookupOrd(0);
-    assertEquals(Float.floatToRawIntBits(-3f), NumericUtils.prefixCodedToInt(value));
+    assertEquals(Float.floatToRawIntBits(-3f), LegacyNumericUtils.prefixCodedToInt(value));
     
     value = v.lookupOrd(1);
-    assertEquals(Float.floatToRawIntBits(5f), NumericUtils.prefixCodedToInt(value));
+    assertEquals(Float.floatToRawIntBits(5f), LegacyNumericUtils.prefixCodedToInt(value));
     TestUtil.checkReader(ir);
     ir.close();
     dir.close();
@@ -134,12 +134,12 @@ public class TestUninvertingReader extends LuceneTestCase {
     IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(null));
     
     Document doc = new Document();
-    doc.add(new LongField("foo", 5, Field.Store.NO));
+    doc.add(new LegacyLongField("foo", 5, Field.Store.NO));
     iw.addDocument(doc);
     
     doc = new Document();
-    doc.add(new LongField("foo", 5, Field.Store.NO));
-    doc.add(new LongField("foo", -3, Field.Store.NO));
+    doc.add(new LegacyLongField("foo", 5, Field.Store.NO));
+    doc.add(new LegacyLongField("foo", -3, Field.Store.NO));
     iw.addDocument(doc);
     
     iw.forceMerge(1);
@@ -161,10 +161,10 @@ public class TestUninvertingReader extends LuceneTestCase {
     assertEquals(SortedSetDocValues.NO_MORE_ORDS, v.nextOrd());
     
     BytesRef value = v.lookupOrd(0);
-    assertEquals(-3, NumericUtils.prefixCodedToLong(value));
+    assertEquals(-3, LegacyNumericUtils.prefixCodedToLong(value));
     
     value = v.lookupOrd(1);
-    assertEquals(5, NumericUtils.prefixCodedToLong(value));
+    assertEquals(5, LegacyNumericUtils.prefixCodedToLong(value));
     TestUtil.checkReader(ir);
     ir.close();
     dir.close();
@@ -175,12 +175,12 @@ public class TestUninvertingReader extends LuceneTestCase {
     IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(null));
     
     Document doc = new Document();
-    doc.add(new LongField("foo", Double.doubleToRawLongBits(5d), Field.Store.NO));
+    doc.add(new LegacyLongField("foo", Double.doubleToRawLongBits(5d), Field.Store.NO));
     iw.addDocument(doc);
     
     doc = new Document();
-    doc.add(new LongField("foo", Double.doubleToRawLongBits(5d), Field.Store.NO));
-    doc.add(new LongField("foo", Double.doubleToRawLongBits(-3d), Field.Store.NO));
+    doc.add(new LegacyLongField("foo", Double.doubleToRawLongBits(5d), Field.Store.NO));
+    doc.add(new LegacyLongField("foo", Double.doubleToRawLongBits(-3d), Field.Store.NO));
     iw.addDocument(doc);
     
     iw.forceMerge(1);
@@ -202,10 +202,10 @@ public class TestUninvertingReader extends LuceneTestCase {
     assertEquals(SortedSetDocValues.NO_MORE_ORDS, v.nextOrd());
     
     BytesRef value = v.lookupOrd(0);
-    assertEquals(Double.doubleToRawLongBits(-3d), NumericUtils.prefixCodedToLong(value));
+    assertEquals(Double.doubleToRawLongBits(-3d), LegacyNumericUtils.prefixCodedToLong(value));
     
     value = v.lookupOrd(1);
-    assertEquals(Double.doubleToRawLongBits(5d), NumericUtils.prefixCodedToLong(value));
+    assertEquals(Double.doubleToRawLongBits(5d), LegacyNumericUtils.prefixCodedToLong(value));
     TestUtil.checkReader(ir);
     ir.close();
     dir.close();
@@ -217,7 +217,7 @@ public class TestUninvertingReader extends LuceneTestCase {
     final Directory dir = newDirectory();
     final IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(null));
     
-    final FieldType NO_TRIE_TYPE = new FieldType(IntField.TYPE_NOT_STORED);
+    final FieldType NO_TRIE_TYPE = new FieldType(LegacyIntField.TYPE_NOT_STORED);
     NO_TRIE_TYPE.setNumericPrecisionStep(Integer.MAX_VALUE);
 
     final Map<String,Type> UNINVERT_MAP = new LinkedHashMap<String,Type>();
@@ -238,8 +238,8 @@ public class TestUninvertingReader extends LuceneTestCase {
     { // (at least) one doc should have every value, so that at least one segment has every value
       final Document doc = new Document();
       for (int i = MIN; i <= MAX; i++) {
-        doc.add(new IntField("trie_multi", i, Field.Store.NO));
-        doc.add(new IntField("notrie_multi", i, NO_TRIE_TYPE));
+        doc.add(new LegacyIntField("trie_multi", i, Field.Store.NO));
+        doc.add(new LegacyIntField("notrie_multi", i, NO_TRIE_TYPE));
       }
       iw.addDocument(doc);
     }
@@ -249,15 +249,15 @@ public class TestUninvertingReader extends LuceneTestCase {
       final Document doc = new Document();
       if (0 != TestUtil.nextInt(random(), 0, 9)) {
         int val = TestUtil.nextInt(random(), MIN, MAX);
-        doc.add(new IntField("trie_single", val, Field.Store.NO));
-        doc.add(new IntField("notrie_single", val, NO_TRIE_TYPE));
+        doc.add(new LegacyIntField("trie_single", val, Field.Store.NO));
+        doc.add(new LegacyIntField("notrie_single", val, NO_TRIE_TYPE));
       }
       if (0 != TestUtil.nextInt(random(), 0, 9)) {
         int numMulti = atLeast(1);
         while (0 < numMulti--) {
           int val = TestUtil.nextInt(random(), MIN, MAX);
-          doc.add(new IntField("trie_multi", val, Field.Store.NO));
-          doc.add(new IntField("notrie_multi", val, NO_TRIE_TYPE));
+          doc.add(new LegacyIntField("trie_multi", val, Field.Store.NO));
+          doc.add(new LegacyIntField("notrie_multi", val, NO_TRIE_TYPE));
         }
       }
       iw.addDocument(doc);
diff --git a/lucene/queries/src/test/org/apache/lucene/queries/function/FunctionTestSetup.java b/lucene/queries/src/test/org/apache/lucene/queries/function/FunctionTestSetup.java
index b71784c..cf3fa1a 100644
--- a/lucene/queries/src/test/org/apache/lucene/queries/function/FunctionTestSetup.java
+++ b/lucene/queries/src/test/org/apache/lucene/queries/function/FunctionTestSetup.java
@@ -5,8 +5,8 @@ import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.FieldType;
-import org.apache.lucene.document.FloatField;
-import org.apache.lucene.document.IntField;
+import org.apache.lucene.document.LegacyFloatField;
+import org.apache.lucene.document.LegacyIntField;
 import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.document.SortedDocValuesField;
 import org.apache.lucene.document.TextField;
@@ -143,11 +143,11 @@ public abstract class FunctionTestSetup extends LuceneTestCase {
     f = newField(TEXT_FIELD, "text of doc" + scoreAndID + textLine(i), customType2); // for regular search
     d.add(f);
 
-    f = new IntField(INT_FIELD, scoreAndID, Store.YES); // for function scoring
+    f = new LegacyIntField(INT_FIELD, scoreAndID, Store.YES); // for function scoring
     d.add(f);
     d.add(new NumericDocValuesField(INT_FIELD, scoreAndID));
 
-    f = new FloatField(FLOAT_FIELD, scoreAndID, Store.YES); // for function scoring
+    f = new LegacyFloatField(FLOAT_FIELD, scoreAndID, Store.YES); // for function scoring
     d.add(f);
     d.add(new NumericDocValuesField(FLOAT_FIELD, Float.floatToRawIntBits(scoreAndID)));
 
diff --git a/lucene/queries/src/test/org/apache/lucene/queries/function/TestFunctionQuerySort.java b/lucene/queries/src/test/org/apache/lucene/queries/function/TestFunctionQuerySort.java
index bfa3aa0..9297733 100644
--- a/lucene/queries/src/test/org/apache/lucene/queries/function/TestFunctionQuerySort.java
+++ b/lucene/queries/src/test/org/apache/lucene/queries/function/TestFunctionQuerySort.java
@@ -21,7 +21,7 @@ import java.io.IOException;
 
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
-import org.apache.lucene.document.IntField;
+import org.apache.lucene.document.LegacyIntField;
 import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexWriterConfig;
@@ -103,7 +103,7 @@ public class TestFunctionQuerySort extends LuceneTestCase {
     RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);
 
     Document doc = new Document();
-    Field field = new IntField("value", 0, Field.Store.YES);
+    Field field = new LegacyIntField("value", 0, Field.Store.YES);
     Field dvField = new NumericDocValuesField("value", 0);
     doc.add(field);
     doc.add(dvField);
diff --git a/lucene/queries/src/test/org/apache/lucene/queries/function/TestValueSources.java b/lucene/queries/src/test/org/apache/lucene/queries/function/TestValueSources.java
index c689f57..1b00fd3 100644
--- a/lucene/queries/src/test/org/apache/lucene/queries/function/TestValueSources.java
+++ b/lucene/queries/src/test/org/apache/lucene/queries/function/TestValueSources.java
@@ -25,11 +25,11 @@ import java.io.IOException;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
-import org.apache.lucene.document.DoubleField;
+import org.apache.lucene.document.LegacyDoubleField;
 import org.apache.lucene.document.Field;
-import org.apache.lucene.document.FloatField;
-import org.apache.lucene.document.IntField;
-import org.apache.lucene.document.LongField;
+import org.apache.lucene.document.LegacyFloatField;
+import org.apache.lucene.document.LegacyIntField;
+import org.apache.lucene.document.LegacyLongField;
 import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.document.SortedDocValuesField;
 import org.apache.lucene.document.StringField;
@@ -121,19 +121,19 @@ public class TestValueSources extends LuceneTestCase {
     document.add(idField);
     Field idDVField = new SortedDocValuesField("id", new BytesRef());
     document.add(idDVField);
-    Field doubleField = new DoubleField("double", 0d, Field.Store.NO);
+    Field doubleField = new LegacyDoubleField("double", 0d, Field.Store.NO);
     document.add(doubleField);
     Field doubleDVField = new NumericDocValuesField("double", 0);
     document.add(doubleDVField);
-    Field floatField = new FloatField("float", 0f, Field.Store.NO);
+    Field floatField = new LegacyFloatField("float", 0f, Field.Store.NO);
     document.add(floatField);
     Field floatDVField = new NumericDocValuesField("float", 0);
     document.add(floatDVField);
-    Field intField = new IntField("int", 0, Field.Store.NO);
+    Field intField = new LegacyIntField("int", 0, Field.Store.NO);
     document.add(intField);
     Field intDVField = new NumericDocValuesField("int", 0);
     document.add(intDVField);
-    Field longField = new LongField("long", 0L, Field.Store.NO);
+    Field longField = new LegacyLongField("long", 0L, Field.Store.NO);
     document.add(longField);
     Field longDVField = new NumericDocValuesField("long", 0);
     document.add(longDVField);
diff --git a/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/builders/NumericRangeQueryNodeBuilder.java b/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/builders/NumericRangeQueryNodeBuilder.java
index 7452679..b0805fe 100644
--- a/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/builders/NumericRangeQueryNodeBuilder.java
+++ b/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/builders/NumericRangeQueryNodeBuilder.java
@@ -17,7 +17,7 @@ package org.apache.lucene.queryparser.flexible.standard.builders;
  * limitations under the License.
  */
 
-import org.apache.lucene.document.FieldType.NumericType;
+import org.apache.lucene.document.FieldType;
 import org.apache.lucene.queryparser.flexible.core.QueryNodeException;
 import org.apache.lucene.queryparser.flexible.core.messages.QueryParserMessages;
 import org.apache.lucene.queryparser.flexible.core.nodes.QueryNode;
@@ -26,12 +26,12 @@ import org.apache.lucene.queryparser.flexible.messages.MessageImpl;
 import org.apache.lucene.queryparser.flexible.standard.config.NumericConfig;
 import org.apache.lucene.queryparser.flexible.standard.nodes.NumericQueryNode;
 import org.apache.lucene.queryparser.flexible.standard.nodes.NumericRangeQueryNode;
-import org.apache.lucene.search.NumericRangeQuery;
+import org.apache.lucene.search.LegacyNumericRangeQuery;
 
 /**
- * Builds {@link NumericRangeQuery}s out of {@link NumericRangeQueryNode}s.
+ * Builds {@link org.apache.lucene.search.LegacyNumericRangeQuery}s out of {@link NumericRangeQueryNode}s.
  *
- * @see NumericRangeQuery
+ * @see org.apache.lucene.search.LegacyNumericRangeQuery
  * @see NumericRangeQueryNode
  */
 public class NumericRangeQueryNodeBuilder implements StandardQueryBuilder {
@@ -44,7 +44,7 @@ public class NumericRangeQueryNodeBuilder implements StandardQueryBuilder {
   }
   
   @Override
-  public NumericRangeQuery<? extends Number> build(QueryNode queryNode)
+  public LegacyNumericRangeQuery<? extends Number> build(QueryNode queryNode)
       throws QueryNodeException {
     NumericRangeQueryNode numericRangeNode = (NumericRangeQueryNode) queryNode;
     
@@ -55,7 +55,7 @@ public class NumericRangeQueryNodeBuilder implements StandardQueryBuilder {
     Number upperNumber = upperNumericNode.getValue();
     
     NumericConfig numericConfig = numericRangeNode.getNumericConfig();
-    NumericType numberType = numericConfig.getType();
+    FieldType.LegacyNumericType numberType = numericConfig.getType();
     String field = StringUtils.toString(numericRangeNode.getField());
     boolean minInclusive = numericRangeNode.isLowerInclusive();
     boolean maxInclusive = numericRangeNode.isUpperInclusive();
@@ -64,21 +64,21 @@ public class NumericRangeQueryNodeBuilder implements StandardQueryBuilder {
     switch (numberType) {
       
       case LONG:
-        return NumericRangeQuery.newLongRange(field, precisionStep,
+        return LegacyNumericRangeQuery.newLongRange(field, precisionStep,
             (Long) lowerNumber, (Long) upperNumber, minInclusive, maxInclusive);
       
       case INT:
-        return NumericRangeQuery.newIntRange(field, precisionStep,
+        return LegacyNumericRangeQuery.newIntRange(field, precisionStep,
             (Integer) lowerNumber, (Integer) upperNumber, minInclusive,
             maxInclusive);
       
       case FLOAT:
-        return NumericRangeQuery.newFloatRange(field, precisionStep,
+        return LegacyNumericRangeQuery.newFloatRange(field, precisionStep,
             (Float) lowerNumber, (Float) upperNumber, minInclusive,
             maxInclusive);
       
       case DOUBLE:
-        return NumericRangeQuery.newDoubleRange(field, precisionStep,
+        return LegacyNumericRangeQuery.newDoubleRange(field, precisionStep,
             (Double) lowerNumber, (Double) upperNumber, minInclusive,
             maxInclusive);
         
diff --git a/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/config/NumericConfig.java b/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/config/NumericConfig.java
index a3160a0..39f2f6c 100644
--- a/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/config/NumericConfig.java
+++ b/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/config/NumericConfig.java
@@ -20,14 +20,14 @@ package org.apache.lucene.queryparser.flexible.standard.config;
 import java.text.NumberFormat;
 import java.util.Objects;
 
-import org.apache.lucene.document.FieldType.NumericType;
-import org.apache.lucene.search.NumericRangeQuery;
+import org.apache.lucene.document.FieldType;
+import org.apache.lucene.document.FieldType.LegacyNumericType;
 
 /**
  * This class holds the configuration used to parse numeric queries and create
- * {@link NumericRangeQuery}s.
+ * {@link org.apache.lucene.search.LegacyNumericRangeQuery}s.
  * 
- * @see NumericRangeQuery
+ * @see org.apache.lucene.search.LegacyNumericRangeQuery
  * @see NumberFormat
  */
 public class NumericConfig {
@@ -36,7 +36,7 @@ public class NumericConfig {
   
   private NumberFormat format;
   
-  private NumericType type;
+  private FieldType.LegacyNumericType type;
   
   /**
    * Constructs a {@link NumericConfig} object.
@@ -51,10 +51,10 @@ public class NumericConfig {
    * 
    * @see NumericConfig#setPrecisionStep(int)
    * @see NumericConfig#setNumberFormat(NumberFormat)
-   * @see #setType(org.apache.lucene.document.FieldType.NumericType)
+   * @see #setType(org.apache.lucene.document.FieldType.LegacyNumericType)
    */
   public NumericConfig(int precisionStep, NumberFormat format,
-      NumericType type) {
+      LegacyNumericType type) {
     setPrecisionStep(precisionStep);
     setNumberFormat(format);
     setType(type);
@@ -66,7 +66,7 @@ public class NumericConfig {
    * 
    * @return the precision used to index the numeric values
    * 
-   * @see NumericRangeQuery#getPrecisionStep()
+   * @see org.apache.lucene.search.LegacyNumericRangeQuery#getPrecisionStep()
    */
   public int getPrecisionStep() {
     return precisionStep;
@@ -78,7 +78,7 @@ public class NumericConfig {
    * @param precisionStep
    *          the precision used to index the numeric values
    * 
-   * @see NumericRangeQuery#getPrecisionStep()
+   * @see org.apache.lucene.search.LegacyNumericRangeQuery#getPrecisionStep()
    */
   public void setPrecisionStep(int precisionStep) {
     this.precisionStep = precisionStep;
@@ -100,7 +100,7 @@ public class NumericConfig {
    * 
    * @return the numeric type used to index the numeric values
    */
-  public NumericType getType() {
+  public LegacyNumericType getType() {
     return type;
   }
   
@@ -109,7 +109,7 @@ public class NumericConfig {
    * 
    * @param type the numeric type used to index the numeric values
    */
-  public void setType(NumericType type) {
+  public void setType(LegacyNumericType type) {
     
     if (type == null) {
       throw new IllegalArgumentException("type cannot be null!");
diff --git a/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/nodes/NumericRangeQueryNode.java b/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/nodes/NumericRangeQueryNode.java
index ee154aa..cf86f8a 100644
--- a/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/nodes/NumericRangeQueryNode.java
+++ b/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/nodes/NumericRangeQueryNode.java
@@ -17,10 +17,10 @@ package org.apache.lucene.queryparser.flexible.standard.nodes;
  * the License.
  */
 
-import org.apache.lucene.document.FieldType.NumericType;
+import org.apache.lucene.document.FieldType;
+import org.apache.lucene.document.FieldType.LegacyNumericType;
 import org.apache.lucene.queryparser.flexible.core.QueryNodeException;
 import org.apache.lucene.queryparser.flexible.core.messages.QueryParserMessages;
-import org.apache.lucene.queryparser.flexible.core.nodes.FieldQueryNode;
 import org.apache.lucene.queryparser.flexible.messages.MessageImpl;
 import org.apache.lucene.queryparser.flexible.standard.config.NumericConfig;
 
@@ -53,16 +53,16 @@ public class NumericRangeQueryNode extends
     setBounds(lower, upper, lowerInclusive, upperInclusive, numericConfig);
   }
   
-  private static NumericType getNumericDataType(Number number) throws QueryNodeException {
+  private static LegacyNumericType getNumericDataType(Number number) throws QueryNodeException {
     
     if (number instanceof Long) {
-      return NumericType.LONG;
+      return FieldType.LegacyNumericType.LONG;
     } else if (number instanceof Integer) {
-      return NumericType.INT;
+      return FieldType.LegacyNumericType.INT;
     } else if (number instanceof Double) {
-      return NumericType.DOUBLE;
+      return LegacyNumericType.DOUBLE;
     } else if (number instanceof Float) {
-      return NumericType.FLOAT;
+      return FieldType.LegacyNumericType.FLOAT;
     } else {
       throw new QueryNodeException(
           new MessageImpl(
@@ -90,7 +90,7 @@ public class NumericRangeQueryNode extends
       throw new IllegalArgumentException("numericConfig cannot be null!");
     }
     
-    NumericType lowerNumberType, upperNumberType;
+    LegacyNumericType lowerNumberType, upperNumberType;
     
     if (lower != null && lower.getValue() != null) {
       lowerNumberType = getNumericDataType(lower.getValue());
diff --git a/lucene/queryparser/src/java/org/apache/lucene/queryparser/xml/CoreParser.java b/lucene/queryparser/src/java/org/apache/lucene/queryparser/xml/CoreParser.java
index ae48f5d..3710f96 100644
--- a/lucene/queryparser/src/java/org/apache/lucene/queryparser/xml/CoreParser.java
+++ b/lucene/queryparser/src/java/org/apache/lucene/queryparser/xml/CoreParser.java
@@ -67,7 +67,7 @@ public class CoreParser implements QueryBuilder {
     queryFactory.addBuilder("TermsQuery", new TermsQueryBuilder(analyzer));
     queryFactory.addBuilder("MatchAllDocsQuery", new MatchAllDocsQueryBuilder());
     queryFactory.addBuilder("BooleanQuery", new BooleanQueryBuilder(queryFactory));
-    queryFactory.addBuilder("NumericRangeQuery", new NumericRangeQueryBuilder());
+    queryFactory.addBuilder("LegacyNumericRangeQuery", new LegacyNumericRangeQueryBuilder());
     queryFactory.addBuilder("RangeQuery", new RangeQueryBuilder());
     queryFactory.addBuilder("DisjunctionMaxQuery", new DisjunctionMaxQueryBuilder(queryFactory));
     if (parser != null) {
diff --git a/lucene/queryparser/src/java/org/apache/lucene/queryparser/xml/builders/LegacyNumericRangeQueryBuilder.java b/lucene/queryparser/src/java/org/apache/lucene/queryparser/xml/builders/LegacyNumericRangeQueryBuilder.java
new file mode 100644
index 0000000..8a02916
--- /dev/null
+++ b/lucene/queryparser/src/java/org/apache/lucene/queryparser/xml/builders/LegacyNumericRangeQueryBuilder.java
@@ -0,0 +1,126 @@
+package org.apache.lucene.queryparser.xml.builders;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.search.LegacyNumericRangeQuery;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.util.LegacyNumericUtils;
+import org.apache.lucene.queryparser.xml.DOMUtils;
+import org.apache.lucene.queryparser.xml.ParserException;
+import org.apache.lucene.queryparser.xml.QueryBuilder;
+import org.w3c.dom.Element;
+
+/**
+ * Creates a {@link org.apache.lucene.search.LegacyNumericRangeQuery}. The table below specifies the required
+ * attributes and the defaults if optional attributes are omitted. For more
+ * detail on what each of the attributes actually do, consult the documentation
+ * for {@link org.apache.lucene.search.LegacyNumericRangeQuery}:
+ * <table summary="supported attributes">
+ * <tr>
+ * <th>Attribute name</th>
+ * <th>Values</th>
+ * <th>Required</th>
+ * <th>Default</th>
+ * </tr>
+ * <tr>
+ * <td>fieldName</td>
+ * <td>String</td>
+ * <td>Yes</td>
+ * <td>N/A</td>
+ * </tr>
+ * <tr>
+ * <td>lowerTerm</td>
+ * <td>Specified by <tt>type</tt></td>
+ * <td>Yes</td>
+ * <td>N/A</td>
+ * </tr>
+ * <tr>
+ * <td>upperTerm</td>
+ * <td>Specified by <tt>type</tt></td>
+ * <td>Yes</td>
+ * <td>N/A</td>
+ * </tr>
+ * <tr>
+ * <td>type</td>
+ * <td>int, long, float, double</td>
+ * <td>No</td>
+ * <td>int</td>
+ * </tr>
+ * <tr>
+ * <td>includeLower</td>
+ * <td>true, false</td>
+ * <td>No</td>
+ * <td>true</td>
+ * </tr>
+ * <tr>
+ * <td>includeUpper</td>
+ * <td>true, false</td>
+ * <td>No</td>
+ * <td>true</td>
+ * </tr>
+ * <tr>
+ * <td>precisionStep</td>
+ * <td>Integer</td>
+ * <td>No</td>
+ * <td>4</td>
+ * </tr>
+ * </table>
+ * <p>
+ * A {@link ParserException} will be thrown if an error occurs parsing the
+ * supplied <tt>lowerTerm</tt> or <tt>upperTerm</tt> into the numeric type
+ * specified by <tt>type</tt>.
+ */
+public class LegacyNumericRangeQueryBuilder implements QueryBuilder {
+
+  @Override
+  public Query getQuery(Element e) throws ParserException {
+    String field = DOMUtils.getAttributeWithInheritanceOrFail(e, "fieldName");
+    String lowerTerm = DOMUtils.getAttributeOrFail(e, "lowerTerm");
+    String upperTerm = DOMUtils.getAttributeOrFail(e, "upperTerm");
+    boolean lowerInclusive = DOMUtils.getAttribute(e, "includeLower", true);
+    boolean upperInclusive = DOMUtils.getAttribute(e, "includeUpper", true);
+    int precisionStep = DOMUtils.getAttribute(e, "precisionStep", LegacyNumericUtils.PRECISION_STEP_DEFAULT);
+
+    String type = DOMUtils.getAttribute(e, "type", "int");
+    try {
+      Query filter;
+      if (type.equalsIgnoreCase("int")) {
+        filter = LegacyNumericRangeQuery.newIntRange(field, precisionStep, Integer
+                .valueOf(lowerTerm), Integer.valueOf(upperTerm), lowerInclusive,
+            upperInclusive);
+      } else if (type.equalsIgnoreCase("long")) {
+        filter = LegacyNumericRangeQuery.newLongRange(field, precisionStep, Long
+                .valueOf(lowerTerm), Long.valueOf(upperTerm), lowerInclusive,
+            upperInclusive);
+      } else if (type.equalsIgnoreCase("double")) {
+        filter = LegacyNumericRangeQuery.newDoubleRange(field, precisionStep, Double
+                .valueOf(lowerTerm), Double.valueOf(upperTerm), lowerInclusive,
+            upperInclusive);
+      } else if (type.equalsIgnoreCase("float")) {
+        filter = LegacyNumericRangeQuery.newFloatRange(field, precisionStep, Float
+                .valueOf(lowerTerm), Float.valueOf(upperTerm), lowerInclusive,
+            upperInclusive);
+      } else {
+        throw new ParserException("type attribute must be one of: [long, int, double, float]");
+      }
+      return filter;
+    } catch (NumberFormatException nfe) {
+      throw new ParserException("Could not parse lowerTerm or upperTerm into a number", nfe);
+    }
+  }
+}
diff --git a/lucene/queryparser/src/java/org/apache/lucene/queryparser/xml/builders/NumericRangeQueryBuilder.java b/lucene/queryparser/src/java/org/apache/lucene/queryparser/xml/builders/NumericRangeQueryBuilder.java
deleted file mode 100644
index b40a6c1..0000000
--- a/lucene/queryparser/src/java/org/apache/lucene/queryparser/xml/builders/NumericRangeQueryBuilder.java
+++ /dev/null
@@ -1,126 +0,0 @@
-package org.apache.lucene.queryparser.xml.builders;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.search.NumericRangeQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.util.NumericUtils;
-import org.apache.lucene.queryparser.xml.DOMUtils;
-import org.apache.lucene.queryparser.xml.ParserException;
-import org.apache.lucene.queryparser.xml.QueryBuilder;
-import org.w3c.dom.Element;
-
-/**
- * Creates a {@link NumericRangeQuery}. The table below specifies the required
- * attributes and the defaults if optional attributes are omitted. For more
- * detail on what each of the attributes actually do, consult the documentation
- * for {@link NumericRangeQuery}:
- * <table summary="supported attributes">
- * <tr>
- * <th>Attribute name</th>
- * <th>Values</th>
- * <th>Required</th>
- * <th>Default</th>
- * </tr>
- * <tr>
- * <td>fieldName</td>
- * <td>String</td>
- * <td>Yes</td>
- * <td>N/A</td>
- * </tr>
- * <tr>
- * <td>lowerTerm</td>
- * <td>Specified by <tt>type</tt></td>
- * <td>Yes</td>
- * <td>N/A</td>
- * </tr>
- * <tr>
- * <td>upperTerm</td>
- * <td>Specified by <tt>type</tt></td>
- * <td>Yes</td>
- * <td>N/A</td>
- * </tr>
- * <tr>
- * <td>type</td>
- * <td>int, long, float, double</td>
- * <td>No</td>
- * <td>int</td>
- * </tr>
- * <tr>
- * <td>includeLower</td>
- * <td>true, false</td>
- * <td>No</td>
- * <td>true</td>
- * </tr>
- * <tr>
- * <td>includeUpper</td>
- * <td>true, false</td>
- * <td>No</td>
- * <td>true</td>
- * </tr>
- * <tr>
- * <td>precisionStep</td>
- * <td>Integer</td>
- * <td>No</td>
- * <td>4</td>
- * </tr>
- * </table>
- * <p>
- * A {@link ParserException} will be thrown if an error occurs parsing the
- * supplied <tt>lowerTerm</tt> or <tt>upperTerm</tt> into the numeric type
- * specified by <tt>type</tt>.
- */
-public class NumericRangeQueryBuilder implements QueryBuilder {
-
-  @Override
-  public Query getQuery(Element e) throws ParserException {
-    String field = DOMUtils.getAttributeWithInheritanceOrFail(e, "fieldName");
-    String lowerTerm = DOMUtils.getAttributeOrFail(e, "lowerTerm");
-    String upperTerm = DOMUtils.getAttributeOrFail(e, "upperTerm");
-    boolean lowerInclusive = DOMUtils.getAttribute(e, "includeLower", true);
-    boolean upperInclusive = DOMUtils.getAttribute(e, "includeUpper", true);
-    int precisionStep = DOMUtils.getAttribute(e, "precisionStep", NumericUtils.PRECISION_STEP_DEFAULT);
-
-    String type = DOMUtils.getAttribute(e, "type", "int");
-    try {
-      Query filter;
-      if (type.equalsIgnoreCase("int")) {
-        filter = NumericRangeQuery.newIntRange(field, precisionStep, Integer
-            .valueOf(lowerTerm), Integer.valueOf(upperTerm), lowerInclusive,
-            upperInclusive);
-      } else if (type.equalsIgnoreCase("long")) {
-        filter = NumericRangeQuery.newLongRange(field, precisionStep, Long
-            .valueOf(lowerTerm), Long.valueOf(upperTerm), lowerInclusive,
-            upperInclusive);
-      } else if (type.equalsIgnoreCase("double")) {
-        filter = NumericRangeQuery.newDoubleRange(field, precisionStep, Double
-            .valueOf(lowerTerm), Double.valueOf(upperTerm), lowerInclusive,
-            upperInclusive);
-      } else if (type.equalsIgnoreCase("float")) {
-        filter = NumericRangeQuery.newFloatRange(field, precisionStep, Float
-            .valueOf(lowerTerm), Float.valueOf(upperTerm), lowerInclusive,
-            upperInclusive);
-      } else {
-        throw new ParserException("type attribute must be one of: [long, int, double, float]");
-      }
-      return filter;
-    } catch (NumberFormatException nfe) {
-      throw new ParserException("Could not parse lowerTerm or upperTerm into a number", nfe);
-    }
-  }
-}
diff --git a/lucene/queryparser/src/resources/org/apache/lucene/queryparser/xml/LuceneCoreQuery.dtd b/lucene/queryparser/src/resources/org/apache/lucene/queryparser/xml/LuceneCoreQuery.dtd
index 8727c5d..48f94ae 100644
--- a/lucene/queryparser/src/resources/org/apache/lucene/queryparser/xml/LuceneCoreQuery.dtd
+++ b/lucene/queryparser/src/resources/org/apache/lucene/queryparser/xml/LuceneCoreQuery.dtd
@@ -288,7 +288,7 @@ Passes content directly through to the standard LuceneQuery parser see "Lucene Q
 	@example 
 	        <em>Search for documents about people who are aged 20-25</em>
 	        %	          
-            <NumericRangeQuery fieldName="age" lowerTerm="20" upperTerm="25" />
+            <LegacyNumericRangeQuery fieldName="age" lowerTerm="20" upperTerm="25" />
 	         %
 	-->
 <!ELEMENT NumericRangeQuery EMPTY>
diff --git a/lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/standard/TestNumericQueryParser.java b/lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/standard/TestNumericQueryParser.java
index 138c30a..c1351b4 100644
--- a/lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/standard/TestNumericQueryParser.java
+++ b/lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/standard/TestNumericQueryParser.java
@@ -33,13 +33,13 @@ import java.util.TimeZone;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
-import org.apache.lucene.document.DoubleField;
+import org.apache.lucene.document.LegacyDoubleField;
 import org.apache.lucene.document.Field;
-import org.apache.lucene.document.FieldType.NumericType;
+import org.apache.lucene.document.FieldType.LegacyNumericType;
 import org.apache.lucene.document.FieldType;
-import org.apache.lucene.document.FloatField;
-import org.apache.lucene.document.IntField;
-import org.apache.lucene.document.LongField;
+import org.apache.lucene.document.LegacyFloatField;
+import org.apache.lucene.document.LegacyIntField;
+import org.apache.lucene.document.LegacyLongField;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.queryparser.flexible.core.QueryNodeException;
@@ -179,10 +179,10 @@ public class TestNumericQueryParser extends LuceneTestCase {
     while ((randomInt = normalizeNumber(Math.abs(random().nextInt())).intValue()) == 0)
       ;
     
-    randomNumberMap.put(NumericType.LONG.name(), randomLong);
-    randomNumberMap.put(NumericType.INT.name(), randomInt);
-    randomNumberMap.put(NumericType.FLOAT.name(), randomFloat);
-    randomNumberMap.put(NumericType.DOUBLE.name(), randomDouble);
+    randomNumberMap.put(LegacyNumericType.LONG.name(), randomLong);
+    randomNumberMap.put(FieldType.LegacyNumericType.INT.name(), randomInt);
+    randomNumberMap.put(LegacyNumericType.FLOAT.name(), randomFloat);
+    randomNumberMap.put(LegacyNumericType.DOUBLE.name(), randomDouble);
     randomNumberMap.put(DATE_FIELD_NAME, randomDate);
     
     RANDOM_NUMBER_MAP = Collections.unmodifiableMap(randomNumberMap);
@@ -198,11 +198,11 @@ public class TestNumericQueryParser extends LuceneTestCase {
     HashMap<String,Field> numericFieldMap = new HashMap<>();
     qp.setNumericConfigMap(numericConfigMap);
     
-    for (NumericType type : NumericType.values()) {
+    for (LegacyNumericType type : LegacyNumericType.values()) {
       numericConfigMap.put(type.name(), new NumericConfig(PRECISION_STEP,
           NUMBER_FORMAT, type));
 
-      FieldType ft = new FieldType(IntField.TYPE_NOT_STORED);
+      FieldType ft = new FieldType(LegacyIntField.TYPE_NOT_STORED);
       ft.setNumericType(type);
       ft.setStored(true);
       ft.setNumericPrecisionStep(PRECISION_STEP);
@@ -211,16 +211,16 @@ public class TestNumericQueryParser extends LuceneTestCase {
 
       switch(type) {
       case INT:
-        field = new IntField(type.name(), 0, ft);
+        field = new LegacyIntField(type.name(), 0, ft);
         break;
       case FLOAT:
-        field = new FloatField(type.name(), 0.0f, ft);
+        field = new LegacyFloatField(type.name(), 0.0f, ft);
         break;
       case LONG:
-        field = new LongField(type.name(), 0l, ft);
+        field = new LegacyLongField(type.name(), 0l, ft);
         break;
       case DOUBLE:
-        field = new DoubleField(type.name(), 0.0, ft);
+        field = new LegacyDoubleField(type.name(), 0.0, ft);
         break;
       default:
         fail();
@@ -231,11 +231,11 @@ public class TestNumericQueryParser extends LuceneTestCase {
     }
     
     numericConfigMap.put(DATE_FIELD_NAME, new NumericConfig(PRECISION_STEP,
-        DATE_FORMAT, NumericType.LONG));
-    FieldType ft = new FieldType(LongField.TYPE_NOT_STORED);
+        DATE_FORMAT, LegacyNumericType.LONG));
+    FieldType ft = new FieldType(LegacyLongField.TYPE_NOT_STORED);
     ft.setStored(true);
     ft.setNumericPrecisionStep(PRECISION_STEP);
-    LongField dateField = new LongField(DATE_FIELD_NAME, 0l, ft);
+    LegacyLongField dateField = new LegacyLongField(DATE_FIELD_NAME, 0l, ft);
     numericFieldMap.put(DATE_FIELD_NAME, dateField);
     doc.add(dateField);
     
@@ -265,17 +265,17 @@ public class TestNumericQueryParser extends LuceneTestCase {
       case NEGATIVE:
         Number number = RANDOM_NUMBER_MAP.get(fieldName);
         
-        if (NumericType.LONG.name().equals(fieldName)
+        if (LegacyNumericType.LONG.name().equals(fieldName)
             || DATE_FIELD_NAME.equals(fieldName)) {
           number = -number.longValue();
           
-        } else if (NumericType.DOUBLE.name().equals(fieldName)) {
+        } else if (FieldType.LegacyNumericType.DOUBLE.name().equals(fieldName)) {
           number = -number.doubleValue();
           
-        } else if (NumericType.FLOAT.name().equals(fieldName)) {
+        } else if (FieldType.LegacyNumericType.FLOAT.name().equals(fieldName)) {
           number = -number.floatValue();
           
-        } else if (NumericType.INT.name().equals(fieldName)) {
+        } else if (LegacyNumericType.INT.name().equals(fieldName)) {
           number = -number.intValue();
           
         } else {
@@ -295,21 +295,21 @@ public class TestNumericQueryParser extends LuceneTestCase {
   private static void setFieldValues(NumberType numberType,
       HashMap<String,Field> numericFieldMap) {
     
-    Number number = getNumberType(numberType, NumericType.DOUBLE
+    Number number = getNumberType(numberType, LegacyNumericType.DOUBLE
         .name());
-    numericFieldMap.get(NumericType.DOUBLE.name()).setDoubleValue(
+    numericFieldMap.get(LegacyNumericType.DOUBLE.name()).setDoubleValue(
         number.doubleValue());
     
-    number = getNumberType(numberType, NumericType.INT.name());
-    numericFieldMap.get(NumericType.INT.name()).setIntValue(
+    number = getNumberType(numberType, FieldType.LegacyNumericType.INT.name());
+    numericFieldMap.get(FieldType.LegacyNumericType.INT.name()).setIntValue(
         number.intValue());
     
-    number = getNumberType(numberType, NumericType.LONG.name());
-    numericFieldMap.get(NumericType.LONG.name()).setLongValue(
+    number = getNumberType(numberType, LegacyNumericType.LONG.name());
+    numericFieldMap.get(FieldType.LegacyNumericType.LONG.name()).setLongValue(
         number.longValue());
     
-    number = getNumberType(numberType, NumericType.FLOAT.name());
-    numericFieldMap.get(NumericType.FLOAT.name()).setFloatValue(
+    number = getNumberType(numberType, FieldType.LegacyNumericType.FLOAT.name());
+    numericFieldMap.get(FieldType.LegacyNumericType.FLOAT.name()).setFloatValue(
         number.floatValue());
     
     number = getNumberType(numberType, DATE_FIELD_NAME);
@@ -411,7 +411,7 @@ public class TestNumericQueryParser extends LuceneTestCase {
     String lowerInclusiveStr = (lowerInclusive ? "[" : "{");
     String upperInclusiveStr = (upperInclusive ? "]" : "}");
     
-    for (NumericType type : NumericType.values()) {
+    for (LegacyNumericType type : LegacyNumericType.values()) {
       String lowerStr = numberToString(getNumberType(lowerType, type.name()));
       String upperStr = numberToString(getNumberType(upperType, type.name()));
       
@@ -457,7 +457,7 @@ public class TestNumericQueryParser extends LuceneTestCase {
 
     StringBuilder sb = new StringBuilder();
     
-    for (NumericType type : NumericType.values()) {
+    for (LegacyNumericType type : FieldType.LegacyNumericType.values()) {
       String boundStr = numberToString(getNumberType(boundType, type.name()));
       
       sb.append("+").append(type.name()).append(operator).append('"').append(boundStr).append('"').append(' ');
@@ -476,7 +476,7 @@ public class TestNumericQueryParser extends LuceneTestCase {
       throws QueryNodeException, IOException {
     StringBuilder sb = new StringBuilder();
     
-    for (NumericType type : NumericType.values()) {
+    for (LegacyNumericType type : LegacyNumericType.values()) {
       String numberStr = numberToString(getNumberType(numberType, type.name()));
       sb.append('+').append(type.name()).append(":\"").append(numberStr)
           .append("\" ");
diff --git a/lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/LegacyNumericRangeQuery.xml b/lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/LegacyNumericRangeQuery.xml
new file mode 100644
index 0000000..f504842
--- /dev/null
+++ b/lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/LegacyNumericRangeQuery.xml
@@ -0,0 +1,31 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+<BooleanQuery fieldName="contents">
+  <Clause occurs="should">
+    <TermQuery>merger</TermQuery>
+  </Clause>
+  <Clause occurs="mustnot">
+    <TermQuery >sumitomo</TermQuery>    
+  </Clause>
+  <Clause occurs="must">
+    <TermQuery>bank</TermQuery>
+  </Clause>
+  <Clause occurs="must">
+    <LegacyNumericRangeQuery fieldName="date2" lowerTerm="19870409" upperTerm="19870412"/>
+  </Clause>
+</BooleanQuery>
diff --git a/lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/NumericRangeQuery.xml b/lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/NumericRangeQuery.xml
deleted file mode 100644
index 933ab1e..0000000
--- a/lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/NumericRangeQuery.xml
+++ /dev/null
@@ -1,31 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-<BooleanQuery fieldName="contents">
-  <Clause occurs="should">
-    <TermQuery>merger</TermQuery>
-  </Clause>
-  <Clause occurs="mustnot">
-    <TermQuery >sumitomo</TermQuery>    
-  </Clause>
-  <Clause occurs="must">
-    <TermQuery>bank</TermQuery>
-  </Clause>
-  <Clause occurs="must">
-    <NumericRangeQuery fieldName="date2" lowerTerm="19870409" upperTerm="19870412"/>
-  </Clause>
-</BooleanQuery>
diff --git a/lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/TestParser.java b/lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/TestParser.java
index f3f7599..0c3f822 100644
--- a/lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/TestParser.java
+++ b/lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/TestParser.java
@@ -23,8 +23,7 @@ import org.apache.lucene.analysis.MockTokenFilter;
 import org.apache.lucene.analysis.MockTokenizer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
-import org.apache.lucene.document.IntField;
-import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.document.LegacyIntField;
 import org.apache.lucene.index.DirectoryReader;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexWriter;
@@ -37,7 +36,6 @@ import org.apache.lucene.search.TopDocs;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
 import org.junit.AfterClass;
-import org.junit.Assume;
 import org.junit.BeforeClass;
 
 import java.io.BufferedReader;
@@ -45,7 +43,6 @@ import java.io.IOException;
 import java.io.InputStream;
 import java.io.InputStreamReader;
 import java.nio.charset.StandardCharsets;
-import java.util.List;
 
 
 public class TestParser extends LuceneTestCase {
@@ -75,7 +72,7 @@ public class TestParser extends LuceneTestCase {
       Document doc = new Document();
       doc.add(newTextField("date", date, Field.Store.YES));
       doc.add(newTextField("contents", content, Field.Store.YES));
-      doc.add(new IntField("date2", Integer.valueOf(date), Field.Store.NO));
+      doc.add(new LegacyIntField("date2", Integer.valueOf(date), Field.Store.NO));
       writer.addDocument(doc);
       line = d.readLine();
     }
@@ -184,8 +181,8 @@ public class TestParser extends LuceneTestCase {
   }
 
   public void testNumericRangeQueryXML() throws ParserException, IOException {
-    Query q = parse("NumericRangeQuery.xml");
-    dumpResults("NumericRangeQuery", q, 5);
+    Query q = parse("LegacyNumericRangeQuery.xml");
+    dumpResults("LegacyNumericRangeQuery", q, 5);
   }
 
   //================= Helper methods ===================================
diff --git a/lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/builders/TestNumericRangeQueryBuilder.java b/lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/builders/TestNumericRangeQueryBuilder.java
index 53a7f09..c3a2d1b 100644
--- a/lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/builders/TestNumericRangeQueryBuilder.java
+++ b/lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/builders/TestNumericRangeQueryBuilder.java
@@ -17,7 +17,7 @@ package org.apache.lucene.queryparser.xml.builders;
  * limitations under the License.
  */
 
-import org.apache.lucene.search.NumericRangeQuery;
+import org.apache.lucene.search.LegacyNumericRangeQuery;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.queryparser.xml.ParserException;
@@ -36,9 +36,9 @@ import java.nio.charset.StandardCharsets;
 public class TestNumericRangeQueryBuilder extends LuceneTestCase {
 
   public void testGetFilterHandleNumericParseErrorStrict() throws Exception {
-    NumericRangeQueryBuilder filterBuilder = new NumericRangeQueryBuilder();
+    LegacyNumericRangeQueryBuilder filterBuilder = new LegacyNumericRangeQueryBuilder();
 
-    String xml = "<NumericRangeQuery fieldName='AGE' type='int' lowerTerm='-1' upperTerm='NaN'/>";
+    String xml = "<LegacyNumericRangeQuery fieldName='AGE' type='int' lowerTerm='-1' upperTerm='NaN'/>";
     Document doc = getDocumentFromString(xml);
     try {
       filterBuilder.getQuery(doc.getDocumentElement());
@@ -50,26 +50,26 @@ public class TestNumericRangeQueryBuilder extends LuceneTestCase {
 
   @SuppressWarnings({"unchecked","rawtypes"})
   public void testGetFilterInt() throws Exception {
-    NumericRangeQueryBuilder filterBuilder = new NumericRangeQueryBuilder();
+    LegacyNumericRangeQueryBuilder filterBuilder = new LegacyNumericRangeQueryBuilder();
 
-    String xml = "<NumericRangeQuery fieldName='AGE' type='int' lowerTerm='-1' upperTerm='10'/>";
+    String xml = "<LegacyNumericRangeQuery fieldName='AGE' type='int' lowerTerm='-1' upperTerm='10'/>";
     Document doc = getDocumentFromString(xml);
     Query filter = filterBuilder.getQuery(doc.getDocumentElement());
-    assertTrue(filter instanceof NumericRangeQuery<?>);
+    assertTrue(filter instanceof LegacyNumericRangeQuery<?>);
 
-    NumericRangeQuery<Integer> numRangeFilter = (NumericRangeQuery<Integer>) filter;
+    LegacyNumericRangeQuery<Integer> numRangeFilter = (LegacyNumericRangeQuery<Integer>) filter;
     assertEquals(Integer.valueOf(-1), numRangeFilter.getMin());
     assertEquals(Integer.valueOf(10), numRangeFilter.getMax());
     assertEquals("AGE", numRangeFilter.getField());
     assertTrue(numRangeFilter.includesMin());
     assertTrue(numRangeFilter.includesMax());
 
-    String xml2 = "<NumericRangeQuery fieldName='AGE' type='int' lowerTerm='-1' upperTerm='10' includeUpper='false'/>";
+    String xml2 = "<LegacyNumericRangeQuery fieldName='AGE' type='int' lowerTerm='-1' upperTerm='10' includeUpper='false'/>";
     Document doc2 = getDocumentFromString(xml2);
     Query filter2 = filterBuilder.getQuery(doc2.getDocumentElement());
-    assertTrue(filter2 instanceof NumericRangeQuery<?>);
+    assertTrue(filter2 instanceof LegacyNumericRangeQuery<?>);
 
-    NumericRangeQuery<Integer> numRangeFilter2 = (NumericRangeQuery) filter2;
+    LegacyNumericRangeQuery<Integer> numRangeFilter2 = (LegacyNumericRangeQuery) filter2;
     assertEquals(Integer.valueOf(-1), numRangeFilter2.getMin());
     assertEquals(Integer.valueOf(10), numRangeFilter2.getMax());
     assertEquals("AGE", numRangeFilter2.getField());
@@ -79,25 +79,25 @@ public class TestNumericRangeQueryBuilder extends LuceneTestCase {
 
   @SuppressWarnings({"unchecked","rawtypes"})
   public void testGetFilterLong() throws Exception {
-    NumericRangeQueryBuilder filterBuilder = new NumericRangeQueryBuilder();
+    LegacyNumericRangeQueryBuilder filterBuilder = new LegacyNumericRangeQueryBuilder();
 
-    String xml = "<NumericRangeQuery fieldName='AGE' type='LoNg' lowerTerm='-2321' upperTerm='60000000'/>";
+    String xml = "<LegacyNumericRangeQuery fieldName='AGE' type='LoNg' lowerTerm='-2321' upperTerm='60000000'/>";
     Document doc = getDocumentFromString(xml);
     Query filter = filterBuilder.getQuery(doc.getDocumentElement());
-    assertTrue(filter instanceof NumericRangeQuery<?>);
-    NumericRangeQuery<Long> numRangeFilter = (NumericRangeQuery) filter;
+    assertTrue(filter instanceof LegacyNumericRangeQuery<?>);
+    LegacyNumericRangeQuery<Long> numRangeFilter = (LegacyNumericRangeQuery) filter;
     assertEquals(Long.valueOf(-2321L), numRangeFilter.getMin());
     assertEquals(Long.valueOf(60000000L), numRangeFilter.getMax());
     assertEquals("AGE", numRangeFilter.getField());
     assertTrue(numRangeFilter.includesMin());
     assertTrue(numRangeFilter.includesMax());
 
-    String xml2 = "<NumericRangeQuery fieldName='AGE' type='LoNg' lowerTerm='-2321' upperTerm='60000000' includeUpper='false'/>";
+    String xml2 = "<LegacyNumericRangeQuery fieldName='AGE' type='LoNg' lowerTerm='-2321' upperTerm='60000000' includeUpper='false'/>";
     Document doc2 = getDocumentFromString(xml2);
     Query filter2 = filterBuilder.getQuery(doc2.getDocumentElement());
-    assertTrue(filter2 instanceof NumericRangeQuery<?>);
+    assertTrue(filter2 instanceof LegacyNumericRangeQuery<?>);
 
-    NumericRangeQuery<Long> numRangeFilter2 = (NumericRangeQuery) filter2;
+    LegacyNumericRangeQuery<Long> numRangeFilter2 = (LegacyNumericRangeQuery) filter2;
     assertEquals(Long.valueOf(-2321L), numRangeFilter2.getMin());
     assertEquals(Long.valueOf(60000000L), numRangeFilter2.getMax());
     assertEquals("AGE", numRangeFilter2.getField());
@@ -107,27 +107,27 @@ public class TestNumericRangeQueryBuilder extends LuceneTestCase {
 
   @SuppressWarnings({"unchecked","rawtypes"})
   public void testGetFilterDouble() throws Exception {
-    NumericRangeQueryBuilder filterBuilder = new NumericRangeQueryBuilder();
+    LegacyNumericRangeQueryBuilder filterBuilder = new LegacyNumericRangeQueryBuilder();
 
-    String xml = "<NumericRangeQuery fieldName='AGE' type='doubLe' lowerTerm='-23.21' upperTerm='60000.00023'/>";
+    String xml = "<LegacyNumericRangeQuery fieldName='AGE' type='doubLe' lowerTerm='-23.21' upperTerm='60000.00023'/>";
     Document doc = getDocumentFromString(xml);
 
     Query filter = filterBuilder.getQuery(doc.getDocumentElement());
-    assertTrue(filter instanceof NumericRangeQuery<?>);
+    assertTrue(filter instanceof LegacyNumericRangeQuery<?>);
 
-    NumericRangeQuery<Double> numRangeFilter = (NumericRangeQuery) filter;
+    LegacyNumericRangeQuery<Double> numRangeFilter = (LegacyNumericRangeQuery) filter;
     assertEquals(Double.valueOf(-23.21d), numRangeFilter.getMin());
     assertEquals(Double.valueOf(60000.00023d), numRangeFilter.getMax());
     assertEquals("AGE", numRangeFilter.getField());
     assertTrue(numRangeFilter.includesMin());
     assertTrue(numRangeFilter.includesMax());
 
-    String xml2 = "<NumericRangeQuery fieldName='AGE' type='doubLe' lowerTerm='-23.21' upperTerm='60000.00023' includeUpper='false'/>";
+    String xml2 = "<LegacyNumericRangeQuery fieldName='AGE' type='doubLe' lowerTerm='-23.21' upperTerm='60000.00023' includeUpper='false'/>";
     Document doc2 = getDocumentFromString(xml2);
     Query filter2 = filterBuilder.getQuery(doc2.getDocumentElement());
-    assertTrue(filter2 instanceof NumericRangeQuery<?>);
+    assertTrue(filter2 instanceof LegacyNumericRangeQuery<?>);
 
-    NumericRangeQuery<Double> numRangeFilter2 = (NumericRangeQuery) filter2;
+    LegacyNumericRangeQuery<Double> numRangeFilter2 = (LegacyNumericRangeQuery) filter2;
     assertEquals(Double.valueOf(-23.21d), numRangeFilter2.getMin());
     assertEquals(Double.valueOf(60000.00023d), numRangeFilter2.getMax());
     assertEquals("AGE", numRangeFilter2.getField());
@@ -137,28 +137,28 @@ public class TestNumericRangeQueryBuilder extends LuceneTestCase {
 
   @SuppressWarnings({"unchecked","rawtypes"})
   public void testGetFilterFloat() throws Exception {
-    NumericRangeQueryBuilder filterBuilder = new NumericRangeQueryBuilder();
+    LegacyNumericRangeQueryBuilder filterBuilder = new LegacyNumericRangeQueryBuilder();
 
-    String xml = "<NumericRangeQuery fieldName='AGE' type='FLOAT' lowerTerm='-2.321432' upperTerm='32432.23'/>";
+    String xml = "<LegacyNumericRangeQuery fieldName='AGE' type='FLOAT' lowerTerm='-2.321432' upperTerm='32432.23'/>";
     Document doc = getDocumentFromString(xml);
 
     Query filter = filterBuilder.getQuery(doc.getDocumentElement());
-    assertTrue(filter instanceof NumericRangeQuery<?>);
+    assertTrue(filter instanceof LegacyNumericRangeQuery<?>);
 
-    NumericRangeQuery<Float> numRangeFilter = (NumericRangeQuery) filter;
+    LegacyNumericRangeQuery<Float> numRangeFilter = (LegacyNumericRangeQuery) filter;
     assertEquals(Float.valueOf(-2.321432f), numRangeFilter.getMin());
     assertEquals(Float.valueOf(32432.23f), numRangeFilter.getMax());
     assertEquals("AGE", numRangeFilter.getField());
     assertTrue(numRangeFilter.includesMin());
     assertTrue(numRangeFilter.includesMax());
 
-    String xml2 = "<NumericRangeQuery fieldName='AGE' type='FLOAT' lowerTerm='-2.321432' upperTerm='32432.23' includeUpper='false' precisionStep='2' />";
+    String xml2 = "<LegacyNumericRangeQuery fieldName='AGE' type='FLOAT' lowerTerm='-2.321432' upperTerm='32432.23' includeUpper='false' precisionStep='2' />";
     Document doc2 = getDocumentFromString(xml2);
 
     Query filter2 = filterBuilder.getQuery(doc2.getDocumentElement());
-    assertTrue(filter2 instanceof NumericRangeQuery<?>);
+    assertTrue(filter2 instanceof LegacyNumericRangeQuery<?>);
 
-    NumericRangeQuery<Float> numRangeFilter2 = (NumericRangeQuery) filter2;
+    LegacyNumericRangeQuery<Float> numRangeFilter2 = (LegacyNumericRangeQuery) filter2;
     assertEquals(Float.valueOf(-2.321432f), numRangeFilter2.getMin());
     assertEquals(Float.valueOf(32432.23f), numRangeFilter2.getMax());
     assertEquals("AGE", numRangeFilter2.getField());
diff --git a/lucene/sandbox/src/java/org/apache/lucene/document/DimensionalLatLonField.java b/lucene/sandbox/src/java/org/apache/lucene/document/DimensionalLatLonField.java
index 32fd102..a1e3199 100644
--- a/lucene/sandbox/src/java/org/apache/lucene/document/DimensionalLatLonField.java
+++ b/lucene/sandbox/src/java/org/apache/lucene/document/DimensionalLatLonField.java
@@ -19,7 +19,7 @@ package org.apache.lucene.document;
 
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.GeoUtils;
-import org.apache.lucene.util.bkd.BKDUtil;
+import org.apache.lucene.util.NumericUtils;
 
 /** Add this to a document to index lat/lon point dimensionally */
 public final class DimensionalLatLonField extends Field {
@@ -46,8 +46,8 @@ public final class DimensionalLatLonField extends Field {
       throw new IllegalArgumentException("invalid lon (" + lon + "): must be -180 to 180");
     }
     byte[] bytes = new byte[8];
-    BKDUtil.intToBytes(encodeLat(lat), bytes, 0);
-    BKDUtil.intToBytes(encodeLon(lon), bytes, 1);
+    NumericUtils.intToBytes(encodeLat(lat), bytes, 0);
+    NumericUtils.intToBytes(encodeLon(lon), bytes, 1);
     fieldsData = new BytesRef(bytes);
   }
 
diff --git a/lucene/sandbox/src/java/org/apache/lucene/document/GeoPointField.java b/lucene/sandbox/src/java/org/apache/lucene/document/GeoPointField.java
index dd87ad5..be70db5 100644
--- a/lucene/sandbox/src/java/org/apache/lucene/document/GeoPointField.java
+++ b/lucene/sandbox/src/java/org/apache/lucene/document/GeoPointField.java
@@ -54,7 +54,7 @@ public final class GeoPointField extends Field {
     TYPE_NOT_STORED.setOmitNorms(true);
     TYPE_NOT_STORED.setIndexOptions(IndexOptions.DOCS);
     TYPE_NOT_STORED.setDocValuesType(DocValuesType.SORTED_NUMERIC);
-    TYPE_NOT_STORED.setNumericType(FieldType.NumericType.LONG);
+    TYPE_NOT_STORED.setNumericType(FieldType.LegacyNumericType.LONG);
     TYPE_NOT_STORED.setNumericPrecisionStep(PRECISION_STEP);
     TYPE_NOT_STORED.freeze();
   }
@@ -69,7 +69,7 @@ public final class GeoPointField extends Field {
     TYPE_STORED.setOmitNorms(true);
     TYPE_STORED.setIndexOptions(IndexOptions.DOCS);
     TYPE_STORED.setDocValuesType(DocValuesType.SORTED_NUMERIC);
-    TYPE_STORED.setNumericType(FieldType.NumericType.LONG);
+    TYPE_STORED.setNumericType(FieldType.LegacyNumericType.LONG);
     TYPE_STORED.setNumericPrecisionStep(PRECISION_STEP);
     TYPE_STORED.setStored(true);
     TYPE_STORED.freeze();
@@ -95,13 +95,13 @@ public final class GeoPointField extends Field {
    *  @param lon longitude double value [-180.0 : 180.0]
    *  @param lat latitude double value [-90.0 : 90.0]
    *  @param type customized field type: must have {@link FieldType#numericType()}
-   *         of {@link FieldType.NumericType#LONG}.
+   *         of {@link org.apache.lucene.document.FieldType.LegacyNumericType#LONG}.
    *  @throws IllegalArgumentException if the field name or type is null, or
    *          if the field type does not have a LONG numericType()
    */
   public GeoPointField(String name, double lon, double lat, FieldType type) {
     super(name, type);
-    if (type.numericType() != FieldType.NumericType.LONG) {
+    if (type.numericType() != FieldType.LegacyNumericType.LONG) {
       throw new IllegalArgumentException("type.numericType() must be LONG but got " + type.numericType());
     }
     if (type.docValuesType() != DocValuesType.SORTED_NUMERIC) {
diff --git a/lucene/sandbox/src/java/org/apache/lucene/search/DimensionalPointInPolygonQuery.java b/lucene/sandbox/src/java/org/apache/lucene/search/DimensionalPointInPolygonQuery.java
index cb07b5e..20a1e94 100644
--- a/lucene/sandbox/src/java/org/apache/lucene/search/DimensionalPointInPolygonQuery.java
+++ b/lucene/sandbox/src/java/org/apache/lucene/search/DimensionalPointInPolygonQuery.java
@@ -21,15 +21,15 @@ import java.io.IOException;
 import java.util.Arrays;
 
 import org.apache.lucene.document.DimensionalLatLonField;
-import org.apache.lucene.index.DimensionalValues;
 import org.apache.lucene.index.DimensionalValues.IntersectVisitor;
 import org.apache.lucene.index.DimensionalValues.Relation;
+import org.apache.lucene.index.DimensionalValues;
 import org.apache.lucene.index.LeafReader;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.util.DocIdSetBuilder;
 import org.apache.lucene.util.GeoRelationUtils;
 import org.apache.lucene.util.GeoUtils;
-import org.apache.lucene.util.bkd.BKDUtil;
+import org.apache.lucene.util.NumericUtils;
 
 /** Finds all previously indexed points that fall within the specified polygon.
  *
@@ -124,8 +124,8 @@ public class DimensionalPointInPolygonQuery extends Query {
                            @Override
                            public void visit(int docID, byte[] packedValue) {
                              assert packedValue.length == 8;
-                             double lat = DimensionalLatLonField.decodeLat(BKDUtil.bytesToInt(packedValue, 0));
-                             double lon = DimensionalLatLonField.decodeLon(BKDUtil.bytesToInt(packedValue, 1));
+                             double lat = DimensionalLatLonField.decodeLat(NumericUtils.bytesToInt(packedValue, 0));
+                             double lon = DimensionalLatLonField.decodeLon(NumericUtils.bytesToInt(packedValue, 1));
                              if (GeoRelationUtils.pointInPolygon(polyLons, polyLats, lat, lon)) {
                                hitCount[0]++;
                                result.add(docID);
@@ -134,10 +134,10 @@ public class DimensionalPointInPolygonQuery extends Query {
 
                            @Override
                            public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {
-                             double cellMinLat = DimensionalLatLonField.decodeLat(BKDUtil.bytesToInt(minPackedValue, 0));
-                             double cellMinLon = DimensionalLatLonField.decodeLon(BKDUtil.bytesToInt(minPackedValue, 1));
-                             double cellMaxLat = DimensionalLatLonField.decodeLat(BKDUtil.bytesToInt(maxPackedValue, 0));
-                             double cellMaxLon = DimensionalLatLonField.decodeLon(BKDUtil.bytesToInt(maxPackedValue, 1));
+                             double cellMinLat = DimensionalLatLonField.decodeLat(NumericUtils.bytesToInt(minPackedValue, 0));
+                             double cellMinLon = DimensionalLatLonField.decodeLon(NumericUtils.bytesToInt(minPackedValue, 1));
+                             double cellMaxLat = DimensionalLatLonField.decodeLat(NumericUtils.bytesToInt(maxPackedValue, 0));
+                             double cellMaxLon = DimensionalLatLonField.decodeLon(NumericUtils.bytesToInt(maxPackedValue, 1));
 
                              if (cellMinLat <= minLat && cellMaxLat >= maxLat && cellMinLon <= minLon && cellMaxLon >= maxLon) {
                                // Cell fully encloses the query
diff --git a/lucene/sandbox/src/java/org/apache/lucene/search/DimensionalPointInRectQuery.java b/lucene/sandbox/src/java/org/apache/lucene/search/DimensionalPointInRectQuery.java
index 73cffc0..b2e8bf3 100644
--- a/lucene/sandbox/src/java/org/apache/lucene/search/DimensionalPointInRectQuery.java
+++ b/lucene/sandbox/src/java/org/apache/lucene/search/DimensionalPointInRectQuery.java
@@ -20,15 +20,15 @@ package org.apache.lucene.search;
 import java.io.IOException;
 
 import org.apache.lucene.document.DimensionalLatLonField;
-import org.apache.lucene.index.DimensionalValues;
 import org.apache.lucene.index.DimensionalValues.IntersectVisitor;
 import org.apache.lucene.index.DimensionalValues.Relation;
+import org.apache.lucene.index.DimensionalValues;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.LeafReader;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.util.DocIdSetBuilder;
 import org.apache.lucene.util.GeoUtils;
-import org.apache.lucene.util.bkd.BKDUtil;
+import org.apache.lucene.util.NumericUtils;
 
 /** Finds all previously indexed points that fall within the specified boundings box.
  *
@@ -98,8 +98,8 @@ public class DimensionalPointInRectQuery extends Query {
                            @Override
                            public void visit(int docID, byte[] packedValue) {
                              assert packedValue.length == 8;
-                             double lat = DimensionalLatLonField.decodeLat(BKDUtil.bytesToInt(packedValue, 0));
-                             double lon = DimensionalLatLonField.decodeLon(BKDUtil.bytesToInt(packedValue, 1));
+                             double lat = DimensionalLatLonField.decodeLat(NumericUtils.bytesToInt(packedValue, 0));
+                             double lon = DimensionalLatLonField.decodeLon(NumericUtils.bytesToInt(packedValue, 1));
                              if (lat >= minLat && lat <= maxLat && lon >= minLon && lon <= maxLon) {
                                hitCount[0]++;
                                result.add(docID);
@@ -108,10 +108,10 @@ public class DimensionalPointInRectQuery extends Query {
 
                            @Override
                            public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {
-                             double cellMinLat = DimensionalLatLonField.decodeLat(BKDUtil.bytesToInt(minPackedValue, 0));
-                             double cellMinLon = DimensionalLatLonField.decodeLon(BKDUtil.bytesToInt(minPackedValue, 1));
-                             double cellMaxLat = DimensionalLatLonField.decodeLat(BKDUtil.bytesToInt(maxPackedValue, 0));
-                             double cellMaxLon = DimensionalLatLonField.decodeLon(BKDUtil.bytesToInt(maxPackedValue, 1));
+                             double cellMinLat = DimensionalLatLonField.decodeLat(NumericUtils.bytesToInt(minPackedValue, 0));
+                             double cellMinLon = DimensionalLatLonField.decodeLon(NumericUtils.bytesToInt(minPackedValue, 1));
+                             double cellMaxLat = DimensionalLatLonField.decodeLat(NumericUtils.bytesToInt(maxPackedValue, 0));
+                             double cellMaxLon = DimensionalLatLonField.decodeLon(NumericUtils.bytesToInt(maxPackedValue, 1));
 
                              if (minLat <= cellMinLat && maxLat >= cellMaxLat && minLon <= cellMinLon && maxLon >= cellMaxLon) {
                                return Relation.CELL_INSIDE_QUERY;
diff --git a/lucene/sandbox/src/java/org/apache/lucene/search/DocValuesRangeQuery.java b/lucene/sandbox/src/java/org/apache/lucene/search/DocValuesRangeQuery.java
index 6a6eae9..b443ab3 100644
--- a/lucene/sandbox/src/java/org/apache/lucene/search/DocValuesRangeQuery.java
+++ b/lucene/sandbox/src/java/org/apache/lucene/search/DocValuesRangeQuery.java
@@ -33,7 +33,7 @@ import org.apache.lucene.util.BytesRef;
  * A range query that works on top of the doc values APIs. Such queries are
  * usually slow since they do not use an inverted index. However, in the
  * dense case where most documents match this query, it <b>might</b> be as
- * fast or faster than a regular {@link NumericRangeQuery}.
+ * fast or faster than a regular {@link DimensionalRangeQuery}.
  *
  * <p>
  * <b>NOTE</b>: be very careful using this query: it is
diff --git a/lucene/sandbox/src/java/org/apache/lucene/search/GeoPointInBBoxQuery.java b/lucene/sandbox/src/java/org/apache/lucene/search/GeoPointInBBoxQuery.java
index 54f85f4..bdd6c9f 100644
--- a/lucene/sandbox/src/java/org/apache/lucene/search/GeoPointInBBoxQuery.java
+++ b/lucene/sandbox/src/java/org/apache/lucene/search/GeoPointInBBoxQuery.java
@@ -21,7 +21,7 @@ import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.util.GeoUtils;
 
 /** Implements a simple bounding box query on a GeoPoint field. This is inspired by
- * {@link org.apache.lucene.search.NumericRangeQuery} and is implemented using a
+ * {@link LegacyNumericRangeQuery} and is implemented using a
  * two phase approach. First, candidate terms are queried using a numeric
  * range based on the morton codes of the min and max lat/lon pairs. Terms
  * passing this initial filter are passed to a final check that verifies whether
diff --git a/lucene/sandbox/src/java/org/apache/lucene/search/GeoPointTermsEnum.java b/lucene/sandbox/src/java/org/apache/lucene/search/GeoPointTermsEnum.java
index db0baae..e4faa23 100644
--- a/lucene/sandbox/src/java/org/apache/lucene/search/GeoPointTermsEnum.java
+++ b/lucene/sandbox/src/java/org/apache/lucene/search/GeoPointTermsEnum.java
@@ -28,7 +28,7 @@ import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
 import org.apache.lucene.util.GeoRelationUtils;
 import org.apache.lucene.util.GeoUtils;
-import org.apache.lucene.util.NumericUtils;
+import org.apache.lucene.util.LegacyNumericUtils;
 
 /**
  * computes all ranges along a space-filling curve that represents
@@ -235,7 +235,7 @@ abstract class GeoPointTermsEnum extends FilteredTermsEnum {
      */
     private void fillBytesRef(BytesRefBuilder result) {
       assert result != null;
-      NumericUtils.longToPrefixCoded(start, shift, result);
+      LegacyNumericUtils.longToPrefixCoded(start, shift, result);
     }
 
     @Override
diff --git a/lucene/sandbox/src/test/org/apache/lucene/search/TestDocValuesRangeQuery.java b/lucene/sandbox/src/test/org/apache/lucene/search/TestDocValuesRangeQuery.java
index d9d4a56..aa51a48 100644
--- a/lucene/sandbox/src/test/org/apache/lucene/search/TestDocValuesRangeQuery.java
+++ b/lucene/sandbox/src/test/org/apache/lucene/search/TestDocValuesRangeQuery.java
@@ -19,9 +19,9 @@ package org.apache.lucene.search;
 
 import java.io.IOException;
 
+import org.apache.lucene.document.DimensionalLongField;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field.Store;
-import org.apache.lucene.document.LongField;
 import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.document.SortedDocValuesField;
 import org.apache.lucene.document.SortedNumericDocValuesField;
@@ -34,9 +34,9 @@ import org.apache.lucene.index.Term;
 import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.BytesRefBuilder;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.NumericUtils;
+import org.apache.lucene.util.RamUsageEstimator;
 import org.apache.lucene.util.TestUtil;
 
 public class TestDocValuesRangeQuery extends LuceneTestCase {
@@ -53,12 +53,12 @@ public class TestDocValuesRangeQuery extends LuceneTestCase {
         for (int j = 0; j < numValues; ++j) {
           final long value = TestUtil.nextLong(random(), -100, 10000);
           doc.add(new SortedNumericDocValuesField("dv", value));
-          doc.add(new LongField("idx", value, Store.NO));
+          doc.add(new DimensionalLongField("idx", value));
         }
         iw.addDocument(doc);
       }
       if (random().nextBoolean()) {
-        iw.deleteDocuments(NumericRangeQuery.newLongRange("idx", 0L, 10L, true, true));
+        iw.deleteDocuments(DimensionalRangeQuery.new1DLongRange("idx", 0L, true, 10L, true));
       }
       iw.commit();
       final IndexReader reader = iw.getReader();
@@ -70,7 +70,7 @@ public class TestDocValuesRangeQuery extends LuceneTestCase {
         final Long max = random().nextBoolean() ? null : TestUtil.nextLong(random(), -100, 1000);
         final boolean minInclusive = random().nextBoolean();
         final boolean maxInclusive = random().nextBoolean();
-        final Query q1 = NumericRangeQuery.newLongRange("idx", min, max, minInclusive, maxInclusive);
+        final Query q1 = DimensionalRangeQuery.new1DLongRange("idx", min, minInclusive, max, maxInclusive);
         final Query q2 = DocValuesRangeQuery.newLongRange("dv", min, max, minInclusive, maxInclusive);
         assertSameMatches(searcher, q1, q2, false);
       }
@@ -84,9 +84,9 @@ public class TestDocValuesRangeQuery extends LuceneTestCase {
     if (l == null) {
       return null;
     } else {
-      final BytesRefBuilder bytes = new BytesRefBuilder();
-      NumericUtils.longToPrefixCoded(l, 0, bytes);
-      return bytes.get();
+      byte[] bytes = new byte[RamUsageEstimator.NUM_BYTES_LONG];
+      NumericUtils.longToBytes(l, bytes, 0);
+      return new BytesRef(bytes);
     }
   }
 
@@ -180,13 +180,13 @@ public class TestDocValuesRangeQuery extends LuceneTestCase {
         final long value = TestUtil.nextLong(random(), -100, 10000);
         doc.add(new SortedNumericDocValuesField("dv1", value));
         doc.add(new SortedSetDocValuesField("dv2", toSortableBytes(value)));
-        doc.add(new LongField("idx", value, Store.NO));
+        doc.add(new DimensionalLongField("idx", value));
         doc.add(new StringField("f", random().nextBoolean() ? "a" : "b", Store.NO));
       }
       iw.addDocument(doc);
     }
     if (random().nextBoolean()) {
-      iw.deleteDocuments(NumericRangeQuery.newLongRange("idx", 0L, 10L, true, true));
+      iw.deleteDocuments(DimensionalRangeQuery.new1DLongRange("idx", 0L, true, 10L, true));
     }
     iw.commit();
     final IndexReader reader = iw.getReader();
@@ -200,7 +200,7 @@ public class TestDocValuesRangeQuery extends LuceneTestCase {
       final boolean maxInclusive = random().nextBoolean();
 
       BooleanQuery.Builder ref = new BooleanQuery.Builder();
-      ref.add(NumericRangeQuery.newLongRange("idx", min, max, minInclusive, maxInclusive), Occur.FILTER);
+      ref.add(DimensionalRangeQuery.new1DLongRange("idx", min, minInclusive, max, maxInclusive), Occur.FILTER);
       ref.add(new TermQuery(new Term("f", "a")), Occur.MUST);
 
       BooleanQuery.Builder bq1 = new BooleanQuery.Builder();
diff --git a/lucene/spatial/src/java/org/apache/lucene/spatial/bbox/BBoxStrategy.java b/lucene/spatial/src/java/org/apache/lucene/spatial/bbox/BBoxStrategy.java
index 2e7ae0a..934b3b9 100644
--- a/lucene/spatial/src/java/org/apache/lucene/spatial/bbox/BBoxStrategy.java
+++ b/lucene/spatial/src/java/org/apache/lucene/spatial/bbox/BBoxStrategy.java
@@ -21,7 +21,7 @@ import com.spatial4j.core.context.SpatialContext;
 import com.spatial4j.core.shape.Point;
 import com.spatial4j.core.shape.Rectangle;
 import com.spatial4j.core.shape.Shape;
-import org.apache.lucene.document.DoubleField;
+import org.apache.lucene.document.LegacyDoubleField;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.FieldType;
 import org.apache.lucene.document.StringField;
@@ -31,7 +31,7 @@ import org.apache.lucene.queries.function.ValueSource;
 import org.apache.lucene.search.BooleanClause;
 import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.NumericRangeQuery;
+import org.apache.lucene.search.LegacyNumericRangeQuery;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.spatial.SpatialStrategy;
@@ -40,7 +40,7 @@ import org.apache.lucene.spatial.query.SpatialOperation;
 import org.apache.lucene.spatial.query.UnsupportedSpatialOperation;
 import org.apache.lucene.spatial.util.DistanceToShapeValueSource;
 import org.apache.lucene.util.BytesRefBuilder;
-import org.apache.lucene.util.NumericUtils;
+import org.apache.lucene.util.LegacyNumericUtils;
 
 
 /**
@@ -63,7 +63,7 @@ import org.apache.lucene.util.NumericUtils;
  * <p>
  * This uses 4 double fields for minX, maxX, minY, maxY
  * and a boolean to mark a dateline cross. Depending on the particular {@link
- * SpatialOperation}s, there are a variety of {@link NumericRangeQuery}s to be
+ * SpatialOperation}s, there are a variety of {@link org.apache.lucene.search.LegacyNumericRangeQuery}s to be
  * done.
  * The {@link #makeOverlapRatioValueSource(com.spatial4j.core.shape.Rectangle, double)}
  * works by calculating the query bbox overlap percentage against the indexed
@@ -103,7 +103,7 @@ public class BBoxStrategy extends SpatialStrategy {
     field_maxY = fieldNamePrefix + SUFFIX_MAXY;
     field_xdl = fieldNamePrefix + SUFFIX_XDL;
 
-    FieldType fieldType = new FieldType(DoubleField.TYPE_NOT_STORED);
+    FieldType fieldType = new FieldType(LegacyDoubleField.TYPE_NOT_STORED);
     fieldType.setNumericPrecisionStep(8);//Solr's default
     fieldType.setDocValuesType(DocValuesType.NUMERIC);
     setFieldType(fieldType);
@@ -124,7 +124,7 @@ public class BBoxStrategy extends SpatialStrategy {
     fieldType.freeze();
     this.fieldType = fieldType;
     //only double's supported right now
-    if (fieldType.numericType() != FieldType.NumericType.DOUBLE)
+    if (fieldType.numericType() != FieldType.LegacyNumericType.DOUBLE)
       throw new IllegalArgumentException("BBoxStrategy only supports doubles at this time.");
     //for xdlFieldType, copy some similar options. Don't do docValues since it isn't needed here.
     xdlFieldType = new FieldType(StringField.TYPE_NOT_STORED);
@@ -168,9 +168,9 @@ public class BBoxStrategy extends SpatialStrategy {
       final Number number = super.numericValue();
       if (number == null)
         return null;
-      if (fieldType().numericType() == FieldType.NumericType.DOUBLE)
+      if (fieldType().numericType() == FieldType.LegacyNumericType.DOUBLE)
         return Double.doubleToLongBits(number.doubleValue());
-      if (fieldType().numericType() == FieldType.NumericType.FLOAT)
+      if (fieldType().numericType() == FieldType.LegacyNumericType.FLOAT)
         return Float.floatToIntBits(number.floatValue());
       return number.longValue();
     }
@@ -253,8 +253,8 @@ public class BBoxStrategy extends SpatialStrategy {
 
     // Y conditions
     // docMinY <= queryExtent.getMinY() AND docMaxY >= queryExtent.getMaxY()
-    Query qMinY = NumericRangeQuery.newDoubleRange(field_minY, getPrecisionStep(), null, bbox.getMinY(), false, true);
-    Query qMaxY = NumericRangeQuery.newDoubleRange(field_maxY, getPrecisionStep(), bbox.getMaxY(), null, true, false);
+    Query qMinY = LegacyNumericRangeQuery.newDoubleRange(field_minY, getPrecisionStep(), null, bbox.getMinY(), false, true);
+    Query qMaxY = LegacyNumericRangeQuery.newDoubleRange(field_maxY, getPrecisionStep(), bbox.getMaxY(), null, true, false);
     Query yConditions = this.makeQuery(BooleanClause.Occur.MUST, qMinY, qMaxY);
 
     // X conditions
@@ -266,8 +266,8 @@ public class BBoxStrategy extends SpatialStrategy {
       // X Conditions for documents that do not cross the date line,
       // documents that contain the min X and max X of the query envelope,
       // docMinX <= queryExtent.getMinX() AND docMaxX >= queryExtent.getMaxX()
-      Query qMinX = NumericRangeQuery.newDoubleRange(field_minX, getPrecisionStep(), null, bbox.getMinX(), false, true);
-      Query qMaxX = NumericRangeQuery.newDoubleRange(field_maxX, getPrecisionStep(), bbox.getMaxX(), null, true, false);
+      Query qMinX = LegacyNumericRangeQuery.newDoubleRange(field_minX, getPrecisionStep(), null, bbox.getMinX(), false, true);
+      Query qMaxX = LegacyNumericRangeQuery.newDoubleRange(field_maxX, getPrecisionStep(), bbox.getMaxX(), null, true, false);
       Query qMinMax = this.makeQuery(BooleanClause.Occur.MUST, qMinX, qMaxX);
       Query qNonXDL = this.makeXDL(false, qMinMax);
 
@@ -278,8 +278,8 @@ public class BBoxStrategy extends SpatialStrategy {
         // the left portion of the document contains the min X of the query
         // OR the right portion of the document contains the max X of the query,
         // docMinXLeft <= queryExtent.getMinX() OR docMaxXRight >= queryExtent.getMaxX()
-        Query qXDLLeft = NumericRangeQuery.newDoubleRange(field_minX, getPrecisionStep(), null, bbox.getMinX(), false, true);
-        Query qXDLRight = NumericRangeQuery.newDoubleRange(field_maxX, getPrecisionStep(), bbox.getMaxX(), null, true, false);
+        Query qXDLLeft = LegacyNumericRangeQuery.newDoubleRange(field_minX, getPrecisionStep(), null, bbox.getMinX(), false, true);
+        Query qXDLRight = LegacyNumericRangeQuery.newDoubleRange(field_maxX, getPrecisionStep(), bbox.getMaxX(), null, true, false);
         Query qXDLLeftRight = this.makeQuery(BooleanClause.Occur.SHOULD, qXDLLeft, qXDLRight);
         Query qXDL = this.makeXDL(true, qXDLLeftRight);
 
@@ -302,8 +302,8 @@ public class BBoxStrategy extends SpatialStrategy {
       // the left portion of the document contains the min X of the query
       // AND the right portion of the document contains the max X of the query,
       // docMinXLeft <= queryExtent.getMinX() AND docMaxXRight >= queryExtent.getMaxX()
-      Query qXDLLeft = NumericRangeQuery.newDoubleRange(field_minX, getPrecisionStep(), null, bbox.getMinX(), false, true);
-      Query qXDLRight = NumericRangeQuery.newDoubleRange(field_maxX, getPrecisionStep(), bbox.getMaxX(), null, true, false);
+      Query qXDLLeft = LegacyNumericRangeQuery.newDoubleRange(field_minX, getPrecisionStep(), null, bbox.getMinX(), false, true);
+      Query qXDLRight = LegacyNumericRangeQuery.newDoubleRange(field_maxX, getPrecisionStep(), bbox.getMaxX(), null, true, false);
       Query qXDLLeftRight = this.makeXDL(true, this.makeQuery(BooleanClause.Occur.MUST, qXDLLeft, qXDLRight));
 
       Query qWorld = makeQuery(BooleanClause.Occur.MUST,
@@ -328,8 +328,8 @@ public class BBoxStrategy extends SpatialStrategy {
 
     // Y conditions
     // docMinY > queryExtent.getMaxY() OR docMaxY < queryExtent.getMinY()
-    Query qMinY = NumericRangeQuery.newDoubleRange(field_minY, getPrecisionStep(), bbox.getMaxY(), null, false, false);
-    Query qMaxY = NumericRangeQuery.newDoubleRange(field_maxY, getPrecisionStep(), null, bbox.getMinY(), false, false);
+    Query qMinY = LegacyNumericRangeQuery.newDoubleRange(field_minY, getPrecisionStep(), bbox.getMaxY(), null, false, false);
+    Query qMaxY = LegacyNumericRangeQuery.newDoubleRange(field_maxY, getPrecisionStep(), null, bbox.getMinY(), false, false);
     Query yConditions = this.makeQuery(BooleanClause.Occur.SHOULD, qMinY, qMaxY);
 
     // X conditions
@@ -340,14 +340,14 @@ public class BBoxStrategy extends SpatialStrategy {
 
       // X Conditions for documents that do not cross the date line,
       // docMinX > queryExtent.getMaxX() OR docMaxX < queryExtent.getMinX()
-      Query qMinX = NumericRangeQuery.newDoubleRange(field_minX, getPrecisionStep(), bbox.getMaxX(), null, false, false);
+      Query qMinX = LegacyNumericRangeQuery.newDoubleRange(field_minX, getPrecisionStep(), bbox.getMaxX(), null, false, false);
       if (bbox.getMinX() == -180.0 && ctx.isGeo()) {//touches dateline; -180 == 180
         BooleanQuery.Builder bq = new BooleanQuery.Builder();
         bq.add(qMinX, BooleanClause.Occur.MUST);
         bq.add(makeNumberTermQuery(field_maxX, 180.0), BooleanClause.Occur.MUST_NOT);
         qMinX = bq.build();
       }
-      Query qMaxX = NumericRangeQuery.newDoubleRange(field_maxX, getPrecisionStep(), null, bbox.getMinX(), false, false);
+      Query qMaxX = LegacyNumericRangeQuery.newDoubleRange(field_maxX, getPrecisionStep(), null, bbox.getMinX(), false, false);
       if (bbox.getMaxX() == 180.0 && ctx.isGeo()) {//touches dateline; -180 == 180
         BooleanQuery.Builder bq = new BooleanQuery.Builder();
         bq.add(qMaxX, BooleanClause.Occur.MUST);
@@ -368,8 +368,8 @@ public class BBoxStrategy extends SpatialStrategy {
         // where: docMaxXLeft = 180.0, docMinXRight = -180.0
         // (docMaxXLeft  < queryExtent.getMinX()) equates to (180.0  < queryExtent.getMinX()) and is ignored
         // (docMinXRight > queryExtent.getMaxX()) equates to (-180.0 > queryExtent.getMaxX()) and is ignored
-        Query qMinXLeft = NumericRangeQuery.newDoubleRange(field_minX, getPrecisionStep(), bbox.getMaxX(), null, false, false);
-        Query qMaxXRight = NumericRangeQuery.newDoubleRange(field_maxX, getPrecisionStep(), null, bbox.getMinX(), false, false);
+        Query qMinXLeft = LegacyNumericRangeQuery.newDoubleRange(field_minX, getPrecisionStep(), bbox.getMaxX(), null, false, false);
+        Query qMaxXRight = LegacyNumericRangeQuery.newDoubleRange(field_maxX, getPrecisionStep(), null, bbox.getMinX(), false, false);
         Query qLeftRight = this.makeQuery(BooleanClause.Occur.MUST, qMinXLeft, qMaxXRight);
         Query qXDL = this.makeXDL(true, qLeftRight);
 
@@ -383,10 +383,10 @@ public class BBoxStrategy extends SpatialStrategy {
       // the document must be disjoint to both the left and right query portions
       // (docMinX > queryExtent.getMaxX()Left OR docMaxX < queryExtent.getMinX()) AND (docMinX > queryExtent.getMaxX() OR docMaxX < queryExtent.getMinX()Left)
       // where: queryExtent.getMaxX()Left = 180.0, queryExtent.getMinX()Left = -180.0
-      Query qMinXLeft = NumericRangeQuery.newDoubleRange(field_minX, getPrecisionStep(), 180.0, null, false, false);
-      Query qMaxXLeft = NumericRangeQuery.newDoubleRange(field_maxX, getPrecisionStep(), null, bbox.getMinX(), false, false);
-      Query qMinXRight = NumericRangeQuery.newDoubleRange(field_minX, getPrecisionStep(), bbox.getMaxX(), null, false, false);
-      Query qMaxXRight = NumericRangeQuery.newDoubleRange(field_maxX, getPrecisionStep(), null, -180.0, false, false);
+      Query qMinXLeft = LegacyNumericRangeQuery.newDoubleRange(field_minX, getPrecisionStep(), 180.0, null, false, false);
+      Query qMaxXLeft = LegacyNumericRangeQuery.newDoubleRange(field_maxX, getPrecisionStep(), null, bbox.getMinX(), false, false);
+      Query qMinXRight = LegacyNumericRangeQuery.newDoubleRange(field_minX, getPrecisionStep(), bbox.getMaxX(), null, false, false);
+      Query qMaxXRight = LegacyNumericRangeQuery.newDoubleRange(field_maxX, getPrecisionStep(), null, -180.0, false, false);
       Query qLeft = this.makeQuery(BooleanClause.Occur.SHOULD, qMinXLeft, qMaxXLeft);
       Query qRight = this.makeQuery(BooleanClause.Occur.SHOULD, qMinXRight, qMaxXRight);
       Query qLeftRight = this.makeQuery(BooleanClause.Occur.MUST, qLeft, qRight);
@@ -478,8 +478,8 @@ public class BBoxStrategy extends SpatialStrategy {
 
     // Y conditions
     // docMinY >= queryExtent.getMinY() AND docMaxY <= queryExtent.getMaxY()
-    Query qMinY = NumericRangeQuery.newDoubleRange(field_minY, getPrecisionStep(), bbox.getMinY(), null, true, false);
-    Query qMaxY = NumericRangeQuery.newDoubleRange(field_maxY, getPrecisionStep(), null, bbox.getMaxY(), false, true);
+    Query qMinY = LegacyNumericRangeQuery.newDoubleRange(field_minY, getPrecisionStep(), bbox.getMinY(), null, true, false);
+    Query qMaxY = LegacyNumericRangeQuery.newDoubleRange(field_maxY, getPrecisionStep(), null, bbox.getMaxY(), false, true);
     Query yConditions = this.makeQuery(BooleanClause.Occur.MUST, qMinY, qMaxY);
 
     // X conditions
@@ -493,8 +493,8 @@ public class BBoxStrategy extends SpatialStrategy {
       // queries that do not cross the date line
 
       // docMinX >= queryExtent.getMinX() AND docMaxX <= queryExtent.getMaxX()
-      Query qMinX = NumericRangeQuery.newDoubleRange(field_minX, getPrecisionStep(), bbox.getMinX(), null, true, false);
-      Query qMaxX = NumericRangeQuery.newDoubleRange(field_maxX, getPrecisionStep(), null, bbox.getMaxX(), false, true);
+      Query qMinX = LegacyNumericRangeQuery.newDoubleRange(field_minX, getPrecisionStep(), bbox.getMinX(), null, true, false);
+      Query qMaxX = LegacyNumericRangeQuery.newDoubleRange(field_maxX, getPrecisionStep(), null, bbox.getMaxX(), false, true);
       Query qMinMax = this.makeQuery(BooleanClause.Occur.MUST, qMinX, qMaxX);
 
       double edge = 0;//none, otherwise opposite dateline of query
@@ -517,14 +517,14 @@ public class BBoxStrategy extends SpatialStrategy {
 
       // the document should be within the left portion of the query
       // docMinX >= queryExtent.getMinX() AND docMaxX <= 180.0
-      Query qMinXLeft = NumericRangeQuery.newDoubleRange(field_minX, getPrecisionStep(), bbox.getMinX(), null, true, false);
-      Query qMaxXLeft = NumericRangeQuery.newDoubleRange(field_maxX, getPrecisionStep(), null, 180.0, false, true);
+      Query qMinXLeft = LegacyNumericRangeQuery.newDoubleRange(field_minX, getPrecisionStep(), bbox.getMinX(), null, true, false);
+      Query qMaxXLeft = LegacyNumericRangeQuery.newDoubleRange(field_maxX, getPrecisionStep(), null, 180.0, false, true);
       Query qLeft = this.makeQuery(BooleanClause.Occur.MUST, qMinXLeft, qMaxXLeft);
 
       // the document should be within the right portion of the query
       // docMinX >= -180.0 AND docMaxX <= queryExtent.getMaxX()
-      Query qMinXRight = NumericRangeQuery.newDoubleRange(field_minX, getPrecisionStep(), -180.0, null, true, false);
-      Query qMaxXRight = NumericRangeQuery.newDoubleRange(field_maxX, getPrecisionStep(), null, bbox.getMaxX(), false, true);
+      Query qMinXRight = LegacyNumericRangeQuery.newDoubleRange(field_minX, getPrecisionStep(), -180.0, null, true, false);
+      Query qMaxXRight = LegacyNumericRangeQuery.newDoubleRange(field_maxX, getPrecisionStep(), null, bbox.getMaxX(), false, true);
       Query qRight = this.makeQuery(BooleanClause.Occur.MUST, qMinXRight, qMaxXRight);
 
       // either left or right conditions should occur,
@@ -537,8 +537,8 @@ public class BBoxStrategy extends SpatialStrategy {
       // AND the right portion of the document must be within the right portion of the query
       // docMinXLeft >= queryExtent.getMinX() AND docMaxXLeft <= 180.0
       // AND docMinXRight >= -180.0 AND docMaxXRight <= queryExtent.getMaxX()
-      Query qXDLLeft = NumericRangeQuery.newDoubleRange(field_minX, getPrecisionStep(), bbox.getMinX(), null, true, false);
-      Query qXDLRight = NumericRangeQuery.newDoubleRange(field_maxX, getPrecisionStep(), null, bbox.getMaxX(), false, true);
+      Query qXDLLeft = LegacyNumericRangeQuery.newDoubleRange(field_minX, getPrecisionStep(), bbox.getMinX(), null, true, false);
+      Query qXDLRight = LegacyNumericRangeQuery.newDoubleRange(field_maxX, getPrecisionStep(), null, bbox.getMaxX(), false, true);
       Query qXDLLeftRight = this.makeQuery(BooleanClause.Occur.MUST, qXDLLeft, qXDLRight);
       Query qXDL = this.makeXDL(true, qXDLLeftRight);
 
@@ -582,7 +582,7 @@ public class BBoxStrategy extends SpatialStrategy {
 
   private Query makeNumberTermQuery(String field, double number) {
     BytesRefBuilder bytes = new BytesRefBuilder();
-    NumericUtils.longToPrefixCodedBytes(NumericUtils.doubleToSortableLong(number), 0, bytes);
+    LegacyNumericUtils.longToPrefixCodedBytes(LegacyNumericUtils.doubleToSortableLong(number), 0, bytes);
     return new TermQuery(new Term(field, bytes.get()));
   }
 
diff --git a/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/BytesRefIteratorTokenStream.java b/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/BytesRefIteratorTokenStream.java
index d82d2f1..071edf4 100644
--- a/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/BytesRefIteratorTokenStream.java
+++ b/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/BytesRefIteratorTokenStream.java
@@ -27,7 +27,7 @@ import org.apache.lucene.util.BytesRefIterator;
 /**
  * A TokenStream used internally by {@link org.apache.lucene.spatial.prefix.PrefixTreeStrategy}.
  *
- * This is modelled after {@link org.apache.lucene.analysis.NumericTokenStream}.
+ * This is modelled after {@link org.apache.lucene.analysis.LegacyNumericTokenStream}.
  *
  * @lucene.internal
  */
diff --git a/lucene/spatial/src/java/org/apache/lucene/spatial/vector/PointVectorStrategy.java b/lucene/spatial/src/java/org/apache/lucene/spatial/vector/PointVectorStrategy.java
index 8d1ad8a..13b2cfd 100644
--- a/lucene/spatial/src/java/org/apache/lucene/spatial/vector/PointVectorStrategy.java
+++ b/lucene/spatial/src/java/org/apache/lucene/spatial/vector/PointVectorStrategy.java
@@ -22,7 +22,7 @@ import com.spatial4j.core.shape.Circle;
 import com.spatial4j.core.shape.Point;
 import com.spatial4j.core.shape.Rectangle;
 import com.spatial4j.core.shape.Shape;
-import org.apache.lucene.document.DoubleField;
+import org.apache.lucene.document.LegacyDoubleField;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.FieldType;
 import org.apache.lucene.queries.function.FunctionRangeQuery;
@@ -30,7 +30,7 @@ import org.apache.lucene.queries.function.ValueSource;
 import org.apache.lucene.search.BooleanClause;
 import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.NumericRangeQuery;
+import org.apache.lucene.search.LegacyNumericRangeQuery;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.spatial.SpatialStrategy;
 import org.apache.lucene.spatial.query.SpatialArgs;
@@ -39,7 +39,7 @@ import org.apache.lucene.spatial.query.UnsupportedSpatialOperation;
 
 /**
  * Simple {@link SpatialStrategy} which represents Points in two numeric {@link
- * DoubleField}s.  The Strategy's best feature is decent distance sort.
+ * org.apache.lucene.document.LegacyDoubleField}s.  The Strategy's best feature is decent distance sort.
  *
  * <p>
  * <b>Characteristics:</b>
@@ -58,7 +58,7 @@ import org.apache.lucene.spatial.query.UnsupportedSpatialOperation;
  * <p>
  * <b>Implementation:</b>
  * <p>
- * This is a simple Strategy.  Search works with {@link NumericRangeQuery}s on
+ * This is a simple Strategy.  Search works with {@link org.apache.lucene.search.LegacyNumericRangeQuery}s on
  * an x and y pair of fields.  A Circle query does the same bbox query but adds a
  * ValueSource filter on
  * {@link #makeDistanceValueSource(com.spatial4j.core.shape.Point)}.
@@ -109,11 +109,11 @@ public class PointVectorStrategy extends SpatialStrategy {
 
   /** @see #createIndexableFields(com.spatial4j.core.shape.Shape) */
   public Field[] createIndexableFields(Point point) {
-    FieldType doubleFieldType = new FieldType(DoubleField.TYPE_NOT_STORED);
+    FieldType doubleFieldType = new FieldType(LegacyDoubleField.TYPE_NOT_STORED);
     doubleFieldType.setNumericPrecisionStep(precisionStep);
     Field[] f = new Field[2];
-    f[0] = new DoubleField(fieldNameX, point.getX(), doubleFieldType);
-    f[1] = new DoubleField(fieldNameY, point.getY(), doubleFieldType);
+    f[0] = new LegacyDoubleField(fieldNameX, point.getX(), doubleFieldType);
+    f[1] = new LegacyDoubleField(fieldNameY, point.getY(), doubleFieldType);
     return f;
   }
 
@@ -166,8 +166,8 @@ public class PointVectorStrategy extends SpatialStrategy {
     return bq.build();
   }
 
-  private NumericRangeQuery<Double> rangeQuery(String fieldName, Double min, Double max) {
-    return NumericRangeQuery.newDoubleRange(
+  private LegacyNumericRangeQuery<Double> rangeQuery(String fieldName, Double min, Double max) {
+    return LegacyNumericRangeQuery.newDoubleRange(
         fieldName,
         precisionStep,
         min,
diff --git a/lucene/spatial3d/src/java/org/apache/lucene/geo3d/Geo3DPointField.java b/lucene/spatial3d/src/java/org/apache/lucene/geo3d/Geo3DPointField.java
index 836546f..1b19d62 100644
--- a/lucene/spatial3d/src/java/org/apache/lucene/geo3d/Geo3DPointField.java
+++ b/lucene/spatial3d/src/java/org/apache/lucene/geo3d/Geo3DPointField.java
@@ -20,8 +20,8 @@ package org.apache.lucene.geo3d;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.FieldType;
 import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.NumericUtils;
 import org.apache.lucene.util.RamUsageEstimator;
-import org.apache.lucene.util.bkd.BKDUtil;
 
 /** Add this to a document to index lat/lon or x/y/z point, indexed as a dimensional value.
  *  Multiple values are allowed: just add multiple Geo3DPointField to the document with the
@@ -61,9 +61,9 @@ public final class Geo3DPointField extends Field {
 
   private void fillFieldsData(double planetMax, double x, double y, double z) {
     byte[] bytes = new byte[12];
-    BKDUtil.intToBytes(Geo3DUtil.encodeValue(planetMax, x), bytes, 0);
-    BKDUtil.intToBytes(Geo3DUtil.encodeValue(planetMax, y), bytes, 1);
-    BKDUtil.intToBytes(Geo3DUtil.encodeValue(planetMax, z), bytes, 2);
+    NumericUtils.intToBytes(Geo3DUtil.encodeValue(planetMax, x), bytes, 0);
+    NumericUtils.intToBytes(Geo3DUtil.encodeValue(planetMax, y), bytes, 1);
+    NumericUtils.intToBytes(Geo3DUtil.encodeValue(planetMax, z), bytes, 2);
     fieldsData = new BytesRef(bytes);
   }
 }
diff --git a/lucene/spatial3d/src/java/org/apache/lucene/geo3d/PointInGeo3DShapeQuery.java b/lucene/spatial3d/src/java/org/apache/lucene/geo3d/PointInGeo3DShapeQuery.java
index e9e8f34..1f465b7 100644
--- a/lucene/spatial3d/src/java/org/apache/lucene/geo3d/PointInGeo3DShapeQuery.java
+++ b/lucene/spatial3d/src/java/org/apache/lucene/geo3d/PointInGeo3DShapeQuery.java
@@ -19,9 +19,9 @@ package org.apache.lucene.geo3d;
 
 import java.io.IOException;
 
-import org.apache.lucene.index.DimensionalValues;
 import org.apache.lucene.index.DimensionalValues.IntersectVisitor;
 import org.apache.lucene.index.DimensionalValues.Relation;
+import org.apache.lucene.index.DimensionalValues;
 import org.apache.lucene.index.LeafReader;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.search.ConstantScoreScorer;
@@ -31,7 +31,7 @@ import org.apache.lucene.search.Query;
 import org.apache.lucene.search.Scorer;
 import org.apache.lucene.search.Weight;
 import org.apache.lucene.util.DocIdSetBuilder;
-import org.apache.lucene.util.bkd.BKDUtil;
+import org.apache.lucene.util.NumericUtils;
 
 /** Finds all previously indexed points that fall within the specified polygon.
  *
@@ -106,9 +106,9 @@ public class PointInGeo3DShapeQuery extends Query {
                            @Override
                            public void visit(int docID, byte[] packedValue) {
                              assert packedValue.length == 12;
-                             double x = Geo3DUtil.decodeValueCenter(planetMax, BKDUtil.bytesToInt(packedValue, 0));
-                             double y = Geo3DUtil.decodeValueCenter(planetMax, BKDUtil.bytesToInt(packedValue, 1));
-                             double z = Geo3DUtil.decodeValueCenter(planetMax, BKDUtil.bytesToInt(packedValue, 2));
+                             double x = Geo3DUtil.decodeValueCenter(planetMax, NumericUtils.bytesToInt(packedValue, 0));
+                             double y = Geo3DUtil.decodeValueCenter(planetMax, NumericUtils.bytesToInt(packedValue, 1));
+                             double z = Geo3DUtil.decodeValueCenter(planetMax, NumericUtils.bytesToInt(packedValue, 2));
                              if (shape.isWithin(x, y, z)) {
                                result.add(docID);
                                hitCount[0]++;
@@ -121,12 +121,12 @@ public class PointInGeo3DShapeQuery extends Query {
                              // here are inclusive, we need to extend the bounds to the largest un-quantized values that
                              // could quantize into these bounds.  The encoding (Geo3DUtil.encodeValue) does
                              // a Math.round from double to long, so e.g. 1.4 -> 1, and -1.4 -> -1:
-                             double xMin = Geo3DUtil.decodeValueMin(planetMax, BKDUtil.bytesToInt(minPackedValue, 0));
-                             double xMax = Geo3DUtil.decodeValueMax(planetMax, BKDUtil.bytesToInt(maxPackedValue, 0));
-                             double yMin = Geo3DUtil.decodeValueMin(planetMax, BKDUtil.bytesToInt(minPackedValue, 1));
-                             double yMax = Geo3DUtil.decodeValueMax(planetMax, BKDUtil.bytesToInt(maxPackedValue, 1));
-                             double zMin = Geo3DUtil.decodeValueMin(planetMax, BKDUtil.bytesToInt(minPackedValue, 2));
-                             double zMax = Geo3DUtil.decodeValueMax(planetMax, BKDUtil.bytesToInt(maxPackedValue, 2));
+                             double xMin = Geo3DUtil.decodeValueMin(planetMax, NumericUtils.bytesToInt(minPackedValue, 0));
+                             double xMax = Geo3DUtil.decodeValueMax(planetMax, NumericUtils.bytesToInt(maxPackedValue, 0));
+                             double yMin = Geo3DUtil.decodeValueMin(planetMax, NumericUtils.bytesToInt(minPackedValue, 1));
+                             double yMax = Geo3DUtil.decodeValueMax(planetMax, NumericUtils.bytesToInt(maxPackedValue, 1));
+                             double zMin = Geo3DUtil.decodeValueMin(planetMax, NumericUtils.bytesToInt(minPackedValue, 2));
+                             double zMax = Geo3DUtil.decodeValueMax(planetMax, NumericUtils.bytesToInt(maxPackedValue, 2));
 
                              //System.out.println("  compare: x=" + cellXMin + "-" + cellXMax + " y=" + cellYMin + "-" + cellYMax + " z=" + cellZMin + "-" + cellZMax);
                              assert xMin <= xMax;
diff --git a/lucene/suggest/src/test/org/apache/lucene/search/suggest/document/TestSuggestField.java b/lucene/suggest/src/test/org/apache/lucene/search/suggest/document/TestSuggestField.java
index be0ac29..c7def2e 100644
--- a/lucene/suggest/src/test/org/apache/lucene/search/suggest/document/TestSuggestField.java
+++ b/lucene/suggest/src/test/org/apache/lucene/search/suggest/document/TestSuggestField.java
@@ -34,9 +34,10 @@ import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.codecs.Codec;
 import org.apache.lucene.codecs.PostingsFormat;
 import org.apache.lucene.codecs.lucene60.Lucene60Codec;
+import org.apache.lucene.document.DimensionalIntField;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
-import org.apache.lucene.document.IntField;
+import org.apache.lucene.document.StoredField;
 import org.apache.lucene.index.DirectoryReader;
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.IndexWriterConfig;
@@ -44,7 +45,7 @@ import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.Term;
-import org.apache.lucene.search.NumericRangeQuery;
+import org.apache.lucene.search.DimensionalRangeQuery;
 import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.TopDocs;
 import org.apache.lucene.search.suggest.BitsProducer;
@@ -304,7 +305,8 @@ public class TestSuggestField extends LuceneTestCase {
     for (int i = 1; i <= num; i++) {
       Document document = new Document();
       document.add(new SuggestField("suggest_field", "abc_" + i, i));
-      document.add(new IntField("weight_fld", i, Field.Store.YES));
+      document.add(new StoredField("weight_fld", i));
+      document.add(new DimensionalIntField("weight_fld", i));
       iw.addDocument(document);
 
       if (usually()) {
@@ -312,7 +314,7 @@ public class TestSuggestField extends LuceneTestCase {
       }
     }
 
-    iw.deleteDocuments(NumericRangeQuery.newIntRange("weight_fld", 2, null, true, false));
+    iw.deleteDocuments(DimensionalRangeQuery.new1DIntRange("weight_fld", 2, true, null, false));
 
     DirectoryReader reader = DirectoryReader.open(iw, true);
     SuggestIndexSearcher indexSearcher = new SuggestIndexSearcher(reader);
@@ -404,7 +406,7 @@ public class TestSuggestField extends LuceneTestCase {
         document.add(new SuggestField("suggest_field", "abc_" + i, i));
         entries.add(new Entry("abc_" + i, i));
       }
-      document.add(new IntField("weight_fld", i, Field.Store.YES));
+      document.add(new StoredField("weight_fld", i));
       iw.addDocument(document);
       if (usually()) {
         iw.commit();
@@ -430,7 +432,7 @@ public class TestSuggestField extends LuceneTestCase {
     for (int i = 0; i < num; i++) {
       Document document = new Document();
       document.add(new SuggestField("suggest_field", "abc_" + i, num));
-      document.add(new IntField("int_field", i, Field.Store.YES));
+      document.add(new StoredField("int_field", i));
       iw.addDocument(document);
 
       if (random().nextBoolean()) {
diff --git a/lucene/test-framework/src/java/org/apache/lucene/index/BaseStoredFieldsFormatTestCase.java b/lucene/test-framework/src/java/org/apache/lucene/index/BaseStoredFieldsFormatTestCase.java
index 0be6d00..c958fa2 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/index/BaseStoredFieldsFormatTestCase.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/index/BaseStoredFieldsFormatTestCase.java
@@ -34,20 +34,20 @@ import org.apache.lucene.codecs.Codec;
 import org.apache.lucene.codecs.StoredFieldsFormat;
 import org.apache.lucene.codecs.simpletext.SimpleTextCodec;
 import org.apache.lucene.document.Document;
-import org.apache.lucene.document.DoubleField;
+import org.apache.lucene.document.LegacyDoubleField;
 import org.apache.lucene.document.Field.Store;
 import org.apache.lucene.document.Field;
-import org.apache.lucene.document.FieldType.NumericType;
+import org.apache.lucene.document.FieldType.LegacyNumericType;
 import org.apache.lucene.document.FieldType;
-import org.apache.lucene.document.FloatField;
-import org.apache.lucene.document.IntField;
-import org.apache.lucene.document.LongField;
+import org.apache.lucene.document.LegacyFloatField;
+import org.apache.lucene.document.LegacyIntField;
+import org.apache.lucene.document.LegacyLongField;
 import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.document.StoredField;
 import org.apache.lucene.document.StringField;
 import org.apache.lucene.document.TextField;
 import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.NumericRangeQuery;
+import org.apache.lucene.search.LegacyNumericRangeQuery;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.search.TopDocs;
@@ -245,51 +245,51 @@ public abstract class BaseStoredFieldsFormatTestCase extends BaseIndexFileFormat
     RandomIndexWriter w = new RandomIndexWriter(random(), dir);
     final int numDocs = atLeast(500);
     final Number[] answers = new Number[numDocs];
-    final NumericType[] typeAnswers = new NumericType[numDocs];
+    final LegacyNumericType[] typeAnswers = new LegacyNumericType[numDocs];
     for(int id=0;id<numDocs;id++) {
       Document doc = new Document();
       final Field nf;
       final Field sf;
       final Number answer;
-      final NumericType typeAnswer;
+      final LegacyNumericType typeAnswer;
       if (random().nextBoolean()) {
         // float/double
         if (random().nextBoolean()) {
           final float f = random().nextFloat();
           answer = Float.valueOf(f);
-          nf = new FloatField("nf", f, Field.Store.NO);
+          nf = new LegacyFloatField("nf", f, Field.Store.NO);
           sf = new StoredField("nf", f);
-          typeAnswer = NumericType.FLOAT;
+          typeAnswer = LegacyNumericType.FLOAT;
         } else {
           final double d = random().nextDouble();
           answer = Double.valueOf(d);
-          nf = new DoubleField("nf", d, Field.Store.NO);
+          nf = new LegacyDoubleField("nf", d, Field.Store.NO);
           sf = new StoredField("nf", d);
-          typeAnswer = NumericType.DOUBLE;
+          typeAnswer = LegacyNumericType.DOUBLE;
         }
       } else {
         // int/long
         if (random().nextBoolean()) {
           final int i = random().nextInt();
           answer = Integer.valueOf(i);
-          nf = new IntField("nf", i, Field.Store.NO);
+          nf = new LegacyIntField("nf", i, Field.Store.NO);
           sf = new StoredField("nf", i);
-          typeAnswer = NumericType.INT;
+          typeAnswer = LegacyNumericType.INT;
         } else {
           final long l = random().nextLong();
           answer = Long.valueOf(l);
-          nf = new LongField("nf", l, Field.Store.NO);
+          nf = new LegacyLongField("nf", l, Field.Store.NO);
           sf = new StoredField("nf", l);
-          typeAnswer = NumericType.LONG;
+          typeAnswer = LegacyNumericType.LONG;
         }
       }
       doc.add(nf);
       doc.add(sf);
       answers[id] = answer;
       typeAnswers[id] = typeAnswer;
-      FieldType ft = new FieldType(IntField.TYPE_STORED);
+      FieldType ft = new FieldType(LegacyIntField.TYPE_STORED);
       ft.setNumericPrecisionStep(Integer.MAX_VALUE);
-      doc.add(new IntField("id", id, ft));
+      doc.add(new LegacyIntField("id", id, ft));
       doc.add(new NumericDocValuesField("id", id));
       w.addDocument(doc);
     }
@@ -349,10 +349,10 @@ public abstract class BaseStoredFieldsFormatTestCase extends BaseIndexFileFormat
     List<Field> fields = Arrays.asList(
         new Field("bytes", bytes, ft),
         new Field("string", string, ft),
-        new LongField("long", l, Store.YES),
-        new IntField("int", i, Store.YES),
-        new FloatField("float", f, Store.YES),
-        new DoubleField("double", d, Store.YES)
+        new LegacyLongField("long", l, Store.YES),
+        new LegacyIntField("int", i, Store.YES),
+        new LegacyFloatField("float", f, Store.YES),
+        new LegacyDoubleField("double", d, Store.YES)
     );
 
     for (int k = 0; k < 100; ++k) {
@@ -520,7 +520,7 @@ public abstract class BaseStoredFieldsFormatTestCase extends BaseIndexFileFormat
     final FieldType type = new FieldType(StringField.TYPE_STORED);
     type.setIndexOptions(IndexOptions.NONE);
     type.freeze();
-    IntField id = new IntField("id", 0, Store.YES);
+    LegacyIntField id = new LegacyIntField("id", 0, Store.YES);
     for (int i = 0; i < data.length; ++i) {
       Document doc = new Document();
       doc.add(id);
@@ -547,7 +547,7 @@ public abstract class BaseStoredFieldsFormatTestCase extends BaseIndexFileFormat
     for (int i = 0; i < 10; ++i) {
       final int min = random().nextInt(data.length);
       final int max = min + random().nextInt(20);
-      iw.deleteDocuments(NumericRangeQuery.newIntRange("id", min, max, true, false));
+      iw.deleteDocuments(LegacyNumericRangeQuery.newIntRange("id", min, max, true, false));
     }
 
     iw.forceMerge(2); // force merges with deletions
diff --git a/lucene/test-framework/src/java/org/apache/lucene/util/LineFileDocs.java b/lucene/test-framework/src/java/org/apache/lucene/util/LineFileDocs.java
index b84848c..6e18fd7 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/util/LineFileDocs.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/util/LineFileDocs.java
@@ -34,10 +34,10 @@ import java.util.Random;
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.zip.GZIPInputStream;
 
+import org.apache.lucene.document.DimensionalIntField;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.FieldType;
-import org.apache.lucene.document.IntField;
 import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.document.SortedDocValuesField;
 import org.apache.lucene.document.StringField;
@@ -186,7 +186,7 @@ public class LineFileDocs implements Closeable {
       id = new StringField("docid", "", Field.Store.YES);
       doc.add(id);
 
-      idNum = new IntField("docid_int", 0, Field.Store.NO);
+      idNum = new DimensionalIntField("docid_int", 0);
       doc.add(idNum);
 
       date = new StringField("date", "", Field.Store.YES);
diff --git a/lucene/test-framework/src/java/org/apache/lucene/util/TestUtil.java b/lucene/test-framework/src/java/org/apache/lucene/util/TestUtil.java
index ebd6788..d61fb6f 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/util/TestUtil.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/util/TestUtil.java
@@ -57,13 +57,14 @@ import org.apache.lucene.codecs.lucene60.Lucene60Codec;
 import org.apache.lucene.codecs.perfield.PerFieldDocValuesFormat;
 import org.apache.lucene.codecs.perfield.PerFieldPostingsFormat;
 import org.apache.lucene.document.BinaryDocValuesField;
+import org.apache.lucene.document.DimensionalBinaryField;
 import org.apache.lucene.document.Document;
-import org.apache.lucene.document.DoubleField;
 import org.apache.lucene.document.Field;
-import org.apache.lucene.document.FieldType.NumericType;
-import org.apache.lucene.document.FloatField;
-import org.apache.lucene.document.IntField;
-import org.apache.lucene.document.LongField;
+import org.apache.lucene.document.FieldType.LegacyNumericType;
+import org.apache.lucene.document.LegacyDoubleField;
+import org.apache.lucene.document.LegacyFloatField;
+import org.apache.lucene.document.LegacyIntField;
+import org.apache.lucene.document.LegacyLongField;
 import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.document.SortedDocValuesField;
 import org.apache.lucene.index.CheckIndex;
@@ -101,7 +102,6 @@ import org.junit.Assert;
 import com.carrotsearch.randomizedtesting.generators.RandomInts;
 import com.carrotsearch.randomizedtesting.generators.RandomPicks;
 
-
 /**
  * General utility methods for Lucene unit tests. 
  */
@@ -1037,7 +1037,8 @@ public final class TestUtil {
       final Field field1 = (Field) f;
       final Field field2;
       final DocValuesType dvType = field1.fieldType().docValuesType();
-      final NumericType numType = field1.fieldType().numericType();
+      final int dimCount = field1.fieldType().dimensionCount();
+      final LegacyNumericType numType = field1.fieldType().numericType();
       if (dvType != DocValuesType.NONE) {
         switch(dvType) {
           case NUMERIC:
@@ -1052,19 +1053,24 @@ public final class TestUtil {
           default:
             throw new IllegalStateException("unknown Type: " + dvType);
         }
+      } else if (dimCount != 0) {
+        BytesRef br = field1.binaryValue();
+        byte[] bytes = new byte[br.length];
+        System.arraycopy(br.bytes, br.offset, bytes, 0, br.length);
+        field2 = new DimensionalBinaryField(field1.name(), bytes, field1.fieldType());
       } else if (numType != null) {
         switch (numType) {
           case INT:
-            field2 = new IntField(field1.name(), field1.numericValue().intValue(), field1.fieldType());
+            field2 = new LegacyIntField(field1.name(), field1.numericValue().intValue(), field1.fieldType());
             break;
           case FLOAT:
-            field2 = new FloatField(field1.name(), field1.numericValue().intValue(), field1.fieldType());
+            field2 = new LegacyFloatField(field1.name(), field1.numericValue().intValue(), field1.fieldType());
             break;
           case LONG:
-            field2 = new LongField(field1.name(), field1.numericValue().intValue(), field1.fieldType());
+            field2 = new LegacyLongField(field1.name(), field1.numericValue().intValue(), field1.fieldType());
             break;
           case DOUBLE:
-            field2 = new DoubleField(field1.name(), field1.numericValue().intValue(), field1.fieldType());
+            field2 = new LegacyDoubleField(field1.name(), field1.numericValue().intValue(), field1.fieldType());
             break;
           default:
             throw new IllegalStateException("unknown Type: " + numType);
diff --git a/lucene/test-framework/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat.java b/lucene/test-framework/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat.java
index 2afda04..3e9db03 100644
--- a/lucene/test-framework/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat.java
+++ b/lucene/test-framework/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat.java
@@ -22,11 +22,10 @@ import java.util.Random;
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.codecs.Codec;
+import org.apache.lucene.document.DimensionalIntField;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
-import org.apache.lucene.document.Field.Store;
 import org.apache.lucene.document.FieldType;
-import org.apache.lucene.document.IntField;
 import org.apache.lucene.document.StoredField;
 import org.apache.lucene.index.BaseStoredFieldsFormatTestCase;
 import org.apache.lucene.index.CodecReader;
@@ -39,7 +38,6 @@ import org.apache.lucene.store.ByteArrayDataInput;
 import org.apache.lucene.store.ByteArrayDataOutput;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.MockDirectoryWrapper;
-import org.junit.Test;
 
 import com.carrotsearch.randomizedtesting.generators.RandomInts;
 
@@ -71,7 +69,8 @@ public class TestCompressingStoredFieldsFormat extends BaseStoredFieldsFormatTes
     IndexWriter iw = new IndexWriter(dir, iwConf);
 
     final Document validDoc = new Document();
-    validDoc.add(new IntField("id", 0, Store.YES));
+    validDoc.add(new DimensionalIntField("id", 0));
+    validDoc.add(new StoredField("id", 0));
     iw.addDocument(validDoc);
     iw.commit();
     
diff --git a/lucene/tools/junit4/cached-timehints.txt b/lucene/tools/junit4/cached-timehints.txt
index 7bd9f10..9c8b22a 100644
--- a/lucene/tools/junit4/cached-timehints.txt
+++ b/lucene/tools/junit4/cached-timehints.txt
@@ -762,7 +762,7 @@ org.apache.lucene.util.TestIdentityHashSet=57,60,49,59,88,67,316
 org.apache.lucene.util.TestIntsRef=6,14,10,14,13,9,19
 org.apache.lucene.util.TestMaxFailuresRule=341,775,565,386,468,1290,381
 org.apache.lucene.util.TestNamedSPILoader=30,12,21,20,26,19,7
-org.apache.lucene.util.TestNumericUtils=644,926,612,559,388,588,701
+org.apache.lucene.util.TestLegacyNumericUtils=644,926,612,559,388,588,701
 org.apache.lucene.util.TestOpenBitSet=2659,2813,1985,1741,1545,1707,1941
 org.apache.lucene.util.TestPagedBytes=7623,5417,734,1069,870,432,344
 org.apache.lucene.util.TestPriorityQueue=16,33,99,34,16,26,48
diff --git a/solr/contrib/analytics/src/java/org/apache/solr/analytics/util/AnalyticsParsers.java b/solr/contrib/analytics/src/java/org/apache/solr/analytics/util/AnalyticsParsers.java
index 320d3f5..f0b73f2 100644
--- a/solr/contrib/analytics/src/java/org/apache/solr/analytics/util/AnalyticsParsers.java
+++ b/solr/contrib/analytics/src/java/org/apache/solr/analytics/util/AnalyticsParsers.java
@@ -22,7 +22,7 @@ import java.util.Arrays;
 import java.util.Date;
 
 import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.NumericUtils;
+import org.apache.lucene.util.LegacyNumericUtils;
 import org.apache.solr.schema.FieldType;
 import org.apache.solr.schema.TrieDateField;
 import org.apache.solr.schema.TrieDoubleField;
@@ -80,7 +80,7 @@ public class AnalyticsParsers {
   public static final NumericParser INT_DOC_VALUES_PARSER = new NumericParser() {
     public String parse(BytesRef bytes) throws IOException {
       try {
-        return ""+NumericUtils.prefixCodedToInt(bytes);
+        return ""+ LegacyNumericUtils.prefixCodedToInt(bytes);
       } catch (NumberFormatException e) {
         throw new IOException("The byte array "+Arrays.toString(bytes.bytes)+" cannot be converted to an int.");
       }
@@ -97,7 +97,7 @@ public class AnalyticsParsers {
   public static final NumericParser LONG_DOC_VALUES_PARSER = new NumericParser() {
     public String parse(BytesRef bytes) throws IOException {
       try {
-        return ""+NumericUtils.prefixCodedToLong(bytes);
+        return ""+ LegacyNumericUtils.prefixCodedToLong(bytes);
       } catch (NumberFormatException e) {
         throw new IOException("The byte array "+Arrays.toString(bytes.bytes)+" cannot be converted to a long.");
       }
@@ -114,14 +114,14 @@ public class AnalyticsParsers {
   public static final NumericParser FLOAT_DOC_VALUES_PARSER = new NumericParser() {
     public String parse(BytesRef bytes) throws IOException {
       try {
-        return ""+NumericUtils.sortableIntToFloat(NumericUtils.prefixCodedToInt(bytes));
+        return ""+ LegacyNumericUtils.sortableIntToFloat(LegacyNumericUtils.prefixCodedToInt(bytes));
       } catch (NumberFormatException e) {
         throw new IOException("The byte array "+Arrays.toString(bytes.bytes)+" cannot be converted to a float.");
       }
     }
     @Override
     public String parseNum(long l) {
-      return ""+NumericUtils.sortableIntToFloat((int)l);
+      return ""+ LegacyNumericUtils.sortableIntToFloat((int) l);
     }
   };
   
@@ -131,14 +131,14 @@ public class AnalyticsParsers {
   public static final NumericParser DOUBLE_DOC_VALUES_PARSER = new NumericParser() {
     public String parse(BytesRef bytes) throws IOException {
       try {
-        return ""+NumericUtils.sortableLongToDouble(NumericUtils.prefixCodedToLong(bytes));
+        return ""+ LegacyNumericUtils.sortableLongToDouble(LegacyNumericUtils.prefixCodedToLong(bytes));
       } catch (NumberFormatException e) {
         throw new IOException("The byte array "+Arrays.toString(bytes.bytes)+" cannot be converted to a double.");
       }
     }
     @Override
     public String parseNum(long l) {
-      return ""+NumericUtils.sortableLongToDouble(l);
+      return ""+ LegacyNumericUtils.sortableLongToDouble(l);
     }
   };
   
@@ -149,7 +149,7 @@ public class AnalyticsParsers {
     @SuppressWarnings("deprecation")
     public String parse(BytesRef bytes) throws IOException {
       try {
-        return DateFormatUtil.formatExternal(new Date(NumericUtils.prefixCodedToLong(bytes)));
+        return DateFormatUtil.formatExternal(new Date(LegacyNumericUtils.prefixCodedToLong(bytes)));
       } catch (NumberFormatException e) {
         throw new IOException("The byte array "+Arrays.toString(bytes.bytes)+" cannot be converted to a date.");
       }
diff --git a/solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/DateFieldSource.java b/solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/DateFieldSource.java
index 947e811..f072417 100644
--- a/solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/DateFieldSource.java
+++ b/solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/DateFieldSource.java
@@ -29,7 +29,7 @@ import org.apache.lucene.queries.function.docvalues.LongDocValues;
 import org.apache.lucene.queries.function.valuesource.LongFieldSource;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.NumericUtils;
+import org.apache.lucene.util.LegacyNumericUtils;
 import org.apache.lucene.util.mutable.MutableValue;
 import org.apache.lucene.util.mutable.MutableValueDate;
 import org.apache.solr.util.DateFormatUtil;
@@ -45,7 +45,7 @@ public class DateFieldSource extends LongFieldSource {
   }
 
   public long externalToLong(String extVal) {
-    return NumericUtils.prefixCodedToLong(new BytesRef(extVal));
+    return LegacyNumericUtils.prefixCodedToLong(new BytesRef(extVal));
   }
 
   public Object longToObject(long val) {
diff --git a/solr/contrib/clustering/src/test-files/clustering/solr/collection1/conf/schema.xml b/solr/contrib/clustering/src/test-files/clustering/solr/collection1/conf/schema.xml
index 39b6b16..d8ad793 100644
--- a/solr/contrib/clustering/src/test-files/clustering/solr/collection1/conf/schema.xml
+++ b/solr/contrib/clustering/src/test-files/clustering/solr/collection1/conf/schema.xml
@@ -80,7 +80,7 @@
     <!--
      Numeric field types that index each value at various levels of precision
      to accelerate range queries when the number of values between the range
-     endpoints is large. See the javadoc for NumericRangeQuery for internal
+     endpoints is large. See the javadoc for LegacyNumericRangeQuery for internal
      implementation details.
 
      Smaller precisionStep values (specified in bits) will lead to more tokens
diff --git a/solr/contrib/dataimporthandler/src/test-files/dih/solr/collection1/conf/dataimport-solr_id-schema.xml b/solr/contrib/dataimporthandler/src/test-files/dih/solr/collection1/conf/dataimport-solr_id-schema.xml
index d14e497..d8cb73b 100644
--- a/solr/contrib/dataimporthandler/src/test-files/dih/solr/collection1/conf/dataimport-solr_id-schema.xml
+++ b/solr/contrib/dataimporthandler/src/test-files/dih/solr/collection1/conf/dataimport-solr_id-schema.xml
@@ -81,7 +81,7 @@
     <!--
      Numeric field types that index each value at various levels of precision
      to accelerate range queries when the number of values between the range
-     endpoints is large. See the javadoc for NumericRangeQuery for internal
+     endpoints is large. See the javadoc for LegacyNumericRangeQuery for internal
      implementation details.
 
      Smaller precisionStep values (specified in bits) will lead to more tokens
diff --git a/solr/contrib/extraction/src/test-files/extraction/solr/collection1/conf/schema.xml b/solr/contrib/extraction/src/test-files/extraction/solr/collection1/conf/schema.xml
index c8d76d8..e3dc2a8 100644
--- a/solr/contrib/extraction/src/test-files/extraction/solr/collection1/conf/schema.xml
+++ b/solr/contrib/extraction/src/test-files/extraction/solr/collection1/conf/schema.xml
@@ -39,7 +39,7 @@
     <!--
      Numeric field types that index each value at various levels of precision
      to accelerate range queries when the number of values between the range
-     endpoints is large. See the javadoc for NumericRangeQuery for internal
+     endpoints is large. See the javadoc for LegacyNumericRangeQuery for internal
      implementation details.
 
      Smaller precisionStep values (specified in bits) will lead to more tokens
diff --git a/solr/contrib/morphlines-core/src/test-files/solr/collection1/conf/schema.xml b/solr/contrib/morphlines-core/src/test-files/solr/collection1/conf/schema.xml
index 0d2c295..8ee829e 100644
--- a/solr/contrib/morphlines-core/src/test-files/solr/collection1/conf/schema.xml
+++ b/solr/contrib/morphlines-core/src/test-files/solr/collection1/conf/schema.xml
@@ -208,7 +208,7 @@
     <!--
      Numeric field types that index each value at various levels of precision
      to accelerate range queries when the number of values between the range
-     endpoints is large. See the javadoc for NumericRangeQuery for internal
+     endpoints is large. See the javadoc for LegacyNumericRangeQuery for internal
      implementation details.
 
      Smaller precisionStep values (specified in bits) will lead to more tokens
diff --git a/solr/contrib/morphlines-core/src/test-files/solr/minimr/conf/schema.xml b/solr/contrib/morphlines-core/src/test-files/solr/minimr/conf/schema.xml
index e096c17..0d8dc35 100644
--- a/solr/contrib/morphlines-core/src/test-files/solr/minimr/conf/schema.xml
+++ b/solr/contrib/morphlines-core/src/test-files/solr/minimr/conf/schema.xml
@@ -223,7 +223,7 @@
     <!--
      Numeric field types that index each value at various levels of precision
      to accelerate range queries when the number of values between the range
-     endpoints is large. See the javadoc for NumericRangeQuery for internal
+     endpoints is large. See the javadoc for LegacyNumericRangeQuery for internal
      implementation details.
 
      Smaller precisionStep values (specified in bits) will lead to more tokens
diff --git a/solr/contrib/morphlines-core/src/test-files/solr/mrunit/conf/schema.xml b/solr/contrib/morphlines-core/src/test-files/solr/mrunit/conf/schema.xml
index d18e8ce..aa0e1d8 100644
--- a/solr/contrib/morphlines-core/src/test-files/solr/mrunit/conf/schema.xml
+++ b/solr/contrib/morphlines-core/src/test-files/solr/mrunit/conf/schema.xml
@@ -223,7 +223,7 @@
     <!--
      Numeric field types that index each value at various levels of precision
      to accelerate range queries when the number of values between the range
-     endpoints is large. See the javadoc for NumericRangeQuery for internal
+     endpoints is large. See the javadoc for LegacyNumericRangeQuery for internal
      implementation details.
 
      Smaller precisionStep values (specified in bits) will lead to more tokens
diff --git a/solr/contrib/morphlines-core/src/test-files/solr/solrcelltest/collection1/conf/schema.xml b/solr/contrib/morphlines-core/src/test-files/solr/solrcelltest/collection1/conf/schema.xml
index bb71a42..29ea56e 100644
--- a/solr/contrib/morphlines-core/src/test-files/solr/solrcelltest/collection1/conf/schema.xml
+++ b/solr/contrib/morphlines-core/src/test-files/solr/solrcelltest/collection1/conf/schema.xml
@@ -175,7 +175,7 @@
     <!--
      Numeric field types that index each value at various levels of precision
      to accelerate range queries when the number of values between the range
-     endpoints is large. See the javadoc for NumericRangeQuery for internal
+     endpoints is large. See the javadoc for LegacyNumericRangeQuery for internal
      implementation details.
 
      Smaller precisionStep values (specified in bits) will lead to more tokens
diff --git a/solr/contrib/uima/src/test-files/uima/solr/collection1/conf/schema.xml b/solr/contrib/uima/src/test-files/uima/solr/collection1/conf/schema.xml
index 483fa2a..dcfadf5 100644
--- a/solr/contrib/uima/src/test-files/uima/solr/collection1/conf/schema.xml
+++ b/solr/contrib/uima/src/test-files/uima/solr/collection1/conf/schema.xml
@@ -108,7 +108,7 @@
       Numeric field types that index each value at various levels of
       precision to accelerate range queries when the number of values
       between the range endpoints is large. See the javadoc for
-      NumericRangeQuery for internal implementation details. Smaller
+      LegacyNumericRangeQuery for internal implementation details. Smaller
       precisionStep values (specified in bits) will lead to more tokens
       indexed per value, slightly larger index size, and faster range
       queries. A precisionStep of 0 disables indexing at different
diff --git a/solr/contrib/uima/src/test-files/uima/uima-tokenizers-schema.xml b/solr/contrib/uima/src/test-files/uima/uima-tokenizers-schema.xml
index 2ab8808..b88fa3b 100644
--- a/solr/contrib/uima/src/test-files/uima/uima-tokenizers-schema.xml
+++ b/solr/contrib/uima/src/test-files/uima/uima-tokenizers-schema.xml
@@ -108,7 +108,7 @@
       Numeric field types that index each value at various levels of
       precision to accelerate range queries when the number of values
       between the range endpoints is large. See the javadoc for
-      NumericRangeQuery for internal implementation details. Smaller
+      LegacyNumericRangeQuery for internal implementation details. Smaller
       precisionStep values (specified in bits) will lead to more tokens
       indexed per value, slightly larger index size, and faster range
       queries. A precisionStep of 0 disables indexing at different
diff --git a/solr/core/src/java/org/apache/solr/handler/component/StatsField.java b/solr/core/src/java/org/apache/solr/handler/component/StatsField.java
index c5f70f4..a79715e 100644
--- a/solr/core/src/java/org/apache/solr/handler/component/StatsField.java
+++ b/solr/core/src/java/org/apache/solr/handler/component/StatsField.java
@@ -30,7 +30,8 @@ import java.util.Map;
 import java.util.Set;
 
 import org.apache.commons.lang.StringUtils;
-import org.apache.lucene.document.FieldType.NumericType;
+import org.apache.lucene.document.FieldType;
+import org.apache.lucene.document.FieldType.LegacyNumericType;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.queries.function.FunctionQuery;
 import org.apache.lucene.queries.function.ValueSource;
@@ -637,17 +638,17 @@ public class StatsField {
         return null;
       }
 
-      final NumericType hashableNumType = getHashableNumericType(field);
+      final FieldType.LegacyNumericType hashableNumType = getHashableNumericType(field);
 
       // some sane defaults
       int log2m = 13;   // roughly equivilent to "cardinality='0.33'"
       int regwidth = 6; // with decent hash, this is plenty for all valid long hashes
 
-      if (NumericType.FLOAT.equals(hashableNumType) || NumericType.INT.equals(hashableNumType)) {
+      if (LegacyNumericType.FLOAT.equals(hashableNumType) || FieldType.LegacyNumericType.INT.equals(hashableNumType)) {
         // for 32bit values, we can adjust our default regwidth down a bit
         regwidth--;
 
-        // NOTE: EnumField uses NumericType.INT, and in theory we could be super conservative
+        // NOTE: EnumField uses LegacyNumericType.INT, and in theory we could be super conservative
         // with it, but there's no point - just let the EXPLICIT HLL handle it
       }
 
@@ -707,7 +708,7 @@ public class StatsField {
       if (null == hasher) {
         // if this is a function, or a non Long field, pre-hashed is invalid
         // NOTE: we ignore hashableNumType - it's LONG for non numerics like Strings
-        if (null == field || !NumericType.LONG.equals(field.getType().getNumericType())) {
+        if (null == field || !FieldType.LegacyNumericType.LONG.equals(field.getType().getNumericType())) {
           throw new SolrException(ErrorCode.BAD_REQUEST, "hllPreHashed is only supported with Long based fields");
         }
       }
@@ -740,16 +741,16 @@ public class StatsField {
   }
 
   /**
-   * Returns the effective {@link NumericType} for the field for the purposes of hash values.  
-   * ie: If the field has an explict NumericType that is returned; If the field has no explicit 
-   * NumericType then {@link NumericType#LONG} is returned;  If field is null, then 
-   * {@link NumericType#FLOAT} is assumed for ValueSource.
+   * Returns the effective {@link org.apache.lucene.document.FieldType.LegacyNumericType} for the field for the purposes of hash values.
+   * ie: If the field has an explict LegacyNumericType that is returned; If the field has no explicit
+   * LegacyNumericType then {@link org.apache.lucene.document.FieldType.LegacyNumericType#LONG} is returned;  If field is null, then
+   * {@link org.apache.lucene.document.FieldType.LegacyNumericType#FLOAT} is assumed for ValueSource.
    */
-  private static NumericType getHashableNumericType(SchemaField field) {
+  private static LegacyNumericType getHashableNumericType(SchemaField field) {
     if (null == field) {
-      return NumericType.FLOAT;
+      return LegacyNumericType.FLOAT;
     }
-    final NumericType result = field.getType().getNumericType();
-    return null == result ? NumericType.LONG : result;
+    final LegacyNumericType result = field.getType().getNumericType();
+    return null == result ? FieldType.LegacyNumericType.LONG : result;
   }
 }
diff --git a/solr/core/src/java/org/apache/solr/request/IntervalFacets.java b/solr/core/src/java/org/apache/solr/request/IntervalFacets.java
index 257b398..9be507c 100644
--- a/solr/core/src/java/org/apache/solr/request/IntervalFacets.java
+++ b/solr/core/src/java/org/apache/solr/request/IntervalFacets.java
@@ -9,7 +9,7 @@ import java.util.Iterator;
 import java.util.List;
 import java.util.Locale;
 
-import org.apache.lucene.document.FieldType.NumericType;
+import org.apache.lucene.document.FieldType.LegacyNumericType;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.DocValues;
 import org.apache.lucene.index.NumericDocValues;
@@ -19,7 +19,7 @@ import org.apache.lucene.search.DocIdSet;
 import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.NumericUtils;
+import org.apache.lucene.util.LegacyNumericUtils;
 import org.apache.solr.common.SolrException;
 import org.apache.solr.common.params.CommonParams;
 import org.apache.solr.common.params.SolrParams;
@@ -174,7 +174,7 @@ public class IntervalFacets implements Iterable<FacetInterval> {
   private void getCountNumeric() throws IOException {
     final FieldType ft = schemaField.getType();
     final String fieldName = schemaField.getName();
-    final NumericType numericType = ft.getNumericType();
+    final LegacyNumericType numericType = ft.getNumericType();
     if (numericType == null) {
       throw new IllegalStateException();
     }
@@ -555,10 +555,10 @@ public class IntervalFacets implements Iterable<FacetInterval> {
             startLimit = ((Integer) schemaField.getType().toObject(schemaField, start)).longValue();
             break;
           case FLOAT:
-            startLimit = NumericUtils.floatToSortableInt((float) schemaField.getType().toObject(schemaField, start));
+            startLimit = LegacyNumericUtils.floatToSortableInt((float) schemaField.getType().toObject(schemaField, start));
             break;
           case DOUBLE:
-            startLimit = NumericUtils.doubleToSortableLong((double) schemaField.getType().toObject(schemaField, start));
+            startLimit = LegacyNumericUtils.doubleToSortableLong((double) schemaField.getType().toObject(schemaField, start));
             break;
           default:
             throw new AssertionError();
@@ -584,10 +584,10 @@ public class IntervalFacets implements Iterable<FacetInterval> {
             endLimit = ((Integer) schemaField.getType().toObject(schemaField, end)).longValue();
             break;
           case FLOAT:
-            endLimit = NumericUtils.floatToSortableInt((float) schemaField.getType().toObject(schemaField, end));
+            endLimit = LegacyNumericUtils.floatToSortableInt((float) schemaField.getType().toObject(schemaField, end));
             break;
           case DOUBLE:
-            endLimit = NumericUtils.doubleToSortableLong((double) schemaField.getType().toObject(schemaField, end));
+            endLimit = LegacyNumericUtils.doubleToSortableLong((double) schemaField.getType().toObject(schemaField, end));
             break;
           default:
             throw new AssertionError();
@@ -754,8 +754,8 @@ public class IntervalFacets implements Iterable<FacetInterval> {
      * <li>{@link IntervalCompareResult#GREATER_THAN_END} if the value is greater than {@code endLimit}
      * <li>{@link IntervalCompareResult#LOWER_THAN_START} if the value is lower than {@code startLimit}
      * </ul>
-     * @see NumericUtils#floatToSortableInt(float)
-     * @see NumericUtils#doubleToSortableLong(double)
+     * @see org.apache.lucene.util.LegacyNumericUtils#floatToSortableInt(float)
+     * @see org.apache.lucene.util.LegacyNumericUtils#doubleToSortableLong(double)
      */
     public IntervalCompareResult includes(long value) {
       if (startLimit > value) {
diff --git a/solr/core/src/java/org/apache/solr/request/NumericFacets.java b/solr/core/src/java/org/apache/solr/request/NumericFacets.java
index d357fcf..4ccc1a3 100644
--- a/solr/core/src/java/org/apache/solr/request/NumericFacets.java
+++ b/solr/core/src/java/org/apache/solr/request/NumericFacets.java
@@ -28,7 +28,6 @@ import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
-import org.apache.lucene.document.FieldType.NumericType;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.DocValues;
 import org.apache.lucene.index.NumericDocValues;
@@ -134,7 +133,7 @@ final class NumericFacets {
     mincount = Math.max(mincount, 1);
     final SchemaField sf = searcher.getSchema().getField(fieldName);
     final FieldType ft = sf.getType();
-    final NumericType numericType = ft.getNumericType();
+    final org.apache.lucene.document.FieldType.LegacyNumericType numericType = ft.getNumericType();
     if (numericType == null) {
       throw new IllegalStateException();
     }
diff --git a/solr/core/src/java/org/apache/solr/schema/EnumField.java b/solr/core/src/java/org/apache/solr/schema/EnumField.java
index dac171e..bd82308 100644
--- a/solr/core/src/java/org/apache/solr/schema/EnumField.java
+++ b/solr/core/src/java/org/apache/solr/schema/EnumField.java
@@ -34,6 +34,7 @@ import java.util.Locale;
 import java.util.Map;
 
 import org.apache.lucene.document.FieldType;
+import org.apache.lucene.document.LegacyIntField;
 import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.document.SortedSetDocValuesField;
 import org.apache.lucene.index.IndexOptions;
@@ -42,7 +43,7 @@ import org.apache.lucene.queries.function.ValueSource;
 import org.apache.lucene.queries.function.valuesource.EnumFieldSource;
 import org.apache.lucene.search.ConstantScoreQuery;
 import org.apache.lucene.search.DocValuesRangeQuery;
-import org.apache.lucene.search.NumericRangeQuery;
+import org.apache.lucene.search.LegacyNumericRangeQuery;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.SortField;
 import org.apache.lucene.uninverting.UninvertingReader.Type;
@@ -50,7 +51,7 @@ import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
 import org.apache.lucene.util.CharsRef;
 import org.apache.lucene.util.CharsRefBuilder;
-import org.apache.lucene.util.NumericUtils;
+import org.apache.lucene.util.LegacyNumericUtils;
 import org.apache.solr.common.EnumFieldValue;
 import org.apache.solr.common.SolrException;
 import org.apache.solr.response.TextResponseWriter;
@@ -235,8 +236,8 @@ public class EnumField extends PrimitiveFieldType {
    * {@inheritDoc}
    */
   @Override
-  public FieldType.NumericType getNumericType() {
-    return FieldType.NumericType.INT;
+  public FieldType.LegacyNumericType getNumericType() {
+    return FieldType.LegacyNumericType.INT;
   }
 
   /**
@@ -259,10 +260,10 @@ public class EnumField extends PrimitiveFieldType {
               max == null ? null : maxValue.longValue(),
               minInclusive, maxInclusive));
     } else {
-      query = NumericRangeQuery.newIntRange(field.getName(), DEFAULT_PRECISION_STEP,
-              min == null ? null : minValue,
-              max == null ? null : maxValue,
-              minInclusive, maxInclusive);
+      query = LegacyNumericRangeQuery.newIntRange(field.getName(), DEFAULT_PRECISION_STEP,
+          min == null ? null : minValue,
+          max == null ? null : maxValue,
+          minInclusive, maxInclusive);
     }
 
     return query;
@@ -298,7 +299,7 @@ public class EnumField extends PrimitiveFieldType {
       return;
 
     final Integer intValue = stringValueToIntValue(s);
-    NumericUtils.intToPrefixCoded(intValue, 0, result);
+    LegacyNumericUtils.intToPrefixCoded(intValue, 0, result);
   }
 
   /**
@@ -329,7 +330,7 @@ public class EnumField extends PrimitiveFieldType {
     if (indexedForm == null)
       return null;
     final BytesRef bytesRef = new BytesRef(indexedForm);
-    final Integer intValue = NumericUtils.prefixCodedToInt(bytesRef);
+    final Integer intValue = LegacyNumericUtils.prefixCodedToInt(bytesRef);
     return intValueToStringValue(intValue);
   }
 
@@ -338,7 +339,7 @@ public class EnumField extends PrimitiveFieldType {
    */
   @Override
   public CharsRef indexedToReadable(BytesRef input, CharsRefBuilder output) {
-    final Integer intValue = NumericUtils.prefixCodedToInt(input);
+    final Integer intValue = LegacyNumericUtils.prefixCodedToInt(input);
     final String stringValue = intValueToStringValue(intValue);
     output.grow(stringValue.length());
     output.setLength(stringValue.length());
@@ -351,7 +352,7 @@ public class EnumField extends PrimitiveFieldType {
    */
   @Override
   public EnumFieldValue toObject(SchemaField sf, BytesRef term) {
-    final Integer intValue = NumericUtils.prefixCodedToInt(term);
+    final Integer intValue = LegacyNumericUtils.prefixCodedToInt(term);
     final String stringValue = intValueToStringValue(intValue);
     return new EnumFieldValue(intValue, stringValue);
   }
@@ -365,7 +366,7 @@ public class EnumField extends PrimitiveFieldType {
     if (val == null)
       return null;
     final BytesRefBuilder bytes = new BytesRefBuilder();
-    NumericUtils.intToPrefixCoded(val.intValue(), 0, bytes);
+    LegacyNumericUtils.intToPrefixCoded(val.intValue(), 0, bytes);
     return bytes.get().utf8ToString();
   }
 
@@ -398,11 +399,11 @@ public class EnumField extends PrimitiveFieldType {
     newType.setStoreTermVectorOffsets(field.storeTermOffsets());
     newType.setStoreTermVectorPositions(field.storeTermPositions());
     newType.setStoreTermVectorPayloads(field.storeTermPayloads());
-    newType.setNumericType(FieldType.NumericType.INT);
+    newType.setNumericType(FieldType.LegacyNumericType.INT);
     newType.setNumericPrecisionStep(DEFAULT_PRECISION_STEP);
 
     final org.apache.lucene.document.Field f;
-    f = new org.apache.lucene.document.IntField(field.getName(), intValue.intValue(), newType);
+    f = new LegacyIntField(field.getName(), intValue.intValue(), newType);
 
     f.setBoost(boost);
     return f;
diff --git a/solr/core/src/java/org/apache/solr/schema/ExternalFileField.java b/solr/core/src/java/org/apache/solr/schema/ExternalFileField.java
index 91f42b0..09038dd 100644
--- a/solr/core/src/java/org/apache/solr/schema/ExternalFileField.java
+++ b/solr/core/src/java/org/apache/solr/schema/ExternalFileField.java
@@ -36,7 +36,7 @@ import java.util.Map;
  * <li>It's OK for a keyField value to point to multiple documents (no uniqueness requirement)</li>
  * </ul>
  * <code>valType</code> is a reference to another fieldType to define the value type of this field
- * (must currently be TrieFloatField or FloatField (valType="pfloat|float|tfloat") if used).
+ * (must currently be TrieFloatField or LegacyFloatField (valType="pfloat|float|tfloat") if used).
  * This parameter has never been implemented. As of Solr 3.6/4.0 it is optional and can be omitted.
  *
  * The format of the external file is simply newline separated keyFieldValue=floatValue.
diff --git a/solr/core/src/java/org/apache/solr/schema/FieldType.java b/solr/core/src/java/org/apache/solr/schema/FieldType.java
index 8295758..cacadba 100644
--- a/solr/core/src/java/org/apache/solr/schema/FieldType.java
+++ b/solr/core/src/java/org/apache/solr/schema/FieldType.java
@@ -49,7 +49,6 @@ import org.apache.lucene.search.SortField;
 import org.apache.lucene.search.SortedSetSelector;
 import org.apache.lucene.search.SortedNumericSelector;
 import org.apache.lucene.search.TermQuery;
-import org.apache.lucene.search.TermRangeQuery;
 import org.apache.lucene.search.similarities.Similarity;
 import org.apache.lucene.uninverting.UninvertingReader;
 import org.apache.lucene.util.BytesRef;
@@ -612,7 +611,7 @@ public abstract class FieldType extends FieldProperties {
 
   /** Return the numeric type of this field, or null if this field is not a
    *  numeric field. */
-  public org.apache.lucene.document.FieldType.NumericType getNumericType() {
+  public org.apache.lucene.document.FieldType.LegacyNumericType getNumericType() {
     return null;
   }
 
diff --git a/solr/core/src/java/org/apache/solr/schema/TrieDoubleField.java b/solr/core/src/java/org/apache/solr/schema/TrieDoubleField.java
index 4403b1b..78ff8fd 100644
--- a/solr/core/src/java/org/apache/solr/schema/TrieDoubleField.java
+++ b/solr/core/src/java/org/apache/solr/schema/TrieDoubleField.java
@@ -30,7 +30,7 @@ import org.apache.lucene.queries.function.docvalues.DoubleDocValues;
 import org.apache.lucene.queries.function.valuesource.SortedSetFieldSource;
 import org.apache.lucene.search.SortedSetSelector;
 import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.NumericUtils;
+import org.apache.lucene.util.LegacyNumericUtils;
 import org.apache.lucene.util.mutable.MutableValue;
 import org.apache.lucene.util.mutable.MutableValueDouble;
 
@@ -83,7 +83,7 @@ public class TrieDoubleField extends TrieField implements DoubleValueFieldType {
               assert !exists(doc) : "zero bytes for doc, but exists is true";
               return 0D;
             }
-            return  NumericUtils.sortableLongToDouble(NumericUtils.prefixCodedToLong(bytes));
+            return  LegacyNumericUtils.sortableLongToDouble(LegacyNumericUtils.prefixCodedToLong(bytes));
           }
 
           @Override
@@ -108,7 +108,7 @@ public class TrieDoubleField extends TrieField implements DoubleValueFieldType {
                 //mval.value = mval.exists ? doubleVal(doc) : 0.0D;
                 BytesRef bytes = view.get(doc);
                 mval.exists = (0 == bytes.length);
-                mval.value = mval.exists ? NumericUtils.sortableLongToDouble(NumericUtils.prefixCodedToLong(bytes)) : 0D;
+                mval.value = mval.exists ? LegacyNumericUtils.sortableLongToDouble(LegacyNumericUtils.prefixCodedToLong(bytes)) : 0D;
               }
             };
           }
diff --git a/solr/core/src/java/org/apache/solr/schema/TrieField.java b/solr/core/src/java/org/apache/solr/schema/TrieField.java
index f3d9f55..60f538d 100644
--- a/solr/core/src/java/org/apache/solr/schema/TrieField.java
+++ b/solr/core/src/java/org/apache/solr/schema/TrieField.java
@@ -25,12 +25,12 @@ import java.util.List;
 import java.util.Locale;
 import java.util.Map;
 
-import org.apache.lucene.document.DoubleField;
+import org.apache.lucene.document.LegacyDoubleField;
 import org.apache.lucene.document.FieldType;
-import org.apache.lucene.document.FieldType.NumericType;
-import org.apache.lucene.document.FloatField;
-import org.apache.lucene.document.IntField;
-import org.apache.lucene.document.LongField;
+import org.apache.lucene.document.FieldType.LegacyNumericType;
+import org.apache.lucene.document.LegacyFloatField;
+import org.apache.lucene.document.LegacyIntField;
+import org.apache.lucene.document.LegacyLongField;
 import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.document.SortedSetDocValuesField;
 import org.apache.lucene.index.IndexOptions;
@@ -41,7 +41,7 @@ import org.apache.lucene.queries.function.valuesource.FloatFieldSource;
 import org.apache.lucene.queries.function.valuesource.IntFieldSource;
 import org.apache.lucene.queries.function.valuesource.LongFieldSource;
 import org.apache.lucene.search.DocValuesRangeQuery;
-import org.apache.lucene.search.NumericRangeQuery;
+import org.apache.lucene.search.LegacyNumericRangeQuery;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.SortedSetSelector;
 import org.apache.lucene.search.SortField;
@@ -50,7 +50,7 @@ import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
 import org.apache.lucene.util.CharsRef;
 import org.apache.lucene.util.CharsRefBuilder;
-import org.apache.lucene.util.NumericUtils;
+import org.apache.lucene.util.LegacyNumericUtils;
 import org.apache.lucene.util.mutable.MutableValueDate;
 import org.apache.lucene.util.mutable.MutableValueLong;
 import org.apache.solr.common.SolrException;
@@ -62,9 +62,9 @@ import org.slf4j.LoggerFactory;
 
 /**
  * Provides field types to support for Lucene's {@link
- * IntField}, {@link LongField}, {@link FloatField} and
- * {@link DoubleField}.
- * See {@link org.apache.lucene.search.NumericRangeQuery} for more details.
+ * org.apache.lucene.document.LegacyIntField}, {@link org.apache.lucene.document.LegacyLongField}, {@link org.apache.lucene.document.LegacyFloatField} and
+ * {@link org.apache.lucene.document.LegacyDoubleField}.
+ * See {@link org.apache.lucene.search.LegacyNumericRangeQuery} for more details.
  * It supports integer, float, long, double and date types.
  * <p>
  * For each number being added to this field, multiple terms are generated as per the algorithm described in the above
@@ -77,7 +77,7 @@ import org.slf4j.LoggerFactory;
  * generated, range search will be no faster than any other number field, but sorting will still be possible.
  *
  *
- * @see org.apache.lucene.search.NumericRangeQuery
+ * @see org.apache.lucene.search.LegacyNumericRangeQuery
  * @since solr 1.4
  */
 public class TrieField extends PrimitiveFieldType {
@@ -324,17 +324,17 @@ public class TrieField extends PrimitiveFieldType {
   }
 
   @Override
-  public NumericType getNumericType() {
+  public FieldType.LegacyNumericType getNumericType() {
     switch (type) {
       case INTEGER:
-        return NumericType.INT;
+        return FieldType.LegacyNumericType.INT;
       case LONG:
       case DATE:
-        return NumericType.LONG;
+        return FieldType.LegacyNumericType.LONG;
       case FLOAT:
-        return NumericType.FLOAT;
+        return FieldType.LegacyNumericType.FLOAT;
       case DOUBLE:
-        return NumericType.DOUBLE;
+        return FieldType.LegacyNumericType.DOUBLE;
       default:
         throw new AssertionError();
     }
@@ -357,23 +357,23 @@ public class TrieField extends PrimitiveFieldType {
                 max == null ? null : (long) Integer.parseInt(max),
                 minInclusive, maxInclusive);
         } else {
-          query = NumericRangeQuery.newIntRange(field.getName(), ps,
-                min == null ? null : Integer.parseInt(min),
-                max == null ? null : Integer.parseInt(max),
-                minInclusive, maxInclusive);
+          query = LegacyNumericRangeQuery.newIntRange(field.getName(), ps,
+              min == null ? null : Integer.parseInt(min),
+              max == null ? null : Integer.parseInt(max),
+              minInclusive, maxInclusive);
         }
         break;
       case FLOAT:
         if (matchOnly) {
           query = DocValuesRangeQuery.newLongRange(field.getName(),
-                min == null ? null : (long) NumericUtils.floatToSortableInt(Float.parseFloat(min)),
-                max == null ? null : (long) NumericUtils.floatToSortableInt(Float.parseFloat(max)),
+                min == null ? null : (long) LegacyNumericUtils.floatToSortableInt(Float.parseFloat(min)),
+                max == null ? null : (long) LegacyNumericUtils.floatToSortableInt(Float.parseFloat(max)),
                 minInclusive, maxInclusive);
         } else {
-          query = NumericRangeQuery.newFloatRange(field.getName(), ps,
-                min == null ? null : Float.parseFloat(min),
-                max == null ? null : Float.parseFloat(max),
-                minInclusive, maxInclusive);
+          query = LegacyNumericRangeQuery.newFloatRange(field.getName(), ps,
+              min == null ? null : Float.parseFloat(min),
+              max == null ? null : Float.parseFloat(max),
+              minInclusive, maxInclusive);
         }
         break;
       case LONG:
@@ -383,23 +383,23 @@ public class TrieField extends PrimitiveFieldType {
                 max == null ? null : Long.parseLong(max),
                 minInclusive, maxInclusive);
         } else {
-          query = NumericRangeQuery.newLongRange(field.getName(), ps,
-                min == null ? null : Long.parseLong(min),
-                max == null ? null : Long.parseLong(max),
-                minInclusive, maxInclusive);
+          query = LegacyNumericRangeQuery.newLongRange(field.getName(), ps,
+              min == null ? null : Long.parseLong(min),
+              max == null ? null : Long.parseLong(max),
+              minInclusive, maxInclusive);
         }
         break;
       case DOUBLE:
         if (matchOnly) {
           query = DocValuesRangeQuery.newLongRange(field.getName(),
-                min == null ? null : NumericUtils.doubleToSortableLong(Double.parseDouble(min)),
-                max == null ? null : NumericUtils.doubleToSortableLong(Double.parseDouble(max)),
+                min == null ? null : LegacyNumericUtils.doubleToSortableLong(Double.parseDouble(min)),
+                max == null ? null : LegacyNumericUtils.doubleToSortableLong(Double.parseDouble(max)),
                 minInclusive, maxInclusive);
         } else {
-          query = NumericRangeQuery.newDoubleRange(field.getName(), ps,
-                min == null ? null : Double.parseDouble(min),
-                max == null ? null : Double.parseDouble(max),
-                minInclusive, maxInclusive);
+          query = LegacyNumericRangeQuery.newDoubleRange(field.getName(), ps,
+              min == null ? null : Double.parseDouble(min),
+              max == null ? null : Double.parseDouble(max),
+              minInclusive, maxInclusive);
         }
         break;
       case DATE:
@@ -409,10 +409,10 @@ public class TrieField extends PrimitiveFieldType {
                 max == null ? null : DateFormatUtil.parseMath(null, max).getTime(),
                 minInclusive, maxInclusive);
         } else {
-          query = NumericRangeQuery.newLongRange(field.getName(), ps,
-                min == null ? null : DateFormatUtil.parseMath(null, min).getTime(),
-                max == null ? null : DateFormatUtil.parseMath(null, max).getTime(),
-                minInclusive, maxInclusive);
+          query = LegacyNumericRangeQuery.newLongRange(field.getName(), ps,
+              min == null ? null : DateFormatUtil.parseMath(null, min).getTime(),
+              max == null ? null : DateFormatUtil.parseMath(null, max).getTime(),
+              minInclusive, maxInclusive);
         }
         break;
       default:
@@ -463,19 +463,19 @@ public class TrieField extends PrimitiveFieldType {
     try {
       switch (type) {
         case INTEGER:
-          NumericUtils.intToPrefixCodedBytes(Integer.parseInt(s), 0, result);
+          LegacyNumericUtils.intToPrefixCodedBytes(Integer.parseInt(s), 0, result);
           break;
         case FLOAT:
-          NumericUtils.intToPrefixCodedBytes(NumericUtils.floatToSortableInt(Float.parseFloat(s)), 0, result);
+          LegacyNumericUtils.intToPrefixCodedBytes(LegacyNumericUtils.floatToSortableInt(Float.parseFloat(s)), 0, result);
           break;
         case LONG:
-          NumericUtils.longToPrefixCodedBytes(Long.parseLong(s), 0, result);
+          LegacyNumericUtils.longToPrefixCodedBytes(Long.parseLong(s), 0, result);
           break;
         case DOUBLE:
-          NumericUtils.longToPrefixCodedBytes(NumericUtils.doubleToSortableLong(Double.parseDouble(s)), 0, result);
+          LegacyNumericUtils.longToPrefixCodedBytes(LegacyNumericUtils.doubleToSortableLong(Double.parseDouble(s)), 0, result);
           break;
         case DATE:
-          NumericUtils.longToPrefixCodedBytes(DateFormatUtil.parseMath(null, s).getTime(), 0, result);
+          LegacyNumericUtils.longToPrefixCodedBytes(DateFormatUtil.parseMath(null, s).getTime(), 0, result);
           break;
         default:
           throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, "Unknown type for trie field: " + type);
@@ -508,15 +508,15 @@ public class TrieField extends PrimitiveFieldType {
     final BytesRef indexedForm = new BytesRef(_indexedForm);
     switch (type) {
       case INTEGER:
-        return Integer.toString( NumericUtils.prefixCodedToInt(indexedForm) );
+        return Integer.toString( LegacyNumericUtils.prefixCodedToInt(indexedForm) );
       case FLOAT:
-        return Float.toString( NumericUtils.sortableIntToFloat(NumericUtils.prefixCodedToInt(indexedForm)) );
+        return Float.toString( LegacyNumericUtils.sortableIntToFloat(LegacyNumericUtils.prefixCodedToInt(indexedForm)) );
       case LONG:
-        return Long.toString( NumericUtils.prefixCodedToLong(indexedForm) );
+        return Long.toString( LegacyNumericUtils.prefixCodedToLong(indexedForm) );
       case DOUBLE:
-        return Double.toString( NumericUtils.sortableLongToDouble(NumericUtils.prefixCodedToLong(indexedForm)) );
+        return Double.toString( LegacyNumericUtils.sortableLongToDouble(LegacyNumericUtils.prefixCodedToLong(indexedForm)) );
       case DATE:
-        return DateFormatUtil.formatExternal(new Date(NumericUtils.prefixCodedToLong(indexedForm)));
+        return DateFormatUtil.formatExternal(new Date(LegacyNumericUtils.prefixCodedToLong(indexedForm)));
       default:
         throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, "Unknown type for trie field: " + type);
     }
@@ -527,19 +527,19 @@ public class TrieField extends PrimitiveFieldType {
     final String value;
     switch (type) {
       case INTEGER:
-        value = Integer.toString( NumericUtils.prefixCodedToInt(indexedForm) );
+        value = Integer.toString( LegacyNumericUtils.prefixCodedToInt(indexedForm) );
         break;
       case FLOAT:
-        value = Float.toString( NumericUtils.sortableIntToFloat(NumericUtils.prefixCodedToInt(indexedForm)) );
+        value = Float.toString( LegacyNumericUtils.sortableIntToFloat(LegacyNumericUtils.prefixCodedToInt(indexedForm)) );
         break;
       case LONG:
-        value = Long.toString( NumericUtils.prefixCodedToLong(indexedForm) );
+        value = Long.toString( LegacyNumericUtils.prefixCodedToLong(indexedForm) );
         break;
       case DOUBLE:
-        value = Double.toString( NumericUtils.sortableLongToDouble(NumericUtils.prefixCodedToLong(indexedForm)) );
+        value = Double.toString( LegacyNumericUtils.sortableLongToDouble(LegacyNumericUtils.prefixCodedToLong(indexedForm)) );
         break;
       case DATE:
-        value = DateFormatUtil.formatExternal(new Date(NumericUtils.prefixCodedToLong(indexedForm)));
+        value = DateFormatUtil.formatExternal(new Date(LegacyNumericUtils.prefixCodedToLong(indexedForm)));
         break;
       default:
         throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, "Unknown type for trie field: " + type);
@@ -554,15 +554,15 @@ public class TrieField extends PrimitiveFieldType {
   public Object toObject(SchemaField sf, BytesRef term) {
     switch (type) {
       case INTEGER:
-        return NumericUtils.prefixCodedToInt(term);
+        return LegacyNumericUtils.prefixCodedToInt(term);
       case FLOAT:
-        return NumericUtils.sortableIntToFloat(NumericUtils.prefixCodedToInt(term));
+        return LegacyNumericUtils.sortableIntToFloat(LegacyNumericUtils.prefixCodedToInt(term));
       case LONG:
-        return NumericUtils.prefixCodedToLong(term);
+        return LegacyNumericUtils.prefixCodedToLong(term);
       case DOUBLE:
-        return NumericUtils.sortableLongToDouble(NumericUtils.prefixCodedToLong(term));
+        return LegacyNumericUtils.sortableLongToDouble(LegacyNumericUtils.prefixCodedToLong(term));
       case DATE:
-        return new Date(NumericUtils.prefixCodedToLong(term));
+        return new Date(LegacyNumericUtils.prefixCodedToLong(term));
       default:
         throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, "Unknown type for trie field: " + type);
     }
@@ -580,17 +580,17 @@ public class TrieField extends PrimitiveFieldType {
     if (val != null) {
       switch (type) {
         case INTEGER:
-          NumericUtils.intToPrefixCodedBytes(val.intValue(), 0, bytes);
+          LegacyNumericUtils.intToPrefixCodedBytes(val.intValue(), 0, bytes);
           break;
         case FLOAT:
-          NumericUtils.intToPrefixCodedBytes(NumericUtils.floatToSortableInt(val.floatValue()), 0, bytes);
+          LegacyNumericUtils.intToPrefixCodedBytes(LegacyNumericUtils.floatToSortableInt(val.floatValue()), 0, bytes);
           break;
         case LONG: //fallthrough!
         case DATE:
-          NumericUtils.longToPrefixCodedBytes(val.longValue(), 0, bytes);
+          LegacyNumericUtils.longToPrefixCodedBytes(val.longValue(), 0, bytes);
           break;
         case DOUBLE:
-          NumericUtils.longToPrefixCodedBytes(NumericUtils.doubleToSortableLong(val.doubleValue()), 0, bytes);
+          LegacyNumericUtils.longToPrefixCodedBytes(LegacyNumericUtils.doubleToSortableLong(val.doubleValue()), 0, bytes);
           break;
         default:
           throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, "Unknown type for trie field: " + f.name());
@@ -602,28 +602,28 @@ public class TrieField extends PrimitiveFieldType {
         throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, "Invalid field contents: "+f.name());
       switch (type) {
         case INTEGER:
-          NumericUtils.intToPrefixCodedBytes(toInt(bytesRef.bytes, bytesRef.offset), 0, bytes);
+          LegacyNumericUtils.intToPrefixCodedBytes(toInt(bytesRef.bytes, bytesRef.offset), 0, bytes);
           break;
         case FLOAT: {
-          // WARNING: Code Duplication! Keep in sync with o.a.l.util.NumericUtils!
-          // copied from NumericUtils to not convert to/from float two times
-          // code in next 2 lines is identical to: int v = NumericUtils.floatToSortableInt(Float.intBitsToFloat(toInt(arr)));
+          // WARNING: Code Duplication! Keep in sync with o.a.l.util.LegacyNumericUtils!
+          // copied from LegacyNumericUtils to not convert to/from float two times
+          // code in next 2 lines is identical to: int v = LegacyNumericUtils.floatToSortableInt(Float.intBitsToFloat(toInt(arr)));
           int v = toInt(bytesRef.bytes, bytesRef.offset);
           if (v<0) v ^= 0x7fffffff;
-          NumericUtils.intToPrefixCodedBytes(v, 0, bytes);
+          LegacyNumericUtils.intToPrefixCodedBytes(v, 0, bytes);
           break;
         }
         case LONG: //fallthrough!
         case DATE:
-          NumericUtils.longToPrefixCodedBytes(toLong(bytesRef.bytes, bytesRef.offset), 0, bytes);
+          LegacyNumericUtils.longToPrefixCodedBytes(toLong(bytesRef.bytes, bytesRef.offset), 0, bytes);
           break;
         case DOUBLE: {
-          // WARNING: Code Duplication! Keep in sync with o.a.l.util.NumericUtils!
-          // copied from NumericUtils to not convert to/from double two times
-          // code in next 2 lines is identical to: long v = NumericUtils.doubleToSortableLong(Double.longBitsToDouble(toLong(arr)));
+          // WARNING: Code Duplication! Keep in sync with o.a.l.util.LegacyNumericUtils!
+          // copied from LegacyNumericUtils to not convert to/from double two times
+          // code in next 2 lines is identical to: long v = LegacyNumericUtils.doubleToSortableLong(Double.longBitsToDouble(toLong(arr)));
           long v = toLong(bytesRef.bytes, bytesRef.offset);
           if (v<0) v ^= 0x7fffffffffffffffL;
-          NumericUtils.longToPrefixCodedBytes(v, 0, bytes);
+          LegacyNumericUtils.longToPrefixCodedBytes(v, 0, bytes);
           break;
         }
         default:
@@ -652,19 +652,19 @@ public class TrieField extends PrimitiveFieldType {
 
     switch (type) {
       case INTEGER:
-        ft.setNumericType(NumericType.INT);
+        ft.setNumericType(LegacyNumericType.INT);
         break;
       case FLOAT:
-        ft.setNumericType(NumericType.FLOAT);
+        ft.setNumericType(FieldType.LegacyNumericType.FLOAT);
         break;
       case LONG:
-        ft.setNumericType(NumericType.LONG);
+        ft.setNumericType(FieldType.LegacyNumericType.LONG);
         break;
       case DOUBLE:
-        ft.setNumericType(NumericType.DOUBLE);
+        ft.setNumericType(FieldType.LegacyNumericType.DOUBLE);
         break;
       case DATE:
-        ft.setNumericType(NumericType.LONG);
+        ft.setNumericType(FieldType.LegacyNumericType.LONG);
         break;
       default:
         throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, "Unknown type for trie field: " + type);
@@ -678,31 +678,31 @@ public class TrieField extends PrimitiveFieldType {
         int i = (value instanceof Number)
           ? ((Number)value).intValue()
           : Integer.parseInt(value.toString());
-        f = new org.apache.lucene.document.IntField(field.getName(), i, ft);
+        f = new LegacyIntField(field.getName(), i, ft);
         break;
       case FLOAT:
         float fl = (value instanceof Number)
           ? ((Number)value).floatValue()
           : Float.parseFloat(value.toString());
-        f = new org.apache.lucene.document.FloatField(field.getName(), fl, ft);
+        f = new LegacyFloatField(field.getName(), fl, ft);
         break;
       case LONG:
         long l = (value instanceof Number)
           ? ((Number)value).longValue()
           : Long.parseLong(value.toString());
-        f = new org.apache.lucene.document.LongField(field.getName(), l, ft);
+        f = new LegacyLongField(field.getName(), l, ft);
         break;
       case DOUBLE:
         double d = (value instanceof Number)
           ? ((Number)value).doubleValue()
           : Double.parseDouble(value.toString());
-        f = new org.apache.lucene.document.DoubleField(field.getName(), d, ft);
+        f = new LegacyDoubleField(field.getName(), d, ft);
         break;
       case DATE:
         Date date = (value instanceof Date)
           ? ((Date)value)
           : DateFormatUtil.parseMath(null, value.toString());
-        f = new org.apache.lucene.document.LongField(field.getName(), date.getTime(), ft);
+        f = new LegacyLongField(field.getName(), date.getTime(), ft);
         break;
       default:
         throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, "Unknown type for trie field: " + type);
@@ -751,8 +751,8 @@ public class TrieField extends PrimitiveFieldType {
   }
 
 
-  static final String INT_PREFIX = new String(new char[]{NumericUtils.SHIFT_START_INT});
-  static final String LONG_PREFIX = new String(new char[]{NumericUtils.SHIFT_START_LONG});
+  static final String INT_PREFIX = new String(new char[]{LegacyNumericUtils.SHIFT_START_INT});
+  static final String LONG_PREFIX = new String(new char[]{LegacyNumericUtils.SHIFT_START_LONG});
 
   /** expert internal use, subject to change.
    * Returns null if no prefix or prefix not needed, or the prefix of the main value of a trie field
diff --git a/solr/core/src/java/org/apache/solr/schema/TrieFloatField.java b/solr/core/src/java/org/apache/solr/schema/TrieFloatField.java
index 7a06fca..2b3f741 100644
--- a/solr/core/src/java/org/apache/solr/schema/TrieFloatField.java
+++ b/solr/core/src/java/org/apache/solr/schema/TrieFloatField.java
@@ -30,7 +30,7 @@ import org.apache.lucene.queries.function.docvalues.FloatDocValues;
 import org.apache.lucene.queries.function.valuesource.SortedSetFieldSource;
 import org.apache.lucene.search.SortedSetSelector;
 import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.NumericUtils;
+import org.apache.lucene.util.LegacyNumericUtils;
 import org.apache.lucene.util.mutable.MutableValue;
 import org.apache.lucene.util.mutable.MutableValueFloat;
 
@@ -83,7 +83,7 @@ public class TrieFloatField extends TrieField implements FloatValueFieldType {
               assert !exists(doc) : "zero bytes for doc, but exists is true";
               return 0F;
             }
-            return  NumericUtils.sortableIntToFloat(NumericUtils.prefixCodedToInt(bytes));
+            return  LegacyNumericUtils.sortableIntToFloat(LegacyNumericUtils.prefixCodedToInt(bytes));
           }
 
           @Override
@@ -109,7 +109,7 @@ public class TrieFloatField extends TrieField implements FloatValueFieldType {
                 //
                 BytesRef bytes = view.get(doc);
                 mval.exists = (0 == bytes.length);
-                mval.value = mval.exists ? NumericUtils.sortableIntToFloat(NumericUtils.prefixCodedToInt(bytes)) : 0F;
+                mval.value = mval.exists ? LegacyNumericUtils.sortableIntToFloat(LegacyNumericUtils.prefixCodedToInt(bytes)) : 0F;
               }
             };
           }
diff --git a/solr/core/src/java/org/apache/solr/schema/TrieIntField.java b/solr/core/src/java/org/apache/solr/schema/TrieIntField.java
index cee0ea6..6ef7b89 100644
--- a/solr/core/src/java/org/apache/solr/schema/TrieIntField.java
+++ b/solr/core/src/java/org/apache/solr/schema/TrieIntField.java
@@ -30,7 +30,7 @@ import org.apache.lucene.queries.function.docvalues.IntDocValues;
 import org.apache.lucene.queries.function.valuesource.SortedSetFieldSource;
 import org.apache.lucene.search.SortedSetSelector;
 import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.NumericUtils;
+import org.apache.lucene.util.LegacyNumericUtils;
 import org.apache.lucene.util.mutable.MutableValue;
 import org.apache.lucene.util.mutable.MutableValueInt;
 
@@ -82,7 +82,7 @@ public class TrieIntField extends TrieField implements IntValueFieldType {
               assert !exists(doc) : "zero bytes for doc, but exists is true";
               return 0;
             }
-            return NumericUtils.prefixCodedToInt(bytes);
+            return LegacyNumericUtils.prefixCodedToInt(bytes);
           }
 
           @Override
@@ -108,7 +108,7 @@ public class TrieIntField extends TrieField implements IntValueFieldType {
                 //
                 BytesRef bytes = view.get(doc);
                 mval.exists = (0 == bytes.length);
-                mval.value = mval.exists ? NumericUtils.prefixCodedToInt(bytes) : 0;
+                mval.value = mval.exists ? LegacyNumericUtils.prefixCodedToInt(bytes) : 0;
               }
             };
           }
diff --git a/solr/core/src/java/org/apache/solr/schema/TrieLongField.java b/solr/core/src/java/org/apache/solr/schema/TrieLongField.java
index 3eb5de5..d255a3a 100644
--- a/solr/core/src/java/org/apache/solr/schema/TrieLongField.java
+++ b/solr/core/src/java/org/apache/solr/schema/TrieLongField.java
@@ -30,7 +30,7 @@ import org.apache.lucene.queries.function.docvalues.LongDocValues;
 import org.apache.lucene.queries.function.valuesource.SortedSetFieldSource;
 import org.apache.lucene.search.SortedSetSelector;
 import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.NumericUtils;
+import org.apache.lucene.util.LegacyNumericUtils;
 import org.apache.lucene.util.mutable.MutableValue;
 import org.apache.lucene.util.mutable.MutableValueLong;
 
@@ -82,7 +82,7 @@ public class TrieLongField extends TrieField implements LongValueFieldType {
               assert !exists(doc) : "zero bytes for doc, but exists is true";
               return 0L;
             }
-            return NumericUtils.prefixCodedToLong(bytes);
+            return LegacyNumericUtils.prefixCodedToLong(bytes);
           }
 
           @Override
@@ -108,7 +108,7 @@ public class TrieLongField extends TrieField implements LongValueFieldType {
                 //
                 BytesRef bytes = view.get(doc);
                 mval.exists = (0 == bytes.length);
-                mval.value = mval.exists ? NumericUtils.prefixCodedToLong(bytes) : 0L;
+                mval.value = mval.exists ? LegacyNumericUtils.prefixCodedToLong(bytes) : 0L;
               }
             };
           }
diff --git a/solr/core/src/java/org/apache/solr/search/QueryParsing.java b/solr/core/src/java/org/apache/solr/search/QueryParsing.java
index c2f4f43..47c49d8 100644
--- a/solr/core/src/java/org/apache/solr/search/QueryParsing.java
+++ b/solr/core/src/java/org/apache/solr/search/QueryParsing.java
@@ -23,7 +23,7 @@ import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.BoostQuery;
 import org.apache.lucene.search.ConstantScoreQuery;
 import org.apache.lucene.search.FuzzyQuery;
-import org.apache.lucene.search.NumericRangeQuery;
+import org.apache.lucene.search.LegacyNumericRangeQuery;
 import org.apache.lucene.search.PrefixQuery;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.TermQuery;
@@ -293,8 +293,8 @@ public class QueryParsing {
       }
 
       out.append(q.includesUpper() ? ']' : '}');
-    } else if (query instanceof NumericRangeQuery) {
-      NumericRangeQuery q = (NumericRangeQuery) query;
+    } else if (query instanceof LegacyNumericRangeQuery) {
+      LegacyNumericRangeQuery q = (LegacyNumericRangeQuery) query;
       String fname = q.getField();
       FieldType ft = writeFieldName(fname, schema, out, flags);
       out.append(q.includesMin() ? '[' : '{');
diff --git a/solr/core/src/java/org/apache/solr/search/QueryWrapperFilter.java b/solr/core/src/java/org/apache/solr/search/QueryWrapperFilter.java
index 017c5e0..80840a4 100644
--- a/solr/core/src/java/org/apache/solr/search/QueryWrapperFilter.java
+++ b/solr/core/src/java/org/apache/solr/search/QueryWrapperFilter.java
@@ -26,7 +26,6 @@ import org.apache.lucene.search.ConstantScoreQuery;
 import org.apache.lucene.search.DocIdSet;
 import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.NumericRangeQuery;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.Scorer;
 import org.apache.lucene.search.Weight;
@@ -36,7 +35,7 @@ import org.apache.lucene.util.Bits;
  * Constrains search results to only match those which also match a provided
  * query.  
  *
- * <p> This could be used, for example, with a {@link NumericRangeQuery} on a suitably
+ * <p> This could be used, for example, with a {@link org.apache.lucene.search.LegacyNumericRangeQuery} on a suitably
  * formatted date field to implement date filtering.  One could re-use a single
  * CachingWrapperFilter(QueryWrapperFilter) that matches, e.g., only documents modified 
  * within the last week.  This would only need to be reconstructed once per day.
diff --git a/solr/core/src/java/org/apache/solr/search/SolrIndexSearcher.java b/solr/core/src/java/org/apache/solr/search/SolrIndexSearcher.java
index 832b34f..ca5e695 100644
--- a/solr/core/src/java/org/apache/solr/search/SolrIndexSearcher.java
+++ b/solr/core/src/java/org/apache/solr/search/SolrIndexSearcher.java
@@ -37,13 +37,13 @@ import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicLong;
 
 import org.apache.lucene.document.Document;
-import org.apache.lucene.document.DoubleField;
+import org.apache.lucene.document.LegacyDoubleField;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.FieldType;
-import org.apache.lucene.document.FloatField;
-import org.apache.lucene.document.IntField;
+import org.apache.lucene.document.LegacyFloatField;
+import org.apache.lucene.document.LegacyIntField;
 import org.apache.lucene.document.LazyDocument;
-import org.apache.lucene.document.LongField;
+import org.apache.lucene.document.LegacyLongField;
 import org.apache.lucene.document.StoredField;
 import org.apache.lucene.document.TextField;
 import org.apache.lucene.index.DirectoryReader;
@@ -635,34 +635,34 @@ public class SolrIndexSearcher extends IndexSearcher implements Closeable,SolrIn
 
     @Override
     public void intField(FieldInfo fieldInfo, int value) {
-      FieldType ft = new FieldType(IntField.TYPE_NOT_STORED);
+      FieldType ft = new FieldType(LegacyIntField.TYPE_NOT_STORED);
       ft.setStored(true);
       ft.setIndexOptions(fieldInfo.getIndexOptions());
-      doc.add(new IntField(fieldInfo.name, value, ft));
+      doc.add(new LegacyIntField(fieldInfo.name, value, ft));
     }
 
     @Override
     public void longField(FieldInfo fieldInfo, long value) {
-      FieldType ft = new FieldType(LongField.TYPE_NOT_STORED);
+      FieldType ft = new FieldType(LegacyLongField.TYPE_NOT_STORED);
       ft.setStored(true);
       ft.setIndexOptions(fieldInfo.getIndexOptions());
-      doc.add(new LongField(fieldInfo.name, value, ft));
+      doc.add(new LegacyLongField(fieldInfo.name, value, ft));
     }
 
     @Override
     public void floatField(FieldInfo fieldInfo, float value) {
-      FieldType ft = new FieldType(FloatField.TYPE_NOT_STORED);
+      FieldType ft = new FieldType(LegacyFloatField.TYPE_NOT_STORED);
       ft.setStored(true);
       ft.setIndexOptions(fieldInfo.getIndexOptions());
-      doc.add(new FloatField(fieldInfo.name, value, ft));
+      doc.add(new LegacyFloatField(fieldInfo.name, value, ft));
     }
 
     @Override
     public void doubleField(FieldInfo fieldInfo, double value) {
-      FieldType ft = new FieldType(DoubleField.TYPE_NOT_STORED);
+      FieldType ft = new FieldType(LegacyDoubleField.TYPE_NOT_STORED);
       ft.setStored(true);
       ft.setIndexOptions(fieldInfo.getIndexOptions());
-      doc.add(new DoubleField(fieldInfo.name, value, ft));
+      doc.add(new LegacyDoubleField(fieldInfo.name, value, ft));
     }
   }
 
diff --git a/solr/core/src/java/org/apache/solr/search/facet/FacetField.java b/solr/core/src/java/org/apache/solr/search/facet/FacetField.java
index 6ef6b26..6213003 100644
--- a/solr/core/src/java/org/apache/solr/search/facet/FacetField.java
+++ b/solr/core/src/java/org/apache/solr/search/facet/FacetField.java
@@ -26,24 +26,18 @@ import java.util.LinkedHashMap;
 import java.util.List;
 import java.util.Map;
 
-import org.apache.lucene.index.DocValues;
 import org.apache.lucene.index.Fields;
 import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.index.MultiDocValues;
 import org.apache.lucene.index.MultiPostingsEnum;
 import org.apache.lucene.index.PostingsEnum;
-import org.apache.lucene.index.SortedDocValues;
-import org.apache.lucene.index.SortedSetDocValues;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.index.Terms;
 import org.apache.lucene.index.TermsEnum;
-import org.apache.lucene.search.DocIdSet;
 import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
-import org.apache.lucene.util.LongValues;
 import org.apache.lucene.util.PriorityQueue;
 import org.apache.lucene.util.StringHelper;
 import org.apache.lucene.util.UnicodeUtil;
@@ -53,7 +47,6 @@ import org.apache.solr.schema.FieldType;
 import org.apache.solr.schema.SchemaField;
 import org.apache.solr.schema.TrieField;
 import org.apache.solr.search.DocSet;
-import org.apache.solr.search.Filter;
 import org.apache.solr.search.HashDocSet;
 import org.apache.solr.search.SolrIndexSearcher;
 import org.apache.solr.search.SortedIntDocSet;
@@ -130,7 +123,7 @@ public class FacetField extends FacetRequest {
       return new FacetFieldProcessorStream(fcontext, this, sf);
     }
 
-    org.apache.lucene.document.FieldType.NumericType ntype = ft.getNumericType();
+    org.apache.lucene.document.FieldType.LegacyNumericType ntype = ft.getNumericType();
 
     if (sf.hasDocValues() && ntype==null) {
       // single and multi-valued string docValues
diff --git a/solr/core/src/java/org/apache/solr/search/facet/FacetRange.java b/solr/core/src/java/org/apache/solr/search/facet/FacetRange.java
index 4e76e10..ea1159f 100644
--- a/solr/core/src/java/org/apache/solr/search/facet/FacetRange.java
+++ b/solr/core/src/java/org/apache/solr/search/facet/FacetRange.java
@@ -24,7 +24,7 @@ import java.util.EnumSet;
 import java.util.List;
 
 import org.apache.lucene.search.Query;
-import org.apache.lucene.util.NumericUtils;
+import org.apache.lucene.util.LegacyNumericUtils;
 import org.apache.solr.common.SolrException;
 import org.apache.solr.common.params.FacetParams;
 import org.apache.solr.common.util.SimpleOrderedMap;
@@ -458,7 +458,7 @@ class FacetRangeProcessor extends FacetProcessor<FacetRange> {
 
     @Override
     public long bitsToSortableBits(long bits) {
-      return NumericUtils.sortableDoubleBits(bits);
+      return LegacyNumericUtils.sortableDoubleBits(bits);
     }
 
     public FloatCalc(final SchemaField f) { super(f); }
@@ -479,7 +479,7 @@ class FacetRangeProcessor extends FacetProcessor<FacetRange> {
 
     @Override
     public long bitsToSortableBits(long bits) {
-      return NumericUtils.sortableDoubleBits(bits);
+      return LegacyNumericUtils.sortableDoubleBits(bits);
     }
 
     public DoubleCalc(final SchemaField f) { super(f); }
diff --git a/solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser.java b/solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser.java
index 81aa5c2..28e2634 100644
--- a/solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser.java
+++ b/solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser.java
@@ -24,7 +24,7 @@ import org.apache.lucene.search.BoostQuery;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.util.BytesRefBuilder;
-import org.apache.lucene.util.NumericUtils;
+import org.apache.lucene.util.LegacyNumericUtils;
 import org.apache.solr.common.SolrDocument;
 import org.apache.solr.common.SolrException;
 import org.apache.solr.common.StringUtils;
@@ -195,8 +195,8 @@ public class CloudMLTQParser extends QParser {
 
   private Term createNumericTerm(String field, String uniqueValue) {
     BytesRefBuilder bytesRefBuilder = new BytesRefBuilder();
-    bytesRefBuilder.grow(NumericUtils.BUF_SIZE_INT);
-    NumericUtils.intToPrefixCoded(Integer.parseInt(uniqueValue), 0, bytesRefBuilder);
+    bytesRefBuilder.grow(LegacyNumericUtils.BUF_SIZE_INT);
+    LegacyNumericUtils.intToPrefixCoded(Integer.parseInt(uniqueValue), 0, bytesRefBuilder);
     return new Term(field, bytesRefBuilder.toBytesRef());
   }
 
diff --git a/solr/core/src/java/org/apache/solr/search/mlt/SimpleMLTQParser.java b/solr/core/src/java/org/apache/solr/search/mlt/SimpleMLTQParser.java
index dbffef4..ae3676a 100644
--- a/solr/core/src/java/org/apache/solr/search/mlt/SimpleMLTQParser.java
+++ b/solr/core/src/java/org/apache/solr/search/mlt/SimpleMLTQParser.java
@@ -26,7 +26,7 @@ import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.search.TopDocs;
 import org.apache.lucene.util.BytesRefBuilder;
-import org.apache.lucene.util.NumericUtils;
+import org.apache.lucene.util.LegacyNumericUtils;
 import org.apache.solr.common.SolrException;
 import org.apache.solr.common.StringUtils;
 import org.apache.solr.common.params.SolrParams;
@@ -169,8 +169,8 @@ public class SimpleMLTQParser extends QParser {
 
   private Term createNumericTerm(String field, String uniqueValue) {
     BytesRefBuilder bytesRefBuilder = new BytesRefBuilder();
-    bytesRefBuilder.grow(NumericUtils.BUF_SIZE_INT);
-    NumericUtils.intToPrefixCoded(Integer.parseInt(uniqueValue), 0, bytesRefBuilder);
+    bytesRefBuilder.grow(LegacyNumericUtils.BUF_SIZE_INT);
+    LegacyNumericUtils.intToPrefixCoded(Integer.parseInt(uniqueValue), 0, bytesRefBuilder);
     return new Term(field, bytesRefBuilder);
   }
 
diff --git a/solr/core/src/java/org/apache/solr/update/VersionInfo.java b/solr/core/src/java/org/apache/solr/update/VersionInfo.java
index e5f396e..5686285 100644
--- a/solr/core/src/java/org/apache/solr/update/VersionInfo.java
+++ b/solr/core/src/java/org/apache/solr/update/VersionInfo.java
@@ -32,7 +32,7 @@ import org.apache.lucene.queries.function.ValueSource;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.util.BitUtil;
 import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.NumericUtils;
+import org.apache.lucene.util.LegacyNumericUtils;
 import org.apache.solr.common.SolrException;
 import org.apache.solr.common.util.SuppressForbidden;
 import org.apache.solr.schema.IndexSchema;
@@ -231,7 +231,7 @@ public class VersionInfo {
     if (versionField.indexed()) {
       LeafReader leafReader = SlowCompositeReaderWrapper.wrap(searcher.getIndexReader());
       Terms versionTerms = leafReader.terms(versionFieldName);
-      Long max = (versionTerms != null) ? NumericUtils.getMaxLong(versionTerms) : null;
+      Long max = (versionTerms != null) ? LegacyNumericUtils.getMaxLong(versionTerms) : null;
       if (max != null) {
         maxVersionInIndex = max.longValue();
         log.info("Found MAX value {} from Terms for {} in index", maxVersionInIndex, versionFieldName);
diff --git a/solr/core/src/test-files/solr/collection1/conf/schema-binaryfield.xml b/solr/core/src/test-files/solr/collection1/conf/schema-binaryfield.xml
index 9c045ad..fcf7656 100644
--- a/solr/core/src/test-files/solr/collection1/conf/schema-binaryfield.xml
+++ b/solr/core/src/test-files/solr/collection1/conf/schema-binaryfield.xml
@@ -45,7 +45,7 @@
     <!--
      Numeric field types that index each value at various levels of precision
      to accelerate range queries when the number of values between the range
-     endpoints is large. See the javadoc for NumericRangeQuery for internal
+     endpoints is large. See the javadoc for LegacyNumericRangeQuery for internal
      implementation details.
 
      Smaller precisionStep values (specified in bits) will lead to more tokens
diff --git a/solr/core/src/test-files/solr/collection1/conf/schema-copyfield-test.xml b/solr/core/src/test-files/solr/collection1/conf/schema-copyfield-test.xml
index d759dca..f24570a 100644
--- a/solr/core/src/test-files/solr/collection1/conf/schema-copyfield-test.xml
+++ b/solr/core/src/test-files/solr/collection1/conf/schema-copyfield-test.xml
@@ -45,7 +45,7 @@
     <!--
      Numeric field types that index each value at various levels of precision
      to accelerate range queries when the number of values between the range
-     endpoints is large. See the javadoc for NumericRangeQuery for internal
+     endpoints is large. See the javadoc for LegacyNumericRangeQuery for internal
      implementation details.
 
      Smaller precisionStep values (specified in bits) will lead to more tokens
diff --git a/solr/core/src/test-files/solr/collection1/conf/schema-customfield.xml b/solr/core/src/test-files/solr/collection1/conf/schema-customfield.xml
index 6fc6c8f..790bc2c 100644
--- a/solr/core/src/test-files/solr/collection1/conf/schema-customfield.xml
+++ b/solr/core/src/test-files/solr/collection1/conf/schema-customfield.xml
@@ -45,7 +45,7 @@
     <!--
      Numeric field types that index each value at various levels of precision
      to accelerate range queries when the number of values between the range
-     endpoints is large. See the javadoc for NumericRangeQuery for internal
+     endpoints is large. See the javadoc for LegacyNumericRangeQuery for internal
      implementation details.
 
      Smaller precisionStep values (specified in bits) will lead to more tokens
diff --git a/solr/core/src/test-files/solr/collection1/conf/schema-required-fields.xml b/solr/core/src/test-files/solr/collection1/conf/schema-required-fields.xml
index c34f34f..454ece4 100644
--- a/solr/core/src/test-files/solr/collection1/conf/schema-required-fields.xml
+++ b/solr/core/src/test-files/solr/collection1/conf/schema-required-fields.xml
@@ -45,7 +45,7 @@
     <!--
      Numeric field types that index each value at various levels of precision
      to accelerate range queries when the number of values between the range
-     endpoints is large. See the javadoc for NumericRangeQuery for internal
+     endpoints is large. See the javadoc for LegacyNumericRangeQuery for internal
      implementation details.
 
      Smaller precisionStep values (specified in bits) will lead to more tokens
diff --git a/solr/core/src/test-files/solr/collection1/conf/schema_latest.xml b/solr/core/src/test-files/solr/collection1/conf/schema_latest.xml
index 7cb8c9e..cf8666f 100644
--- a/solr/core/src/test-files/solr/collection1/conf/schema_latest.xml
+++ b/solr/core/src/test-files/solr/collection1/conf/schema_latest.xml
@@ -369,7 +369,7 @@
     <!--
      Numeric field types that index each value at various levels of precision
      to accelerate range queries when the number of values between the range
-     endpoints is large. See the javadoc for NumericRangeQuery for internal
+     endpoints is large. See the javadoc for LegacyNumericRangeQuery for internal
      implementation details.
 
      Smaller precisionStep values (specified in bits) will lead to more tokens
diff --git a/solr/core/src/test/org/apache/solr/search/SpatialFilterTest.java b/solr/core/src/test/org/apache/solr/search/SpatialFilterTest.java
index 79e832e..2898694 100644
--- a/solr/core/src/test/org/apache/solr/search/SpatialFilterTest.java
+++ b/solr/core/src/test/org/apache/solr/search/SpatialFilterTest.java
@@ -203,7 +203,7 @@ public class SpatialFilterTest extends SolrTestCaseJ4 {
     query = parser.parse();
     assertNotNull("Query is null", query);
     assertTrue(query.getClass() + " is not an instanceof "
-            + NumericRangeQuery.class,
-            query instanceof NumericRangeQuery);
+            + LegacyNumericRangeQuery.class,
+            query instanceof LegacyNumericRangeQuery);
     req.close();
   }*/
diff --git a/solr/core/src/test/org/apache/solr/search/TestMaxScoreQueryParser.java b/solr/core/src/test/org/apache/solr/search/TestMaxScoreQueryParser.java
index d82b2c5..088fa7c 100644
--- a/solr/core/src/test/org/apache/solr/search/TestMaxScoreQueryParser.java
+++ b/solr/core/src/test/org/apache/solr/search/TestMaxScoreQueryParser.java
@@ -46,7 +46,7 @@ public class TestMaxScoreQueryParser extends AbstractSolrTestCase {
     assertEquals(new BoostQuery(new TermQuery(new Term("text", "foo")), 3f), q);
 
     q = parse("price:[0 TO 10]");
-    assertTrue(q instanceof NumericRangeQuery);
+    assertTrue(q instanceof LegacyNumericRangeQuery);
   }
 
   @Test
diff --git a/solr/core/src/test/org/apache/solr/search/function/TestOrdValues.java b/solr/core/src/test/org/apache/solr/search/function/TestOrdValues.java
index 0e2dcf9..2848dc4 100644
--- a/solr/core/src/test/org/apache/solr/search/function/TestOrdValues.java
+++ b/solr/core/src/test/org/apache/solr/search/function/TestOrdValues.java
@@ -22,8 +22,8 @@ import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.FieldType;
-import org.apache.lucene.document.FloatField;
-import org.apache.lucene.document.IntField;
+import org.apache.lucene.document.LegacyFloatField;
+import org.apache.lucene.document.LegacyIntField;
 import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.document.SortedDocValuesField;
 import org.apache.lucene.document.TextField;
@@ -270,11 +270,11 @@ public class TestOrdValues extends LuceneTestCase {
     f = newField(TEXT_FIELD, "text of doc" + scoreAndID + textLine(i), customType2); // for regular search
     d.add(f);
 
-    f = new IntField(INT_FIELD, scoreAndID, Store.YES); // for function scoring
+    f = new LegacyIntField(INT_FIELD, scoreAndID, Store.YES); // for function scoring
     d.add(f);
     d.add(new NumericDocValuesField(INT_FIELD, scoreAndID));
 
-    f = new FloatField(FLOAT_FIELD, scoreAndID, Store.YES); // for function scoring
+    f = new LegacyFloatField(FLOAT_FIELD, scoreAndID, Store.YES); // for function scoring
     d.add(f);
     d.add(new NumericDocValuesField(FLOAT_FIELD, Float.floatToRawIntBits(scoreAndID)));
 

