GitDiffStart: 9712dbe0eafb59563a5f6184b281c79be1ac5d3b | Sat Aug 22 21:24:27 2009 +0000
diff --git a/CHANGES.txt b/CHANGES.txt
index 416c679..cfc271d 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -691,12 +691,12 @@ New features
     SpanNearQuery that does not need to use the payloads, you can
     disable loading them with a new constructor switch.  (Mark Miller)
 
-33. LUCENE-1341: Added BoostingNearQuery to enable SpanNearQuery functionality
+33. LUCENE-1341: Added PayloadNearQuery to enable SpanNearQuery functionality
     with payloads (Peter Keegan, Grant Ingersoll, Mark Miller)
 
-34. LUCENE-1790: Added BoostingFunctionTermQuery to enable scoring of payloads
+34. LUCENE-1790: Added PayloadTermQuery to enable scoring of payloads
     based on the maximum payload seen for a document.
-    Slight refactoring of Similarity and other payload queries (Grant Ingersoll)
+    Slight refactoring of Similarity and other payload queries (Grant Ingersoll, Mark Miller)
 
 36. LUCENE-1749: Addition of FieldCacheSanityChecker utility, and
     hooks to use it in all existing Lucene Tests.  This class can
diff --git a/src/java/org/apache/lucene/search/payloads/BoostingFunctionTermQuery.java b/src/java/org/apache/lucene/search/payloads/BoostingFunctionTermQuery.java
deleted file mode 100644
index b253c44..0000000
--- a/src/java/org/apache/lucene/search/payloads/BoostingFunctionTermQuery.java
+++ /dev/null
@@ -1,205 +0,0 @@
-package org.apache.lucene.search.payloads;
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.index.Term;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.TermPositions;
-import org.apache.lucene.search.Searcher;
-import org.apache.lucene.search.Scorer;
-import org.apache.lucene.search.Weight;
-import org.apache.lucene.search.Similarity;
-import org.apache.lucene.search.Explanation;
-import org.apache.lucene.search.ComplexExplanation;
-import org.apache.lucene.search.spans.TermSpans;
-import org.apache.lucene.search.spans.SpanTermQuery;
-import org.apache.lucene.search.spans.SpanWeight;
-import org.apache.lucene.search.spans.SpanScorer;
-
-import java.io.IOException;
-
-/**
- * This class is very similar to {@link org.apache.lucene.search.spans.SpanTermQuery} 
- * except that it factors in the value of the payload located at each of the positions
- *  where the {@link org.apache.lucene.index.Term} occurs.
- * <p>
- * In order to take advantage of this, you must override
- * {@link org.apache.lucene.search.Similarity#scorePayload(String, byte[],int,int)}
- * which returns 1 by default.
- * <p>
- * Payload scores are aggregated using a pluggable {@link PayloadFunction}.
- **/
-public class BoostingFunctionTermQuery extends SpanTermQuery  implements PayloadQuery{
-  protected PayloadFunction function;
-  private boolean includeSpanScore;
-
-  public BoostingFunctionTermQuery(Term term, PayloadFunction function) {
-    this(term, function, true);
-  }
-
-  public BoostingFunctionTermQuery(Term term, PayloadFunction function, boolean includeSpanScore) {
-    super(term);
-    this.function = function;
-    this.includeSpanScore = includeSpanScore;
-  }
-
-  
-
-  public Weight createWeight(Searcher searcher) throws IOException {
-    return new BoostingFunctionTermWeight(this, searcher);
-  }
-
-  protected class BoostingFunctionTermWeight extends SpanWeight {
-
-    public BoostingFunctionTermWeight(BoostingFunctionTermQuery query, Searcher searcher) throws IOException {
-      super(query, searcher);
-    }
-
-    public Scorer scorer(IndexReader reader, boolean scoreDocsInOrder, boolean topScorer) throws IOException {
-      return new BoostingFunctionSpanScorer((TermSpans) query.getSpans(reader), this,
-          similarity, reader.norms(query.getField()));
-    }
-
-    protected class BoostingFunctionSpanScorer extends SpanScorer {
-      //TODO: is this the best way to allocate this?
-      protected byte[] payload = new byte[256];
-      protected TermPositions positions;
-      protected float payloadScore;
-      protected int payloadsSeen;
-
-      public BoostingFunctionSpanScorer(TermSpans spans, Weight weight, Similarity similarity,
-                                   byte[] norms) throws IOException {
-        super(spans, weight, similarity, norms);
-        positions = spans.getPositions();
-      }
-
-      protected boolean setFreqCurrentDoc() throws IOException {
-        if (!more) {
-          return false;
-        }
-        doc = spans.doc();
-        freq = 0.0f;
-        payloadScore = 0;
-        payloadsSeen = 0;
-        Similarity similarity1 = getSimilarity();
-        while (more && doc == spans.doc()) {
-          int matchLength = spans.end() - spans.start();
-
-          freq += similarity1.sloppyFreq(matchLength);
-          processPayload(similarity1);
-
-          more = spans.next();//this moves positions to the next match in this document
-        }
-        return more || (freq != 0);
-      }
-
-
-      protected void processPayload(Similarity similarity) throws IOException {
-        if (positions.isPayloadAvailable()) {
-          payload = positions.getPayload(payload, 0);
-          payloadScore = function.currentScore(doc, term.field(), spans.start(), spans.end(), payloadsSeen, payloadScore,
-                  similarity.scorePayload(doc, term.field(), spans.start(), spans.end(), payload, 0, positions.getPayloadLength()));
-          payloadsSeen++;
-
-        } else {
-          //zero out the payload?
-        }
-      }
-
-      /**
-       *
-       * @return {@link #getSpanScore()} * {@link #getPayloadScore()}
-       * @throws IOException
-       */
-      public float score() throws IOException {
-
-        return includeSpanScore ? getSpanScore() * getPayloadScore() : getPayloadScore();
-      }
-
-      /**
-       * Returns the SpanScorer score only.
-       * <p/>
-       * Should not be overriden without good cause!
-       *
-       * @return the score for just the Span part w/o the payload
-       * @throws IOException
-       *
-       * @see #score()
-       */
-      protected float getSpanScore() throws IOException{
-        return super.score();
-      }
-
-      /**
-       * The score for the payload
-       * @return The score, as calculated by {@link PayloadFunction#docScore(int, String, int, float)}
-       */
-      protected float getPayloadScore() {
-        return function.docScore(doc, term.field(), payloadsSeen, payloadScore);
-      }
-
-
-      public Explanation explain(final int doc) throws IOException {
-        ComplexExplanation result = new ComplexExplanation();
-        Explanation nonPayloadExpl = super.explain(doc);
-        result.addDetail(nonPayloadExpl);
-        //QUESTION: Is there a way to avoid this skipTo call?  We need to know whether to load the payload or not
-        Explanation payloadBoost = new Explanation();
-        result.addDetail(payloadBoost);
-
-
-        float payloadScore = getPayloadScore();
-        payloadBoost.setValue(payloadScore);
-        //GSI: I suppose we could toString the payload, but I don't think that would be a good idea
-        payloadBoost.setDescription("scorePayload(...)");
-        result.setValue(nonPayloadExpl.getValue() * payloadScore);
-        result.setDescription("btq, product of:");
-        result.setMatch(nonPayloadExpl.getValue()==0 ? Boolean.FALSE : Boolean.TRUE); // LUCENE-1303
-        return result;
-      }
-
-    }
-  }
-
-  public int hashCode() {
-    final int prime = 31;
-    int result = super.hashCode();
-    result = prime * result + ((function == null) ? 0 : function.hashCode());
-    result = prime * result + (includeSpanScore ? 1231 : 1237);
-    return result;
-  }
-
-  public boolean equals(Object obj) {
-    if (this == obj)
-      return true;
-    if (!super.equals(obj))
-      return false;
-    if (getClass() != obj.getClass())
-      return false;
-    BoostingFunctionTermQuery other = (BoostingFunctionTermQuery) obj;
-    if (function == null) {
-      if (other.function != null)
-        return false;
-    } else if (!function.equals(other.function))
-      return false;
-    if (includeSpanScore != other.includeSpanScore)
-      return false;
-    return true;
-  }
-
-
-}
diff --git a/src/java/org/apache/lucene/search/payloads/BoostingNearQuery.java b/src/java/org/apache/lucene/search/payloads/BoostingNearQuery.java
deleted file mode 100644
index 00a7da7..0000000
--- a/src/java/org/apache/lucene/search/payloads/BoostingNearQuery.java
+++ /dev/null
@@ -1,230 +0,0 @@
-package org.apache.lucene.search.payloads;
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.search.Explanation;
-import org.apache.lucene.search.Scorer;
-import org.apache.lucene.search.Searcher;
-import org.apache.lucene.search.Similarity;
-import org.apache.lucene.search.Weight;
-import org.apache.lucene.search.spans.NearSpansOrdered;
-import org.apache.lucene.search.spans.NearSpansUnordered;
-import org.apache.lucene.search.spans.SpanNearQuery;
-import org.apache.lucene.search.spans.SpanQuery;
-import org.apache.lucene.search.spans.SpanScorer;
-import org.apache.lucene.search.spans.SpanWeight;
-import org.apache.lucene.search.spans.Spans;
-import org.apache.lucene.util.ToStringUtils;
-
-import java.io.IOException;
-import java.util.Collection;
-import java.util.Iterator;
-
-/**
- * This class is very similar to {@link org.apache.lucene.search.spans.SpanNearQuery} except
- * that it factors in the value of the payloads located at each of the positions where the
- * {@link org.apache.lucene.search.spans.TermSpans} occurs.
- * <p/>
- * In order to take advantage of this, you must override {@link org.apache.lucene.search.Similarity#scorePayload(String, byte[],int,int)}
- * which returns 1 by default.
- * <p/>
- * Payload scores are aggregated using a pluggable {@link PayloadFunction}.
- *
- * @see org.apache.lucene.search.Similarity#scorePayload(String, byte[], int, int)
- */
-
-public class BoostingNearQuery extends SpanNearQuery implements PayloadQuery {
-  protected String fieldName;
-  protected PayloadFunction function;
-
-  public BoostingNearQuery(SpanQuery[] clauses, int slop, boolean inOrder) {
-    this(clauses, slop, inOrder, new AveragePayloadFunction());
-  }
-
-  public BoostingNearQuery(SpanQuery[] clauses, int slop, boolean inOrder, PayloadFunction function) {
-    super(clauses, slop, inOrder);
-    fieldName = clauses[0].getField(); // all clauses must have same field
-    this.function = function;
-  }
-
-
-  public Weight createWeight(Searcher searcher) throws IOException {
-    return new BoostingSpanWeight(this, searcher);
-  }
-  
-  public Object clone() {
-    int sz = clauses.size();
-    SpanQuery[] newClauses = new SpanQuery[sz];
-
-    for (int i = 0; i < sz; i++) {
-      SpanQuery clause = (SpanQuery) clauses.get(i);
-      newClauses[i] = (SpanQuery) clause.clone();
-    }
-    BoostingNearQuery boostingNearQuery = new BoostingNearQuery(newClauses, slop, inOrder);
-    boostingNearQuery.setBoost(getBoost());
-    return boostingNearQuery;
-  }
-  
-  public String toString(String field) {
-    StringBuffer buffer = new StringBuffer();
-    buffer.append("boostingNear([");
-    Iterator i = clauses.iterator();
-    while (i.hasNext()) {
-      SpanQuery clause = (SpanQuery)i.next();
-      buffer.append(clause.toString(field));
-      if (i.hasNext()) {
-        buffer.append(", ");
-      }
-    }
-    buffer.append("], ");
-    buffer.append(slop);
-    buffer.append(", ");
-    buffer.append(inOrder);
-    buffer.append(")");
-    buffer.append(ToStringUtils.boost(getBoost()));
-    return buffer.toString();
-  }
-  
-  //@Override
-  public int hashCode() {
-    final int prime = 31;
-    int result = super.hashCode();
-    result = prime * result + ((fieldName == null) ? 0 : fieldName.hashCode());
-    result = prime * result + ((function == null) ? 0 : function.hashCode());
-    return result;
-  }
-
-  //@Override
-  public boolean equals(Object obj) {
-    if (this == obj)
-      return true;
-    if (!super.equals(obj))
-      return false;
-    if (getClass() != obj.getClass())
-      return false;
-    BoostingNearQuery other = (BoostingNearQuery) obj;
-    if (fieldName == null) {
-      if (other.fieldName != null)
-        return false;
-    } else if (!fieldName.equals(other.fieldName))
-      return false;
-    if (function == null) {
-      if (other.function != null)
-        return false;
-    } else if (!function.equals(other.function))
-      return false;
-    return true;
-  }
-
-  public class BoostingSpanWeight extends SpanWeight {
-    public BoostingSpanWeight(SpanQuery query, Searcher searcher) throws IOException {
-      super(query, searcher);
-    }
-
-    public Scorer scorer(IndexReader reader) throws IOException {
-      return new BoostingSpanScorer(query.getSpans(reader), this,
-              similarity,
-              reader.norms(query.getField()));
-    }
-
-    public Scorer scorer(IndexReader reader, boolean scoreDocsInOrder, boolean topScorer) throws IOException {
-      return new BoostingSpanScorer(query.getSpans(reader), this,
-              similarity,
-              reader.norms(query.getField()));
-    }
-  }
-
-  public class BoostingSpanScorer extends SpanScorer {
-    Spans spans;
-    
-    protected float payloadScore;
-    private int payloadsSeen;
-    Similarity similarity = getSimilarity();
-
-    protected BoostingSpanScorer(Spans spans, Weight weight, Similarity similarity, byte[] norms)
-            throws IOException {
-      super(spans, weight, similarity, norms);
-      this.spans = spans;
-    }
-
-    // Get the payloads associated with all underlying subspans
-    public void getPayloads(Spans[] subSpans) throws IOException {
-      for (int i = 0; i < subSpans.length; i++) {
-        if (subSpans[i] instanceof NearSpansOrdered) {
-          if (((NearSpansOrdered) subSpans[i]).isPayloadAvailable()) {
-            processPayloads(((NearSpansOrdered) subSpans[i]).getPayload(), subSpans[i].start(), subSpans[i].end());
-          }
-          getPayloads(((NearSpansOrdered) subSpans[i]).getSubSpans());
-        } else if (subSpans[i] instanceof NearSpansUnordered) {
-          if (((NearSpansUnordered) subSpans[i]).isPayloadAvailable()) {
-            processPayloads(((NearSpansUnordered) subSpans[i]).getPayload(), subSpans[i].start(), subSpans[i].end());
-          }
-          getPayloads(((NearSpansUnordered) subSpans[i]).getSubSpans());
-        }
-      }
-    }
-
-    /**
-     * By default, uses the {@link PayloadFunction} to score the payloads, but can be overridden to do other things.
-     *
-     * @param payLoads The payloads
-     * @param start The start position of the span being scored
-     * @param end The end position of the span being scored
-     *
-     * @see Spans
-     */
-    protected void processPayloads(Collection payLoads, int start, int end) {
-      for (Iterator iterator = payLoads.iterator(); iterator.hasNext();) {
-        byte[] thePayload = (byte[]) iterator.next();
-        payloadScore = function.currentScore(doc, fieldName, start, end, payloadsSeen, payloadScore,
-                similarity.scorePayload(doc, fieldName, spans.start(), spans.end(), thePayload, 0, thePayload.length));
-        ++payloadsSeen;
-      }
-    }
-
-    //
-    protected boolean setFreqCurrentDoc() throws IOException {
-      Spans[] spansArr = new Spans[1];
-      spansArr[0] = spans;
-      payloadScore = 0;
-      payloadsSeen = 0;
-      getPayloads(spansArr);
-      return super.setFreqCurrentDoc();
-    }
-
-    public float score() throws IOException {
-
-      return super.score() * function.docScore(doc, fieldName, payloadsSeen, payloadScore);
-    }
-
-    public Explanation explain(int doc) throws IOException {
-      Explanation result = new Explanation();
-      Explanation nonPayloadExpl = super.explain(doc);
-      result.addDetail(nonPayloadExpl);
-      Explanation payloadBoost = new Explanation();
-      result.addDetail(payloadBoost);
-      float avgPayloadScore = (payloadsSeen > 0 ? (payloadScore / payloadsSeen) : 1);
-      payloadBoost.setValue(avgPayloadScore);
-      payloadBoost.setDescription("scorePayload(...)");
-      result.setValue(nonPayloadExpl.getValue() * avgPayloadScore);
-      result.setDescription("bnq, product of:");
-      return result;
-    }
-  }
-  
-}
diff --git a/src/java/org/apache/lucene/search/payloads/BoostingTermQuery.java b/src/java/org/apache/lucene/search/payloads/BoostingTermQuery.java
index 1268eda..e90df44 100644
--- a/src/java/org/apache/lucene/search/payloads/BoostingTermQuery.java
+++ b/src/java/org/apache/lucene/search/payloads/BoostingTermQuery.java
@@ -37,9 +37,9 @@ import org.apache.lucene.search.spans.TermSpans;
  * 
  * @see org.apache.lucene.search.Similarity#scorePayload(String, byte[], int, int)
  *
- * @deprecated See {@link org.apache.lucene.search.payloads.BoostingFunctionTermQuery}
+ * @deprecated See {@link org.apache.lucene.search.payloads.PayloadTermQuery}
  */
-public class BoostingTermQuery extends BoostingFunctionTermQuery implements PayloadQuery{
+public class BoostingTermQuery extends PayloadTermQuery {
 
   public BoostingTermQuery(Term term) {
     this(term, true);
@@ -53,14 +53,14 @@ public class BoostingTermQuery extends BoostingFunctionTermQuery implements Payl
     return new BoostingTermWeight(this, searcher);
   }
 
-  protected class BoostingTermWeight extends BoostingFunctionTermWeight {
+  protected class BoostingTermWeight extends PayloadTermWeight {
 
     public BoostingTermWeight(BoostingTermQuery query, Searcher searcher) throws IOException {
       super(query, searcher);
     }
 
     public Scorer scorer(IndexReader reader, boolean scoreDocsInOrder, boolean topScorer) throws IOException {
-      return new BoostingFunctionSpanScorer((TermSpans) query.getSpans(reader), this,
+      return new PayloadTermSpanScorer((TermSpans) query.getSpans(reader), this,
           similarity, reader.norms(query.getField()));
     }
 
diff --git a/src/java/org/apache/lucene/search/payloads/PayloadFunction.java b/src/java/org/apache/lucene/search/payloads/PayloadFunction.java
index 153458b..2f9723f 100644
--- a/src/java/org/apache/lucene/search/payloads/PayloadFunction.java
+++ b/src/java/org/apache/lucene/search/payloads/PayloadFunction.java
@@ -20,10 +20,10 @@ import java.io.Serializable;
 
 
 /**
- * An abstract class that defines a way for Boosting*Query instances
+ * An abstract class that defines a way for Payload*Query instances
  * to transform the cumulative effects of payload scores for a document.
  *
- * @see org.apache.lucene.search.payloads.BoostingFunctionTermQuery for more information
+ * @see org.apache.lucene.search.payloads.PayloadTermQuery for more information
  *
  * <p/>
  * This class and its derivations are experimental and subject to change
diff --git a/src/java/org/apache/lucene/search/payloads/PayloadNearQuery.java b/src/java/org/apache/lucene/search/payloads/PayloadNearQuery.java
new file mode 100644
index 0000000..028c7af
--- /dev/null
+++ b/src/java/org/apache/lucene/search/payloads/PayloadNearQuery.java
@@ -0,0 +1,240 @@
+package org.apache.lucene.search.payloads;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.search.Explanation;
+import org.apache.lucene.search.Scorer;
+import org.apache.lucene.search.Searcher;
+import org.apache.lucene.search.Similarity;
+import org.apache.lucene.search.Weight;
+import org.apache.lucene.search.spans.NearSpansOrdered;
+import org.apache.lucene.search.spans.NearSpansUnordered;
+import org.apache.lucene.search.spans.SpanNearQuery;
+import org.apache.lucene.search.spans.SpanQuery;
+import org.apache.lucene.search.spans.SpanScorer;
+import org.apache.lucene.search.spans.SpanWeight;
+import org.apache.lucene.search.spans.Spans;
+import org.apache.lucene.util.ToStringUtils;
+
+import java.io.IOException;
+import java.util.Collection;
+import java.util.Iterator;
+
+/**
+ * This class is very similar to
+ * {@link org.apache.lucene.search.spans.SpanNearQuery} except that it factors
+ * in the value of the payloads located at each of the positions where the
+ * {@link org.apache.lucene.search.spans.TermSpans} occurs.
+ * <p/>
+ * In order to take advantage of this, you must override
+ * {@link org.apache.lucene.search.Similarity#scorePayload(String, byte[],int,int)}
+ * which returns 1 by default.
+ * <p/>
+ * Payload scores are aggregated using a pluggable {@link PayloadFunction}.
+ * 
+ * @see org.apache.lucene.search.Similarity#scorePayload(String, byte[], int,
+ *      int)
+ */
+public class PayloadNearQuery extends SpanNearQuery {
+  protected String fieldName;
+  protected PayloadFunction function;
+
+  public PayloadNearQuery(SpanQuery[] clauses, int slop, boolean inOrder) {
+    this(clauses, slop, inOrder, new AveragePayloadFunction());
+  }
+
+  public PayloadNearQuery(SpanQuery[] clauses, int slop, boolean inOrder,
+      PayloadFunction function) {
+    super(clauses, slop, inOrder);
+    fieldName = clauses[0].getField(); // all clauses must have same field
+    this.function = function;
+  }
+
+  public Weight createWeight(Searcher searcher) throws IOException {
+    return new PayloadNearSpanWeight(this, searcher);
+  }
+
+  public Object clone() {
+    int sz = clauses.size();
+    SpanQuery[] newClauses = new SpanQuery[sz];
+
+    for (int i = 0; i < sz; i++) {
+      SpanQuery clause = (SpanQuery) clauses.get(i);
+      newClauses[i] = (SpanQuery) clause.clone();
+    }
+    PayloadNearQuery boostingNearQuery = new PayloadNearQuery(newClauses, slop,
+        inOrder);
+    boostingNearQuery.setBoost(getBoost());
+    return boostingNearQuery;
+  }
+
+  public String toString(String field) {
+    StringBuffer buffer = new StringBuffer();
+    buffer.append("payloadNear([");
+    Iterator i = clauses.iterator();
+    while (i.hasNext()) {
+      SpanQuery clause = (SpanQuery) i.next();
+      buffer.append(clause.toString(field));
+      if (i.hasNext()) {
+        buffer.append(", ");
+      }
+    }
+    buffer.append("], ");
+    buffer.append(slop);
+    buffer.append(", ");
+    buffer.append(inOrder);
+    buffer.append(")");
+    buffer.append(ToStringUtils.boost(getBoost()));
+    return buffer.toString();
+  }
+
+  // @Override
+  public int hashCode() {
+    final int prime = 31;
+    int result = super.hashCode();
+    result = prime * result + ((fieldName == null) ? 0 : fieldName.hashCode());
+    result = prime * result + ((function == null) ? 0 : function.hashCode());
+    return result;
+  }
+
+  // @Override
+  public boolean equals(Object obj) {
+    if (this == obj)
+      return true;
+    if (!super.equals(obj))
+      return false;
+    if (getClass() != obj.getClass())
+      return false;
+    PayloadNearQuery other = (PayloadNearQuery) obj;
+    if (fieldName == null) {
+      if (other.fieldName != null)
+        return false;
+    } else if (!fieldName.equals(other.fieldName))
+      return false;
+    if (function == null) {
+      if (other.function != null)
+        return false;
+    } else if (!function.equals(other.function))
+      return false;
+    return true;
+  }
+
+  public class PayloadNearSpanWeight extends SpanWeight {
+    public PayloadNearSpanWeight(SpanQuery query, Searcher searcher)
+        throws IOException {
+      super(query, searcher);
+    }
+
+    public Scorer scorer(IndexReader reader) throws IOException {
+      return new PayloadNearSpanScorer(query.getSpans(reader), this,
+          similarity, reader.norms(query.getField()));
+    }
+
+    public Scorer scorer(IndexReader reader, boolean scoreDocsInOrder,
+        boolean topScorer) throws IOException {
+      return new PayloadNearSpanScorer(query.getSpans(reader), this,
+          similarity, reader.norms(query.getField()));
+    }
+  }
+
+  public class PayloadNearSpanScorer extends SpanScorer {
+    Spans spans;
+
+    protected float payloadScore;
+    private int payloadsSeen;
+    Similarity similarity = getSimilarity();
+
+    protected PayloadNearSpanScorer(Spans spans, Weight weight,
+        Similarity similarity, byte[] norms) throws IOException {
+      super(spans, weight, similarity, norms);
+      this.spans = spans;
+    }
+
+    // Get the payloads associated with all underlying subspans
+    public void getPayloads(Spans[] subSpans) throws IOException {
+      for (int i = 0; i < subSpans.length; i++) {
+        if (subSpans[i] instanceof NearSpansOrdered) {
+          if (((NearSpansOrdered) subSpans[i]).isPayloadAvailable()) {
+            processPayloads(((NearSpansOrdered) subSpans[i]).getPayload(),
+                subSpans[i].start(), subSpans[i].end());
+          }
+          getPayloads(((NearSpansOrdered) subSpans[i]).getSubSpans());
+        } else if (subSpans[i] instanceof NearSpansUnordered) {
+          if (((NearSpansUnordered) subSpans[i]).isPayloadAvailable()) {
+            processPayloads(((NearSpansUnordered) subSpans[i]).getPayload(),
+                subSpans[i].start(), subSpans[i].end());
+          }
+          getPayloads(((NearSpansUnordered) subSpans[i]).getSubSpans());
+        }
+      }
+    }
+
+    /**
+     * By default, uses the {@link PayloadFunction} to score the payloads, but
+     * can be overridden to do other things.
+     * 
+     * @param payLoads The payloads
+     * @param start The start position of the span being scored
+     * @param end The end position of the span being scored
+     * 
+     * @see Spans
+     */
+    protected void processPayloads(Collection payLoads, int start, int end) {
+      for (Iterator iterator = payLoads.iterator(); iterator.hasNext();) {
+        byte[] thePayload = (byte[]) iterator.next();
+        payloadScore = function.currentScore(doc, fieldName, start, end,
+            payloadsSeen, payloadScore, similarity.scorePayload(doc, fieldName,
+                spans.start(), spans.end(), thePayload, 0, thePayload.length));
+        ++payloadsSeen;
+      }
+    }
+
+    //
+    protected boolean setFreqCurrentDoc() throws IOException {
+      Spans[] spansArr = new Spans[1];
+      spansArr[0] = spans;
+      payloadScore = 0;
+      payloadsSeen = 0;
+      getPayloads(spansArr);
+      return super.setFreqCurrentDoc();
+    }
+
+    public float score() throws IOException {
+
+      return super.score()
+          * function.docScore(doc, fieldName, payloadsSeen, payloadScore);
+    }
+
+    public Explanation explain(int doc) throws IOException {
+      Explanation result = new Explanation();
+      Explanation nonPayloadExpl = super.explain(doc);
+      result.addDetail(nonPayloadExpl);
+      Explanation payloadBoost = new Explanation();
+      result.addDetail(payloadBoost);
+      float avgPayloadScore = (payloadsSeen > 0 ? (payloadScore / payloadsSeen)
+          : 1);
+      payloadBoost.setValue(avgPayloadScore);
+      payloadBoost.setDescription("scorePayload(...)");
+      result.setValue(nonPayloadExpl.getValue() * avgPayloadScore);
+      result.setDescription("bnq, product of:");
+      return result;
+    }
+  }
+
+}
diff --git a/src/java/org/apache/lucene/search/payloads/PayloadQuery.java b/src/java/org/apache/lucene/search/payloads/PayloadQuery.java
deleted file mode 100644
index a2269c6..0000000
--- a/src/java/org/apache/lucene/search/payloads/PayloadQuery.java
+++ /dev/null
@@ -1,24 +0,0 @@
-package org.apache.lucene.search.payloads;
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-/**
- * Marker interface indicating this Query is Payload aware.
- *
- **/
-public interface PayloadQuery {
-}
diff --git a/src/java/org/apache/lucene/search/payloads/PayloadTermQuery.java b/src/java/org/apache/lucene/search/payloads/PayloadTermQuery.java
new file mode 100644
index 0000000..9b6d244
--- /dev/null
+++ b/src/java/org/apache/lucene/search/payloads/PayloadTermQuery.java
@@ -0,0 +1,213 @@
+package org.apache.lucene.search.payloads;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.index.Term;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.TermPositions;
+import org.apache.lucene.search.Searcher;
+import org.apache.lucene.search.Scorer;
+import org.apache.lucene.search.Weight;
+import org.apache.lucene.search.Similarity;
+import org.apache.lucene.search.Explanation;
+import org.apache.lucene.search.ComplexExplanation;
+import org.apache.lucene.search.spans.TermSpans;
+import org.apache.lucene.search.spans.SpanTermQuery;
+import org.apache.lucene.search.spans.SpanWeight;
+import org.apache.lucene.search.spans.SpanScorer;
+
+import java.io.IOException;
+
+/**
+ * This class is very similar to
+ * {@link org.apache.lucene.search.spans.SpanTermQuery} except that it factors
+ * in the value of the payload located at each of the positions where the
+ * {@link org.apache.lucene.index.Term} occurs.
+ * <p>
+ * In order to take advantage of this, you must override
+ * {@link org.apache.lucene.search.Similarity#scorePayload(String, byte[],int,int)}
+ * which returns 1 by default.
+ * <p>
+ * Payload scores are aggregated using a pluggable {@link PayloadFunction}.
+ **/
+public class PayloadTermQuery extends SpanTermQuery {
+  protected PayloadFunction function;
+  private boolean includeSpanScore;
+
+  public PayloadTermQuery(Term term, PayloadFunction function) {
+    this(term, function, true);
+  }
+
+  public PayloadTermQuery(Term term, PayloadFunction function,
+      boolean includeSpanScore) {
+    super(term);
+    this.function = function;
+    this.includeSpanScore = includeSpanScore;
+  }
+
+  public Weight createWeight(Searcher searcher) throws IOException {
+    return new PayloadTermWeight(this, searcher);
+  }
+
+  protected class PayloadTermWeight extends SpanWeight {
+
+    public PayloadTermWeight(PayloadTermQuery query, Searcher searcher)
+        throws IOException {
+      super(query, searcher);
+    }
+
+    public Scorer scorer(IndexReader reader, boolean scoreDocsInOrder,
+        boolean topScorer) throws IOException {
+      return new PayloadTermSpanScorer((TermSpans) query.getSpans(reader),
+          this, similarity, reader.norms(query.getField()));
+    }
+
+    protected class PayloadTermSpanScorer extends SpanScorer {
+      // TODO: is this the best way to allocate this?
+      protected byte[] payload = new byte[256];
+      protected TermPositions positions;
+      protected float payloadScore;
+      protected int payloadsSeen;
+
+      public PayloadTermSpanScorer(TermSpans spans, Weight weight,
+          Similarity similarity, byte[] norms) throws IOException {
+        super(spans, weight, similarity, norms);
+        positions = spans.getPositions();
+      }
+
+      protected boolean setFreqCurrentDoc() throws IOException {
+        if (!more) {
+          return false;
+        }
+        doc = spans.doc();
+        freq = 0.0f;
+        payloadScore = 0;
+        payloadsSeen = 0;
+        Similarity similarity1 = getSimilarity();
+        while (more && doc == spans.doc()) {
+          int matchLength = spans.end() - spans.start();
+
+          freq += similarity1.sloppyFreq(matchLength);
+          processPayload(similarity1);
+
+          more = spans.next();// this moves positions to the next match in this
+                              // document
+        }
+        return more || (freq != 0);
+      }
+
+      protected void processPayload(Similarity similarity) throws IOException {
+        if (positions.isPayloadAvailable()) {
+          payload = positions.getPayload(payload, 0);
+          payloadScore = function.currentScore(doc, term.field(),
+              spans.start(), spans.end(), payloadsSeen, payloadScore,
+              similarity.scorePayload(doc, term.field(), spans.start(), spans
+                  .end(), payload, 0, positions.getPayloadLength()));
+          payloadsSeen++;
+
+        } else {
+          // zero out the payload?
+        }
+      }
+
+      /**
+       * 
+       * @return {@link #getSpanScore()} * {@link #getPayloadScore()}
+       * @throws IOException
+       */
+      public float score() throws IOException {
+
+        return includeSpanScore ? getSpanScore() * getPayloadScore()
+            : getPayloadScore();
+      }
+
+      /**
+       * Returns the SpanScorer score only.
+       * <p/>
+       * Should not be overriden without good cause!
+       * 
+       * @return the score for just the Span part w/o the payload
+       * @throws IOException
+       * 
+       * @see #score()
+       */
+      protected float getSpanScore() throws IOException {
+        return super.score();
+      }
+
+      /**
+       * The score for the payload
+       * 
+       * @return The score, as calculated by
+       *         {@link PayloadFunction#docScore(int, String, int, float)}
+       */
+      protected float getPayloadScore() {
+        return function.docScore(doc, term.field(), payloadsSeen, payloadScore);
+      }
+
+      public Explanation explain(final int doc) throws IOException {
+        ComplexExplanation result = new ComplexExplanation();
+        Explanation nonPayloadExpl = super.explain(doc);
+        result.addDetail(nonPayloadExpl);
+        // QUESTION: Is there a way to avoid this skipTo call? We need to know
+        // whether to load the payload or not
+        Explanation payloadBoost = new Explanation();
+        result.addDetail(payloadBoost);
+
+        float payloadScore = getPayloadScore();
+        payloadBoost.setValue(payloadScore);
+        // GSI: I suppose we could toString the payload, but I don't think that
+        // would be a good idea
+        payloadBoost.setDescription("scorePayload(...)");
+        result.setValue(nonPayloadExpl.getValue() * payloadScore);
+        result.setDescription("btq, product of:");
+        result.setMatch(nonPayloadExpl.getValue() == 0 ? Boolean.FALSE
+            : Boolean.TRUE); // LUCENE-1303
+        return result;
+      }
+
+    }
+  }
+
+  public int hashCode() {
+    final int prime = 31;
+    int result = super.hashCode();
+    result = prime * result + ((function == null) ? 0 : function.hashCode());
+    result = prime * result + (includeSpanScore ? 1231 : 1237);
+    return result;
+  }
+
+  public boolean equals(Object obj) {
+    if (this == obj)
+      return true;
+    if (!super.equals(obj))
+      return false;
+    if (getClass() != obj.getClass())
+      return false;
+    PayloadTermQuery other = (PayloadTermQuery) obj;
+    if (function == null) {
+      if (other.function != null)
+        return false;
+    } else if (!function.equals(other.function))
+      return false;
+    if (includeSpanScore != other.includeSpanScore)
+      return false;
+    return true;
+  }
+
+}
diff --git a/src/java/org/apache/lucene/search/payloads/package.html b/src/java/org/apache/lucene/search/payloads/package.html
index f377366..e5e0a8f 100644
--- a/src/java/org/apache/lucene/search/payloads/package.html
+++ b/src/java/org/apache/lucene/search/payloads/package.html
@@ -26,8 +26,8 @@
 </DIV>
 <div>
   <ol>
-    <li><a href="./BoostingFunctionTermQuery.html">BoostingFunctionTermQuery</a> -- Boost a term's score based on the value of the payload located at that term.</li>
-  	<li><a href="./BoostingNearQuery.html">BoostingNearQuery</a> -- A <a href="SpanNearQuery.html">SpanNearQuery</a> that factors in the value of the payloads located 
+    <li><a href="./PayloadTermQuery.html">PayloadTermQuery</a> -- Boost a term's score based on the value of the payload located at that term.</li>
+  	<li><a href="./PayloadNearQuery.html">PayloadNearQuery</a> -- A <a href="SpanNearQuery.html">SpanNearQuery</a> that factors in the value of the payloads located 
   	at each of the positions where the spans occur.</li>
   </ol>
 </div>
diff --git a/src/test/org/apache/lucene/search/payloads/BoostingFunctionTermQueryTest.java b/src/test/org/apache/lucene/search/payloads/BoostingFunctionTermQueryTest.java
deleted file mode 100644
index 3265a34..0000000
--- a/src/test/org/apache/lucene/search/payloads/BoostingFunctionTermQueryTest.java
+++ /dev/null
@@ -1,322 +0,0 @@
-package org.apache.lucene.search.payloads;
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util.English;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.QueryUtils;
-import org.apache.lucene.search.TopDocs;
-import org.apache.lucene.search.ScoreDoc;
-import org.apache.lucene.search.CheckHits;
-import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.DefaultSimilarity;
-import org.apache.lucene.search.spans.SpanTermQuery;
-import org.apache.lucene.search.spans.Spans;
-import org.apache.lucene.search.spans.TermSpans;
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.LowerCaseTokenizer;
-import org.apache.lucene.analysis.TokenFilter;
-import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;
-import org.apache.lucene.index.Payload;
-import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.store.RAMDirectory;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-
-import java.io.Reader;
-import java.io.IOException;
-
-
-/**
- *
- *
- **/
-public class BoostingFunctionTermQueryTest extends LuceneTestCase {
-  private IndexSearcher searcher;
-  private BoostingSimilarity similarity = new BoostingSimilarity();
-  private byte[] payloadField = new byte[]{1};
-  private byte[] payloadMultiField1 = new byte[]{2};
-  private byte[] payloadMultiField2 = new byte[]{4};
-  protected RAMDirectory directory;
-
-  public BoostingFunctionTermQueryTest(String s) {
-    super(s);
-  }
-
-  private class PayloadAnalyzer extends Analyzer {
-
-
-    public TokenStream tokenStream(String fieldName, Reader reader) {
-      TokenStream result = new LowerCaseTokenizer(reader);
-      result = new PayloadFilter(result, fieldName);
-      return result;
-    }
-  }
-
-  private class PayloadFilter extends TokenFilter {
-    String fieldName;
-    int numSeen = 0;
-    
-    PayloadAttribute payloadAtt;    
-    
-    public PayloadFilter(TokenStream input, String fieldName) {
-      super(input);
-      this.fieldName = fieldName;
-      payloadAtt = (PayloadAttribute) addAttribute(PayloadAttribute.class);
-    }
-    
-    public boolean incrementToken() throws IOException {
-      boolean hasNext = input.incrementToken();
-      if (hasNext) {
-        if (fieldName.equals("field")) {
-          payloadAtt.setPayload(new Payload(payloadField));
-        } else if (fieldName.equals("multiField")) {
-          if (numSeen % 2 == 0) {
-            payloadAtt.setPayload(new Payload(payloadMultiField1));
-          } else {
-            payloadAtt.setPayload(new Payload(payloadMultiField2));
-          }
-          numSeen++;
-        }
-        return true;
-      } else {
-        return false;
-      }
-    }
-  }
-
-  protected void setUp() throws Exception {
-    super.setUp();
-    directory = new RAMDirectory();
-    PayloadAnalyzer analyzer = new PayloadAnalyzer();
-    IndexWriter writer
-            = new IndexWriter(directory, analyzer, true, IndexWriter.MaxFieldLength.LIMITED);
-    writer.setSimilarity(similarity);
-    //writer.infoStream = System.out;
-    for (int i = 0; i < 1000; i++) {
-      Document doc = new Document();
-      Field noPayloadField = new Field(PayloadHelper.NO_PAYLOAD_FIELD, English.intToEnglish(i), Field.Store.YES, Field.Index.ANALYZED);
-      //noPayloadField.setBoost(0);
-      doc.add(noPayloadField);
-      doc.add(new Field("field", English.intToEnglish(i), Field.Store.YES, Field.Index.ANALYZED));
-      doc.add(new Field("multiField", English.intToEnglish(i) + "  " + English.intToEnglish(i), Field.Store.YES, Field.Index.ANALYZED));
-      writer.addDocument(doc);
-    }
-    writer.optimize();
-    writer.close();
-
-    searcher = new IndexSearcher(directory, true);
-    searcher.setSimilarity(similarity);
-  }
-
-  public void test() throws IOException {
-    BoostingFunctionTermQuery query = new BoostingFunctionTermQuery(new Term("field", "seventy"),
-            new MaxPayloadFunction());
-    TopDocs hits = searcher.search(query, null, 100);
-    assertTrue("hits is null and it shouldn't be", hits != null);
-    assertTrue("hits Size: " + hits.totalHits + " is not: " + 100, hits.totalHits == 100);
-
-    //they should all have the exact same score, because they all contain seventy once, and we set
-    //all the other similarity factors to be 1
-
-    assertTrue(hits.getMaxScore() + " does not equal: " + 1, hits.getMaxScore() == 1);
-    for (int i = 0; i < hits.scoreDocs.length; i++) {
-      ScoreDoc doc = hits.scoreDocs[i];
-      assertTrue(doc.score + " does not equal: " + 1, doc.score == 1);
-    }
-    CheckHits.checkExplanations(query, PayloadHelper.FIELD, searcher, true);
-    Spans spans = query.getSpans(searcher.getIndexReader());
-    assertTrue("spans is null and it shouldn't be", spans != null);
-    assertTrue("spans is not an instanceof " + TermSpans.class, spans instanceof TermSpans);
-    /*float score = hits.score(0);
-    for (int i =1; i < hits.length(); i++)
-    {
-      assertTrue("scores are not equal and they should be", score == hits.score(i));
-    }*/
-
-  }
-  
-  public void testQuery() {
-    BoostingFunctionTermQuery boostingFuncTermQuery = new BoostingFunctionTermQuery(new Term(PayloadHelper.MULTI_FIELD, "seventy"),
-        new MaxPayloadFunction());
-    QueryUtils.check(boostingFuncTermQuery);
-    
-    SpanTermQuery spanTermQuery = new SpanTermQuery(new Term(PayloadHelper.MULTI_FIELD, "seventy"));
-
-    assertTrue(boostingFuncTermQuery.equals(spanTermQuery) == spanTermQuery.equals(boostingFuncTermQuery));
-    
-    BoostingFunctionTermQuery boostingFuncTermQuery2 = new BoostingFunctionTermQuery(new Term(PayloadHelper.MULTI_FIELD, "seventy"),
-        new AveragePayloadFunction());
-    
-    QueryUtils.checkUnequal(boostingFuncTermQuery, boostingFuncTermQuery2);
-  }
-
-  public void testMultipleMatchesPerDoc() throws Exception {
-    BoostingFunctionTermQuery query = new BoostingFunctionTermQuery(new Term(PayloadHelper.MULTI_FIELD, "seventy"),
-            new MaxPayloadFunction());
-    TopDocs hits = searcher.search(query, null, 100);
-    assertTrue("hits is null and it shouldn't be", hits != null);
-    assertTrue("hits Size: " + hits.totalHits + " is not: " + 100, hits.totalHits == 100);
-
-    //they should all have the exact same score, because they all contain seventy once, and we set
-    //all the other similarity factors to be 1
-
-    //System.out.println("Hash: " + seventyHash + " Twice Hash: " + 2*seventyHash);
-    assertTrue(hits.getMaxScore() + " does not equal: " + 4.0, hits.getMaxScore() == 4.0);
-    //there should be exactly 10 items that score a 4, all the rest should score a 2
-    //The 10 items are: 70 + i*100 where i in [0-9]
-    int numTens = 0;
-    for (int i = 0; i < hits.scoreDocs.length; i++) {
-      ScoreDoc doc = hits.scoreDocs[i];
-      if (doc.doc % 10 == 0) {
-        numTens++;
-        assertTrue(doc.score + " does not equal: " + 4.0, doc.score == 4.0);
-      } else {
-        assertTrue(doc.score + " does not equal: " + 2, doc.score == 2);
-      }
-    }
-    assertTrue(numTens + " does not equal: " + 10, numTens == 10);
-    CheckHits.checkExplanations(query, "field", searcher, true);
-    Spans spans = query.getSpans(searcher.getIndexReader());
-    assertTrue("spans is null and it shouldn't be", spans != null);
-    assertTrue("spans is not an instanceof " + TermSpans.class, spans instanceof TermSpans);
-    //should be two matches per document
-    int count = 0;
-    //100 hits times 2 matches per hit, we should have 200 in count
-    while (spans.next()) {
-      count++;
-    }
-    assertTrue(count + " does not equal: " + 200, count == 200);
-  }
-
-  //Set includeSpanScore to false, in which case just the payload score comes through.
-  public void testIgnoreSpanScorer() throws Exception {
-    BoostingFunctionTermQuery query = new BoostingFunctionTermQuery(new Term(PayloadHelper.MULTI_FIELD, "seventy"),
-            new MaxPayloadFunction(), false);
-
-    IndexSearcher theSearcher = new IndexSearcher(directory, true);
-    theSearcher.setSimilarity(new FullSimilarity());
-    TopDocs hits = searcher.search(query, null, 100);
-    assertTrue("hits is null and it shouldn't be", hits != null);
-    assertTrue("hits Size: " + hits.totalHits + " is not: " + 100, hits.totalHits == 100);
-
-    //they should all have the exact same score, because they all contain seventy once, and we set
-    //all the other similarity factors to be 1
-
-    //System.out.println("Hash: " + seventyHash + " Twice Hash: " + 2*seventyHash);
-    assertTrue(hits.getMaxScore() + " does not equal: " + 4.0, hits.getMaxScore() == 4.0);
-    //there should be exactly 10 items that score a 4, all the rest should score a 2
-    //The 10 items are: 70 + i*100 where i in [0-9]
-    int numTens = 0;
-    for (int i = 0; i < hits.scoreDocs.length; i++) {
-      ScoreDoc doc = hits.scoreDocs[i];
-      if (doc.doc % 10 == 0) {
-        numTens++;
-        assertTrue(doc.score + " does not equal: " + 4.0, doc.score == 4.0);
-      } else {
-        assertTrue(doc.score + " does not equal: " + 2, doc.score == 2);
-      }
-    }
-    assertTrue(numTens + " does not equal: " + 10, numTens == 10);
-    CheckHits.checkExplanations(query, "field", searcher, true);
-    Spans spans = query.getSpans(searcher.getIndexReader());
-    assertTrue("spans is null and it shouldn't be", spans != null);
-    assertTrue("spans is not an instanceof " + TermSpans.class, spans instanceof TermSpans);
-    //should be two matches per document
-    int count = 0;
-    //100 hits times 2 matches per hit, we should have 200 in count
-    while (spans.next()) {
-      count++;
-    }
-  }
-
-  public void testNoMatch() throws Exception {
-    BoostingFunctionTermQuery query = new BoostingFunctionTermQuery(new Term(PayloadHelper.FIELD, "junk"),
-            new MaxPayloadFunction());
-    TopDocs hits = searcher.search(query, null, 100);
-    assertTrue("hits is null and it shouldn't be", hits != null);
-    assertTrue("hits Size: " + hits.totalHits + " is not: " + 0, hits.totalHits == 0);
-
-  }
-
-  public void testNoPayload() throws Exception {
-    BoostingFunctionTermQuery q1 = new BoostingFunctionTermQuery(new Term(PayloadHelper.NO_PAYLOAD_FIELD, "zero"),
-            new MaxPayloadFunction());
-    BoostingFunctionTermQuery q2 = new BoostingFunctionTermQuery(new Term(PayloadHelper.NO_PAYLOAD_FIELD, "foo"),
-            new MaxPayloadFunction());
-    BooleanClause c1 = new BooleanClause(q1, BooleanClause.Occur.MUST);
-    BooleanClause c2 = new BooleanClause(q2, BooleanClause.Occur.MUST_NOT);
-    BooleanQuery query = new BooleanQuery();
-    query.add(c1);
-    query.add(c2);
-    TopDocs hits = searcher.search(query, null, 100);
-    assertTrue("hits is null and it shouldn't be", hits != null);
-    assertTrue("hits Size: " + hits.totalHits + " is not: " + 1, hits.totalHits == 1);
-    int[] results = new int[1];
-    results[0] = 0;//hits.scoreDocs[0].doc;
-    CheckHits.checkHitCollector(query, PayloadHelper.NO_PAYLOAD_FIELD, searcher, results);
-  }
-
-  // must be static for weight serialization tests 
-  static class BoostingSimilarity extends DefaultSimilarity {
-
-    // TODO: Remove warning after API has been finalized
-    public float scorePayload(int docId, String fieldName, int start, int end, byte[] payload, int offset, int length) {
-      //we know it is size 4 here, so ignore the offset/length
-      return payload[0];
-    }
-
-    //!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
-    //Make everything else 1 so we see the effect of the payload
-    //!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
-    public float lengthNorm(String fieldName, int numTerms) {
-      return 1;
-    }
-
-    public float queryNorm(float sumOfSquaredWeights) {
-      return 1;
-    }
-
-    public float sloppyFreq(int distance) {
-      return 1;
-    }
-
-    public float coord(int overlap, int maxOverlap) {
-      return 1;
-    }
-
-    public float idf(int docFreq, int numDocs) {
-      return 1;
-    }
-
-    public float tf(float freq) {
-      return freq == 0 ? 0 : 1;
-    }
-  }
-
-  static class FullSimilarity extends DefaultSimilarity{
-    public float scorePayload(int docId, String fieldName, byte[] payload, int offset, int length) {
-      //we know it is size 4 here, so ignore the offset/length
-      return payload[0];
-    }
-  }
-
-}
diff --git a/src/test/org/apache/lucene/search/payloads/TestBoostingNearQuery.java b/src/test/org/apache/lucene/search/payloads/TestBoostingNearQuery.java
deleted file mode 100644
index f46aca6..0000000
--- a/src/test/org/apache/lucene/search/payloads/TestBoostingNearQuery.java
+++ /dev/null
@@ -1,221 +0,0 @@
-package org.apache.lucene.search.payloads;
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-import java.io.IOException;
-import java.io.Reader;
-import java.util.Collection;
-
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.LowerCaseTokenizer;
-import org.apache.lucene.analysis.Token;
-import org.apache.lucene.analysis.TokenFilter;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.Payload;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.DefaultSimilarity;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.QueryUtils;
-import org.apache.lucene.search.ScoreDoc;
-import org.apache.lucene.search.Searcher;
-import org.apache.lucene.search.TopDocs;
-import org.apache.lucene.search.spans.SpanQuery;
-import org.apache.lucene.store.RAMDirectory;
-import org.apache.lucene.util.English;
-import org.apache.lucene.util.LuceneTestCase;
-
-
-public class TestBoostingNearQuery extends LuceneTestCase {
-	private IndexSearcher searcher;
-	private BoostingSimilarity similarity = new BoostingSimilarity();
-	private byte[] payload2 = new byte[]{2};
-	private byte[] payload4 = new byte[]{4};
-
-	public TestBoostingNearQuery(String s) {
-		super(s);
-	}
-
-	private class PayloadAnalyzer extends Analyzer {
-		public TokenStream tokenStream(String fieldName, Reader reader) {
-			TokenStream result = new LowerCaseTokenizer(reader);
-			result = new PayloadFilter(result, fieldName);
-			return result;
-		}
-	}
-
-	private class PayloadFilter extends TokenFilter {
-		String fieldName;
-		int numSeen = 0;
-    protected PayloadAttribute payAtt;
-
-		public PayloadFilter(TokenStream input, String fieldName) {
-			super(input);
-			this.fieldName = fieldName;
-      payAtt = (PayloadAttribute) addAttribute(PayloadAttribute.class);
-		}
-
-    public boolean incrementToken() throws IOException {
-      boolean result = false;
-      if (input.incrementToken() == true){
-        if (numSeen % 2 == 0) {
-					payAtt.setPayload(new Payload(payload2));
-				} else {
-					payAtt.setPayload(new Payload(payload4));
-				}
-				numSeen++;
-        result = true;
-      }
-      return result;
-    }
-  }
-  
-	private BoostingNearQuery newPhraseQuery (String fieldName, String phrase, boolean inOrder) {
-		int n;
-		String[] words = phrase.split("[\\s]+");
-		SpanQuery clauses[] = new SpanQuery[words.length];
-		for (int i=0;i<clauses.length;i++) {
-			clauses[i] = new BoostingTermQuery(new Term(fieldName, words[i]));  
-		} 
-		return new BoostingNearQuery(clauses, 0, inOrder);
-	}
-
-	protected void setUp() throws Exception {
-		super.setUp();
-		RAMDirectory directory = new RAMDirectory();
-		PayloadAnalyzer analyzer = new PayloadAnalyzer();
-		IndexWriter writer
-		= new IndexWriter(directory, analyzer, true, IndexWriter.MaxFieldLength.LIMITED);
-		writer.setSimilarity(similarity);
-		//writer.infoStream = System.out;
-		for (int i = 0; i < 1000; i++) {
-			Document doc = new Document();
-			doc.add(new Field("field", English.intToEnglish(i), Field.Store.YES, Field.Index.ANALYZED));
-			writer.addDocument(doc);
-		}
-		writer.optimize();
-		writer.close();
-
-		searcher = new IndexSearcher(directory, true);
-		searcher.setSimilarity(similarity);
-	}
-
-	public void test() throws IOException {
-		BoostingNearQuery query;
-		TopDocs hits;
-
-		query = newPhraseQuery("field", "twenty two", true);
-		QueryUtils.check(query);
-		
-		// all 10 hits should have score = 3 because adjacent terms have payloads of 2,4
-		// and all the similarity factors are set to 1
-		hits = searcher.search(query, null, 100);
-		assertTrue("hits is null and it shouldn't be", hits != null);
-		assertTrue("should be 10 hits", hits.totalHits == 10);
-		for (int j = 0; j < hits.scoreDocs.length; j++) {
-			ScoreDoc doc = hits.scoreDocs[j];
-			assertTrue(doc.score + " does not equal: " + 3, doc.score == 3);
-		}
-		for (int i=1;i<10;i++) {
-			query = newPhraseQuery("field", English.intToEnglish(i)+" hundred", true);
-			// all should have score = 3 because adjacent terms have payloads of 2,4
-			// and all the similarity factors are set to 1
-			hits = searcher.search(query, null, 100);
-			assertTrue("hits is null and it shouldn't be", hits != null);
-			assertTrue("should be 100 hits", hits.totalHits == 100);
-			for (int j = 0; j < hits.scoreDocs.length; j++) {
-				ScoreDoc doc = hits.scoreDocs[j];
-//				System.out.println("Doc: " + doc.toString());
-//				System.out.println("Explain: " + searcher.explain(query, doc.doc));
-				assertTrue(doc.score + " does not equal: " + 3, doc.score == 3);
-			}
-		}
-	}
-
-	public void testLongerSpan() throws IOException {
-		BoostingNearQuery query;
-		TopDocs hits;
-		query = newPhraseQuery("field", "nine hundred ninety nine", true);
-		hits = searcher.search(query, null, 100);
-		ScoreDoc doc = hits.scoreDocs[0];
-//		System.out.println("Doc: " + doc.toString());
-//		System.out.println("Explain: " + searcher.explain(query, doc.doc));
-		assertTrue("hits is null and it shouldn't be", hits != null);
-		assertTrue("there should only be one hit", hits.totalHits == 1);
-		// should have score = 3 because adjacent terms have payloads of 2,4
-		assertTrue(doc.score + " does not equal: " + 3, doc.score == 3); 
-	}
-
-	public void testComplexNested() throws IOException {
-		BoostingNearQuery query;
-		TopDocs hits;
-
-		// combine ordered and unordered spans with some nesting to make sure all payloads are counted
-
-		SpanQuery q1 = newPhraseQuery("field", "nine hundred", true);
-		SpanQuery q2 = newPhraseQuery("field", "ninety nine", true);
-		SpanQuery q3 = newPhraseQuery("field", "nine ninety", false);
-		SpanQuery q4 = newPhraseQuery("field", "hundred nine", false);
-		SpanQuery[]clauses = new SpanQuery[] {new BoostingNearQuery(new SpanQuery[] {q1,q2}, 0, true), new BoostingNearQuery(new SpanQuery[] {q3,q4}, 0, false)};
-		query = new BoostingNearQuery(clauses, 0, false);
-		hits = searcher.search(query, null, 100);
-		assertTrue("hits is null and it shouldn't be", hits != null);
-		// should be only 1 hit - doc 999
-		assertTrue("should only be one hit", hits.scoreDocs.length == 1);
-		// the score should be 3 - the average of all the underlying payloads
-		ScoreDoc doc = hits.scoreDocs[0];
-//		System.out.println("Doc: " + doc.toString());
-//		System.out.println("Explain: " + searcher.explain(query, doc.doc));
-		assertTrue(doc.score + " does not equal: " + 3, doc.score == 3);  
-	}
-	// must be static for weight serialization tests 
-	static class BoostingSimilarity extends DefaultSimilarity {
-
-// TODO: Remove warning after API has been finalized
-    public float scorePayload(int docId, String fieldName, int start, int end, byte[] payload, int offset, int length) {
-      //we know it is size 4 here, so ignore the offset/length
-      return payload[0];
-    }
-		//!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
-		//Make everything else 1 so we see the effect of the payload
-		//!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
-		public float lengthNorm(String fieldName, int numTerms) {
-			return 1;
-		}
-
-		public float queryNorm(float sumOfSquaredWeights) {
-			return 1;
-		}
-
-		public float sloppyFreq(int distance) {
-			return 1;
-		}
-
-		public float coord(int overlap, int maxOverlap) {
-			return 1;
-		}
-		public float tf(float freq) {
-			return 1;
-		}
-		// idf used for phrase queries
-		public float idf(Collection terms, Searcher searcher) {
-			return 1;
-		}
-	}
-}
diff --git a/src/test/org/apache/lucene/search/payloads/TestPayloadNearQuery.java b/src/test/org/apache/lucene/search/payloads/TestPayloadNearQuery.java
new file mode 100644
index 0000000..1a7770c
--- /dev/null
+++ b/src/test/org/apache/lucene/search/payloads/TestPayloadNearQuery.java
@@ -0,0 +1,221 @@
+package org.apache.lucene.search.payloads;
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+import java.io.IOException;
+import java.io.Reader;
+import java.util.Collection;
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.LowerCaseTokenizer;
+import org.apache.lucene.analysis.Token;
+import org.apache.lucene.analysis.TokenFilter;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.index.IndexWriter;
+import org.apache.lucene.index.Payload;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.DefaultSimilarity;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.QueryUtils;
+import org.apache.lucene.search.ScoreDoc;
+import org.apache.lucene.search.Searcher;
+import org.apache.lucene.search.TopDocs;
+import org.apache.lucene.search.spans.SpanQuery;
+import org.apache.lucene.store.RAMDirectory;
+import org.apache.lucene.util.English;
+import org.apache.lucene.util.LuceneTestCase;
+
+
+public class TestPayloadNearQuery extends LuceneTestCase {
+	private IndexSearcher searcher;
+	private BoostingSimilarity similarity = new BoostingSimilarity();
+	private byte[] payload2 = new byte[]{2};
+	private byte[] payload4 = new byte[]{4};
+
+	public TestPayloadNearQuery(String s) {
+		super(s);
+	}
+
+	private class PayloadAnalyzer extends Analyzer {
+		public TokenStream tokenStream(String fieldName, Reader reader) {
+			TokenStream result = new LowerCaseTokenizer(reader);
+			result = new PayloadFilter(result, fieldName);
+			return result;
+		}
+	}
+
+	private class PayloadFilter extends TokenFilter {
+		String fieldName;
+		int numSeen = 0;
+    protected PayloadAttribute payAtt;
+
+		public PayloadFilter(TokenStream input, String fieldName) {
+			super(input);
+			this.fieldName = fieldName;
+      payAtt = (PayloadAttribute) addAttribute(PayloadAttribute.class);
+		}
+
+    public boolean incrementToken() throws IOException {
+      boolean result = false;
+      if (input.incrementToken() == true){
+        if (numSeen % 2 == 0) {
+					payAtt.setPayload(new Payload(payload2));
+				} else {
+					payAtt.setPayload(new Payload(payload4));
+				}
+				numSeen++;
+        result = true;
+      }
+      return result;
+    }
+  }
+  
+	private PayloadNearQuery newPhraseQuery (String fieldName, String phrase, boolean inOrder) {
+		int n;
+		String[] words = phrase.split("[\\s]+");
+		SpanQuery clauses[] = new SpanQuery[words.length];
+		for (int i=0;i<clauses.length;i++) {
+			clauses[i] = new PayloadTermQuery(new Term(fieldName, words[i]), new AveragePayloadFunction());  
+		} 
+		return new PayloadNearQuery(clauses, 0, inOrder);
+	}
+
+	protected void setUp() throws Exception {
+		super.setUp();
+		RAMDirectory directory = new RAMDirectory();
+		PayloadAnalyzer analyzer = new PayloadAnalyzer();
+		IndexWriter writer
+		= new IndexWriter(directory, analyzer, true, IndexWriter.MaxFieldLength.LIMITED);
+		writer.setSimilarity(similarity);
+		//writer.infoStream = System.out;
+		for (int i = 0; i < 1000; i++) {
+			Document doc = new Document();
+			doc.add(new Field("field", English.intToEnglish(i), Field.Store.YES, Field.Index.ANALYZED));
+			writer.addDocument(doc);
+		}
+		writer.optimize();
+		writer.close();
+
+		searcher = new IndexSearcher(directory, true);
+		searcher.setSimilarity(similarity);
+	}
+
+	public void test() throws IOException {
+		PayloadNearQuery query;
+		TopDocs hits;
+
+		query = newPhraseQuery("field", "twenty two", true);
+		QueryUtils.check(query);
+		
+		// all 10 hits should have score = 3 because adjacent terms have payloads of 2,4
+		// and all the similarity factors are set to 1
+		hits = searcher.search(query, null, 100);
+		assertTrue("hits is null and it shouldn't be", hits != null);
+		assertTrue("should be 10 hits", hits.totalHits == 10);
+		for (int j = 0; j < hits.scoreDocs.length; j++) {
+			ScoreDoc doc = hits.scoreDocs[j];
+			assertTrue(doc.score + " does not equal: " + 3, doc.score == 3);
+		}
+		for (int i=1;i<10;i++) {
+			query = newPhraseQuery("field", English.intToEnglish(i)+" hundred", true);
+			// all should have score = 3 because adjacent terms have payloads of 2,4
+			// and all the similarity factors are set to 1
+			hits = searcher.search(query, null, 100);
+			assertTrue("hits is null and it shouldn't be", hits != null);
+			assertTrue("should be 100 hits", hits.totalHits == 100);
+			for (int j = 0; j < hits.scoreDocs.length; j++) {
+				ScoreDoc doc = hits.scoreDocs[j];
+//				System.out.println("Doc: " + doc.toString());
+//				System.out.println("Explain: " + searcher.explain(query, doc.doc));
+				assertTrue(doc.score + " does not equal: " + 3, doc.score == 3);
+			}
+		}
+	}
+
+	public void testLongerSpan() throws IOException {
+		PayloadNearQuery query;
+		TopDocs hits;
+		query = newPhraseQuery("field", "nine hundred ninety nine", true);
+		hits = searcher.search(query, null, 100);
+		ScoreDoc doc = hits.scoreDocs[0];
+//		System.out.println("Doc: " + doc.toString());
+//		System.out.println("Explain: " + searcher.explain(query, doc.doc));
+		assertTrue("hits is null and it shouldn't be", hits != null);
+		assertTrue("there should only be one hit", hits.totalHits == 1);
+		// should have score = 3 because adjacent terms have payloads of 2,4
+		assertTrue(doc.score + " does not equal: " + 3, doc.score == 3); 
+	}
+
+	public void testComplexNested() throws IOException {
+		PayloadNearQuery query;
+		TopDocs hits;
+
+		// combine ordered and unordered spans with some nesting to make sure all payloads are counted
+
+		SpanQuery q1 = newPhraseQuery("field", "nine hundred", true);
+		SpanQuery q2 = newPhraseQuery("field", "ninety nine", true);
+		SpanQuery q3 = newPhraseQuery("field", "nine ninety", false);
+		SpanQuery q4 = newPhraseQuery("field", "hundred nine", false);
+		SpanQuery[]clauses = new SpanQuery[] {new PayloadNearQuery(new SpanQuery[] {q1,q2}, 0, true), new PayloadNearQuery(new SpanQuery[] {q3,q4}, 0, false)};
+		query = new PayloadNearQuery(clauses, 0, false);
+		hits = searcher.search(query, null, 100);
+		assertTrue("hits is null and it shouldn't be", hits != null);
+		// should be only 1 hit - doc 999
+		assertTrue("should only be one hit", hits.scoreDocs.length == 1);
+		// the score should be 3 - the average of all the underlying payloads
+		ScoreDoc doc = hits.scoreDocs[0];
+//		System.out.println("Doc: " + doc.toString());
+//		System.out.println("Explain: " + searcher.explain(query, doc.doc));
+		assertTrue(doc.score + " does not equal: " + 3, doc.score == 3);  
+	}
+	// must be static for weight serialization tests 
+	static class BoostingSimilarity extends DefaultSimilarity {
+
+// TODO: Remove warning after API has been finalized
+    public float scorePayload(int docId, String fieldName, int start, int end, byte[] payload, int offset, int length) {
+      //we know it is size 4 here, so ignore the offset/length
+      return payload[0];
+    }
+		//!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+		//Make everything else 1 so we see the effect of the payload
+		//!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+		public float lengthNorm(String fieldName, int numTerms) {
+			return 1;
+		}
+
+		public float queryNorm(float sumOfSquaredWeights) {
+			return 1;
+		}
+
+		public float sloppyFreq(int distance) {
+			return 1;
+		}
+
+		public float coord(int overlap, int maxOverlap) {
+			return 1;
+		}
+		public float tf(float freq) {
+			return 1;
+		}
+		// idf used for phrase queries
+		public float idf(Collection terms, Searcher searcher) {
+			return 1;
+		}
+	}
+}
diff --git a/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery.java b/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery.java
new file mode 100644
index 0000000..6c98ecc
--- /dev/null
+++ b/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery.java
@@ -0,0 +1,322 @@
+package org.apache.lucene.search.payloads;
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.English;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.QueryUtils;
+import org.apache.lucene.search.TopDocs;
+import org.apache.lucene.search.ScoreDoc;
+import org.apache.lucene.search.CheckHits;
+import org.apache.lucene.search.BooleanClause;
+import org.apache.lucene.search.BooleanQuery;
+import org.apache.lucene.search.DefaultSimilarity;
+import org.apache.lucene.search.spans.SpanTermQuery;
+import org.apache.lucene.search.spans.Spans;
+import org.apache.lucene.search.spans.TermSpans;
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.LowerCaseTokenizer;
+import org.apache.lucene.analysis.TokenFilter;
+import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;
+import org.apache.lucene.index.Payload;
+import org.apache.lucene.index.IndexWriter;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.store.RAMDirectory;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+
+import java.io.Reader;
+import java.io.IOException;
+
+
+/**
+ *
+ *
+ **/
+public class TestPayloadTermQuery extends LuceneTestCase {
+  private IndexSearcher searcher;
+  private BoostingSimilarity similarity = new BoostingSimilarity();
+  private byte[] payloadField = new byte[]{1};
+  private byte[] payloadMultiField1 = new byte[]{2};
+  private byte[] payloadMultiField2 = new byte[]{4};
+  protected RAMDirectory directory;
+
+  public TestPayloadTermQuery(String s) {
+    super(s);
+  }
+
+  private class PayloadAnalyzer extends Analyzer {
+
+
+    public TokenStream tokenStream(String fieldName, Reader reader) {
+      TokenStream result = new LowerCaseTokenizer(reader);
+      result = new PayloadFilter(result, fieldName);
+      return result;
+    }
+  }
+
+  private class PayloadFilter extends TokenFilter {
+    String fieldName;
+    int numSeen = 0;
+    
+    PayloadAttribute payloadAtt;    
+    
+    public PayloadFilter(TokenStream input, String fieldName) {
+      super(input);
+      this.fieldName = fieldName;
+      payloadAtt = (PayloadAttribute) addAttribute(PayloadAttribute.class);
+    }
+    
+    public boolean incrementToken() throws IOException {
+      boolean hasNext = input.incrementToken();
+      if (hasNext) {
+        if (fieldName.equals("field")) {
+          payloadAtt.setPayload(new Payload(payloadField));
+        } else if (fieldName.equals("multiField")) {
+          if (numSeen % 2 == 0) {
+            payloadAtt.setPayload(new Payload(payloadMultiField1));
+          } else {
+            payloadAtt.setPayload(new Payload(payloadMultiField2));
+          }
+          numSeen++;
+        }
+        return true;
+      } else {
+        return false;
+      }
+    }
+  }
+
+  protected void setUp() throws Exception {
+    super.setUp();
+    directory = new RAMDirectory();
+    PayloadAnalyzer analyzer = new PayloadAnalyzer();
+    IndexWriter writer
+            = new IndexWriter(directory, analyzer, true, IndexWriter.MaxFieldLength.LIMITED);
+    writer.setSimilarity(similarity);
+    //writer.infoStream = System.out;
+    for (int i = 0; i < 1000; i++) {
+      Document doc = new Document();
+      Field noPayloadField = new Field(PayloadHelper.NO_PAYLOAD_FIELD, English.intToEnglish(i), Field.Store.YES, Field.Index.ANALYZED);
+      //noPayloadField.setBoost(0);
+      doc.add(noPayloadField);
+      doc.add(new Field("field", English.intToEnglish(i), Field.Store.YES, Field.Index.ANALYZED));
+      doc.add(new Field("multiField", English.intToEnglish(i) + "  " + English.intToEnglish(i), Field.Store.YES, Field.Index.ANALYZED));
+      writer.addDocument(doc);
+    }
+    writer.optimize();
+    writer.close();
+
+    searcher = new IndexSearcher(directory, true);
+    searcher.setSimilarity(similarity);
+  }
+
+  public void test() throws IOException {
+    PayloadTermQuery query = new PayloadTermQuery(new Term("field", "seventy"),
+            new MaxPayloadFunction());
+    TopDocs hits = searcher.search(query, null, 100);
+    assertTrue("hits is null and it shouldn't be", hits != null);
+    assertTrue("hits Size: " + hits.totalHits + " is not: " + 100, hits.totalHits == 100);
+
+    //they should all have the exact same score, because they all contain seventy once, and we set
+    //all the other similarity factors to be 1
+
+    assertTrue(hits.getMaxScore() + " does not equal: " + 1, hits.getMaxScore() == 1);
+    for (int i = 0; i < hits.scoreDocs.length; i++) {
+      ScoreDoc doc = hits.scoreDocs[i];
+      assertTrue(doc.score + " does not equal: " + 1, doc.score == 1);
+    }
+    CheckHits.checkExplanations(query, PayloadHelper.FIELD, searcher, true);
+    Spans spans = query.getSpans(searcher.getIndexReader());
+    assertTrue("spans is null and it shouldn't be", spans != null);
+    assertTrue("spans is not an instanceof " + TermSpans.class, spans instanceof TermSpans);
+    /*float score = hits.score(0);
+    for (int i =1; i < hits.length(); i++)
+    {
+      assertTrue("scores are not equal and they should be", score == hits.score(i));
+    }*/
+
+  }
+  
+  public void testQuery() {
+    PayloadTermQuery boostingFuncTermQuery = new PayloadTermQuery(new Term(PayloadHelper.MULTI_FIELD, "seventy"),
+        new MaxPayloadFunction());
+    QueryUtils.check(boostingFuncTermQuery);
+    
+    SpanTermQuery spanTermQuery = new SpanTermQuery(new Term(PayloadHelper.MULTI_FIELD, "seventy"));
+
+    assertTrue(boostingFuncTermQuery.equals(spanTermQuery) == spanTermQuery.equals(boostingFuncTermQuery));
+    
+    PayloadTermQuery boostingFuncTermQuery2 = new PayloadTermQuery(new Term(PayloadHelper.MULTI_FIELD, "seventy"),
+        new AveragePayloadFunction());
+    
+    QueryUtils.checkUnequal(boostingFuncTermQuery, boostingFuncTermQuery2);
+  }
+
+  public void testMultipleMatchesPerDoc() throws Exception {
+    PayloadTermQuery query = new PayloadTermQuery(new Term(PayloadHelper.MULTI_FIELD, "seventy"),
+            new MaxPayloadFunction());
+    TopDocs hits = searcher.search(query, null, 100);
+    assertTrue("hits is null and it shouldn't be", hits != null);
+    assertTrue("hits Size: " + hits.totalHits + " is not: " + 100, hits.totalHits == 100);
+
+    //they should all have the exact same score, because they all contain seventy once, and we set
+    //all the other similarity factors to be 1
+
+    //System.out.println("Hash: " + seventyHash + " Twice Hash: " + 2*seventyHash);
+    assertTrue(hits.getMaxScore() + " does not equal: " + 4.0, hits.getMaxScore() == 4.0);
+    //there should be exactly 10 items that score a 4, all the rest should score a 2
+    //The 10 items are: 70 + i*100 where i in [0-9]
+    int numTens = 0;
+    for (int i = 0; i < hits.scoreDocs.length; i++) {
+      ScoreDoc doc = hits.scoreDocs[i];
+      if (doc.doc % 10 == 0) {
+        numTens++;
+        assertTrue(doc.score + " does not equal: " + 4.0, doc.score == 4.0);
+      } else {
+        assertTrue(doc.score + " does not equal: " + 2, doc.score == 2);
+      }
+    }
+    assertTrue(numTens + " does not equal: " + 10, numTens == 10);
+    CheckHits.checkExplanations(query, "field", searcher, true);
+    Spans spans = query.getSpans(searcher.getIndexReader());
+    assertTrue("spans is null and it shouldn't be", spans != null);
+    assertTrue("spans is not an instanceof " + TermSpans.class, spans instanceof TermSpans);
+    //should be two matches per document
+    int count = 0;
+    //100 hits times 2 matches per hit, we should have 200 in count
+    while (spans.next()) {
+      count++;
+    }
+    assertTrue(count + " does not equal: " + 200, count == 200);
+  }
+
+  //Set includeSpanScore to false, in which case just the payload score comes through.
+  public void testIgnoreSpanScorer() throws Exception {
+    PayloadTermQuery query = new PayloadTermQuery(new Term(PayloadHelper.MULTI_FIELD, "seventy"),
+            new MaxPayloadFunction(), false);
+
+    IndexSearcher theSearcher = new IndexSearcher(directory, true);
+    theSearcher.setSimilarity(new FullSimilarity());
+    TopDocs hits = searcher.search(query, null, 100);
+    assertTrue("hits is null and it shouldn't be", hits != null);
+    assertTrue("hits Size: " + hits.totalHits + " is not: " + 100, hits.totalHits == 100);
+
+    //they should all have the exact same score, because they all contain seventy once, and we set
+    //all the other similarity factors to be 1
+
+    //System.out.println("Hash: " + seventyHash + " Twice Hash: " + 2*seventyHash);
+    assertTrue(hits.getMaxScore() + " does not equal: " + 4.0, hits.getMaxScore() == 4.0);
+    //there should be exactly 10 items that score a 4, all the rest should score a 2
+    //The 10 items are: 70 + i*100 where i in [0-9]
+    int numTens = 0;
+    for (int i = 0; i < hits.scoreDocs.length; i++) {
+      ScoreDoc doc = hits.scoreDocs[i];
+      if (doc.doc % 10 == 0) {
+        numTens++;
+        assertTrue(doc.score + " does not equal: " + 4.0, doc.score == 4.0);
+      } else {
+        assertTrue(doc.score + " does not equal: " + 2, doc.score == 2);
+      }
+    }
+    assertTrue(numTens + " does not equal: " + 10, numTens == 10);
+    CheckHits.checkExplanations(query, "field", searcher, true);
+    Spans spans = query.getSpans(searcher.getIndexReader());
+    assertTrue("spans is null and it shouldn't be", spans != null);
+    assertTrue("spans is not an instanceof " + TermSpans.class, spans instanceof TermSpans);
+    //should be two matches per document
+    int count = 0;
+    //100 hits times 2 matches per hit, we should have 200 in count
+    while (spans.next()) {
+      count++;
+    }
+  }
+
+  public void testNoMatch() throws Exception {
+    PayloadTermQuery query = new PayloadTermQuery(new Term(PayloadHelper.FIELD, "junk"),
+            new MaxPayloadFunction());
+    TopDocs hits = searcher.search(query, null, 100);
+    assertTrue("hits is null and it shouldn't be", hits != null);
+    assertTrue("hits Size: " + hits.totalHits + " is not: " + 0, hits.totalHits == 0);
+
+  }
+
+  public void testNoPayload() throws Exception {
+    PayloadTermQuery q1 = new PayloadTermQuery(new Term(PayloadHelper.NO_PAYLOAD_FIELD, "zero"),
+            new MaxPayloadFunction());
+    PayloadTermQuery q2 = new PayloadTermQuery(new Term(PayloadHelper.NO_PAYLOAD_FIELD, "foo"),
+            new MaxPayloadFunction());
+    BooleanClause c1 = new BooleanClause(q1, BooleanClause.Occur.MUST);
+    BooleanClause c2 = new BooleanClause(q2, BooleanClause.Occur.MUST_NOT);
+    BooleanQuery query = new BooleanQuery();
+    query.add(c1);
+    query.add(c2);
+    TopDocs hits = searcher.search(query, null, 100);
+    assertTrue("hits is null and it shouldn't be", hits != null);
+    assertTrue("hits Size: " + hits.totalHits + " is not: " + 1, hits.totalHits == 1);
+    int[] results = new int[1];
+    results[0] = 0;//hits.scoreDocs[0].doc;
+    CheckHits.checkHitCollector(query, PayloadHelper.NO_PAYLOAD_FIELD, searcher, results);
+  }
+
+  // must be static for weight serialization tests 
+  static class BoostingSimilarity extends DefaultSimilarity {
+
+    // TODO: Remove warning after API has been finalized
+    public float scorePayload(int docId, String fieldName, int start, int end, byte[] payload, int offset, int length) {
+      //we know it is size 4 here, so ignore the offset/length
+      return payload[0];
+    }
+
+    //!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    //Make everything else 1 so we see the effect of the payload
+    //!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    public float lengthNorm(String fieldName, int numTerms) {
+      return 1;
+    }
+
+    public float queryNorm(float sumOfSquaredWeights) {
+      return 1;
+    }
+
+    public float sloppyFreq(int distance) {
+      return 1;
+    }
+
+    public float coord(int overlap, int maxOverlap) {
+      return 1;
+    }
+
+    public float idf(int docFreq, int numDocs) {
+      return 1;
+    }
+
+    public float tf(float freq) {
+      return freq == 0 ? 0 : 1;
+    }
+  }
+
+  static class FullSimilarity extends DefaultSimilarity{
+    public float scorePayload(int docId, String fieldName, byte[] payload, int offset, int length) {
+      //we know it is size 4 here, so ignore the offset/length
+      return payload[0];
+    }
+  }
+
+}

