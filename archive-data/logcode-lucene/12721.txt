GitDiffStart: 0bf1f362eb88a31ebc7fd59053a00df1ad6b44b4 | Sun Apr 22 12:55:11 2012 +0000
diff --git a/lucene/MIGRATE.txt b/lucene/MIGRATE.txt
index 2a94e41..b7afc69 100644
--- a/lucene/MIGRATE.txt
+++ b/lucene/MIGRATE.txt
@@ -376,7 +376,7 @@ LUCENE-1458, LUCENE-2111: Flexible Indexing
     - o.a.l.util.CharacterUtils -> o.a.l.analysis.util.CharacterUtils
 
 * LUCENE-2514: The option to use a Collator's order (instead of binary order) for
-  sorting and range queries has been moved to contrib/queries.
+  sorting and range queries has been moved to lucene/queries.
 
   The Collated TermRangeQuery/Filter has been moved to SlowCollatedTermRangeQuery/Filter, 
   and the collated sorting has been moved to SlowCollatedStringComparator.
diff --git a/lucene/NOTICE.txt b/lucene/NOTICE.txt
index a20f302..e3c5962 100644
--- a/lucene/NOTICE.txt
+++ b/lucene/NOTICE.txt
@@ -12,8 +12,7 @@ including, but not limited to:
  - Apache Xerces
 
 ICU4J, (under analysis/icu) is licensed under an MIT styles license
-(contrib/icu/lib/ICU-LICENSE.txt) and Copyright (c) 1995-2008 
-International Business Machines Corporation and others
+and Copyright (c) 1995-2008 International Business Machines Corporation and others
 
 Some data files (under analysis/icu/src/data) are derived from Unicode data such
 as the Unicode Character Database. See http://unicode.org/copyright.html for more
diff --git a/lucene/analysis/icu/src/java/overview.html b/lucene/analysis/icu/src/java/overview.html
index 26dae8d..cc129ef 100644
--- a/lucene/analysis/icu/src/java/overview.html
+++ b/lucene/analysis/icu/src/java/overview.html
@@ -79,17 +79,14 @@ algorithm.
 <hr/>
 <h1><a name="collation">Collation</a></h1>
 <p>
-  <code>ICUCollationKeyFilter</code>
+  <code>ICUCollationKeyAnalyzer</code>
   converts each token into its binary <code>CollationKey</code> using the 
-  provided <code>Collator</code>, and then encode the <code>CollationKey</code>
-  as a String using
-  {@link org.apache.lucene.util.IndexableBinaryStringTools}, to allow it to be 
+  provided <code>Collator</code>, allowing it to be 
   stored as an index term.
 </p>
 <p>
-  <code>ICUCollationKeyFilter</code> depends on ICU4J 4.4 to produce the 
-  <code>CollationKey</code>s.  <code>icu4j-4.4.jar</code>
-  is included in Lucene's Subversion repository at <code>contrib/icu/lib/</code>.
+  <code>ICUCollationKeyAnalyzer</code> depends on ICU4J to produce the 
+  <code>CollationKey</code>s.
 </p>
 
 <h2>Use Cases</h2>
@@ -209,11 +206,11 @@ algorithm.
   </li>
 </ol> 
 <p>
-  <code>ICUCollationKeyFilter</code> uses ICU4J's <code>Collator</code>, which 
+  <code>ICUCollationKeyAnalyzer</code> uses ICU4J's <code>Collator</code>, which 
   makes its version available, thus allowing collation to be versioned
-  independently from the JVM.  <code>ICUCollationKeyFilter</code> is also 
+  independently from the JVM.  <code>ICUCollationKeyAnalyzer</code> is also 
   significantly faster and generates significantly shorter keys than 
-  <code>CollationKeyFilter</code>.  See
+  <code>CollationKeyAnalyzer</code>.  See
   <a href="http://site.icu-project.org/charts/collation-icu4j-sun"
     >http://site.icu-project.org/charts/collation-icu4j-sun</a> for key
   generation timing and key length comparisons between ICU4J and
@@ -222,8 +219,8 @@ algorithm.
 <p>
   <code>CollationKey</code>s generated by <code>java.text.Collator</code>s are 
   not compatible with those those generated by ICU Collators.  Specifically, if
-  you use <code>CollationKeyFilter</code> to generate index terms, do not use
-  <code>ICUCollationKeyFilter</code> on the query side, or vice versa.
+  you use <code>CollationKeyAnalyzer</code> to generate index terms, do not use
+  <code>ICUCollationKeyAnalyzer</code> on the query side, or vice versa.
 </p>
 <hr/>
 <h1><a name="normalization">Normalization</a></h1>
diff --git a/lucene/benchmark/conf/createLineFile.alg b/lucene/benchmark/conf/createLineFile.alg
index cad01d9..b53456a 100644
--- a/lucene/benchmark/conf/createLineFile.alg
+++ b/lucene/benchmark/conf/createLineFile.alg
@@ -20,7 +20,7 @@
 # This alg will process the Reuters documents feed to produce a
 # single file that contains all documents, one per line.
 #
-# To use this, first cd to contrib/benchmark and then run:
+# To use this, first cd to benchmark and then run:
 #
 #   ant run-task -Dtask.alg=conf/createLineFile.alg
 #
diff --git a/lucene/benchmark/conf/extractWikipedia.alg b/lucene/benchmark/conf/extractWikipedia.alg
index f0df54d..6f56986 100644
--- a/lucene/benchmark/conf/extractWikipedia.alg
+++ b/lucene/benchmark/conf/extractWikipedia.alg
@@ -20,7 +20,7 @@
 # This alg will process the Wikipedia documents feed to produce a
 # single file that contains all documents, one per line.
 #
-# To use this, first cd to contrib/benchmark and then run:
+# To use this, first cd to benchmark and then run:
 #
 #   ant run-task -Dtask.alg=conf/extractWikipedia.alg
 #
diff --git a/lucene/benchmark/conf/indexLineFile.alg b/lucene/benchmark/conf/indexLineFile.alg
index bcb9922..5748d42 100644
--- a/lucene/benchmark/conf/indexLineFile.alg
+++ b/lucene/benchmark/conf/indexLineFile.alg
@@ -24,7 +24,7 @@
 # indexing your documents vs time spent creating the documents.
 #
 # To use this, you must first run the createLineFile.alg, then cd to
-# contrib/benchmark and then run:
+# benchmark and then run:
 #
 #   ant run-task -Dtask.alg=conf/indexLineFile.alg
 #
diff --git a/lucene/benchmark/conf/readContentSource.alg b/lucene/benchmark/conf/readContentSource.alg
index 9923af0..0759cc9 100644
--- a/lucene/benchmark/conf/readContentSource.alg
+++ b/lucene/benchmark/conf/readContentSource.alg
@@ -22,7 +22,7 @@
 # gather baselines for operations like indexing (if reading from the content 
 # source takes 'X' time, we cannot index faster).
 #
-# To use this, first cd to contrib/benchmark and then run:
+# To use this, first cd to benchmark and then run:
 #
 #   ant run-task -Dtask.alg=conf/readContentSource.alg
 #
diff --git a/lucene/benchmark/conf/tokenize.alg b/lucene/benchmark/conf/tokenize.alg
index 57951ff..2ab105d 100644
--- a/lucene/benchmark/conf/tokenize.alg
+++ b/lucene/benchmark/conf/tokenize.alg
@@ -20,7 +20,7 @@
 # This alg reads all tokens out of a document but does not index them.
 # This is useful for benchmarking tokenizers.
 #
-# To use this, cd to contrib/benchmark and then run:
+# To use this, cd to benchmark and then run:
 #
 #   ant run-task -Dtask.alg=conf/tokenize.alg
 #
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/package.html b/lucene/core/src/java/org/apache/lucene/analysis/package.html
index 0ac07e6..d5e10cf 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/package.html
+++ b/lucene/core/src/java/org/apache/lucene/analysis/package.html
@@ -229,7 +229,7 @@ and proximity searches (though sentence identification is not provided by Lucene
   Tokenizer, and TokenFilter(s) <i>(optional)</i> &mdash; or components you
   create, or a combination of existing and newly created components.  Before
   pursuing this approach, you may find it worthwhile to explore the
-  contrib/analyzers library and/or ask on the 
+  <a href="{@docRoot}/../analyzers-common/overview-summary.html">analyzers-common</a> library and/or ask on the 
   <a href="http://lucene.apache.org/java/docs/mailinglists.html"
       >java-user@lucene.apache.org mailing list</a> first to see if what you
   need already exists. If you are still committed to creating your own
diff --git a/lucene/core/src/java/org/apache/lucene/search/FieldCacheTermsFilter.java b/lucene/core/src/java/org/apache/lucene/search/FieldCacheTermsFilter.java
index f5974a1..172c71d 100644
--- a/lucene/core/src/java/org/apache/lucene/search/FieldCacheTermsFilter.java
+++ b/lucene/core/src/java/org/apache/lucene/search/FieldCacheTermsFilter.java
@@ -34,7 +34,7 @@ import org.apache.lucene.util.BytesRef;
  * <p/>
  * 
  * This is the same functionality as TermsFilter (from
- * contrib/queries), except this filter requires that the
+ * queries/), except this filter requires that the
  * field contains only a single term for all documents.
  * Because of drastically different implementations, they
  * also have different performance characteristics, as
diff --git a/lucene/core/src/java/org/apache/lucene/search/FilteredDocIdSet.java b/lucene/core/src/java/org/apache/lucene/search/FilteredDocIdSet.java
index a9f908a..4b316f5 100644
--- a/lucene/core/src/java/org/apache/lucene/search/FilteredDocIdSet.java
+++ b/lucene/core/src/java/org/apache/lucene/search/FilteredDocIdSet.java
@@ -28,7 +28,7 @@ import org.apache.lucene.util.Bits;
  * <p/>
  *
  * Technically, this same functionality could be achieved
- * with ChainedFilter (under contrib/misc), however the
+ * with ChainedFilter (under queries/), however the
  * benefit of this class is it never materializes the full
  * bitset for the filter.  Instead, the {@link #match}
  * method is invoked on-demand, per docID visited during
diff --git a/lucene/core/src/java/org/apache/lucene/search/RegexpQuery.java b/lucene/core/src/java/org/apache/lucene/search/RegexpQuery.java
index 19dafa3..3f77c99 100644
--- a/lucene/core/src/java/org/apache/lucene/search/RegexpQuery.java
+++ b/lucene/core/src/java/org/apache/lucene/search/RegexpQuery.java
@@ -38,7 +38,7 @@ import org.apache.lucene.util.automaton.RegExp;
  * <p>
  * The supported syntax is documented in the {@link RegExp} class.
  * Note this might be different than other regular expression implementations.
- * For some alternatives with different syntax, look under contrib/regex
+ * For some alternatives with different syntax, look under the sandbox.
  * </p>
  * <p>
  * Note this query can be slow, as it needs to iterate over many terms. In order
diff --git a/lucene/misc/README.txt b/lucene/misc/README.txt
index 29c5803..44560ee 100644
--- a/lucene/misc/README.txt
+++ b/lucene/misc/README.txt
@@ -1,3 +1,3 @@
-contrib/miscellaneous is a home of different Lucene-related classes
+miscellaneous is a home of different Lucene-related classes
 that all belong to org.apache.lucene.misc package, as they are not
 substantial enough to warrant their own package.
diff --git a/lucene/misc/src/java/overview.html b/lucene/misc/src/java/overview.html
index a2c668d..1423edd 100644
--- a/lucene/misc/src/java/overview.html
+++ b/lucene/misc/src/java/overview.html
@@ -47,7 +47,7 @@ for details.
 
 Steps to build:
 <ul>
-  <li> <tt>cd lucene/contrib/misc/</tt>
+  <li> <tt>cd lucene/misc/</tt>
 
   <li> To compile NativePosixUtil.cpp -> libNativePosixUtil.so, run<tt> ant build-native-unix</tt>.
   
diff --git a/lucene/test-framework/src/java/org/apache/lucene/util/LineFileDocs.java b/lucene/test-framework/src/java/org/apache/lucene/util/LineFileDocs.java
index b6787cc..2373e4b 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/util/LineFileDocs.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/util/LineFileDocs.java
@@ -36,9 +36,9 @@ import org.apache.lucene.document.StringField;
 import org.apache.lucene.document.TextField;
 import org.apache.lucene.index.DocValues;
 
-/** Minimal port of contrib/benchmark's LneDocSource +
+/** Minimal port of benchmark's LneDocSource +
  * DocMaker, so tests can enum docs from a line file created
- * by contrib/benchmark's WriteLineDoc task */
+ * by benchmark's WriteLineDoc task */
 public class LineFileDocs implements Closeable {
 
   private BufferedReader reader;
diff --git a/solr/NOTICE.txt b/solr/NOTICE.txt
index 7268c9b..28c95cb 100644
--- a/solr/NOTICE.txt
+++ b/solr/NOTICE.txt
@@ -49,8 +49,7 @@ including, but not limited to:
  - Apache Xerces
 
 ICU4J, (under analysis/icu) is licensed under an MIT styles license
-(contrib/icu/lib/ICU-LICENSE.txt) and Copyright (c) 1995-2008 
-International Business Machines Corporation and others
+and Copyright (c) 1995-2008 International Business Machines Corporation and others
 
 Some data files (under analysis/icu/src/data) are derived from Unicode data such
 as the Unicode Character Database. See http://unicode.org/copyright.html for more

