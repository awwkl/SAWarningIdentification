GitDiffStart: dc58134cdc235d07a0790794a75d1e690e791460 | Fri Apr 1 06:58:12 2011 +0000
diff --git a/dev-tools/eclipse/dot.classpath b/dev-tools/eclipse/dot.classpath
index 987ea9f..a5d64f9 100644
--- a/dev-tools/eclipse/dot.classpath
+++ b/dev-tools/eclipse/dot.classpath
@@ -57,6 +57,7 @@
 	<classpathentry kind="src" path="solr/src/webapp/src"/>
 	<classpathentry kind="src" path="solr/src/common"/>
 	<classpathentry kind="src" path="solr/src/solrj"/>
+	<classpathentry kind="src" path="solr/src/test-framework"/>
 	<classpathentry kind="src" path="solr/src/test"/>
 	<classpathentry kind="src" path="solr/src/test-files"/>
 	<classpathentry kind="src" path="solr/contrib/analysis-extras/src/java"/>
diff --git a/lucene/common-build.xml b/lucene/common-build.xml
index 3225f7e..5d17436 100644
--- a/lucene/common-build.xml
+++ b/lucene/common-build.xml
@@ -515,8 +515,11 @@
               <sysproperty key="tests.seed" value="${tests.seed}"/>
               <!-- set the Version that tests should run against -->
               <sysproperty key="tests.luceneMatchVersion" value="${tests.luceneMatchVersion}"/>
-              <!-- for lucene we can be strict, and we don't want false fails even across methods -->
+              <!-- for lucene we can be strict, and we don't want false fails even across methods
+              make this a param so lucene-core/contrib tests use it only?
               <sysproperty key="tests.cleanthreads" value="perMethod"/>
+              -->
+	    	  <sysproperty key="tests.cleanthreads" value="perClass"/>
               <!-- logging config file -->
               <sysproperty key="java.util.logging.config.file" value="${tests.loggingfile}"/>
           <!-- set whether or not nightly tests should run -->
diff --git a/solr/build.xml b/solr/build.xml
index 5821f99..82c1cd0 100644
--- a/solr/build.xml
+++ b/solr/build.xml
@@ -17,36 +17,81 @@
  limitations under the License.
 -->
 
-<project name="solr" default="usage" basedir="." xmlns:artifact="antlib:org.apache.maven.artifact.ant">
+<project name="solr-core" default="usage">
+  <description>Solr</description>
 
-  <property name="solr-path" value="." />
-	
-  <import file="common-build.xml"/>
-  
-  <!-- 3rd party libraries for compilation -->
-  <property name="lib" location="lib" />
-
-  <!-- solr source files -->
-  <property name="src" location="src" />
-  <property name="web.xml" location="${src}/webapp/web/WEB-INF/web.xml"/>
+  <property name="src.dir" location="src/java"/>
 
-  <!-- Destination for distribution files (demo WAR, contrib JARs, etc.) -->
-  <property name="dist" location="dist" />
+  <!-- solr uses this as the test working directory: nocommit classpath -->
+  <property name="tests.userdir" value="src/test-files"/>
 
-  <property name="clover.db.dir" location="${dest}/tests/clover/db"/>
-  <property name="clover.report.dir" location="${dest}/tests/clover/reports"/>
+  <path id="additional.dependencies">
+  	<fileset dir="lib" includes="**/*.jar"/>
+  	<fileset dir="example/lib" includes="**/*.jar"/>
+  </path>
   
-    <available
-            property="clover.present"
-            classname="com.cenqua.clover.tasks.CloverReportTask"
-            />
-   <condition property="clover.enabled">
-       <and>
-           <isset property="run.clover"/>
-           <isset property="clover.present"/>
-       </and>
-   </condition>
-                 
+  <import file="common-build.xml"/>
+
+  <!-- add some descriptions to some inherited targets -->
+  <target name="compile" description="Compile the source code." 
+  	      depends="compile-core, build-contrib"/>
+  <target name="test" description="Run core and contrib unit tests." 
+  	      depends="common.test, test-contrib"/>
+  <target name="test-core" description="Runs the core unit tests."
+          depends="common.test"/>
+  <target name="compile-test" description="Compile unit tests." 
+   	      depends="compile-test-framework, common.compile-test"/>
+  <target name="javadocs" description="Generate javadocs for core, client, and contrib" 
+          depends="contrib-build.javadocs, javadocs-solrj, javadocs-contrib"/>
+  <target name="javadocs-core" description="Generate javadocs for core." 
+          depends="contrib-build.javadocs"/>
+ 
+  <!-- hackish we have to call init/clover here, but solr core depends upon solrj? -->
+  <target name="compile-core" depends="init, clover, compile-analyzers-common, 
+        compile-analyzers-phonetic, compile-highlighter, compile-memory, compile-misc, 
+        compile-queries, compile-spatial, compile-spellchecker, compile-solrj, 
+        common.compile-core, compile-webapp" 
+  	  unless="solr-core.compiled">
+  </target>
+ 
+  <target name="compile-webapp" depends="compile-solrj">
+    <compile srcdir="src/webapp/src" 
+             destdir="${build.dir}/classes/webapp">
+      <classpath refid="classpath"/>
+    </compile>
+  </target>
+ 
+  <!-- TODO: factor solrj into a separate dir so its a normal module?
+       we have to reinvent wheels the way it is now -->
+ 
+  <target name="compile-solrj" description="Compile the java client.">
+    <compile srcdir="src/common:src/solrj" 
+             destdir="${build.dir}/classes/solrj">
+  	  <classpath refid="classpath"/>
+  	</compile>
+  </target>
+
+  <!-- hacky? -->
+  <target name="compile-test-framework" depends="compile-core">
+    <compile srcdir="src/test-framework" destdir="${build.dir}/classes/test-framework">
+  	  <classpath refid="test.classpath"/>
+  	</compile>
+  </target>
+
+  <target name="javadocs-solrj" depends="compile-solrj" description="Generates solrj javadoc documentation.">
+    <sequential>
+      <mkdir dir="${javadoc.dir}/solrj"/>
+      <invoke-javadoc
+        destdir="${javadoc.dir}/solrj"
+        title="${Name}-j ${version} API (${specversion})">
+        <sources>
+          <packageset dir="src/common"/>
+          <packageset dir="src/solrj"/>
+        </sources>
+      </invoke-javadoc>
+    </sequential>
+  </target>
+
   <!-- Default target: usage.  Prints out instructions. -->
   <target name="usage"
           description="Prints out instructions">
@@ -64,1068 +109,45 @@
     <echo message="Use 'ant test' to run unit tests." />
   </target>
 
-  <!-- Clean: cleans compiled files and other temporary artifacts. -->
-  <target name="clean" depends="clean-contrib"
-          description="Cleans compiled files and other temporary artifacts.">
-    <delete dir="${dest}" />
-    <delete dir="${dist}" />
-    <delete dir="${package.dir}" />
-    <delete dir="example/solr/lib" />
-    <delete dir="${lucene-libs}" />
+  <!-- TODO: lucene/solr could share these -->
+  <target name="build-contrib" depends="compile-test"
+          description="Builds all contrib modules and their tests">
+    <contrib-crawl target="build-artifacts-and-tests"/>
   </target>
 
-  <target name="clean-dest"
-          description="Cleans out ${dest} but leaves ${dist} and ${package.dir} alone.  This allows us to run nightly and clover together in Hudson">
-    <delete includeemptydirs="true" >
-      <fileset dir="${dest}">
-        <exclude name="docs/"/>
-      </fileset>
-    </delete>
+  <target name="javadocs-contrib" description="Generate javadocs for contrib classes"
+  	      depends="build-contrib">
+    <contrib-crawl target="javadocs" failonerror="true"/>
   </target>
 
-  <!-- ========================================================================= -->
-  <!-- ===================== COMPILATION-RELATED TASKS ========================= -->
-  <!-- ========================================================================= -->
-  
-  <!-- The compilation classpath -->
-  <path id="compile.classpath">
-    <fileset dir="${lib}">
-      <include name="*.jar" />
-    </fileset>
-    <path refid="lucene.classpath"/>
-  </path>
-
-  <target name="compile-solrj"
-          description="Compile the java client."
-          depends="compile-lucene">
-
-    <solr-javac destdir="${dest}/solrj"
-                classpathref="compile.classpath">
-      <src path="${src}/common" />
-      <src path="${src}/solrj" />
-    </solr-javac>
+  <target name="test-contrib" description="Run contrib unit tests."
+  	      depends="build-contrib">
+    <contrib-crawl target="test" failonerror="true"/>
   </target>
 
-
-  <!-- This depend on all of solr -->
-  <path id="compile.classpath.solrj">
-    <path refid="compile.classpath" />
-    <pathelement location="${dest}/solrj"/>
-    <!-- jetty -->
-    <fileset dir="example/lib">
-      <include name="**/*.jar" />
-    </fileset>
-  </path>
-    
-  <!-- Compile the project. -->
-  <target name="compile"
-          description="Compile the source code."
-          depends="validate-solr, compile-solrj">
-
-    <solr-javac destdir="${dest}/solr"
-                classpathref="compile.classpath.solrj">
-      <src path="${src}/java" />
-      <src path="${src}/webapp/src" />
-    </solr-javac>
+  <target name="compile-analyzers-common" unless="analyzers-common.uptodate">
+  	<ant dir="${common.dir}/../modules/analysis/common" target="default" inheritAll="false"/>
   </target>
-
-  <target name="javadoc-dep">
-    <copy failonerror="false" todir="${build.docs}">
-      <fileset dir="site" />
-    </copy>
+  <target name="compile-analyzers-phonetic" unless="analyzers-phonetic.uptodate">
+  	<ant dir="${common.dir}/../modules/analysis/phonetic" target="default" inheritAll="false"/>
   </target>
-
-  <target name="javadoc-solrj" depends="compile-solrj,javadoc-dep" description="Generates solrj javadoc documentation.">
-    <sequential>
-      <mkdir dir="${build.javadoc}/solrj"/>
-
-      <path id="javadoc.classpath">
-        <path refid="compile.classpath"/>
-      </path>
-
-      <invoke-javadoc
-        destdir="${build.javadoc}/solrj"
-        title="${Name}-j ${version} API (${specversion})">
-        <sources>
-          <packageset dir="${src}/common"/>
-          <packageset dir="${src}/solrj"/>
-        </sources>
-      </invoke-javadoc>
-    </sequential>
+  <target name="compile-highlighter" unless="highlighter.uptodate">
+  	<ant dir="${common.dir}/contrib/highlighter" target="default" inheritAll="false"/>
   </target>
-  
-  <target name="javadoc-core" depends="compile,javadoc-dep"  description="Generates javadoc documentation for core.">
-
-    <sequential>
-      <mkdir dir="${build.javadoc}/solr"/>
-
-      <path id="javadoc.classpath">
-        <path refid="compile.classpath"/>
-        <path refid="compile.classpath.solrj"/>
-        <pathelement location="${dest}/solrj"/>
-      </path>
-
-      <invoke-javadoc
-        destdir="${build.javadoc}/solr"
-      	title="${Name} ${version} core API (${specversion})">
-        <sources>
-          <packageset dir="${src}/java" />
-          <packageset dir="${src}/webapp/src"/>
-        </sources>
-      </invoke-javadoc>
-    </sequential>
+  <target name="compile-memory" unless="memory.uptodate">
+  	<ant dir="${common.dir}/contrib/memory" target="default" inheritAll="false"/>
   </target>
-
-
-  <target name="javadoc-all" depends="compile,javadoc-dep" description="Generate javadoc for core, client and contrib">
-    <sequential>
-      <mkdir dir="${build.javadoc}"/>
-
-      <path id="javadoc.classpath">
-         <path refid="compile.classpath"/>
-         <path refid="compile.classpath.solrj"/>
-          <fileset dir="contrib">
-            <include name="**/lib/**/*.jar"/>
-            <include name="**/lucene-libs/**/*.jar"/>
-            <exclude name="**/analysis-extras/lib/**/*icu4j*.jar"/> <!-- extraction/lib/ has this one -->
-          </fileset>
-         <pathelement location="${dest}/client/solrj"/>
-      </path>
-
-      <invoke-javadoc destdir="${build.javadoc}">
-        <sources>
-          <packageset dir="${src}/common" />
-          <packageset dir="${src}/solrj" />
-          <packageset dir="${src}/java" />
-          <packageset dir="${src}/webapp/src" />
-          <packageset dir="contrib/dataimporthandler/src/main/java" />
-          <packageset dir="contrib/dataimporthandler/src/extras/main/java" />
-          <packageset dir="contrib/clustering/src/main/java" />
-          <packageset dir="contrib/extraction/src/main/java" />
-          <packageset dir="contrib/uima/src/main/java" />
-          <packageset dir="contrib/analysis-extras/src/java" />
-          <group title="Core" packages="org.apache.*" />
-          <group title="Common" packages="org.apache.solr.common.*" />
-          <group title="SolrJ" packages="org.apache.solr.client.solrj*" />
-          <group title="contrib: DataImportHandler" packages="org.apache.solr.handler.dataimport*" />
-          <group title="contrib: Clustering" packages="org.apache.solr.handler.clustering*" />
-          <group title="contrib: Solr Cell" packages="org.apache.solr.handler.extraction*" />
-          <group title="contrib: Solr UIMA" packages="org.apache.solr.uima*" />
-        </sources>
-      </invoke-javadoc>
-    </sequential>
-  </target>
-
-  <target name="javadoc-contrib" description="Generate javadoc for contrib classes" depends="build-contrib,javadoc-dep">
-    <contrib-crawl target="javadoc"
-                   failonerror="true"/>
-  </target>
-
-  <target name="javadoc" depends="javadoc-core, javadoc-contrib, javadoc-solrj, javadoc-all">
-  </target>
-  <target name="javadocs" depends="javadoc"/>
-
-  <target name="stub-factories" depends="dist-jar"
-          description="Generates stub factories as needed">
-
-    <path id="stub.jars">
-      <!-- this needs to be a list of all jars that might contain
-           classes we want to build factories for
-        -->
-      <fileset dir="${lib}">
-        <include name="lucene-*.jar"/>
-      </fileset>
-      <fileset dir="${dist}">
-        <include name="*.jar"/>
-        <exclude name="*solrj*.jar"/>
-      </fileset>
-    </path>
-    <pathconvert property="jar.list" pathsep=" " refid="stub.jars" />
-    <property name="stub.list" value="${dest}/need-stub-factories.txt" />
-    <java fork="false" 
-          classname="org.apache.solr.util.SuggestMissingFactories"
-          logError="true"
-          failonerror="true"
-          classpathref="test.run.classpath"
-          output="${stub.list}">
-      <arg line="${jar.list}" />
-    </java>
-    <fail unless="stub.src.path">...
-    
-  This task requires that the property 'stub.src.path' be set.
-      
-  It must contain a "path" listing directories containing source
-  files that this task should use when looking for classes that
-  need factories created, the format is platform specific --
-  typically it is  colon seperated in Unix, semi-colon seperated
-  on windows, ie:
-
-  ant stub-factories -Dstub.src.path="./src:../lucene/contrib:../lucene/src/java"
-      
-  FYI: The file ${stub.list} contains a list of classes
-  that seem to need stub factories. (if java files can be found to
-  use as guides for creating them).
-    </fail>              
-
-    <pathconvert pathsep=" " property="stub.src.dirs">
-      <path>
-        <pathelement path="${stub.src.path}"/>
-      </path>
-    </pathconvert>
-    <exec executable="${basedir}/src/dev-tools/stub-analysis-factory-maker.pl" 
-          dir="src/java/org/apache/solr/analysis/"
-          failonerror="true">
-        <redirector input="${stub.list}">
-           <!-- place to put special case classes we want to ignore -->
-           <inputfilterchain>
-              <linecontainsregexp negate="true">
-                 <!-- only for internal Solr highlighting purposes -->
-                 <regexp pattern="TokenOrderingFilter"/>
-              </linecontainsregexp>
-              <linecontainsregexp negate="true">
-                 <!-- no way to leverage this in Solr -->
-                 <regexp pattern="CachingTokenFilter"/>
-              </linecontainsregexp>
-              <linecontainsregexp negate="true">
-                 <!-- no way to leverage this in Solr -->
-                 <regexp pattern="HyphenationCompoundWordTokenFilter"/>
-              </linecontainsregexp>
-              <linecontainsregexp negate="true">
-                 <!-- no way to leverage these in Solr (yet) -->
-                 <regexp pattern="Sink|Tee"/>
-              </linecontainsregexp>
-              <linecontainsregexp negate="true">
-                 <!-- Solr already has a different impl for this -->
-                 <regexp pattern="SynonymTokenFilter"/> 
-              </linecontainsregexp>
-              <linecontainsregexp negate="true">
-                 <!-- solr and lucene both have one? ? ? ? -->
-                 <regexp pattern="LengthFilter"/> 
-              </linecontainsregexp>
-              <linecontainsregexp negate="true">
-                 <!-- solr provides it's own SnowballPorterFilter variant -->
-                 <regexp pattern="SnowballFilter"/> 
-              </linecontainsregexp>
-           </inputfilterchain>
-        </redirector>
-      <arg line="${stub.src.dirs}"/>
-    </exec>
-  </target>
-
-
-  <!-- ========================================================================= -->
-  <!-- ===================== TESTING-RELATED TASKS ============================= -->
-  <!-- ========================================================================= -->
-
-
-  <!-- Classpath for unit test compilation. -->
-  <!-- For now, it's the same as main classpath.  Later it will have JUnit, Clover, etc. -->
-  <path id="test.compile.classpath">
-    <path refid="compile.classpath" />
-    <path refid="compile.classpath.solrj" />
-    <pathelement location="${dest}/solr"/>
-    <pathelement location="${dest}/solrj"/> <!-- include solrj -->
-    <pathelement location="${common-solr.dir}/../lucene/build/classes/test-framework" />  <!-- include some lucene test code -->
-  </path>
-
-  <path id="test.run.classpath">
-    <path refid="test.compile.classpath" />
-    <pathelement location="${dest}/tests"/>
-    <!-- include the solrj classpath and jetty files included in example -->
-    <path refid="compile.classpath.solrj" />
-    <pathelement location="${common-solr.dir}/../lucene/build/classes/test-framework" />  <!-- include some lucene test code -->
-    <pathelement path="${java.class.path}"/>
-  </path>
-
-  <!-- Compile unit tests. -->
-  <target name="compileTests"
-          description="Compile unit tests."
-          depends="compile,compile-solrj">
-
-    <mkdir dir="${dest}/tests" />
-    <solr-javac 
-       destdir="${dest}/tests"
-       classpathref="test.compile.classpath">
-      <src path="${src}/test" />
-    </solr-javac>
-    <!-- Copy any data files present to the classpath -->
-    <copy todir="${dest}/tests">
-      <fileset dir="${src}/test-files" excludes="**/*.java"/>
-    </copy>
+  <target name="compile-misc" unless="misc.uptodate">
+  	<ant dir="${common.dir}/contrib/misc" target="default" inheritAll="false"/>
   </target>
-
-  <!-- Run core unit tests. -->
-  <target name="test-core"
-          description="Runs the core unit tests."
-          depends="compileTests, junit" />
-	
-  <!-- Run contrib unit tests. -->
-  <target name="test"
-        description="Runs the core unit tests."
-        depends="test-core, test-contrib, test-jsp" />
-
-  <target name="junit" depends="compileTests,junit-mkdir,junit-sequential,junit-parallel"/>
-
-  <target name="junit-sequential" if="tests.sequential">
-    <junit-macro/>
+  <target name="compile-queries" unless="queries.uptodate">
+  	<ant dir="${common.dir}/contrib/queries" target="default" inheritAll="false"/>
   </target>
-
-  <target name="junit-parallel" unless="tests.sequential">
-   <parallel threadsPerProcessor="${tests.threadspercpu}">
-    <junit-macro threadNum="1" threadTotal="8"/>
-    <junit-macro threadNum="2" threadTotal="8"/>
-    <junit-macro threadNum="3" threadTotal="8"/>
-    <junit-macro threadNum="4" threadTotal="8"/>
-    <junit-macro threadNum="5" threadTotal="8"/>
-    <junit-macro threadNum="6" threadTotal="8"/>
-    <junit-macro threadNum="7" threadTotal="8"/>
-    <junit-macro threadNum="8" threadTotal="8"/>
-   </parallel>
+  <target name="compile-spatial" unless="spatial.uptodate">
+  	<ant dir="${common.dir}/contrib/spatial" target="default" inheritAll="false"/>
   </target>
-
-  <target name="junit-mkdir">
-    <mkdir dir="${junit.output.dir}"/>
-  </target>
-
-  <macrodef name="junit-macro">
-  <attribute name="threadNum" default="1"/>
-  <attribute name="threadTotal" default="1"/>
-  <attribute name="tempDir" default="${junit.output.dir}/temp"/>
-    <sequential>
-    <!-- no description so it doesn't show up in -projecthelp -->  
-    <condition property="runall">
-      <not>
-        <or>
-          <isset property="testcase"/>
-          <isset property="testpackage"/>
-          <isset property="testpackageroot"/>
-        </or>
-      </not>
-    </condition>
-    <!-- <mkdir dir="@{tempDir}/@{pattern}"/> 
-       This is very loud and obnoxious. abuse touch instead for a "quiet" mkdir
-    -->
-    <touch file="@{tempDir}/@{threadNum}/quiet.ant" verbose="false" mkdirs="true"/>
-    <property name="dir.prop" value=""/>
-    <junit printsummary="no"
-           haltonfailure="no"
-           maxmemory="512M"
-           errorProperty="tests.failed"
-           failureProperty="tests.failed"
-           dir="@{tempDir}/@{threadNum}"
-           tempdir="@{tempDir}/@{threadNum}"
-           forkmode="perBatch"
-           >
-      <sysproperty key="java.util.logging.config.file" value="${common-solr.dir}/testlogging.properties"/>
-      <sysproperty key="tests.luceneMatchVersion" value="${tests.luceneMatchVersion}"/>
-      <sysproperty key="tests.codec" value="${tests.codec}"/>
-      <sysproperty key="tests.locale" value="${tests.locale}"/>
-      <sysproperty key="tests.timezone" value="${tests.timezone}"/>
-      <sysproperty key="tests.multiplier" value="${tests.multiplier}"/>
-      <sysproperty key="tests.iter" value="${tests.iter}"/>
-      <sysproperty key="tests.seed" value="${tests.seed}"/>
-      <sysproperty key="tests.verbose" value="${tests.verbose}"/>
-      <sysproperty key="jetty.testMode" value="1"/>
-      <sysproperty key="tempDir" file="@{tempDir}/@{threadNum}"/>
-      <sysproperty key="testmethod" value="${testmethod}"/>
-      <!-- set whether or not nightly tests should run -->
-      <sysproperty key="tests.nightly" value="${tests.nightly}"/>
-      <!-- TODO: why is this unconditionally set to "" above? disable for now
-         <jvmarg line="${dir.prop}"/>
-      -->
-      <jvmarg line="${args}"/>
-
-      <formatter classname="${junit.details.formatter}" usefile="false" if="junit.details"/>
-      <classpath refid="test.run.classpath"/>
-      <assertions>
-        <enable package="org.apache.lucene"/>
-        <enable package="org.apache.solr"/>
-      </assertions>
-      <formatter type="${junit.formatter}"/>
-      <batchtest fork="yes" todir="${junit.output.dir}" if="runall">
-        <fileset dir="src/test" includes="**/Test*.java,**/*Test.java">
-          <custom classname="${junit.parallel.selector}" classpathref="test.run.classpath">
-          	<param name="divisor" value="@{threadTotal}" />
-          	<param name="part" value="@{threadNum}" />
-          </custom>
-        </fileset>
-      </batchtest>
-      <batchtest fork="yes" todir="${junit.output.dir}" if="testpackage">
-        <fileset dir="src/test" includes="**/${testpackage}/**/Test*.java,**/${testpackage}/**/*Test.java">
-          <custom classname="${junit.parallel.selector}" classpathref="test.run.classpath">
-      	    <param name="divisor" value="@{threadTotal}" />
-      	    <param name="part" value="@{threadNum}" />
-          </custom>
-      	</fileset>
-      </batchtest>
-      <batchtest fork="yes" todir="${junit.output.dir}" if="testpackageroot">
-        <fileset dir="src/test" includes="**/${testpackageroot}/Test*.java,**/${testpackageroot}/*Test.java">
-          <custom classname="${junit.parallel.selector}" classpathref="test.run.classpath">
-        	<param name="divisor" value="@{threadTotal}" />
-        	<param name="part" value="@{threadNum}" />
-          </custom>
-        </fileset>
-      </batchtest>
-      <batchtest fork="yes" todir="${junit.output.dir}" if="testcase">
-        <fileset dir="src/test" includes="**/${testcase}.java"/>
-      </batchtest>
-    </junit>
-
-    <fail if="tests.failed">Tests failed!</fail>
-    </sequential>
-  </macrodef>
-
-      
-  <target name="test-reports"
-          description="Generates HTML test reports.">
-    <mkdir dir="${junit.reports}"/>
-    <junitreport todir="${junit.output.dir}">
-      <fileset dir="${junit.output.dir}">
-        <include name="TEST-*.xml"/>
-      </fileset>
-      <report format="frames" todir="${junit.reports}"/>
-    </junitreport>
-  </target>
-
-  <target name="clover" depends="clover.setup, clover.info"
-          description="Instrument the Unit tests using Clover.  Requires a Clover license and clover.jar in the ANT classpath.  To use, specify -Drun.clover=true on the command line."/>
-
-  <target name="clover.setup" if="clover.enabled">
-    <taskdef resource="cloverlib.xml"/>
-    <mkdir dir="${clover.db.dir}"/>
-    <clover-setup initString="${clover.db.dir}/solr_coverage.db">
-      <fileset dir="src/common"/>
-      <fileset dir="src/solrj"/>
-      <fileset dir="src/java"/>
-      <fileset dir="src/webapp/src"/>
-      <fileset dir="contrib/dataimporthandler/src/main/java" />
-      <fileset dir="contrib/clustering/src/main/java" />
-      <fileset dir="contrib/extraction/src/main/java" />
-      <fileset dir="contrib/uima/src/main/java" />
-      <fileset dir="contrib/analysis-extras/src/java" />
-    </clover-setup>
-  </target>
-
-  <target name="clover.info" unless="clover.present">
-  	<echo>
-      Clover not found. Code coverage reports disabled.
-  	</echo>
-  </target>
-
-  <target name="clover.check">
-	<fail unless="clover.present">
-	  ##################################################################
-      Clover not found.
-      Please make sure clover.jar is in ANT_HOME/lib, or made available
-      to Ant using other mechanisms like -lib or CLASSPATH.
-      ##################################################################
-  	</fail>
-  </target>
-    <!--
-     Run after Junit tests.
-     -->
-  <target name="generate-clover-reports" depends="clover.check, clover">
-    <mkdir dir="${clover.report.dir}"/>
-    <clover-report>
-       <current outfile="${clover.report.dir}/clover.xml"
-                title="${fullnamever}">
-          <format type="xml"/>
-       </current>
-       <current outfile="${clover.report.dir}" title="${fullnamever}">
-          <format type="html"/>
-       </current>
-    </clover-report>
-  </target>
-
-  <!-- ========================================================================= -->
-
-  <!-- Checks that all JSP files in the webapp compile successfully using Jetty's Jasper -->
-  <target name="test-jsp" depends="compile">
-    <property name="jsp.target" location="${dest}/jsp-temp" />
-    <taskdef classname="org.apache.jasper.JspC" name="jasper" >
-      <classpath>
-        <fileset dir="example/lib" includes="**/*.jar" />
-      </classpath>
-    </taskdef>
-    <delete dir="${jsp.target}" />
-    <mkdir dir="${jsp.target}" />
-    <jasper
-      uriroot="${src}/webapp/web"
-      outputDir="${jsp.target}" 
-      compile="false" 
-      verbose="1"
-      package="j"
-    />
-    <javac
-      srcdir="${jsp.target}"
-      destdir="${jsp.target}"
-      target="${java.compat.version}"
-      source="${java.compat.version}"
-      debug="off"
-      encoding="utf8"
-      includeAntRuntime="${javac.includeAntRuntime}"
-      classpathref="test.compile.classpath"
-    />
-  </target>
-
-
-  <!-- ========================================================================= -->
-  <!-- ===================== DISTRIBUTION-RELATED TASKS ======================== -->
-  <!-- ========================================================================= -->
-
-
-  <!-- Creates the Solr distribution files. -->
-  <target name="dist"
-          description="Creates the Solr distribution files."
-          depends="dist-solrj, dist-jar, dist-contrib, dist-war" />
-
-  <!-- Creates the Solr WAR file. -->
-  <target name="dist-war"
-          description="Creates the Solr WAR Distribution file."
-          depends="compile, test-jsp, make-manifest, dist-jar, dist-solrj, lucene-jars-to-solr">
-    <mkdir dir="${dist}" />
-    <war destfile="${dist}/${fullnamever}.war"
-         webxml="${web.xml}"
-         filesetmanifest="skip"
-         manifest="${dest}/META-INF/MANIFEST.MF">
-       <lib dir="${lib}">
-         <exclude name="servlet-api*.jar" />
-         <exclude name="easymock-*.jar" />
-         <exclude name="junit-*.jar" />
-         <exclude name="*.txt" />
-         <exclude name="*.template" />
-       </lib>
-      
-       <lib dir="${lucene-libs}"/>
-         
-       <lib dir="${dist}">
-         <include name="${fullname}-solrj-${version}.jar" />
-         <include name="${fullname}-core-${version}.jar" />
-       </lib>
-       <fileset dir="${src}/webapp/web" />
-       
-       <!-- Include anything put in by contrib projects -->
-       <fileset dir="${dest}/web" />
-       	
-       <metainf dir="${basedir}" includes="LICENSE.txt,NOTICE.txt"/>
-    </war>
-  </target>
-
-  <target name="dist-src" description="Creates the Solr source distribution files for maven"
-          depends="make-manifest">
-    <mkdir dir="${dist}" />
-
-    <solr-jar destfile="${dist}/${fullname}-solrj-src-${version}.jar">
-      <fileset dir="${src}/common" />
-      <fileset dir="${src}/solrj"/>
-    </solr-jar>
-    	
-    <solr-jar destfile="${dist}/${fullname}-core-src-${version}.jar">
-      <fileset dir="${src}/java" />
-      <fileset dir="${src}/webapp/src"/>
-    </solr-jar>
-  	
-    <solr-jar destfile="${dist}/apache-solr-dataimporthandler-src-${version}.jar"
-              basedir="contrib/dataimporthandler/src/main/java" />
-    <solr-jar destfile="${dist}/apache-solr-dataimporthandler-extras-src-${version}.jar"
-              basedir="contrib/dataimporthandler/src/extras/main/java" />
-
-    <solr-jar destfile="${dist}/apache-solr-cell-src-${version}.jar"
-              basedir="contrib/extraction/src" />
-    <solr-jar destfile="${dist}/apache-solr-clustering-src-${version}.jar"
-              basedir="contrib/clustering/src" />
-    <solr-jar destfile="${dist}/apache-solr-analysis-extras-src-${version}.jar"
-              basedir="contrib/analysis-extras/src" />
-    <solr-jar destfile="${dist}/apache-solr-uima-src-${version}.jar"
-              basedir="contrib/uima/src/main/java" >
-       <fileset dir="contrib/uima/src/main/resources" />
-    </solr-jar>
-  </target>
-
-  <target name="dist-javadoc" description="Creates the Solr javadoc distribution files for maven"
-          depends="make-manifest, javadoc">
-    <mkdir dir="${dist}" />
-
-    <solr-jar destfile="${dist}/${fullname}-core-docs-${version}.jar"
-              basedir="${build.javadoc}/solr" />
-    <solr-jar destfile="${dist}/${fullname}-solrj-docs-${version}.jar"
-              basedir="${build.javadoc}/solrj" />
-    <solr-jar destfile="${dist}/apache-solr-dataimporthandler-docs-${version}.jar"
-              basedir="${build.javadoc}/contrib-solr-dataimporthandler" />
-    <solr-jar destfile="${dist}/apache-solr-clustering-docs-${version}.jar"
-              basedir="${build.javadoc}/contrib-solr-clustering" />
-    <solr-jar destfile="${dist}/apache-solr-cell-docs-${version}.jar"
-              basedir="${build.javadoc}/contrib-solr-cell" />
-    <solr-jar destfile="${dist}/apache-solr-analysis-extras-docs-${version}.jar"
-              basedir="${build.javadoc}/contrib-solr-analysis-extras" />
-    <solr-jar destfile="${dist}/apache-solr-uima-docs-${version}.jar"
-              basedir="${build.javadoc}/contrib-solr-uima" />
-  </target>
-
-  <!-- Creates the solr jar. -->
-  <target name="dist-jar"
-          description="Creates the Solr JAR Distribution file."
-          depends="compile, make-manifest">
-    <mkdir dir="${dist}" />
-    <solr-jar destfile="${dist}/${fullname}-core-${version}.jar">
-      <fileset dir="${dest}/solr" />
-    </solr-jar>
-
-  </target>
-
-  <!-- Creates the solr jar. -->
-  <target name="dist-solrj"
-          description="Creates the Solr JAR Distribution file."
-          depends="compile-solrj, make-manifest">
-    <mkdir dir="${dist}" />
-    <solr-jar
-         destfile="${dist}/${fullname}-solrj-${version}.jar"
-         basedir="${dest}/solrj" />
-
-    <mkdir  dir="${dist}/solrj-lib" />
-    <copy todir="${dist}/solrj-lib">
-      <fileset dir="${lib}">
-        <include name="commons-codec-*.jar"/>
-        <include name="commons-io-*.jar"/>
-        <include name="commons-httpclient-*.jar"/>
-        <include name="*stax-*.jar" />
-        <include name="wstx-*.jar" />
-        <include name="jcl-over-slf4j-*.jar" />
-        <include name="slf4j-api-*.jar" />
-      </fileset>
-    </copy>
-      
-  </target>
-
-  <target name="example" 
-          description="Creates a runnable example configuration."
-          depends="compile-lucene,dist-contrib,dist-war,example-contrib">
-    <copy file="${dist}/${fullnamever}.war"
-          tofile="${example}/webapps/${ant.project.name}.war"/>
-    <jar destfile="${example}/exampledocs/post.jar"
-         basedir="${dest}/solr"
-         filesetmanifest="skip"
-         includes="org/apache/solr/util/SimplePostTool*.class">
-       <manifest>
-          <attribute name="Main-Class"
-                     value="org.apache.solr.util.SimplePostTool"/>
-       </manifest>
-    </jar>
-
-    <delete includeemptydirs="true">
-      <fileset dir="${example}/work" includes="**/*"/>
-    </delete>
-    <echo>See ${example}/README.txt for how to run the Solr example configuration.</echo>
-  </target>
-	
-  <target name="run-example" depends="example"
-          description="Run Solr interactively, via Jetty.  -Dexample.debug=true to enable JVM debugger">
-    <property name="example.solr.home" location="example/solr"/>
-    <property name="example.data.dir" location="example/solr/data"/>
-    <property name="example.debug.suspend" value="n"/>
-    <property name="example.jetty.port" value="8983"/>
-    <condition property="example.jvm.line" value="-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=${example.debug.suspend},address=5005">
-      <isset property="example.debug"/>
-    </condition>
-    <property name="example.jvm.line" value=""/>
-    <property name="example.heap.size" value="512M"/>
-    <java jar="${example}/start.jar" fork="true" dir="${example}" maxmemory="${example.heap.size}">
-      <jvmarg line="${example.jvm.line}"/>
-      <sysproperty key="solr.solr.home" file="${example.solr.home}"/>
-      <sysproperty key="solr.data.dir" file="${example.data.dir}"/>
-      <sysproperty key="jetty.port" value="${example.jetty.port}"/>
-    </java>
-
-  </target>
-  
-  <!-- make a distribution -->
-  <target name="package" depends="package-src,create-package"/>
-
-  <property name="svn.export.dir" location="${dest}/svn-export"/>
-
-  <!-- Makes a tarball from running "svn export" at the root level.    -->
-  <!-- Copies NOTICE.txt and LICENSE.txt from solr/ to the root level. -->
-  <target name="package-src" depends="svn-export-source"
-          description="Packages the Solr Source Distribution">
-    <mkdir dir="${package.dir}"/>
-    <property name="source.package.file"
-              value="${package.dir}/${fullnamever}-src.tgz"/>
-    <delete file="${source.package.file}" failonerror="false" />
-    <tar destfile="${source.package.file}" compression="gzip" longfile="gnu">
-      <tarfileset dir="${svn.export.dir}" prefix="${fullnamever}"/>
-      <tarfileset dir="${svn.export.dir}/solr" prefix="${fullnamever}"
-                  includes="NOTICE.txt,LICENSE.txt"/>
-    </tar>
-    <solr-checksum file="${source.package.file}"/>
-  </target>
-
-  <!-- Runs "svn export" in build/svn-export/ with the same root-level URL -->
-  <!-- and revision as the current working copy.                           -->
-  <target name="svn-export-source" depends="get-svn-info">
-    <delete dir="${svn.export.dir}" includeemptydirs="true" failonerror="false"/>
-    <mkdir dir="${dest}"/>
-    <exec dir="." executable="${svn.exe}" failonerror="true">
-      <arg value="export"/>
-      <arg value="--native-eol"/>
-      <arg value="LF"/>
-      <arg value="-r"/>
-      <arg value="${svn.Revision}"/>
-      <arg value="${svn.URL}"/>
-      <arg value="${svn.export.dir}"/>
-    </exec>
-  </target>
-
-  <!-- Populates properties svn.URL and svn.Revision using "svn info" -->
-  <target name="get-svn-info">
-    <exec dir=".." executable="${svn.exe}" outputproperty="svn.info" failonerror="true">
-      <arg value="info"/>
-    </exec>
-    <loadproperties>
-      <propertyresource name="svn.info"/>
-      <filterchain>
-        <linecontainsregexp>
-          <regexp pattern="(URL|Revision):"/>
-        </linecontainsregexp>
-        <replacestring from=": " to="="/>
-        <prefixlines prefix="svn."/>
-      </filterchain>
-    </loadproperties>
-  </target>
-
-  <target name="create-package"
-          description="Packages the Solr Binary Distribution"
-          depends="dist, example, javadoc">
-    <mkdir dir="${package.dir}"/>
-
-    <delete includeemptydirs="true">
-      <fileset dir="${example}/work" includes="**/*"/>
-    </delete>
-
-    <delete includeemptydirs="true" failonerror="false">
-      <fileset dir="${dest}/${fullnamever}" includes="**/*"/>
-    </delete>
-
-    <delete file="${package.dir}/${fullnamever}.tgz" failonerror="false" />
-    <delete file="${package.dir}/${fullnamever}.zip" failonerror="false" />
-
-    <tar destfile="${package.dir}/${fullnamever}.tgz" compression="gzip" longfile="gnu">
-      <tarfileset dir="."
-        prefix="${fullnamever}"
-        includes="LICENSE.txt NOTICE.txt *.txt example/** client/** contrib/**/lib/ contrib/**/lucene-libs/ contrib/**/README.txt contrib/**/CHANGES.txt"
-        excludes="${dist}/** ${dest}/** lib/README.committers.txt **/data/ **/logs/* **/classes/ **/*.sh **/bin/ src/scripts/** src/site/build/** **/target/** client/ruby/flare/** client/python/** client/javascript/** contrib/**/build/** **/*.iml **/*.ipr **/*.iws **/*pom.xml.template" />
-      <tarfileset dir="."
-        mode="755"
-        prefix="${fullnamever}"
-        includes="example/**/*.sh example/**/bin/" />
-      <tarfileset dir="."
-        prefix="${fullnamever}"
-        includes="dist/*.jar dist/*.war dist/solrj-lib/*"
-        excludes="**/*.tgz **/*.zip **/*.md5 **/*src*.jar **/*docs*.jar" />
-      <!-- hack: the javadocs are built twice since maven needs separate packages... exclude those -->
-      <tarfileset dir="${build.docs}"
-        prefix="${fullnamever}/docs/"
-        excludes="api/solr/** api/contrib-*/**"
-       />
-    </tar>
-    <solr-checksum file="${package.dir}/${fullnamever}.tgz"/>
-
-    <gunzip src="${package.dir}/${fullnamever}.tgz" dest="${dest}/${fullnamever}.tar"/>
-    <untar src="${dest}/${fullnamever}.tar" dest="${dest}"/>
-
-    <!--
-      This is a list of text file patterns to convert to CRLF line-ending style.
-      Shell scripts and files included in shell scripts should not be converted.
-      NB: The line-ending conversion process will mangle non-UTF8-encoded files.
-     -->
-    <fixcrlf srcdir="${dest}/${fullnamever}"
-       encoding="UTF-8"
-       eol="crlf"
-       includes="**/*.alg **/*.cfg **/*.cgi **/*.cpp **/*.css **/*.csv **/*.dtd
-                 **/*.erb **/*.fcgi **/.htaccess **/*.htm **/*.html **/*.incl
-                 **/*.java **/*.javacc **/*.jflex **/*.jflex-macro **/*.jj
-                 **/*.js **/*.json **/*.jsp **/*LICENSE **/package-list **/*.pl
-                 **/*.pom **/*pom.xml.template **/*.properties **/*.py
-                 **/*.rake **/Rakefile **/*.rb **/*.rbbi **/README* **/*.rhtml
-                 **/*.rslp **/*.rxml **/*.script **/*.svg **/*.tsv **/*.txt
-                 **/UPGRADING **/USAGE **/*.uxf **/*.vm **/*.xcat **/*.xml
-                 **/*.xsl **/*.xslt **/*.yml"       
-       excludes="**/stopwordsWrongEncoding.txt **/gb18030-example.xml"
-     />
-
-    <zip destfile="${package.dir}/${fullnamever}.zip">
-      <zipfileset dir="${dest}/${fullnamever}"
-        prefix="${fullnamever}" 
-        excludes="**/*.sh **/bin/ src/scripts/" />
-      <zipfileset dir="${dest}/${fullnamever}"
-        prefix="${fullnamever}"
-        includes="**/*.sh **/bin/ src/scripts/"
-        filemode="755" />
-    </zip>
-    <solr-checksum file="${package.dir}/${fullnamever}.zip"/>
-
-  </target>
-
-
-  <target name="build-site" depends="svn-up" 
-          description="Prototype Helper for Committers.  Assumes SVN is in the path">
-    <delete dir="src/site/build"/>
-    <exec executable="forrest" dir="src/site"/>
-    <copy todir="site">
-      <fileset dir="src/site/build/site"/>
-    </copy>
-    <antcall target="svn-up"/>
-  
-  </target>
-  <target name="svn-up">
-    <exec executable="${svn.exe}">
-      <arg value="update"/>
-    </exec>
-  </target>
-
-  <target name="clean-package-signatures">
-    <delete failonerror="false">
-      <fileset dir="${package.dir}">
-        <include name="**/*.asc"/>
-      </fileset>
-    </delete>
-  </target>
-  <target name="sign-artifacts" depends="clean-package-signatures">
-    <!--<property file="${user.home}/.solr/build.properties" />-->
-    <input message="password:>" addproperty="gpg.passphrase">
-      <handler classname="org.apache.tools.ant.input.SecureInputHandler" />
-    </input>
-    <sign-artifact input.file="${package.dir}/${fullnamever}.tgz" output.file="${package.dir}/${fullnamever}.tgz.asc" gpg.passphrase="${gpg.passphrase}"/>
-    <sign-artifact input.file="${package.dir}/${fullnamever}.zip" output.file="${package.dir}/${fullnamever}.zip.asc" gpg.passphrase="${gpg.passphrase}"/>
-    <sign-artifact input.file="${package.dir}/${fullnamever}-src.tgz" output.file="${package.dir}/${fullnamever}-src.tgz.asc" gpg.passphrase="${gpg.passphrase}"/>
-
-    <!-- Maven artifacts -->
-    <sign-maven-dependency-artifacts artifact.id="solr-commons-csv" gpg.passphrase="${gpg.passphrase}"/>
-    <sign-maven-dependency-artifacts artifact.id="solr-noggit" gpg.passphrase="${gpg.passphrase}"/>
-    <sign-maven-dependency-artifacts artifact.id="solr-uima-an-alchemy" gpg.passphrase="${gpg.passphrase}"/>
-    <sign-maven-dependency-artifacts artifact.id="solr-uima-an-calais" gpg.passphrase="${gpg.passphrase}"/>
-    <sign-maven-dependency-artifacts artifact.id="solr-uima-an-tagger" gpg.passphrase="${gpg.passphrase}"/>
-    <sign-maven-dependency-artifacts artifact.id="solr-uima-an-wst" gpg.passphrase="${gpg.passphrase}"/>
-    <sign-maven-war-artifacts artifact.id="solr" gpg.passphrase="${gpg.passphrase}"/>
-    <sign-maven-artifacts artifact.id="solr-analysis-extras" gpg.passphrase="${gpg.passphrase}"/>
-    <sign-maven-artifacts artifact.id="solr-cell" gpg.passphrase="${gpg.passphrase}"/>
-    <sign-maven-artifacts artifact.id="solr-clustering" gpg.passphrase="${gpg.passphrase}"/>
-    <sign-maven-artifacts artifact.id="solr-core" gpg.passphrase="${gpg.passphrase}"/>
-    <sign-maven-artifacts artifact.id="solr-dataimporthandler" gpg.passphrase="${gpg.passphrase}"/>
-    <sign-maven-artifacts artifact.id="solr-dataimporthandler-extras" gpg.passphrase="${gpg.passphrase}"/>
-    <sign-maven-artifacts artifact.id="solr-solrj" gpg.passphrase="${gpg.passphrase}"/>
-    <sign-maven-artifacts artifact.id="solr-uima" gpg.passphrase="${gpg.passphrase}"/>
-
-    <!-- These are special since there are no jars, just poms -->
-    <sign-artifact input.file="${maven.dist.prefix}/solr-parent/${version}/solr-parent-${version}.pom" gpg.passphrase="${gpg.passphrase}"/>
-  </target>
-
-  <property name="rc" value="rc0"/>
-  <property name="remote.staging.dir" value="public_html/staging_area/${rc}/${version}"/>
-  <property name="keyfile" value="${user.home}/.ssh/id_rsa"/>
-  <property name="scp.user" value="${user.name}"/>
-  <!--keys.dir is the location of the https://svn.apache.org/repos/asf/lucene/java/dist/ directory-->
-  <property name="keys.dir" value="${common-solr.dir}/../../dist"/>
-  <target name="copy-to-stage">
-    <sshexec host="people.apache.org"
-	    username="${scp.user}"
-	    keyfile="${keyfile}"
-	    command="mkdir -p ${remote.staging.dir}"/>
-    <echo>Uploading artifacts to ${scp.user}@people.apache.org:${remote.staging.dir}</echo>
-    <scp todir="${scp.user}@people.apache.org:${remote.staging.dir}"
-         username="${scp.user}"
-	    keyfile="${keyfile}"
-      verbose="true"
-        >
-      <fileset dir="package"/>
-      <fileset dir="${keys.dir}">
-        <include name="KEYS"/>
-      </fileset>
-    </scp>
-  </target>
-
-  <target name="prepare-release" depends="clean, svn-up, package, generate-maven-artifacts, sign-artifacts"
-          description="Prototype helper for Committers.  Assumes gpg is in the path"/>
-
-  <target name="stage" depends="prepare-release, copy-to-stage"/>
-
-  <target name="generate-maven-artifacts" depends="maven.ant.tasks-check,dist,dist-src,dist-javadoc">
-    <sequential>
-	  <ant target="get-maven-poms" dir=".."/>
-
-      <!--
-
-       !!!!!!!!!!
-       NOTE:  If you add new artifacts, please make sure you also add to the sign-artifacts target
-       so that they get signed during release.
-      !!!!!!!
-       -->
-
-      <mkdir dir="${maven.build.dir}"/>
-      <mkdir dir="${maven.dist.dir}"/>
-
-      <!-- ========== SOLR PARENT POM ========== -->
-
-      <m2-deploy pom.xml="pom.xml"/>
-
-      <!-- ========== SOLR SPECIFIC NON-MAVENIZED DEPENDENCIES ========== -->
-      <m2-deploy-with-pom-template pom.xml="lib/solr-commons-csv-pom.xml.template"
-                                   jar.file="lib/commons-csv-1.0-SNAPSHOT-r966014.jar" />
-
-      <m2-deploy-with-pom-template pom.xml="lib/apache-solr-noggit-pom.xml.template"
-                                   jar.file="lib/apache-solr-noggit-r944541.jar" />
-      
-      <m2-deploy-with-pom-template pom.xml="contrib/uima/lib/solr-uima-an-alchemy-pom.xml.template"
-                                   jar.file="contrib/uima/lib/uima-an-alchemy-2.3.1-SNAPSHOT-r1062868.jar" />
-
-      <m2-deploy-with-pom-template pom.xml="contrib/uima/lib/solr-uima-an-calais-pom.xml.template"
-                                   jar.file="contrib/uima/lib/uima-an-calais-2.3.1-SNAPSHOT-r1062868.jar" />
-
-      <m2-deploy-with-pom-template pom.xml="contrib/uima/lib/solr-uima-an-tagger-pom.xml.template"
-                                   jar.file="contrib/uima/lib/uima-an-tagger-2.3.1-SNAPSHOT-r1062868.jar" />
-
-      <m2-deploy-with-pom-template pom.xml="contrib/uima/lib/solr-uima-an-wst-pom.xml.template"
-                                   jar.file="contrib/uima/lib/uima-an-wst-2.3.1-SNAPSHOT-r1076132.jar" />
-
-      <!-- ========== SOLR ARTIFACTS ========== -->
-
-      <m2-deploy pom.xml="contrib/dataimporthandler/src/pom.xml"
-                 jar.file="${dist}/apache-solr-dataimporthandler-${version}.jar">
-        <artifact-attachments>
-          <attach file="${dist}/apache-solr-dataimporthandler-src-${version}.jar" classifier="sources"/>
-          <attach file="${dist}/apache-solr-dataimporthandler-docs-${version}.jar" classifier="javadoc"/>
-        </artifact-attachments>
-      </m2-deploy>
-
-      <m2-deploy pom.xml="contrib/dataimporthandler/src/extras/pom.xml"
-                 jar.file="${dist}/apache-solr-dataimporthandler-extras-${version}.jar">
-        <artifact-attachments>
-          <attach file="${dist}/apache-solr-dataimporthandler-extras-src-${version}.jar" classifier="sources"/>
-          <attach file="${dist}/apache-solr-dataimporthandler-docs-${version}.jar" classifier="javadoc"/>
-        </artifact-attachments>
-      </m2-deploy>
-
-      <m2-deploy pom.xml="contrib/extraction/pom.xml"
-                 jar.file="${dist}/apache-solr-cell-${version}.jar">
-        <artifact-attachments>
-          <attach file="${dist}/apache-solr-cell-src-${version}.jar" classifier="sources"/>
-          <attach file="${dist}/apache-solr-cell-docs-${version}.jar" classifier="javadoc"/>
-        </artifact-attachments>
-      </m2-deploy>
-      
-      <m2-deploy pom.xml="contrib/clustering/pom.xml"
-                 jar.file="${dist}/apache-solr-clustering-${version}.jar">
-        <artifact-attachments>
-          <attach file="${dist}/apache-solr-clustering-src-${version}.jar" classifier="sources"/>
-          <attach file="${dist}/apache-solr-clustering-docs-${version}.jar" classifier="javadoc"/>
-        </artifact-attachments>
-      </m2-deploy>
-
-      <m2-deploy pom.xml="contrib/analysis-extras/pom.xml"
-                 jar.file="${dist}/apache-solr-analysis-extras-${version}.jar">
-        <artifact-attachments>
-          <attach file="${dist}/apache-solr-analysis-extras-src-${version}.jar" classifier="sources"/>
-          <attach file="${dist}/apache-solr-analysis-extras-docs-${version}.jar" classifier="javadoc"/>
-        </artifact-attachments>
-      </m2-deploy>
-
-      <m2-deploy pom.xml="contrib/uima/pom.xml"
-                 jar.file="${dist}/apache-solr-uima-${version}.jar">
-        <artifact-attachments>
-          <attach file="${dist}/apache-solr-uima-src-${version}.jar" classifier="sources"/>
-          <attach file="${dist}/apache-solr-uima-docs-${version}.jar" classifier="javadoc"/>
-        </artifact-attachments>
-      </m2-deploy>
-
-      <m2-deploy pom.xml="src/pom.xml"
-                 jar.file="${dist}/apache-solr-core-${version}.jar">
-        <artifact-attachments>
-          <attach file="${dist}/apache-solr-core-src-${version}.jar" classifier="sources"/>
-          <attach file="${dist}/apache-solr-core-docs-${version}.jar" classifier="javadoc"/>
-        </artifact-attachments>
-      </m2-deploy>
-
-      <m2-deploy pom.xml="src/solrj/pom.xml"
-                 jar.file="${dist}/apache-solr-solrj-${version}.jar">
-        <artifact-attachments>
-          <attach file="${dist}/apache-solr-solrj-src-${version}.jar" classifier="sources"/>
-          <attach file="${dist}/apache-solr-solrj-docs-${version}.jar" classifier="javadoc"/>
-        </artifact-attachments>
-      </m2-deploy>
-
-      <m2-deploy pom.xml="src/webapp/pom.xml"
-                 jar.file="${dist}/apache-solr-${version}.war"/>
-    </sequential>
-  </target>
-
-  <target name="set-fsdir">
-     <property name="use.fsdir" value="true"/>
-  </target>
-  
-  <target name="-taskdef">
-    <typedef resource="org/apache/rat/anttasks/antlib.xml" uri="antlib:rat.anttasks">
-      <classpath>
-        <fileset dir="." includes="rat*.jar"/>
-      </classpath>
-    </typedef>
-  </target>
-  <target name="rat-sources" depends="-taskdef"
-    description="runs the tasks over src/java excluding the license directory">
-    <rat:report xmlns:rat="antlib:org.apache.rat.anttasks">
-      <fileset dir="src/java"/>
-      <fileset dir="src/test"/>
-      <fileset dir="src/webapp"/>
-      <fileset dir="src/common"/>
-      <fileset dir="src/solrj"/>
-      <fileset dir="client">
-        <exclude name="**/CHANGES.*"/>
-      </fileset>
-      <fileset dir="contrib/dataimporthandler/src/main/java"/>
-      <fileset dir="contrib/dataimporthandler/src/test/java"/>
-      <fileset dir="contrib/dataimporthandler/src/extras/main/java"/>
-      <fileset dir="contrib/dataimporthandler/src/extras/test/java"/>
-      <fileset dir="contrib/clustering/src/main/java"/>
-      <fileset dir="contrib/clustering/src/test/java"/>
-      <fileset dir="contrib/extraction/src/main/java"/>
-      <fileset dir="contrib/extraction/src/test/java"/>
-      <fileset dir="contrib/analysis-extras/src/test"/>
-      <fileset dir="contrib/analysis-extras/src/test"/>
-      <fileset dir="contrib/uima/src/main/java"/>
-      <fileset dir="contrib/uima/src/test/java"/>
-    </rat:report>
-  </target>
-
-	
-  <!-- ========================================================================= -->
-  <!-- ===================== Runtime: luke         ============================= -->
-  <!-- ========================================================================= -->
-  <property  name="luke.version" value="1.0.1"/>
-  <available file="luke/luke-${luke.version}.jar" property="luke.jar.exists" />
-  <target name="luke-download" unless="luke.jar.exists" depends="proxy.setup">
-    <mkdir dir="luke"/>
-    <get src="http://luke.googlecode.com/files/luke-${luke.version}.jar"
-        dest="luke/luke-${luke.version}.jar"/>
-  </target>
-  <path id="luke.classpath">
-    <pathelement location="${common-solr.dir}/../lucene/build/classes/java" />
-    <pathelement location="${common-solr.dir}/../lucene/build/contrib/xml-query-parser/classes/java" />
-
-  </path>
-  <target name="luke" depends="luke-download">
-    <java fork="true" 
-          classname="org.getopt.luke.Luke"
-          logError="true"
-          failonerror="true">
-      <classpath>
-        <fileset dir="luke">
-          <include name="luke-${luke.version}.jar"/>
-        </fileset>
-        <path refid="lucene.classpath"/>
-        <path refid="luke.classpath"/>
-        <path refid="test.run.classpath"/>
-       </classpath>
-    </java>
+  <target name="compile-spellchecker" unless="spellchecker.uptodate">
+  	<ant dir="${common.dir}/contrib/spellchecker" target="default" inheritAll="false"/>
   </target>
 
 </project>
-
-
diff --git a/solr/common-build.xml b/solr/common-build.xml
index 861ff23..32006ba 100644
--- a/solr/common-build.xml
+++ b/solr/common-build.xml
@@ -15,624 +15,106 @@
  limitations under the License.
 -->
 
-<project name="common-solr" xmlns:artifact="antlib:org.apache.maven.artifact.ant">
+<project name="common-solr" default="default">
   <description>
     This file is designed for importing into a main build file, and not intended
     for standalone use.
   </description>
 
   <dirname file="${ant.file.common-solr}" property="common-solr.dir"/>
-  <import file="${common-solr.dir}/../common-build.xml"/>
   
-  <!-- change this together with the default and test's solrconfig.xml after starting a new development branch: -->
-  <property name="tests.luceneMatchVersion" value="4.0"/>
-
-  <!-- Initialize property values: allow easy customization via build.properties -->
-  <property file="build.properties" />
-
   <property name="Name" value="Solr" />
+  <property name="version" value="4.0-SNAPSHOT"/>
+  <property name="final.name" value="apache-${name}-${version}"/>
 
-  <property name="name" value="${ant.project.name}"/>
+  <!-- solr uses 1.6 -->
+  <property name="javac.source" value="1.6"/>
+  <property name="javac.target" value="1.6"/>
 
-  <property name="dev-tools.dir" value="${solr-path}/../dev-tools"/>
-  <property name="prettify.dir" value="${solr-path}/../lucene/src/tools/prettify"/>
-  <property name="package.dir" location="package"/>
+  <!-- solr uses its own build/dist directories -->
+  <property name="build.dir" location="${common-solr.dir}/build"/>
+  <property name="dist.dir" location="${common-solr.dir}/dist"/>
+  <property name="tests.userdir" value="${common-solr.dir}/src/test-files"/>
+  <property name="javadoc.dir" location="${common-solr.dir}/build/docs/api"/>
+  <property name="javadoc.link" value="http://java.sun.com/javase/6/docs/api/"/>
 
-  <tstamp>
-    <format property="year" pattern="yyyy"/>
-    <format property="DSTAMP" pattern="yyyy-MM-dd"/>
-    <format property="TSTAMP" pattern="HH:mm:ss"/>
-    <!-- datetime format that is safe to treat as part of a dotted version -->
-    <format property="dateversion" pattern="yyyy.MM.dd.HH.mm.ss" />
-  </tstamp>
+  <path id="additional.dependencies">
+  	<fileset dir="${common-solr.dir}/lib" includes="**/*.jar"/>
+  	<fileset dir="${common-solr.dir}/example/lib" includes="**/*.jar"/>
+  	<fileset dir="lib" includes="**/*.jar" erroronmissingdir="false"/>
+  </path>
 
-  <property name="junit.details" value="1"/>
+  <pathconvert property="project.classpath" targetos="unix" refid="additional.dependencies"/>
 
-  <!-- default arguments to pass to jvm executing tests -->
-  <property name="args" value="" />
+  <property name="tests.loggingfile" value="${common-solr.dir}/testlogging.properties"/>
 
-  <!-- TODO: measure toning this down by default to 1 -->
   <property name="tests.threadspercpu" value="2"/>
-  <condition property="tests.sequential">
-    <or>
-      <isset property="testcase"/>
-      <equals arg1="${tests.threadspercpu}" arg2="0"/>
-    </or>
-  </condition>
-
-  <property name="tests.multiplier" value="1" />
-  <property name="tests.codec" value="randomPerField" />
-  <property name="tests.locale" value="random" />
-  <property name="tests.timezone" value="random" />
-  <property name="tests.iter" value="1" />
-  <property name="tests.seed" value="random" />
-  <property name="tests.nightly" value="false" />
-  <property name="tests.verbose" value="false" />
-
-  <condition property="dir.prop" value="-Dsolr.directoryFactory=solr.StandardDirectoryFactory">
-    <isset property="use.fsdir"/>
-  </condition>
-
-  <!-- Example directory -->
-  <property name="example" value="${common-solr.dir}/example" />
-  <!-- 
-    we attempt to exec svnversion to get details build information
-    for jar manifests.  this property can be set at runtime to an
-    explicit path as needed, or ant will just try to find it in the
-    default PATH. (this is useful for Hudson)
-  -->
-  <property name="svnversion.exe" value="svnversion" />
-  <property name="svn.exe" value="svn" />
-
-  <!-- Java Version we are compatible with -->
-  <property name="java.compat.version" value="1.6" />
-
-  <!-- clover wants to run with -lib, otherwise we prefer a repeatable
-       classpath -->
-  <property name="javac.includeAntRuntime" value="${run.clover}"/>
-
-  <!-- Solr Implementation Version -->
-  <!--
-       This can be any string value that does not include spaces
-       This will be used when creating build artifact file names.
-
-       By default, this should be set to "X.Y.N-SNAPSHOT" where X.Y.N is
-       "1 greater" then the last version released (on this branch).
-    -->
-  <property name="version" value="4.0-SNAPSHOT" />
-  
-  <!-- Solr Specification Version -->
-  <!--
-       This will be used in the Manifest file, and therefore must
-       match the pattern "digit+{.digit+}*"
-       
-       By default, this should be set to "X.Y.M.${dateversion}"
-       where X.Y.M is the last version released (on this branch).
-    -->
-  <property name="specversion" value="4.0.0.${dateversion}" />
-
-  
-    <!-- Type of checksum to compute for distribution files -->
-  <property name="checksum.algorithm" value="md5" />
-  
-  <property name="fullname" value="apache-${ant.project.name}"/>
-  <property name="fullnamever" value="apache-${ant.project.name}-${version}"/>
-
-  <!-- Destination for compiled classes and binaries -->
-  <property name="dest" value="build" />
-  
-  <!-- Destination for Lucene jars -->
-  <property name="lucene-libs" location="lucene-libs" />
-
-  <!-- Javadoc properties -->
-  <property name="javadoc.years" value="2006 - ${year}" />
-  <property name="javadoc.access" value="protected"/>
-  <property name="javadoc.link.java"
-            value="http://java.sun.com/javase/6/docs/api/"/>
-  <property name="javadoc.link.junit"
-            value="http://junit.sourceforge.net/javadoc/"/>
-  <property name="javadoc.link.lucene"
-            value="https://hudson.apache.org/hudson/job/Lucene-trunk/javadoc/all/"/>
-  <property name="javadoc.packages" value="org.apache.solr.*"/>
-  <property name="build.docs" value="${dest}/docs"/>
-  <property name="build.javadoc" value="${common-solr.dir}/${build.docs}/api"/>
-  <property name="build.javadoc.solrj" value="${build.docs}/api-solrj"/>
-  
-  <!-- JUnit properties -->
-  <property name="testmethod" value=""/>
-  <property name="junit.includes" value="**/Test*.java,**/*Test.java"/>
-  <property name="junit.output.dir" location="${common-solr.dir}/${dest}/test-results"/>
-  <property name="junit.reports" location="${common-solr.dir}/${dest}/test-results/reports"/>
-  <property name="junit.formatter" value="plain"/>
-  <condition property="junit.details.formatter" 
-      value="org.apache.tools.ant.taskdefs.optional.junit.BriefJUnitResultFormatter"
-      else="org.apache.lucene.util.LuceneJUnitResultFormatter">
-    <isset property="tests.sequential"/>
-  </condition>
-  <property name="junit.parallel.selector" value="org.apache.lucene.util.LuceneJUnitDividingSelector"/>
-
-  <!-- Maven properties -->
-  <property name="maven.build.dir" value="${basedir}/build/maven"/>
-  <property name="maven.dist.dir" value="${package.dir}/maven"/>
-
-  <property name="maven.dist.prefix" value="${maven.dist.dir}/org/apache/solr"/>
-
-  <!-- By default, "deploy" to a temporary directory (as well as installing
-       into your local repository).  If you wish to deploy to a remote
-       repository, set this property to the URL of that repository.  In
-       addition, if the repository requires authentication, you can set
-       properties "m2.repository.username" and "m2.repository.private.key"
-       to define your credentials.
-  -->
-  <property name="m2.repository.url" value="file://${maven.dist.dir}"/>
-  <property name="m2.repository.private.key" value="${user.home}/.ssh/id_dsa"/>
-
-  <available property="maven.ant.tasks.present" classname="org.apache.maven.artifact.ant.Pom" />
-
-  <!-- End Maven Properties -->
-  
-  <available property="clover.present"
-            classname="com.cenqua.clover.tasks.CloverReportTask"
-            />
-   <condition property="clover.enabled">
-       <and>
-           <isset property="run.clover"/>
-           <isset property="clover.present"/>
-       </and>
-   </condition>
-   
-  <!-- Lucene -->
-  
-  <path id="lucene.classpath">
-    <pathelement location="${common-solr.dir}/../lucene/build/classes/java" />
-    <pathelement location="${common-solr.dir}/../modules/analysis/build/common/classes/java" />
-    <pathelement location="${common-solr.dir}/../modules/analysis/build/phonetic/classes/java" />
-    <pathelement location="${common-solr.dir}/../lucene/build/contrib/highlighter/classes/java" />
-    <pathelement location="${common-solr.dir}/../lucene/build/contrib/memory/classes/java" />
-    <pathelement location="${common-solr.dir}/../lucene/build/contrib/misc/classes/java" />
-    <pathelement location="${common-solr.dir}/../lucene/build/contrib/queries/classes/java" />
-    <pathelement location="${common-solr.dir}/../lucene/build/contrib/spatial/classes/java" />
-    <pathelement location="${common-solr.dir}/../lucene/build/contrib/spellchecker/classes/java" />
-  </path>   
-
-  <target name="prep-lucene-jars">
-    <sequential>
-      <subant target="jar-core" inheritall="false" failonerror="true">
-        <fileset dir="../lucene/" includes="build.xml" />
-      </subant>
-      <subant target="jar" inheritall="false" failonerror="true">
-        <fileset dir="../modules/analysis/common" includes="build.xml" />
-        <fileset dir="../modules/analysis/phonetic" includes="build.xml" />
-        <fileset dir="../lucene/contrib/highlighter" includes="build.xml" />
-        <fileset dir="../lucene/contrib/memory" includes="build.xml" />
-        <fileset dir="../lucene/contrib/misc" includes="build.xml" />
-        <fileset dir="../lucene/contrib/queries" includes="build.xml" />
-        <fileset dir="../lucene/contrib/spatial" includes="build.xml" />
-        <fileset dir="../lucene/contrib/spellchecker" includes="build.xml" />
-      </subant>
-    </sequential>
-  </target>
-      
-  <target name="lucene-jars-to-solr" depends="prep-lucene-jars">
-    <mkdir dir="${lucene-libs}"/>
-    <copy todir="${lucene-libs}" preservelastmodified="true" flatten="true" failonerror="true" overwrite="true">
-      <fileset dir="../lucene/build/">
-        <include name="lucene-core-${version}.jar" />
-      </fileset>
-      <fileset dir="../modules/analysis/build/common">
-        <include name="lucene-analyzers-common-${version}.jar" />
-      </fileset>
-      <fileset dir="../modules/analysis/build/phonetic">
-        <include name="lucene-analyzers-phonetic-${version}.jar" />
-      </fileset>
-      <fileset dir="../lucene/build/contrib/highlighter">
-        <include name="lucene-highlighter-${version}.jar" />
-      </fileset>
-      <fileset dir="../lucene/build/contrib/memory">
-        <include name="lucene-memory-${version}.jar" />
-      </fileset>
-      <fileset dir="../lucene/build/contrib/misc">
-        <include name="lucene-misc-${version}.jar" />
-      </fileset>
-      <fileset dir="../lucene/build/contrib/queries">
-        <include name="lucene-queries-${version}.jar" />
-      </fileset>
-      <fileset dir="../lucene/build/contrib/spatial">
-        <include name="lucene-spatial-${version}.jar" />
-      </fileset>
-      <fileset dir="../lucene/build/contrib/spellchecker">
-        <include name="lucene-spellchecker-${version}.jar" />
-      </fileset>
-      </copy>
-  </target>  
-  
-  <target name="compile-lucene" unless="lucene-compiled">
-    <property name="lucene-compiled" value="true"/>
-    <subant target="default">
-      <fileset dir="../modules/analysis/common" includes="build.xml"/>
-      <fileset dir="../modules/analysis/phonetic" includes="build.xml"/>
-      <fileset dir="../lucene/contrib/highlighter" includes="build.xml"/>
-      <fileset dir="../lucene/contrib/memory" includes="build.xml"/>
-      <fileset dir="../lucene/contrib/misc" includes="build.xml"/>
-      <fileset dir="../lucene/contrib/queries" includes="build.xml"/>
-      <fileset dir="../lucene/contrib/spatial" includes="build.xml"/>
-      <fileset dir="../lucene/contrib/spellchecker" includes="build.xml"/>
-    </subant>
-  </target>
-   
-   
-  <!-- Macro for compilation -->
-  <macrodef name="solr-javac">
-    <attribute name="destdir" />
-    <attribute name="classpathref" />
-    <element name="nested" optional="true" implicit="true" />
-    <sequential>
-      <mkdir dir="@{destdir}" />
-      <javac destdir="@{destdir}"
-             target="${java.compat.version}"
-             source="${java.compat.version}"
-             debug="on"
-             encoding="utf8"
-             includeAntRuntime="${javac.includeAntRuntime}"
-             sourcepath=""
-             classpathref="@{classpathref}">
-         <compilerarg line="-Xlint -Xlint:-deprecation -Xlint:-serial"/>
-         <nested />
-      </javac>
-    </sequential>
-  </macrodef>
-
-  <!-- Macro for building Jars -->
-  <macrodef name="solr-jar">
-    <attribute name="destfile" />
-    <attribute name="basedir" default="." />
-    <attribute name="includes" default="org/apache/**" />
-    <attribute name="excludes" default="" />
-    <attribute name="manifest" default="${common-solr.dir}/${dest}/META-INF/MANIFEST.MF" />
-    <element name="nested" optional="true" implicit="true" />
-    <sequential>
-      <jar destfile="@{destfile}"
-           basedir="@{basedir}"
-           includes="@{includes}"
-           excludes="@{excludes}"
-           filesetmanifest="skip"
-           manifest="@{manifest}">
-        <metainf dir="${common-solr.dir}" includes="LICENSE.txt,NOTICE.txt"/>
-        <nested />
-      </jar>
-    </sequential>
-  </macrodef>
-
-  <!-- Macro for building checksum files
-       This is only needed until the "format" option is supported
-       by ant's built in checksum task
-   -->
-  <macrodef name="solr-checksum">
-    <attribute name="file"/>
-    <sequential>
-      <echo>Building checksums for '@{file}'</echo>
-      <checksum file="@{file}" algorithm="md5" format="MD5SUM" forceoverwrite="yes" readbuffersize="65536"/>
-      <checksum file="@{file}" algorithm="sha1" format="MD5SUM" forceoverwrite="yes" readbuffersize="65536"/>
-    </sequential>
-  </macrodef>
-
 
+  <import file="../lucene/contrib/contrib-build.xml"/>
+
+  <!-- solr depends on the following modules/contribs -->	
+  <module-uptodate name="analysis/common" jarfile="${common.dir}/../modules/analysis/build/common/lucene-analyzers-common-${version}.jar"
+        property="analyzers-common.uptodate" classpath.property="analyzers-common.jar"/>
+  <module-uptodate name="analysis/phonetic" jarfile="${common.dir}/../modules/analysis/build/phonetic/lucene-analyzers-phonetic-${version}.jar"
+        property="analyzers-phonetic.uptodate" classpath.property="analyzers-phonetic.jar"/>
+  <contrib-uptodate name="highlighter" property="highlighter.uptodate" classpath.property="highlighter.jar"/>
+  <contrib-uptodate name="memory" property="memory.uptodate" classpath.property="memory.jar"/>
+  <contrib-uptodate name="misc" property="misc.uptodate" classpath.property="misc.jar"/>
+  <contrib-uptodate name="queries" property="queries.uptodate" classpath.property="queries.jar"/>
+  <contrib-uptodate name="spatial" property="spatial.uptodate" classpath.property="spatial.jar"/>
+  <contrib-uptodate name="spellchecker" property="spellchecker.uptodate" classpath.property="spellchecker.jar"/>
+	
+  <path id="solr.base.classpath">
+  	<pathelement path="${analyzers-common.jar}"/>
+  	<pathelement path="${analyzers-phonetic.jar}"/>
+  	<pathelement path="${highlighter.jar}"/>
+  	<pathelement path="${memory.jar}"/>
+  	<pathelement path="${misc.jar}"/>
+  	<pathelement path="${queries.jar}"/>
+  	<pathelement path="${spatial.jar}"/>
+  	<pathelement path="${spellchecker.jar}"/>
+  	<pathelement location="${common-solr.dir}/build/classes/solrj"/>
+  	<pathelement location="${common-solr.dir}/build/classes/webapp"/>
+  	<pathelement location="${common-solr.dir}/build/classes/java"/>
+  	<path refid="base.classpath"/>
+  </path>
+
+  <path id="classpath" refid="solr.base.classpath"/>
+
+  <path id="solr.test.base.classpath">
+  	<pathelement path="${common-solr.dir}/build/classes/test-framework"/>
+  	<pathelement path="${common-solr.dir}/build/classes/test"/>
+  	<pathelement path="${tests.userdir}"/>
+  	<path refid="test.base.classpath"/>
+  </path>
+ 
+  <path id="test.classpath" refid="solr.test.base.classpath"/>
+
+  <!-- TODO: lucene and solr should share this macro -->
   <macrodef name="contrib-crawl">
     <attribute name="target" default=""/>
     <attribute name="failonerror" default="true"/>
     <sequential>
       <subant target="@{target}" failonerror="@{failonerror}">
-        <property name="lucene-compiled" value="${lucene-compiled}"/>
-        <fileset dir="."
-                 includes="contrib/*/build.xml"
-        />
+        <property name="core.compiled" value="true"/>
+        <property name="solr.core.compiled" value="true"/>
+        <fileset dir="." includes="contrib/*/build.xml"/>
       </subant>
     </sequential>
   </macrodef>
 
-  <property name="failonjavadocwarning" value="true"/>
-  <macrodef name="invoke-javadoc">
-    <element name="sources" optional="yes"/>
-    <attribute name="destdir"/>
-  	<attribute name="title" default="${Name} ${version} API (${specversion})"/>
-    <sequential>
-      <mkdir dir="@{destdir}"/>
-      <copy todir="@{destdir}/prettify" overwrite="false">
-        <fileset dir="${prettify.dir}"/>
-      </copy>
-      <record name="@{destdir}/log_javadoc.txt" action="start" append="no"/>
-      <javadoc
-          packagenames="org.apache.solr.*"
-          failonerror="true"
-          destdir="@{destdir}"
-          access="${javadoc.access}"
-          encoding="utf-8"
-          author="true"
-          version="true"
-          use="true"
-          source="${ant.java.version}"
-          link="${javadoc.link.java}"
-          windowtitle="${Name} ${version} API"
-          doctitle="@{title}"
-          stylesheetfile="@{destdir}/prettify/stylesheet+prettify.css"
-          bottom="Copyright &amp;copy; ${year} Apache Software Foundation.  All Rights Reserved.">
-        <tag name="todo" description="To Do:"/>
-        <tag name="uml.property" description="UML Property:"/>
-        <tag name="lucene.experimental" 
-      	description="WARNING: This API is experimental and might change in incompatible ways in the next release."/>
-        <tag name="lucene.internal"
-        description="NOTE: This API is for Lucene internal purposes only and might change in incompatible ways in the next release."/>
-      	<link offline="true" packagelistLoc="${build.javadoc}"/>
-        <link href="${javadoc.link.java}"/>
-        <link href="${javadoc.link.junit}"/>
-        <link href="${javadoc.link.lucene}"/>
-      	<header><![CDATA[
-      		 <script src="{@docRoot}/prettify/prettify.js" type="text/javascript"></script>
-      		 <script language="JavaScript">window.onload=function(){windowTitle();prettyPrint();}</script>
-      	]]></header>
-
-        <sources />
-
-        <classpath refid="javadoc.classpath"/>
-      </javadoc>
-      <record name="@{destdir}/log_javadoc.txt" action="stop"/>
-
-      <delete>
-        <fileset file="@{destdir}/log_javadoc.txt">
-          <not>
-           <containsregexp expression="\[javadoc\]\s*[1-9][0-9]*[\s]*warning"/>
-          </not>
-        </fileset>
-      </delete>
-
-      <fail message="Javadocs warnings were found!" >
-        <condition>
-          <and>
-            <available file="@{destdir}/log_javadoc.txt"/>
-            <istrue value="${failonjavadocwarning}"/>
-          </and>
-        </condition>
-      </fail>
-   </sequential>
-  </macrodef>
-
-  <!-- NOTE, the pom.xml MUST be a relative path.  An absolute path may break the build on windows -->
-  <macrodef name="m2-deploy" description="Builds a Maven artifact">
-    <element name="artifact-attachments" optional="yes"/>
-    <attribute name="pom.xml" default="pom.xml"/>
-    <attribute name="jar.file" default="${jar.file}"/>
-    <sequential>
-      <artifact:install-provider artifactId="wagon-ssh" version="1.0-beta-7"/>
-      <artifact:pom id="maven.project" file="@{pom.xml}"/>
-      <artifact:deploy file="@{jar.file}">
-        <artifact-attachments/>
-        <remoteRepository url="${m2.repository.url}">
-          <authentication username="${m2.repository.username}" privateKey="${m2.repository.private.key}"/>
-        </remoteRepository>
-        <pom refid="maven.project"/>
-      </artifact:deploy>
-    </sequential>
-  </macrodef>
-
-  <macrodef name="m2-deploy-with-pom-template" description="Builds a Maven artifact given a POM template">
-    <attribute name="pom.xml"/>
-    <attribute name="jar.file"/>
-    <sequential>
-      <copy file="@{pom.xml}" tofile="${maven.build.dir}/@{pom.xml}">
-        <filterset begintoken="@" endtoken="@">
-          <filter token="version" value="${version}"/>
-        </filterset>
-      </copy>
-      <artifact:install-provider artifactId="wagon-ssh" version="1.0-beta-7"/>
-      <artifact:pom id="maven.project" file="${maven.build.dir}/@{pom.xml}" />
-      <artifact:deploy file="@{jar.file}">
-        <remoteRepository url="${m2.repository.url}">
-          <authentication username="${m2.repository.username}" privateKey="${m2.repository.private.key}"/>
-        </remoteRepository>
-        <pom refid="maven.project"/>
-      </artifact:deploy>
-    </sequential>
-  </macrodef>
-
-  <property name="gpg.exe" value="gpg" />
-  <property name="gpg.key" value="CODE SIGNING KEY" />
-  <macrodef name="sign-artifact" description="Signs the artifact">
-    <attribute name="input.file"/>
-    <attribute name="output.file" default="@{input.file}.asc"/>
-    <attribute name="gpg.passphrase"/>
-    <sequential>
-      <echo >Signing @{input.file} Sig File: @{output.file}</echo>
-
-      <exec executable="${gpg.exe}" >
-        <arg value="--batch"/>
-        <arg value="--armor"/>
-        <arg value="--output"/>
-        <arg value="@{output.file}"/>
-        <arg value="--default-key"/>
-        <arg value="${gpg.key}"/>
-        <arg value="--passphrase"/>
-        <arg value="@{gpg.passphrase}"/>
-        <arg value="--detach-sig"/>
-        <arg value="@{input.file}"/>
-      </exec>
-    </sequential>
-  </macrodef>
-
-  <!--
-   We need to sign:
-   The POM
-   The library jar
-   The sources jar
-   the javadoc jar
-   -->
-  <macrodef name="sign-maven-artifacts" description="Signs maven artifacts">
-    <attribute name="artifact.id"/>
-    <attribute name="prefix.dir" default="${maven.dist.prefix}"/>
-    <attribute name="gpg.passphrase"/>
-    <sequential>
-      <sign-artifact input.file="@{prefix.dir}/@{artifact.id}/${version}/@{artifact.id}-${version}.jar" gpg.passphrase="@{gpg.passphrase}"/>
-      <sign-artifact input.file="@{prefix.dir}/@{artifact.id}/${version}/@{artifact.id}-${version}-javadoc.jar" gpg.passphrase="@{gpg.passphrase}"/>
-      <sign-artifact input.file="@{prefix.dir}/@{artifact.id}/${version}/@{artifact.id}-${version}-sources.jar" gpg.passphrase="@{gpg.passphrase}"/>
-      <sign-artifact input.file="@{prefix.dir}/@{artifact.id}/${version}/@{artifact.id}-${version}.pom" gpg.passphrase="@{gpg.passphrase}"/>
-    </sequential>
-  </macrodef>
-
-  <macrodef name="sign-maven-war-artifacts" description="Signs maven artifacts">
-    <attribute name="artifact.id"/>
-    <attribute name="prefix.dir" default="${maven.dist.prefix}"/>
-    <attribute name="gpg.passphrase"/>
-    <sequential>
-      <sign-artifact input.file="@{prefix.dir}/@{artifact.id}/${version}/@{artifact.id}-${version}.war" gpg.passphrase="@{gpg.passphrase}"/>
-      <sign-artifact input.file="@{prefix.dir}/@{artifact.id}/${version}/@{artifact.id}-${version}.pom" gpg.passphrase="@{gpg.passphrase}"/>
-    </sequential>
-  </macrodef>
-
-  <macrodef name="sign-maven-dependency-artifacts" description="Signs a maven artifact and its POM">
-    <attribute name="artifact.id"/>
-    <attribute name="prefix.dir" default="${maven.dist.prefix}"/>
-    <attribute name="gpg.passphrase"/>
-    <sequential>
-      <sign-artifact input.file="@{prefix.dir}/@{artifact.id}/${version}/@{artifact.id}-${version}.jar"  gpg.passphrase="@{gpg.passphrase}"/>
-      <sign-artifact input.file="@{prefix.dir}/@{artifact.id}/${version}/@{artifact.id}-${version}.pom"  gpg.passphrase="@{gpg.passphrase}"/>
+  <macrodef name="solr-contrib-uptodate">
+    <attribute name="name"/>
+    <attribute name="property" default="@{name}.uptodate"/>
+    <attribute name="classpath.property" default="@{name}.jar"/>
+    <!-- set jarfile only, if the target jar file has no generic name -->
+    <attribute name="jarfile" default="${common-solr.dir}/build/contrib/@{name}/@{name}-${version}.jar"/>
+  	<sequential>
+      <!--<echo message="Checking '@{jarfile}' against source folder '${common.dir}/contrib/@{name}/src/java'"/>-->
+      <property name="@{classpath.property}" location="@{jarfile}"/>
+      <uptodate property="@{property}" targetfile="@{jarfile}">
+        <srcfiles dir="${common-solr.dir}/contrib/@{name}/src/main/java" includes="**/*.java"/>
+      </uptodate>
     </sequential>
   </macrodef>
-
-  <!-- setup proxy for download tasks -->
-  <condition property="proxy.specified">
-    <or>
-      <isset property="proxy.host"/>
-      <isset property="proxy.port"/>
-      <isset property="proxy.user"/>
-    </or>
-  </condition>
-
-  <target name="proxy.setup" if="proxy.specified">
-    <setproxy proxyhost="${proxy.host}" proxyport="${proxy.port}" proxyuser="${proxy.user}" proxypassword="${proxy.password}"/>
-  </target>
-
-
-  <target name="clean-contrib"
-	          description="Cleans all contrib modules and their tests">
-	<contrib-crawl target="clean"/>
-  </target>
-
-  <target name="build-contrib"
-          description="Builds all contrib modules and their tests">
-    <contrib-crawl target="build"/>
-  </target>
-
-  <target name="test-contrib" depends="build-contrib">
-    <contrib-crawl target="test" failonerror="true"/>
-  </target>
-
-  <target name="dist-contrib" description="Make the contribs ready for distribution">
-  	<contrib-crawl target="dist" failonerror="true" />
-  </target>
-
-  <target name="example-contrib" description="Tell the contrib to add their stuff to examples">
-  	<contrib-crawl target="example" failonerror="true" />
-  </target>
-
-  <!-- Creates a Manifest file for Jars and WARs -->
-  <target name="make-manifest">
-     <!-- If possible, include the svnversion -->
-     <exec dir="." executable="${svnversion.exe}" outputproperty="svnversion" failifexecutionfails="false">
-      <arg line="."/>
-     </exec>
-
-     <!-- no description, don't advertise -->
-     <mkdir dir="${dest}/META-INF/" />
-     <manifest mode="replace" file="${dest}/META-INF/MANIFEST.MF">
-        <!--
-        http://java.sun.com/j2se/1.5.0/docs/guide/jar/jar.html#JAR%20Manifest
-        http://java.sun.com/j2se/1.5.0/docs/guide/versioning/spec/versioning2.html
-        http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Package.html
-        http://java.sun.com/j2se/1.5.0/docs/api/java/util/jar/package-summary.html
-        http://java.sun.com/developer/Books/javaprogramming/JAR/basics/manifest.html
-        -->
-        <!-- Don't set 'Manifest-Version' it identifies the version of the
-             manifest file format, and should always be 1.0 (the default)
-
-             Don't set 'Created-by' attribute, its purpose is 
-             to identify the version of java used to build the jar,
-             which ant will do by default.
-
-             Ant will happily override these with bogus strings if you
-             tell it to, so don't.
-
-             NOTE: we don't use section info because all of our manifest data
-             applies to the entire jar/war ... no package specific info.
-        -->
-        <attribute name="Extension-Name" 
-                   value="org.apache.solr"/>
-        <attribute name="Specification-Title" 
-                   value="Apache Solr Search Server"/>
-        <!-- spec version must match "digit+{.digit+}*" -->
-        <attribute name="Specification-Version" 
-                   value="${specversion}"/>
-        <attribute name="Specification-Vendor" 
-                   value="The Apache Software Foundation"/>
-        <attribute name="Implementation-Title" 
-                   value="org.apache.solr"/>
-        <!-- impl version can be any string -->
-        <attribute name="Implementation-Version" 
-                   value="${version} ${svnversion} - ${user.name} - ${DSTAMP} ${TSTAMP}"/>
-        <attribute name="Implementation-Vendor" 
-                   value="The Apache Software Foundation"/>
-        <attribute name="X-Compile-Source-JDK" 
-                   value="${java.compat.version}"/>
-        <attribute name="X-Compile-Target-JDK" 
-                   value="${java.compat.version}"/>
-     </manifest>
-  </target>
-
-  <target name="maven.ant.tasks-check">
-    <fail unless="maven.ant.tasks.present">#
-    ##########################################################################
-      Maven ant tasks not found.
-
-      Please download the Maven ant tasks JAR (maven-ant-tasks-2.1.1.jar)
-      from http://maven.apache.org/ant-tasks/download.html and add it to your
-      $$HOME/.ant/lib/ directory, or to your $$ANT_HOME/lib/ directory, or
-      to your $$CLASSPATH, or add "-lib /path/to/maven-ant-tasks-2.1.1.jar"
-      to the ant command.
-    ##########################################################################
-    </fail>
-  </target>
-  <!-- Validation -->
-  <target name="validate" depends="validate-solr"/>
-  <target name="validate-solr" depends="check-legal-solr" unless="validated-solr"/>
-
-  <target name="check-legal-solr" depends="compile-tools">
-    <java classname="org.apache.lucene.validation.DependencyChecker" failonerror="true" fork="true">
-      <classpath>
-        <path refid="tools.runtime.classpath" />
-      </classpath>
-      <!-- TODO: it might be better to just automatically find all directories that contain jar files, but that could take a
-       long time.  This should be faster, but we could miss a directory
-       -->
-      <!-- Solr -->
-      <arg value="-c" />
-      <arg value="${basedir}/lib" />
-      <arg value="-c" />
-      <arg value="${basedir}/contrib/analysis-extras/lib" />
-      <arg value="-c" />
-      <arg value="${basedir}/contrib/clustering/lib" />
-      <arg value="-c" />
-      <arg value="${basedir}/contrib/dataimporthandler/lib" />
-      <arg value="-c" />
-      <arg value="${basedir}/contrib/extraction/lib" />
-      <arg value="-c" />
-      <arg value="${basedir}/contrib/uima/lib" />
-      <arg value="-c" />
-      <arg value="${basedir}/example/example-DIH/solr/db/lib" />
-      <arg value="-c" />
-      <arg value="${basedir}/example/example-DIH/solr/mail/lib" />
-      <arg value="-c" />
-      <arg value="${basedir}/example/example/lib" />
-      <arg value="-c" />
-      <arg value="${basedir}/src/test-files/solr/lib" />
-    </java>
-  </target>
-
 </project>
diff --git a/solr/contrib/analysis-extras/build.xml b/solr/contrib/analysis-extras/build.xml
index 1b135e3..d4c455e 100644
--- a/solr/contrib/analysis-extras/build.xml
+++ b/solr/contrib/analysis-extras/build.xml
@@ -17,194 +17,43 @@
     limitations under the License.
  -->
 
-<project name="solr-analysis-extras" default="build">
-
-  <property name="solr-path" value="../.."/>
-
-  <import file="../../common-build.xml"/>
+<project name="solr-analysis-extras" default="default">
 
   <description>
     Additional analysis components
   </description>
 
-  <property name="example.local" value="example"/>
-  
-  <!-- support for the additional analyzers modules -->
-  <path id="modules.classpath">
-    <pathelement location="${common-solr.dir}/../modules/analysis/build/icu/classes/java" />
-    <pathelement location="${common-solr.dir}/../modules/analysis/build/smartcn/classes/java" />
-  	<pathelement location="${common-solr.dir}/../modules/analysis/build/stempel/classes/java" />
-  </path>
-	
-  <target name="prep-module-jars">
-    <subant target="jar" inheritall="false" failonerror="true">
-      <fileset dir="${common-solr.dir}/../modules/analysis/icu" includes="build.xml" />
-      <fileset dir="${common-solr.dir}/../modules/analysis/smartcn" includes="build.xml" />
-      <fileset dir="${common-solr.dir}/../modules/analysis/stempel" includes="build.xml" />
-    </subant>
-  </target>
-
-  <target name="module-jars-to-solr" depends="prep-module-jars">
-    <mkdir dir="${lucene-libs}"/>
-    <copy todir="${lucene-libs}" preservelastmodified="true" flatten="true" failonerror="true" overwrite="true">
-      <fileset dir="${common-solr.dir}/../modules/analysis/build/icu">
-        <include name="lucene-analyzers-icu-${version}.jar" />
-      </fileset>
-      <fileset dir="${common-solr.dir}/../modules/analysis/build/smartcn">
-          <include name="lucene-analyzers-smartcn-${version}.jar" />
-  	  </fileset>
-      <fileset dir="${common-solr.dir}/../modules/analysis/build/stempel">
-        <include name="lucene-analyzers-stempel-${version}.jar" />
-	  </fileset>
-    </copy>
-  </target>
-	 
-  <path id="common.classpath">
-    <fileset dir="lib"/>
-    <pathelement location="${solr-path}/build/solr"/>
-    <pathelement location="${solr-path}/build/solrj"/>
-    <path refid="lucene.classpath"/>
-  	<path refid="modules.classpath"/>
-    <fileset dir="${solr-path}/lib" includes="*.jar"/>
-  </path>
-
-  <path id="test.classpath">
-    <pathelement path="${dest}/classes"/>
-    <pathelement path="${dest}/test-classes"/>
-    <pathelement path="${java.class.path}"/>
-    <pathelement location="${common-solr.dir}/build/tests"/> <!-- include solr test code -->
-    <pathelement location="${common-solr.dir}/../lucene/build/classes/test-framework" />  <!-- include some lucene test code -->
-    <path refid="common.classpath"/>
-  </path>
-
-  <target name="clean">
-    <delete failonerror="false" dir="${dest}"/>
+  <property name="src.dir" location="src/java"/>
+  <property name="tests.src.dir" location="src/test"/>
+  <property name="tests.userdir" location="src/test-files"/>
 
-    <!-- example doesn't create this anymore, but clean it up
-         if it's still there from an old build
-      -->
-    <delete dir="example/lib" />
-  	<delete dir="${lucene-libs}" />
-  </target>
-
-
-  <target name="init" depends="module-jars-to-solr">
-    <mkdir dir="${dest}/classes"/>
-    
-    <mkdir dir="${build.javadoc}"/>
-    <subant target="compileTests">
-      <fileset dir="${solr-path}" includes="build.xml"/>
-    </subant>
-    <subant target="make-manifest">
-      <fileset dir="${solr-path}" includes="build.xml"/>
-    </subant>
-  </target>
+  <import file="../contrib-build.xml"/>
 
+  <module-uptodate name="analysis/icu" jarfile="${common.dir}/../modules/analysis/build/icu/lucene-analyzers-icu-${version}.jar"
+	    property="analyzers-icu.uptodate" classpath.property="analyzers-icu.jar"/>
+  <module-uptodate name="analysis/smartcn" jarfile="${common.dir}/../modules/analysis/build/smartcn/lucene-analyzers-smartcn-${version}.jar"
+		property="analyzers-smartcn.uptodate" classpath.property="analyzers-smartcn.jar"/>
+  <module-uptodate name="analysis/stempel" jarfile="${common.dir}/../modules/analysis/build/stempel/lucene-analyzers-stempel-${version}.jar"
+		property="analyzers-stempel.uptodate" classpath.property="analyzers-stempel.jar"/>
 
-  <target name="compile" depends="init">
-    <solr-javac destdir="${dest}/classes"
-                classpathref="common.classpath">
-      <src path="src/java"/>
-    </solr-javac>
-  </target>
-
-  <target name="build" depends="compile">
-    <solr-jar destfile="${dest}/${fullnamever}.jar" basedir="${dest}/classes"
-              manifest="../../${dest}/META-INF/MANIFEST.MF"/>
-  </target>
-
-  <target name="compileTests" depends="compile">
-    <solr-javac destdir="${dest}/test-classes"
-                classpathref="test.classpath">
-      <src path="src/test"/>
-    </solr-javac>
-    <!-- Copy any data files present to the classpath -->
-    <copy todir="${dest}/test-classes">
-      <fileset dir="src/test-files" excludes="**/*.java"/>
-    </copy>
-  </target>
-
-  <target name="example" depends="build,dist">
-    <!-- this task use to copy lib's but that's no longer needed because
-         ../lib and ../lib/downloads are now included explicitly by
-         example/conf/solrconfig.xml
-      -->
-  </target>
-
-
-  <target name="test" depends="compileTests">
-    <mkdir dir="${junit.output.dir}"/>
-
-    <junit printsummary="no"
-           haltonfailure="no"
-           maxmemory="512M"
-           errorProperty="tests.failed"
-           failureProperty="tests.failed"
-           dir="${junit.output.dir}"
-           tempdir="${junit.output.dir}"
-           forkmode="perBatch"
-            >
-      <sysproperty key="java.util.logging.config.file" value="${common-solr.dir}/testlogging.properties"/>
-      <sysproperty key="tests.luceneMatchVersion" value="${tests.luceneMatchVersion}"/>
-      <sysproperty key="tests.codec" value="${tests.codec}"/>
-      <sysproperty key="tests.locale" value="${tests.locale}"/>
-      <sysproperty key="tests.timezone" value="${tests.timezone}"/>
-      <sysproperty key="tests.multiplier" value="${tests.multiplier}"/>
-      <sysproperty key="tests.seed" value="${tests.seed}"/>
-      <sysproperty key="tests.verbose" value="${tests.verbose}"/>
-      <sysproperty key="tests.iter" value="${tests.iter}"/>
-      <!-- set whether or not nightly tests should run -->
-      <sysproperty key="tests.nightly" value="${tests.nightly}"/>
-      <sysproperty key="jetty.testMode" value="1"/>
-      <sysproperty key="tempDir" file="${junit.output.dir}"/>
-      <sysproperty key="testmethod" value="${testmethod}"/>
-      <jvmarg line="${args}"/>
-      <formatter classname="${junit.details.formatter}" usefile="false" if="junit.details"/>
-      <classpath refid="test.classpath"/>
-      <assertions>
-        <enable package="org.apache.lucene"/>
-        <enable package="org.apache.solr"/>
-      </assertions>
-      <formatter type="${junit.formatter}"/>
-      <batchtest fork="yes" todir="${junit.output.dir}" unless="testcase">
-        <fileset dir="src/test" includes="${junit.includes}"/>
-      </batchtest>
-      <batchtest fork="yes" todir="${junit.output.dir}" if="testcase">
-        <fileset dir="src/test" includes="**/${testcase}.java"/>
-      </batchtest>
-    </junit>
+  <path id="classpath">
+  	<pathelement path="${analyzers-icu.jar}"/>
+  	<pathelement path="${analyzers-smartcn.jar}"/>
+  	<pathelement path="${analyzers-stempel.jar}"/>
+    <path refid="solr.base.classpath"/>
+  </path>
 
-    <fail if="tests.failed">Tests failed!</fail>
+  <target name="compile-analyzers-icu" unless="analyzers-icu.uptodate">
+  	<ant dir="${common.dir}/../modules/analysis/icu" target="default" inheritAll="false"/>
   </target>
 
-  <target name="dist" depends="build">
-    <!--
-      <copy file="${dest}/${fullnamever}.jar" todir="${solr-path}/build/web/WEB-INF/lib"/>
-      <copy todir="${solr-path}/build/web/WEB-INF/lib" flatten="true">
-        <fileset dir="lib">
-          <include name="**/*.jar"/>
-        </fileset>
-      </copy>
-    -->
-    <copy file="${dest}/${fullnamever}.jar" todir="${solr-path}/dist"/>
+  <target name="compile-analyzers-smartcn" unless="analyzers-smartcn.uptodate">
+  	<ant dir="${common.dir}/../modules/analysis/smartcn" target="default" inheritAll="false"/>
   </target>
 
-  <target name="javadoc">
-    <sequential>
-      <mkdir dir="${build.javadoc}/contrib-${name}"/>
-
-      <path id="javadoc.classpath">
-        <path refid="common.classpath"/>
-      </path>
-
-      <invoke-javadoc
-              destdir="${build.javadoc}/contrib-${name}"
-              title="${Name} ${version} contrib-${fullnamever} API">
-        <sources>
-          <packageset dir="src/java"/>
-        </sources>
-      </invoke-javadoc>
-    </sequential>
+  <target name="compile-analyzers-stempel" unless="analyzers-stempel.uptodate">
+  	<ant dir="${common.dir}/../modules/analysis/stempel" target="default" inheritAll="false"/>
   </target>
 
+  <target name="compile-core" depends="compile-analyzers-icu, compile-analyzers-smartcn, compile-analyzers-stempel, solr-contrib-build.compile-core"/>
 </project>
diff --git a/solr/contrib/clustering/build.xml b/solr/contrib/clustering/build.xml
index 7090ca7..799ce0f 100644
--- a/solr/contrib/clustering/build.xml
+++ b/solr/contrib/clustering/build.xml
@@ -17,168 +17,15 @@
     limitations under the License.
  -->
 
-<project name="solr-clustering" default="build">
-
-  <property name="solr-path" value="../.."/>
-
-  <import file="../../common-build.xml"/>
+<project name="solr-clustering" default="default">
 
   <description>
     Clustering Integraton
   </description>
 
-  <property name="example.local" value="example"/>
-  
-  <path id="common.classpath">
-  	<fileset dir="lib" includes="*.jar"/>
-    <pathelement location="${solr-path}/build/solr"/>
-    <pathelement location="${solr-path}/build/solrj"/>
-    <path refid="lucene.classpath"/>
-    <fileset dir="${solr-path}/lib" includes="*.jar"/>
-  </path>
-
-  <path id="test.classpath">
-    <pathelement path="${dest}/classes"/>
-    <pathelement path="${dest}/test-classes"/>
-    <pathelement path="${java.class.path}"/>
-    <pathelement location="${common-solr.dir}/build/tests"/> <!-- include solr test code -->
-    <pathelement location="${common-solr.dir}/../lucene/build/classes/test-framework" />  <!-- include some lucene test code -->
-    <path refid="common.classpath"/>
-    <!-- DistributedClusteringComponentTest uses Jetty -->
-    <fileset dir="${solr-path}/example/lib">
-      <include name="**/*.jar" />
-    </fileset>
-  </path>
-
-  <target name="clean">
-    <delete failonerror="false" dir="${dest}"/>
-
-    <!-- example doesn't create this anymore, but clean it up
-         if it's still there from an old build
-      -->
-    <delete dir="example/lib" />
-  </target>
-
-
-  <target name="init">
-    <mkdir dir="${dest}/classes"/>
-    
-    <mkdir dir="${build.javadoc}"/>
-    <subant target="compileTests">
-      <fileset dir="${solr-path}" includes="build.xml"/>
-    </subant>
-    <subant target="make-manifest">
-      <fileset dir="${solr-path}" includes="build.xml"/>
-    </subant>
-  </target>
-
-
-  <target name="compile" depends="init">
-    <solr-javac destdir="${dest}/classes"
-                classpathref="common.classpath">
-      <src path="src/main/java"/>
-    </solr-javac>
-  </target>
-
-  <target name="build" depends="compile">
-    <solr-jar destfile="${dest}/${fullnamever}.jar" basedir="${dest}/classes"
-              manifest="../../${dest}/META-INF/MANIFEST.MF"/>
-  </target>
-
-  <target name="compileTests" depends="compile">
-    <solr-javac destdir="${dest}/test-classes"
-                classpathref="test.classpath">
-      <src path="src/test/java"/>
-    </solr-javac>
-    <!-- Copy any data files present to the classpath -->
-    <copy todir="${dest}/test-classes">
-      <fileset dir="src/test/resources" excludes="**/*.java"/>
-    </copy>
-  </target>
-
-  <target name="example" depends="build,dist">
-    <!-- this task use to copy lib's but that's no longer needed because
-         ../lib and ../lib/downloads are now included explicitly by
-         example/conf/solrconfig.xml
-      -->
-  </target>
-
-
-  <target name="test" depends="compileTests">
-    <mkdir dir="${junit.output.dir}"/>
-
-    <junit printsummary="no"
-           haltonfailure="no"
-           maxmemory="512M"
-           errorProperty="tests.failed"
-           failureProperty="tests.failed"
-           dir="${junit.output.dir}"
-           tempdir="${junit.output.dir}"
-           forkmode="perBatch"
-            >
-      <sysproperty key="java.util.logging.config.file" value="${common-solr.dir}/testlogging.properties"/>
-      <sysproperty key="tests.luceneMatchVersion" value="${tests.luceneMatchVersion}"/>
-      <sysproperty key="tests.codec" value="${tests.codec}"/>
-      <sysproperty key="tests.locale" value="${tests.locale}"/>
-      <sysproperty key="tests.timezone" value="${tests.timezone}"/>
-      <sysproperty key="tests.multiplier" value="${tests.multiplier}"/>
-      <sysproperty key="tests.seed" value="${tests.seed}"/>
-      <sysproperty key="tests.verbose" value="${tests.verbose}"/>
-      <sysproperty key="tests.iter" value="${tests.iter}"/>
-      <!-- set whether or not nightly tests should run -->
-      <sysproperty key="tests.nightly" value="${tests.nightly}"/>
-      <sysproperty key="jetty.testMode" value="1"/>
-      <sysproperty key="tempDir" file="${junit.output.dir}"/>
-      <sysproperty key="testmethod" value="${testmethod}"/>
-      <jvmarg line="${args}"/>
-      <formatter classname="${junit.details.formatter}" usefile="false" if="junit.details"/>
-      <classpath refid="test.classpath"/>
-      <assertions>
-        <enable package="org.apache.lucene"/>
-        <enable package="org.apache.solr"/>
-      </assertions>
-      <formatter type="${junit.formatter}"/>
-      <batchtest fork="yes" todir="${junit.output.dir}" unless="testcase">
-        <fileset dir="src/test/java" includes="${junit.includes}">
-          <exclude name="**/AbstractClusteringTest*"/>
-        </fileset>
-      </batchtest>
-      <batchtest fork="yes" todir="${junit.output.dir}" if="testcase">
-        <fileset dir="src/test/java" includes="**/${testcase}.java"/>
-      </batchtest>
-    </junit>
-
-    <fail if="tests.failed">Tests failed!</fail>
-  </target>
-
-  <target name="dist" depends="build">
-    <!--
-      <copy file="${dest}/${fullnamever}.jar" todir="${solr-path}/build/web/WEB-INF/lib"/>
-      <copy todir="${solr-path}/build/web/WEB-INF/lib" flatten="true">
-        <fileset dir="lib">
-          <include name="**/*.jar"/>
-        </fileset>
-      </copy>
-    -->
-    <copy file="${dest}/${fullnamever}.jar" todir="${solr-path}/dist"/>
-  </target>
-
-  <target name="javadoc">
-    <sequential>
-      <mkdir dir="${build.javadoc}/contrib-${name}"/>
-
-      <path id="javadoc.classpath">
-        <path refid="common.classpath"/>
-      </path>
-
-      <invoke-javadoc
-              destdir="${build.javadoc}/contrib-${name}"
-              title="${Name} ${version} contrib-${fullnamever} API">
-        <sources>
-          <packageset dir="src/main/java"/>
-        </sources>
-      </invoke-javadoc>
-    </sequential>
-  </target>
+  <property name="src.dir" location="src/main/java"/>
+  <property name="tests.src.dir" location="src/test/java"/>
+  <property name="tests.userdir" location="src/test/resources"/>
 
+  <import file="../contrib-build.xml"/>
 </project>
diff --git a/solr/contrib/contrib-build.xml b/solr/contrib/contrib-build.xml
new file mode 100644
index 0000000..252f357
--- /dev/null
+++ b/solr/contrib/contrib-build.xml
@@ -0,0 +1,49 @@
+<?xml version="1.0"?>
+
+<!--
+    Licensed to the Apache Software Foundation (ASF) under one or more
+    contributor license agreements.  See the NOTICE file distributed with
+    this work for additional information regarding copyright ownership.
+    The ASF licenses this file to You under the Apache License, Version 2.0
+    the "License"); you may not use this file except in compliance with
+    the License.  You may obtain a copy of the License at
+ 
+        http://www.apache.org/licenses/LICENSE-2.0
+ 
+    Unless required by applicable law or agreed to in writing, software
+    distributed under the License is distributed on an "AS IS" BASIS,
+    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+    See the License for the specific language governing permissions and
+    limitations under the License.
+ -->
+
+<project name="solr-contrib-build">
+  <!-- TODO: adjust build.dir/dist.dir appropriately when a contrib project is run individually -->
+  <property name="build.dir" location="../../build/contrib/${ant.project.name}"/>
+  <property name="dist.dir" location="../../dist/"/>
+  	
+  <import file="../common-build.xml"/>
+
+  <target name="build-solr" unless="solr.core.compiled">
+    <ant dir="${common-solr.dir}" target="compile-test" inheritAll="false"/>
+    <!-- set the property for this ant execution to speed up later tasks depending on this -->
+    <property name="solr.core.compiled" value="true"/>
+  </target>
+  
+  <target name="compile-core" depends="build-solr, common.compile-core"/>
+  
+  <macrodef name="solr-contrib-uptodate">
+    <attribute name="name"/>
+    <attribute name="property" default="solr-@{name}.uptodate"/>
+    <attribute name="classpath.property" default="solr-@{name}.jar"/>
+    <!-- set jarfile only, if the target jar file has no generic name -->
+    <attribute name="jarfile" default="${common-solr.dir}/build/contrib/solr-@{name}/apache-solr-@{name}-${version}.jar"/>
+    <sequential>
+      <!--<echo message="Checking '@{jarfile}' against source folder '${common.dir}/contrib/@{name}/src/java'"/>-->
+      <property name="@{classpath.property}" location="@{jarfile}"/>
+      <uptodate property="@{property}" targetfile="@{jarfile}">
+        <srcfiles dir="../@{name}/src/main/java" includes="**/*.java"/>
+      </uptodate>
+    </sequential>
+  </macrodef>
+</project>
diff --git a/solr/contrib/dataimporthandler-extras/build.xml b/solr/contrib/dataimporthandler-extras/build.xml
new file mode 100644
index 0000000..d03b584
--- /dev/null
+++ b/solr/contrib/dataimporthandler-extras/build.xml
@@ -0,0 +1,58 @@
+<?xml version="1.0"?>
+
+<!--
+    Licensed to the Apache Software Foundation (ASF) under one or more
+    contributor license agreements.  See the NOTICE file distributed with
+    this work for additional information regarding copyright ownership.
+    The ASF licenses this file to You under the Apache License, Version 2.0
+    the "License"); you may not use this file except in compliance with
+    the License.  You may obtain a copy of the License at
+ 
+        http://www.apache.org/licenses/LICENSE-2.0
+ 
+    Unless required by applicable law or agreed to in writing, software
+    distributed under the License is distributed on an "AS IS" BASIS,
+    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+    See the License for the specific language governing permissions and
+    limitations under the License.
+ -->
+
+<project name="solr-dataimporthandler-extras" default="default">
+
+  <description>
+    Data Import Handler Extras
+  </description>
+  
+  <property name="src.dir" location="src/main/java"/>
+  <property name="tests.src.dir" location="src/test/java"/>
+  <property name="tests.userdir" location="src/test/resources"/>
+
+  <import file="../contrib-build.xml"/>
+
+  <solr-contrib-uptodate name="dataimporthandler" 
+                         property="solr-dataimporthandler.uptodate" 
+                         classpath.property="solr-dataimporthandler.jar"/>
+
+  <target name="compile-solr-dataimporthandler" unless="solr-dataimporthandler.uptodate">
+  	<ant dir="${common-solr.dir}/contrib/dataimporthandler" target="default" inheritAll="false"/>
+  </target>
+
+  <!-- 
+       really sucks we do this always, without an up-to-date thing for tests
+       we should probably fix this, the same issue exists in modules
+   -->
+  <target name="compile-solr-dataimporthandler-tests">
+  	<ant dir="${common-solr.dir}/contrib/dataimporthandler" target="compile-test" inheritAll="false"/>
+  </target>
+
+  <path id="classpath">
+    <pathelement location="${common-solr.dir}/build/contrib/solr-dataimporthandler/classes/java"/>
+    <pathelement location="${common-solr.dir}/build/contrib/solr-dataimporthandler/classes/test"/>
+    <fileset dir="${common-solr.dir}/contrib/dataimporthandler/lib" includes="**/*.jar"/>
+    <fileset dir="${common-solr.dir}/contrib/extraction/lib" includes="**/*.jar"/>
+    <path refid="solr.base.classpath"/>
+  </path>
+
+  <target name="compile-core" depends="compile-solr-dataimporthandler, solr-contrib-build.compile-core"/>
+  <target name="compile-test" depends="compile-solr-dataimporthandler-tests, contrib-build.compile-test"/>
+</project>
diff --git a/solr/contrib/dataimporthandler-extras/src/main/java/org/apache/solr/handler/dataimport/MailEntityProcessor.java b/solr/contrib/dataimporthandler-extras/src/main/java/org/apache/solr/handler/dataimport/MailEntityProcessor.java
new file mode 100644
index 0000000..0231d1e
--- /dev/null
+++ b/solr/contrib/dataimporthandler-extras/src/main/java/org/apache/solr/handler/dataimport/MailEntityProcessor.java
@@ -0,0 +1,602 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.solr.handler.dataimport;
+
+import com.sun.mail.imap.IMAPMessage;
+
+import org.apache.tika.config.TikaConfig;
+import org.apache.tika.utils.ParseUtils;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import javax.mail.*;
+import javax.mail.internet.AddressException;
+import javax.mail.internet.ContentType;
+import javax.mail.internet.InternetAddress;
+import javax.mail.internet.MimeMessage;
+import javax.mail.search.AndTerm;
+import javax.mail.search.ComparisonTerm;
+import javax.mail.search.ReceivedDateTerm;
+import javax.mail.search.SearchTerm;
+import java.io.InputStream;
+import java.text.ParseException;
+import java.text.SimpleDateFormat;
+import java.util.*;
+
+/**
+ * An {@link EntityProcessor} instance which can index emails along with their attachments from POP3 or IMAP sources. Refer to
+ * <a href="http://wiki.apache.org/solr/DataImportHandler">http://wiki.apache.org/solr/DataImportHandler</a> for more
+ * details. <b>This API is experimental and subject to change</b>
+ *
+ * @version $Id$
+ * @since solr 1.4
+ */
+public class MailEntityProcessor extends EntityProcessorBase {
+
+  public static interface CustomFilter {
+    public SearchTerm getCustomSearch(Folder folder);
+  }
+
+  @Override
+  public void init(Context context) {
+    super.init(context);
+    // set attributes using  XXX getXXXFromContext(attribute, defualtValue);
+    // applies variable resolver and return default if value is not found or null
+    // REQUIRED : connection and folder info
+    user = getStringFromContext("user", null);
+    password = getStringFromContext("password", null);
+    host = getStringFromContext("host", null);
+    protocol = getStringFromContext("protocol", null);
+    folderNames = getStringFromContext("folders", null);
+    // validate
+    if (host == null || protocol == null || user == null || password == null
+            || folderNames == null)
+      throw new DataImportHandlerException(DataImportHandlerException.SEVERE,
+              "'user|password|protocol|host|folders' are required attributes");
+
+    //OPTIONAL : have defaults and are optional
+    recurse = getBoolFromContext("recurse", true);
+    String excludes = getStringFromContext("exclude", "");
+    if (excludes != null && !excludes.trim().equals("")) {
+      exclude = Arrays.asList(excludes.split(","));
+    }
+    String includes = getStringFromContext("include", "");
+    if (includes != null && !includes.trim().equals("")) {
+      include = Arrays.asList(includes.split(","));
+    }
+    batchSize = getIntFromContext("batchSize", 20);
+    customFilter = getStringFromContext("customFilter", "");
+    String s = getStringFromContext("fetchMailsSince", "");
+    if (s != null)
+      try {
+        fetchMailsSince = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").parse(s);
+      } catch (ParseException e) {
+        throw new DataImportHandlerException(DataImportHandlerException.SEVERE, "Invalid value for fetchMailSince: " + s, e);
+      }
+
+    fetchSize = getIntFromContext("fetchSize", 32 * 1024);
+    cTimeout = getIntFromContext("connectTimeout", 30 * 1000);
+    rTimeout = getIntFromContext("readTimeout", 60 * 1000);
+    processAttachment = getBoolFromContext("processAttachement", true);
+
+    logConfig();
+  }
+
+  @Override
+  public Map<String, Object> nextRow() {
+    Message mail;
+    Map<String, Object> row = null;
+    do {
+      // try till there is a valid document or folders get exhausted.
+      // when mail == NULL, it means end of processing
+      mail = getNextMail();
+      if (mail != null)
+        row = getDocumentFromMail(mail);
+    } while (row == null && mail != null);    
+    return row;
+  }
+
+  private Message getNextMail() {
+    if (!connected) {
+      if (!connectToMailBox())
+        return null;
+      connected = true;
+    }
+    if (folderIter == null) {
+      createFilters();
+      folderIter = new FolderIterator(mailbox);
+    }
+    // get next message from the folder
+    // if folder is exhausted get next folder
+    // loop till a valid mail or all folders exhausted.
+    while (msgIter == null || !msgIter.hasNext()) {
+      Folder next = folderIter.hasNext() ? folderIter.next() : null;
+      if (next == null) {
+        return null;
+      }
+      msgIter = new MessageIterator(next, batchSize);
+    }
+    return msgIter.next();
+  }
+
+  private Map<String, Object> getDocumentFromMail(Message mail) {
+    Map<String, Object> row = new HashMap<String, Object>();
+    try {
+      addPartToDocument(mail, row, true);
+      return row;
+    } catch (Exception e) {
+      return null;
+    }
+  }
+
+  public void addPartToDocument(Part part, Map<String, Object> row, boolean outerMost) throws Exception {
+    if (part instanceof Message) {
+      addEnvelopToDocument(part, row);
+    }
+
+    String ct = part.getContentType();
+    ContentType ctype = new ContentType(ct);
+    if (part.isMimeType("multipart/*")) {
+      Multipart mp = (Multipart) part.getContent();
+      int count = mp.getCount();
+      if (part.isMimeType("multipart/alternative"))
+        count = 1;
+      for (int i = 0; i < count; i++)
+        addPartToDocument(mp.getBodyPart(i), row, false);
+    } else if (part.isMimeType("message/rfc822")) {
+      addPartToDocument((Part) part.getContent(), row, false);
+    } else {
+      String disp = part.getDisposition();
+      if (!processAttachment || (disp != null && disp.equalsIgnoreCase(Part.ATTACHMENT)))        return;
+      InputStream is = part.getInputStream();
+      String fileName = part.getFileName();
+      String content = ParseUtils.getStringContent(is, TikaConfig.getDefaultConfig(), ctype.getBaseType().toLowerCase(Locale.ENGLISH));
+      if (disp != null && disp.equalsIgnoreCase(Part.ATTACHMENT)) {
+        if (row.get(ATTACHMENT) == null)
+          row.put(ATTACHMENT, new ArrayList<String>());
+        List<String> contents = (List<String>) row.get(ATTACHMENT);
+        contents.add(content);
+        row.put(ATTACHMENT, contents);
+        if (row.get(ATTACHMENT_NAMES) == null)
+          row.put(ATTACHMENT_NAMES, new ArrayList<String>());
+        List<String> names = (List<String>) row.get(ATTACHMENT_NAMES);
+        names.add(fileName);
+        row.put(ATTACHMENT_NAMES, names);
+      } else {
+        if (row.get(CONTENT) == null)
+          row.put(CONTENT, new ArrayList<String>());
+        List<String> contents = (List<String>) row.get(CONTENT);
+        contents.add(content);
+        row.put(CONTENT, contents);
+      }
+    }
+  }
+
+  private void addEnvelopToDocument(Part part, Map<String, Object> row) throws MessagingException {
+    MimeMessage mail = (MimeMessage) part;
+    Address[] adresses;
+    if ((adresses = mail.getFrom()) != null && adresses.length > 0)
+      row.put(FROM, adresses[0].toString());
+
+    List<String> to = new ArrayList<String>();
+    if ((adresses = mail.getRecipients(Message.RecipientType.TO)) != null)
+      addAddressToList(adresses, to);
+    if ((adresses = mail.getRecipients(Message.RecipientType.CC)) != null)
+      addAddressToList(adresses, to);
+    if ((adresses = mail.getRecipients(Message.RecipientType.BCC)) != null)
+      addAddressToList(adresses, to);
+    if (to.size() > 0)
+      row.put(TO_CC_BCC, to);
+
+    row.put(MESSAGE_ID, mail.getMessageID());
+    row.put(SUBJECT, mail.getSubject());
+
+    Date d = mail.getSentDate();
+    if (d != null) {
+      row.put(SENT_DATE, d);
+    }
+
+    List<String> flags = new ArrayList<String>();
+    for (Flags.Flag flag : mail.getFlags().getSystemFlags()) {
+      if (flag == Flags.Flag.ANSWERED)
+        flags.add(FLAG_ANSWERED);
+      else if (flag == Flags.Flag.DELETED)
+        flags.add(FLAG_DELETED);
+      else if (flag == Flags.Flag.DRAFT)
+        flags.add(FLAG_DRAFT);
+      else if (flag == Flags.Flag.FLAGGED)
+        flags.add(FLAG_FLAGGED);
+      else if (flag == Flags.Flag.RECENT)
+        flags.add(FLAG_RECENT);
+      else if (flag == Flags.Flag.SEEN)
+        flags.add(FLAG_SEEN);
+    }
+    flags.addAll(Arrays.asList(mail.getFlags().getUserFlags()));
+    row.put(FLAGS, flags);
+
+    String[] hdrs = mail.getHeader("X-Mailer");
+    if (hdrs != null)
+      row.put(XMAILER, hdrs[0]);
+  }
+
+
+  private void addAddressToList(Address[] adresses, List<String> to) throws AddressException {
+    for (Address address : adresses) {
+      to.add(address.toString());
+      InternetAddress ia = (InternetAddress) address;
+      if (ia.isGroup()) {
+        InternetAddress[] group = ia.getGroup(false);
+        for (InternetAddress member : group)
+          to.add(member.toString());
+      }
+    }
+  }
+
+  private boolean connectToMailBox() {
+    try {
+      Properties props = new Properties();
+      props.setProperty("mail.store.protocol", protocol);
+      props.setProperty("mail.imap.fetchsize", "" + fetchSize);
+      props.setProperty("mail.imap.timeout", "" + rTimeout);
+      props.setProperty("mail.imap.connectiontimeout", "" + cTimeout);
+      Session session = Session.getDefaultInstance(props, null);
+      mailbox = session.getStore(protocol);
+      mailbox.connect(host, user, password);
+      LOG.info("Connected to mailbox");
+      return true;
+    } catch (MessagingException e) {
+      throw new DataImportHandlerException(DataImportHandlerException.SEVERE,
+              "Connection failed", e);
+    }
+  }
+
+  private void createFilters() {
+    if (fetchMailsSince != null) {
+      filters.add(new MailsSinceLastCheckFilter(fetchMailsSince));
+    }
+    if (customFilter != null && !customFilter.equals("")) {
+      try {
+        Class cf = Class.forName(customFilter);
+        Object obj = cf.newInstance();
+        if (obj instanceof CustomFilter) {
+          filters.add((CustomFilter) obj);
+        }
+      } catch (Exception e) {
+        throw new DataImportHandlerException(DataImportHandlerException.SEVERE,
+                "Custom filter could not be created", e);
+      }
+    }
+  }
+
+  private void logConfig() {
+    if (!LOG.isInfoEnabled()) return;
+    StringBuffer config = new StringBuffer();
+    config.append("user : ").append(user).append(System.getProperty("line.separator"));
+    config.append("pwd : ").append(password).append(System.getProperty("line.separator"));
+    config.append("protocol : ").append(protocol).append(System.getProperty("line.separator"));
+    config.append("host : ").append(host).append(System.getProperty("line.separator"));
+    config.append("folders : ").append(folderNames).append(System.getProperty("line.separator"));
+    config.append("recurse : ").append(recurse).append(System.getProperty("line.separator"));
+    config.append("exclude : ").append(exclude.toString()).append(System.getProperty("line.separator"));
+    config.append("include : ").append(include.toString()).append(System.getProperty("line.separator"));
+    config.append("batchSize : ").append(batchSize).append(System.getProperty("line.separator"));
+    config.append("fetchSize : ").append(fetchSize).append(System.getProperty("line.separator"));
+    config.append("read timeout : ").append(rTimeout).append(System.getProperty("line.separator"));
+    config.append("conection timeout : ").append(cTimeout).append(System.getProperty("line.separator"));
+    config.append("custom filter : ").append(customFilter).append(System.getProperty("line.separator"));
+    config.append("fetch mail since : ").append(fetchMailsSince).append(System.getProperty("line.separator"));
+    LOG.info(config.toString());
+  }
+
+  class FolderIterator implements Iterator<Folder> {
+    private Store mailbox;
+    private List<String> topLevelFolders;
+    private List<Folder> folders = null;
+    private Folder lastFolder = null;
+
+    public FolderIterator(Store mailBox) {
+      this.mailbox = mailBox;
+      folders = new ArrayList<Folder>();
+      getTopLevelFolders(mailBox);
+    }
+
+    public boolean hasNext() {
+      return !folders.isEmpty();
+    }
+
+    public Folder next() {
+      try {
+        boolean hasMessages = false;
+        Folder next;
+        do {
+          if (lastFolder != null) {
+            lastFolder.close(false);
+            lastFolder = null;
+          }
+          if (folders.isEmpty()) {
+            mailbox.close();
+            return null;
+          }
+          next = folders.remove(0);
+          if (next != null) {
+            String fullName = next.getFullName();
+            if (!excludeFolder(fullName)) {
+              hasMessages = (next.getType() & Folder.HOLDS_MESSAGES) != 0;
+              next.open(Folder.READ_ONLY);
+              lastFolder = next;
+              LOG.info("Opened folder : " + fullName);
+            }
+            if (recurse && ((next.getType() & Folder.HOLDS_FOLDERS) != 0)) {
+              Folder[] children = next.list();
+              LOG.info("Added its children to list  : ");
+              for (int i = children.length - 1; i >= 0; i--) {
+                folders.add(0, children[i]);
+                LOG.info("child name : " + children[i].getFullName());
+              }
+              if (children.length == 0)
+                LOG.info("NO children : ");
+            }
+          }
+        }
+        while (!hasMessages);
+        return next;
+      } catch (MessagingException e) {
+        //throw new DataImportHandlerException(DataImportHandlerException.SEVERE,
+        //        "Folder open failed", e);
+      }
+      return null;
+    }
+
+    public void remove() {
+      throw new UnsupportedOperationException("Its read only mode...");
+    }
+
+    private void getTopLevelFolders(Store mailBox) {
+      if (folderNames != null)
+        topLevelFolders = Arrays.asList(folderNames.split(","));
+      for (int i = 0; topLevelFolders != null && i < topLevelFolders.size(); i++) {
+        try {
+          folders.add(mailbox.getFolder(topLevelFolders.get(i)));
+        } catch (MessagingException e) {
+          // skip bad ones unless its the last one and still no good folder
+          if (folders.size() == 0 && i == topLevelFolders.size() - 1)
+            throw new DataImportHandlerException(DataImportHandlerException.SEVERE,
+                    "Folder retreival failed");
+        }
+      }
+      if (topLevelFolders == null || topLevelFolders.size() == 0) {
+        try {
+          folders.add(mailBox.getDefaultFolder());
+        } catch (MessagingException e) {
+          throw new DataImportHandlerException(DataImportHandlerException.SEVERE,
+                  "Folder retreival failed");
+        }
+      }
+    }
+
+    private boolean excludeFolder(String name) {
+      for (String s : exclude) {
+        if (name.matches(s))
+          return true;
+      }
+      for (String s : include) {
+        if (name.matches(s))
+          return false;
+      }
+      return include.size() > 0;
+    }
+  }
+
+  class MessageIterator implements Iterator<Message> {
+    private Folder folder;
+    private Message[] messagesInCurBatch;
+    private int current = 0;
+    private int currentBatch = 0;
+    private int batchSize = 0;
+    private int totalInFolder = 0;
+    private boolean doBatching = true;
+
+    public MessageIterator(Folder folder, int batchSize) {
+      try {
+        this.folder = folder;
+        this.batchSize = batchSize;
+        SearchTerm st = getSearchTerm();
+        if (st != null) {
+          doBatching = false;
+          messagesInCurBatch = folder.search(st);
+          totalInFolder = messagesInCurBatch.length;
+          folder.fetch(messagesInCurBatch, fp);
+          current = 0;
+          LOG.info("Total messages : " + totalInFolder);
+          LOG.info("Search criteria applied. Batching disabled");
+        } else {
+          totalInFolder = folder.getMessageCount();
+          LOG.info("Total messages : " + totalInFolder);
+          getNextBatch(batchSize, folder);
+        }
+      } catch (MessagingException e) {
+        throw new DataImportHandlerException(DataImportHandlerException.SEVERE,
+                "Message retreival failed", e);
+      }
+    }
+
+    private void getNextBatch(int batchSize, Folder folder) throws MessagingException {
+      // after each batch invalidate cache
+      if (messagesInCurBatch != null) {
+        for (Message m : messagesInCurBatch) {
+          if (m instanceof IMAPMessage)
+            ((IMAPMessage) m).invalidateHeaders();
+        }
+      }
+      int lastMsg = (currentBatch + 1) * batchSize;
+      lastMsg = lastMsg > totalInFolder ? totalInFolder : lastMsg;
+      messagesInCurBatch = folder.getMessages(currentBatch * batchSize + 1, lastMsg);
+      folder.fetch(messagesInCurBatch, fp);
+      current = 0;
+      currentBatch++;
+      LOG.info("Current Batch  : " + currentBatch);
+      LOG.info("Messages in this batch  : " + messagesInCurBatch.length);
+    }
+
+    public boolean hasNext() {
+      boolean hasMore = current < messagesInCurBatch.length;
+      if (!hasMore && doBatching
+              && currentBatch * batchSize < totalInFolder) {
+        // try next batch
+        try {
+          getNextBatch(batchSize, folder);
+          hasMore = current < messagesInCurBatch.length;
+        } catch (MessagingException e) {
+          throw new DataImportHandlerException(DataImportHandlerException.SEVERE,
+                  "Message retreival failed", e);
+        }
+      }
+      return hasMore;
+    }
+
+    public Message next() {
+      return hasNext() ? messagesInCurBatch[current++] : null;
+    }
+
+    public void remove() {
+      throw new UnsupportedOperationException("Its read only mode...");
+    }
+
+    private SearchTerm getSearchTerm() {
+      if (filters.size() == 0)
+        return null;
+      if (filters.size() == 1)
+        return filters.get(0).getCustomSearch(folder);
+      SearchTerm last = filters.get(0).getCustomSearch(folder);
+      for (int i = 1; i < filters.size(); i++) {
+        CustomFilter filter = filters.get(i);
+        SearchTerm st = filter.getCustomSearch(folder);
+        if (st != null) {
+          last = new AndTerm(last, st);
+        }
+      }
+      return last;
+    }
+  }
+
+  class MailsSinceLastCheckFilter implements CustomFilter {
+
+    private Date since;
+
+    public MailsSinceLastCheckFilter(Date date) {
+      since = date;
+    }
+
+    public SearchTerm getCustomSearch(Folder folder) {
+      return new ReceivedDateTerm(ComparisonTerm.GE, since);
+    }
+  }
+
+  // user settings stored in member variables
+  private String user;
+  private String password;
+  private String host;
+  private String protocol;
+
+  private String folderNames;
+  private List<String> exclude = new ArrayList<String>();
+  private List<String> include = new ArrayList<String>();
+  private boolean recurse;
+
+  private int batchSize;
+  private int fetchSize;
+  private int cTimeout;
+  private int rTimeout;
+
+  private Date fetchMailsSince;
+  private String customFilter;
+
+  private boolean processAttachment = true;
+
+  // holds the current state
+  private Store mailbox;
+  private boolean connected = false;
+  private FolderIterator folderIter;
+  private MessageIterator msgIter;
+  private List<CustomFilter> filters = new ArrayList<CustomFilter>();
+  private static FetchProfile fp = new FetchProfile();
+  private static final Logger LOG = LoggerFactory.getLogger(DataImporter.class);
+
+  // diagnostics
+  private int rowCount = 0;
+
+  static {
+    fp.add(FetchProfile.Item.ENVELOPE);
+    fp.add(FetchProfile.Item.FLAGS);
+    fp.add("X-Mailer");
+  }
+
+  // Fields To Index
+  // single valued
+  private static final String MESSAGE_ID = "messageId";
+  private static final String SUBJECT = "subject";
+  private static final String FROM = "from";
+  private static final String SENT_DATE = "sentDate";
+  private static final String XMAILER = "xMailer";
+  // multi valued
+  private static final String TO_CC_BCC = "allTo";
+  private static final String FLAGS = "flags";
+  private static final String CONTENT = "content";
+  private static final String ATTACHMENT = "attachment";
+  private static final String ATTACHMENT_NAMES = "attachmentNames";
+  // flag values
+  private static final String FLAG_ANSWERED = "answered";
+  private static final String FLAG_DELETED = "deleted";
+  private static final String FLAG_DRAFT = "draft";
+  private static final String FLAG_FLAGGED = "flagged";
+  private static final String FLAG_RECENT = "recent";
+  private static final String FLAG_SEEN = "seen";
+
+  private int getIntFromContext(String prop, int ifNull) {
+    int v = ifNull;
+    try {
+      String val = context.getEntityAttribute(prop);
+      if (val != null) {
+        val = context.replaceTokens(val);
+        v = Integer.valueOf(val);
+      }
+    } catch (NumberFormatException e) {
+      //do nothing
+    }
+    return v;
+  }
+
+  private boolean getBoolFromContext(String prop, boolean ifNull) {
+    boolean v = ifNull;
+    String val = context.getEntityAttribute(prop);
+    if (val != null) {
+      val = context.replaceTokens(val);
+      v = Boolean.valueOf(val);
+    }
+    return v;
+  }
+
+  private String getStringFromContext(String prop, String ifNull) {
+    String v = ifNull;
+    String val = context.getEntityAttribute(prop);
+    if (val != null) {
+      val = context.replaceTokens(val);
+      v = val;
+    }
+    return v;
+  }
+}
diff --git a/solr/contrib/dataimporthandler-extras/src/main/java/org/apache/solr/handler/dataimport/TikaEntityProcessor.java b/solr/contrib/dataimporthandler-extras/src/main/java/org/apache/solr/handler/dataimport/TikaEntityProcessor.java
new file mode 100644
index 0000000..9913c15
--- /dev/null
+++ b/solr/contrib/dataimporthandler-extras/src/main/java/org/apache/solr/handler/dataimport/TikaEntityProcessor.java
@@ -0,0 +1,197 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.solr.handler.dataimport;
+
+import org.apache.commons.io.IOUtils;
+import org.apache.tika.config.TikaConfig;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.parser.AutoDetectParser;
+import org.apache.tika.parser.ParseContext;
+import org.apache.tika.parser.Parser;
+import org.apache.tika.sax.BodyContentHandler;
+import org.apache.tika.sax.ContentHandlerDecorator;
+import org.apache.tika.sax.XHTMLContentHandler;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.xml.sax.Attributes;
+import org.xml.sax.ContentHandler;
+import org.xml.sax.SAXException;
+import org.xml.sax.helpers.DefaultHandler;
+
+import javax.xml.transform.OutputKeys;
+import javax.xml.transform.TransformerConfigurationException;
+import javax.xml.transform.sax.SAXTransformerFactory;
+import javax.xml.transform.sax.TransformerHandler;
+import javax.xml.transform.stream.StreamResult;
+import java.io.File;
+import java.io.InputStream;
+import java.io.StringWriter;
+import java.io.Writer;
+import java.util.HashMap;
+import java.util.Map;
+
+import static org.apache.solr.handler.dataimport.DataImportHandlerException.SEVERE;
+import static org.apache.solr.handler.dataimport.DataImportHandlerException.wrapAndThrow;
+import static org.apache.solr.handler.dataimport.DataImporter.COLUMN;
+import static org.apache.solr.handler.dataimport.XPathEntityProcessor.URL;
+/**
+ * <p>An implementation of {@link EntityProcessor} which reads data from rich docs
+ * using <a href="http://tika.apache.org/">Apache Tika</a>
+ *
+ * @version $Id$
+ * @since solr 3.1
+ */
+public class TikaEntityProcessor extends EntityProcessorBase {
+  private TikaConfig tikaConfig;
+  private static final Logger LOG = LoggerFactory.getLogger(TikaEntityProcessor.class);
+  private String format = "text";
+  private boolean done = false;
+  private String parser;
+  static final String AUTO_PARSER = "org.apache.tika.parser.AutoDetectParser";
+
+
+  @Override
+  protected void firstInit(Context context) {
+    try {
+      String tikaConfigFile = context.getResolvedEntityAttribute("tikaConfig");
+      if (tikaConfigFile == null) {
+        ClassLoader classLoader = context.getSolrCore().getResourceLoader().getClassLoader();
+        tikaConfig = new TikaConfig(classLoader);
+      } else {
+        File configFile = new File(tikaConfigFile);
+        if (!configFile.isAbsolute()) {
+          configFile = new File(context.getSolrCore().getResourceLoader().getConfigDir(), tikaConfigFile);
+        }
+        tikaConfig = new TikaConfig(configFile);
+      }
+    } catch (Exception e) {
+      wrapAndThrow (SEVERE, e,"Unable to load Tika Config");
+    }
+
+    format = context.getResolvedEntityAttribute("format");
+    if(format == null)
+      format = "text";
+    if (!"html".equals(format) && !"xml".equals(format) && !"text".equals(format)&& !"none".equals(format) )
+      throw new DataImportHandlerException(SEVERE, "'format' can be one of text|html|xml|none");
+    parser = context.getResolvedEntityAttribute("parser");
+    if(parser == null) {
+      parser = AUTO_PARSER;
+    }
+    done = false;
+  }
+
+  @Override
+  public Map<String, Object> nextRow() {
+    if(done) return null;
+    Map<String, Object> row = new HashMap<String, Object>();
+    DataSource<InputStream> dataSource = context.getDataSource();
+    InputStream is = dataSource.getData(context.getResolvedEntityAttribute(URL));
+    ContentHandler contentHandler = null;
+    Metadata metadata = new Metadata();
+    StringWriter sw = new StringWriter();
+    try {
+      if ("html".equals(format)) {
+        contentHandler = getHtmlHandler(sw);
+      } else if ("xml".equals(format)) {
+        contentHandler = getXmlContentHandler(sw);
+      } else if ("text".equals(format)) {
+        contentHandler = getTextContentHandler(sw);
+      } else if("none".equals(format)){
+        contentHandler = new DefaultHandler();        
+      }
+    } catch (TransformerConfigurationException e) {
+      wrapAndThrow(SEVERE, e, "Unable to create content handler");
+    }
+    Parser tikaParser = null;
+    if(parser.equals(AUTO_PARSER)){
+      AutoDetectParser parser = new AutoDetectParser();
+      parser.setConfig(tikaConfig);
+      tikaParser = parser;
+    } else {
+      tikaParser = (Parser) context.getSolrCore().getResourceLoader().newInstance(parser);
+    }
+    try {
+      tikaParser.parse(is, contentHandler, metadata , new ParseContext());
+    } catch (Exception e) {
+      wrapAndThrow(SEVERE, e, "Unable to read content");
+    }
+    IOUtils.closeQuietly(is);
+    for (Map<String, String> field : context.getAllEntityFields()) {
+      if (!"true".equals(field.get("meta"))) continue;
+      String col = field.get(COLUMN);
+      String s = metadata.get(col);
+      if (s != null) row.put(col, s);
+    }
+    if(!"none".equals(format) ) row.put("text", sw.toString());
+    done = true;
+    return row;
+  }
+
+  private static ContentHandler getHtmlHandler(Writer writer)
+          throws TransformerConfigurationException {
+    SAXTransformerFactory factory = (SAXTransformerFactory)
+            SAXTransformerFactory.newInstance();
+    TransformerHandler handler = factory.newTransformerHandler();
+    handler.getTransformer().setOutputProperty(OutputKeys.METHOD, "html");
+    handler.setResult(new StreamResult(writer));
+    return new ContentHandlerDecorator(handler) {
+      @Override
+      public void startElement(
+              String uri, String localName, String name, Attributes atts)
+              throws SAXException {
+        if (XHTMLContentHandler.XHTML.equals(uri)) {
+          uri = null;
+        }
+        if (!"head".equals(localName)) {
+          super.startElement(uri, localName, name, atts);
+        }
+      }
+
+      @Override
+      public void endElement(String uri, String localName, String name)
+              throws SAXException {
+        if (XHTMLContentHandler.XHTML.equals(uri)) {
+          uri = null;
+        }
+        if (!"head".equals(localName)) {
+          super.endElement(uri, localName, name);
+        }
+      }
+
+      @Override
+      public void startPrefixMapping(String prefix, String uri) {/*no op*/ }
+
+      @Override
+      public void endPrefixMapping(String prefix) {/*no op*/ }
+    };
+  }
+
+  private static ContentHandler getTextContentHandler(Writer writer) {
+    return new BodyContentHandler(writer);
+  }
+
+  private static ContentHandler getXmlContentHandler(Writer writer)
+          throws TransformerConfigurationException {
+    SAXTransformerFactory factory = (SAXTransformerFactory)
+            SAXTransformerFactory.newInstance();
+    TransformerHandler handler = factory.newTransformerHandler();
+    handler.getTransformer().setOutputProperty(OutputKeys.METHOD, "xml");
+    handler.setResult(new StreamResult(writer));
+    return handler;
+  }
+
+}
diff --git a/solr/contrib/dataimporthandler-extras/src/test/java/org/apache/solr/handler/dataimport/TestMailEntityProcessor.java b/solr/contrib/dataimporthandler-extras/src/test/java/org/apache/solr/handler/dataimport/TestMailEntityProcessor.java
new file mode 100644
index 0000000..2ac19b3
--- /dev/null
+++ b/solr/contrib/dataimporthandler-extras/src/test/java/org/apache/solr/handler/dataimport/TestMailEntityProcessor.java
@@ -0,0 +1,214 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.solr.handler.dataimport;
+
+import org.apache.solr.common.SolrInputDocument;
+import org.junit.Ignore;
+import org.junit.Test;
+
+import java.text.ParseException;
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+
+// Test mailbox is like this: foldername(mailcount)
+// top1(2) -> child11(6)
+//         -> child12(0)
+// top2(2) -> child21(1)
+//                 -> grandchild211(2)
+//                 -> grandchild212(1)
+//         -> child22(2)
+
+/**
+ * Test for MailEntityProcessor. The tests are marked as ignored because we'd need a mail server (real or mocked) for
+ * these to work.
+ *
+ * TODO: Find a way to make the tests actually test code
+ *
+ * @version $Id$
+ * @see org.apache.solr.handler.dataimport.MailEntityProcessor
+ * @since solr 1.4
+ */
+public class TestMailEntityProcessor extends AbstractDataImportHandlerTestCase {
+
+  // Credentials
+  private static final String user = "user";
+  private static final String password = "password";
+  private static final String host = "host";
+  private static final String protocol = "imaps";
+
+  private static Map<String, String> paramMap = new HashMap<String, String>();
+
+  @Test
+  @Ignore("Needs a Mock Mail Server to work")
+  public void testConnection() {
+    // also tests recurse = false and default settings
+    paramMap.put("folders", "top2");
+    paramMap.put("recurse", "false");
+    paramMap.put("processAttachement", "false");
+    DataImporter di = new DataImporter();
+    di.loadAndInit(getConfigFromMap(paramMap));
+    DataConfig.Entity ent = di.getConfig().document.entities.get(0);
+    ent.isDocRoot = true;
+    DataImporter.RequestParams rp = new DataImporter.RequestParams();
+    rp.command = "full-import";
+    SolrWriterImpl swi = new SolrWriterImpl();
+    di.runCmd(rp, swi);
+    assertEquals("top1 did not return 2 messages", swi.docs.size(), 2);
+  }
+
+  @Test
+  @Ignore("Needs a Mock Mail Server to work")
+  public void testRecursion() {
+    paramMap.put("folders", "top2");
+    paramMap.put("recurse", "true");
+    paramMap.put("processAttachement", "false");
+    DataImporter di = new DataImporter();
+    di.loadAndInit(getConfigFromMap(paramMap));
+    DataConfig.Entity ent = di.getConfig().document.entities.get(0);
+    ent.isDocRoot = true;
+    DataImporter.RequestParams rp = new DataImporter.RequestParams();
+    rp.command = "full-import";
+    SolrWriterImpl swi = new SolrWriterImpl();
+    di.runCmd(rp, swi);
+    assertEquals("top2 and its children did not return 8 messages", swi.docs.size(), 8);
+  }
+
+  @Test
+  @Ignore("Needs a Mock Mail Server to work")
+  public void testExclude() {
+    paramMap.put("folders", "top2");
+    paramMap.put("recurse", "true");
+    paramMap.put("processAttachement", "false");
+    paramMap.put("exclude", ".*grandchild.*");
+    DataImporter di = new DataImporter();
+    di.loadAndInit(getConfigFromMap(paramMap));
+    DataConfig.Entity ent = di.getConfig().document.entities.get(0);
+    ent.isDocRoot = true;
+    DataImporter.RequestParams rp = new DataImporter.RequestParams();
+    rp.command = "full-import";
+    SolrWriterImpl swi = new SolrWriterImpl();
+    di.runCmd(rp, swi);
+    assertEquals("top2 and its direct children did not return 5 messages", swi.docs.size(), 5);
+  }
+
+  @Test
+  @Ignore("Needs a Mock Mail Server to work")
+  public void testInclude() {
+    paramMap.put("folders", "top2");
+    paramMap.put("recurse", "true");
+    paramMap.put("processAttachement", "false");
+    paramMap.put("include", ".*grandchild.*");
+    DataImporter di = new DataImporter();
+    di.loadAndInit(getConfigFromMap(paramMap));
+    DataConfig.Entity ent = di.getConfig().document.entities.get(0);
+    ent.isDocRoot = true;
+    DataImporter.RequestParams rp = new DataImporter.RequestParams();
+    rp.command = "full-import";
+    SolrWriterImpl swi = new SolrWriterImpl();
+    di.runCmd(rp, swi);
+    assertEquals("top2 and its direct children did not return 3 messages", swi.docs.size(), 3);
+  }
+
+  @Test
+  @Ignore("Needs a Mock Mail Server to work")
+  public void testIncludeAndExclude() {
+    paramMap.put("folders", "top1,top2");
+    paramMap.put("recurse", "true");
+    paramMap.put("processAttachement", "false");
+    paramMap.put("exclude", ".*top1.*");
+    paramMap.put("include", ".*grandchild.*");
+    DataImporter di = new DataImporter();
+    di.loadAndInit(getConfigFromMap(paramMap));
+    DataConfig.Entity ent = di.getConfig().document.entities.get(0);
+    ent.isDocRoot = true;
+    DataImporter.RequestParams rp = new DataImporter.RequestParams();
+    rp.command = "full-import";
+    SolrWriterImpl swi = new SolrWriterImpl();
+    di.runCmd(rp, swi);
+    assertEquals("top2 and its direct children did not return 3 messages", swi.docs.size(), 3);
+  }
+
+  @Test
+  @Ignore("Needs a Mock Mail Server to work")
+  public void testFetchTimeSince() throws ParseException {
+    paramMap.put("folders", "top1/child11");
+    paramMap.put("recurse", "true");
+    paramMap.put("processAttachement", "false");
+    paramMap.put("fetchMailsSince", "2008-12-26 00:00:00");
+    DataImporter di = new DataImporter();
+    di.loadAndInit(getConfigFromMap(paramMap));
+    DataConfig.Entity ent = di.getConfig().document.entities.get(0);
+    ent.isDocRoot = true;
+    DataImporter.RequestParams rp = new DataImporter.RequestParams();
+    rp.command = "full-import";
+    SolrWriterImpl swi = new SolrWriterImpl();
+    di.runCmd(rp, swi);
+    assertEquals("top2 and its direct children did not return 3 messages", swi.docs.size(), 3);
+  }
+
+  private String getConfigFromMap(Map<String, String> params) {
+    String conf =
+            "<dataConfig>" +
+                    "<document>" +
+                    "<entity processor=\"org.apache.solr.handler.dataimport.MailEntityProcessor\" " +
+                    "someconfig" +
+                    "/>" +
+                    "</document>" +
+                    "</dataConfig>";
+    params.put("user", user);
+    params.put("password", password);
+    params.put("host", host);
+    params.put("protocol", protocol);
+    StringBuilder attribs = new StringBuilder("");
+    for (String key : params.keySet())
+      attribs.append(" ").append(key).append("=" + "\"").append(params.get(key)).append("\"");
+    attribs.append(" ");
+    return conf.replace("someconfig", attribs.toString());
+  }
+
+  static class SolrWriterImpl extends SolrWriter {
+    List<SolrInputDocument> docs = new ArrayList<SolrInputDocument>();
+    Boolean deleteAllCalled;
+    Boolean commitCalled;
+
+    public SolrWriterImpl() {
+      super(null, ".", null);
+    }
+
+    @Override
+    public boolean upload(SolrInputDocument doc) {
+      return docs.add(doc);
+    }
+
+    @Override
+    public void log(int event, String name, Object row) {
+      // Do nothing
+    }
+
+    @Override
+    public void doDeleteAll() {
+      deleteAllCalled = Boolean.TRUE;
+    }
+
+    @Override
+    public void commit(boolean b) {
+      commitCalled = Boolean.TRUE;
+    }
+  }
+}
diff --git a/solr/contrib/dataimporthandler-extras/src/test/java/org/apache/solr/handler/dataimport/TestTikaEntityProcessor.java b/solr/contrib/dataimporthandler-extras/src/test/java/org/apache/solr/handler/dataimport/TestTikaEntityProcessor.java
new file mode 100644
index 0000000..019fa85
--- /dev/null
+++ b/solr/contrib/dataimporthandler-extras/src/test/java/org/apache/solr/handler/dataimport/TestTikaEntityProcessor.java
@@ -0,0 +1,53 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.solr.handler.dataimport;
+
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+/**Testcase for TikaEntityProcessor
+ * @version $Id$
+ * @since solr 1.5 
+ */
+public class TestTikaEntityProcessor extends AbstractDataImportHandlerTestCase {
+  @BeforeClass
+  public static void beforeClass() throws Exception {
+    initCore("dataimport-solrconfig.xml", "dataimport-schema-no-unique-key.xml", getFile("solr-dihextras").getAbsolutePath());
+  }
+
+  @Test
+  public void testIndexingWithTikaEntityProcessor() throws Exception {
+    String conf =
+            "<dataConfig>" +
+                    "  <dataSource type=\"BinFileDataSource\"/>" +
+                    "  <document>" +
+                    "    <entity processor=\"TikaEntityProcessor\" url=\"" + getFile("solr-word.pdf").getAbsolutePath() + "\" >" +
+                    "      <field column=\"Author\" meta=\"true\" name=\"author\"/>" +
+                    "      <field column=\"title\" meta=\"true\" name=\"title\"/>" +
+                    "      <field column=\"text\"/>" +
+                    "     </entity>" +
+                    "  </document>" +
+                    "</dataConfig>";
+    runFullImport(conf);
+    assertQ(req("*:*")
+            ,"//*[@numFound='1']"
+            ,"//str[@name='author'][.='Grant Ingersoll']"
+            ,"//str[@name='title'][.='solr-word']"
+            ,"//str[@name='text']"
+            );
+  }
+}
diff --git a/solr/contrib/dataimporthandler-extras/src/test/resources/solr-dihextras/conf/dataimport-schema-no-unique-key.xml b/solr/contrib/dataimporthandler-extras/src/test/resources/solr-dihextras/conf/dataimport-schema-no-unique-key.xml
new file mode 100644
index 0000000..b1ec8be
--- /dev/null
+++ b/solr/contrib/dataimporthandler-extras/src/test/resources/solr-dihextras/conf/dataimport-schema-no-unique-key.xml
@@ -0,0 +1,205 @@
+<?xml version="1.0" encoding="UTF-8" ?>
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+
+<!--  
+ This is the Solr schema file. This file should be named "schema.xml" and
+ should be in the conf directory under the solr home
+ (i.e. ./solr/conf/schema.xml by default) 
+ or located where the classloader for the Solr webapp can find it.
+
+ This example schema is the recommended starting point for users.
+ It should be kept correct and concise, usable out-of-the-box.
+
+ For more information, on how to customize this file, please see
+ http://wiki.apache.org/solr/SchemaXml
+-->
+
+<schema name="test" version="1.2">
+  <!-- attribute "name" is the name of this schema and is only used for display purposes.
+       Applications should change this to reflect the nature of the search collection.
+       version="1.1" is Solr's version number for the schema syntax and semantics.  It should
+       not normally be changed by applications.
+       1.0: multiValued attribute did not exist, all fields are multiValued by nature
+       1.1: multiValued attribute introduced, false by default -->
+
+  <types>
+    <!-- field type definitions. The "name" attribute is
+       just a label to be used by field definitions.  The "class"
+       attribute and any other attributes determine the real
+       behavior of the fieldType.
+         Class names starting with "solr" refer to java classes in the
+       org.apache.solr.analysis package.
+    -->
+
+    <!-- The StrField type is not analyzed, but indexed/stored verbatim.  
+       - StrField and TextField support an optional compressThreshold which
+       limits compression (if enabled in the derived fields) to values which
+       exceed a certain size (in characters).
+    -->
+    <fieldType name="string" class="solr.StrField" sortMissingLast="true" omitNorms="true"/>
+
+    <!-- boolean type: "true" or "false" -->
+    <fieldType name="boolean" class="solr.BoolField" sortMissingLast="true" omitNorms="true"/>
+
+    <!-- The optional sortMissingLast and sortMissingFirst attributes are
+         currently supported on types that are sorted internally as strings.
+       - If sortMissingLast="true", then a sort on this field will cause documents
+         without the field to come after documents with the field,
+         regardless of the requested sort order (asc or desc).
+       - If sortMissingFirst="true", then a sort on this field will cause documents
+         without the field to come before documents with the field,
+         regardless of the requested sort order.
+       - If sortMissingLast="false" and sortMissingFirst="false" (the default),
+         then default lucene sorting will be used which places docs without the
+         field first in an ascending sort and last in a descending sort.
+    -->    
+
+
+    <!-- numeric field types that store and index the text
+         value verbatim (and hence don't support range queries, since the
+         lexicographic ordering isn't equal to the numeric ordering) -->
+    <fieldType name="integer" class="solr.IntField" omitNorms="true"/>
+    <fieldType name="long" class="solr.LongField" omitNorms="true"/>
+    <fieldType name="float" class="solr.FloatField" omitNorms="true"/>
+    <fieldType name="double" class="solr.DoubleField" omitNorms="true"/>
+
+
+    <!-- Numeric field types that manipulate the value into
+         a string value that isn't human-readable in its internal form,
+         but with a lexicographic ordering the same as the numeric ordering,
+         so that range queries work correctly. -->
+    <fieldType name="sint" class="solr.SortableIntField" sortMissingLast="true" omitNorms="true"/>
+    <fieldType name="slong" class="solr.SortableLongField" sortMissingLast="true" omitNorms="true"/>
+    <fieldType name="sfloat" class="solr.SortableFloatField" sortMissingLast="true" omitNorms="true"/>
+    <fieldType name="sdouble" class="solr.SortableDoubleField" sortMissingLast="true" omitNorms="true"/>
+
+
+    <!-- The format for this date field is of the form 1995-12-31T23:59:59Z, and
+         is a more restricted form of the canonical representation of dateTime
+         http://www.w3.org/TR/xmlschema-2/#dateTime    
+         The trailing "Z" designates UTC time and is mandatory.
+         Optional fractional seconds are allowed: 1995-12-31T23:59:59.999Z
+         All other components are mandatory.
+
+         Expressions can also be used to denote calculations that should be
+         performed relative to "NOW" to determine the value, ie...
+
+               NOW/HOUR
+                  ... Round to the start of the current hour
+               NOW-1DAY
+                  ... Exactly 1 day prior to now
+               NOW/DAY+6MONTHS+3DAYS
+                  ... 6 months and 3 days in the future from the start of
+                      the current day
+                      
+         Consult the DateField javadocs for more information.
+      -->
+    <fieldType name="date" class="solr.DateField" sortMissingLast="true" omitNorms="true"/>
+
+
+    <!-- The "RandomSortField" is not used to store or search any
+         data.  You can declare fields of this type it in your schema
+         to generate psuedo-random orderings of your docs for sorting 
+         purposes.  The ordering is generated based on the field name 
+         and the version of the index, As long as the index version
+         remains unchanged, and the same field name is reused,
+         the ordering of the docs will be consistent.  
+         If you want differend psuedo-random orderings of documents,
+         for the same version of the index, use a dynamicField and
+         change the name
+     -->
+    <fieldType name="random" class="solr.RandomSortField" indexed="true" />
+
+    <!-- solr.TextField allows the specification of custom text analyzers
+         specified as a tokenizer and a list of token filters. Different
+         analyzers may be specified for indexing and querying.
+
+         The optional positionIncrementGap puts space between multiple fields of
+         this type on the same document, with the purpose of preventing false phrase
+         matching across fields.
+
+         For more info on customizing your analyzer chain, please see
+         http://wiki.apache.org/solr/AnalyzersTokenizersTokenFilters
+     -->
+
+    <!-- One can also specify an existing Analyzer class that has a
+         default constructor via the class attribute on the analyzer element
+    <fieldType name="text_greek" class="solr.TextField">
+      <analyzer class="org.apache.lucene.analysis.el.GreekAnalyzer"/>
+    </fieldType>
+    -->
+
+    <!-- A text field that only splits on whitespace for exact matching of words -->
+    <fieldType name="text_ws" class="solr.TextField" positionIncrementGap="100">
+      <analyzer>
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+      </analyzer>
+    </fieldType>
+
+    <!-- A text field that uses WordDelimiterFilter to enable splitting and matching of
+        words on case-change, alpha numeric boundaries, and non-alphanumeric chars,
+        so that a query of "wifi" or "wi fi" could match a document containing "Wi-Fi".
+        Synonyms and stopwords are customized by external files, and stemming is enabled.
+        Duplicate tokens at the same position (which may result from Stemmed Synonyms or
+        WordDelim parts) are removed.
+        -->
+    <fieldType name="text" class="solr.TextField" positionIncrementGap="100">
+      <analyzer type="index">
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+        <!-- in this example, we will only use synonyms at query time
+        <filter class="solr.SynonymFilterFactory" synonyms="index_synonyms.txt" ignoreCase="true" expand="false"/>
+        -->
+        <!--<filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt"/>-->
+        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="1" catenateNumbers="1" catenateAll="0" splitOnCaseChange="1"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <!--<filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
+        <filter class="solr.PorterStemFilterFactory"/>-->
+        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
+      </analyzer>
+      <analyzer type="query">
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+        <!--<filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt" ignoreCase="true" expand="true"/>-->
+        <!--<filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt"/>-->
+        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="0" catenateNumbers="0" catenateAll="0" splitOnCaseChange="1"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <!--<filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
+        <filter class="solr.PorterStemFilterFactory"/>-->
+        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
+      </analyzer>
+    </fieldType>
+    <!-- since fields of this type are by default not stored or indexed, any data added to 
+         them will be ignored outright 
+     --> 
+    <fieldtype name="ignored" stored="false" indexed="false" class="solr.StrField" /> 
+
+ </types>
+
+
+ <fields>
+   <field name="title" type="string" indexed="true" stored="true"/>
+   <field name="author" type="string" indexed="true" stored="true" />
+   <field name="text" type="text" indexed="true" stored="true" />
+   
+ </fields>
+ <!-- field for the QueryParser to use when an explicit fieldname is absent -->
+ <defaultSearchField>text</defaultSearchField>
+
+ <!-- SolrQueryParser configuration: defaultOperator="AND|OR" -->
+ <solrQueryParser defaultOperator="OR"/>
+
+</schema>
diff --git a/solr/contrib/dataimporthandler-extras/src/test/resources/solr-dihextras/conf/dataimport-solrconfig.xml b/solr/contrib/dataimporthandler-extras/src/test/resources/solr-dihextras/conf/dataimport-solrconfig.xml
new file mode 100644
index 0000000..9f41933
--- /dev/null
+++ b/solr/contrib/dataimporthandler-extras/src/test/resources/solr-dihextras/conf/dataimport-solrconfig.xml
@@ -0,0 +1,397 @@
+<?xml version="1.0" encoding="UTF-8" ?>
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+
+<config>
+  <luceneMatchVersion>${tests.luceneMatchVersion:LUCENE_CURRENT}</luceneMatchVersion>
+
+  <!-- Used to specify an alternate directory to hold all index data
+       other than the default ./data under the Solr home.
+       If replication is in use, this should match the replication configuration. -->
+       <dataDir>${solr.data.dir:}</dataDir>
+
+
+  <indexDefaults>
+   <!-- Values here affect all index writers and act as a default unless overridden. -->
+    <useCompoundFile>false</useCompoundFile>
+
+    <mergeFactor>10</mergeFactor>
+    <!--
+     If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
+
+     -->
+    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
+    <!-- Tell Lucene when to flush documents to disk.
+    Giving Lucene more memory for indexing means faster indexing at the cost of more RAM
+
+    If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
+
+    -->
+    <ramBufferSizeMB>32</ramBufferSizeMB>
+    <maxMergeDocs>2147483647</maxMergeDocs>
+    <maxFieldLength>10000</maxFieldLength>
+    <writeLockTimeout>1000</writeLockTimeout>
+    <commitLockTimeout>10000</commitLockTimeout>
+
+    <!--
+     Expert: Turn on Lucene's auto commit capability.
+
+     TODO: Add recommendations on why you would want to do this.
+
+     NOTE: Despite the name, this value does not have any relation to Solr's autoCommit functionality
+
+     -->
+    <!--<luceneAutoCommit>false</luceneAutoCommit>-->
+    <!--
+     Expert:
+     The Merge Policy in Lucene controls how merging is handled by Lucene.  The default in 2.3 is the LogByteSizeMergePolicy, previous
+     versions used LogDocMergePolicy.
+
+     LogByteSizeMergePolicy chooses segments to merge based on their size.  The Lucene 2.2 default, LogDocMergePolicy chose when
+     to merge based on number of documents
+
+     Other implementations of MergePolicy must have a no-argument constructor
+     -->
+    <!--<mergePolicy>org.apache.lucene.index.LogByteSizeMergePolicy</mergePolicy>-->
+
+    <!--
+     Expert:
+     The Merge Scheduler in Lucene controls how merges are performed.  The ConcurrentMergeScheduler (Lucene 2.3 default)
+      can perform merges in the background using separate threads.  The SerialMergeScheduler (Lucene 2.2 default) does not.
+     -->
+    <!--<mergeScheduler>org.apache.lucene.index.ConcurrentMergeScheduler</mergeScheduler>-->
+
+    <!--
+      As long as Solr is the only process modifying your index, it is
+      safe to use Lucene's in process locking mechanism.  But you may
+      specify one of the other Lucene LockFactory implementations in
+      the event that you have a custom situation.
+      
+      none = NoLockFactory (typically only used with read only indexes)
+      single = SingleInstanceLockFactory (suggested)
+      native = NativeFSLockFactory
+      simple = SimpleFSLockFactory
+
+      ('simple' is the default for backwards compatibility with Solr 1.2)
+    -->
+    <lockType>single</lockType>
+  </indexDefaults>
+
+  <mainIndex>
+    <!-- options specific to the main on-disk lucene index -->
+    <useCompoundFile>false</useCompoundFile>
+    <ramBufferSizeMB>32</ramBufferSizeMB>
+    <mergeFactor>10</mergeFactor>
+    <!-- Deprecated -->
+    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
+    <maxMergeDocs>2147483647</maxMergeDocs>
+    <maxFieldLength>10000</maxFieldLength>
+
+    <!-- If true, unlock any held write or commit locks on startup. 
+         This defeats the locking mechanism that allows multiple
+         processes to safely access a lucene index, and should be
+         used with care.
+         This is not needed if lock type is 'none' or 'single'
+     -->
+    <unlockOnStartup>false</unlockOnStartup>
+  </mainIndex>
+
+  <!-- the default high-performance update handler -->
+  <updateHandler class="solr.DirectUpdateHandler2">
+
+    <!-- A prefix of "solr." for class names is an alias that
+         causes solr to search appropriate packages, including
+         org.apache.solr.(search|update|request|core|analysis)
+     -->
+
+    <!-- Limit the number of deletions Solr will buffer during doc updating.
+        
+        Setting this lower can help bound memory use during indexing.
+    -->
+    <maxPendingDeletes>100000</maxPendingDeletes>
+
+  </updateHandler>
+
+
+  <query>
+    <!-- Maximum number of clauses in a boolean query... can affect
+        range or prefix queries that expand to big boolean
+        queries.  An exception is thrown if exceeded.  -->
+    <maxBooleanClauses>1024</maxBooleanClauses>
+
+    
+    <!-- Cache used by SolrIndexSearcher for filters (DocSets),
+         unordered sets of *all* documents that match a query.
+         When a new searcher is opened, its caches may be prepopulated
+         or "autowarmed" using data from caches in the old searcher.
+         autowarmCount is the number of items to prepopulate.  For LRUCache,
+         the autowarmed items will be the most recently accessed items.
+       Parameters:
+         class - the SolrCache implementation (currently only LRUCache)
+         size - the maximum number of entries in the cache
+         initialSize - the initial capacity (number of entries) of
+           the cache.  (seel java.util.HashMap)
+         autowarmCount - the number of entries to prepopulate from
+           and old cache.
+         -->
+    <filterCache
+      class="solr.LRUCache"
+      size="512"
+      initialSize="512"
+      autowarmCount="256"/>
+
+   <!-- queryResultCache caches results of searches - ordered lists of
+         document ids (DocList) based on a query, a sort, and the range
+         of documents requested.  -->
+    <queryResultCache
+      class="solr.LRUCache"
+      size="512"
+      initialSize="512"
+      autowarmCount="256"/>
+
+  <!-- documentCache caches Lucene Document objects (the stored fields for each document).
+       Since Lucene internal document ids are transient, this cache will not be autowarmed.  -->
+    <documentCache
+      class="solr.LRUCache"
+      size="512"
+      initialSize="512"
+      autowarmCount="0"/>
+
+    <!-- If true, stored fields that are not requested will be loaded lazily.
+
+    This can result in a significant speed improvement if the usual case is to
+    not load all stored fields, especially if the skipped fields are large compressed
+    text fields.
+    -->
+    <enableLazyFieldLoading>true</enableLazyFieldLoading>
+
+    <!-- Example of a generic cache.  These caches may be accessed by name
+         through SolrIndexSearcher.getCache(),cacheLookup(), and cacheInsert().
+         The purpose is to enable easy caching of user/application level data.
+         The regenerator argument should be specified as an implementation
+         of solr.search.CacheRegenerator if autowarming is desired.  -->
+    <!--
+    <cache name="myUserCache"
+      class="solr.LRUCache"
+      size="4096"
+      initialSize="1024"
+      autowarmCount="1024"
+      regenerator="org.mycompany.mypackage.MyRegenerator"
+      />
+    -->
+
+   <!-- An optimization that attempts to use a filter to satisfy a search.
+         If the requested sort does not include score, then the filterCache
+         will be checked for a filter matching the query. If found, the filter
+         will be used as the source of document ids, and then the sort will be
+         applied to that.
+    <useFilterForSortedQuery>true</useFilterForSortedQuery>
+   -->
+
+   <!-- An optimization for use with the queryResultCache.  When a search
+         is requested, a superset of the requested number of document ids
+         are collected.  For example, if a search for a particular query
+         requests matching documents 10 through 19, and queryWindowSize is 50,
+         then documents 0 through 49 will be collected and cached.  Any further
+         requests in that range can be satisfied via the cache.  -->
+    <queryResultWindowSize>50</queryResultWindowSize>
+    
+    <!-- Maximum number of documents to cache for any entry in the
+         queryResultCache. -->
+    <queryResultMaxDocsCached>200</queryResultMaxDocsCached>
+
+    <!-- This entry enables an int hash representation for filters (DocSets)
+         when the number of items in the set is less than maxSize.  For smaller
+         sets, this representation is more memory efficient, more efficient to
+         iterate over, and faster to take intersections.  -->
+    <HashDocSet maxSize="3000" loadFactor="0.75"/>
+
+    <!-- a newSearcher event is fired whenever a new searcher is being prepared
+         and there is a current searcher handling requests (aka registered). -->
+    <!-- QuerySenderListener takes an array of NamedList and executes a
+         local query request for each NamedList in sequence. -->
+    <listener event="newSearcher" class="solr.QuerySenderListener">
+      <arr name="queries">
+        <lst> <str name="q">solr</str> <str name="start">0</str> <str name="rows">10</str> </lst>
+        <lst> <str name="q">rocks</str> <str name="start">0</str> <str name="rows">10</str> </lst>
+        <lst><str name="q">static newSearcher warming query from solrconfig.xml</str></lst>
+      </arr>
+    </listener>
+
+    <!-- a firstSearcher event is fired whenever a new searcher is being
+         prepared but there is no current registered searcher to handle
+         requests or to gain autowarming data from. -->
+    <listener event="firstSearcher" class="solr.QuerySenderListener">
+      <arr name="queries">
+      </arr>
+    </listener>
+
+    <!-- If a search request comes in and there is no current registered searcher,
+         then immediately register the still warming searcher and use it.  If
+         "false" then all requests will block until the first searcher is done
+         warming. -->
+    <useColdSearcher>false</useColdSearcher>
+
+    <!-- Maximum number of searchers that may be warming in the background
+      concurrently.  An error is returned if this limit is exceeded. Recommend
+      1-2 for read-only slaves, higher for masters w/o cache warming. -->
+    <maxWarmingSearchers>4</maxWarmingSearchers>
+
+  </query>
+
+  <!-- 
+    Let the dispatch filter handler /select?qt=XXX
+    handleSelect=true will use consistent error handling for /select and /update
+    handleSelect=false will use solr1.1 style error formatting
+    -->
+  <requestDispatcher handleSelect="true" >
+    <!--Make sure your system has some authentication before enabling remote streaming!  -->
+    <requestParsers enableRemoteStreaming="false" multipartUploadLimitInKB="2048" />
+        
+    <!-- Set HTTP caching related parameters (for proxy caches and clients).
+          
+         To get the behaviour of Solr 1.2 (ie: no caching related headers)
+         use the never304="true" option and do not specify a value for
+         <cacheControl>
+    -->
+    <httpCaching never304="true">
+    <!--httpCaching lastModifiedFrom="openTime"
+                 etagSeed="Solr"-->
+       <!-- lastModFrom="openTime" is the default, the Last-Modified value
+            (and validation against If-Modified-Since requests) will all be
+            relative to when the current Searcher was opened.
+            You can change it to lastModFrom="dirLastMod" if you want the
+            value to exactly corrispond to when the physical index was last
+            modified.
+               
+            etagSeed="..." is an option you can change to force the ETag
+            header (and validation against If-None-Match requests) to be
+            differnet even if the index has not changed (ie: when making
+            significant changes to your config file)
+
+            lastModifiedFrom and etagSeed are both ignored if you use the
+            never304="true" option.
+       -->
+       <!-- If you include a <cacheControl> directive, it will be used to
+            generate a Cache-Control header, as well as an Expires header
+            if the value contains "max-age="
+               
+            By default, no Cache-Control header is generated.
+
+            You can use the <cacheControl> option even if you have set
+            never304="true"
+       -->
+       <!-- <cacheControl>max-age=30, public</cacheControl> -->
+    </httpCaching>
+  </requestDispatcher>
+  
+      
+  <!-- requestHandler plugins... incoming queries will be dispatched to the
+     correct handler based on the path or the qt (query type) param.
+     Names starting with a '/' are accessed with the a path equal to the 
+     registered name.  Names without a leading '/' are accessed with:
+      http://host/app/select?qt=name
+     If no qt is defined, the requestHandler that declares default="true"
+     will be used.
+  -->
+  <requestHandler name="standard" class="solr.StandardRequestHandler" default="true">
+    <!-- default values for query parameters -->
+     <lst name="defaults">
+       <str name="echoParams">explicit</str>
+       <!-- 
+       <int name="rows">10</int>
+       <str name="fl">*</str>
+       <str name="version">2.1</str>
+        -->
+     </lst>
+  </requestHandler>
+  
+  <requestHandler name="/dataimport" class="org.apache.solr.handler.dataimport.DataImportHandler">
+  </requestHandler>
+    
+  <!--
+   
+   Search components are registered to SolrCore and used by Search Handlers
+   
+   By default, the following components are avaliable:
+    
+   <searchComponent name="query"     class="org.apache.solr.handler.component.QueryComponent" />
+   <searchComponent name="facet"     class="org.apache.solr.handler.component.FacetComponent" />
+   <searchComponent name="mlt"       class="org.apache.solr.handler.component.MoreLikeThisComponent" />
+   <searchComponent name="highlight" class="org.apache.solr.handler.component.HighlightComponent" />
+   <searchComponent name="debug"     class="org.apache.solr.handler.component.DebugComponent" />
+  
+   If you register a searchComponent to one of the standard names, that will be used instead.
+  
+   -->
+ 
+  <requestHandler name="/search" class="org.apache.solr.handler.component.SearchHandler">
+    <lst name="defaults">
+      <str name="echoParams">explicit</str>
+    </lst>
+    <!--
+    By default, this will register the following components:
+    
+    <arr name="components">
+      <str>query</str>
+      <str>facet</str>
+      <str>mlt</str>
+      <str>highlight</str>
+      <str>debug</str>
+    </arr>
+    
+    To insert handlers before or after the 'standard' components, use:
+    
+    <arr name="first-components">
+      <str>first</str>
+    </arr>
+    
+    <arr name="last-components">
+      <str>last</str>
+    </arr>
+    
+    -->
+  </requestHandler>
+  
+  <!-- Update request handler.  
+  
+       Note: Since solr1.1 requestHandlers requires a valid content type header if posted in 
+       the body. For example, curl now requires: -H 'Content-type:text/xml; charset=utf-8'
+       The response format differs from solr1.1 formatting and returns a standard error code.
+       
+       To enable solr1.1 behavior, remove the /update handler or change its path
+       
+       "update.processor.class" is the class name for the UpdateRequestProcessor.  It is initalized
+       only once.  This can not be changed for each request.
+    -->
+  <requestHandler name="/update" class="solr.XmlUpdateRequestHandler" >
+    <!--
+    <str name="update.processor.class">org.apache.solr.handler.UpdateRequestProcessor</str>
+    -->
+  </requestHandler>
+  
+  <!-- config for the admin interface --> 
+  <admin>
+    <defaultQuery>*:*</defaultQuery>
+    
+    <!-- configure a healthcheck file for servers behind a loadbalancer
+    <healthcheck type="file">server-enabled</healthcheck>
+    -->
+  </admin>
+
+</config>
+
diff --git a/solr/contrib/dataimporthandler-extras/src/test/resources/solr-word.pdf b/solr/contrib/dataimporthandler-extras/src/test/resources/solr-word.pdf
new file mode 100644
index 0000000..bd8b865
--- /dev/null
+++ b/solr/contrib/dataimporthandler-extras/src/test/resources/solr-word.pdf
@@ -0,0 +1,2 @@
+This is a test of PDF and Word extraction in Solr, it is only a test. Do not panic.
+
\ No newline at end of file
diff --git a/solr/contrib/dataimporthandler/build.xml b/solr/contrib/dataimporthandler/build.xml
index 5b9ddc1..bdb0cd5 100644
--- a/solr/contrib/dataimporthandler/build.xml
+++ b/solr/contrib/dataimporthandler/build.xml
@@ -17,295 +17,16 @@
     limitations under the License.
  -->
 
-<project name="solr-dataimporthandler" default="build">
+<project name="solr-dataimporthandler" default="default">
 	
-  <property name="solr-path" value="../.." />
-  <property name="tikalibs-path" value="../extraction/lib" />
-
-  <import file="../../common-build.xml"/>
-  
   <description>
     Data Import Handler
   </description>
-  <path id="classpath.jetty">
-    <!-- jetty -->
-    <fileset dir="${solr-path}/example/lib">
-      <include name="**/*.jar" />
-    </fileset>
-  </path>
-  <path id="common.classpath">
-  	<pathelement location="${solr-path}/build/solr" />
-  	<pathelement location="${solr-path}/build/solrj" />
-  	<fileset dir="${solr-path}/lib" includes="*.jar"/>
-    <path refid="lucene.classpath"/>
-  </path>
-
-  <path id="extras.classpath">
-  	<pathelement location="${solr-path}/build/solr" />
-  	<pathelement location="${solr-path}/build/solrj" />
-  	<pathelement location="target/classes" />
-  	<fileset dir="${solr-path}/lib" includes="*.jar"/>
-  	<fileset dir="lib/" includes="*.jar"/>
-  	<fileset dir="${tikalibs-path}" includes="*.jar"/>
-    <path refid="lucene.classpath"/>
-  </path>
-	
-  <path id="test.classpath">
-  	<path refid="common.classpath" />
-  	<path refid="classpath.jetty" />
-	  <pathelement path="target/classes" />
-  	<pathelement path="target/test-classes" />
-    <pathelement location="${solr-path}/build/tests"/> <!-- include solr test code -->
-    <pathelement location="${solr-path}/../lucene/build/classes/test-framework" />  <!-- include some lucene test code -->
-    <pathelement path="${java.class.path}"/>
-  </path>
-
-  <path id="test.extras.classpath">
-  	<path refid="extras.classpath" />
-  	<path refid="classpath.jetty" />
-	  <pathelement path="target/classes" />
-	  <pathelement path="target/extras/classes" />
-  	<pathelement path="target/test-classes" />
-  	<pathelement path="target/extras/test-classes" />
-    <pathelement location="${solr-path}/build/tests"/> <!-- include solr test code -->
-    <pathelement location="${solr-path}/../lucene/build/classes/test-framework" />  <!-- include some lucene test code -->
-    <pathelement path="${java.class.path}"/>
-  </path>
-	
-  <target name="clean">
-  	<delete failonerror="false" dir="target"/>
-    <delete failonerror="false">
-      <fileset dir="src/test/resources" includes="**/dataimport.properties" />
-    </delete>
-    <!-- Clean up examples -->
-    <delete failonerror="false">
-      <!-- we no longer copy things into this directory, but we still clean it up
-           the files are still there from a previous checkout
-        -->
-      <fileset dir="${example}/example-DIH/solr/mail/lib" includes="*.jar" />
-    </delete>
-  </target>
-	
-  <target name="init">
-  	<mkdir dir="target/classes"/>
-    <mkdir dir="${build.javadoc}" />
-    <subant target="compileTests">
-      <fileset dir="${solr-path}" includes="build.xml"/>
-    </subant>
-    <subant target="make-manifest">
-      <fileset dir="${solr-path}" includes="build.xml"/>
-    </subant>
-  </target>
-	
-  <target name="compile" depends="init">
-    <solr-javac destdir="target/classes"
-                classpathref="common.classpath">
-      <src path="src/main/java" />
-    </solr-javac>
-  </target>
-
-  <target name="compileExtras" depends="compile">
-    <solr-javac destdir="target/extras/classes"
-                classpathref="extras.classpath">
-      <src path="src/extras/main/java" />
-    </solr-javac>
-  </target>
-	
-  <target name="build" depends="compile,compileExtras">
-    <solr-jar destfile="target/${fullnamever}.jar" basedir="target/classes"
-              manifest="../../${dest}/META-INF/MANIFEST.MF" />
-    <solr-jar destfile="target/apache-${ant.project.name}-extras-${version}.jar" basedir="target/extras/classes"
-              manifest="../../${dest}/META-INF/MANIFEST.MF" />
-  </target>
-	
-  <target name="compileTests" depends="compile">
-  	<solr-javac destdir="target/test-classes"
-  	                classpathref="test.classpath">
-  	  <src path="src/test/java" />
-  	</solr-javac>
-    <!-- Copy any data files present to the classpath -->
-    <copy todir="target/test-classes">
-      <fileset dir="src/test/resources" excludes="**/*.java"/>
-    </copy>
-  </target>
-
-  <target name="compileExtrasTests" depends="compileExtras">
-  	<solr-javac destdir="target/extras/test-classes"
-  	                classpathref="test.classpath">
-  	  <src path="src/extras/test/java" />
-  	</solr-javac>
-    <!-- Copy any data files present to the classpath -->
-    <copy todir="target/extras/test-classes">
-      <fileset dir="src/extras/test/resources" excludes="**/*.java"/>
-    </copy>
-  </target>
-
-  <property name="tempDir" value="${junit.output.dir}/temp" />
-  <target  name="test" depends="testCore,testExtras"/>
-	
-  <target name="testCore" depends="compileTests">
-  	<mkdir dir="${junit.output.dir}"/>
-    <!-- <mkdir dir="@{tempDir}/@{pattern}"/> 
-       This is very loud and obnoxious. abuse touch instead for a "quiet" mkdir
-    -->
-  	<touch file="${tempDir}/quiet.ant" verbose="false" mkdirs="true"/>
-    <condition property="runall">
-      <not>
-        <or>
-          <isset property="testcase"/>
-          <isset property="testpackage"/>
-          <isset property="testpackageroot"/>
-        </or>
-      </not>
-    </condition>
-    
-  	<junit printsummary="no"
-           haltonfailure="no"
-           maxmemory="512M"
-           errorProperty="tests.failed"
-           failureProperty="tests.failed"
-           dir="${tempDir}"
-           tempdir="${tempDir}"
-           forkmode="perBatch"
-           >
-      <sysproperty key="java.util.logging.config.file" value="${common-solr.dir}/testlogging.properties"/>
-      <sysproperty key="tests.luceneMatchVersion" value="${tests.luceneMatchVersion}"/>
-      <sysproperty key="tests.codec" value="${tests.codec}"/>
-      <sysproperty key="tests.locale" value="${tests.locale}"/>
-      <sysproperty key="tests.timezone" value="${tests.timezone}"/>
-      <sysproperty key="tests.multiplier" value="${tests.multiplier}"/>
-      <sysproperty key="tests.iter" value="${tests.iter}"/>
-      <sysproperty key="tests.seed" value="${tests.seed}"/>
-      <sysproperty key="tests.verbose" value="${tests.verbose}"/>
-      <!-- set whether or not nightly tests should run -->
-      <sysproperty key="tests.nightly" value="${tests.nightly}"/>
-      <sysproperty key="jetty.testMode" value="1"/>
-      <sysproperty key="tempDir" file="${tempDir}"/>
-      <sysproperty key="testmethod" value="${testmethod}"/>
-      <jvmarg line="${args}"/>
-      <formatter classname="${junit.details.formatter}" usefile="false" if="junit.details"/>
-      <classpath refid="test.classpath"/>
-      <formatter type="${junit.formatter}"/>
-      <batchtest fork="yes" todir="${junit.output.dir}" if="runall">
-        <fileset dir="src/test/java" includes="${junit.includes}"/>
-      </batchtest>
-      <batchtest fork="yes" todir="${junit.output.dir}" if="testcase">
-        <fileset dir="src/test/java" includes="**/${testcase}.java"/>
-      </batchtest>
-      <batchtest fork="yes" todir="${junit.output.dir}" if="testpackage">
-        <fileset dir="src/test/java" includes="**/${testpackage}/**/Test*.java,**/${testpackage}/**/*Test.java"/>
-      </batchtest>
-      <batchtest fork="yes" todir="${junit.output.dir}" if="testpackageroot">
-        <fileset dir="src/test/java" includes="**/${testpackageroot}/Test*.java,**/${testpackageroot}/*Test.java"/>
-      </batchtest>
-    </junit>
-
-    <fail if="tests.failed">Tests failed!</fail>
-  </target>
-
-  <target name="testExtras" depends="compileExtrasTests">
-  	<mkdir dir="${junit.output.dir}"/>
-    <!-- <mkdir dir="@{tempDir}/@{pattern}"/> 
-       This is very loud and obnoxious. abuse touch instead for a "quiet" mkdir
-    -->
-  	<touch file="${tempDir}/quiet.ant" verbose="false" mkdirs="true"/>
-
-    <condition property="runall">
-      <not>
-        <or>
-          <isset property="testcase"/>
-          <isset property="testpackage"/>
-          <isset property="testpackageroot"/>
-        </or>
-      </not>
-    </condition>    
-    
-  	<junit printsummary="no"
-           haltonfailure="no"
-           maxmemory="512M"
-           errorProperty="tests.failed"
-           failureProperty="tests.failed"
-           dir="${tempDir}"
-           tempdir="${tempDir}"
-           forkmode="perBatch"
-           >
-      <sysproperty key="java.util.logging.config.file" value="${common-solr.dir}/testlogging.properties"/>
-      <sysproperty key="tests.luceneMatchVersion" value="${tests.luceneMatchVersion}"/>
-      <sysproperty key="tests.codec" value="${tests.codec}"/>
-      <sysproperty key="tests.locale" value="${tests.locale}"/>
-      <sysproperty key="tests.timezone" value="${tests.timezone}"/>
-      <sysproperty key="tests.multiplier" value="${tests.multiplier}"/>
-      <sysproperty key="tests.iter" value="${tests.iter}"/>
-      <sysproperty key="tests.seed" value="${tests.seed}"/>
-      <sysproperty key="tests.verbose" value="${tests.verbose}"/>
-      <!-- set whether or not nightly tests should run -->
-      <sysproperty key="tests.nightly" value="${tests.nightly}"/>
-      <sysproperty key="jetty.testMode" value="1"/>
-      <sysproperty key="tempDir" file="${tempDir}"/>
-      <sysproperty key="testmethod" value="${testmethod}"/>
-      <jvmarg line="${args}"/>
-      <formatter classname="${junit.details.formatter}" usefile="false" if="junit.details"/>
-      <classpath refid="test.extras.classpath"/>
-      <assertions>
-        <enable package="org.apache.lucene"/>
-        <enable package="org.apache.solr"/>
-      </assertions>
-      <formatter type="${junit.formatter}"/>
-  	  
-      <batchtest fork="yes" todir="${junit.output.dir}" if="runall">
-        <fileset dir="src/extras/test/java" includes="${junit.includes}"/>
-      </batchtest>
-      <batchtest fork="yes" todir="${junit.output.dir}" if="testcase">
-        <fileset dir="src/extras/test/java" includes="**/${testcase}.java"/>
-      </batchtest>
-      <batchtest fork="yes" todir="${junit.output.dir}" if="testpackage">
-        <fileset dir="src/extras/test/java" includes="**/${testpackage}/**/Test*.java,**/${testpackage}/**/*Test.java"/>
-      </batchtest>
-      <batchtest fork="yes" todir="${junit.output.dir}" if="testpackageroot">
-        <fileset dir="src/extras/test/java" includes="**/${testpackageroot}/Test*.java,**/${testpackageroot}/*Test.java"/>
-      </batchtest>
-  	  
-  	  
-    </junit>
-
-    <fail if="tests.failed">Tests failed!</fail>
-  </target>
-	
-  <target name="dist" depends="build">
-  	<copy todir="../../build/web">
-  		<fileset dir="src/main/webapp" includes="**" />
-  	</copy>
-  	<mkdir dir="../../build/web/WEB-INF/lib"/>
-  	<!--<copy file="target/${fullnamever}.jar" todir="${solr-path}/build/web/WEB-INF/lib"></copy>-->
-  	<copy file="target/${fullnamever}.jar" todir="${solr-path}/dist"></copy>
-  	<copy file="target/apache-${ant.project.name}-extras-${version}.jar" todir="${solr-path}/dist"></copy>
-  </target>
-	
-  <target name="javadoc">
-   	<sequential>
-      <mkdir dir="${build.javadoc}/contrib-${name}"/>
-
-      <path id="javadoc.classpath">
-        <path refid="common.classpath"/>
-        <path refid="extras.classpath"/>
-      </path>
 
-      <invoke-javadoc
-        destdir="${build.javadoc}/contrib-${name}"
-      	title="${Name} ${version} contrib-${fullnamever} API">
-        <sources>
-          <packageset dir="src/main/java"/>
-          <packageset dir="src/extras/main/java"/>
-        </sources>
-      </invoke-javadoc>
-    </sequential>
-  </target>
+  <property name="src.dir" location="src/main/java"/>
+  <property name="tests.src.dir" location="src/test/java"/>
+  <property name="tests.userdir" location="src/test/resources"/>
 
-  <target name="example" depends="build,dist">
-    <!--
-        this target use to copy libs, but that is no longer needed.
-        now we just depend on dist to ensure the extra's jar exists.
-     -->
-  </target>
+  <import file="../contrib-build.xml"/>
   
 </project>
diff --git a/solr/contrib/dataimporthandler/src/extras/main/java/org/apache/solr/handler/dataimport/MailEntityProcessor.java b/solr/contrib/dataimporthandler/src/extras/main/java/org/apache/solr/handler/dataimport/MailEntityProcessor.java
deleted file mode 100644
index 0231d1e..0000000
--- a/solr/contrib/dataimporthandler/src/extras/main/java/org/apache/solr/handler/dataimport/MailEntityProcessor.java
+++ /dev/null
@@ -1,602 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.solr.handler.dataimport;
-
-import com.sun.mail.imap.IMAPMessage;
-
-import org.apache.tika.config.TikaConfig;
-import org.apache.tika.utils.ParseUtils;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import javax.mail.*;
-import javax.mail.internet.AddressException;
-import javax.mail.internet.ContentType;
-import javax.mail.internet.InternetAddress;
-import javax.mail.internet.MimeMessage;
-import javax.mail.search.AndTerm;
-import javax.mail.search.ComparisonTerm;
-import javax.mail.search.ReceivedDateTerm;
-import javax.mail.search.SearchTerm;
-import java.io.InputStream;
-import java.text.ParseException;
-import java.text.SimpleDateFormat;
-import java.util.*;
-
-/**
- * An {@link EntityProcessor} instance which can index emails along with their attachments from POP3 or IMAP sources. Refer to
- * <a href="http://wiki.apache.org/solr/DataImportHandler">http://wiki.apache.org/solr/DataImportHandler</a> for more
- * details. <b>This API is experimental and subject to change</b>
- *
- * @version $Id$
- * @since solr 1.4
- */
-public class MailEntityProcessor extends EntityProcessorBase {
-
-  public static interface CustomFilter {
-    public SearchTerm getCustomSearch(Folder folder);
-  }
-
-  @Override
-  public void init(Context context) {
-    super.init(context);
-    // set attributes using  XXX getXXXFromContext(attribute, defualtValue);
-    // applies variable resolver and return default if value is not found or null
-    // REQUIRED : connection and folder info
-    user = getStringFromContext("user", null);
-    password = getStringFromContext("password", null);
-    host = getStringFromContext("host", null);
-    protocol = getStringFromContext("protocol", null);
-    folderNames = getStringFromContext("folders", null);
-    // validate
-    if (host == null || protocol == null || user == null || password == null
-            || folderNames == null)
-      throw new DataImportHandlerException(DataImportHandlerException.SEVERE,
-              "'user|password|protocol|host|folders' are required attributes");
-
-    //OPTIONAL : have defaults and are optional
-    recurse = getBoolFromContext("recurse", true);
-    String excludes = getStringFromContext("exclude", "");
-    if (excludes != null && !excludes.trim().equals("")) {
-      exclude = Arrays.asList(excludes.split(","));
-    }
-    String includes = getStringFromContext("include", "");
-    if (includes != null && !includes.trim().equals("")) {
-      include = Arrays.asList(includes.split(","));
-    }
-    batchSize = getIntFromContext("batchSize", 20);
-    customFilter = getStringFromContext("customFilter", "");
-    String s = getStringFromContext("fetchMailsSince", "");
-    if (s != null)
-      try {
-        fetchMailsSince = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").parse(s);
-      } catch (ParseException e) {
-        throw new DataImportHandlerException(DataImportHandlerException.SEVERE, "Invalid value for fetchMailSince: " + s, e);
-      }
-
-    fetchSize = getIntFromContext("fetchSize", 32 * 1024);
-    cTimeout = getIntFromContext("connectTimeout", 30 * 1000);
-    rTimeout = getIntFromContext("readTimeout", 60 * 1000);
-    processAttachment = getBoolFromContext("processAttachement", true);
-
-    logConfig();
-  }
-
-  @Override
-  public Map<String, Object> nextRow() {
-    Message mail;
-    Map<String, Object> row = null;
-    do {
-      // try till there is a valid document or folders get exhausted.
-      // when mail == NULL, it means end of processing
-      mail = getNextMail();
-      if (mail != null)
-        row = getDocumentFromMail(mail);
-    } while (row == null && mail != null);    
-    return row;
-  }
-
-  private Message getNextMail() {
-    if (!connected) {
-      if (!connectToMailBox())
-        return null;
-      connected = true;
-    }
-    if (folderIter == null) {
-      createFilters();
-      folderIter = new FolderIterator(mailbox);
-    }
-    // get next message from the folder
-    // if folder is exhausted get next folder
-    // loop till a valid mail or all folders exhausted.
-    while (msgIter == null || !msgIter.hasNext()) {
-      Folder next = folderIter.hasNext() ? folderIter.next() : null;
-      if (next == null) {
-        return null;
-      }
-      msgIter = new MessageIterator(next, batchSize);
-    }
-    return msgIter.next();
-  }
-
-  private Map<String, Object> getDocumentFromMail(Message mail) {
-    Map<String, Object> row = new HashMap<String, Object>();
-    try {
-      addPartToDocument(mail, row, true);
-      return row;
-    } catch (Exception e) {
-      return null;
-    }
-  }
-
-  public void addPartToDocument(Part part, Map<String, Object> row, boolean outerMost) throws Exception {
-    if (part instanceof Message) {
-      addEnvelopToDocument(part, row);
-    }
-
-    String ct = part.getContentType();
-    ContentType ctype = new ContentType(ct);
-    if (part.isMimeType("multipart/*")) {
-      Multipart mp = (Multipart) part.getContent();
-      int count = mp.getCount();
-      if (part.isMimeType("multipart/alternative"))
-        count = 1;
-      for (int i = 0; i < count; i++)
-        addPartToDocument(mp.getBodyPart(i), row, false);
-    } else if (part.isMimeType("message/rfc822")) {
-      addPartToDocument((Part) part.getContent(), row, false);
-    } else {
-      String disp = part.getDisposition();
-      if (!processAttachment || (disp != null && disp.equalsIgnoreCase(Part.ATTACHMENT)))        return;
-      InputStream is = part.getInputStream();
-      String fileName = part.getFileName();
-      String content = ParseUtils.getStringContent(is, TikaConfig.getDefaultConfig(), ctype.getBaseType().toLowerCase(Locale.ENGLISH));
-      if (disp != null && disp.equalsIgnoreCase(Part.ATTACHMENT)) {
-        if (row.get(ATTACHMENT) == null)
-          row.put(ATTACHMENT, new ArrayList<String>());
-        List<String> contents = (List<String>) row.get(ATTACHMENT);
-        contents.add(content);
-        row.put(ATTACHMENT, contents);
-        if (row.get(ATTACHMENT_NAMES) == null)
-          row.put(ATTACHMENT_NAMES, new ArrayList<String>());
-        List<String> names = (List<String>) row.get(ATTACHMENT_NAMES);
-        names.add(fileName);
-        row.put(ATTACHMENT_NAMES, names);
-      } else {
-        if (row.get(CONTENT) == null)
-          row.put(CONTENT, new ArrayList<String>());
-        List<String> contents = (List<String>) row.get(CONTENT);
-        contents.add(content);
-        row.put(CONTENT, contents);
-      }
-    }
-  }
-
-  private void addEnvelopToDocument(Part part, Map<String, Object> row) throws MessagingException {
-    MimeMessage mail = (MimeMessage) part;
-    Address[] adresses;
-    if ((adresses = mail.getFrom()) != null && adresses.length > 0)
-      row.put(FROM, adresses[0].toString());
-
-    List<String> to = new ArrayList<String>();
-    if ((adresses = mail.getRecipients(Message.RecipientType.TO)) != null)
-      addAddressToList(adresses, to);
-    if ((adresses = mail.getRecipients(Message.RecipientType.CC)) != null)
-      addAddressToList(adresses, to);
-    if ((adresses = mail.getRecipients(Message.RecipientType.BCC)) != null)
-      addAddressToList(adresses, to);
-    if (to.size() > 0)
-      row.put(TO_CC_BCC, to);
-
-    row.put(MESSAGE_ID, mail.getMessageID());
-    row.put(SUBJECT, mail.getSubject());
-
-    Date d = mail.getSentDate();
-    if (d != null) {
-      row.put(SENT_DATE, d);
-    }
-
-    List<String> flags = new ArrayList<String>();
-    for (Flags.Flag flag : mail.getFlags().getSystemFlags()) {
-      if (flag == Flags.Flag.ANSWERED)
-        flags.add(FLAG_ANSWERED);
-      else if (flag == Flags.Flag.DELETED)
-        flags.add(FLAG_DELETED);
-      else if (flag == Flags.Flag.DRAFT)
-        flags.add(FLAG_DRAFT);
-      else if (flag == Flags.Flag.FLAGGED)
-        flags.add(FLAG_FLAGGED);
-      else if (flag == Flags.Flag.RECENT)
-        flags.add(FLAG_RECENT);
-      else if (flag == Flags.Flag.SEEN)
-        flags.add(FLAG_SEEN);
-    }
-    flags.addAll(Arrays.asList(mail.getFlags().getUserFlags()));
-    row.put(FLAGS, flags);
-
-    String[] hdrs = mail.getHeader("X-Mailer");
-    if (hdrs != null)
-      row.put(XMAILER, hdrs[0]);
-  }
-
-
-  private void addAddressToList(Address[] adresses, List<String> to) throws AddressException {
-    for (Address address : adresses) {
-      to.add(address.toString());
-      InternetAddress ia = (InternetAddress) address;
-      if (ia.isGroup()) {
-        InternetAddress[] group = ia.getGroup(false);
-        for (InternetAddress member : group)
-          to.add(member.toString());
-      }
-    }
-  }
-
-  private boolean connectToMailBox() {
-    try {
-      Properties props = new Properties();
-      props.setProperty("mail.store.protocol", protocol);
-      props.setProperty("mail.imap.fetchsize", "" + fetchSize);
-      props.setProperty("mail.imap.timeout", "" + rTimeout);
-      props.setProperty("mail.imap.connectiontimeout", "" + cTimeout);
-      Session session = Session.getDefaultInstance(props, null);
-      mailbox = session.getStore(protocol);
-      mailbox.connect(host, user, password);
-      LOG.info("Connected to mailbox");
-      return true;
-    } catch (MessagingException e) {
-      throw new DataImportHandlerException(DataImportHandlerException.SEVERE,
-              "Connection failed", e);
-    }
-  }
-
-  private void createFilters() {
-    if (fetchMailsSince != null) {
-      filters.add(new MailsSinceLastCheckFilter(fetchMailsSince));
-    }
-    if (customFilter != null && !customFilter.equals("")) {
-      try {
-        Class cf = Class.forName(customFilter);
-        Object obj = cf.newInstance();
-        if (obj instanceof CustomFilter) {
-          filters.add((CustomFilter) obj);
-        }
-      } catch (Exception e) {
-        throw new DataImportHandlerException(DataImportHandlerException.SEVERE,
-                "Custom filter could not be created", e);
-      }
-    }
-  }
-
-  private void logConfig() {
-    if (!LOG.isInfoEnabled()) return;
-    StringBuffer config = new StringBuffer();
-    config.append("user : ").append(user).append(System.getProperty("line.separator"));
-    config.append("pwd : ").append(password).append(System.getProperty("line.separator"));
-    config.append("protocol : ").append(protocol).append(System.getProperty("line.separator"));
-    config.append("host : ").append(host).append(System.getProperty("line.separator"));
-    config.append("folders : ").append(folderNames).append(System.getProperty("line.separator"));
-    config.append("recurse : ").append(recurse).append(System.getProperty("line.separator"));
-    config.append("exclude : ").append(exclude.toString()).append(System.getProperty("line.separator"));
-    config.append("include : ").append(include.toString()).append(System.getProperty("line.separator"));
-    config.append("batchSize : ").append(batchSize).append(System.getProperty("line.separator"));
-    config.append("fetchSize : ").append(fetchSize).append(System.getProperty("line.separator"));
-    config.append("read timeout : ").append(rTimeout).append(System.getProperty("line.separator"));
-    config.append("conection timeout : ").append(cTimeout).append(System.getProperty("line.separator"));
-    config.append("custom filter : ").append(customFilter).append(System.getProperty("line.separator"));
-    config.append("fetch mail since : ").append(fetchMailsSince).append(System.getProperty("line.separator"));
-    LOG.info(config.toString());
-  }
-
-  class FolderIterator implements Iterator<Folder> {
-    private Store mailbox;
-    private List<String> topLevelFolders;
-    private List<Folder> folders = null;
-    private Folder lastFolder = null;
-
-    public FolderIterator(Store mailBox) {
-      this.mailbox = mailBox;
-      folders = new ArrayList<Folder>();
-      getTopLevelFolders(mailBox);
-    }
-
-    public boolean hasNext() {
-      return !folders.isEmpty();
-    }
-
-    public Folder next() {
-      try {
-        boolean hasMessages = false;
-        Folder next;
-        do {
-          if (lastFolder != null) {
-            lastFolder.close(false);
-            lastFolder = null;
-          }
-          if (folders.isEmpty()) {
-            mailbox.close();
-            return null;
-          }
-          next = folders.remove(0);
-          if (next != null) {
-            String fullName = next.getFullName();
-            if (!excludeFolder(fullName)) {
-              hasMessages = (next.getType() & Folder.HOLDS_MESSAGES) != 0;
-              next.open(Folder.READ_ONLY);
-              lastFolder = next;
-              LOG.info("Opened folder : " + fullName);
-            }
-            if (recurse && ((next.getType() & Folder.HOLDS_FOLDERS) != 0)) {
-              Folder[] children = next.list();
-              LOG.info("Added its children to list  : ");
-              for (int i = children.length - 1; i >= 0; i--) {
-                folders.add(0, children[i]);
-                LOG.info("child name : " + children[i].getFullName());
-              }
-              if (children.length == 0)
-                LOG.info("NO children : ");
-            }
-          }
-        }
-        while (!hasMessages);
-        return next;
-      } catch (MessagingException e) {
-        //throw new DataImportHandlerException(DataImportHandlerException.SEVERE,
-        //        "Folder open failed", e);
-      }
-      return null;
-    }
-
-    public void remove() {
-      throw new UnsupportedOperationException("Its read only mode...");
-    }
-
-    private void getTopLevelFolders(Store mailBox) {
-      if (folderNames != null)
-        topLevelFolders = Arrays.asList(folderNames.split(","));
-      for (int i = 0; topLevelFolders != null && i < topLevelFolders.size(); i++) {
-        try {
-          folders.add(mailbox.getFolder(topLevelFolders.get(i)));
-        } catch (MessagingException e) {
-          // skip bad ones unless its the last one and still no good folder
-          if (folders.size() == 0 && i == topLevelFolders.size() - 1)
-            throw new DataImportHandlerException(DataImportHandlerException.SEVERE,
-                    "Folder retreival failed");
-        }
-      }
-      if (topLevelFolders == null || topLevelFolders.size() == 0) {
-        try {
-          folders.add(mailBox.getDefaultFolder());
-        } catch (MessagingException e) {
-          throw new DataImportHandlerException(DataImportHandlerException.SEVERE,
-                  "Folder retreival failed");
-        }
-      }
-    }
-
-    private boolean excludeFolder(String name) {
-      for (String s : exclude) {
-        if (name.matches(s))
-          return true;
-      }
-      for (String s : include) {
-        if (name.matches(s))
-          return false;
-      }
-      return include.size() > 0;
-    }
-  }
-
-  class MessageIterator implements Iterator<Message> {
-    private Folder folder;
-    private Message[] messagesInCurBatch;
-    private int current = 0;
-    private int currentBatch = 0;
-    private int batchSize = 0;
-    private int totalInFolder = 0;
-    private boolean doBatching = true;
-
-    public MessageIterator(Folder folder, int batchSize) {
-      try {
-        this.folder = folder;
-        this.batchSize = batchSize;
-        SearchTerm st = getSearchTerm();
-        if (st != null) {
-          doBatching = false;
-          messagesInCurBatch = folder.search(st);
-          totalInFolder = messagesInCurBatch.length;
-          folder.fetch(messagesInCurBatch, fp);
-          current = 0;
-          LOG.info("Total messages : " + totalInFolder);
-          LOG.info("Search criteria applied. Batching disabled");
-        } else {
-          totalInFolder = folder.getMessageCount();
-          LOG.info("Total messages : " + totalInFolder);
-          getNextBatch(batchSize, folder);
-        }
-      } catch (MessagingException e) {
-        throw new DataImportHandlerException(DataImportHandlerException.SEVERE,
-                "Message retreival failed", e);
-      }
-    }
-
-    private void getNextBatch(int batchSize, Folder folder) throws MessagingException {
-      // after each batch invalidate cache
-      if (messagesInCurBatch != null) {
-        for (Message m : messagesInCurBatch) {
-          if (m instanceof IMAPMessage)
-            ((IMAPMessage) m).invalidateHeaders();
-        }
-      }
-      int lastMsg = (currentBatch + 1) * batchSize;
-      lastMsg = lastMsg > totalInFolder ? totalInFolder : lastMsg;
-      messagesInCurBatch = folder.getMessages(currentBatch * batchSize + 1, lastMsg);
-      folder.fetch(messagesInCurBatch, fp);
-      current = 0;
-      currentBatch++;
-      LOG.info("Current Batch  : " + currentBatch);
-      LOG.info("Messages in this batch  : " + messagesInCurBatch.length);
-    }
-
-    public boolean hasNext() {
-      boolean hasMore = current < messagesInCurBatch.length;
-      if (!hasMore && doBatching
-              && currentBatch * batchSize < totalInFolder) {
-        // try next batch
-        try {
-          getNextBatch(batchSize, folder);
-          hasMore = current < messagesInCurBatch.length;
-        } catch (MessagingException e) {
-          throw new DataImportHandlerException(DataImportHandlerException.SEVERE,
-                  "Message retreival failed", e);
-        }
-      }
-      return hasMore;
-    }
-
-    public Message next() {
-      return hasNext() ? messagesInCurBatch[current++] : null;
-    }
-
-    public void remove() {
-      throw new UnsupportedOperationException("Its read only mode...");
-    }
-
-    private SearchTerm getSearchTerm() {
-      if (filters.size() == 0)
-        return null;
-      if (filters.size() == 1)
-        return filters.get(0).getCustomSearch(folder);
-      SearchTerm last = filters.get(0).getCustomSearch(folder);
-      for (int i = 1; i < filters.size(); i++) {
-        CustomFilter filter = filters.get(i);
-        SearchTerm st = filter.getCustomSearch(folder);
-        if (st != null) {
-          last = new AndTerm(last, st);
-        }
-      }
-      return last;
-    }
-  }
-
-  class MailsSinceLastCheckFilter implements CustomFilter {
-
-    private Date since;
-
-    public MailsSinceLastCheckFilter(Date date) {
-      since = date;
-    }
-
-    public SearchTerm getCustomSearch(Folder folder) {
-      return new ReceivedDateTerm(ComparisonTerm.GE, since);
-    }
-  }
-
-  // user settings stored in member variables
-  private String user;
-  private String password;
-  private String host;
-  private String protocol;
-
-  private String folderNames;
-  private List<String> exclude = new ArrayList<String>();
-  private List<String> include = new ArrayList<String>();
-  private boolean recurse;
-
-  private int batchSize;
-  private int fetchSize;
-  private int cTimeout;
-  private int rTimeout;
-
-  private Date fetchMailsSince;
-  private String customFilter;
-
-  private boolean processAttachment = true;
-
-  // holds the current state
-  private Store mailbox;
-  private boolean connected = false;
-  private FolderIterator folderIter;
-  private MessageIterator msgIter;
-  private List<CustomFilter> filters = new ArrayList<CustomFilter>();
-  private static FetchProfile fp = new FetchProfile();
-  private static final Logger LOG = LoggerFactory.getLogger(DataImporter.class);
-
-  // diagnostics
-  private int rowCount = 0;
-
-  static {
-    fp.add(FetchProfile.Item.ENVELOPE);
-    fp.add(FetchProfile.Item.FLAGS);
-    fp.add("X-Mailer");
-  }
-
-  // Fields To Index
-  // single valued
-  private static final String MESSAGE_ID = "messageId";
-  private static final String SUBJECT = "subject";
-  private static final String FROM = "from";
-  private static final String SENT_DATE = "sentDate";
-  private static final String XMAILER = "xMailer";
-  // multi valued
-  private static final String TO_CC_BCC = "allTo";
-  private static final String FLAGS = "flags";
-  private static final String CONTENT = "content";
-  private static final String ATTACHMENT = "attachment";
-  private static final String ATTACHMENT_NAMES = "attachmentNames";
-  // flag values
-  private static final String FLAG_ANSWERED = "answered";
-  private static final String FLAG_DELETED = "deleted";
-  private static final String FLAG_DRAFT = "draft";
-  private static final String FLAG_FLAGGED = "flagged";
-  private static final String FLAG_RECENT = "recent";
-  private static final String FLAG_SEEN = "seen";
-
-  private int getIntFromContext(String prop, int ifNull) {
-    int v = ifNull;
-    try {
-      String val = context.getEntityAttribute(prop);
-      if (val != null) {
-        val = context.replaceTokens(val);
-        v = Integer.valueOf(val);
-      }
-    } catch (NumberFormatException e) {
-      //do nothing
-    }
-    return v;
-  }
-
-  private boolean getBoolFromContext(String prop, boolean ifNull) {
-    boolean v = ifNull;
-    String val = context.getEntityAttribute(prop);
-    if (val != null) {
-      val = context.replaceTokens(val);
-      v = Boolean.valueOf(val);
-    }
-    return v;
-  }
-
-  private String getStringFromContext(String prop, String ifNull) {
-    String v = ifNull;
-    String val = context.getEntityAttribute(prop);
-    if (val != null) {
-      val = context.replaceTokens(val);
-      v = val;
-    }
-    return v;
-  }
-}
diff --git a/solr/contrib/dataimporthandler/src/extras/main/java/org/apache/solr/handler/dataimport/TikaEntityProcessor.java b/solr/contrib/dataimporthandler/src/extras/main/java/org/apache/solr/handler/dataimport/TikaEntityProcessor.java
deleted file mode 100644
index 9913c15..0000000
--- a/solr/contrib/dataimporthandler/src/extras/main/java/org/apache/solr/handler/dataimport/TikaEntityProcessor.java
+++ /dev/null
@@ -1,197 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.solr.handler.dataimport;
-
-import org.apache.commons.io.IOUtils;
-import org.apache.tika.config.TikaConfig;
-import org.apache.tika.metadata.Metadata;
-import org.apache.tika.parser.AutoDetectParser;
-import org.apache.tika.parser.ParseContext;
-import org.apache.tika.parser.Parser;
-import org.apache.tika.sax.BodyContentHandler;
-import org.apache.tika.sax.ContentHandlerDecorator;
-import org.apache.tika.sax.XHTMLContentHandler;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-import org.xml.sax.Attributes;
-import org.xml.sax.ContentHandler;
-import org.xml.sax.SAXException;
-import org.xml.sax.helpers.DefaultHandler;
-
-import javax.xml.transform.OutputKeys;
-import javax.xml.transform.TransformerConfigurationException;
-import javax.xml.transform.sax.SAXTransformerFactory;
-import javax.xml.transform.sax.TransformerHandler;
-import javax.xml.transform.stream.StreamResult;
-import java.io.File;
-import java.io.InputStream;
-import java.io.StringWriter;
-import java.io.Writer;
-import java.util.HashMap;
-import java.util.Map;
-
-import static org.apache.solr.handler.dataimport.DataImportHandlerException.SEVERE;
-import static org.apache.solr.handler.dataimport.DataImportHandlerException.wrapAndThrow;
-import static org.apache.solr.handler.dataimport.DataImporter.COLUMN;
-import static org.apache.solr.handler.dataimport.XPathEntityProcessor.URL;
-/**
- * <p>An implementation of {@link EntityProcessor} which reads data from rich docs
- * using <a href="http://tika.apache.org/">Apache Tika</a>
- *
- * @version $Id$
- * @since solr 3.1
- */
-public class TikaEntityProcessor extends EntityProcessorBase {
-  private TikaConfig tikaConfig;
-  private static final Logger LOG = LoggerFactory.getLogger(TikaEntityProcessor.class);
-  private String format = "text";
-  private boolean done = false;
-  private String parser;
-  static final String AUTO_PARSER = "org.apache.tika.parser.AutoDetectParser";
-
-
-  @Override
-  protected void firstInit(Context context) {
-    try {
-      String tikaConfigFile = context.getResolvedEntityAttribute("tikaConfig");
-      if (tikaConfigFile == null) {
-        ClassLoader classLoader = context.getSolrCore().getResourceLoader().getClassLoader();
-        tikaConfig = new TikaConfig(classLoader);
-      } else {
-        File configFile = new File(tikaConfigFile);
-        if (!configFile.isAbsolute()) {
-          configFile = new File(context.getSolrCore().getResourceLoader().getConfigDir(), tikaConfigFile);
-        }
-        tikaConfig = new TikaConfig(configFile);
-      }
-    } catch (Exception e) {
-      wrapAndThrow (SEVERE, e,"Unable to load Tika Config");
-    }
-
-    format = context.getResolvedEntityAttribute("format");
-    if(format == null)
-      format = "text";
-    if (!"html".equals(format) && !"xml".equals(format) && !"text".equals(format)&& !"none".equals(format) )
-      throw new DataImportHandlerException(SEVERE, "'format' can be one of text|html|xml|none");
-    parser = context.getResolvedEntityAttribute("parser");
-    if(parser == null) {
-      parser = AUTO_PARSER;
-    }
-    done = false;
-  }
-
-  @Override
-  public Map<String, Object> nextRow() {
-    if(done) return null;
-    Map<String, Object> row = new HashMap<String, Object>();
-    DataSource<InputStream> dataSource = context.getDataSource();
-    InputStream is = dataSource.getData(context.getResolvedEntityAttribute(URL));
-    ContentHandler contentHandler = null;
-    Metadata metadata = new Metadata();
-    StringWriter sw = new StringWriter();
-    try {
-      if ("html".equals(format)) {
-        contentHandler = getHtmlHandler(sw);
-      } else if ("xml".equals(format)) {
-        contentHandler = getXmlContentHandler(sw);
-      } else if ("text".equals(format)) {
-        contentHandler = getTextContentHandler(sw);
-      } else if("none".equals(format)){
-        contentHandler = new DefaultHandler();        
-      }
-    } catch (TransformerConfigurationException e) {
-      wrapAndThrow(SEVERE, e, "Unable to create content handler");
-    }
-    Parser tikaParser = null;
-    if(parser.equals(AUTO_PARSER)){
-      AutoDetectParser parser = new AutoDetectParser();
-      parser.setConfig(tikaConfig);
-      tikaParser = parser;
-    } else {
-      tikaParser = (Parser) context.getSolrCore().getResourceLoader().newInstance(parser);
-    }
-    try {
-      tikaParser.parse(is, contentHandler, metadata , new ParseContext());
-    } catch (Exception e) {
-      wrapAndThrow(SEVERE, e, "Unable to read content");
-    }
-    IOUtils.closeQuietly(is);
-    for (Map<String, String> field : context.getAllEntityFields()) {
-      if (!"true".equals(field.get("meta"))) continue;
-      String col = field.get(COLUMN);
-      String s = metadata.get(col);
-      if (s != null) row.put(col, s);
-    }
-    if(!"none".equals(format) ) row.put("text", sw.toString());
-    done = true;
-    return row;
-  }
-
-  private static ContentHandler getHtmlHandler(Writer writer)
-          throws TransformerConfigurationException {
-    SAXTransformerFactory factory = (SAXTransformerFactory)
-            SAXTransformerFactory.newInstance();
-    TransformerHandler handler = factory.newTransformerHandler();
-    handler.getTransformer().setOutputProperty(OutputKeys.METHOD, "html");
-    handler.setResult(new StreamResult(writer));
-    return new ContentHandlerDecorator(handler) {
-      @Override
-      public void startElement(
-              String uri, String localName, String name, Attributes atts)
-              throws SAXException {
-        if (XHTMLContentHandler.XHTML.equals(uri)) {
-          uri = null;
-        }
-        if (!"head".equals(localName)) {
-          super.startElement(uri, localName, name, atts);
-        }
-      }
-
-      @Override
-      public void endElement(String uri, String localName, String name)
-              throws SAXException {
-        if (XHTMLContentHandler.XHTML.equals(uri)) {
-          uri = null;
-        }
-        if (!"head".equals(localName)) {
-          super.endElement(uri, localName, name);
-        }
-      }
-
-      @Override
-      public void startPrefixMapping(String prefix, String uri) {/*no op*/ }
-
-      @Override
-      public void endPrefixMapping(String prefix) {/*no op*/ }
-    };
-  }
-
-  private static ContentHandler getTextContentHandler(Writer writer) {
-    return new BodyContentHandler(writer);
-  }
-
-  private static ContentHandler getXmlContentHandler(Writer writer)
-          throws TransformerConfigurationException {
-    SAXTransformerFactory factory = (SAXTransformerFactory)
-            SAXTransformerFactory.newInstance();
-    TransformerHandler handler = factory.newTransformerHandler();
-    handler.getTransformer().setOutputProperty(OutputKeys.METHOD, "xml");
-    handler.setResult(new StreamResult(writer));
-    return handler;
-  }
-
-}
diff --git a/solr/contrib/dataimporthandler/src/extras/test/java/org/apache/solr/handler/dataimport/TestMailEntityProcessor.java b/solr/contrib/dataimporthandler/src/extras/test/java/org/apache/solr/handler/dataimport/TestMailEntityProcessor.java
deleted file mode 100644
index 2ac19b3..0000000
--- a/solr/contrib/dataimporthandler/src/extras/test/java/org/apache/solr/handler/dataimport/TestMailEntityProcessor.java
+++ /dev/null
@@ -1,214 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.solr.handler.dataimport;
-
-import org.apache.solr.common.SolrInputDocument;
-import org.junit.Ignore;
-import org.junit.Test;
-
-import java.text.ParseException;
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-
-// Test mailbox is like this: foldername(mailcount)
-// top1(2) -> child11(6)
-//         -> child12(0)
-// top2(2) -> child21(1)
-//                 -> grandchild211(2)
-//                 -> grandchild212(1)
-//         -> child22(2)
-
-/**
- * Test for MailEntityProcessor. The tests are marked as ignored because we'd need a mail server (real or mocked) for
- * these to work.
- *
- * TODO: Find a way to make the tests actually test code
- *
- * @version $Id$
- * @see org.apache.solr.handler.dataimport.MailEntityProcessor
- * @since solr 1.4
- */
-public class TestMailEntityProcessor extends AbstractDataImportHandlerTestCase {
-
-  // Credentials
-  private static final String user = "user";
-  private static final String password = "password";
-  private static final String host = "host";
-  private static final String protocol = "imaps";
-
-  private static Map<String, String> paramMap = new HashMap<String, String>();
-
-  @Test
-  @Ignore("Needs a Mock Mail Server to work")
-  public void testConnection() {
-    // also tests recurse = false and default settings
-    paramMap.put("folders", "top2");
-    paramMap.put("recurse", "false");
-    paramMap.put("processAttachement", "false");
-    DataImporter di = new DataImporter();
-    di.loadAndInit(getConfigFromMap(paramMap));
-    DataConfig.Entity ent = di.getConfig().document.entities.get(0);
-    ent.isDocRoot = true;
-    DataImporter.RequestParams rp = new DataImporter.RequestParams();
-    rp.command = "full-import";
-    SolrWriterImpl swi = new SolrWriterImpl();
-    di.runCmd(rp, swi);
-    assertEquals("top1 did not return 2 messages", swi.docs.size(), 2);
-  }
-
-  @Test
-  @Ignore("Needs a Mock Mail Server to work")
-  public void testRecursion() {
-    paramMap.put("folders", "top2");
-    paramMap.put("recurse", "true");
-    paramMap.put("processAttachement", "false");
-    DataImporter di = new DataImporter();
-    di.loadAndInit(getConfigFromMap(paramMap));
-    DataConfig.Entity ent = di.getConfig().document.entities.get(0);
-    ent.isDocRoot = true;
-    DataImporter.RequestParams rp = new DataImporter.RequestParams();
-    rp.command = "full-import";
-    SolrWriterImpl swi = new SolrWriterImpl();
-    di.runCmd(rp, swi);
-    assertEquals("top2 and its children did not return 8 messages", swi.docs.size(), 8);
-  }
-
-  @Test
-  @Ignore("Needs a Mock Mail Server to work")
-  public void testExclude() {
-    paramMap.put("folders", "top2");
-    paramMap.put("recurse", "true");
-    paramMap.put("processAttachement", "false");
-    paramMap.put("exclude", ".*grandchild.*");
-    DataImporter di = new DataImporter();
-    di.loadAndInit(getConfigFromMap(paramMap));
-    DataConfig.Entity ent = di.getConfig().document.entities.get(0);
-    ent.isDocRoot = true;
-    DataImporter.RequestParams rp = new DataImporter.RequestParams();
-    rp.command = "full-import";
-    SolrWriterImpl swi = new SolrWriterImpl();
-    di.runCmd(rp, swi);
-    assertEquals("top2 and its direct children did not return 5 messages", swi.docs.size(), 5);
-  }
-
-  @Test
-  @Ignore("Needs a Mock Mail Server to work")
-  public void testInclude() {
-    paramMap.put("folders", "top2");
-    paramMap.put("recurse", "true");
-    paramMap.put("processAttachement", "false");
-    paramMap.put("include", ".*grandchild.*");
-    DataImporter di = new DataImporter();
-    di.loadAndInit(getConfigFromMap(paramMap));
-    DataConfig.Entity ent = di.getConfig().document.entities.get(0);
-    ent.isDocRoot = true;
-    DataImporter.RequestParams rp = new DataImporter.RequestParams();
-    rp.command = "full-import";
-    SolrWriterImpl swi = new SolrWriterImpl();
-    di.runCmd(rp, swi);
-    assertEquals("top2 and its direct children did not return 3 messages", swi.docs.size(), 3);
-  }
-
-  @Test
-  @Ignore("Needs a Mock Mail Server to work")
-  public void testIncludeAndExclude() {
-    paramMap.put("folders", "top1,top2");
-    paramMap.put("recurse", "true");
-    paramMap.put("processAttachement", "false");
-    paramMap.put("exclude", ".*top1.*");
-    paramMap.put("include", ".*grandchild.*");
-    DataImporter di = new DataImporter();
-    di.loadAndInit(getConfigFromMap(paramMap));
-    DataConfig.Entity ent = di.getConfig().document.entities.get(0);
-    ent.isDocRoot = true;
-    DataImporter.RequestParams rp = new DataImporter.RequestParams();
-    rp.command = "full-import";
-    SolrWriterImpl swi = new SolrWriterImpl();
-    di.runCmd(rp, swi);
-    assertEquals("top2 and its direct children did not return 3 messages", swi.docs.size(), 3);
-  }
-
-  @Test
-  @Ignore("Needs a Mock Mail Server to work")
-  public void testFetchTimeSince() throws ParseException {
-    paramMap.put("folders", "top1/child11");
-    paramMap.put("recurse", "true");
-    paramMap.put("processAttachement", "false");
-    paramMap.put("fetchMailsSince", "2008-12-26 00:00:00");
-    DataImporter di = new DataImporter();
-    di.loadAndInit(getConfigFromMap(paramMap));
-    DataConfig.Entity ent = di.getConfig().document.entities.get(0);
-    ent.isDocRoot = true;
-    DataImporter.RequestParams rp = new DataImporter.RequestParams();
-    rp.command = "full-import";
-    SolrWriterImpl swi = new SolrWriterImpl();
-    di.runCmd(rp, swi);
-    assertEquals("top2 and its direct children did not return 3 messages", swi.docs.size(), 3);
-  }
-
-  private String getConfigFromMap(Map<String, String> params) {
-    String conf =
-            "<dataConfig>" +
-                    "<document>" +
-                    "<entity processor=\"org.apache.solr.handler.dataimport.MailEntityProcessor\" " +
-                    "someconfig" +
-                    "/>" +
-                    "</document>" +
-                    "</dataConfig>";
-    params.put("user", user);
-    params.put("password", password);
-    params.put("host", host);
-    params.put("protocol", protocol);
-    StringBuilder attribs = new StringBuilder("");
-    for (String key : params.keySet())
-      attribs.append(" ").append(key).append("=" + "\"").append(params.get(key)).append("\"");
-    attribs.append(" ");
-    return conf.replace("someconfig", attribs.toString());
-  }
-
-  static class SolrWriterImpl extends SolrWriter {
-    List<SolrInputDocument> docs = new ArrayList<SolrInputDocument>();
-    Boolean deleteAllCalled;
-    Boolean commitCalled;
-
-    public SolrWriterImpl() {
-      super(null, ".", null);
-    }
-
-    @Override
-    public boolean upload(SolrInputDocument doc) {
-      return docs.add(doc);
-    }
-
-    @Override
-    public void log(int event, String name, Object row) {
-      // Do nothing
-    }
-
-    @Override
-    public void doDeleteAll() {
-      deleteAllCalled = Boolean.TRUE;
-    }
-
-    @Override
-    public void commit(boolean b) {
-      commitCalled = Boolean.TRUE;
-    }
-  }
-}
diff --git a/solr/contrib/dataimporthandler/src/extras/test/java/org/apache/solr/handler/dataimport/TestTikaEntityProcessor.java b/solr/contrib/dataimporthandler/src/extras/test/java/org/apache/solr/handler/dataimport/TestTikaEntityProcessor.java
deleted file mode 100644
index 019fa85..0000000
--- a/solr/contrib/dataimporthandler/src/extras/test/java/org/apache/solr/handler/dataimport/TestTikaEntityProcessor.java
+++ /dev/null
@@ -1,53 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.solr.handler.dataimport;
-
-import org.junit.BeforeClass;
-import org.junit.Test;
-
-/**Testcase for TikaEntityProcessor
- * @version $Id$
- * @since solr 1.5 
- */
-public class TestTikaEntityProcessor extends AbstractDataImportHandlerTestCase {
-  @BeforeClass
-  public static void beforeClass() throws Exception {
-    initCore("dataimport-solrconfig.xml", "dataimport-schema-no-unique-key.xml", getFile("solr-dihextras").getAbsolutePath());
-  }
-
-  @Test
-  public void testIndexingWithTikaEntityProcessor() throws Exception {
-    String conf =
-            "<dataConfig>" +
-                    "  <dataSource type=\"BinFileDataSource\"/>" +
-                    "  <document>" +
-                    "    <entity processor=\"TikaEntityProcessor\" url=\"" + getFile("solr-word.pdf").getAbsolutePath() + "\" >" +
-                    "      <field column=\"Author\" meta=\"true\" name=\"author\"/>" +
-                    "      <field column=\"title\" meta=\"true\" name=\"title\"/>" +
-                    "      <field column=\"text\"/>" +
-                    "     </entity>" +
-                    "  </document>" +
-                    "</dataConfig>";
-    runFullImport(conf);
-    assertQ(req("*:*")
-            ,"//*[@numFound='1']"
-            ,"//str[@name='author'][.='Grant Ingersoll']"
-            ,"//str[@name='title'][.='solr-word']"
-            ,"//str[@name='text']"
-            );
-  }
-}
diff --git a/solr/contrib/dataimporthandler/src/extras/test/resources/solr-dihextras/conf/dataimport-schema-no-unique-key.xml b/solr/contrib/dataimporthandler/src/extras/test/resources/solr-dihextras/conf/dataimport-schema-no-unique-key.xml
deleted file mode 100644
index b1ec8be..0000000
--- a/solr/contrib/dataimporthandler/src/extras/test/resources/solr-dihextras/conf/dataimport-schema-no-unique-key.xml
+++ /dev/null
@@ -1,205 +0,0 @@
-<?xml version="1.0" encoding="UTF-8" ?>
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-
-<!--  
- This is the Solr schema file. This file should be named "schema.xml" and
- should be in the conf directory under the solr home
- (i.e. ./solr/conf/schema.xml by default) 
- or located where the classloader for the Solr webapp can find it.
-
- This example schema is the recommended starting point for users.
- It should be kept correct and concise, usable out-of-the-box.
-
- For more information, on how to customize this file, please see
- http://wiki.apache.org/solr/SchemaXml
--->
-
-<schema name="test" version="1.2">
-  <!-- attribute "name" is the name of this schema and is only used for display purposes.
-       Applications should change this to reflect the nature of the search collection.
-       version="1.1" is Solr's version number for the schema syntax and semantics.  It should
-       not normally be changed by applications.
-       1.0: multiValued attribute did not exist, all fields are multiValued by nature
-       1.1: multiValued attribute introduced, false by default -->
-
-  <types>
-    <!-- field type definitions. The "name" attribute is
-       just a label to be used by field definitions.  The "class"
-       attribute and any other attributes determine the real
-       behavior of the fieldType.
-         Class names starting with "solr" refer to java classes in the
-       org.apache.solr.analysis package.
-    -->
-
-    <!-- The StrField type is not analyzed, but indexed/stored verbatim.  
-       - StrField and TextField support an optional compressThreshold which
-       limits compression (if enabled in the derived fields) to values which
-       exceed a certain size (in characters).
-    -->
-    <fieldType name="string" class="solr.StrField" sortMissingLast="true" omitNorms="true"/>
-
-    <!-- boolean type: "true" or "false" -->
-    <fieldType name="boolean" class="solr.BoolField" sortMissingLast="true" omitNorms="true"/>
-
-    <!-- The optional sortMissingLast and sortMissingFirst attributes are
-         currently supported on types that are sorted internally as strings.
-       - If sortMissingLast="true", then a sort on this field will cause documents
-         without the field to come after documents with the field,
-         regardless of the requested sort order (asc or desc).
-       - If sortMissingFirst="true", then a sort on this field will cause documents
-         without the field to come before documents with the field,
-         regardless of the requested sort order.
-       - If sortMissingLast="false" and sortMissingFirst="false" (the default),
-         then default lucene sorting will be used which places docs without the
-         field first in an ascending sort and last in a descending sort.
-    -->    
-
-
-    <!-- numeric field types that store and index the text
-         value verbatim (and hence don't support range queries, since the
-         lexicographic ordering isn't equal to the numeric ordering) -->
-    <fieldType name="integer" class="solr.IntField" omitNorms="true"/>
-    <fieldType name="long" class="solr.LongField" omitNorms="true"/>
-    <fieldType name="float" class="solr.FloatField" omitNorms="true"/>
-    <fieldType name="double" class="solr.DoubleField" omitNorms="true"/>
-
-
-    <!-- Numeric field types that manipulate the value into
-         a string value that isn't human-readable in its internal form,
-         but with a lexicographic ordering the same as the numeric ordering,
-         so that range queries work correctly. -->
-    <fieldType name="sint" class="solr.SortableIntField" sortMissingLast="true" omitNorms="true"/>
-    <fieldType name="slong" class="solr.SortableLongField" sortMissingLast="true" omitNorms="true"/>
-    <fieldType name="sfloat" class="solr.SortableFloatField" sortMissingLast="true" omitNorms="true"/>
-    <fieldType name="sdouble" class="solr.SortableDoubleField" sortMissingLast="true" omitNorms="true"/>
-
-
-    <!-- The format for this date field is of the form 1995-12-31T23:59:59Z, and
-         is a more restricted form of the canonical representation of dateTime
-         http://www.w3.org/TR/xmlschema-2/#dateTime    
-         The trailing "Z" designates UTC time and is mandatory.
-         Optional fractional seconds are allowed: 1995-12-31T23:59:59.999Z
-         All other components are mandatory.
-
-         Expressions can also be used to denote calculations that should be
-         performed relative to "NOW" to determine the value, ie...
-
-               NOW/HOUR
-                  ... Round to the start of the current hour
-               NOW-1DAY
-                  ... Exactly 1 day prior to now
-               NOW/DAY+6MONTHS+3DAYS
-                  ... 6 months and 3 days in the future from the start of
-                      the current day
-                      
-         Consult the DateField javadocs for more information.
-      -->
-    <fieldType name="date" class="solr.DateField" sortMissingLast="true" omitNorms="true"/>
-
-
-    <!-- The "RandomSortField" is not used to store or search any
-         data.  You can declare fields of this type it in your schema
-         to generate psuedo-random orderings of your docs for sorting 
-         purposes.  The ordering is generated based on the field name 
-         and the version of the index, As long as the index version
-         remains unchanged, and the same field name is reused,
-         the ordering of the docs will be consistent.  
-         If you want differend psuedo-random orderings of documents,
-         for the same version of the index, use a dynamicField and
-         change the name
-     -->
-    <fieldType name="random" class="solr.RandomSortField" indexed="true" />
-
-    <!-- solr.TextField allows the specification of custom text analyzers
-         specified as a tokenizer and a list of token filters. Different
-         analyzers may be specified for indexing and querying.
-
-         The optional positionIncrementGap puts space between multiple fields of
-         this type on the same document, with the purpose of preventing false phrase
-         matching across fields.
-
-         For more info on customizing your analyzer chain, please see
-         http://wiki.apache.org/solr/AnalyzersTokenizersTokenFilters
-     -->
-
-    <!-- One can also specify an existing Analyzer class that has a
-         default constructor via the class attribute on the analyzer element
-    <fieldType name="text_greek" class="solr.TextField">
-      <analyzer class="org.apache.lucene.analysis.el.GreekAnalyzer"/>
-    </fieldType>
-    -->
-
-    <!-- A text field that only splits on whitespace for exact matching of words -->
-    <fieldType name="text_ws" class="solr.TextField" positionIncrementGap="100">
-      <analyzer>
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-      </analyzer>
-    </fieldType>
-
-    <!-- A text field that uses WordDelimiterFilter to enable splitting and matching of
-        words on case-change, alpha numeric boundaries, and non-alphanumeric chars,
-        so that a query of "wifi" or "wi fi" could match a document containing "Wi-Fi".
-        Synonyms and stopwords are customized by external files, and stemming is enabled.
-        Duplicate tokens at the same position (which may result from Stemmed Synonyms or
-        WordDelim parts) are removed.
-        -->
-    <fieldType name="text" class="solr.TextField" positionIncrementGap="100">
-      <analyzer type="index">
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-        <!-- in this example, we will only use synonyms at query time
-        <filter class="solr.SynonymFilterFactory" synonyms="index_synonyms.txt" ignoreCase="true" expand="false"/>
-        -->
-        <!--<filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt"/>-->
-        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="1" catenateNumbers="1" catenateAll="0" splitOnCaseChange="1"/>
-        <filter class="solr.LowerCaseFilterFactory"/>
-        <!--<filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
-        <filter class="solr.PorterStemFilterFactory"/>-->
-        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
-      </analyzer>
-      <analyzer type="query">
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-        <!--<filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt" ignoreCase="true" expand="true"/>-->
-        <!--<filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt"/>-->
-        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="0" catenateNumbers="0" catenateAll="0" splitOnCaseChange="1"/>
-        <filter class="solr.LowerCaseFilterFactory"/>
-        <!--<filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
-        <filter class="solr.PorterStemFilterFactory"/>-->
-        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
-      </analyzer>
-    </fieldType>
-    <!-- since fields of this type are by default not stored or indexed, any data added to 
-         them will be ignored outright 
-     --> 
-    <fieldtype name="ignored" stored="false" indexed="false" class="solr.StrField" /> 
-
- </types>
-
-
- <fields>
-   <field name="title" type="string" indexed="true" stored="true"/>
-   <field name="author" type="string" indexed="true" stored="true" />
-   <field name="text" type="text" indexed="true" stored="true" />
-   
- </fields>
- <!-- field for the QueryParser to use when an explicit fieldname is absent -->
- <defaultSearchField>text</defaultSearchField>
-
- <!-- SolrQueryParser configuration: defaultOperator="AND|OR" -->
- <solrQueryParser defaultOperator="OR"/>
-
-</schema>
diff --git a/solr/contrib/dataimporthandler/src/extras/test/resources/solr-dihextras/conf/dataimport-solrconfig.xml b/solr/contrib/dataimporthandler/src/extras/test/resources/solr-dihextras/conf/dataimport-solrconfig.xml
deleted file mode 100644
index 9f41933..0000000
--- a/solr/contrib/dataimporthandler/src/extras/test/resources/solr-dihextras/conf/dataimport-solrconfig.xml
+++ /dev/null
@@ -1,397 +0,0 @@
-<?xml version="1.0" encoding="UTF-8" ?>
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-
-<config>
-  <luceneMatchVersion>${tests.luceneMatchVersion:LUCENE_CURRENT}</luceneMatchVersion>
-
-  <!-- Used to specify an alternate directory to hold all index data
-       other than the default ./data under the Solr home.
-       If replication is in use, this should match the replication configuration. -->
-       <dataDir>${solr.data.dir:}</dataDir>
-
-
-  <indexDefaults>
-   <!-- Values here affect all index writers and act as a default unless overridden. -->
-    <useCompoundFile>false</useCompoundFile>
-
-    <mergeFactor>10</mergeFactor>
-    <!--
-     If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
-
-     -->
-    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
-    <!-- Tell Lucene when to flush documents to disk.
-    Giving Lucene more memory for indexing means faster indexing at the cost of more RAM
-
-    If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
-
-    -->
-    <ramBufferSizeMB>32</ramBufferSizeMB>
-    <maxMergeDocs>2147483647</maxMergeDocs>
-    <maxFieldLength>10000</maxFieldLength>
-    <writeLockTimeout>1000</writeLockTimeout>
-    <commitLockTimeout>10000</commitLockTimeout>
-
-    <!--
-     Expert: Turn on Lucene's auto commit capability.
-
-     TODO: Add recommendations on why you would want to do this.
-
-     NOTE: Despite the name, this value does not have any relation to Solr's autoCommit functionality
-
-     -->
-    <!--<luceneAutoCommit>false</luceneAutoCommit>-->
-    <!--
-     Expert:
-     The Merge Policy in Lucene controls how merging is handled by Lucene.  The default in 2.3 is the LogByteSizeMergePolicy, previous
-     versions used LogDocMergePolicy.
-
-     LogByteSizeMergePolicy chooses segments to merge based on their size.  The Lucene 2.2 default, LogDocMergePolicy chose when
-     to merge based on number of documents
-
-     Other implementations of MergePolicy must have a no-argument constructor
-     -->
-    <!--<mergePolicy>org.apache.lucene.index.LogByteSizeMergePolicy</mergePolicy>-->
-
-    <!--
-     Expert:
-     The Merge Scheduler in Lucene controls how merges are performed.  The ConcurrentMergeScheduler (Lucene 2.3 default)
-      can perform merges in the background using separate threads.  The SerialMergeScheduler (Lucene 2.2 default) does not.
-     -->
-    <!--<mergeScheduler>org.apache.lucene.index.ConcurrentMergeScheduler</mergeScheduler>-->
-
-    <!--
-      As long as Solr is the only process modifying your index, it is
-      safe to use Lucene's in process locking mechanism.  But you may
-      specify one of the other Lucene LockFactory implementations in
-      the event that you have a custom situation.
-      
-      none = NoLockFactory (typically only used with read only indexes)
-      single = SingleInstanceLockFactory (suggested)
-      native = NativeFSLockFactory
-      simple = SimpleFSLockFactory
-
-      ('simple' is the default for backwards compatibility with Solr 1.2)
-    -->
-    <lockType>single</lockType>
-  </indexDefaults>
-
-  <mainIndex>
-    <!-- options specific to the main on-disk lucene index -->
-    <useCompoundFile>false</useCompoundFile>
-    <ramBufferSizeMB>32</ramBufferSizeMB>
-    <mergeFactor>10</mergeFactor>
-    <!-- Deprecated -->
-    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
-    <maxMergeDocs>2147483647</maxMergeDocs>
-    <maxFieldLength>10000</maxFieldLength>
-
-    <!-- If true, unlock any held write or commit locks on startup. 
-         This defeats the locking mechanism that allows multiple
-         processes to safely access a lucene index, and should be
-         used with care.
-         This is not needed if lock type is 'none' or 'single'
-     -->
-    <unlockOnStartup>false</unlockOnStartup>
-  </mainIndex>
-
-  <!-- the default high-performance update handler -->
-  <updateHandler class="solr.DirectUpdateHandler2">
-
-    <!-- A prefix of "solr." for class names is an alias that
-         causes solr to search appropriate packages, including
-         org.apache.solr.(search|update|request|core|analysis)
-     -->
-
-    <!-- Limit the number of deletions Solr will buffer during doc updating.
-        
-        Setting this lower can help bound memory use during indexing.
-    -->
-    <maxPendingDeletes>100000</maxPendingDeletes>
-
-  </updateHandler>
-
-
-  <query>
-    <!-- Maximum number of clauses in a boolean query... can affect
-        range or prefix queries that expand to big boolean
-        queries.  An exception is thrown if exceeded.  -->
-    <maxBooleanClauses>1024</maxBooleanClauses>
-
-    
-    <!-- Cache used by SolrIndexSearcher for filters (DocSets),
-         unordered sets of *all* documents that match a query.
-         When a new searcher is opened, its caches may be prepopulated
-         or "autowarmed" using data from caches in the old searcher.
-         autowarmCount is the number of items to prepopulate.  For LRUCache,
-         the autowarmed items will be the most recently accessed items.
-       Parameters:
-         class - the SolrCache implementation (currently only LRUCache)
-         size - the maximum number of entries in the cache
-         initialSize - the initial capacity (number of entries) of
-           the cache.  (seel java.util.HashMap)
-         autowarmCount - the number of entries to prepopulate from
-           and old cache.
-         -->
-    <filterCache
-      class="solr.LRUCache"
-      size="512"
-      initialSize="512"
-      autowarmCount="256"/>
-
-   <!-- queryResultCache caches results of searches - ordered lists of
-         document ids (DocList) based on a query, a sort, and the range
-         of documents requested.  -->
-    <queryResultCache
-      class="solr.LRUCache"
-      size="512"
-      initialSize="512"
-      autowarmCount="256"/>
-
-  <!-- documentCache caches Lucene Document objects (the stored fields for each document).
-       Since Lucene internal document ids are transient, this cache will not be autowarmed.  -->
-    <documentCache
-      class="solr.LRUCache"
-      size="512"
-      initialSize="512"
-      autowarmCount="0"/>
-
-    <!-- If true, stored fields that are not requested will be loaded lazily.
-
-    This can result in a significant speed improvement if the usual case is to
-    not load all stored fields, especially if the skipped fields are large compressed
-    text fields.
-    -->
-    <enableLazyFieldLoading>true</enableLazyFieldLoading>
-
-    <!-- Example of a generic cache.  These caches may be accessed by name
-         through SolrIndexSearcher.getCache(),cacheLookup(), and cacheInsert().
-         The purpose is to enable easy caching of user/application level data.
-         The regenerator argument should be specified as an implementation
-         of solr.search.CacheRegenerator if autowarming is desired.  -->
-    <!--
-    <cache name="myUserCache"
-      class="solr.LRUCache"
-      size="4096"
-      initialSize="1024"
-      autowarmCount="1024"
-      regenerator="org.mycompany.mypackage.MyRegenerator"
-      />
-    -->
-
-   <!-- An optimization that attempts to use a filter to satisfy a search.
-         If the requested sort does not include score, then the filterCache
-         will be checked for a filter matching the query. If found, the filter
-         will be used as the source of document ids, and then the sort will be
-         applied to that.
-    <useFilterForSortedQuery>true</useFilterForSortedQuery>
-   -->
-
-   <!-- An optimization for use with the queryResultCache.  When a search
-         is requested, a superset of the requested number of document ids
-         are collected.  For example, if a search for a particular query
-         requests matching documents 10 through 19, and queryWindowSize is 50,
-         then documents 0 through 49 will be collected and cached.  Any further
-         requests in that range can be satisfied via the cache.  -->
-    <queryResultWindowSize>50</queryResultWindowSize>
-    
-    <!-- Maximum number of documents to cache for any entry in the
-         queryResultCache. -->
-    <queryResultMaxDocsCached>200</queryResultMaxDocsCached>
-
-    <!-- This entry enables an int hash representation for filters (DocSets)
-         when the number of items in the set is less than maxSize.  For smaller
-         sets, this representation is more memory efficient, more efficient to
-         iterate over, and faster to take intersections.  -->
-    <HashDocSet maxSize="3000" loadFactor="0.75"/>
-
-    <!-- a newSearcher event is fired whenever a new searcher is being prepared
-         and there is a current searcher handling requests (aka registered). -->
-    <!-- QuerySenderListener takes an array of NamedList and executes a
-         local query request for each NamedList in sequence. -->
-    <listener event="newSearcher" class="solr.QuerySenderListener">
-      <arr name="queries">
-        <lst> <str name="q">solr</str> <str name="start">0</str> <str name="rows">10</str> </lst>
-        <lst> <str name="q">rocks</str> <str name="start">0</str> <str name="rows">10</str> </lst>
-        <lst><str name="q">static newSearcher warming query from solrconfig.xml</str></lst>
-      </arr>
-    </listener>
-
-    <!-- a firstSearcher event is fired whenever a new searcher is being
-         prepared but there is no current registered searcher to handle
-         requests or to gain autowarming data from. -->
-    <listener event="firstSearcher" class="solr.QuerySenderListener">
-      <arr name="queries">
-      </arr>
-    </listener>
-
-    <!-- If a search request comes in and there is no current registered searcher,
-         then immediately register the still warming searcher and use it.  If
-         "false" then all requests will block until the first searcher is done
-         warming. -->
-    <useColdSearcher>false</useColdSearcher>
-
-    <!-- Maximum number of searchers that may be warming in the background
-      concurrently.  An error is returned if this limit is exceeded. Recommend
-      1-2 for read-only slaves, higher for masters w/o cache warming. -->
-    <maxWarmingSearchers>4</maxWarmingSearchers>
-
-  </query>
-
-  <!-- 
-    Let the dispatch filter handler /select?qt=XXX
-    handleSelect=true will use consistent error handling for /select and /update
-    handleSelect=false will use solr1.1 style error formatting
-    -->
-  <requestDispatcher handleSelect="true" >
-    <!--Make sure your system has some authentication before enabling remote streaming!  -->
-    <requestParsers enableRemoteStreaming="false" multipartUploadLimitInKB="2048" />
-        
-    <!-- Set HTTP caching related parameters (for proxy caches and clients).
-          
-         To get the behaviour of Solr 1.2 (ie: no caching related headers)
-         use the never304="true" option and do not specify a value for
-         <cacheControl>
-    -->
-    <httpCaching never304="true">
-    <!--httpCaching lastModifiedFrom="openTime"
-                 etagSeed="Solr"-->
-       <!-- lastModFrom="openTime" is the default, the Last-Modified value
-            (and validation against If-Modified-Since requests) will all be
-            relative to when the current Searcher was opened.
-            You can change it to lastModFrom="dirLastMod" if you want the
-            value to exactly corrispond to when the physical index was last
-            modified.
-               
-            etagSeed="..." is an option you can change to force the ETag
-            header (and validation against If-None-Match requests) to be
-            differnet even if the index has not changed (ie: when making
-            significant changes to your config file)
-
-            lastModifiedFrom and etagSeed are both ignored if you use the
-            never304="true" option.
-       -->
-       <!-- If you include a <cacheControl> directive, it will be used to
-            generate a Cache-Control header, as well as an Expires header
-            if the value contains "max-age="
-               
-            By default, no Cache-Control header is generated.
-
-            You can use the <cacheControl> option even if you have set
-            never304="true"
-       -->
-       <!-- <cacheControl>max-age=30, public</cacheControl> -->
-    </httpCaching>
-  </requestDispatcher>
-  
-      
-  <!-- requestHandler plugins... incoming queries will be dispatched to the
-     correct handler based on the path or the qt (query type) param.
-     Names starting with a '/' are accessed with the a path equal to the 
-     registered name.  Names without a leading '/' are accessed with:
-      http://host/app/select?qt=name
-     If no qt is defined, the requestHandler that declares default="true"
-     will be used.
-  -->
-  <requestHandler name="standard" class="solr.StandardRequestHandler" default="true">
-    <!-- default values for query parameters -->
-     <lst name="defaults">
-       <str name="echoParams">explicit</str>
-       <!-- 
-       <int name="rows">10</int>
-       <str name="fl">*</str>
-       <str name="version">2.1</str>
-        -->
-     </lst>
-  </requestHandler>
-  
-  <requestHandler name="/dataimport" class="org.apache.solr.handler.dataimport.DataImportHandler">
-  </requestHandler>
-    
-  <!--
-   
-   Search components are registered to SolrCore and used by Search Handlers
-   
-   By default, the following components are avaliable:
-    
-   <searchComponent name="query"     class="org.apache.solr.handler.component.QueryComponent" />
-   <searchComponent name="facet"     class="org.apache.solr.handler.component.FacetComponent" />
-   <searchComponent name="mlt"       class="org.apache.solr.handler.component.MoreLikeThisComponent" />
-   <searchComponent name="highlight" class="org.apache.solr.handler.component.HighlightComponent" />
-   <searchComponent name="debug"     class="org.apache.solr.handler.component.DebugComponent" />
-  
-   If you register a searchComponent to one of the standard names, that will be used instead.
-  
-   -->
- 
-  <requestHandler name="/search" class="org.apache.solr.handler.component.SearchHandler">
-    <lst name="defaults">
-      <str name="echoParams">explicit</str>
-    </lst>
-    <!--
-    By default, this will register the following components:
-    
-    <arr name="components">
-      <str>query</str>
-      <str>facet</str>
-      <str>mlt</str>
-      <str>highlight</str>
-      <str>debug</str>
-    </arr>
-    
-    To insert handlers before or after the 'standard' components, use:
-    
-    <arr name="first-components">
-      <str>first</str>
-    </arr>
-    
-    <arr name="last-components">
-      <str>last</str>
-    </arr>
-    
-    -->
-  </requestHandler>
-  
-  <!-- Update request handler.  
-  
-       Note: Since solr1.1 requestHandlers requires a valid content type header if posted in 
-       the body. For example, curl now requires: -H 'Content-type:text/xml; charset=utf-8'
-       The response format differs from solr1.1 formatting and returns a standard error code.
-       
-       To enable solr1.1 behavior, remove the /update handler or change its path
-       
-       "update.processor.class" is the class name for the UpdateRequestProcessor.  It is initalized
-       only once.  This can not be changed for each request.
-    -->
-  <requestHandler name="/update" class="solr.XmlUpdateRequestHandler" >
-    <!--
-    <str name="update.processor.class">org.apache.solr.handler.UpdateRequestProcessor</str>
-    -->
-  </requestHandler>
-  
-  <!-- config for the admin interface --> 
-  <admin>
-    <defaultQuery>*:*</defaultQuery>
-    
-    <!-- configure a healthcheck file for servers behind a loadbalancer
-    <healthcheck type="file">server-enabled</healthcheck>
-    -->
-  </admin>
-
-</config>
-
diff --git a/solr/contrib/dataimporthandler/src/extras/test/resources/solr-word.pdf b/solr/contrib/dataimporthandler/src/extras/test/resources/solr-word.pdf
deleted file mode 100644
index bd8b865..0000000
--- a/solr/contrib/dataimporthandler/src/extras/test/resources/solr-word.pdf
+++ /dev/null
@@ -1,2 +0,0 @@
-This is a test of PDF and Word extraction in Solr, it is only a test. Do not panic.
-
\ No newline at end of file
diff --git a/solr/contrib/extraction/build.xml b/solr/contrib/extraction/build.xml
index de7542d..112d173 100644
--- a/solr/contrib/extraction/build.xml
+++ b/solr/contrib/extraction/build.xml
@@ -17,177 +17,16 @@
     limitations under the License.
  -->
 
-<project name="solr-cell" default="build">
+<project name="solr-cell" default="default">
 
-  <property name="solr-path" value="../.." />
-
-  <import file="../../common-build.xml"/>
-  
   <description>
     Solr Integration with Tika for extracting content from binary file formats such as Microsoft Word and Adobe PDF.
   </description>
 
-  <path id="common.classpath">
-    <pathelement location="${solr-path}/build/solr" />
-    <pathelement location="${solr-path}/build/solrj" />
-    <fileset dir="lib" includes="*.jar"/>
-    <fileset dir="${solr-path}/lib" includes="*.jar"/>
-    <path refid="lucene.classpath"/>
-  </path>
-
-  <path id="test.classpath">
-    <path refid="common.classpath" />
-    <pathelement path="${dest}/classes" />
-    <pathelement path="${dest}/test-classes" />
-    <pathelement location="${solr-path}/build/tests"/> <!-- include solr test code -->
-    <pathelement location="${solr-path}/../lucene/build/classes/test-framework" />  <!-- include some lucene test code -->
-    <pathelement path="${java.class.path}"/>
-  </path>
-
-  <target name="clean">
-    <delete failonerror="false" dir="${dest}"/>
-  </target>
-
-  <target name="init">
-    <mkdir dir="${dest}/classes"/>
-    <mkdir dir="${build.javadoc}" />
-    <subant target="compileTests">
-      <fileset dir="${solr-path}" includes="build.xml"/>
-    </subant>
-    <subant target="make-manifest">
-      <fileset dir="${solr-path}" includes="build.xml"/>
-    </subant>
-
-  </target>
-
-  <target name="compile" depends="init">
-    <solr-javac destdir="${dest}/classes"
-    classpathref="common.classpath">
-      <src path="src/main/java" />
-    </solr-javac>
-  </target>
-
-  <target name="build" depends="compile">
-    <solr-jar destfile="${dest}/${fullnamever}.jar" basedir="${dest}/classes"
-              manifest="../../${dest}/META-INF/MANIFEST.MF">
-
-    </solr-jar>
-  </target>
-
-  <target name="compileTests" depends="compile">
-  	<solr-javac destdir="${dest}/test-classes"
-  	                classpathref="test.classpath">
-  	  <src path="src/test/java" />
-  	</solr-javac>
-    <!-- Copy any data files present to the classpath -->
-    <copy todir="${dest}/test-classes">
-      <fileset dir="src/test/resources" excludes="**/*.java"/>
-    </copy>
-  </target>
-
-  <property name="tempDir" value="${junit.output.dir}/temp" />
-
-  <target name="test" depends="compileTests">
-  	<mkdir dir="${junit.output.dir}"/>
-    <!-- <mkdir dir="@{tempDir}/@{pattern}"/> 
-       This is very loud and obnoxious. abuse touch instead for a "quiet" mkdir
-    -->
-  	<touch file="${tempDir}/quiet.ant" verbose="false" mkdirs="true"/>
-
-    <condition property="runall">
-      <not>
-        <or>
-          <isset property="testcase"/>
-          <isset property="testpackage"/>
-          <isset property="testpackageroot"/>
-        </or>
-      </not>
-    </condition>    
-    
-  	<junit printsummary="no"
-           haltonfailure="no"
-           maxmemory="512M"
-           errorProperty="tests.failed"
-           failureProperty="tests.failed"
-           dir="${tempDir}"
-           tempdir="${tempDir}"
-           forkmode="perBatch"
-           >
-      <sysproperty key="java.util.logging.config.file" value="${common-solr.dir}/testlogging.properties"/>
-      <sysproperty key="tests.luceneMatchVersion" value="${tests.luceneMatchVersion}"/>
-      <sysproperty key="tests.codec" value="${tests.codec}"/>
-      <sysproperty key="tests.locale" value="${tests.locale}"/>
-      <sysproperty key="tests.timezone" value="${tests.timezone}"/>
-      <sysproperty key="tests.multiplier" value="${tests.multiplier}"/>
-      <sysproperty key="tests.iter" value="${tests.iter}"/>
-      <sysproperty key="tests.seed" value="${tests.seed}"/>
-      <sysproperty key="tests.verbose" value="${tests.verbose}"/>
-      <!-- set whether or not nightly tests should run -->
-      <sysproperty key="tests.nightly" value="${tests.nightly}"/>
-      <sysproperty key="jetty.testMode" value="1"/>
-      <sysproperty key="tempDir" file="${tempDir}"/>
-      <sysproperty key="testmethod" value="${testmethod}"/>
-      <jvmarg line="${args}"/>
-      <formatter classname="${junit.details.formatter}" usefile="false" if="junit.details"/>
-      <classpath refid="test.classpath"/>
-      <assertions>
-        <enable package="org.apache.lucene"/>
-        <enable package="org.apache.solr"/>
-      </assertions>
-      <formatter type="${junit.formatter}"/>
-      <batchtest fork="yes" todir="${junit.output.dir}" if="runall">
-        <fileset dir="src/test/java" includes="${junit.includes}"/>
-      </batchtest>
-      <batchtest fork="yes" todir="${junit.output.dir}" if="testcase">
-        <fileset dir="src/test/java" includes="**/${testcase}.java"/>
-      </batchtest>
-      <batchtest fork="yes" todir="${junit.output.dir}" if="testpackage">
-        <fileset dir="src/test/java" includes="**/${testpackage}/**/Test*.java,**/${testpackage}/**/*Test.java"/>
-      </batchtest>
-      <batchtest fork="yes" todir="${junit.output.dir}" if="testpackageroot">
-        <fileset dir="src/test/java" includes="**/${testpackageroot}/Test*.java,**/${testpackageroot}/*Test.java"/>
-      </batchtest>
-    </junit>
-
-    <fail if="tests.failed">Tests failed!</fail>
-  </target>
-
-  <target name="test-reports"
-          description="Generates HTML test reports.">
-    <mkdir dir="${junit.reports}"/>
-    <junitreport todir="${junit.output.dir}">
-      <fileset dir="${junit.output.dir}">
-        <include name="TEST-*.xml"/>
-      </fileset>
-      <report format="frames" todir="${junit.reports}"/>
-    </junitreport>
-  </target>
-
-  <target name="dist" depends="build">
-    <copy file="build/${fullnamever}.jar" todir="${solr-path}/dist"/>
-  </target>
-
-  <target name="example" depends="build">
-    <!-- :NOOP: this use to copy libs but now we can refer to them by path -->
-  </target>
-
-  <target name="javadoc">
-   	<sequential>
-      <mkdir dir="${build.javadoc}/contrib-${name}"/>
-
-      <path id="javadoc.classpath">
-        <path refid="common.classpath"/>
-      </path>
-
-      <invoke-javadoc
-        destdir="${build.javadoc}/contrib-${name}"
-      	title="${Name} ${version} contrib-${fullnamever} API">
-        <sources>
-          <packageset dir="src/main/java"/>
-        </sources>
-      </invoke-javadoc>
-    </sequential>
-  </target>
+  <property name="src.dir" location="src/main/java"/>
+  <property name="tests.src.dir" location="src/test/java"/>
+  <property name="tests.userdir" location="src/test/resources"/>
 
+  <import file="../contrib-build.xml"/>
 
 </project>
diff --git a/solr/contrib/uima/build.xml b/solr/contrib/uima/build.xml
index 34dbefe..085b96c 100644
--- a/solr/contrib/uima/build.xml
+++ b/solr/contrib/uima/build.xml
@@ -17,173 +17,16 @@
     limitations under the License.
  -->
 
-<project name="solr-uima" default="build">
+<project name="solr-uima" default="default">
 
-  <property name="solr-path" value="../.." />
-
-  <import file="../../common-build.xml"/>
-  
   <description>
     Solr Integration with UIMA for extracting metadata from arbitrary (text) fields and enrich document with features extracted from UIMA types (language, sentences, concepts, named entities, etc.)
   </description>
 
-  <path id="common.classpath">
-    <pathelement location="${solr-path}/build/solr" />
-    <pathelement location="${solr-path}/build/solrj" />
-    <fileset dir="lib" includes="*.jar"/>
-    <fileset dir="${solr-path}/lib" includes="*.jar"/>
-    <path refid="lucene.classpath"/>
-    <pathelement location="${basedir}/src/main/resources" />    
-  </path>
-
-  <path id="test.classpath">
-    <path refid="common.classpath" />
-    <pathelement path="${dest}/classes" />
-    <pathelement path="${dest}/test-classes" />
-    <pathelement location="${solr-path}/build/tests"/> <!-- include solr test code -->
-    <pathelement location="${solr-path}/../lucene/build/classes/test-framework" />  <!-- include some lucene test code -->
-    <pathelement path="${java.class.path}"/>
-  </path>
-
-  <target name="clean">
-    <delete failonerror="false" dir="${dest}"/>
-  </target>
-
-  <target name="init">
-    <mkdir dir="${dest}/classes"/>
-    <mkdir dir="${build.javadoc}" />
-    <subant target="compileTests">
-      <fileset dir="${solr-path}" includes="build.xml"/>
-    </subant>
-    <subant target="make-manifest">
-      <fileset dir="${solr-path}" includes="build.xml"/>
-    </subant>
-  </target>
-
-  <target name="compile" depends="init">
-    <solr-javac destdir="${dest}/classes"
-    classpathref="common.classpath">
-      <src path="src/main/java" />
-    </solr-javac>
-  </target>
-
-  <target name="build" depends="compile">
-    <solr-jar destfile="${dest}/${fullnamever}.jar" basedir="${dest}/classes"
-              manifest="../../${dest}/META-INF/MANIFEST.MF">
-      <fileset dir="src/main/resources" />
-    </solr-jar>
-  </target>
-
-  <target name="compileTests" depends="compile">
-  	<solr-javac destdir="${dest}/test-classes"
-  	                classpathref="test.classpath">
-  	  <src path="src/test/java" />
-  	</solr-javac>
-        <copy todir="${dest}/test-classes">
-          <fileset dir="src/test/resources" excludes="**/*.java"/>
-        </copy>
-  </target>
-
-  <property name="tempDir" value="${junit.output.dir}/temp" />
-
-  <target name="test" depends="compileTests">
-  	<mkdir dir="${junit.output.dir}"/>
-    <!-- <mkdir dir="@{tempDir}/@{pattern}"/> 
-       This is very loud and obnoxious. abuse touch instead for a "quiet" mkdir
-    -->
-  	<touch file="${tempDir}/quiet.ant" verbose="false" mkdirs="true"/>
-
-    <condition property="runall">
-      <not>
-        <or>
-          <isset property="testcase"/>
-          <isset property="testpackage"/>
-          <isset property="testpackageroot"/>
-        </or>
-      </not>
-    </condition>    
-    
-  	<junit printsummary="no"
-           haltonfailure="no"
-           maxmemory="512M"
-           errorProperty="tests.failed"
-           failureProperty="tests.failed"
-           dir="${tempDir}"
-           tempdir="${tempDir}"
-           forkmode="perBatch"
-           >
-      <sysproperty key="java.util.logging.config.file" value="${common-solr.dir}/testlogging.properties"/>
-      <sysproperty key="tests.luceneMatchVersion" value="${tests.luceneMatchVersion}"/>
-      <sysproperty key="tests.codec" value="${tests.codec}"/>
-      <sysproperty key="tests.locale" value="${tests.locale}"/>
-      <sysproperty key="tests.timezone" value="${tests.timezone}"/>
-      <sysproperty key="tests.multiplier" value="${tests.multiplier}"/>
-      <sysproperty key="tests.iter" value="${tests.iter}"/>
-      <sysproperty key="tests.seed" value="${tests.seed}"/>
-      <sysproperty key="jetty.insecurerandom" value="1"/>
-      <sysproperty key="tempDir" file="${tempDir}"/>
-      <sysproperty key="testmethod" value="${testmethod}"/>
-      <jvmarg line="${args}"/>
-      <formatter classname="${junit.details.formatter}" usefile="false" if="junit.details"/>
-      <classpath refid="test.classpath"/>
-      <assertions>
-        <enable package="org.apache.lucene"/>
-        <enable package="org.apache.solr"/>
-      </assertions>
-      <formatter type="${junit.formatter}"/>
-      <batchtest fork="yes" todir="${junit.output.dir}" if="runall">
-        <fileset dir="src/test/java" includes="${junit.includes}"/>
-      </batchtest>
-      <batchtest fork="yes" todir="${junit.output.dir}" if="testcase">
-        <fileset dir="src/test/java" includes="**/${testcase}.java"/>
-      </batchtest>
-      <batchtest fork="yes" todir="${junit.output.dir}" if="testpackage">
-        <fileset dir="src/test/java" includes="**/${testpackage}/**/Test*.java,**/${testpackage}/**/*Test.java"/>
-      </batchtest>
-      <batchtest fork="yes" todir="${junit.output.dir}" if="testpackageroot">
-        <fileset dir="src/test/java" includes="**/${testpackageroot}/Test*.java,**/${testpackageroot}/*Test.java"/>
-      </batchtest>
-    </junit>
-
-    <fail if="tests.failed">Tests failed!</fail>
-  </target>
-
-  <target name="test-reports"
-          description="Generates HTML test reports.">
-    <mkdir dir="${junit.reports}"/>
-    <junitreport todir="${junit.output.dir}">
-      <fileset dir="${junit.output.dir}">
-        <include name="TEST-*.xml"/>
-      </fileset>
-      <report format="frames" todir="${junit.reports}"/>
-    </junitreport>
-  </target>
-
-  <target name="dist" depends="build">
-    <copy file="build/${fullnamever}.jar" todir="${solr-path}/dist"/>
-  </target>
-
-  <target name="example" depends="build">
-    <!-- :NOOP: this use to copy libs but now we can refer to them by path -->
-  </target>
-
-  <target name="javadoc">
-   	<sequential>
-      <mkdir dir="${build.javadoc}/contrib-${name}"/>
-
-      <path id="javadoc.classpath">
-        <path refid="common.classpath"/>
-      </path>
-
-      <invoke-javadoc
-        destdir="${build.javadoc}/contrib-${name}"
-      	title="${Name} ${version} contrib-${fullnamever} API">
-        <sources>
-          <packageset dir="src/main/java"/>
-        </sources>
-      </invoke-javadoc>
-    </sequential>
-  </target>
+  <property name="src.dir" location="src/main/java"/>
+  <property name="tests.src.dir" location="src/test/java"/>
+  <property name="tests.userdir" location="src/test/resources"/>
 
+  <import file="../contrib-build.xml"/>
 
 </project>
diff --git a/solr/src/java/org/apache/solr/util/TestHarness.java b/solr/src/java/org/apache/solr/util/TestHarness.java
deleted file mode 100644
index ea5a703..0000000
--- a/solr/src/java/org/apache/solr/util/TestHarness.java
+++ /dev/null
@@ -1,576 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.util;
-
-import org.apache.solr.common.SolrException;
-import org.apache.solr.common.params.CommonParams;
-import org.apache.solr.common.util.NamedList;
-import org.apache.solr.common.util.XML;
-import org.apache.solr.core.SolrConfig;
-import org.apache.solr.core.SolrCore;
-import org.apache.solr.core.CoreContainer;
-import org.apache.solr.core.CoreDescriptor;
-import org.apache.solr.core.SolrResourceLoader;
-import org.apache.solr.handler.JsonUpdateRequestHandler;
-import org.apache.solr.handler.XmlUpdateRequestHandler;
-import org.apache.solr.request.LocalSolrQueryRequest;
-import org.apache.solr.request.SolrQueryRequest;
-import org.apache.solr.request.SolrRequestHandler;
-import org.apache.solr.request.SolrRequestInfo;
-import org.apache.solr.response.QueryResponseWriter;
-import org.apache.solr.response.SolrQueryResponse;
-import org.apache.solr.schema.IndexSchema;
-import org.apache.solr.servlet.DirectSolrConnection;
-import org.w3c.dom.Document;
-import org.xml.sax.SAXException;
-import org.apache.solr.common.util.NamedList.NamedListEntry;
-
-import javax.xml.parsers.DocumentBuilder;
-import javax.xml.parsers.DocumentBuilderFactory;
-import javax.xml.xpath.XPath;
-import javax.xml.xpath.XPathConstants;
-import javax.xml.xpath.XPathExpressionException;
-import javax.xml.xpath.XPathFactory;
-
-import java.io.ByteArrayInputStream;
-import java.io.IOException;
-import java.io.StringReader;
-import java.io.StringWriter;
-import java.io.UnsupportedEncodingException;
-import java.util.HashMap;
-import java.util.Map;
-
-
-/**
- * This class provides a simple harness that may be useful when
- * writing testcases.
- *
- * <p>
- * This class lives in the main source tree (and not in the test source
- * tree), so that it will be included with even the most minimal solr
- * distribution, in order to encourage plugin writers to create unit 
- * tests for their plugins.
- *
- * @version $Id$
- */
-public class TestHarness {
-  protected CoreContainer container;
-  private SolrCore core;
-  private XPath xpath = XPathFactory.newInstance().newXPath();
-  private DocumentBuilder builder;
-  public XmlUpdateRequestHandler updater;
-        
-  public static SolrConfig createConfig(String confFile) {
-      // set some system properties for use by tests
-      System.setProperty("solr.test.sys.prop1", "propone");
-      System.setProperty("solr.test.sys.prop2", "proptwo");
-      try {
-      return new SolrConfig(confFile);
-      }
-      catch(Exception xany) {
-        throw new RuntimeException(xany);
-      }
-  }
-        
-  /**
-   * Assumes "solrconfig.xml" is the config file to use, and
-   * "schema.xml" is the schema path to use.
-   *
-   * @param dataDirectory path for index data, will not be cleaned up
-   */
-  public TestHarness( String dataDirectory) {
-    this( dataDirectory, "schema.xml");
-  }
-  
-  /**
-   * Assumes "solrconfig.xml" is the config file to use.
-   *
-   * @param dataDirectory path for index data, will not be cleaned up
-   * @param schemaFile path of schema file
-   */
-  public TestHarness( String dataDirectory, String schemaFile) {
-    this( dataDirectory, "solrconfig.xml", schemaFile);
-  }
-  /**
-   * @param dataDirectory path for index data, will not be cleaned up
-   * @param configFile solrconfig filename
-   * @param schemaFile schema filename
-   */
-   public TestHarness( String dataDirectory, String configFile, String schemaFile) {
-     this( dataDirectory, createConfig(configFile), schemaFile);
-   }
-   /**
-    * @param dataDirectory path for index data, will not be cleaned up
-    * @param solrConfig solronfig instance
-    * @param schemaFile schema filename
-    */
-      public TestHarness( String dataDirectory,
-                          SolrConfig solrConfig,
-                          String schemaFile) {
-     this( dataDirectory, solrConfig, new IndexSchema(solrConfig, schemaFile, null));
-   }
-   /**
-    * @param dataDirectory path for index data, will not be cleaned up
-    * @param solrConfig solrconfig instance
-    * @param indexSchema schema instance
-    */
-  public TestHarness( String dataDirectory,
-                      SolrConfig solrConfig,
-                      IndexSchema indexSchema) {
-      this("", new Initializer("", dataDirectory, solrConfig, indexSchema));
-  }
-  
-  public TestHarness(String coreName, CoreContainer.Initializer init) {
-    try {
-      container = init.initialize();
-      if (coreName == null)
-        coreName = "";
-      // get the core & decrease its refcount:
-      // the container holds the core for the harness lifetime
-      core = container.getCore(coreName);
-      if (core != null)
-        core.close();
-      builder = DocumentBuilderFactory.newInstance().newDocumentBuilder();
-      
-      updater = new XmlUpdateRequestHandler();
-      updater.init( null );
-    } catch (Exception e) {
-      throw new RuntimeException(e);
-    }
-  }
-  
-  // Creates a container based on infos needed to create one core
-  static class Initializer extends CoreContainer.Initializer {
-    String coreName;
-    String dataDirectory;
-    SolrConfig solrConfig;
-    IndexSchema indexSchema;
-    public Initializer(String coreName,
-                      String dataDirectory,
-                      SolrConfig solrConfig,
-                      IndexSchema indexSchema) {
-      if (coreName == null)
-        coreName = "";
-      this.coreName = coreName;
-      this.dataDirectory = dataDirectory;
-      this.solrConfig = solrConfig;
-      this.indexSchema = indexSchema;
-    }
-    public String getCoreName() {
-      return coreName;
-    }
-    @Override
-    public CoreContainer initialize() {
-      CoreContainer container = new CoreContainer(new SolrResourceLoader(SolrResourceLoader.locateSolrHome())) {
-        {
-          hostPort = System.getProperty("hostPort");
-          hostContext = "solr";
-          defaultCoreName = "collection1";
-          initZooKeeper(System.getProperty("zkHost"), 10000);
-        }
-      };
-      
-      CoreDescriptor dcore = new CoreDescriptor(container, coreName, solrConfig.getResourceLoader().getInstanceDir());
-      dcore.setConfigName(solrConfig.getResourceName());
-      dcore.setSchemaName(indexSchema.getResourceName());
-      SolrCore core = new SolrCore("collection1", dataDirectory, solrConfig, indexSchema, dcore);
-      container.register(coreName, core, false);
-
-      return container;
-    }
-  }
-  
-  public CoreContainer getCoreContainer() {
-    return container;
-  }
-
-  public SolrCore getCore() {
-    return core;
-  }
-        
-  /**
-   * Processes an "update" (add, commit or optimize) and
-   * returns the response as a String.
-   *
-   * @param xml The XML of the update
-   * @return The XML response to the update
-   */
-  public String update(String xml) {
-    DirectSolrConnection connection = new DirectSolrConnection(core);
-    SolrRequestHandler handler = core.getRequestHandler("/update");
-    // prefer the handler mapped to /update, but use our generic backup handler
-    // if that lookup fails
-    if (handler == null) {
-      handler = updater;
-    }
-    try {
-      return connection.request(handler, null, xml);
-    } catch (SolrException e) {
-      throw (SolrException)e;
-    } catch (Exception e) {
-      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);
-    }
-  }
-  
-        
-  /**
-   * Validates that an "update" (add, commit or optimize) results in success.
-   *
-   * :TODO: currently only deals with one add/doc at a time, this will need changed if/when SOLR-2 is resolved
-   * 
-   * @param xml The XML of the update
-   * @return null if successful, otherwise the XML response to the update
-   */
-  public String validateUpdate(String xml) throws SAXException {
-    return checkUpdateStatus(xml, "0");
-  }
-
-  /**
-   * Validates that an "update" (add, commit or optimize) results in success.
-   *
-   * :TODO: currently only deals with one add/doc at a time, this will need changed if/when SOLR-2 is resolved
-   * 
-   * @param xml The XML of the update
-   * @return null if successful, otherwise the XML response to the update
-   */
-  public String validateErrorUpdate(String xml) throws SAXException {
-    try {
-      return checkUpdateStatus(xml, "1");
-    } catch (SolrException e) {
-      // return ((SolrException)e).getMessage();
-      return null;  // success
-    }
-  }
-
-  /**
-   * Validates that an "update" (add, commit or optimize) results in success.
-   *
-   * :TODO: currently only deals with one add/doc at a time, this will need changed if/when SOLR-2 is resolved
-   * 
-   * @param xml The XML of the update
-   * @return null if successful, otherwise the XML response to the update
-   */
-  public String checkUpdateStatus(String xml, String code) throws SAXException {
-    try {
-      String res = update(xml);
-      String valid = validateXPath(res, "//int[@name='status']="+code );
-      return (null == valid) ? null : res;
-    } catch (XPathExpressionException e) {
-      throw new RuntimeException
-        ("?!? static xpath has bug?", e);
-    }
-  }
-
-    
-  /**
-   * Validates a "query" response against an array of XPath test strings
-   *
-   * @param req the Query to process
-   * @return null if all good, otherwise the first test that fails.
-   * @exception Exception any exception in the response.
-   * @exception IOException if there is a problem writing the XML
-   * @see LocalSolrQueryRequest
-   */
-  public String validateQuery(SolrQueryRequest req, String... tests)
-    throws IOException, Exception {
-                
-    String res = query(req);
-    return validateXPath(res, tests);
-  }
-            
-  /**
-   * Processes a "query" using a user constructed SolrQueryRequest
-   *
-   * @param req the Query to process, will be closed.
-   * @return The XML response to the query
-   * @exception Exception any exception in the response.
-   * @exception IOException if there is a problem writing the XML
-   * @see LocalSolrQueryRequest
-   */
-  public String query(SolrQueryRequest req) throws IOException, Exception {
-    return query(req.getParams().get(CommonParams.QT), req);
-  }
-
-  /**
-   * Processes a "query" using a user constructed SolrQueryRequest, and closes the request at the end.
-   *
-   * @param handler the name of the request handler to process the request
-   * @param req the Query to process, will be closed.
-   * @return The XML response to the query
-   * @exception Exception any exception in the response.
-   * @exception IOException if there is a problem writing the XML
-   * @see LocalSolrQueryRequest
-   */
-  public String query(String handler, SolrQueryRequest req) throws IOException, Exception {
-    try {
-      SolrQueryResponse rsp = new SolrQueryResponse();
-      SolrRequestInfo.setRequestInfo(new SolrRequestInfo(req, rsp));
-      core.execute(core.getRequestHandler(handler),req,rsp);
-      if (rsp.getException() != null) {
-        throw rsp.getException();
-      }
-      StringWriter sw = new StringWriter(32000);
-      QueryResponseWriter responseWriter = core.getQueryResponseWriter(req);
-      responseWriter.write(sw,req,rsp);
-
-      req.close();
-
-      return sw.toString();
-    } finally {
-      req.close();
-      SolrRequestInfo.clearRequestInfo();
-    }
-  }
-
-  /** It is the users responsibility to close the request object when done with it.
-   * This method does not set/clear SolrRequestInfo */
-  public SolrQueryResponse queryAndResponse(String handler, SolrQueryRequest req) throws Exception {
-    SolrQueryResponse rsp = new SolrQueryResponse();
-    core.execute(core.getRequestHandler(handler),req,rsp);
-    if (rsp.getException() != null) {
-      throw rsp.getException();
-    }
-    return rsp;
-  }
-
-
-  /**
-   * A helper method which valides a String against an array of XPath test
-   * strings.
-   *
-   * @param xml The xml String to validate
-   * @param tests Array of XPath strings to test (in boolean mode) on the xml
-   * @return null if all good, otherwise the first test that fails.
-   */
-  public String validateXPath(String xml, String... tests)
-    throws XPathExpressionException, SAXException {
-        
-    if (tests==null || tests.length == 0) return null;
-                
-    Document document=null;
-    try {
-      document = builder.parse(new ByteArrayInputStream
-                               (xml.getBytes("UTF-8")));
-    } catch (UnsupportedEncodingException e1) {
-      throw new RuntimeException("Totally weird UTF-8 exception", e1);
-    } catch (IOException e2) {
-      throw new RuntimeException("Totally weird io exception", e2);
-    }
-                
-    for (String xp : tests) {
-      xp=xp.trim();
-      Boolean bool = (Boolean) xpath.evaluate(xp, document,
-                                              XPathConstants.BOOLEAN);
-
-      if (!bool) {
-        return xp;
-      }
-    }
-    return null;
-                
-  }
-
-  /**
-   * Shuts down and frees any resources
-   */
-  public void close() {
-    if (container != null) {
-      for (SolrCore c : container.getCores()) {
-        if (c.getOpenCount() > 1)
-          throw new RuntimeException("SolrCore.getOpenCount()=="+core.getOpenCount());
-      }      
-    }
-
-    if (container != null) {
-      container.shutdown();
-      container = null;
-    }
-  }
-
-  /**
-   * A helper that creates an xml &lt;doc&gt; containing all of the
-   * fields and values specified
-   *
-   * @param fieldsAndValues 0 and Even numbered args are fields names odds are field values.
-   */
-  public static StringBuffer makeSimpleDoc(String... fieldsAndValues) {
-
-    try {
-      StringWriter w = new StringWriter();
-      w.append("<doc>");
-      for (int i = 0; i < fieldsAndValues.length; i+=2) {
-        XML.writeXML(w, "field", fieldsAndValues[i+1], "name",
-                     fieldsAndValues[i]);
-      }
-      w.append("</doc>");
-      return w.getBuffer();
-    } catch (IOException e) {
-      throw new RuntimeException
-        ("this should never happen with a StringWriter", e);
-    }
-  }
-
-  /**
-   * Generates a delete by query xml string
-   * @param q Query that has not already been xml escaped
-   */
-  public static String deleteByQuery(String q) {
-    return delete("query", q);
-  }
-  /**
-   * Generates a delete by id xml string
-   * @param id ID that has not already been xml escaped
-   */
-  public static String deleteById(String id) {
-    return delete("id", id);
-  }
-        
-  /**
-   * Generates a delete xml string
-   * @param val text that has not already been xml escaped
-   */
-  private static String delete(String deltype, String val) {
-    try {
-      StringWriter r = new StringWriter();
-            
-      r.write("<delete>");
-      XML.writeXML(r, deltype, val);
-      r.write("</delete>");
-            
-      return r.getBuffer().toString();
-    } catch (IOException e) {
-      throw new RuntimeException
-        ("this should never happen with a StringWriter", e);
-    }
-  }
-    
-  /**
-   * Helper that returns an &lt;optimize&gt; String with
-   * optional key/val pairs.
-   *
-   * @param args 0 and Even numbered args are params, Odd numbered args are values.
-   */
-  public static String optimize(String... args) {
-    return simpleTag("optimize", args);
-  }
-
-  private static String simpleTag(String tag, String... args) {
-    try {
-      StringWriter r = new StringWriter();
-
-      // this is annoying
-      if (null == args || 0 == args.length) {
-        XML.writeXML(r, tag, null);
-      } else {
-        XML.writeXML(r, tag, null, (Object[])args);
-      }
-      return r.getBuffer().toString();
-    } catch (IOException e) {
-      throw new RuntimeException
-        ("this should never happen with a StringWriter", e);
-    }
-  }
-    
-  /**
-   * Helper that returns an &lt;commit&gt; String with
-   * optional key/val pairs.
-   *
-   * @param args 0 and Even numbered args are params, Odd numbered args are values.
-   */
-  public static String commit(String... args) {
-    return simpleTag("commit", args);
-  }
-    
-  public LocalRequestFactory getRequestFactory(String qtype,
-                                               int start,
-                                               int limit) {
-    LocalRequestFactory f = new LocalRequestFactory();
-    f.qtype = qtype;
-    f.start = start;
-    f.limit = limit;
-    return f;
-  }
-    
-  /**
-   * 0 and Even numbered args are keys, Odd numbered args are values.
-   */
-  public LocalRequestFactory getRequestFactory(String qtype,
-                                               int start, int limit,
-                                               String... args) {
-    LocalRequestFactory f = getRequestFactory(qtype, start, limit);
-    for (int i = 0; i < args.length; i+=2) {
-      f.args.put(args[i], args[i+1]);
-    }
-    return f;
-        
-  }
-    
-  public LocalRequestFactory getRequestFactory(String qtype,
-                                               int start, int limit,
-                                               Map<String,String> args) {
-
-    LocalRequestFactory f = getRequestFactory(qtype, start, limit);
-    f.args.putAll(args);
-    return f;
-  }
-    
-  /**
-   * A Factory that generates LocalSolrQueryRequest objects using a
-   * specified set of default options.
-   */
-  public class LocalRequestFactory {
-    public String qtype = "standard";
-    public int start = 0;
-    public int limit = 1000;
-    public Map<String,String> args = new HashMap<String,String>();
-    public LocalRequestFactory() {
-    }
-    /**
-     * Creates a LocalSolrQueryRequest based on variable args; for
-     * historical reasons, this method has some peculiar behavior:
-     * <ul>
-     *   <li>If there is a single arg, then it is treated as the "q"
-     *       param, and the LocalSolrQueryRequest consists of that query
-     *       string along with "qt", "start", and "rows" params (based
-     *       on the qtype, start, and limit properties of this factory)
-     *       along with any other default "args" set on this factory.
-     *   </li>
-     *   <li>If there are multiple args, then there must be an even number
-     *       of them, and each pair of args is used as a key=value param in
-     *       the LocalSolrQueryRequest.  <b>NOTE: In this usage, the "qtype",
-     *       "start", "limit", and "args" properties of this factory are
-     *       ignored.</b>
-     *   </li>
-     * </ul>
-     */
-    public LocalSolrQueryRequest makeRequest(String ... q) {
-      if (q.length==1) {
-        return new LocalSolrQueryRequest(TestHarness.this.getCore(),
-                                       q[0], qtype, start, limit, args);
-      }
-      if (q.length%2 != 0) { 
-        throw new RuntimeException("The length of the string array (query arguments) needs to be even");
-      }
-      Map.Entry<String, String> [] entries = new NamedListEntry[q.length / 2];
-      for (int i = 0; i < q.length; i += 2) {
-        entries[i/2] = new NamedListEntry<String>(q[i], q[i+1]);
-      }
-      return new LocalSolrQueryRequest(TestHarness.this.getCore(), new NamedList(entries));
-    }
-  }
-}
diff --git a/solr/src/test-framework/org/apache/solr/BaseDistributedSearchTestCase.java b/solr/src/test-framework/org/apache/solr/BaseDistributedSearchTestCase.java
new file mode 100644
index 0000000..1ec2654
--- /dev/null
+++ b/solr/src/test-framework/org/apache/solr/BaseDistributedSearchTestCase.java
@@ -0,0 +1,638 @@
+package org.apache.solr;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.File;
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collections;
+import java.util.Date;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Map;
+import java.util.Random;
+import java.util.Set;
+
+import junit.framework.TestCase;
+
+import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrServerException;
+import org.apache.solr.client.solrj.embedded.JettySolrRunner;
+import org.apache.solr.client.solrj.impl.CommonsHttpSolrServer;
+import org.apache.solr.client.solrj.response.QueryResponse;
+import org.apache.solr.common.SolrDocument;
+import org.apache.solr.common.SolrDocumentList;
+import org.apache.solr.common.SolrInputDocument;
+import org.apache.solr.common.params.ModifiableSolrParams;
+import org.apache.solr.common.util.NamedList;
+import org.apache.solr.schema.TrieDateField;
+import org.apache.solr.util.AbstractSolrTestCase;
+import org.junit.Test;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * Helper base class for distributed search test cases
+ *
+ * @since solr 1.5
+ */
+public abstract class BaseDistributedSearchTestCase extends SolrTestCaseJ4 {
+  public static Random r = random;
+
+  protected int shardCount = 4;
+  /**
+   * Sub classes can set this flag in their constructor to true if they
+   * want to fix the number of shards to 'shardCount'
+   *
+   * The default is false which means that test will be executed with
+   * 1, 2, 3, ....shardCount number of shards repeatedly
+   */
+  protected boolean fixShardCount = false;
+
+  protected JettySolrRunner controlJetty;
+  protected List<SolrServer> clients = new ArrayList<SolrServer>();
+  protected List<JettySolrRunner> jettys = new ArrayList<JettySolrRunner>();
+  protected String context = "/solr";
+  protected String shards;
+  protected String[] shardsArr;
+  // Some ISPs redirect to their own web site for domains that don't exist, causing this to fail
+  // protected String[] deadServers = {"does_not_exist_54321.com:33331/solr","localhost:33332/solr"};
+  protected String[] deadServers = {"[::1]:33332/solr"};
+  protected File testDir;
+  protected SolrServer controlClient;
+
+  // to stress with higher thread counts and requests, make sure the junit
+  // xml formatter is not being used (all output will be buffered before
+  // transformation to xml and cause an OOM exception).
+  protected int stress = 2;
+  protected boolean verifyStress = true;
+  protected int nThreads = 3;
+
+
+  public static int ORDERED = 1;
+  public static int SKIP = 2;
+  public static int SKIPVAL = 4;
+  public static int UNORDERED = 8;
+
+  protected int flags;
+  protected Map<String, Integer> handle = new HashMap<String, Integer>();
+
+  protected String id = "id";
+  public static Logger log = LoggerFactory.getLogger(BaseDistributedSearchTestCase.class);
+  
+  public static RandVal rint = new RandVal() {
+    @Override
+    public Object val() {
+      return r.nextInt();
+    }
+  };
+
+  public static RandVal rlong = new RandVal() {
+    @Override
+    public Object val() {
+      return r.nextLong();
+    }
+  };
+
+  public static RandVal rfloat = new RandVal() {
+    @Override
+    public Object val() {
+      return r.nextFloat();
+    }
+  };
+
+  public static RandVal rdouble = new RandVal() {
+    @Override
+    public Object val() {
+      return r.nextDouble();
+    }
+  };
+
+  public static RandVal rdate = new RandDate();
+
+  /**
+   * Perform the actual tests here
+   *
+   * @throws Exception on error
+   */
+  public abstract void doTest() throws Exception;
+
+  public static String[] fieldNames = new String[]{"n_ti1", "n_f1", "n_tf1", "n_d1", "n_td1", "n_l1", "n_tl1", "n_dt1", "n_tdt1"};
+  public static RandVal[] randVals = new RandVal[]{rint, rfloat, rfloat, rdouble, rdouble, rlong, rlong, rdate, rdate};
+
+  protected String[] getFieldNames() {
+    return fieldNames;
+  }
+
+  protected RandVal[] getRandValues() {
+    return randVals;
+  }
+
+  /**
+   * Subclasses can override this to change a test's solr home
+   * (default is in test-files)
+   */
+  public String getSolrHome() {
+    return SolrTestCaseJ4.TEST_HOME();
+  }
+  
+  @Override
+  public void setUp() throws Exception {
+    SolrTestCaseJ4.resetExceptionIgnores();  // ignore anything with ignore_exception in it
+    super.setUp();
+    System.setProperty("solr.test.sys.prop1", "propone");
+    System.setProperty("solr.test.sys.prop2", "proptwo");
+    System.setProperty("solr.solr.home", getSolrHome());
+    testDir = new File(TEMP_DIR,
+            getClass().getName() + "-" + System.currentTimeMillis());
+    testDir.mkdirs();
+  }
+
+  @Override
+  public void tearDown() throws Exception {
+    destroyServers();
+    if (!AbstractSolrTestCase.recurseDelete(testDir)) {
+      System.err.println("!!!! WARNING: best effort to remove " + testDir.getAbsolutePath() + " FAILED !!!!!");
+    }
+    super.tearDown();
+  }
+
+  protected void createServers(int numShards) throws Exception {
+    controlJetty = createJetty(testDir, testDir + "/control/data");
+    controlClient = createNewSolrServer(controlJetty.getLocalPort());
+
+    shardsArr = new String[numShards];
+    StringBuilder sb = new StringBuilder();
+    for (int i = 0; i < numShards; i++) {
+      if (sb.length() > 0) sb.append(',');
+      JettySolrRunner j = createJetty(testDir, testDir + "/shard" + i + "/data");
+      jettys.add(j);
+      clients.add(createNewSolrServer(j.getLocalPort()));
+      String shardStr = "localhost:" + j.getLocalPort() + context;
+      shardsArr[i] = shardStr;
+      sb.append(shardStr);
+    }
+
+    shards = sb.toString();
+  }
+
+
+  protected void setDistributedParams(ModifiableSolrParams params) {
+    params.set("shards", getShardsString());
+  }
+
+  protected String getShardsString() {
+    if (deadServers == null) return shards;
+    
+    StringBuilder sb = new StringBuilder();
+    for (String shard : shardsArr) {
+      if (sb.length() > 0) sb.append(',');
+      int nDeadServers = r.nextInt(deadServers.length+1);
+      if (nDeadServers > 0) {
+        List<String> replicas = new ArrayList<String>(Arrays.asList(deadServers));
+        Collections.shuffle(replicas, r);
+        replicas.add(r.nextInt(nDeadServers+1), shard);
+        for (int i=0; i<nDeadServers+1; i++) {
+          if (i!=0) sb.append('|');
+          sb.append(replicas.get(i));
+        }
+      } else {
+        sb.append(shard);
+      }
+    }
+
+    return sb.toString();
+  }
+
+  protected void destroyServers() throws Exception {
+    controlJetty.stop();
+    for (JettySolrRunner jetty : jettys) jetty.stop();
+    clients.clear();
+    jettys.clear();
+  }
+  
+  public JettySolrRunner createJetty(File baseDir, String dataDir) throws Exception {
+    return createJetty(baseDir, dataDir, null, null);
+  }
+
+  public JettySolrRunner createJetty(File baseDir, String dataDir, String shardId) throws Exception {
+    return createJetty(baseDir, dataDir, shardId, null);
+  }
+  
+  public JettySolrRunner createJetty(File baseDir, String dataDir, String shardList, String solrConfigOverride) throws Exception {
+    System.setProperty("solr.data.dir", dataDir);
+    JettySolrRunner jetty = new JettySolrRunner("/solr", 0, solrConfigOverride);
+    if(shardList != null) {
+      System.setProperty("shard", shardList);
+    }
+    jetty.start();
+    System.clearProperty("shard");
+    return jetty;
+  }
+  
+  protected SolrServer createNewSolrServer(int port) {
+    try {
+      // setup the server...
+      String url = "http://localhost:" + port + context;
+      CommonsHttpSolrServer s = new CommonsHttpSolrServer(url);
+      s.setConnectionTimeout(100); // 1/10th sec
+      s.setDefaultMaxConnectionsPerHost(100);
+      s.setMaxTotalConnections(100);
+      return s;
+    }
+    catch (Exception ex) {
+      throw new RuntimeException(ex);
+    }
+  }
+
+  protected void addFields(SolrInputDocument doc, Object... fields) {
+    for (int i = 0; i < fields.length; i += 2) {
+      doc.addField((String) (fields[i]), fields[i + 1]);
+    }
+  }// add random fields to the documet before indexing
+
+  protected void indexr(Object... fields) throws Exception {
+    SolrInputDocument doc = new SolrInputDocument();
+    addFields(doc, fields);
+    addFields(doc, "rnd_b", true);
+    addFields(doc, getRandFields(getFieldNames(), getRandValues()));
+    indexDoc(doc);
+  }
+
+  protected void index(Object... fields) throws Exception {
+    SolrInputDocument doc = new SolrInputDocument();
+    addFields(doc, fields);
+    indexDoc(doc);
+  }
+
+  protected void indexDoc(SolrInputDocument doc) throws IOException, SolrServerException {
+    controlClient.add(doc);
+
+    int which = (doc.getField(id).toString().hashCode() & 0x7fffffff) % clients.size();
+    SolrServer client = clients.get(which);
+    client.add(doc);
+  }
+
+  protected void index_specific(int serverNumber, Object... fields) throws Exception {
+    SolrInputDocument doc = new SolrInputDocument();
+    for (int i = 0; i < fields.length; i += 2) {
+      doc.addField((String) (fields[i]), fields[i + 1]);
+    }
+    controlClient.add(doc);
+
+    SolrServer client = clients.get(serverNumber);
+    client.add(doc);
+  }
+
+  protected void del(String q) throws Exception {
+    controlClient.deleteByQuery(q);
+    for (SolrServer client : clients) {
+      client.deleteByQuery(q);
+    }
+  }// serial commit...
+
+  protected void commit() throws Exception {
+    controlClient.commit();
+    for (SolrServer client : clients) client.commit();
+  }
+
+  protected QueryResponse queryServer(ModifiableSolrParams params) throws SolrServerException {
+    // query a random server
+    int which = r.nextInt(clients.size());
+    SolrServer client = clients.get(which);
+    QueryResponse rsp = client.query(params);
+    return rsp;
+  }
+
+  protected void query(Object... q) throws Exception {
+    final ModifiableSolrParams params = new ModifiableSolrParams();
+
+    for (int i = 0; i < q.length; i += 2) {
+      params.add(q[i].toString(), q[i + 1].toString());
+    }
+
+    final QueryResponse controlRsp = controlClient.query(params);
+
+    setDistributedParams(params);
+
+    QueryResponse rsp = queryServer(params);
+
+    compareResponses(rsp, controlRsp);
+
+    if (stress > 0) {
+      log.info("starting stress...");
+      Thread[] threads = new Thread[nThreads];
+      for (int i = 0; i < threads.length; i++) {
+        threads[i] = new Thread() {
+          @Override
+          public void run() {
+            for (int j = 0; j < stress; j++) {
+              int which = r.nextInt(clients.size());
+              SolrServer client = clients.get(which);
+              try {
+                QueryResponse rsp = client.query(new ModifiableSolrParams(params));
+                if (verifyStress) {
+                  compareResponses(rsp, controlRsp);
+                }
+              } catch (SolrServerException e) {
+                throw new RuntimeException(e);
+              }
+            }
+          }
+        };
+        threads[i].start();
+      }
+
+      for (Thread thread : threads) {
+        thread.join();
+      }
+    }
+  }
+
+  public static boolean eq(String a, String b) {
+    return a == b || (a != null && a.equals(b));
+  }
+
+  public static int flags(Map<String, Integer> handle, Object key) {
+    if (handle == null) return 0;
+    Integer f = handle.get(key);
+    return f == null ? 0 : f;
+  }
+
+  public static String compare(NamedList a, NamedList b, int flags, Map<String, Integer> handle) {
+    boolean ordered = (flags & UNORDERED) == 0;
+
+    int posa = 0, posb = 0;
+    int aSkipped = 0, bSkipped = 0;
+
+    for (; ;) {
+      if (posa >= a.size() || posb >= b.size()) {
+        break;
+      }
+
+      String namea, nameb;
+      Object vala, valb = null;
+
+      int flagsa, flagsb;
+      for (; ;) {
+        namea = a.getName(posa);
+        vala = a.getVal(posa);
+        posa++;
+        flagsa = flags(handle, namea);
+        if ((flagsa & SKIP) != 0) {
+          aSkipped++;
+          continue;
+        }
+        break;
+      }
+
+      if (!ordered) posb = 0;  // reset if not ordered
+
+      while (posb < b.size()) {
+        nameb = b.getName(posb);
+        valb = b.getVal(posb);
+        posb++;
+        flagsb = flags(handle, nameb);
+        if ((flagsb & SKIP) != 0) {
+          bSkipped++;
+          continue;
+        }
+        if (eq(namea, nameb)) {
+          break;
+        }
+        if (ordered) {
+          return "." + namea + "!=" + nameb + " (unordered or missing)";
+        }
+        // if unordered, continue until we find the right field.
+      }
+
+      // ok, namea and nameb should be equal here already.
+      if ((flagsa & SKIPVAL) != 0) continue;  // keys matching is enough
+
+      String cmp = compare(vala, valb, flagsa, handle);
+      if (cmp != null) return "." + namea + cmp;
+    }
+
+
+    if (a.size() - aSkipped != b.size() - bSkipped) {
+      return ".size()==" + a.size() + "," + b.size() + "skipped=" + aSkipped + "," + bSkipped;
+    }
+
+    return null;
+  }
+
+  public static String compare1(Map a, Map b, int flags, Map<String, Integer> handle) {
+    String cmp;
+
+    for (Object keya : a.keySet()) {
+      Object vala = a.get(keya);
+      int flagsa = flags(handle, keya);
+      if ((flagsa & SKIP) != 0) continue;
+      if (!b.containsKey(keya)) {
+        return "[" + keya + "]==null";
+      }
+      if ((flagsa & SKIPVAL) != 0) continue;
+      Object valb = b.get(keya);
+      cmp = compare(vala, valb, flagsa, handle);
+      if (cmp != null) return "[" + keya + "]" + cmp;
+    }
+    return null;
+  }
+
+  public static String compare(Map a, Map b, int flags, Map<String, Integer> handle) {
+    String cmp;
+    cmp = compare1(a, b, flags, handle);
+    if (cmp != null) return cmp;
+    return compare1(b, a, flags, handle);
+  }
+
+  public static String compare(SolrDocument a, SolrDocument b, int flags, Map<String, Integer> handle) {
+    return compare(a.getFieldValuesMap(), b.getFieldValuesMap(), flags, handle);
+  }
+
+  public static String compare(SolrDocumentList a, SolrDocumentList b, int flags, Map<String, Integer> handle) {
+    boolean ordered = (flags & UNORDERED) == 0;
+
+    String cmp;
+    int f = flags(handle, "maxScore");
+    if ((f & SKIPVAL) == 0) {
+      cmp = compare(a.getMaxScore(), b.getMaxScore(), 0, handle);
+      if (cmp != null) return ".maxScore" + cmp;
+    } else {
+      if (b.getMaxScore() != null) {
+        if (a.getMaxScore() == null) {
+          return ".maxScore missing";
+        }
+      }
+    }
+
+    cmp = compare(a.getNumFound(), b.getNumFound(), 0, handle);
+    if (cmp != null) return ".numFound" + cmp;
+
+    cmp = compare(a.getStart(), b.getStart(), 0, handle);
+    if (cmp != null) return ".start" + cmp;
+
+    cmp = compare(a.size(), b.size(), 0, handle);
+    if (cmp != null) return ".size()" + cmp;
+
+    // only for completely ordered results (ties might be in a different order)
+    if (ordered) {
+      for (int i = 0; i < a.size(); i++) {
+        cmp = compare(a.get(i), b.get(i), 0, handle);
+        if (cmp != null) return "[" + i + "]" + cmp;
+      }
+      return null;
+    }
+
+    // unordered case
+    for (int i = 0; i < a.size(); i++) {
+      SolrDocument doc = a.get(i);
+      Object key = doc.getFirstValue("id");
+      SolrDocument docb = null;
+      if (key == null) {
+        // no id field to correlate... must compare ordered
+        docb = b.get(i);
+      } else {
+        for (int j = 0; j < b.size(); j++) {
+          docb = b.get(j);
+          if (key.equals(docb.getFirstValue("id"))) break;
+        }
+      }
+      // if (docb == null) return "[id="+key+"]";
+      cmp = compare(doc, docb, 0, handle);
+      if (cmp != null) return "[id=" + key + "]" + cmp;
+    }
+    return null;
+  }
+
+  public static String compare(Object[] a, Object[] b, int flags, Map<String, Integer> handle) {
+    if (a.length != b.length) {
+      return ".length:" + a.length + "!=" + b.length;
+    }
+    for (int i = 0; i < a.length; i++) {
+      String cmp = compare(a[i], b[i], flags, handle);
+      if (cmp != null) return "[" + i + "]" + cmp;
+    }
+    return null;
+  }
+
+  public static String compare(Object a, Object b, int flags, Map<String, Integer> handle) {
+    if (a == b) return null;
+    if (a == null || b == null) return ":" + a + "!=" + b;
+
+    if (a instanceof NamedList && b instanceof NamedList) {
+      return compare((NamedList) a, (NamedList) b, flags, handle);
+    }
+
+    if (a instanceof SolrDocumentList && b instanceof SolrDocumentList) {
+      return compare((SolrDocumentList) a, (SolrDocumentList) b, flags, handle);
+    }
+
+    if (a instanceof SolrDocument && b instanceof SolrDocument) {
+      return compare((SolrDocument) a, (SolrDocument) b, flags, handle);
+    }
+
+    if (a instanceof Map && b instanceof Map) {
+      return compare((Map) a, (Map) b, flags, handle);
+    }
+
+    if (a instanceof Object[] && b instanceof Object[]) {
+      return compare((Object[]) a, (Object[]) b, flags, handle);
+    }
+
+    if (a instanceof byte[] && b instanceof byte[]) {
+      if (!Arrays.equals((byte[]) a, (byte[]) b)) {
+        return ":" + a + "!=" + b;
+      }
+      return null;
+    }
+
+    if (a instanceof List && b instanceof List) {
+      return compare(((List) a).toArray(), ((List) b).toArray(), flags, handle);
+
+    }
+
+    if (!(a.equals(b))) {
+      return ":" + a + "!=" + b;
+    }
+
+    return null;
+  }
+
+  protected void compareResponses(QueryResponse a, QueryResponse b) {
+    String cmp;
+    cmp = compare(a.getResponse(), b.getResponse(), flags, handle);
+    if (cmp != null) {
+      log.info("Mismatched responses:\n" + a + "\n" + b);
+      TestCase.fail(cmp);
+    }
+  }
+
+  @Test
+  public void testDistribSearch() throws Exception {
+    if (fixShardCount) {
+      createServers(shardCount);
+      RandVal.uniqueValues = new HashSet(); //reset random values
+      doTest();
+      destroyServers();
+    } else {
+      for (int nServers = 1; nServers < shardCount; nServers++) {
+        createServers(nServers);
+        RandVal.uniqueValues = new HashSet(); //reset random values
+        doTest();
+        destroyServers();
+      }
+    }
+  }
+
+  public static Object[] getRandFields(String[] fields, RandVal[] randVals) {
+    Object[] o = new Object[fields.length * 2];
+    for (int i = 0; i < fields.length; i++) {
+      o[i * 2] = fields[i];
+      o[i * 2 + 1] = randVals[i].uval();
+    }
+    return o;
+  }
+
+  public static abstract class RandVal {
+    public static Random r = random;
+    public static Set uniqueValues = new HashSet();
+
+    public abstract Object val();
+
+    public Object uval() {
+      for (; ;) {
+        Object v = val();
+        if (uniqueValues.add(v)) return v;
+      }
+    }
+  }
+
+  public static class RandDate extends RandVal {
+    public static TrieDateField df = new TrieDateField();
+
+    @Override
+    public Object val() {
+      long v = r.nextLong();
+      Date d = new Date(v);
+      return df.toExternal(d);
+    }
+  }
+}
diff --git a/solr/src/test-framework/org/apache/solr/JSONTestUtil.java b/solr/src/test-framework/org/apache/solr/JSONTestUtil.java
new file mode 100644
index 0000000..8bd5a79
--- /dev/null
+++ b/solr/src/test-framework/org/apache/solr/JSONTestUtil.java
@@ -0,0 +1,346 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr;
+
+import org.apache.noggit.ObjectBuilder;
+import org.apache.solr.common.util.StrUtils;
+
+import java.util.*;
+
+
+public class JSONTestUtil {
+
+  public static String match(String input, String pathAndExpected) throws Exception {
+    int pos = pathAndExpected.indexOf("==");
+    String path = pos>=0 ? pathAndExpected.substring(0,pos) : null;
+    String expected = pos>=0 ? pathAndExpected.substring(pos+2) : pathAndExpected;
+    return match(path, input, expected);
+  }
+
+  public static String match(String path, String input, String expected) throws Exception {
+    Object inputObj = ObjectBuilder.fromJSON(input);
+    Object expectObj = ObjectBuilder.fromJSON(expected);
+    return matchObj(path, inputObj, expectObj);
+  }
+
+  /**
+  public static Object fromJSON(String json) {
+    try {
+      Object out = ObjectBuilder.fromJSON(json);
+    } finally {
+
+  }
+  **/
+  
+  public static String matchObj(String path, Object input, Object expected) throws Exception {
+    CollectionTester tester = new CollectionTester(input);
+    boolean reversed = path.startsWith("!");
+    String positivePath = reversed ? path.substring(1) : path;
+    if (!tester.seek(positivePath) ^ reversed) {
+      return "Path not found: " + path;
+    }
+    if (expected != null && (!tester.match(expected) ^ reversed)) {
+      return tester.err + " @ " + tester.getPath();
+    }
+    return null;
+  }
+}
+
+
+/** Tests simple object graphs, like those generated by the noggit JSON parser */
+class CollectionTester {
+  public Object valRoot;
+  public Object val;
+  public Object expectedRoot;
+  public Object expected;
+  public List<Object> path;
+  public String err;
+
+  public CollectionTester(Object val) {
+    this.val = val;
+    this.valRoot = val;
+    path = new ArrayList<Object>();
+  }
+
+  public String getPath() {
+    StringBuilder sb = new StringBuilder();
+    boolean first=true;
+    for (Object seg : path) {
+      if (seg==null) break;
+      if (!first) sb.append('/');
+      else first=false;
+
+      if (seg instanceof Integer) {
+        sb.append('[');
+        sb.append(seg);
+        sb.append(']');
+      } else {
+        sb.append(seg.toString());
+      }
+    }
+    return sb.toString();
+  }
+
+  void setPath(Object lastSeg) {
+    path.set(path.size()-1, lastSeg);
+  }
+  Object popPath() {
+    return path.remove(path.size()-1);
+  }
+  void pushPath(Object lastSeg) {
+    path.add(lastSeg);
+  }
+
+  void setErr(String msg) {
+    err = msg;
+  }
+
+  public boolean match(Object expected) {
+    this.expectedRoot = expected;
+    this.expected = expected;
+    return match();
+  }
+
+  boolean match() {
+    if (expected == val) {
+      return true;
+    }
+    if (expected == null || val == null) {
+      setErr("mismatch: '" + expected + "'!='" + val + "'");
+      return false;
+    }
+    if (expected instanceof List) {
+      return matchList();
+    }
+    if (expected instanceof Map) {
+      return matchMap();
+    }
+
+    // generic fallback
+    if (!expected.equals(val)) {
+
+      // make an exception for some numerics
+      if ((expected instanceof Integer && val instanceof Long || expected instanceof Long && val instanceof Integer)
+          && ((Number)expected).longValue() == ((Number)val).longValue())
+      {
+        return true;
+      } else if ((expected instanceof Float && val instanceof Double || expected instanceof Double && val instanceof Float)) {
+        double a = ((Number)expected).doubleValue();
+        double b = ((Number)val).doubleValue();
+        if (Double.compare(a,b) == 0) return true;
+        if (Math.abs(a-b) < 1e-5) return true;
+        return false;
+      } else {
+        setErr("mismatch: '" + expected + "'!='" + val + "'");
+        return false;
+      }
+    }
+
+    // setErr("unknown expected type " + expected.getClass().getName());
+    return true;
+  }
+
+  boolean matchList() {
+    List expectedList = (List)expected;
+    List v = asList();
+    if (v == null) return false;
+    int a = 0;
+    int b = 0;
+    pushPath(null);
+    for (;;) {
+      if (a >= expectedList.size() &&  b >=v.size()) {
+        break;
+      }
+
+      if (a >= expectedList.size() || b >=v.size()) {
+        popPath();
+        setErr("List size mismatch");
+        return false;
+      }
+
+      expected = expectedList.get(a);
+      val = v.get(b);
+      setPath(b);
+      if (!match()) return false;
+
+      a++; b++;
+    }
+    
+    popPath();
+    return true;
+  }
+
+  private static Set<String> reserved = new HashSet<String>(Arrays.asList("_SKIP_","_MATCH_","_ORDERED_","_UNORDERED_"));
+
+  boolean matchMap() {
+    Map<String,Object> expectedMap = (Map<String,Object>)expected;
+    Map<String,Object> v = asMap();
+    if (v == null) return false;
+
+    boolean ordered = false;
+    String skipList = (String)expectedMap.get("_SKIP_");
+    String matchList = (String)expectedMap.get("_MATCH_");
+    Object orderedStr = expectedMap.get("_ORDERED_");
+    Object unorderedStr = expectedMap.get("_UNORDERED_");
+
+    if (orderedStr != null) ordered = true;
+    if (unorderedStr != null) ordered = false;
+
+    Set<String> match = null;
+    if (matchList != null) {
+      match = new HashSet(StrUtils.splitSmart(matchList,",",false));
+    }
+
+    Set<String> skips = null;
+    if (skipList != null) {
+      skips = new HashSet(StrUtils.splitSmart(skipList,",",false));
+    }
+
+    Set<String> keys = match != null ? match : expectedMap.keySet();
+    Set<String> visited = new HashSet<String>();
+
+    Iterator<Map.Entry<String,Object>> iter = ordered ? v.entrySet().iterator() : null;
+
+    int numExpected=0;
+
+    pushPath(null);
+    for (String expectedKey : keys) {
+      if (reserved.contains(expectedKey)) continue;
+      numExpected++;
+
+      setPath(expectedKey);
+      if (!v.containsKey(expectedKey)) {
+        popPath();
+        setErr("expected key '" + expectedKey + "'");
+        return false;
+      }
+
+      expected = expectedMap.get(expectedKey);
+
+      if (ordered) {
+        Map.Entry<String,Object> entry;
+        String foundKey;
+        for(;;) {
+          if (!iter.hasNext()) {
+            popPath();
+            setErr("expected key '" + expectedKey + "' in ordered map");
+            return false;           
+          }
+          entry = iter.next();
+          foundKey = entry.getKey();
+          if (skips != null && skips.contains(foundKey))continue;
+          if (match != null && !match.contains(foundKey)) continue;
+          break;
+        }
+
+        if (!entry.getKey().equals(expectedKey)) {
+          popPath();          
+          setErr("expected key '" + expectedKey + "' instead of '"+entry.getKey()+"' in ordered map");
+          return false;
+        }
+        val = entry.getValue();
+      } else {
+        if (skips != null && skips.contains(expectedKey)) continue;
+        val = v.get(expectedKey);
+      }
+
+      if (!match()) return false;
+    }
+
+    popPath();
+
+    // now check if there were any extra keys in the value (as long as there wasn't a specific list to include)
+    if (match == null) {
+      int skipped = 0;
+      if (skips != null) {
+        for (String skipStr : skips)
+          if (v.containsKey(skipStr)) skipped++;
+      }
+      if (numExpected != (v.size() - skipped)) {
+        HashSet<String> set = new HashSet<String>(v.keySet());
+        set.removeAll(expectedMap.keySet());
+        setErr("unexpected map keys " + set); 
+        return false;
+      }
+    }
+
+    return true;
+  }
+
+  public boolean seek(String seekPath) {
+    if (path == null) return true;
+    if (seekPath.startsWith("/")) {
+      seekPath = seekPath.substring(1);
+    }
+    if (seekPath.endsWith("/")) {
+      seekPath = seekPath.substring(0,seekPath.length()-1);
+    }
+    List<String> pathList = StrUtils.splitSmart(seekPath, "/", false);
+    return seek(pathList);
+  }
+
+  List asList() {
+    // TODO: handle native arrays
+    if (val instanceof List) {
+      return (List)val;
+    }
+    setErr("expected List");
+    return null;
+  }
+  
+  Map<String,Object> asMap() {
+    // TODO: handle NamedList
+    if (val instanceof Map) {
+      return (Map<String,Object>)val;
+    }
+    setErr("expected Map");
+    return null;
+  }
+
+  public boolean seek(List<String> seekPath) {
+    if (seekPath.size() == 0) return true;
+    String seg = seekPath.get(0);
+
+    if (seg.charAt(0)=='[') {
+      List listVal = asList();
+      if (listVal==null) return false;
+
+      int arrIdx = Integer.parseInt(seg.substring(1, seg.length()-1));
+
+      if (arrIdx >= listVal.size()) return false;
+
+      val = listVal.get(arrIdx);
+      pushPath(arrIdx);
+    } else {
+      Map<String,Object> mapVal = asMap();
+      if (mapVal==null) return false;
+
+      // use containsKey rather than get to handle null values
+      if (!mapVal.containsKey(seg)) return false;
+
+      val = mapVal.get(seg);
+      pushPath(seg);
+    }
+
+    // recurse after removing head of the path
+    return seek(seekPath.subList(1,seekPath.size()));
+  }
+
+
+
+}
diff --git a/solr/src/test-framework/org/apache/solr/SolrTestCaseJ4.java b/solr/src/test-framework/org/apache/solr/SolrTestCaseJ4.java
new file mode 100755
index 0000000..da5d837
--- /dev/null
+++ b/solr/src/test-framework/org/apache/solr/SolrTestCaseJ4.java
@@ -0,0 +1,1071 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+
+package org.apache.solr;
+
+
+import org.apache.lucene.util.LuceneTestCase;
+import org.apache.noggit.CharArr;
+import org.apache.noggit.JSONUtil;
+import org.apache.noggit.ObjectBuilder;
+import org.apache.solr.common.SolrException;
+import org.apache.solr.common.SolrInputDocument;
+import org.apache.solr.common.SolrInputField;
+import org.apache.solr.common.params.CommonParams;
+import org.apache.solr.common.params.ModifiableSolrParams;
+import org.apache.solr.common.params.SolrParams;
+import org.apache.solr.common.util.XML;
+import org.apache.solr.core.SolrConfig;
+import org.apache.solr.core.SolrCore;
+import org.apache.solr.handler.JsonUpdateRequestHandler;
+import org.apache.solr.request.LocalSolrQueryRequest;
+import org.apache.solr.request.SolrQueryRequest;
+import org.apache.solr.request.SolrRequestHandler;
+import org.apache.solr.schema.IndexSchema;
+import org.apache.solr.schema.SchemaField;
+import org.apache.solr.search.SolrIndexSearcher;
+import org.apache.solr.servlet.DirectSolrConnection;
+import org.apache.solr.util.TestHarness;
+import org.junit.AfterClass;
+import org.junit.BeforeClass;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.xml.sax.SAXException;
+
+import javax.xml.xpath.XPathExpressionException;
+import java.io.File;
+import java.io.IOException;
+import java.io.StringWriter;
+import java.util.*;
+
+/**
+ * A junit4 Solr test harness that extends LuceneTestCaseJ4.
+ * Unlike AbstractSolrTestCase, a new core is not created for each test method.
+ *
+ */
+public abstract class SolrTestCaseJ4 extends LuceneTestCase {
+
+  @BeforeClass
+  public static void beforeClassSolrTestCase() throws Exception {
+    ignoreException("ignore_exception");
+  }
+
+  @AfterClass
+  public static void afterClassSolrTestCase() throws Exception {
+    deleteCore();
+    resetExceptionIgnores();
+  }
+
+  @Override
+  public void setUp() throws Exception {
+    super.setUp();
+    log.info("###Starting " + getName());  // returns <unknown>???
+  }
+
+  @Override
+  public void tearDown() throws Exception {
+    log.info("###Ending " + getName());    
+    super.tearDown();
+  }
+
+  /** Call initCore in @BeforeClass to instantiate a solr core in your test class.
+   * deleteCore will be called for you via SolrTestCaseJ4 @AfterClass */
+  public static void initCore(String config, String schema) throws Exception {
+    initCore(config, schema, TEST_HOME());
+  }
+
+  /** Call initCore in @BeforeClass to instantiate a solr core in your test class.
+   * deleteCore will be called for you via SolrTestCaseJ4 @AfterClass */
+  public static void initCore(String config, String schema, String solrHome) throws Exception {
+    startTrackingSearchers();
+    configString = config;
+    schemaString = schema;
+    if (solrHome != null) {
+      System.setProperty("solr.solr.home", solrHome);
+    }
+    initCore();
+  }
+
+
+  static long numOpens;
+  static long numCloses;
+  protected static void startTrackingSearchers() {
+    numOpens = SolrIndexSearcher.numOpens.get();
+    numCloses = SolrIndexSearcher.numCloses.get();
+  }
+
+  protected static void endTrackingSearchers() {
+     long endNumOpens = SolrIndexSearcher.numOpens.get();
+     long endNumCloses = SolrIndexSearcher.numCloses.get();
+
+     if (endNumOpens-numOpens != endNumCloses-numCloses) {
+       String msg = "ERROR: SolrIndexSearcher opens=" + (endNumOpens-numOpens) + " closes=" + (endNumCloses-numCloses);
+       log.error(msg);
+       fail(msg);
+     }
+  }
+
+  /** Causes an exception matching the regex pattern to not be logged. */
+  public static void ignoreException(String pattern) {
+    if (SolrException.ignorePatterns == null)
+      SolrException.ignorePatterns = new HashSet<String>();
+    SolrException.ignorePatterns.add(pattern);
+  }
+
+  public static void resetExceptionIgnores() {
+    SolrException.ignorePatterns = null;
+    ignoreException("ignore_exception");  // always ignore "ignore_exception"    
+  }
+
+  protected static String getClassName() {
+    StackTraceElement[] stack = new RuntimeException("WhoAmI").fillInStackTrace().getStackTrace();
+    for (int i = stack.length-1; i>=0; i--) {
+      StackTraceElement ste = stack[i];
+      String cname = ste.getClassName();
+      if (cname.indexOf(".lucene.")>=0 || cname.indexOf(".solr.")>=0) {
+        return cname;
+      }
+    }
+    return SolrTestCaseJ4.class.getName();
+  }
+
+  protected static String getSimpleClassName() {
+    String cname = getClassName();
+    return cname.substring(cname.lastIndexOf('.')+1);
+  }
+
+  protected static String configString;
+  protected static String schemaString;
+
+  protected static SolrConfig solrConfig;
+  /**
+   * Harness initialized by initTestHarness.
+   *
+   * <p>
+   * For use in test methods as needed.
+   * </p>
+   */
+  protected static TestHarness h;
+  /**
+   * LocalRequestFactory initialized by initTestHarness using sensible
+   * defaults.
+   *
+   * <p>
+   * For use in test methods as needed.
+   * </p>
+   */
+  protected static TestHarness.LocalRequestFactory lrf;
+
+
+  /**
+   * Subclasses must define this method to return the name of the
+   * schema.xml they wish to use.
+   */
+  public static  String getSchemaFile() {
+    return schemaString;
+  };
+
+  /**
+   * Subclasses must define this method to return the name of the
+   * solrconfig.xml they wish to use.
+   */
+  public static  String getSolrConfigFile() {
+    return configString;
+  };
+
+  /**
+   * The directory used to story the index managed by the TestHarness h
+   */
+  protected static File dataDir;
+
+  /**
+   * Initializes things your test might need
+   *
+   * <ul>
+   * <li>Creates a dataDir in the "java.io.tmpdir"</li>
+   * <li>initializes the TestHarness h using this data directory, and getSchemaPath()</li>
+   * <li>initializes the LocalRequestFactory lrf using sensible defaults.</li>
+   * </ul>
+   *
+   */
+
+  public static Logger log = LoggerFactory.getLogger(SolrTestCaseJ4.class);
+
+  private static String factoryProp;
+
+  public static void createTempDir() {
+    String cname = getSimpleClassName();
+    dataDir = new File(TEMP_DIR,
+            "solrtest-" + cname + "-" + System.currentTimeMillis());
+    dataDir.mkdirs();
+  }
+
+  public static void initCore() throws Exception {
+    log.info("####initCore");
+
+    ignoreException("ignore_exception");
+    factoryProp = System.getProperty("solr.directoryFactory");
+    if (factoryProp == null) {
+      System.setProperty("solr.directoryFactory","solr.RAMDirectoryFactory");
+    }
+    if (dataDir == null) {
+      createTempDir();
+    }
+
+    // other  methods like starting a jetty instance need these too
+    System.setProperty("solr.test.sys.prop1", "propone");
+    System.setProperty("solr.test.sys.prop2", "proptwo");
+
+    String configFile = getSolrConfigFile();
+    if (configFile != null) {
+
+      solrConfig = h.createConfig(getSolrConfigFile());
+      h = new TestHarness( dataDir.getAbsolutePath(),
+              solrConfig,
+              getSchemaFile());
+      lrf = h.getRequestFactory
+              ("standard",0,20,CommonParams.VERSION,"2.2");
+    }
+    log.info("####initCore end");
+  }
+
+  /** Subclasses that override setUp can optionally call this method
+   * to log the fact that their setUp process has ended.
+   */
+  public void postSetUp() {
+    log.info("####POSTSETUP " + getName());
+  }
+
+
+  /** Subclasses that override tearDown can optionally call this method
+   * to log the fact that the tearDown process has started.  This is necessary
+   * since subclasses will want to call super.tearDown() at the *end* of their
+   * tearDown method.
+   */
+  public void preTearDown() {
+    log.info("####PRETEARDOWN " + getName());
+  }
+
+  /**
+   * Shuts down the test harness, and makes the best attempt possible
+   * to delete dataDir, unless the system property "solr.test.leavedatadir"
+   * is set.
+   */
+  public static void deleteCore() throws Exception {
+    log.info("###deleteCore" );
+    if (h != null) { h.close(); }
+    if (dataDir != null) {
+      String skip = System.getProperty("solr.test.leavedatadir");
+      if (null != skip && 0 != skip.trim().length()) {
+        System.err.println("NOTE: per solr.test.leavedatadir, dataDir will not be removed: " + dataDir.getAbsolutePath());
+      } else {
+        if (!recurseDelete(dataDir)) {
+          System.err.println("!!!! WARNING: best effort to remove " + dataDir.getAbsolutePath() + " FAILED !!!!!");
+        }
+      }
+    }
+
+    if (factoryProp == null) {
+      System.clearProperty("solr.directoryFactory");
+    }
+    
+    dataDir = null;
+    solrConfig = null;
+    h = null;
+    lrf = null;
+    configString = schemaString = null;
+
+    endTrackingSearchers();
+  }
+
+
+  /** Validates an update XML String is successful
+   */
+  public static void assertU(String update) {
+    assertU(null, update);
+  }
+
+  /** Validates an update XML String is successful
+   */
+  public static void assertU(String message, String update) {
+    checkUpdateU(message, update, true);
+  }
+
+  /** Validates an update XML String failed
+   */
+  public static void assertFailedU(String update) {
+    assertFailedU(null, update);
+  }
+
+  /** Validates an update XML String failed
+   */
+  public static void assertFailedU(String message, String update) {
+    checkUpdateU(message, update, false);
+  }
+
+  /** Checks the success or failure of an update message
+   */
+  private static void checkUpdateU(String message, String update, boolean shouldSucceed) {
+    try {
+      String m = (null == message) ? "" : message + " ";
+      if (shouldSucceed) {
+           String res = h.validateUpdate(update);
+         if (res != null) fail(m + "update was not successful: " + res);
+      } else {
+           String res = h.validateErrorUpdate(update);
+         if (res != null) fail(m + "update succeeded, but should have failed: " + res);
+      }
+    } catch (SAXException e) {
+      throw new RuntimeException("Invalid XML", e);
+    }
+  }
+
+  /** Validates a query matches some XPath test expressions and closes the query */
+  public static void assertQ(SolrQueryRequest req, String... tests) {
+    assertQ(null, req, tests);
+  }
+
+  /** Validates a query matches some XPath test expressions and closes the query */
+  public static void assertQ(String message, SolrQueryRequest req, String... tests) {
+    try {
+      String m = (null == message) ? "" : message + " ";
+      String response = h.query(req);
+
+      if (req.getParams().getBool("facet", false)) {
+        // add a test to ensure that faceting did not throw an exception
+        // internally, where it would be added to facet_counts/exception
+        String[] allTests = new String[tests.length+1];
+        System.arraycopy(tests,0,allTests,1,tests.length);
+        allTests[0] = "*[count(//lst[@name='facet_counts']/*[@name='exception'])=0]";
+        tests = allTests;
+      }
+
+      String results = h.validateXPath(response, tests);
+
+      if (null != results) {
+        String msg = "REQUEST FAILED: xpath=" + results
+            + "\n\txml response was: " + response
+            + "\n\trequest was:" + req.getParamString();
+
+        log.error(msg);
+        throw new RuntimeException(msg);
+      }
+
+    } catch (XPathExpressionException e1) {
+      throw new RuntimeException("XPath is invalid", e1);
+    } catch (Exception e2) {
+      SolrException.log(log,"REQUEST FAILED: " + req.getParamString(), e2);
+      throw new RuntimeException("Exception during query", e2);
+    }
+  }
+
+  /** Validates a query matches some JSON test expressions and closes the query.
+   * The text expression is of the form path:JSON.  To facilitate easy embedding
+   * in Java strings, the JSON can have double quotes replaced with single quotes.
+   *
+   * Please use this with care: this makes it easy to match complete structures, but doing so
+   * can result in fragile tests if you are matching more than what you want to test.
+   *
+   **/
+  public static void assertJQ(SolrQueryRequest req, String... tests) throws Exception {
+    SolrParams params =  null;
+    try {
+      params = req.getParams();
+      if (!"json".equals(params.get("wt","xml")) || params.get("indent")==null) {
+        ModifiableSolrParams newParams = new ModifiableSolrParams(params);
+        newParams.set("wt","json");
+        if (params.get("indent")==null) newParams.set("indent","true");
+        req.setParams(newParams);
+      }
+
+      String response;
+      boolean failed=true;
+      try {
+        response = h.query(req);
+        failed = false;
+      } finally {
+        if (failed) {
+          log.error("REQUEST FAILED: " + req.getParamString());
+        }
+      }
+
+      for (String test : tests) {
+        String testJSON = test.replace('\'', '"');
+
+        try {
+          failed = true;
+          String err = JSONTestUtil.match(response, testJSON);
+          failed = false;
+          if (err != null) {
+            log.error("query failed JSON validation. error=" + err +
+                "\n expected =" + testJSON +
+                "\n response = " + response +
+                "\n request = " + req.getParamString()
+            );
+            throw new RuntimeException(err);
+          }
+        } finally {
+          if (failed) {
+            log.error("JSON query validation threw an exception." + 
+                "\n expected =" + testJSON +
+                "\n response = " + response +
+                "\n request = " + req.getParamString()
+            );
+          }
+        }
+      }
+    } finally {
+      // restore the params
+      if (params != null && params != req.getParams()) req.setParams(params);
+    }
+  }  
+
+
+  /** Makes sure a query throws a SolrException with the listed response code */
+  public static void assertQEx(String message, SolrQueryRequest req, int code ) {
+    try {
+      h.query(req);
+      fail( message );
+    } catch (SolrException sex) {
+      assertEquals( code, sex.code() );
+    } catch (Exception e2) {
+      throw new RuntimeException("Exception during query", e2);
+    }
+  }
+
+  public static void assertQEx(String message, SolrQueryRequest req, SolrException.ErrorCode code ) {
+    try {
+      h.query(req);
+      fail( message );
+    } catch (SolrException e) {
+      assertEquals( code.code, e.code() );
+    } catch (Exception e2) {
+      throw new RuntimeException("Exception during query", e2);
+    }
+  }
+
+
+  /**
+   * @see TestHarness#optimize
+   */
+  public static String optimize(String... args) {
+    return h.optimize(args);
+  }
+  /**
+   * @see TestHarness#commit
+   */
+  public static String commit(String... args) {
+    return h.commit(args);
+  }
+
+  /**
+   * Generates a simple &lt;add&gt;&lt;doc&gt;... XML String with no options
+   *
+   * @param fieldsAndValues 0th and Even numbered args are fields names odds are field values.
+   * @see #add
+   * @see #doc
+   */
+  public static String adoc(String... fieldsAndValues) {
+    XmlDoc d = doc(fieldsAndValues);
+    return add(d);
+  }
+
+  /**
+   * Generates a simple &lt;add&gt;&lt;doc&gt;... XML String with no options
+   */
+  public static String adoc(SolrInputDocument sdoc) {
+    List<String> fields = new ArrayList<String>();
+    for (SolrInputField sf : sdoc) {
+      for (Object o : sf.getValues()) {
+        fields.add(sf.getName());
+        fields.add(o.toString());
+      }
+    }
+    return adoc(fields.toArray(new String[fields.size()]));
+  }
+
+
+  /**
+   * Generates an &lt;add&gt;&lt;doc&gt;... XML String with options
+   * on the add.
+   *
+   * @param doc the Document to add
+   * @param args 0th and Even numbered args are param names, Odds are param values.
+   * @see #add
+   * @see #doc
+   */
+  public static String add(XmlDoc doc, String... args) {
+    try {
+      StringWriter r = new StringWriter();
+
+      // this is anoying
+      if (null == args || 0 == args.length) {
+        r.write("<add>");
+        r.write(doc.xml);
+        r.write("</add>");
+      } else {
+        XML.writeUnescapedXML(r, "add", doc.xml, (Object[])args);
+      }
+
+      return r.getBuffer().toString();
+    } catch (IOException e) {
+      throw new RuntimeException
+        ("this should never happen with a StringWriter", e);
+    }
+  }
+
+  /**
+   * Generates a &lt;delete&gt;... XML string for an ID
+   *
+   * @see TestHarness#deleteById
+   */
+  public static String delI(String id) {
+    return h.deleteById(id);
+  }
+  /**
+   * Generates a &lt;delete&gt;... XML string for an query
+   *
+   * @see TestHarness#deleteByQuery
+   */
+  public static String delQ(String q) {
+    return h.deleteByQuery(q);
+  }
+
+  /**
+   * Generates a simple &lt;doc&gt;... XML String with no options
+   *
+   * @param fieldsAndValues 0th and Even numbered args are fields names, Odds are field values.
+   * @see TestHarness#makeSimpleDoc
+   */
+  public static XmlDoc doc(String... fieldsAndValues) {
+    XmlDoc d = new XmlDoc();
+    d.xml = h.makeSimpleDoc(fieldsAndValues).toString();
+    return d;
+  }
+
+  public static ModifiableSolrParams params(String... params) {
+    ModifiableSolrParams msp = new ModifiableSolrParams();
+    for (int i=0; i<params.length; i+=2) {
+      msp.add(params[i], params[i+1]);
+    }
+    return msp;
+  }
+
+  /**
+   * Generates a SolrQueryRequest using the LocalRequestFactory
+   * @see #lrf
+   */
+  public static SolrQueryRequest req(String... q) {
+    return lrf.makeRequest(q);
+  }
+
+  /**
+   * Generates a SolrQueryRequest using the LocalRequestFactory
+   * @see #lrf
+   */
+  public static SolrQueryRequest req(String[] params, String... moreParams) {
+    String[] allParams = moreParams;
+    if (params.length!=0) {
+      int len = params.length + moreParams.length;
+      allParams = new String[len];
+      System.arraycopy(params,0,allParams,0,params.length);
+      System.arraycopy(moreParams,0,allParams,params.length,moreParams.length);
+    }
+
+    return lrf.makeRequest(allParams);
+  }
+
+  /**
+   * Generates a SolrQueryRequest
+   */
+  public static SolrQueryRequest req(SolrParams params, String... moreParams) {
+    ModifiableSolrParams mp = new ModifiableSolrParams(params);
+    for (int i=0; i<moreParams.length; i+=2) {
+      mp.add(moreParams[i], moreParams[i+1]);
+    }
+    return new LocalSolrQueryRequest(h.getCore(), mp);
+  }
+
+  /** Neccessary to make method signatures un-ambiguous */
+  public static class XmlDoc {
+    public String xml;
+    @Override
+    public String toString() { return xml; }
+  }
+
+  public static boolean recurseDelete(File f) {
+    if (f.isDirectory()) {
+      for (File sub : f.listFiles()) {
+        if (!recurseDelete(sub)) {
+          System.err.println("!!!! WARNING: best effort to remove " + sub.getAbsolutePath() + " FAILED !!!!!");
+          return false;
+        }
+      }
+    }
+    return f.delete();
+  }
+  
+  public void clearIndex() {
+    assertU(delQ("*:*"));
+  }
+
+  /** Send JSON update commands */
+  public static String updateJ(String json, SolrParams args) throws Exception {
+    SolrCore core = h.getCore();
+    DirectSolrConnection connection = new DirectSolrConnection(core);
+    SolrRequestHandler handler = core.getRequestHandler("/udate/json");
+    if (handler == null) {
+      handler = new JsonUpdateRequestHandler();
+      handler.init(null);
+    }
+    return connection.request(handler, args, json);
+  }
+
+
+  /////////////////////////////////////////////////////////////////////////////////////
+  //////////////////////////// random document / index creation ///////////////////////
+  /////////////////////////////////////////////////////////////////////////////////////
+  
+  public abstract static class Vals {
+    public abstract Comparable get();
+    public String toJSON(Comparable val) {
+      return JSONUtil.toJSON(val);
+    }
+
+    protected int between(int min, int max) {
+      return min != max ? random.nextInt(max-min+1) + min : min;
+    }
+  }
+
+  public abstract static class IVals extends Vals {
+    public abstract int getInt();
+  }
+
+  public static class IRange extends IVals {
+    final int min;
+    final int max;
+    public IRange(int min, int max) {
+      this.min = min;
+      this.max = max;
+    }
+
+    @Override
+    public int getInt() {
+      return between(min,max);
+    }
+
+    @Override
+    public Comparable get() {
+      return getInt();
+    }
+  }
+
+  public static class FVal extends Vals {
+    final float min;
+    final float max;
+    public FVal(float min, float max) {
+      this.min = min;
+      this.max = max;
+    }
+
+    public float getFloat() {
+      if (min >= max) return min;
+      return min + random.nextFloat() *  (max - min);
+    }
+
+    @Override
+    public Comparable get() {
+      return getFloat();
+    }
+  }  
+
+  public static class SVal extends Vals {
+    char start;
+    char end;
+    int minLength;
+    int maxLength;
+
+    public SVal() {
+      this('a','z',1,10);
+    }
+
+    public SVal(char start, char end, int minLength, int maxLength) {
+      this.start = start;
+      this.end = end;
+      this.minLength = minLength;
+      this.maxLength = maxLength;
+    }
+
+    @Override
+    public Comparable get() {
+      char[] arr = new char[between(minLength,maxLength)];
+      for (int i=0; i<arr.length; i++) {
+        arr[i] = (char)between(start, end);
+      }
+      return new String(arr);
+    }
+  }
+
+  public static final IRange ZERO_ONE = new IRange(0,1);
+  public static final IRange ONE_ONE = new IRange(1,1);
+
+  public static class Doc implements Comparable{
+    public Comparable id;
+    public List<Fld> fields;
+    public int order; // the order this document was added to the index
+
+
+    @Override
+    public String toString() {
+      return "Doc("+order+"):"+fields.toString();
+    }
+
+    @Override
+    public int hashCode() {
+      return id.hashCode();
+    }
+
+    @Override
+    public boolean equals(Object o) {
+      if (!(o instanceof Doc)) return false;
+      Doc other = (Doc)o;
+      return this==other || id != null && id.equals(other.id);
+    }
+
+    @Override
+    public int compareTo(Object o) {
+      if (!(o instanceof Doc)) return this.getClass().hashCode() - o.getClass().hashCode();
+      Doc other = (Doc)o;
+      return this.id.compareTo(other.id);
+    }
+
+    public List<Comparable> getValues(String field) {
+      for (Fld fld : fields) {
+        if (fld.ftype.fname.equals(field)) return fld.vals;
+      }
+      return null;
+    }
+
+    public Comparable getFirstValue(String field) {
+      List<Comparable> vals = getValues(field);
+      return vals==null || vals.size()==0 ? null : vals.get(0);
+    }
+
+    public Map<String,Object> toObject(IndexSchema schema) {
+      Map<String,Object> result = new HashMap<String,Object>();
+      for (Fld fld : fields) {
+        SchemaField sf = schema.getField(fld.ftype.fname);
+        if (!sf.multiValued()) {
+          result.put(fld.ftype.fname, fld.vals.get(0));
+        } else {
+          result.put(fld.ftype.fname, fld.vals);
+        }
+      }
+      return result;
+    }
+
+  }
+
+  public static class Fld {
+    public FldType ftype;
+    public List<Comparable> vals;
+    @Override
+    public String toString() {
+      return ftype.fname + "=" + (vals.size()==1 ? vals.get(0).toString() : vals.toString());
+    }
+  }
+
+  class FldType {
+    public String fname;
+    public IRange numValues;
+    public Vals vals;
+
+    public FldType(String fname, Vals vals) {
+      this(fname, ZERO_ONE, vals);
+    }
+
+    public FldType(String fname, IRange numValues, Vals vals) {
+      this.fname = fname;
+      this.numValues = numValues;
+      this.vals = vals;      
+    }
+
+    public Comparable createValue() {
+      return vals.get();
+    }
+
+    public List<Comparable> createValues() {
+      int nVals = numValues.getInt();
+      if (nVals <= 0) return null;
+      List<Comparable> vals = new ArrayList<Comparable>(nVals);
+      for (int i=0; i<nVals; i++)
+        vals.add(createValue());
+      return vals;
+    }
+
+    public Fld createField() {
+      List<Comparable> vals = createValues();
+      if (vals == null) return null;
+
+      Fld fld = new Fld();
+      fld.ftype = this;
+      fld.vals = vals;
+      return fld;          
+    }
+
+  }
+
+
+  public Map<Comparable,Doc> indexDocs(List<FldType> descriptor, Map<Comparable,Doc> model, int nDocs) throws Exception {
+    if (model == null) {
+      model = new LinkedHashMap<Comparable,Doc>();
+    }
+
+    // commit an average of 10 times for large sets, or 10% of the time for small sets
+    int commitOneOutOf = Math.max(nDocs/10, 10);
+
+    for (int i=0; i<nDocs; i++) {
+      Doc doc = createDoc(descriptor);
+      // doc.order = order++;
+      updateJ(toJSON(doc), null);
+      model.put(doc.id, doc);
+
+      // commit 10% of the time
+      if (random.nextInt(commitOneOutOf)==0) {
+        assertU(commit());
+      }
+
+      // duplicate 10% of the docs
+      if (random.nextInt(10)==0) {
+        updateJ(toJSON(doc), null);
+        model.put(doc.id, doc);        
+      }
+    }
+
+    // optimize 10% of the time
+    if (random.nextInt(10)==0) {
+      assertU(optimize());
+    } else {
+      assertU(commit());
+    }
+
+    // merging segments no longer selects just adjacent segments hence ids (doc.order) can be shuffled.
+    // we need to look at the index to determine the order.
+    String responseStr = h.query(req("q","*:*", "fl","id", "sort","_docid_ asc", "rows",Integer.toString(model.size()*2), "wt","json", "indent","true"));
+    Object response = ObjectBuilder.fromJSON(responseStr);
+
+    response = ((Map)response).get("response");
+    response = ((Map)response).get("docs");
+    List<Map> docList = (List<Map>)response;
+    int order = 0;
+    for (Map doc : docList) {
+      Object id = doc.get("id");
+      Doc modelDoc = model.get(id);
+      if (modelDoc == null) continue;  // may be some docs in the index that aren't modeled
+      modelDoc.order = order++;
+    }
+
+    // make sure we updated the order of all docs in the model
+    assertEquals(order, model.size());
+
+    return model;
+  }
+
+  public static Doc createDoc(List<FldType> descriptor) {
+    Doc doc = new Doc();
+    doc.fields = new ArrayList<Fld>();
+    for (FldType ftype : descriptor) {
+      Fld fld = ftype.createField();
+      if (fld != null) {
+        doc.fields.add(fld);
+        if ("id".equals(ftype.fname))
+          doc.id = fld.vals.get(0);
+      }
+    }
+    return doc;
+  }
+
+  public static Comparator<Doc> createSort(IndexSchema schema, List<FldType> fieldTypes, String[] out) {
+    StringBuilder sortSpec = new StringBuilder();
+    int nSorts = random.nextInt(4);
+    List<Comparator<Doc>> comparators = new ArrayList<Comparator<Doc>>();
+    for (int i=0; i<nSorts; i++) {
+      if (i>0) sortSpec.append(',');
+
+      int which = random.nextInt(fieldTypes.size()+2);
+      boolean asc = random.nextBoolean();
+      if (which == fieldTypes.size()) {
+        // sort by score
+        sortSpec.append("score").append(asc ? " asc" : " desc");
+        comparators.add(createComparator("score", asc, false, false, false));
+      } else if (which == fieldTypes.size() + 1) {
+        // sort by docid
+        sortSpec.append("_docid_").append(asc ? " asc" : " desc");
+        comparators.add(createComparator("_docid_", asc, false, false, false));
+      } else {
+        String field = fieldTypes.get(which).fname;
+        sortSpec.append(field).append(asc ? " asc" : " desc");
+        SchemaField sf = schema.getField(field);
+        comparators.add(createComparator(field, asc, sf.sortMissingLast(), sf.sortMissingFirst(), !(sf.sortMissingLast()||sf.sortMissingFirst()) ));
+      }
+    }
+
+    out[0] = sortSpec.length() > 0 ? sortSpec.toString() : null;
+
+    if (comparators.size() == 0) {
+      // default sort is by score desc
+      comparators.add(createComparator("score", false, false, false, false));      
+    }
+
+    return createComparator(comparators);
+  }
+
+  public static Comparator<Doc> createComparator(final String field, final boolean asc, final boolean sortMissingLast, final boolean sortMissingFirst, final boolean sortMissingAsZero) {
+    final int mul = asc ? 1 : -1;
+
+    if (field.equals("_docid_")) {
+     return new Comparator<Doc>() {
+      @Override
+      public int compare(Doc o1, Doc o2) {
+        return (o1.order - o2.order) * mul;
+      }
+     };
+    }
+
+    if (field.equals("score")) {
+      return createComparator("score_f", asc, sortMissingLast, sortMissingFirst, sortMissingAsZero);
+    }
+
+    return new Comparator<Doc>() {
+      private Comparable zeroVal(Comparable template) {
+        if (template == null) return null;
+        if (template instanceof String) return null;  // fast-path for string
+        if (template instanceof Integer) return 0;
+        if (template instanceof Long) return (long)0;
+        if (template instanceof Float) return (float)0;
+        if (template instanceof Double) return (double)0;
+        if (template instanceof Short) return (short)0;
+        if (template instanceof Byte) return (byte)0;
+        if (template instanceof Character) return (char)0;
+        return null;
+      }
+
+      @Override
+      public int compare(Doc o1, Doc o2) {
+        Comparable v1 = o1.getFirstValue(field);
+        Comparable v2 = o2.getFirstValue(field);
+
+        v1 = v1 == null ? zeroVal(v2) : v1;
+        v2 = v2 == null ? zeroVal(v1) : v2;
+
+        int c = 0;
+        if (v1 == v2) {
+          c = 0;
+        } else if (v1 == null) {
+          if (sortMissingLast) c = mul;
+          else if (sortMissingFirst) c = -mul;
+          else c = -1;
+        } else if (v2 == null) {
+          if (sortMissingLast) c = -mul;
+          else if (sortMissingFirst) c = mul;
+          else c = 1;
+        } else {
+          c = v1.compareTo(v2);
+        }
+
+        c = c * mul;
+
+        return c;
+      }
+    };
+  }
+
+  public static Comparator<Doc> createComparator(final List<Comparator<Doc>> comparators) {
+    return new Comparator<Doc>() {
+      @Override
+      public int compare(Doc o1, Doc o2) {
+        int c = 0;
+        for (Comparator<Doc> comparator : comparators) {
+          c = comparator.compare(o1, o2);
+          if (c!=0) return c;
+        }
+        return o1.order - o2.order;
+      }
+    };
+  }
+
+
+  public static String toJSON(Doc doc) {
+    CharArr out = new CharArr();
+    try {
+      out.append("{\"add\":{\"doc\":{");
+      boolean firstField = true;
+      for (Fld fld : doc.fields) {
+        if (firstField) firstField=false;
+        else out.append(',');
+        JSONUtil.writeString(fld.ftype.fname, 0, fld.ftype.fname.length(), out);
+        out.append(':');
+        if (fld.vals.size() > 1) {
+          out.append('[');
+        }
+        boolean firstVal = true;
+        for (Comparable val : fld.vals) {
+          if (firstVal) firstVal=false;
+          else out.append(',');
+          out.append(JSONUtil.toJSON(val));
+        }
+        if (fld.vals.size() > 1) {
+          out.append(']');
+        }
+      }
+      out.append("}}}");
+    } catch (IOException e) {
+      // should never happen
+    }
+    return out.toString();
+  }
+
+  /** Gets a resource from the context classloader as {@link File}. This method should only be used,
+   * if a real file is needed. To get a stream, code should prefer
+   * {@link Class#getResourceAsStream} using {@code this.getClass()}.
+   */
+  public static File getFile(String name) {
+    try {
+      File file = new File(name);
+      if (!file.exists()) {
+        file = new File(Thread.currentThread().getContextClassLoader().getResource(name).toURI());
+      }
+      return file;
+    } catch (Exception e) {
+      /* more friendly than NPE */
+      throw new RuntimeException("Cannot find resource: " + name);
+    }
+  }
+  
+  public static String TEST_HOME() {
+    return getFile("solr/conf").getParent();
+  }
+
+  public static Throwable getRootCause(Throwable t) {
+    Throwable result = t;
+    for (Throwable cause = t; null != cause; cause = cause.getCause()) {
+      result = cause;
+    }
+    return result;
+  }
+}
diff --git a/solr/src/test-framework/org/apache/solr/analysis/BaseTokenTestCase.java b/solr/src/test-framework/org/apache/solr/analysis/BaseTokenTestCase.java
new file mode 100644
index 0000000..ce3338d
--- /dev/null
+++ b/solr/src/test-framework/org/apache/solr/analysis/BaseTokenTestCase.java
@@ -0,0 +1,38 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import java.util.Collections;
+import java.util.Map;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.util.Version;
+import org.apache.solr.core.Config;
+
+/**
+ * General token testing helper functions
+ */
+public abstract class BaseTokenTestCase extends BaseTokenStreamTestCase
+{
+  /** a map containing the default test version param for easy testing */
+  protected static final Map<String,String> DEFAULT_VERSION_PARAM = 
+    Collections.singletonMap("luceneMatchVersion", System.getProperty("tests.luceneMatchVersion", "LUCENE_CURRENT"));
+
+  /** The default test version for easy testing */
+  public static final Version DEFAULT_VERSION = Config.parseLuceneVersionString(DEFAULT_VERSION_PARAM.get("luceneMatchVersion"));
+}
diff --git a/solr/src/test-framework/org/apache/solr/util/AbstractSolrTestCase.java b/solr/src/test-framework/org/apache/solr/util/AbstractSolrTestCase.java
new file mode 100644
index 0000000..e26cfda
--- /dev/null
+++ b/solr/src/test-framework/org/apache/solr/util/AbstractSolrTestCase.java
@@ -0,0 +1,429 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+
+package org.apache.solr.util;
+
+
+import org.apache.lucene.util.LuceneTestCase;
+import org.apache.solr.SolrTestCaseJ4;
+import org.apache.solr.core.SolrConfig;
+import org.apache.solr.common.SolrException;
+import org.apache.solr.common.SolrInputDocument;
+import org.apache.solr.common.SolrInputField;
+import org.apache.solr.common.params.CommonParams;
+import org.apache.solr.common.util.XML;
+import org.apache.solr.request.*;
+import org.apache.solr.util.TestHarness;
+
+import org.xml.sax.SAXException;
+import org.slf4j.LoggerFactory;
+import org.slf4j.Logger;
+import javax.xml.xpath.XPathExpressionException;
+
+import java.io.*;
+import java.util.HashSet;
+import java.util.List;
+import java.util.ArrayList;
+
+/**
+ * An Abstract base class that makes writing Solr JUnit tests "easier"
+ *
+ * <p>
+ * Test classes that subclass this need only specify the path to the
+ * schema.xml file (:TODO: the solrconfig.xml as well) and write some
+ * testMethods.  This class takes care of creating/destroying the index,
+ * and provides several assert methods to assist you.
+ * </p>
+ *
+ * @see #setUp
+ * @see #tearDown
+ */
+public abstract class AbstractSolrTestCase extends LuceneTestCase {
+    protected SolrConfig solrConfig;
+  /**
+   * Harness initialized by initTestHarness.
+   *
+   * <p>
+   * For use in test methods as needed.
+   * </p>
+   */
+  protected TestHarness h;
+  /**
+   * LocalRequestFactory initialized by initTestHarness using sensible
+   * defaults.
+   *
+   * <p>
+   * For use in test methods as needed.
+   * </p>
+   */
+  protected TestHarness.LocalRequestFactory lrf;
+    
+  /**
+   * Subclasses must define this method to return the name of the
+   * schema.xml they wish to use.
+   */
+  public abstract String getSchemaFile();
+    
+  /**
+   * Subclasses must define this method to return the name of the
+   * solrconfig.xml they wish to use.
+   */
+  public abstract String getSolrConfigFile();
+
+  /**
+   * Subclasses can override this to change a test's solr home
+   * (default is in test-files)
+   */
+  public String getSolrHome() {
+    return SolrTestCaseJ4.TEST_HOME();
+  }
+  
+  /**
+   * The directory used to story the index managed by the TestHarness h
+   */
+  protected File dataDir;
+    
+  /**
+   * Initializes things your test might need
+   *
+   * <ul>
+   * <li>Creates a dataDir in the "java.io.tmpdir"</li>
+   * <li>initializes the TestHarness h using this data directory, and getSchemaPath()</li>
+   * <li>initializes the LocalRequestFactory lrf using sensible defaults.</li>
+   * </ul>
+   *
+   */
+
+  public static Logger log = LoggerFactory.getLogger(AbstractSolrTestCase.class);
+
+  private String factoryProp;
+  @Override
+  public void setUp() throws Exception {
+    super.setUp();
+    log.info("####SETUP_START " + getName());
+    ignoreException("ignore_exception");
+    factoryProp = System.getProperty("solr.directoryFactory");
+    if (factoryProp == null) {
+      System.setProperty("solr.directoryFactory","solr.RAMDirectoryFactory");
+    }
+    dataDir = new File(TEMP_DIR,
+            getClass().getName() + "-" + System.currentTimeMillis());
+    dataDir.mkdirs();
+    String configFile = getSolrConfigFile();
+    System.setProperty("solr.solr.home", getSolrHome());
+    if (configFile != null) {
+
+      solrConfig = h.createConfig(getSolrConfigFile());
+      h = new TestHarness( dataDir.getAbsolutePath(),
+              solrConfig,
+              getSchemaFile());
+      lrf = h.getRequestFactory
+              ("standard",0,20,CommonParams.VERSION,"2.2");
+    }
+    log.info("####SETUP_END " + getName());
+  }
+
+    /** Causes an exception matching the regex pattern to not be logged. */
+  public static void ignoreException(String pattern) {
+    if (SolrException.ignorePatterns == null)
+      SolrException.ignorePatterns = new HashSet<String>();
+    SolrException.ignorePatterns.add(pattern);
+  }
+
+  public static void resetExceptionIgnores() {
+    SolrException.ignorePatterns = null;
+    ignoreException("ignore_exception");  // always ignore "ignore_exception"
+  }
+
+  /** Subclasses that override setUp can optionally call this method
+   * to log the fact that their setUp process has ended.
+   */
+  public void postSetUp() {
+    log.info("####POSTSETUP " + getName());
+  }
+
+
+  /** Subclasses that override tearDown can optionally call this method
+   * to log the fact that the tearDown process has started.  This is necessary
+   * since subclasses will want to call super.tearDown() at the *end* of their
+   * tearDown method.
+   */
+  public void preTearDown() {
+    log.info("####PRETEARDOWN " + getName());      
+  }
+
+  /**
+   * Shuts down the test harness, and makes the best attempt possible
+   * to delete dataDir, unless the system property "solr.test.leavedatadir"
+   * is set.
+   */
+  @Override
+  public void tearDown() throws Exception {
+    log.info("####TEARDOWN_START " + getName());
+    if (factoryProp == null) {
+      System.clearProperty("solr.directoryFactory");
+    }
+
+    if (h != null) { h.close(); }
+    String skip = System.getProperty("solr.test.leavedatadir");
+    if (null != skip && 0 != skip.trim().length()) {
+      System.err.println("NOTE: per solr.test.leavedatadir, dataDir will not be removed: " + dataDir.getAbsolutePath());
+    } else {
+      if (!recurseDelete(dataDir)) {
+        System.err.println("!!!! WARNING: best effort to remove " + dataDir.getAbsolutePath() + " FAILED !!!!!");
+      }
+    }
+
+    resetExceptionIgnores();  
+    super.tearDown();
+  }
+
+  /** Validates an update XML String is successful
+   */
+  public void assertU(String update) {
+    assertU(null, update);
+  }
+
+  /** Validates an update XML String is successful
+   */
+  public void assertU(String message, String update) {
+    checkUpdateU(message, update, true);
+  }
+
+  /** Validates an update XML String failed
+   */
+  public void assertFailedU(String update) {
+    assertFailedU(null, update);
+  }
+
+  /** Validates an update XML String failed
+   */
+  public void assertFailedU(String message, String update) {
+    checkUpdateU(message, update, false);
+  }
+
+  /** Checks the success or failure of an update message
+   */
+  private void checkUpdateU(String message, String update, boolean shouldSucceed) {
+    try {
+      String m = (null == message) ? "" : message + " ";
+      if (shouldSucceed) {
+           String res = h.validateUpdate(update);
+         if (res != null) fail(m + "update was not successful: " + res);
+      } else {
+           String res = h.validateErrorUpdate(update);
+         if (res != null) fail(m + "update succeeded, but should have failed: " + res);        
+      }
+    } catch (SAXException e) {
+      throw new RuntimeException("Invalid XML", e);
+    }
+  }
+
+  /** Validates a query matches some XPath test expressions and closes the query */
+  public void assertQ(SolrQueryRequest req, String... tests) {
+    assertQ(null, req, tests);
+  }
+  
+  /** Validates a query matches some XPath test expressions and closes the query */
+  public void assertQ(String message, SolrQueryRequest req, String... tests) {
+    try {
+      String m = (null == message) ? "" : message + " ";
+      String response = h.query(req);
+      String results = h.validateXPath(response, tests);
+      if (null != results) {
+        fail(m + "query failed XPath: " + results +
+             "\n xml response was: " + response +
+             "\n request was: " + req.getParamString());
+      }
+    } catch (XPathExpressionException e1) {
+      throw new RuntimeException("XPath is invalid", e1);
+    } catch (Exception e2) {
+      throw new RuntimeException("Exception during query", e2);
+    }
+  }
+
+  /** Makes sure a query throws a SolrException with the listed response code */
+  public void assertQEx(String message, SolrQueryRequest req, int code ) {
+    try {
+      h.query(req);
+      fail( message );
+    } catch (SolrException sex) {
+      assertEquals( code, sex.code() );
+    } catch (Exception e2) {
+      throw new RuntimeException("Exception during query", e2);
+    }
+  }
+
+  public void assertQEx(String message, SolrQueryRequest req, SolrException.ErrorCode code ) {
+    try {
+      h.query(req);
+      fail( message );
+    } catch (SolrException e) {
+      assertEquals( code.code, e.code() );
+    } catch (Exception e2) {
+      throw new RuntimeException("Exception during query", e2);
+    }
+  }
+
+  
+  /**
+   * @see TestHarness#optimize
+   */
+  public String optimize(String... args) {
+    return h.optimize(args);
+  }
+  /**
+   * @see TestHarness#commit
+   */
+  public String commit(String... args) {
+    return h.commit(args);
+  }
+
+  /**
+   * Generates a simple &lt;add&gt;&lt;doc&gt;... XML String with no options
+   *
+   * @param fieldsAndValues 0th and Even numbered args are fields names odds are field values.
+   * @see #add
+   * @see #doc
+   */
+  public String adoc(String... fieldsAndValues) {
+    Doc d = doc(fieldsAndValues);
+    return add(d);
+  }
+
+  /**
+   * Generates a simple &lt;add&gt;&lt;doc&gt;... XML String with no options
+   */
+  public String adoc(SolrInputDocument sdoc) {
+    List<String> fields = new ArrayList<String>();
+    for (SolrInputField sf : sdoc) {
+      for (Object o : sf.getValues()) {
+        fields.add(sf.getName());
+        fields.add(o.toString());
+      }
+    }
+    return adoc(fields.toArray(new String[fields.size()]));
+  }
+
+    
+  /**
+   * Generates an &lt;add&gt;&lt;doc&gt;... XML String with options
+   * on the add.
+   *
+   * @param doc the Document to add
+   * @param args 0th and Even numbered args are param names, Odds are param values.
+   * @see #add
+   * @see #doc
+   */
+  public String add(Doc doc, String... args) {
+    try {
+      StringWriter r = new StringWriter();
+            
+      // this is anoying
+      if (null == args || 0 == args.length) {
+        r.write("<add>");
+        r.write(doc.xml);
+        r.write("</add>");
+      } else {
+        XML.writeUnescapedXML(r, "add", doc.xml, (Object[])args);
+      }
+            
+      return r.getBuffer().toString();
+    } catch (IOException e) {
+      throw new RuntimeException
+        ("this should never happen with a StringWriter", e);
+    }
+  }
+
+  /**
+   * Generates a &lt;delete&gt;... XML string for an ID
+   *
+   * @see TestHarness#deleteById
+   */
+  public String delI(String id) {
+    return h.deleteById(id);
+  }
+  /**
+   * Generates a &lt;delete&gt;... XML string for an query
+   *
+   * @see TestHarness#deleteByQuery
+   */
+  public String delQ(String q) {
+    return h.deleteByQuery(q);
+  }
+  
+  /**
+   * Generates a simple &lt;doc&gt;... XML String with no options
+   *
+   * @param fieldsAndValues 0th and Even numbered args are fields names, Odds are field values.
+   * @see TestHarness#makeSimpleDoc
+   */
+  public Doc doc(String... fieldsAndValues) {
+    Doc d = new Doc();
+    d.xml = h.makeSimpleDoc(fieldsAndValues).toString();
+    return d;
+  }
+
+  /**
+   * Generates a SolrQueryRequest using the LocalRequestFactory
+   * @see #lrf
+   */
+  public SolrQueryRequest req(String... q) {
+    return lrf.makeRequest(q);
+  }
+
+  /**
+   * Generates a SolrQueryRequest using the LocalRequestFactory
+   * @see #lrf
+   */
+  public SolrQueryRequest req(String[] params, String... moreParams) {
+    String[] allParams = moreParams;
+    if (params.length!=0) {
+      int len = params.length + moreParams.length;
+      allParams = new String[len];
+      System.arraycopy(params,0,allParams,0,params.length);
+      System.arraycopy(moreParams,0,allParams,params.length,moreParams.length);
+    }
+
+    return lrf.makeRequest(allParams);
+  }
+
+  /** Neccessary to make method signatures un-ambiguous */
+  public static class Doc {
+    public String xml;
+    @Override
+    public String toString() { return xml; }
+  }
+
+  public static boolean recurseDelete(File f) {
+    if (f.isDirectory()) {
+      for (File sub : f.listFiles()) {
+        if (!recurseDelete(sub)) {
+          System.err.println("!!!! WARNING: best effort to remove " + sub.getAbsolutePath() + " FAILED !!!!!");
+          return false;
+        }
+      }
+    }
+    return f.delete();
+  }
+
+  /** @see SolrTestCaseJ4#getFile */
+  public static File getFile(String name) throws IOException {
+    return SolrTestCaseJ4.getFile(name);
+  }
+}
diff --git a/solr/src/test-framework/org/apache/solr/util/TestHarness.java b/solr/src/test-framework/org/apache/solr/util/TestHarness.java
new file mode 100644
index 0000000..4eee02b
--- /dev/null
+++ b/solr/src/test-framework/org/apache/solr/util/TestHarness.java
@@ -0,0 +1,576 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.util;
+
+import org.apache.solr.common.SolrException;
+import org.apache.solr.common.params.CommonParams;
+import org.apache.solr.common.util.NamedList;
+import org.apache.solr.common.util.XML;
+import org.apache.solr.core.SolrConfig;
+import org.apache.solr.core.SolrCore;
+import org.apache.solr.core.CoreContainer;
+import org.apache.solr.core.CoreDescriptor;
+import org.apache.solr.core.SolrResourceLoader;
+import org.apache.solr.handler.JsonUpdateRequestHandler;
+import org.apache.solr.handler.XmlUpdateRequestHandler;
+import org.apache.solr.request.LocalSolrQueryRequest;
+import org.apache.solr.request.SolrQueryRequest;
+import org.apache.solr.request.SolrRequestHandler;
+import org.apache.solr.request.SolrRequestInfo;
+import org.apache.solr.response.QueryResponseWriter;
+import org.apache.solr.response.SolrQueryResponse;
+import org.apache.solr.schema.IndexSchema;
+import org.apache.solr.servlet.DirectSolrConnection;
+import org.w3c.dom.Document;
+import org.xml.sax.SAXException;
+import org.apache.solr.common.util.NamedList.NamedListEntry;
+
+import javax.xml.parsers.DocumentBuilder;
+import javax.xml.parsers.DocumentBuilderFactory;
+import javax.xml.xpath.XPath;
+import javax.xml.xpath.XPathConstants;
+import javax.xml.xpath.XPathExpressionException;
+import javax.xml.xpath.XPathFactory;
+
+import java.io.ByteArrayInputStream;
+import java.io.IOException;
+import java.io.StringReader;
+import java.io.StringWriter;
+import java.io.UnsupportedEncodingException;
+import java.util.HashMap;
+import java.util.Map;
+
+
+/**
+ * This class provides a simple harness that may be useful when
+ * writing testcases.
+ *
+ * <p>
+ * This class lives in the tests-framework source tree (and not in the test source
+ * tree), so that it will be included with even the most minimal solr
+ * distribution, in order to encourage plugin writers to create unit 
+ * tests for their plugins.
+ *
+ * @version $Id$
+ */
+public class TestHarness {
+  protected CoreContainer container;
+  private SolrCore core;
+  private XPath xpath = XPathFactory.newInstance().newXPath();
+  private DocumentBuilder builder;
+  public XmlUpdateRequestHandler updater;
+        
+  public static SolrConfig createConfig(String confFile) {
+      // set some system properties for use by tests
+      System.setProperty("solr.test.sys.prop1", "propone");
+      System.setProperty("solr.test.sys.prop2", "proptwo");
+      try {
+      return new SolrConfig(confFile);
+      }
+      catch(Exception xany) {
+        throw new RuntimeException(xany);
+      }
+  }
+        
+  /**
+   * Assumes "solrconfig.xml" is the config file to use, and
+   * "schema.xml" is the schema path to use.
+   *
+   * @param dataDirectory path for index data, will not be cleaned up
+   */
+  public TestHarness( String dataDirectory) {
+    this( dataDirectory, "schema.xml");
+  }
+  
+  /**
+   * Assumes "solrconfig.xml" is the config file to use.
+   *
+   * @param dataDirectory path for index data, will not be cleaned up
+   * @param schemaFile path of schema file
+   */
+  public TestHarness( String dataDirectory, String schemaFile) {
+    this( dataDirectory, "solrconfig.xml", schemaFile);
+  }
+  /**
+   * @param dataDirectory path for index data, will not be cleaned up
+   * @param configFile solrconfig filename
+   * @param schemaFile schema filename
+   */
+   public TestHarness( String dataDirectory, String configFile, String schemaFile) {
+     this( dataDirectory, createConfig(configFile), schemaFile);
+   }
+   /**
+    * @param dataDirectory path for index data, will not be cleaned up
+    * @param solrConfig solronfig instance
+    * @param schemaFile schema filename
+    */
+      public TestHarness( String dataDirectory,
+                          SolrConfig solrConfig,
+                          String schemaFile) {
+     this( dataDirectory, solrConfig, new IndexSchema(solrConfig, schemaFile, null));
+   }
+   /**
+    * @param dataDirectory path for index data, will not be cleaned up
+    * @param solrConfig solrconfig instance
+    * @param indexSchema schema instance
+    */
+  public TestHarness( String dataDirectory,
+                      SolrConfig solrConfig,
+                      IndexSchema indexSchema) {
+      this("", new Initializer("", dataDirectory, solrConfig, indexSchema));
+  }
+  
+  public TestHarness(String coreName, CoreContainer.Initializer init) {
+    try {
+      container = init.initialize();
+      if (coreName == null)
+        coreName = "";
+      // get the core & decrease its refcount:
+      // the container holds the core for the harness lifetime
+      core = container.getCore(coreName);
+      if (core != null)
+        core.close();
+      builder = DocumentBuilderFactory.newInstance().newDocumentBuilder();
+      
+      updater = new XmlUpdateRequestHandler();
+      updater.init( null );
+    } catch (Exception e) {
+      throw new RuntimeException(e);
+    }
+  }
+  
+  // Creates a container based on infos needed to create one core
+  static class Initializer extends CoreContainer.Initializer {
+    String coreName;
+    String dataDirectory;
+    SolrConfig solrConfig;
+    IndexSchema indexSchema;
+    public Initializer(String coreName,
+                      String dataDirectory,
+                      SolrConfig solrConfig,
+                      IndexSchema indexSchema) {
+      if (coreName == null)
+        coreName = "";
+      this.coreName = coreName;
+      this.dataDirectory = dataDirectory;
+      this.solrConfig = solrConfig;
+      this.indexSchema = indexSchema;
+    }
+    public String getCoreName() {
+      return coreName;
+    }
+    @Override
+    public CoreContainer initialize() {
+      CoreContainer container = new CoreContainer(new SolrResourceLoader(SolrResourceLoader.locateSolrHome())) {
+        {
+          hostPort = System.getProperty("hostPort");
+          hostContext = "solr";
+          defaultCoreName = "collection1";
+          initZooKeeper(System.getProperty("zkHost"), 10000);
+        }
+      };
+      
+      CoreDescriptor dcore = new CoreDescriptor(container, coreName, solrConfig.getResourceLoader().getInstanceDir());
+      dcore.setConfigName(solrConfig.getResourceName());
+      dcore.setSchemaName(indexSchema.getResourceName());
+      SolrCore core = new SolrCore("collection1", dataDirectory, solrConfig, indexSchema, dcore);
+      container.register(coreName, core, false);
+
+      return container;
+    }
+  }
+  
+  public CoreContainer getCoreContainer() {
+    return container;
+  }
+
+  public SolrCore getCore() {
+    return core;
+  }
+        
+  /**
+   * Processes an "update" (add, commit or optimize) and
+   * returns the response as a String.
+   *
+   * @param xml The XML of the update
+   * @return The XML response to the update
+   */
+  public String update(String xml) {
+    DirectSolrConnection connection = new DirectSolrConnection(core);
+    SolrRequestHandler handler = core.getRequestHandler("/update");
+    // prefer the handler mapped to /update, but use our generic backup handler
+    // if that lookup fails
+    if (handler == null) {
+      handler = updater;
+    }
+    try {
+      return connection.request(handler, null, xml);
+    } catch (SolrException e) {
+      throw (SolrException)e;
+    } catch (Exception e) {
+      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);
+    }
+  }
+  
+        
+  /**
+   * Validates that an "update" (add, commit or optimize) results in success.
+   *
+   * :TODO: currently only deals with one add/doc at a time, this will need changed if/when SOLR-2 is resolved
+   * 
+   * @param xml The XML of the update
+   * @return null if successful, otherwise the XML response to the update
+   */
+  public String validateUpdate(String xml) throws SAXException {
+    return checkUpdateStatus(xml, "0");
+  }
+
+  /**
+   * Validates that an "update" (add, commit or optimize) results in success.
+   *
+   * :TODO: currently only deals with one add/doc at a time, this will need changed if/when SOLR-2 is resolved
+   * 
+   * @param xml The XML of the update
+   * @return null if successful, otherwise the XML response to the update
+   */
+  public String validateErrorUpdate(String xml) throws SAXException {
+    try {
+      return checkUpdateStatus(xml, "1");
+    } catch (SolrException e) {
+      // return ((SolrException)e).getMessage();
+      return null;  // success
+    }
+  }
+
+  /**
+   * Validates that an "update" (add, commit or optimize) results in success.
+   *
+   * :TODO: currently only deals with one add/doc at a time, this will need changed if/when SOLR-2 is resolved
+   * 
+   * @param xml The XML of the update
+   * @return null if successful, otherwise the XML response to the update
+   */
+  public String checkUpdateStatus(String xml, String code) throws SAXException {
+    try {
+      String res = update(xml);
+      String valid = validateXPath(res, "//int[@name='status']="+code );
+      return (null == valid) ? null : res;
+    } catch (XPathExpressionException e) {
+      throw new RuntimeException
+        ("?!? static xpath has bug?", e);
+    }
+  }
+
+    
+  /**
+   * Validates a "query" response against an array of XPath test strings
+   *
+   * @param req the Query to process
+   * @return null if all good, otherwise the first test that fails.
+   * @exception Exception any exception in the response.
+   * @exception IOException if there is a problem writing the XML
+   * @see LocalSolrQueryRequest
+   */
+  public String validateQuery(SolrQueryRequest req, String... tests)
+    throws IOException, Exception {
+                
+    String res = query(req);
+    return validateXPath(res, tests);
+  }
+            
+  /**
+   * Processes a "query" using a user constructed SolrQueryRequest
+   *
+   * @param req the Query to process, will be closed.
+   * @return The XML response to the query
+   * @exception Exception any exception in the response.
+   * @exception IOException if there is a problem writing the XML
+   * @see LocalSolrQueryRequest
+   */
+  public String query(SolrQueryRequest req) throws IOException, Exception {
+    return query(req.getParams().get(CommonParams.QT), req);
+  }
+
+  /**
+   * Processes a "query" using a user constructed SolrQueryRequest, and closes the request at the end.
+   *
+   * @param handler the name of the request handler to process the request
+   * @param req the Query to process, will be closed.
+   * @return The XML response to the query
+   * @exception Exception any exception in the response.
+   * @exception IOException if there is a problem writing the XML
+   * @see LocalSolrQueryRequest
+   */
+  public String query(String handler, SolrQueryRequest req) throws IOException, Exception {
+    try {
+      SolrQueryResponse rsp = new SolrQueryResponse();
+      SolrRequestInfo.setRequestInfo(new SolrRequestInfo(req, rsp));
+      core.execute(core.getRequestHandler(handler),req,rsp);
+      if (rsp.getException() != null) {
+        throw rsp.getException();
+      }
+      StringWriter sw = new StringWriter(32000);
+      QueryResponseWriter responseWriter = core.getQueryResponseWriter(req);
+      responseWriter.write(sw,req,rsp);
+
+      req.close();
+
+      return sw.toString();
+    } finally {
+      req.close();
+      SolrRequestInfo.clearRequestInfo();
+    }
+  }
+
+  /** It is the users responsibility to close the request object when done with it.
+   * This method does not set/clear SolrRequestInfo */
+  public SolrQueryResponse queryAndResponse(String handler, SolrQueryRequest req) throws Exception {
+    SolrQueryResponse rsp = new SolrQueryResponse();
+    core.execute(core.getRequestHandler(handler),req,rsp);
+    if (rsp.getException() != null) {
+      throw rsp.getException();
+    }
+    return rsp;
+  }
+
+
+  /**
+   * A helper method which valides a String against an array of XPath test
+   * strings.
+   *
+   * @param xml The xml String to validate
+   * @param tests Array of XPath strings to test (in boolean mode) on the xml
+   * @return null if all good, otherwise the first test that fails.
+   */
+  public String validateXPath(String xml, String... tests)
+    throws XPathExpressionException, SAXException {
+        
+    if (tests==null || tests.length == 0) return null;
+                
+    Document document=null;
+    try {
+      document = builder.parse(new ByteArrayInputStream
+                               (xml.getBytes("UTF-8")));
+    } catch (UnsupportedEncodingException e1) {
+      throw new RuntimeException("Totally weird UTF-8 exception", e1);
+    } catch (IOException e2) {
+      throw new RuntimeException("Totally weird io exception", e2);
+    }
+                
+    for (String xp : tests) {
+      xp=xp.trim();
+      Boolean bool = (Boolean) xpath.evaluate(xp, document,
+                                              XPathConstants.BOOLEAN);
+
+      if (!bool) {
+        return xp;
+      }
+    }
+    return null;
+                
+  }
+
+  /**
+   * Shuts down and frees any resources
+   */
+  public void close() {
+    if (container != null) {
+      for (SolrCore c : container.getCores()) {
+        if (c.getOpenCount() > 1)
+          throw new RuntimeException("SolrCore.getOpenCount()=="+core.getOpenCount());
+      }      
+    }
+
+    if (container != null) {
+      container.shutdown();
+      container = null;
+    }
+  }
+
+  /**
+   * A helper that creates an xml &lt;doc&gt; containing all of the
+   * fields and values specified
+   *
+   * @param fieldsAndValues 0 and Even numbered args are fields names odds are field values.
+   */
+  public static StringBuffer makeSimpleDoc(String... fieldsAndValues) {
+
+    try {
+      StringWriter w = new StringWriter();
+      w.append("<doc>");
+      for (int i = 0; i < fieldsAndValues.length; i+=2) {
+        XML.writeXML(w, "field", fieldsAndValues[i+1], "name",
+                     fieldsAndValues[i]);
+      }
+      w.append("</doc>");
+      return w.getBuffer();
+    } catch (IOException e) {
+      throw new RuntimeException
+        ("this should never happen with a StringWriter", e);
+    }
+  }
+
+  /**
+   * Generates a delete by query xml string
+   * @param q Query that has not already been xml escaped
+   */
+  public static String deleteByQuery(String q) {
+    return delete("query", q);
+  }
+  /**
+   * Generates a delete by id xml string
+   * @param id ID that has not already been xml escaped
+   */
+  public static String deleteById(String id) {
+    return delete("id", id);
+  }
+        
+  /**
+   * Generates a delete xml string
+   * @param val text that has not already been xml escaped
+   */
+  private static String delete(String deltype, String val) {
+    try {
+      StringWriter r = new StringWriter();
+            
+      r.write("<delete>");
+      XML.writeXML(r, deltype, val);
+      r.write("</delete>");
+            
+      return r.getBuffer().toString();
+    } catch (IOException e) {
+      throw new RuntimeException
+        ("this should never happen with a StringWriter", e);
+    }
+  }
+    
+  /**
+   * Helper that returns an &lt;optimize&gt; String with
+   * optional key/val pairs.
+   *
+   * @param args 0 and Even numbered args are params, Odd numbered args are values.
+   */
+  public static String optimize(String... args) {
+    return simpleTag("optimize", args);
+  }
+
+  private static String simpleTag(String tag, String... args) {
+    try {
+      StringWriter r = new StringWriter();
+
+      // this is annoying
+      if (null == args || 0 == args.length) {
+        XML.writeXML(r, tag, null);
+      } else {
+        XML.writeXML(r, tag, null, (Object[])args);
+      }
+      return r.getBuffer().toString();
+    } catch (IOException e) {
+      throw new RuntimeException
+        ("this should never happen with a StringWriter", e);
+    }
+  }
+    
+  /**
+   * Helper that returns an &lt;commit&gt; String with
+   * optional key/val pairs.
+   *
+   * @param args 0 and Even numbered args are params, Odd numbered args are values.
+   */
+  public static String commit(String... args) {
+    return simpleTag("commit", args);
+  }
+    
+  public LocalRequestFactory getRequestFactory(String qtype,
+                                               int start,
+                                               int limit) {
+    LocalRequestFactory f = new LocalRequestFactory();
+    f.qtype = qtype;
+    f.start = start;
+    f.limit = limit;
+    return f;
+  }
+    
+  /**
+   * 0 and Even numbered args are keys, Odd numbered args are values.
+   */
+  public LocalRequestFactory getRequestFactory(String qtype,
+                                               int start, int limit,
+                                               String... args) {
+    LocalRequestFactory f = getRequestFactory(qtype, start, limit);
+    for (int i = 0; i < args.length; i+=2) {
+      f.args.put(args[i], args[i+1]);
+    }
+    return f;
+        
+  }
+    
+  public LocalRequestFactory getRequestFactory(String qtype,
+                                               int start, int limit,
+                                               Map<String,String> args) {
+
+    LocalRequestFactory f = getRequestFactory(qtype, start, limit);
+    f.args.putAll(args);
+    return f;
+  }
+    
+  /**
+   * A Factory that generates LocalSolrQueryRequest objects using a
+   * specified set of default options.
+   */
+  public class LocalRequestFactory {
+    public String qtype = "standard";
+    public int start = 0;
+    public int limit = 1000;
+    public Map<String,String> args = new HashMap<String,String>();
+    public LocalRequestFactory() {
+    }
+    /**
+     * Creates a LocalSolrQueryRequest based on variable args; for
+     * historical reasons, this method has some peculiar behavior:
+     * <ul>
+     *   <li>If there is a single arg, then it is treated as the "q"
+     *       param, and the LocalSolrQueryRequest consists of that query
+     *       string along with "qt", "start", and "rows" params (based
+     *       on the qtype, start, and limit properties of this factory)
+     *       along with any other default "args" set on this factory.
+     *   </li>
+     *   <li>If there are multiple args, then there must be an even number
+     *       of them, and each pair of args is used as a key=value param in
+     *       the LocalSolrQueryRequest.  <b>NOTE: In this usage, the "qtype",
+     *       "start", "limit", and "args" properties of this factory are
+     *       ignored.</b>
+     *   </li>
+     * </ul>
+     */
+    public LocalSolrQueryRequest makeRequest(String ... q) {
+      if (q.length==1) {
+        return new LocalSolrQueryRequest(TestHarness.this.getCore(),
+                                       q[0], qtype, start, limit, args);
+      }
+      if (q.length%2 != 0) { 
+        throw new RuntimeException("The length of the string array (query arguments) needs to be even");
+      }
+      Map.Entry<String, String> [] entries = new NamedListEntry[q.length / 2];
+      for (int i = 0; i < q.length; i += 2) {
+        entries[i/2] = new NamedListEntry<String>(q[i], q[i+1]);
+      }
+      return new LocalSolrQueryRequest(TestHarness.this.getCore(), new NamedList(entries));
+    }
+  }
+}
diff --git a/solr/src/test/org/apache/solr/BaseDistributedSearchTestCase.java b/solr/src/test/org/apache/solr/BaseDistributedSearchTestCase.java
deleted file mode 100644
index c32ccc5..0000000
--- a/solr/src/test/org/apache/solr/BaseDistributedSearchTestCase.java
+++ /dev/null
@@ -1,638 +0,0 @@
-package org.apache.solr;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.File;
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collections;
-import java.util.Date;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Map;
-import java.util.Random;
-import java.util.Set;
-
-import junit.framework.TestCase;
-
-import org.apache.solr.client.solrj.SolrServer;
-import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.embedded.JettySolrRunner;
-import org.apache.solr.client.solrj.impl.CommonsHttpSolrServer;
-import org.apache.solr.client.solrj.response.QueryResponse;
-import org.apache.solr.common.SolrDocument;
-import org.apache.solr.common.SolrDocumentList;
-import org.apache.solr.common.SolrInputDocument;
-import org.apache.solr.common.params.ModifiableSolrParams;
-import org.apache.solr.common.util.NamedList;
-import org.apache.solr.schema.TrieDateField;
-import org.apache.solr.util.AbstractSolrTestCase;
-import org.junit.Test;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-/**
- * Helper base class for distributed search test cases
- *
- * @since solr 1.5
- */
-public abstract class BaseDistributedSearchTestCase extends SolrTestCaseJ4 {
-  public static Random r = random;
-
-  protected int shardCount = 4;
-  /**
-   * Sub classes can set this flag in their constructor to true if they
-   * want to fix the number of shards to 'shardCount'
-   *
-   * The default is false which means that test will be executed with
-   * 1, 2, 3, ....shardCount number of shards repeatedly
-   */
-  protected boolean fixShardCount = false;
-
-  protected JettySolrRunner controlJetty;
-  protected List<SolrServer> clients = new ArrayList<SolrServer>();
-  protected List<JettySolrRunner> jettys = new ArrayList<JettySolrRunner>();
-  protected String context = "/solr";
-  protected String shards;
-  protected String[] shardsArr;
-  // Some ISPs redirect to their own web site for domains that don't exist, causing this to fail
-  // protected String[] deadServers = {"does_not_exist_54321.com:33331/solr","localhost:33332/solr"};
-  protected String[] deadServers = {"[::1]:33332/solr"};
-  protected File testDir;
-  protected SolrServer controlClient;
-
-  // to stress with higher thread counts and requests, make sure the junit
-  // xml formatter is not being used (all output will be buffered before
-  // transformation to xml and cause an OOM exception).
-  protected int stress = 2;
-  protected boolean verifyStress = true;
-  protected int nThreads = 3;
-
-
-  public static int ORDERED = 1;
-  public static int SKIP = 2;
-  public static int SKIPVAL = 4;
-  public static int UNORDERED = 8;
-
-  protected int flags;
-  protected Map<String, Integer> handle = new HashMap<String, Integer>();
-
-  protected String id = "id";
-  public static Logger log = LoggerFactory.getLogger(BaseDistributedSearchTestCase.class);
-  
-  public static RandVal rint = new RandVal() {
-    @Override
-    public Object val() {
-      return r.nextInt();
-    }
-  };
-
-  public static RandVal rlong = new RandVal() {
-    @Override
-    public Object val() {
-      return r.nextLong();
-    }
-  };
-
-  public static RandVal rfloat = new RandVal() {
-    @Override
-    public Object val() {
-      return r.nextFloat();
-    }
-  };
-
-  public static RandVal rdouble = new RandVal() {
-    @Override
-    public Object val() {
-      return r.nextDouble();
-    }
-  };
-
-  public static RandVal rdate = new RandDate();
-
-  /**
-   * Perform the actual tests here
-   *
-   * @throws Exception on error
-   */
-  public abstract void doTest() throws Exception;
-
-  public static String[] fieldNames = new String[]{"n_ti1", "n_f1", "n_tf1", "n_d1", "n_td1", "n_l1", "n_tl1", "n_dt1", "n_tdt1"};
-  public static RandVal[] randVals = new RandVal[]{rint, rfloat, rfloat, rdouble, rdouble, rlong, rlong, rdate, rdate};
-
-  protected String[] getFieldNames() {
-    return fieldNames;
-  }
-
-  protected RandVal[] getRandValues() {
-    return randVals;
-  }
-
-  /**
-   * Subclasses can override this to change a test's solr home
-   * (default is in test-files)
-   */
-  public String getSolrHome() {
-    return SolrTestCaseJ4.TEST_HOME;
-  }
-  
-  @Override
-  public void setUp() throws Exception {
-    SolrTestCaseJ4.resetExceptionIgnores();  // ignore anything with ignore_exception in it
-    super.setUp();
-    System.setProperty("solr.test.sys.prop1", "propone");
-    System.setProperty("solr.test.sys.prop2", "proptwo");
-    System.setProperty("solr.solr.home", getSolrHome());
-    testDir = new File(TEMP_DIR,
-            getClass().getName() + "-" + System.currentTimeMillis());
-    testDir.mkdirs();
-  }
-
-  @Override
-  public void tearDown() throws Exception {
-    destroyServers();
-    if (!AbstractSolrTestCase.recurseDelete(testDir)) {
-      System.err.println("!!!! WARNING: best effort to remove " + testDir.getAbsolutePath() + " FAILED !!!!!");
-    }
-    super.tearDown();
-  }
-
-  protected void createServers(int numShards) throws Exception {
-    controlJetty = createJetty(testDir, testDir + "/control/data");
-    controlClient = createNewSolrServer(controlJetty.getLocalPort());
-
-    shardsArr = new String[numShards];
-    StringBuilder sb = new StringBuilder();
-    for (int i = 0; i < numShards; i++) {
-      if (sb.length() > 0) sb.append(',');
-      JettySolrRunner j = createJetty(testDir, testDir + "/shard" + i + "/data");
-      jettys.add(j);
-      clients.add(createNewSolrServer(j.getLocalPort()));
-      String shardStr = "localhost:" + j.getLocalPort() + context;
-      shardsArr[i] = shardStr;
-      sb.append(shardStr);
-    }
-
-    shards = sb.toString();
-  }
-
-
-  protected void setDistributedParams(ModifiableSolrParams params) {
-    params.set("shards", getShardsString());
-  }
-
-  protected String getShardsString() {
-    if (deadServers == null) return shards;
-    
-    StringBuilder sb = new StringBuilder();
-    for (String shard : shardsArr) {
-      if (sb.length() > 0) sb.append(',');
-      int nDeadServers = r.nextInt(deadServers.length+1);
-      if (nDeadServers > 0) {
-        List<String> replicas = new ArrayList<String>(Arrays.asList(deadServers));
-        Collections.shuffle(replicas, r);
-        replicas.add(r.nextInt(nDeadServers+1), shard);
-        for (int i=0; i<nDeadServers+1; i++) {
-          if (i!=0) sb.append('|');
-          sb.append(replicas.get(i));
-        }
-      } else {
-        sb.append(shard);
-      }
-    }
-
-    return sb.toString();
-  }
-
-  protected void destroyServers() throws Exception {
-    controlJetty.stop();
-    for (JettySolrRunner jetty : jettys) jetty.stop();
-    clients.clear();
-    jettys.clear();
-  }
-  
-  public JettySolrRunner createJetty(File baseDir, String dataDir) throws Exception {
-    return createJetty(baseDir, dataDir, null, null);
-  }
-
-  public JettySolrRunner createJetty(File baseDir, String dataDir, String shardId) throws Exception {
-    return createJetty(baseDir, dataDir, shardId, null);
-  }
-  
-  public JettySolrRunner createJetty(File baseDir, String dataDir, String shardList, String solrConfigOverride) throws Exception {
-    System.setProperty("solr.data.dir", dataDir);
-    JettySolrRunner jetty = new JettySolrRunner("/solr", 0, solrConfigOverride);
-    if(shardList != null) {
-      System.setProperty("shard", shardList);
-    }
-    jetty.start();
-    System.clearProperty("shard");
-    return jetty;
-  }
-  
-  protected SolrServer createNewSolrServer(int port) {
-    try {
-      // setup the server...
-      String url = "http://localhost:" + port + context;
-      CommonsHttpSolrServer s = new CommonsHttpSolrServer(url);
-      s.setConnectionTimeout(100); // 1/10th sec
-      s.setDefaultMaxConnectionsPerHost(100);
-      s.setMaxTotalConnections(100);
-      return s;
-    }
-    catch (Exception ex) {
-      throw new RuntimeException(ex);
-    }
-  }
-
-  protected void addFields(SolrInputDocument doc, Object... fields) {
-    for (int i = 0; i < fields.length; i += 2) {
-      doc.addField((String) (fields[i]), fields[i + 1]);
-    }
-  }// add random fields to the documet before indexing
-
-  protected void indexr(Object... fields) throws Exception {
-    SolrInputDocument doc = new SolrInputDocument();
-    addFields(doc, fields);
-    addFields(doc, "rnd_b", true);
-    addFields(doc, getRandFields(getFieldNames(), getRandValues()));
-    indexDoc(doc);
-  }
-
-  protected void index(Object... fields) throws Exception {
-    SolrInputDocument doc = new SolrInputDocument();
-    addFields(doc, fields);
-    indexDoc(doc);
-  }
-
-  protected void indexDoc(SolrInputDocument doc) throws IOException, SolrServerException {
-    controlClient.add(doc);
-
-    int which = (doc.getField(id).toString().hashCode() & 0x7fffffff) % clients.size();
-    SolrServer client = clients.get(which);
-    client.add(doc);
-  }
-
-  protected void index_specific(int serverNumber, Object... fields) throws Exception {
-    SolrInputDocument doc = new SolrInputDocument();
-    for (int i = 0; i < fields.length; i += 2) {
-      doc.addField((String) (fields[i]), fields[i + 1]);
-    }
-    controlClient.add(doc);
-
-    SolrServer client = clients.get(serverNumber);
-    client.add(doc);
-  }
-
-  protected void del(String q) throws Exception {
-    controlClient.deleteByQuery(q);
-    for (SolrServer client : clients) {
-      client.deleteByQuery(q);
-    }
-  }// serial commit...
-
-  protected void commit() throws Exception {
-    controlClient.commit();
-    for (SolrServer client : clients) client.commit();
-  }
-
-  protected QueryResponse queryServer(ModifiableSolrParams params) throws SolrServerException {
-    // query a random server
-    int which = r.nextInt(clients.size());
-    SolrServer client = clients.get(which);
-    QueryResponse rsp = client.query(params);
-    return rsp;
-  }
-
-  protected void query(Object... q) throws Exception {
-    final ModifiableSolrParams params = new ModifiableSolrParams();
-
-    for (int i = 0; i < q.length; i += 2) {
-      params.add(q[i].toString(), q[i + 1].toString());
-    }
-
-    final QueryResponse controlRsp = controlClient.query(params);
-
-    setDistributedParams(params);
-
-    QueryResponse rsp = queryServer(params);
-
-    compareResponses(rsp, controlRsp);
-
-    if (stress > 0) {
-      log.info("starting stress...");
-      Thread[] threads = new Thread[nThreads];
-      for (int i = 0; i < threads.length; i++) {
-        threads[i] = new Thread() {
-          @Override
-          public void run() {
-            for (int j = 0; j < stress; j++) {
-              int which = r.nextInt(clients.size());
-              SolrServer client = clients.get(which);
-              try {
-                QueryResponse rsp = client.query(new ModifiableSolrParams(params));
-                if (verifyStress) {
-                  compareResponses(rsp, controlRsp);
-                }
-              } catch (SolrServerException e) {
-                throw new RuntimeException(e);
-              }
-            }
-          }
-        };
-        threads[i].start();
-      }
-
-      for (Thread thread : threads) {
-        thread.join();
-      }
-    }
-  }
-
-  public static boolean eq(String a, String b) {
-    return a == b || (a != null && a.equals(b));
-  }
-
-  public static int flags(Map<String, Integer> handle, Object key) {
-    if (handle == null) return 0;
-    Integer f = handle.get(key);
-    return f == null ? 0 : f;
-  }
-
-  public static String compare(NamedList a, NamedList b, int flags, Map<String, Integer> handle) {
-    boolean ordered = (flags & UNORDERED) == 0;
-
-    int posa = 0, posb = 0;
-    int aSkipped = 0, bSkipped = 0;
-
-    for (; ;) {
-      if (posa >= a.size() || posb >= b.size()) {
-        break;
-      }
-
-      String namea, nameb;
-      Object vala, valb = null;
-
-      int flagsa, flagsb;
-      for (; ;) {
-        namea = a.getName(posa);
-        vala = a.getVal(posa);
-        posa++;
-        flagsa = flags(handle, namea);
-        if ((flagsa & SKIP) != 0) {
-          aSkipped++;
-          continue;
-        }
-        break;
-      }
-
-      if (!ordered) posb = 0;  // reset if not ordered
-
-      while (posb < b.size()) {
-        nameb = b.getName(posb);
-        valb = b.getVal(posb);
-        posb++;
-        flagsb = flags(handle, nameb);
-        if ((flagsb & SKIP) != 0) {
-          bSkipped++;
-          continue;
-        }
-        if (eq(namea, nameb)) {
-          break;
-        }
-        if (ordered) {
-          return "." + namea + "!=" + nameb + " (unordered or missing)";
-        }
-        // if unordered, continue until we find the right field.
-      }
-
-      // ok, namea and nameb should be equal here already.
-      if ((flagsa & SKIPVAL) != 0) continue;  // keys matching is enough
-
-      String cmp = compare(vala, valb, flagsa, handle);
-      if (cmp != null) return "." + namea + cmp;
-    }
-
-
-    if (a.size() - aSkipped != b.size() - bSkipped) {
-      return ".size()==" + a.size() + "," + b.size() + "skipped=" + aSkipped + "," + bSkipped;
-    }
-
-    return null;
-  }
-
-  public static String compare1(Map a, Map b, int flags, Map<String, Integer> handle) {
-    String cmp;
-
-    for (Object keya : a.keySet()) {
-      Object vala = a.get(keya);
-      int flagsa = flags(handle, keya);
-      if ((flagsa & SKIP) != 0) continue;
-      if (!b.containsKey(keya)) {
-        return "[" + keya + "]==null";
-      }
-      if ((flagsa & SKIPVAL) != 0) continue;
-      Object valb = b.get(keya);
-      cmp = compare(vala, valb, flagsa, handle);
-      if (cmp != null) return "[" + keya + "]" + cmp;
-    }
-    return null;
-  }
-
-  public static String compare(Map a, Map b, int flags, Map<String, Integer> handle) {
-    String cmp;
-    cmp = compare1(a, b, flags, handle);
-    if (cmp != null) return cmp;
-    return compare1(b, a, flags, handle);
-  }
-
-  public static String compare(SolrDocument a, SolrDocument b, int flags, Map<String, Integer> handle) {
-    return compare(a.getFieldValuesMap(), b.getFieldValuesMap(), flags, handle);
-  }
-
-  public static String compare(SolrDocumentList a, SolrDocumentList b, int flags, Map<String, Integer> handle) {
-    boolean ordered = (flags & UNORDERED) == 0;
-
-    String cmp;
-    int f = flags(handle, "maxScore");
-    if ((f & SKIPVAL) == 0) {
-      cmp = compare(a.getMaxScore(), b.getMaxScore(), 0, handle);
-      if (cmp != null) return ".maxScore" + cmp;
-    } else {
-      if (b.getMaxScore() != null) {
-        if (a.getMaxScore() == null) {
-          return ".maxScore missing";
-        }
-      }
-    }
-
-    cmp = compare(a.getNumFound(), b.getNumFound(), 0, handle);
-    if (cmp != null) return ".numFound" + cmp;
-
-    cmp = compare(a.getStart(), b.getStart(), 0, handle);
-    if (cmp != null) return ".start" + cmp;
-
-    cmp = compare(a.size(), b.size(), 0, handle);
-    if (cmp != null) return ".size()" + cmp;
-
-    // only for completely ordered results (ties might be in a different order)
-    if (ordered) {
-      for (int i = 0; i < a.size(); i++) {
-        cmp = compare(a.get(i), b.get(i), 0, handle);
-        if (cmp != null) return "[" + i + "]" + cmp;
-      }
-      return null;
-    }
-
-    // unordered case
-    for (int i = 0; i < a.size(); i++) {
-      SolrDocument doc = a.get(i);
-      Object key = doc.getFirstValue("id");
-      SolrDocument docb = null;
-      if (key == null) {
-        // no id field to correlate... must compare ordered
-        docb = b.get(i);
-      } else {
-        for (int j = 0; j < b.size(); j++) {
-          docb = b.get(j);
-          if (key.equals(docb.getFirstValue("id"))) break;
-        }
-      }
-      // if (docb == null) return "[id="+key+"]";
-      cmp = compare(doc, docb, 0, handle);
-      if (cmp != null) return "[id=" + key + "]" + cmp;
-    }
-    return null;
-  }
-
-  public static String compare(Object[] a, Object[] b, int flags, Map<String, Integer> handle) {
-    if (a.length != b.length) {
-      return ".length:" + a.length + "!=" + b.length;
-    }
-    for (int i = 0; i < a.length; i++) {
-      String cmp = compare(a[i], b[i], flags, handle);
-      if (cmp != null) return "[" + i + "]" + cmp;
-    }
-    return null;
-  }
-
-  public static String compare(Object a, Object b, int flags, Map<String, Integer> handle) {
-    if (a == b) return null;
-    if (a == null || b == null) return ":" + a + "!=" + b;
-
-    if (a instanceof NamedList && b instanceof NamedList) {
-      return compare((NamedList) a, (NamedList) b, flags, handle);
-    }
-
-    if (a instanceof SolrDocumentList && b instanceof SolrDocumentList) {
-      return compare((SolrDocumentList) a, (SolrDocumentList) b, flags, handle);
-    }
-
-    if (a instanceof SolrDocument && b instanceof SolrDocument) {
-      return compare((SolrDocument) a, (SolrDocument) b, flags, handle);
-    }
-
-    if (a instanceof Map && b instanceof Map) {
-      return compare((Map) a, (Map) b, flags, handle);
-    }
-
-    if (a instanceof Object[] && b instanceof Object[]) {
-      return compare((Object[]) a, (Object[]) b, flags, handle);
-    }
-
-    if (a instanceof byte[] && b instanceof byte[]) {
-      if (!Arrays.equals((byte[]) a, (byte[]) b)) {
-        return ":" + a + "!=" + b;
-      }
-      return null;
-    }
-
-    if (a instanceof List && b instanceof List) {
-      return compare(((List) a).toArray(), ((List) b).toArray(), flags, handle);
-
-    }
-
-    if (!(a.equals(b))) {
-      return ":" + a + "!=" + b;
-    }
-
-    return null;
-  }
-
-  protected void compareResponses(QueryResponse a, QueryResponse b) {
-    String cmp;
-    cmp = compare(a.getResponse(), b.getResponse(), flags, handle);
-    if (cmp != null) {
-      log.info("Mismatched responses:\n" + a + "\n" + b);
-      TestCase.fail(cmp);
-    }
-  }
-
-  @Test
-  public void testDistribSearch() throws Exception {
-    if (fixShardCount) {
-      createServers(shardCount);
-      RandVal.uniqueValues = new HashSet(); //reset random values
-      doTest();
-      destroyServers();
-    } else {
-      for (int nServers = 1; nServers < shardCount; nServers++) {
-        createServers(nServers);
-        RandVal.uniqueValues = new HashSet(); //reset random values
-        doTest();
-        destroyServers();
-      }
-    }
-  }
-
-  public static Object[] getRandFields(String[] fields, RandVal[] randVals) {
-    Object[] o = new Object[fields.length * 2];
-    for (int i = 0; i < fields.length; i++) {
-      o[i * 2] = fields[i];
-      o[i * 2 + 1] = randVals[i].uval();
-    }
-    return o;
-  }
-
-  public static abstract class RandVal {
-    public static Random r = random;
-    public static Set uniqueValues = new HashSet();
-
-    public abstract Object val();
-
-    public Object uval() {
-      for (; ;) {
-        Object v = val();
-        if (uniqueValues.add(v)) return v;
-      }
-    }
-  }
-
-  public static class RandDate extends RandVal {
-    public static TrieDateField df = new TrieDateField();
-
-    @Override
-    public Object val() {
-      long v = r.nextLong();
-      Date d = new Date(v);
-      return df.toExternal(d);
-    }
-  }
-}
diff --git a/solr/src/test/org/apache/solr/JSONTestUtil.java b/solr/src/test/org/apache/solr/JSONTestUtil.java
deleted file mode 100644
index 8bd5a79..0000000
--- a/solr/src/test/org/apache/solr/JSONTestUtil.java
+++ /dev/null
@@ -1,346 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr;
-
-import org.apache.noggit.ObjectBuilder;
-import org.apache.solr.common.util.StrUtils;
-
-import java.util.*;
-
-
-public class JSONTestUtil {
-
-  public static String match(String input, String pathAndExpected) throws Exception {
-    int pos = pathAndExpected.indexOf("==");
-    String path = pos>=0 ? pathAndExpected.substring(0,pos) : null;
-    String expected = pos>=0 ? pathAndExpected.substring(pos+2) : pathAndExpected;
-    return match(path, input, expected);
-  }
-
-  public static String match(String path, String input, String expected) throws Exception {
-    Object inputObj = ObjectBuilder.fromJSON(input);
-    Object expectObj = ObjectBuilder.fromJSON(expected);
-    return matchObj(path, inputObj, expectObj);
-  }
-
-  /**
-  public static Object fromJSON(String json) {
-    try {
-      Object out = ObjectBuilder.fromJSON(json);
-    } finally {
-
-  }
-  **/
-  
-  public static String matchObj(String path, Object input, Object expected) throws Exception {
-    CollectionTester tester = new CollectionTester(input);
-    boolean reversed = path.startsWith("!");
-    String positivePath = reversed ? path.substring(1) : path;
-    if (!tester.seek(positivePath) ^ reversed) {
-      return "Path not found: " + path;
-    }
-    if (expected != null && (!tester.match(expected) ^ reversed)) {
-      return tester.err + " @ " + tester.getPath();
-    }
-    return null;
-  }
-}
-
-
-/** Tests simple object graphs, like those generated by the noggit JSON parser */
-class CollectionTester {
-  public Object valRoot;
-  public Object val;
-  public Object expectedRoot;
-  public Object expected;
-  public List<Object> path;
-  public String err;
-
-  public CollectionTester(Object val) {
-    this.val = val;
-    this.valRoot = val;
-    path = new ArrayList<Object>();
-  }
-
-  public String getPath() {
-    StringBuilder sb = new StringBuilder();
-    boolean first=true;
-    for (Object seg : path) {
-      if (seg==null) break;
-      if (!first) sb.append('/');
-      else first=false;
-
-      if (seg instanceof Integer) {
-        sb.append('[');
-        sb.append(seg);
-        sb.append(']');
-      } else {
-        sb.append(seg.toString());
-      }
-    }
-    return sb.toString();
-  }
-
-  void setPath(Object lastSeg) {
-    path.set(path.size()-1, lastSeg);
-  }
-  Object popPath() {
-    return path.remove(path.size()-1);
-  }
-  void pushPath(Object lastSeg) {
-    path.add(lastSeg);
-  }
-
-  void setErr(String msg) {
-    err = msg;
-  }
-
-  public boolean match(Object expected) {
-    this.expectedRoot = expected;
-    this.expected = expected;
-    return match();
-  }
-
-  boolean match() {
-    if (expected == val) {
-      return true;
-    }
-    if (expected == null || val == null) {
-      setErr("mismatch: '" + expected + "'!='" + val + "'");
-      return false;
-    }
-    if (expected instanceof List) {
-      return matchList();
-    }
-    if (expected instanceof Map) {
-      return matchMap();
-    }
-
-    // generic fallback
-    if (!expected.equals(val)) {
-
-      // make an exception for some numerics
-      if ((expected instanceof Integer && val instanceof Long || expected instanceof Long && val instanceof Integer)
-          && ((Number)expected).longValue() == ((Number)val).longValue())
-      {
-        return true;
-      } else if ((expected instanceof Float && val instanceof Double || expected instanceof Double && val instanceof Float)) {
-        double a = ((Number)expected).doubleValue();
-        double b = ((Number)val).doubleValue();
-        if (Double.compare(a,b) == 0) return true;
-        if (Math.abs(a-b) < 1e-5) return true;
-        return false;
-      } else {
-        setErr("mismatch: '" + expected + "'!='" + val + "'");
-        return false;
-      }
-    }
-
-    // setErr("unknown expected type " + expected.getClass().getName());
-    return true;
-  }
-
-  boolean matchList() {
-    List expectedList = (List)expected;
-    List v = asList();
-    if (v == null) return false;
-    int a = 0;
-    int b = 0;
-    pushPath(null);
-    for (;;) {
-      if (a >= expectedList.size() &&  b >=v.size()) {
-        break;
-      }
-
-      if (a >= expectedList.size() || b >=v.size()) {
-        popPath();
-        setErr("List size mismatch");
-        return false;
-      }
-
-      expected = expectedList.get(a);
-      val = v.get(b);
-      setPath(b);
-      if (!match()) return false;
-
-      a++; b++;
-    }
-    
-    popPath();
-    return true;
-  }
-
-  private static Set<String> reserved = new HashSet<String>(Arrays.asList("_SKIP_","_MATCH_","_ORDERED_","_UNORDERED_"));
-
-  boolean matchMap() {
-    Map<String,Object> expectedMap = (Map<String,Object>)expected;
-    Map<String,Object> v = asMap();
-    if (v == null) return false;
-
-    boolean ordered = false;
-    String skipList = (String)expectedMap.get("_SKIP_");
-    String matchList = (String)expectedMap.get("_MATCH_");
-    Object orderedStr = expectedMap.get("_ORDERED_");
-    Object unorderedStr = expectedMap.get("_UNORDERED_");
-
-    if (orderedStr != null) ordered = true;
-    if (unorderedStr != null) ordered = false;
-
-    Set<String> match = null;
-    if (matchList != null) {
-      match = new HashSet(StrUtils.splitSmart(matchList,",",false));
-    }
-
-    Set<String> skips = null;
-    if (skipList != null) {
-      skips = new HashSet(StrUtils.splitSmart(skipList,",",false));
-    }
-
-    Set<String> keys = match != null ? match : expectedMap.keySet();
-    Set<String> visited = new HashSet<String>();
-
-    Iterator<Map.Entry<String,Object>> iter = ordered ? v.entrySet().iterator() : null;
-
-    int numExpected=0;
-
-    pushPath(null);
-    for (String expectedKey : keys) {
-      if (reserved.contains(expectedKey)) continue;
-      numExpected++;
-
-      setPath(expectedKey);
-      if (!v.containsKey(expectedKey)) {
-        popPath();
-        setErr("expected key '" + expectedKey + "'");
-        return false;
-      }
-
-      expected = expectedMap.get(expectedKey);
-
-      if (ordered) {
-        Map.Entry<String,Object> entry;
-        String foundKey;
-        for(;;) {
-          if (!iter.hasNext()) {
-            popPath();
-            setErr("expected key '" + expectedKey + "' in ordered map");
-            return false;           
-          }
-          entry = iter.next();
-          foundKey = entry.getKey();
-          if (skips != null && skips.contains(foundKey))continue;
-          if (match != null && !match.contains(foundKey)) continue;
-          break;
-        }
-
-        if (!entry.getKey().equals(expectedKey)) {
-          popPath();          
-          setErr("expected key '" + expectedKey + "' instead of '"+entry.getKey()+"' in ordered map");
-          return false;
-        }
-        val = entry.getValue();
-      } else {
-        if (skips != null && skips.contains(expectedKey)) continue;
-        val = v.get(expectedKey);
-      }
-
-      if (!match()) return false;
-    }
-
-    popPath();
-
-    // now check if there were any extra keys in the value (as long as there wasn't a specific list to include)
-    if (match == null) {
-      int skipped = 0;
-      if (skips != null) {
-        for (String skipStr : skips)
-          if (v.containsKey(skipStr)) skipped++;
-      }
-      if (numExpected != (v.size() - skipped)) {
-        HashSet<String> set = new HashSet<String>(v.keySet());
-        set.removeAll(expectedMap.keySet());
-        setErr("unexpected map keys " + set); 
-        return false;
-      }
-    }
-
-    return true;
-  }
-
-  public boolean seek(String seekPath) {
-    if (path == null) return true;
-    if (seekPath.startsWith("/")) {
-      seekPath = seekPath.substring(1);
-    }
-    if (seekPath.endsWith("/")) {
-      seekPath = seekPath.substring(0,seekPath.length()-1);
-    }
-    List<String> pathList = StrUtils.splitSmart(seekPath, "/", false);
-    return seek(pathList);
-  }
-
-  List asList() {
-    // TODO: handle native arrays
-    if (val instanceof List) {
-      return (List)val;
-    }
-    setErr("expected List");
-    return null;
-  }
-  
-  Map<String,Object> asMap() {
-    // TODO: handle NamedList
-    if (val instanceof Map) {
-      return (Map<String,Object>)val;
-    }
-    setErr("expected Map");
-    return null;
-  }
-
-  public boolean seek(List<String> seekPath) {
-    if (seekPath.size() == 0) return true;
-    String seg = seekPath.get(0);
-
-    if (seg.charAt(0)=='[') {
-      List listVal = asList();
-      if (listVal==null) return false;
-
-      int arrIdx = Integer.parseInt(seg.substring(1, seg.length()-1));
-
-      if (arrIdx >= listVal.size()) return false;
-
-      val = listVal.get(arrIdx);
-      pushPath(arrIdx);
-    } else {
-      Map<String,Object> mapVal = asMap();
-      if (mapVal==null) return false;
-
-      // use containsKey rather than get to handle null values
-      if (!mapVal.containsKey(seg)) return false;
-
-      val = mapVal.get(seg);
-      pushPath(seg);
-    }
-
-    // recurse after removing head of the path
-    return seek(seekPath.subList(1,seekPath.size()));
-  }
-
-
-
-}
diff --git a/solr/src/test/org/apache/solr/SolrTestCaseJ4.java b/solr/src/test/org/apache/solr/SolrTestCaseJ4.java
deleted file mode 100755
index 546850a..0000000
--- a/solr/src/test/org/apache/solr/SolrTestCaseJ4.java
+++ /dev/null
@@ -1,1085 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-
-package org.apache.solr;
-
-
-import org.apache.lucene.util.LuceneTestCase;
-import org.apache.noggit.CharArr;
-import org.apache.noggit.JSONUtil;
-import org.apache.noggit.ObjectBuilder;
-import org.apache.solr.common.SolrException;
-import org.apache.solr.common.SolrInputDocument;
-import org.apache.solr.common.SolrInputField;
-import org.apache.solr.common.params.CommonParams;
-import org.apache.solr.common.params.ModifiableSolrParams;
-import org.apache.solr.common.params.SolrParams;
-import org.apache.solr.common.util.XML;
-import org.apache.solr.core.SolrConfig;
-import org.apache.solr.core.SolrCore;
-import org.apache.solr.handler.JsonUpdateRequestHandler;
-import org.apache.solr.request.LocalSolrQueryRequest;
-import org.apache.solr.request.SolrQueryRequest;
-import org.apache.solr.request.SolrRequestHandler;
-import org.apache.solr.schema.IndexSchema;
-import org.apache.solr.schema.SchemaField;
-import org.apache.solr.search.SolrIndexSearcher;
-import org.apache.solr.servlet.DirectSolrConnection;
-import org.apache.solr.util.TestHarness;
-import org.junit.AfterClass;
-import org.junit.BeforeClass;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-import org.xml.sax.SAXException;
-
-import javax.xml.xpath.XPathExpressionException;
-import java.io.File;
-import java.io.IOException;
-import java.io.StringWriter;
-import java.util.*;
-
-/**
- * A junit4 Solr test harness that extends LuceneTestCaseJ4.
- * Unlike AbstractSolrTestCase, a new core is not created for each test method.
- *
- */
-public abstract class SolrTestCaseJ4 extends LuceneTestCase {
-
-  @BeforeClass
-  public static void beforeClassSolrTestCase() throws Exception {
-    ignoreException("ignore_exception");
-  }
-
-  @AfterClass
-  public static void afterClassSolrTestCase() throws Exception {
-    deleteCore();
-    resetExceptionIgnores();
-  }
-
-  @Override
-  public void setUp() throws Exception {
-    super.setUp();
-    log.info("###Starting " + getName());  // returns <unknown>???
-  }
-
-  @Override
-  public void tearDown() throws Exception {
-    log.info("###Ending " + getName());    
-    super.tearDown();
-  }
-
-  /** Call initCore in @BeforeClass to instantiate a solr core in your test class.
-   * deleteCore will be called for you via SolrTestCaseJ4 @AfterClass */
-  public static void initCore(String config, String schema) throws Exception {
-    initCore(config, schema, TEST_HOME);
-  }
-
-  /** Call initCore in @BeforeClass to instantiate a solr core in your test class.
-   * deleteCore will be called for you via SolrTestCaseJ4 @AfterClass */
-  public static void initCore(String config, String schema, String solrHome) throws Exception {
-    startTrackingSearchers();
-    configString = config;
-    schemaString = schema;
-    if (solrHome != null) {
-      System.setProperty("solr.solr.home", solrHome);
-    }
-    initCore();
-  }
-
-
-  static long numOpens;
-  static long numCloses;
-  protected static void startTrackingSearchers() {
-    numOpens = SolrIndexSearcher.numOpens.get();
-    numCloses = SolrIndexSearcher.numCloses.get();
-  }
-
-  protected static void endTrackingSearchers() {
-     long endNumOpens = SolrIndexSearcher.numOpens.get();
-     long endNumCloses = SolrIndexSearcher.numCloses.get();
-
-     if (endNumOpens-numOpens != endNumCloses-numCloses) {
-       String msg = "ERROR: SolrIndexSearcher opens=" + (endNumOpens-numOpens) + " closes=" + (endNumCloses-numCloses);
-       log.error(msg);
-       fail(msg);
-     }
-  }
-
-  /** Causes an exception matching the regex pattern to not be logged. */
-  public static void ignoreException(String pattern) {
-    if (SolrException.ignorePatterns == null)
-      SolrException.ignorePatterns = new HashSet<String>();
-    SolrException.ignorePatterns.add(pattern);
-  }
-
-  public static void resetExceptionIgnores() {
-    SolrException.ignorePatterns = null;
-    ignoreException("ignore_exception");  // always ignore "ignore_exception"    
-  }
-
-  protected static String getClassName() {
-    StackTraceElement[] stack = new RuntimeException("WhoAmI").fillInStackTrace().getStackTrace();
-    for (int i = stack.length-1; i>=0; i--) {
-      StackTraceElement ste = stack[i];
-      String cname = ste.getClassName();
-      if (cname.indexOf(".lucene.")>=0 || cname.indexOf(".solr.")>=0) {
-        return cname;
-      }
-    }
-    return SolrTestCaseJ4.class.getName();
-  }
-
-  protected static String getSimpleClassName() {
-    String cname = getClassName();
-    return cname.substring(cname.lastIndexOf('.')+1);
-  }
-
-  protected static String configString;
-  protected static String schemaString;
-
-  protected static SolrConfig solrConfig;
-  /**
-   * Harness initialized by initTestHarness.
-   *
-   * <p>
-   * For use in test methods as needed.
-   * </p>
-   */
-  protected static TestHarness h;
-  /**
-   * LocalRequestFactory initialized by initTestHarness using sensible
-   * defaults.
-   *
-   * <p>
-   * For use in test methods as needed.
-   * </p>
-   */
-  protected static TestHarness.LocalRequestFactory lrf;
-
-
-  /**
-   * Subclasses must define this method to return the name of the
-   * schema.xml they wish to use.
-   */
-  public static  String getSchemaFile() {
-    return schemaString;
-  };
-
-  /**
-   * Subclasses must define this method to return the name of the
-   * solrconfig.xml they wish to use.
-   */
-  public static  String getSolrConfigFile() {
-    return configString;
-  };
-
-  /**
-   * The directory used to story the index managed by the TestHarness h
-   */
-  protected static File dataDir;
-
-  /**
-   * Initializes things your test might need
-   *
-   * <ul>
-   * <li>Creates a dataDir in the "java.io.tmpdir"</li>
-   * <li>initializes the TestHarness h using this data directory, and getSchemaPath()</li>
-   * <li>initializes the LocalRequestFactory lrf using sensible defaults.</li>
-   * </ul>
-   *
-   */
-
-  public static Logger log = LoggerFactory.getLogger(SolrTestCaseJ4.class);
-
-  private static String factoryProp;
-
-  public static void createTempDir() {
-    String cname = getSimpleClassName();
-    dataDir = new File(TEMP_DIR,
-            "solrtest-" + cname + "-" + System.currentTimeMillis());
-    dataDir.mkdirs();
-  }
-
-  public static void initCore() throws Exception {
-    log.info("####initCore");
-
-    ignoreException("ignore_exception");
-    factoryProp = System.getProperty("solr.directoryFactory");
-    if (factoryProp == null) {
-      System.setProperty("solr.directoryFactory","solr.RAMDirectoryFactory");
-    }
-    if (dataDir == null) {
-      createTempDir();
-    }
-
-    // other  methods like starting a jetty instance need these too
-    System.setProperty("solr.test.sys.prop1", "propone");
-    System.setProperty("solr.test.sys.prop2", "proptwo");
-
-    String configFile = getSolrConfigFile();
-    if (configFile != null) {
-
-      solrConfig = h.createConfig(getSolrConfigFile());
-      h = new TestHarness( dataDir.getAbsolutePath(),
-              solrConfig,
-              getSchemaFile());
-      lrf = h.getRequestFactory
-              ("standard",0,20,CommonParams.VERSION,"2.2");
-    }
-    log.info("####initCore end");
-  }
-
-  /** Subclasses that override setUp can optionally call this method
-   * to log the fact that their setUp process has ended.
-   */
-  public void postSetUp() {
-    log.info("####POSTSETUP " + getName());
-  }
-
-
-  /** Subclasses that override tearDown can optionally call this method
-   * to log the fact that the tearDown process has started.  This is necessary
-   * since subclasses will want to call super.tearDown() at the *end* of their
-   * tearDown method.
-   */
-  public void preTearDown() {
-    log.info("####PRETEARDOWN " + getName());
-  }
-
-  /**
-   * Shuts down the test harness, and makes the best attempt possible
-   * to delete dataDir, unless the system property "solr.test.leavedatadir"
-   * is set.
-   */
-  public static void deleteCore() throws Exception {
-    log.info("###deleteCore" );
-    if (h != null) { h.close(); }
-    if (dataDir != null) {
-      String skip = System.getProperty("solr.test.leavedatadir");
-      if (null != skip && 0 != skip.trim().length()) {
-        System.err.println("NOTE: per solr.test.leavedatadir, dataDir will not be removed: " + dataDir.getAbsolutePath());
-      } else {
-        if (!recurseDelete(dataDir)) {
-          System.err.println("!!!! WARNING: best effort to remove " + dataDir.getAbsolutePath() + " FAILED !!!!!");
-        }
-      }
-    }
-
-    if (factoryProp == null) {
-      System.clearProperty("solr.directoryFactory");
-    }
-    
-    dataDir = null;
-    solrConfig = null;
-    h = null;
-    lrf = null;
-    configString = schemaString = null;
-
-    endTrackingSearchers();
-  }
-
-
-  /** Validates an update XML String is successful
-   */
-  public static void assertU(String update) {
-    assertU(null, update);
-  }
-
-  /** Validates an update XML String is successful
-   */
-  public static void assertU(String message, String update) {
-    checkUpdateU(message, update, true);
-  }
-
-  /** Validates an update XML String failed
-   */
-  public static void assertFailedU(String update) {
-    assertFailedU(null, update);
-  }
-
-  /** Validates an update XML String failed
-   */
-  public static void assertFailedU(String message, String update) {
-    checkUpdateU(message, update, false);
-  }
-
-  /** Checks the success or failure of an update message
-   */
-  private static void checkUpdateU(String message, String update, boolean shouldSucceed) {
-    try {
-      String m = (null == message) ? "" : message + " ";
-      if (shouldSucceed) {
-           String res = h.validateUpdate(update);
-         if (res != null) fail(m + "update was not successful: " + res);
-      } else {
-           String res = h.validateErrorUpdate(update);
-         if (res != null) fail(m + "update succeeded, but should have failed: " + res);
-      }
-    } catch (SAXException e) {
-      throw new RuntimeException("Invalid XML", e);
-    }
-  }
-
-  /** Validates a query matches some XPath test expressions and closes the query */
-  public static void assertQ(SolrQueryRequest req, String... tests) {
-    assertQ(null, req, tests);
-  }
-
-  /** Validates a query matches some XPath test expressions and closes the query */
-  public static void assertQ(String message, SolrQueryRequest req, String... tests) {
-    try {
-      String m = (null == message) ? "" : message + " ";
-      String response = h.query(req);
-
-      if (req.getParams().getBool("facet", false)) {
-        // add a test to ensure that faceting did not throw an exception
-        // internally, where it would be added to facet_counts/exception
-        String[] allTests = new String[tests.length+1];
-        System.arraycopy(tests,0,allTests,1,tests.length);
-        allTests[0] = "*[count(//lst[@name='facet_counts']/*[@name='exception'])=0]";
-        tests = allTests;
-      }
-
-      String results = h.validateXPath(response, tests);
-
-      if (null != results) {
-        String msg = "REQUEST FAILED: xpath=" + results
-            + "\n\txml response was: " + response
-            + "\n\trequest was:" + req.getParamString();
-
-        log.error(msg);
-        throw new RuntimeException(msg);
-      }
-
-    } catch (XPathExpressionException e1) {
-      throw new RuntimeException("XPath is invalid", e1);
-    } catch (Exception e2) {
-      SolrException.log(log,"REQUEST FAILED: " + req.getParamString(), e2);
-      throw new RuntimeException("Exception during query", e2);
-    }
-  }
-
-  /** Validates a query matches some JSON test expressions and closes the query.
-   * The text expression is of the form path:JSON.  To facilitate easy embedding
-   * in Java strings, the JSON can have double quotes replaced with single quotes.
-   *
-   * Please use this with care: this makes it easy to match complete structures, but doing so
-   * can result in fragile tests if you are matching more than what you want to test.
-   *
-   **/
-  public static void assertJQ(SolrQueryRequest req, String... tests) throws Exception {
-    SolrParams params =  null;
-    try {
-      params = req.getParams();
-      if (!"json".equals(params.get("wt","xml")) || params.get("indent")==null) {
-        ModifiableSolrParams newParams = new ModifiableSolrParams(params);
-        newParams.set("wt","json");
-        if (params.get("indent")==null) newParams.set("indent","true");
-        req.setParams(newParams);
-      }
-
-      String response;
-      boolean failed=true;
-      try {
-        response = h.query(req);
-        failed = false;
-      } finally {
-        if (failed) {
-          log.error("REQUEST FAILED: " + req.getParamString());
-        }
-      }
-
-      for (String test : tests) {
-        String testJSON = test.replace('\'', '"');
-
-        try {
-          failed = true;
-          String err = JSONTestUtil.match(response, testJSON);
-          failed = false;
-          if (err != null) {
-            log.error("query failed JSON validation. error=" + err +
-                "\n expected =" + testJSON +
-                "\n response = " + response +
-                "\n request = " + req.getParamString()
-            );
-            throw new RuntimeException(err);
-          }
-        } finally {
-          if (failed) {
-            log.error("JSON query validation threw an exception." + 
-                "\n expected =" + testJSON +
-                "\n response = " + response +
-                "\n request = " + req.getParamString()
-            );
-          }
-        }
-      }
-    } finally {
-      // restore the params
-      if (params != null && params != req.getParams()) req.setParams(params);
-    }
-  }  
-
-
-  /** Makes sure a query throws a SolrException with the listed response code */
-  public static void assertQEx(String message, SolrQueryRequest req, int code ) {
-    try {
-      h.query(req);
-      fail( message );
-    } catch (SolrException sex) {
-      assertEquals( code, sex.code() );
-    } catch (Exception e2) {
-      throw new RuntimeException("Exception during query", e2);
-    }
-  }
-
-  public static void assertQEx(String message, SolrQueryRequest req, SolrException.ErrorCode code ) {
-    try {
-      h.query(req);
-      fail( message );
-    } catch (SolrException e) {
-      assertEquals( code.code, e.code() );
-    } catch (Exception e2) {
-      throw new RuntimeException("Exception during query", e2);
-    }
-  }
-
-
-  /**
-   * @see TestHarness#optimize
-   */
-  public static String optimize(String... args) {
-    return h.optimize(args);
-  }
-  /**
-   * @see TestHarness#commit
-   */
-  public static String commit(String... args) {
-    return h.commit(args);
-  }
-
-  /**
-   * Generates a simple &lt;add&gt;&lt;doc&gt;... XML String with no options
-   *
-   * @param fieldsAndValues 0th and Even numbered args are fields names odds are field values.
-   * @see #add
-   * @see #doc
-   */
-  public static String adoc(String... fieldsAndValues) {
-    XmlDoc d = doc(fieldsAndValues);
-    return add(d);
-  }
-
-  /**
-   * Generates a simple &lt;add&gt;&lt;doc&gt;... XML String with no options
-   */
-  public static String adoc(SolrInputDocument sdoc) {
-    List<String> fields = new ArrayList<String>();
-    for (SolrInputField sf : sdoc) {
-      for (Object o : sf.getValues()) {
-        fields.add(sf.getName());
-        fields.add(o.toString());
-      }
-    }
-    return adoc(fields.toArray(new String[fields.size()]));
-  }
-
-
-  /**
-   * Generates an &lt;add&gt;&lt;doc&gt;... XML String with options
-   * on the add.
-   *
-   * @param doc the Document to add
-   * @param args 0th and Even numbered args are param names, Odds are param values.
-   * @see #add
-   * @see #doc
-   */
-  public static String add(XmlDoc doc, String... args) {
-    try {
-      StringWriter r = new StringWriter();
-
-      // this is anoying
-      if (null == args || 0 == args.length) {
-        r.write("<add>");
-        r.write(doc.xml);
-        r.write("</add>");
-      } else {
-        XML.writeUnescapedXML(r, "add", doc.xml, (Object[])args);
-      }
-
-      return r.getBuffer().toString();
-    } catch (IOException e) {
-      throw new RuntimeException
-        ("this should never happen with a StringWriter", e);
-    }
-  }
-
-  /**
-   * Generates a &lt;delete&gt;... XML string for an ID
-   *
-   * @see TestHarness#deleteById
-   */
-  public static String delI(String id) {
-    return h.deleteById(id);
-  }
-  /**
-   * Generates a &lt;delete&gt;... XML string for an query
-   *
-   * @see TestHarness#deleteByQuery
-   */
-  public static String delQ(String q) {
-    return h.deleteByQuery(q);
-  }
-
-  /**
-   * Generates a simple &lt;doc&gt;... XML String with no options
-   *
-   * @param fieldsAndValues 0th and Even numbered args are fields names, Odds are field values.
-   * @see TestHarness#makeSimpleDoc
-   */
-  public static XmlDoc doc(String... fieldsAndValues) {
-    XmlDoc d = new XmlDoc();
-    d.xml = h.makeSimpleDoc(fieldsAndValues).toString();
-    return d;
-  }
-
-  public static ModifiableSolrParams params(String... params) {
-    ModifiableSolrParams msp = new ModifiableSolrParams();
-    for (int i=0; i<params.length; i+=2) {
-      msp.add(params[i], params[i+1]);
-    }
-    return msp;
-  }
-
-  /**
-   * Generates a SolrQueryRequest using the LocalRequestFactory
-   * @see #lrf
-   */
-  public static SolrQueryRequest req(String... q) {
-    return lrf.makeRequest(q);
-  }
-
-  /**
-   * Generates a SolrQueryRequest using the LocalRequestFactory
-   * @see #lrf
-   */
-  public static SolrQueryRequest req(String[] params, String... moreParams) {
-    String[] allParams = moreParams;
-    if (params.length!=0) {
-      int len = params.length + moreParams.length;
-      allParams = new String[len];
-      System.arraycopy(params,0,allParams,0,params.length);
-      System.arraycopy(moreParams,0,allParams,params.length,moreParams.length);
-    }
-
-    return lrf.makeRequest(allParams);
-  }
-
-  /**
-   * Generates a SolrQueryRequest
-   */
-  public static SolrQueryRequest req(SolrParams params, String... moreParams) {
-    ModifiableSolrParams mp = new ModifiableSolrParams(params);
-    for (int i=0; i<moreParams.length; i+=2) {
-      mp.add(moreParams[i], moreParams[i+1]);
-    }
-    return new LocalSolrQueryRequest(h.getCore(), mp);
-  }
-
-  /** Neccessary to make method signatures un-ambiguous */
-  public static class XmlDoc {
-    public String xml;
-    @Override
-    public String toString() { return xml; }
-  }
-
-  public static boolean recurseDelete(File f) {
-    if (f.isDirectory()) {
-      for (File sub : f.listFiles()) {
-        if (!recurseDelete(sub)) {
-          System.err.println("!!!! WARNING: best effort to remove " + sub.getAbsolutePath() + " FAILED !!!!!");
-          return false;
-        }
-      }
-    }
-    return f.delete();
-  }
-  
-  public void clearIndex() {
-    assertU(delQ("*:*"));
-  }
-
-  /** Send JSON update commands */
-  public static String updateJ(String json, SolrParams args) throws Exception {
-    SolrCore core = h.getCore();
-    DirectSolrConnection connection = new DirectSolrConnection(core);
-    SolrRequestHandler handler = core.getRequestHandler("/udate/json");
-    if (handler == null) {
-      handler = new JsonUpdateRequestHandler();
-      handler.init(null);
-    }
-    return connection.request(handler, args, json);
-  }
-
-
-  /////////////////////////////////////////////////////////////////////////////////////
-  //////////////////////////// random document / index creation ///////////////////////
-  /////////////////////////////////////////////////////////////////////////////////////
-  
-  public abstract static class Vals {
-    public abstract Comparable get();
-    public String toJSON(Comparable val) {
-      return JSONUtil.toJSON(val);
-    }
-
-    protected int between(int min, int max) {
-      return min != max ? random.nextInt(max-min+1) + min : min;
-    }
-  }
-
-  public abstract static class IVals extends Vals {
-    public abstract int getInt();
-  }
-
-  public static class IRange extends IVals {
-    final int min;
-    final int max;
-    public IRange(int min, int max) {
-      this.min = min;
-      this.max = max;
-    }
-
-    @Override
-    public int getInt() {
-      return between(min,max);
-    }
-
-    @Override
-    public Comparable get() {
-      return getInt();
-    }
-  }
-
-  public static class FVal extends Vals {
-    final float min;
-    final float max;
-    public FVal(float min, float max) {
-      this.min = min;
-      this.max = max;
-    }
-
-    public float getFloat() {
-      if (min >= max) return min;
-      return min + random.nextFloat() *  (max - min);
-    }
-
-    @Override
-    public Comparable get() {
-      return getFloat();
-    }
-  }  
-
-  public static class SVal extends Vals {
-    char start;
-    char end;
-    int minLength;
-    int maxLength;
-
-    public SVal() {
-      this('a','z',1,10);
-    }
-
-    public SVal(char start, char end, int minLength, int maxLength) {
-      this.start = start;
-      this.end = end;
-      this.minLength = minLength;
-      this.maxLength = maxLength;
-    }
-
-    @Override
-    public Comparable get() {
-      char[] arr = new char[between(minLength,maxLength)];
-      for (int i=0; i<arr.length; i++) {
-        arr[i] = (char)between(start, end);
-      }
-      return new String(arr);
-    }
-  }
-
-  public static final IRange ZERO_ONE = new IRange(0,1);
-  public static final IRange ONE_ONE = new IRange(1,1);
-
-  public static class Doc implements Comparable{
-    public Comparable id;
-    public List<Fld> fields;
-    public int order; // the order this document was added to the index
-
-
-    @Override
-    public String toString() {
-      return "Doc("+order+"):"+fields.toString();
-    }
-
-    @Override
-    public int hashCode() {
-      return id.hashCode();
-    }
-
-    @Override
-    public boolean equals(Object o) {
-      if (!(o instanceof Doc)) return false;
-      Doc other = (Doc)o;
-      return this==other || id != null && id.equals(other.id);
-    }
-
-    @Override
-    public int compareTo(Object o) {
-      if (!(o instanceof Doc)) return this.getClass().hashCode() - o.getClass().hashCode();
-      Doc other = (Doc)o;
-      return this.id.compareTo(other.id);
-    }
-
-    public List<Comparable> getValues(String field) {
-      for (Fld fld : fields) {
-        if (fld.ftype.fname.equals(field)) return fld.vals;
-      }
-      return null;
-    }
-
-    public Comparable getFirstValue(String field) {
-      List<Comparable> vals = getValues(field);
-      return vals==null || vals.size()==0 ? null : vals.get(0);
-    }
-
-    public Map<String,Object> toObject(IndexSchema schema) {
-      Map<String,Object> result = new HashMap<String,Object>();
-      for (Fld fld : fields) {
-        SchemaField sf = schema.getField(fld.ftype.fname);
-        if (!sf.multiValued()) {
-          result.put(fld.ftype.fname, fld.vals.get(0));
-        } else {
-          result.put(fld.ftype.fname, fld.vals);
-        }
-      }
-      return result;
-    }
-
-  }
-
-  public static class Fld {
-    public FldType ftype;
-    public List<Comparable> vals;
-    @Override
-    public String toString() {
-      return ftype.fname + "=" + (vals.size()==1 ? vals.get(0).toString() : vals.toString());
-    }
-  }
-
-  class FldType {
-    public String fname;
-    public IRange numValues;
-    public Vals vals;
-
-    public FldType(String fname, Vals vals) {
-      this(fname, ZERO_ONE, vals);
-    }
-
-    public FldType(String fname, IRange numValues, Vals vals) {
-      this.fname = fname;
-      this.numValues = numValues;
-      this.vals = vals;      
-    }
-
-    public Comparable createValue() {
-      return vals.get();
-    }
-
-    public List<Comparable> createValues() {
-      int nVals = numValues.getInt();
-      if (nVals <= 0) return null;
-      List<Comparable> vals = new ArrayList<Comparable>(nVals);
-      for (int i=0; i<nVals; i++)
-        vals.add(createValue());
-      return vals;
-    }
-
-    public Fld createField() {
-      List<Comparable> vals = createValues();
-      if (vals == null) return null;
-
-      Fld fld = new Fld();
-      fld.ftype = this;
-      fld.vals = vals;
-      return fld;          
-    }
-
-  }
-
-
-  public Map<Comparable,Doc> indexDocs(List<FldType> descriptor, Map<Comparable,Doc> model, int nDocs) throws Exception {
-    if (model == null) {
-      model = new LinkedHashMap<Comparable,Doc>();
-    }
-
-    // commit an average of 10 times for large sets, or 10% of the time for small sets
-    int commitOneOutOf = Math.max(nDocs/10, 10);
-
-    for (int i=0; i<nDocs; i++) {
-      Doc doc = createDoc(descriptor);
-      // doc.order = order++;
-      updateJ(toJSON(doc), null);
-      model.put(doc.id, doc);
-
-      // commit 10% of the time
-      if (random.nextInt(commitOneOutOf)==0) {
-        assertU(commit());
-      }
-
-      // duplicate 10% of the docs
-      if (random.nextInt(10)==0) {
-        updateJ(toJSON(doc), null);
-        model.put(doc.id, doc);        
-      }
-    }
-
-    // optimize 10% of the time
-    if (random.nextInt(10)==0) {
-      assertU(optimize());
-    } else {
-      assertU(commit());
-    }
-
-    // merging segments no longer selects just adjacent segments hence ids (doc.order) can be shuffled.
-    // we need to look at the index to determine the order.
-    String responseStr = h.query(req("q","*:*", "fl","id", "sort","_docid_ asc", "rows",Integer.toString(model.size()*2), "wt","json", "indent","true"));
-    Object response = ObjectBuilder.fromJSON(responseStr);
-
-    response = ((Map)response).get("response");
-    response = ((Map)response).get("docs");
-    List<Map> docList = (List<Map>)response;
-    int order = 0;
-    for (Map doc : docList) {
-      Object id = doc.get("id");
-      Doc modelDoc = model.get(id);
-      if (modelDoc == null) continue;  // may be some docs in the index that aren't modeled
-      modelDoc.order = order++;
-    }
-
-    // make sure we updated the order of all docs in the model
-    assertEquals(order, model.size());
-
-    return model;
-  }
-
-  public static Doc createDoc(List<FldType> descriptor) {
-    Doc doc = new Doc();
-    doc.fields = new ArrayList<Fld>();
-    for (FldType ftype : descriptor) {
-      Fld fld = ftype.createField();
-      if (fld != null) {
-        doc.fields.add(fld);
-        if ("id".equals(ftype.fname))
-          doc.id = fld.vals.get(0);
-      }
-    }
-    return doc;
-  }
-
-  public static Comparator<Doc> createSort(IndexSchema schema, List<FldType> fieldTypes, String[] out) {
-    StringBuilder sortSpec = new StringBuilder();
-    int nSorts = random.nextInt(4);
-    List<Comparator<Doc>> comparators = new ArrayList<Comparator<Doc>>();
-    for (int i=0; i<nSorts; i++) {
-      if (i>0) sortSpec.append(',');
-
-      int which = random.nextInt(fieldTypes.size()+2);
-      boolean asc = random.nextBoolean();
-      if (which == fieldTypes.size()) {
-        // sort by score
-        sortSpec.append("score").append(asc ? " asc" : " desc");
-        comparators.add(createComparator("score", asc, false, false, false));
-      } else if (which == fieldTypes.size() + 1) {
-        // sort by docid
-        sortSpec.append("_docid_").append(asc ? " asc" : " desc");
-        comparators.add(createComparator("_docid_", asc, false, false, false));
-      } else {
-        String field = fieldTypes.get(which).fname;
-        sortSpec.append(field).append(asc ? " asc" : " desc");
-        SchemaField sf = schema.getField(field);
-        comparators.add(createComparator(field, asc, sf.sortMissingLast(), sf.sortMissingFirst(), !(sf.sortMissingLast()||sf.sortMissingFirst()) ));
-      }
-    }
-
-    out[0] = sortSpec.length() > 0 ? sortSpec.toString() : null;
-
-    if (comparators.size() == 0) {
-      // default sort is by score desc
-      comparators.add(createComparator("score", false, false, false, false));      
-    }
-
-    return createComparator(comparators);
-  }
-
-  public static Comparator<Doc> createComparator(final String field, final boolean asc, final boolean sortMissingLast, final boolean sortMissingFirst, final boolean sortMissingAsZero) {
-    final int mul = asc ? 1 : -1;
-
-    if (field.equals("_docid_")) {
-     return new Comparator<Doc>() {
-      @Override
-      public int compare(Doc o1, Doc o2) {
-        return (o1.order - o2.order) * mul;
-      }
-     };
-    }
-
-    if (field.equals("score")) {
-      return createComparator("score_f", asc, sortMissingLast, sortMissingFirst, sortMissingAsZero);
-    }
-
-    return new Comparator<Doc>() {
-      private Comparable zeroVal(Comparable template) {
-        if (template == null) return null;
-        if (template instanceof String) return null;  // fast-path for string
-        if (template instanceof Integer) return 0;
-        if (template instanceof Long) return (long)0;
-        if (template instanceof Float) return (float)0;
-        if (template instanceof Double) return (double)0;
-        if (template instanceof Short) return (short)0;
-        if (template instanceof Byte) return (byte)0;
-        if (template instanceof Character) return (char)0;
-        return null;
-      }
-
-      @Override
-      public int compare(Doc o1, Doc o2) {
-        Comparable v1 = o1.getFirstValue(field);
-        Comparable v2 = o2.getFirstValue(field);
-
-        v1 = v1 == null ? zeroVal(v2) : v1;
-        v2 = v2 == null ? zeroVal(v1) : v2;
-
-        int c = 0;
-        if (v1 == v2) {
-          c = 0;
-        } else if (v1 == null) {
-          if (sortMissingLast) c = mul;
-          else if (sortMissingFirst) c = -mul;
-          else c = -1;
-        } else if (v2 == null) {
-          if (sortMissingLast) c = -mul;
-          else if (sortMissingFirst) c = mul;
-          else c = 1;
-        } else {
-          c = v1.compareTo(v2);
-        }
-
-        c = c * mul;
-
-        return c;
-      }
-    };
-  }
-
-  public static Comparator<Doc> createComparator(final List<Comparator<Doc>> comparators) {
-    return new Comparator<Doc>() {
-      @Override
-      public int compare(Doc o1, Doc o2) {
-        int c = 0;
-        for (Comparator<Doc> comparator : comparators) {
-          c = comparator.compare(o1, o2);
-          if (c!=0) return c;
-        }
-        return o1.order - o2.order;
-      }
-    };
-  }
-
-
-  public static String toJSON(Doc doc) {
-    CharArr out = new CharArr();
-    try {
-      out.append("{\"add\":{\"doc\":{");
-      boolean firstField = true;
-      for (Fld fld : doc.fields) {
-        if (firstField) firstField=false;
-        else out.append(',');
-        JSONUtil.writeString(fld.ftype.fname, 0, fld.ftype.fname.length(), out);
-        out.append(':');
-        if (fld.vals.size() > 1) {
-          out.append('[');
-        }
-        boolean firstVal = true;
-        for (Comparable val : fld.vals) {
-          if (firstVal) firstVal=false;
-          else out.append(',');
-          out.append(JSONUtil.toJSON(val));
-        }
-        if (fld.vals.size() > 1) {
-          out.append(']');
-        }
-      }
-      out.append("}}}");
-    } catch (IOException e) {
-      // should never happen
-    }
-    return out.toString();
-  }
-
-  /** Gets a resource from the context classloader as {@link File}. This method should only be used,
-   * if a real file is needed. To get a stream, code should prefer
-   * {@link Class#getResourceAsStream} using {@code this.getClass()}.
-   */
-  public static File getFile(String name) {
-    try {
-      File file = new File(name);
-      if (!file.exists()) {
-        file = new File(Thread.currentThread().getContextClassLoader().getResource(name).toURI());
-      }
-      return file;
-    } catch (Exception e) {
-      /* more friendly than NPE */
-      throw new RuntimeException("Cannot find resource: " + name);
-    }
-  }
-  
-  private static final String SOURCE_HOME = determineSourceHome();
-  public static String TEST_HOME = getFile("solr/conf").getParent();
-  public static String WEBAPP_HOME = new File(SOURCE_HOME, "src/webapp/web").getAbsolutePath();
-  public static String EXAMPLE_HOME = new File(SOURCE_HOME, "example/solr").getAbsolutePath();
-  public static String EXAMPLE_MULTICORE_HOME = new File(SOURCE_HOME, "example/multicore").getAbsolutePath();
-  public static String EXAMPLE_SCHEMA=EXAMPLE_HOME+"/conf/schema.xml";
-  public static String EXAMPLE_CONFIG=EXAMPLE_HOME+"/conf/solrconfig.xml";
-  
-  static String determineSourceHome() {
-    // ugly, ugly hack to determine the example home without depending on the CWD
-    // this is needed for example/multicore tests which reside outside the classpath
-    File base = getFile("solr/conf/").getAbsoluteFile();
-    while (!new File(base, "solr/CHANGES.txt").exists()) {
-      base = base.getParentFile();
-    }
-    return new File(base, "solr/").getAbsolutePath();
-  }
-
-  public static Throwable getRootCause(Throwable t) {
-    Throwable result = t;
-    for (Throwable cause = t; null != cause; cause = cause.getCause()) {
-      result = cause;
-    }
-    return result;
-  }
-}
diff --git a/solr/src/test/org/apache/solr/analysis/BaseTokenTestCase.java b/solr/src/test/org/apache/solr/analysis/BaseTokenTestCase.java
deleted file mode 100644
index ce3338d..0000000
--- a/solr/src/test/org/apache/solr/analysis/BaseTokenTestCase.java
+++ /dev/null
@@ -1,38 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import java.util.Collections;
-import java.util.Map;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.util.Version;
-import org.apache.solr.core.Config;
-
-/**
- * General token testing helper functions
- */
-public abstract class BaseTokenTestCase extends BaseTokenStreamTestCase
-{
-  /** a map containing the default test version param for easy testing */
-  protected static final Map<String,String> DEFAULT_VERSION_PARAM = 
-    Collections.singletonMap("luceneMatchVersion", System.getProperty("tests.luceneMatchVersion", "LUCENE_CURRENT"));
-
-  /** The default test version for easy testing */
-  public static final Version DEFAULT_VERSION = Config.parseLuceneVersionString(DEFAULT_VERSION_PARAM.get("luceneMatchVersion"));
-}
diff --git a/solr/src/test/org/apache/solr/client/solrj/MergeIndexesExampleTestBase.java b/solr/src/test/org/apache/solr/client/solrj/MergeIndexesExampleTestBase.java
index 6ff0546..3c6b2d1 100644
--- a/solr/src/test/org/apache/solr/client/solrj/MergeIndexesExampleTestBase.java
+++ b/solr/src/test/org/apache/solr/client/solrj/MergeIndexesExampleTestBase.java
@@ -24,6 +24,7 @@ import org.apache.solr.client.solrj.request.UpdateRequest.ACTION;
 import org.apache.solr.common.SolrInputDocument;
 import org.apache.solr.core.CoreContainer;
 import org.apache.solr.core.SolrCore;
+import org.apache.solr.util.ExternalPaths;
 
 /**
  * Abstract base class for testing merge indexes command
@@ -37,7 +38,7 @@ public abstract class MergeIndexesExampleTestBase extends SolrExampleTestBase {
 
   @Override
   public String getSolrHome() {
-    return SolrJettyTestBase.EXAMPLE_MULTICORE_HOME;
+    return ExternalPaths.EXAMPLE_MULTICORE_HOME;
   }
 
   @Override
diff --git a/solr/src/test/org/apache/solr/client/solrj/MultiCoreExampleTestBase.java b/solr/src/test/org/apache/solr/client/solrj/MultiCoreExampleTestBase.java
index 6aa5851..39fae68 100644
--- a/solr/src/test/org/apache/solr/client/solrj/MultiCoreExampleTestBase.java
+++ b/solr/src/test/org/apache/solr/client/solrj/MultiCoreExampleTestBase.java
@@ -25,6 +25,7 @@ import org.apache.solr.client.solrj.response.CoreAdminResponse;
 import org.apache.solr.common.SolrInputDocument;
 import org.apache.solr.core.CoreContainer;
 import org.apache.solr.core.SolrCore;
+import org.apache.solr.util.ExternalPaths;
 
 
 /**
@@ -36,7 +37,7 @@ public abstract class MultiCoreExampleTestBase extends SolrExampleTestBase
   // protected static final CoreContainer cores = new CoreContainer();
   protected static CoreContainer cores;
 
-  @Override public String getSolrHome() { return SolrJettyTestBase.EXAMPLE_MULTICORE_HOME; }
+  @Override public String getSolrHome() { return ExternalPaths.EXAMPLE_MULTICORE_HOME; }
   
   @Override public String getSchemaFile()     { return getSolrHome()+"/core0/conf/schema.xml";     }
   @Override public String getSolrConfigFile() { return getSolrHome()+"/core0/conf/solrconfig.xml"; }
diff --git a/solr/src/test/org/apache/solr/client/solrj/SolrExampleBinaryTest.java b/solr/src/test/org/apache/solr/client/solrj/SolrExampleBinaryTest.java
index 220c64c..6baa377 100644
--- a/solr/src/test/org/apache/solr/client/solrj/SolrExampleBinaryTest.java
+++ b/solr/src/test/org/apache/solr/client/solrj/SolrExampleBinaryTest.java
@@ -22,6 +22,7 @@ import org.apache.solr.client.solrj.SolrServer;
 import org.apache.solr.client.solrj.impl.BinaryRequestWriter;
 import org.apache.solr.client.solrj.impl.BinaryResponseParser;
 import org.apache.solr.client.solrj.impl.CommonsHttpSolrServer;
+import org.apache.solr.util.ExternalPaths;
 import org.junit.BeforeClass;
 
 
@@ -32,7 +33,7 @@ import org.junit.BeforeClass;
 public class SolrExampleBinaryTest extends SolrExampleTests {
   @BeforeClass
   public static void beforeTest() throws Exception {
-    createJetty(EXAMPLE_HOME, null, null);
+    createJetty(ExternalPaths.EXAMPLE_HOME, null, null);
   }
 
   @Override
diff --git a/solr/src/test/org/apache/solr/client/solrj/SolrJettyTestBase.java b/solr/src/test/org/apache/solr/client/solrj/SolrJettyTestBase.java
index ad8a70a..4ca9a75 100755
--- a/solr/src/test/org/apache/solr/client/solrj/SolrJettyTestBase.java
+++ b/solr/src/test/org/apache/solr/client/solrj/SolrJettyTestBase.java
@@ -24,6 +24,7 @@ import org.apache.solr.SolrTestCaseJ4;
 import org.apache.solr.client.solrj.embedded.EmbeddedSolrServer;
 import org.apache.solr.client.solrj.embedded.JettySolrRunner;
 import org.apache.solr.client.solrj.impl.CommonsHttpSolrServer;
+import org.apache.solr.util.ExternalPaths;
 import org.junit.AfterClass;
 
 abstract public class SolrJettyTestBase extends SolrTestCaseJ4 
@@ -32,7 +33,7 @@ abstract public class SolrJettyTestBase extends SolrTestCaseJ4
   // using configs in the test directory allows more flexibility to change "example"
   // without breaking configs.
 
-  public String getSolrHome() { return EXAMPLE_HOME; }
+  public String getSolrHome() { return ExternalPaths.EXAMPLE_HOME; }
 
   public static JettySolrRunner jetty;
   public static int port;
diff --git a/solr/src/test/org/apache/solr/client/solrj/TestBatchUpdate.java b/solr/src/test/org/apache/solr/client/solrj/TestBatchUpdate.java
index 9f5a4b5..69fb792 100644
--- a/solr/src/test/org/apache/solr/client/solrj/TestBatchUpdate.java
+++ b/solr/src/test/org/apache/solr/client/solrj/TestBatchUpdate.java
@@ -22,6 +22,7 @@ import org.apache.solr.client.solrj.impl.CommonsHttpSolrServer;
 import org.apache.solr.client.solrj.request.RequestWriter;
 import org.apache.solr.client.solrj.response.QueryResponse;
 import org.apache.solr.common.SolrInputDocument;
+import org.apache.solr.util.ExternalPaths;
 import org.junit.BeforeClass;
 import org.junit.Test;
 
@@ -38,7 +39,7 @@ public class TestBatchUpdate extends SolrJettyTestBase {
 
   @BeforeClass
   public static void beforeTest() throws Exception {
-    createJetty(EXAMPLE_HOME, null, null);
+    createJetty(ExternalPaths.EXAMPLE_HOME, null, null);
   }
 
   static final int numdocs = 1000;  
diff --git a/solr/src/test/org/apache/solr/client/solrj/embedded/JettyWebappTest.java b/solr/src/test/org/apache/solr/client/solrj/embedded/JettyWebappTest.java
index cce5d3d..ab67aad 100644
--- a/solr/src/test/org/apache/solr/client/solrj/embedded/JettyWebappTest.java
+++ b/solr/src/test/org/apache/solr/client/solrj/embedded/JettyWebappTest.java
@@ -26,6 +26,7 @@ import org.apache.lucene.util.LuceneTestCase;
 import org.apache.commons.io.IOUtils;
 import org.apache.solr.SolrTestCaseJ4;
 import org.apache.solr.client.solrj.SolrJettyTestBase;
+import org.apache.solr.util.ExternalPaths;
 import org.mortbay.jetty.Connector;
 import org.mortbay.jetty.Server;
 import org.mortbay.jetty.bio.SocketConnector;
@@ -47,13 +48,13 @@ public class JettyWebappTest extends LuceneTestCase
   public void setUp() throws Exception 
   {
     super.setUp();
-    System.setProperty("solr.solr.home", SolrJettyTestBase.EXAMPLE_HOME);
+    System.setProperty("solr.solr.home", ExternalPaths.EXAMPLE_HOME);
     
     File dataDir = new File(SolrTestCaseJ4.TEMP_DIR,
         getClass().getName() + "-" + System.currentTimeMillis());
     dataDir.mkdirs();
     System.setProperty("solr.data.dir", dataDir.getCanonicalPath());
-    String path = SolrJettyTestBase.WEBAPP_HOME;
+    String path = ExternalPaths.WEBAPP_HOME;
 
     server = new Server(port);
     // insecure: only use for tests!!!!
diff --git a/solr/src/test/org/apache/solr/client/solrj/embedded/LargeVolumeBinaryJettyTest.java b/solr/src/test/org/apache/solr/client/solrj/embedded/LargeVolumeBinaryJettyTest.java
index 69b13fa..0e4a507 100644
--- a/solr/src/test/org/apache/solr/client/solrj/embedded/LargeVolumeBinaryJettyTest.java
+++ b/solr/src/test/org/apache/solr/client/solrj/embedded/LargeVolumeBinaryJettyTest.java
@@ -17,6 +17,7 @@
 package org.apache.solr.client.solrj.embedded;
 
 import org.apache.solr.client.solrj.LargeVolumeTestBase;
+import org.apache.solr.util.ExternalPaths;
 import org.junit.BeforeClass;
 
 /**
@@ -26,6 +27,6 @@ import org.junit.BeforeClass;
 public class LargeVolumeBinaryJettyTest extends LargeVolumeTestBase {
   @BeforeClass
   public static void beforeTest() throws Exception {
-    createJetty(EXAMPLE_HOME, null, null);
+    createJetty(ExternalPaths.EXAMPLE_HOME, null, null);
   }
 }
diff --git a/solr/src/test/org/apache/solr/client/solrj/embedded/LargeVolumeEmbeddedTest.java b/solr/src/test/org/apache/solr/client/solrj/embedded/LargeVolumeEmbeddedTest.java
index b72098a..a01e6a7 100644
--- a/solr/src/test/org/apache/solr/client/solrj/embedded/LargeVolumeEmbeddedTest.java
+++ b/solr/src/test/org/apache/solr/client/solrj/embedded/LargeVolumeEmbeddedTest.java
@@ -18,11 +18,12 @@
 package org.apache.solr.client.solrj.embedded;
 
 import org.apache.solr.client.solrj.LargeVolumeTestBase;
+import org.apache.solr.util.ExternalPaths;
 import org.junit.BeforeClass;
 
 public class LargeVolumeEmbeddedTest extends LargeVolumeTestBase {
   @BeforeClass
   public static void beforeTest() throws Exception {
-    initCore(EXAMPLE_CONFIG, EXAMPLE_SCHEMA, EXAMPLE_HOME);
+    initCore(ExternalPaths.EXAMPLE_CONFIG, ExternalPaths.EXAMPLE_SCHEMA, ExternalPaths.EXAMPLE_HOME);
   }
 }
diff --git a/solr/src/test/org/apache/solr/client/solrj/embedded/LargeVolumeJettyTest.java b/solr/src/test/org/apache/solr/client/solrj/embedded/LargeVolumeJettyTest.java
index 4303164..25040b0 100644
--- a/solr/src/test/org/apache/solr/client/solrj/embedded/LargeVolumeJettyTest.java
+++ b/solr/src/test/org/apache/solr/client/solrj/embedded/LargeVolumeJettyTest.java
@@ -18,11 +18,12 @@
 package org.apache.solr.client.solrj.embedded;
 
 import org.apache.solr.client.solrj.LargeVolumeTestBase;
+import org.apache.solr.util.ExternalPaths;
 import org.junit.BeforeClass;
 
 public class LargeVolumeJettyTest extends LargeVolumeTestBase {
   @BeforeClass
   public static void beforeTest() throws Exception {
-    createJetty(EXAMPLE_HOME, null, null);
+    createJetty(ExternalPaths.EXAMPLE_HOME, null, null);
   }
 }
diff --git a/solr/src/test/org/apache/solr/client/solrj/embedded/SolrExampleEmbeddedTest.java b/solr/src/test/org/apache/solr/client/solrj/embedded/SolrExampleEmbeddedTest.java
index 7483972..6a569bc 100644
--- a/solr/src/test/org/apache/solr/client/solrj/embedded/SolrExampleEmbeddedTest.java
+++ b/solr/src/test/org/apache/solr/client/solrj/embedded/SolrExampleEmbeddedTest.java
@@ -18,6 +18,7 @@
 package org.apache.solr.client.solrj.embedded;
 
 import org.apache.solr.client.solrj.SolrExampleTests;
+import org.apache.solr.util.ExternalPaths;
 import org.junit.BeforeClass;
 
 /**
@@ -30,6 +31,6 @@ public class SolrExampleEmbeddedTest extends SolrExampleTests {
 
   @BeforeClass
   public static void beforeTest() throws Exception {
-    initCore(EXAMPLE_CONFIG, EXAMPLE_SCHEMA, EXAMPLE_HOME);
+    initCore(ExternalPaths.EXAMPLE_CONFIG, ExternalPaths.EXAMPLE_SCHEMA, ExternalPaths.EXAMPLE_HOME);
   }
 }
diff --git a/solr/src/test/org/apache/solr/client/solrj/embedded/SolrExampleJettyTest.java b/solr/src/test/org/apache/solr/client/solrj/embedded/SolrExampleJettyTest.java
index b18605a..41bbaeb 100644
--- a/solr/src/test/org/apache/solr/client/solrj/embedded/SolrExampleJettyTest.java
+++ b/solr/src/test/org/apache/solr/client/solrj/embedded/SolrExampleJettyTest.java
@@ -19,6 +19,7 @@ package org.apache.solr.client.solrj.embedded;
 
 import org.apache.solr.client.solrj.SolrExampleTests;
 import org.apache.solr.client.solrj.impl.CommonsHttpSolrServer;
+import org.apache.solr.util.ExternalPaths;
 import org.junit.Assert;
 import org.junit.BeforeClass;
 import org.junit.Test;
@@ -33,7 +34,7 @@ public class SolrExampleJettyTest extends SolrExampleTests {
 
   @BeforeClass
   public static void beforeTest() throws Exception {
-    createJetty(EXAMPLE_HOME, null, null);
+    createJetty(ExternalPaths.EXAMPLE_HOME, null, null);
   }
 
   @Test
diff --git a/solr/src/test/org/apache/solr/client/solrj/embedded/SolrExampleStreamingTest.java b/solr/src/test/org/apache/solr/client/solrj/embedded/SolrExampleStreamingTest.java
index 66e1ed0..a7747d0 100644
--- a/solr/src/test/org/apache/solr/client/solrj/embedded/SolrExampleStreamingTest.java
+++ b/solr/src/test/org/apache/solr/client/solrj/embedded/SolrExampleStreamingTest.java
@@ -21,6 +21,7 @@ import org.apache.solr.client.solrj.SolrExampleTests;
 import org.apache.solr.client.solrj.SolrServer;
 import org.apache.solr.client.solrj.impl.CommonsHttpSolrServer;
 import org.apache.solr.client.solrj.impl.StreamingUpdateSolrServer;
+import org.apache.solr.util.ExternalPaths;
 import org.junit.BeforeClass;
 
 
@@ -32,7 +33,7 @@ import org.junit.BeforeClass;
 public class SolrExampleStreamingTest extends SolrExampleTests {
   @BeforeClass
   public static void beforeTest() throws Exception {
-    createJetty(EXAMPLE_HOME, null, null);
+    createJetty(ExternalPaths.EXAMPLE_HOME, null, null);
   }
 
   @Override
diff --git a/solr/src/test/org/apache/solr/client/solrj/response/TermsResponseTest.java b/solr/src/test/org/apache/solr/client/solrj/response/TermsResponseTest.java
index 5e0eed5..4a599f0 100644
--- a/solr/src/test/org/apache/solr/client/solrj/response/TermsResponseTest.java
+++ b/solr/src/test/org/apache/solr/client/solrj/response/TermsResponseTest.java
@@ -24,6 +24,7 @@ import org.apache.solr.client.solrj.SolrQuery;
 import org.apache.solr.common.SolrInputDocument;
 import org.apache.solr.client.solrj.request.QueryRequest;
 import org.apache.solr.client.solrj.response.TermsResponse.Term;
+import org.apache.solr.util.ExternalPaths;
 import org.junit.Before;
 import org.junit.BeforeClass;
 import org.junit.Test;
@@ -35,7 +36,7 @@ public class TermsResponseTest extends SolrJettyTestBase {
 
   @BeforeClass
   public static void beforeTest() throws Exception {
-    initCore(EXAMPLE_CONFIG, EXAMPLE_SCHEMA, EXAMPLE_HOME);
+    initCore(ExternalPaths.EXAMPLE_CONFIG, ExternalPaths.EXAMPLE_SCHEMA, ExternalPaths.EXAMPLE_HOME);
   }
   
   @Before
diff --git a/solr/src/test/org/apache/solr/client/solrj/response/TestSpellCheckResponse.java b/solr/src/test/org/apache/solr/client/solrj/response/TestSpellCheckResponse.java
index ff789f5..646d8bc 100644
--- a/solr/src/test/org/apache/solr/client/solrj/response/TestSpellCheckResponse.java
+++ b/solr/src/test/org/apache/solr/client/solrj/response/TestSpellCheckResponse.java
@@ -25,6 +25,7 @@ import org.apache.solr.client.solrj.response.SpellCheckResponse.Correction;
 import org.apache.solr.common.SolrInputDocument;
 import org.apache.solr.common.params.CommonParams;
 import org.apache.solr.common.params.SpellingParams;
+import org.apache.solr.util.ExternalPaths;
 import org.junit.BeforeClass;
 import org.junit.Test;
 
@@ -40,7 +41,7 @@ public class TestSpellCheckResponse extends SolrJettyTestBase {
   @BeforeClass
   public static void beforeTest() throws Exception {
     // createJetty(EXAMPLE_HOME, null, null);
-    initCore(EXAMPLE_CONFIG, EXAMPLE_SCHEMA, EXAMPLE_HOME);
+    initCore(ExternalPaths.EXAMPLE_CONFIG, ExternalPaths.EXAMPLE_SCHEMA, ExternalPaths.EXAMPLE_HOME);
     // initCore("solrconfig.xml", "schema.xml", null);
   }
   
diff --git a/solr/src/test/org/apache/solr/cloud/BasicDistributedZkTest.java b/solr/src/test/org/apache/solr/cloud/BasicDistributedZkTest.java
index 2452a90..23b420c 100644
--- a/solr/src/test/org/apache/solr/cloud/BasicDistributedZkTest.java
+++ b/solr/src/test/org/apache/solr/cloud/BasicDistributedZkTest.java
@@ -60,7 +60,7 @@ public class BasicDistributedZkTest extends AbstractDistributedZkTestCase {
   
   @BeforeClass
   public static void beforeClass() throws Exception {
-    System.setProperty("solr.solr.home", SolrTestCaseJ4.TEST_HOME);
+    System.setProperty("solr.solr.home", SolrTestCaseJ4.TEST_HOME());
   }
   
   @Override
diff --git a/solr/src/test/org/apache/solr/common/util/TestSystemIdResolver.java b/solr/src/test/org/apache/solr/common/util/TestSystemIdResolver.java
index a827db9..d8ffdeb 100644
--- a/solr/src/test/org/apache/solr/common/util/TestSystemIdResolver.java
+++ b/solr/src/test/org/apache/solr/common/util/TestSystemIdResolver.java
@@ -38,9 +38,9 @@ public class TestSystemIdResolver extends LuceneTestCase {
   }
   
   public void testResolving() throws Exception {
-    final ResourceLoader loader = new SolrResourceLoader(SolrTestCaseJ4.TEST_HOME, this.getClass().getClassLoader());
+    final ResourceLoader loader = new SolrResourceLoader(SolrTestCaseJ4.TEST_HOME(), this.getClass().getClassLoader());
     final SystemIdResolver resolver = new SystemIdResolver(loader);
-    final String fileUri = new File(SolrTestCaseJ4.TEST_HOME+"/crazy-path-to-config.xml").toURI().toASCIIString();
+    final String fileUri = new File(SolrTestCaseJ4.TEST_HOME()+"/crazy-path-to-config.xml").toURI().toASCIIString();
     
     assertEquals("solrres:/test.xml", SystemIdResolver.createSystemIdFromResourceName("test.xml"));
     assertEquals("solrres://@/usr/local/etc/test.xml", SystemIdResolver.createSystemIdFromResourceName("/usr/local/etc/test.xml"));
@@ -60,10 +60,10 @@ public class TestSystemIdResolver extends LuceneTestCase {
     assertEntityResolving(resolver, "solrres:/schema.xml", "solrres:/solrconfig.xml", "schema.xml");
     assertEntityResolving(resolver, "solrres:/org/apache/solr/common/util/TestSystemIdResolver.class",
       "solrres:/org/apache/solr/common/ResourceLoader.class", "util/TestSystemIdResolver.class");
-    assertEntityResolving(resolver, SystemIdResolver.createSystemIdFromResourceName(SolrTestCaseJ4.TEST_HOME+"/conf/schema.xml"),
-      SystemIdResolver.createSystemIdFromResourceName(SolrTestCaseJ4.TEST_HOME+"/conf/solrconfig.xml"), "schema.xml");
-    assertEntityResolving(resolver, SystemIdResolver.createSystemIdFromResourceName(SolrTestCaseJ4.TEST_HOME+"/crazy-path-to-schema.xml"),
-      SystemIdResolver.createSystemIdFromResourceName(SolrTestCaseJ4.TEST_HOME+"/crazy-path-to-config.xml"), "crazy-path-to-schema.xml");
+    assertEntityResolving(resolver, SystemIdResolver.createSystemIdFromResourceName(SolrTestCaseJ4.TEST_HOME()+"/conf/schema.xml"),
+      SystemIdResolver.createSystemIdFromResourceName(SolrTestCaseJ4.TEST_HOME()+"/conf/solrconfig.xml"), "schema.xml");
+    assertEntityResolving(resolver, SystemIdResolver.createSystemIdFromResourceName(SolrTestCaseJ4.TEST_HOME()+"/crazy-path-to-schema.xml"),
+      SystemIdResolver.createSystemIdFromResourceName(SolrTestCaseJ4.TEST_HOME()+"/crazy-path-to-config.xml"), "crazy-path-to-schema.xml");
     
     // test, that resolving works if somebody uses an absolute file:-URI in a href attribute, the resolver should return null (default fallback)
     assertNull(resolver.resolveEntity(null, null, "solrres:/solrconfig.xml", fileUri));
diff --git a/solr/src/test/org/apache/solr/servlet/NoCacheHeaderTest.java b/solr/src/test/org/apache/solr/servlet/NoCacheHeaderTest.java
index e1d5bc6..ee360bf 100644
--- a/solr/src/test/org/apache/solr/servlet/NoCacheHeaderTest.java
+++ b/solr/src/test/org/apache/solr/servlet/NoCacheHeaderTest.java
@@ -31,7 +31,7 @@ import org.junit.Test;
 public class NoCacheHeaderTest extends CacheHeaderTestBase {
   @BeforeClass
   public static void beforeTest() throws Exception {
-    createJetty(TEST_HOME, "solr/conf/solrconfig-nocache.xml", null);
+    createJetty(TEST_HOME(), "solr/conf/solrconfig-nocache.xml", null);
   }
 
   // The tests
diff --git a/solr/src/test/org/apache/solr/spelling/suggest/PersistenceTest.java b/solr/src/test/org/apache/solr/spelling/suggest/PersistenceTest.java
index 4e4c899..58997c5 100644
--- a/solr/src/test/org/apache/solr/spelling/suggest/PersistenceTest.java
+++ b/solr/src/test/org/apache/solr/spelling/suggest/PersistenceTest.java
@@ -49,7 +49,7 @@ public class PersistenceTest extends SolrTestCaseJ4 {
     for (String k : keys) {
       lookup.add(k, new Float(k.length()));
     }
-    File storeDir = new File(TEST_HOME);
+    File storeDir = new File(TEST_HOME());
     lookup.store(storeDir);
     lookup = new TSTLookup();
     lookup.load(storeDir);
@@ -66,7 +66,7 @@ public class PersistenceTest extends SolrTestCaseJ4 {
     for (String k : keys) {
       lookup.add(k, new Float(k.length()));
     }
-    File storeDir = new File(TEST_HOME);
+    File storeDir = new File(TEST_HOME());
     lookup.store(storeDir);
     lookup = new JaspellLookup();
     lookup.load(storeDir);
diff --git a/solr/src/test/org/apache/solr/util/AbstractSolrTestCase.java b/solr/src/test/org/apache/solr/util/AbstractSolrTestCase.java
deleted file mode 100644
index 26aa202..0000000
--- a/solr/src/test/org/apache/solr/util/AbstractSolrTestCase.java
+++ /dev/null
@@ -1,429 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-
-package org.apache.solr.util;
-
-
-import org.apache.lucene.util.LuceneTestCase;
-import org.apache.solr.SolrTestCaseJ4;
-import org.apache.solr.core.SolrConfig;
-import org.apache.solr.common.SolrException;
-import org.apache.solr.common.SolrInputDocument;
-import org.apache.solr.common.SolrInputField;
-import org.apache.solr.common.params.CommonParams;
-import org.apache.solr.common.util.XML;
-import org.apache.solr.request.*;
-import org.apache.solr.util.TestHarness;
-
-import org.xml.sax.SAXException;
-import org.slf4j.LoggerFactory;
-import org.slf4j.Logger;
-import javax.xml.xpath.XPathExpressionException;
-
-import java.io.*;
-import java.util.HashSet;
-import java.util.List;
-import java.util.ArrayList;
-
-/**
- * An Abstract base class that makes writing Solr JUnit tests "easier"
- *
- * <p>
- * Test classes that subclass this need only specify the path to the
- * schema.xml file (:TODO: the solrconfig.xml as well) and write some
- * testMethods.  This class takes care of creating/destroying the index,
- * and provides several assert methods to assist you.
- * </p>
- *
- * @see #setUp
- * @see #tearDown
- */
-public abstract class AbstractSolrTestCase extends LuceneTestCase {
-    protected SolrConfig solrConfig;
-  /**
-   * Harness initialized by initTestHarness.
-   *
-   * <p>
-   * For use in test methods as needed.
-   * </p>
-   */
-  protected TestHarness h;
-  /**
-   * LocalRequestFactory initialized by initTestHarness using sensible
-   * defaults.
-   *
-   * <p>
-   * For use in test methods as needed.
-   * </p>
-   */
-  protected TestHarness.LocalRequestFactory lrf;
-    
-  /**
-   * Subclasses must define this method to return the name of the
-   * schema.xml they wish to use.
-   */
-  public abstract String getSchemaFile();
-    
-  /**
-   * Subclasses must define this method to return the name of the
-   * solrconfig.xml they wish to use.
-   */
-  public abstract String getSolrConfigFile();
-
-  /**
-   * Subclasses can override this to change a test's solr home
-   * (default is in test-files)
-   */
-  public String getSolrHome() {
-    return SolrTestCaseJ4.TEST_HOME;
-  }
-  
-  /**
-   * The directory used to story the index managed by the TestHarness h
-   */
-  protected File dataDir;
-    
-  /**
-   * Initializes things your test might need
-   *
-   * <ul>
-   * <li>Creates a dataDir in the "java.io.tmpdir"</li>
-   * <li>initializes the TestHarness h using this data directory, and getSchemaPath()</li>
-   * <li>initializes the LocalRequestFactory lrf using sensible defaults.</li>
-   * </ul>
-   *
-   */
-
-  public static Logger log = LoggerFactory.getLogger(AbstractSolrTestCase.class);
-
-  private String factoryProp;
-  @Override
-  public void setUp() throws Exception {
-    super.setUp();
-    log.info("####SETUP_START " + getName());
-    ignoreException("ignore_exception");
-    factoryProp = System.getProperty("solr.directoryFactory");
-    if (factoryProp == null) {
-      System.setProperty("solr.directoryFactory","solr.RAMDirectoryFactory");
-    }
-    dataDir = new File(TEMP_DIR,
-            getClass().getName() + "-" + System.currentTimeMillis());
-    dataDir.mkdirs();
-    String configFile = getSolrConfigFile();
-    System.setProperty("solr.solr.home", getSolrHome());
-    if (configFile != null) {
-
-      solrConfig = h.createConfig(getSolrConfigFile());
-      h = new TestHarness( dataDir.getAbsolutePath(),
-              solrConfig,
-              getSchemaFile());
-      lrf = h.getRequestFactory
-              ("standard",0,20,CommonParams.VERSION,"2.2");
-    }
-    log.info("####SETUP_END " + getName());
-  }
-
-    /** Causes an exception matching the regex pattern to not be logged. */
-  public static void ignoreException(String pattern) {
-    if (SolrException.ignorePatterns == null)
-      SolrException.ignorePatterns = new HashSet<String>();
-    SolrException.ignorePatterns.add(pattern);
-  }
-
-  public static void resetExceptionIgnores() {
-    SolrException.ignorePatterns = null;
-    ignoreException("ignore_exception");  // always ignore "ignore_exception"
-  }
-
-  /** Subclasses that override setUp can optionally call this method
-   * to log the fact that their setUp process has ended.
-   */
-  public void postSetUp() {
-    log.info("####POSTSETUP " + getName());
-  }
-
-
-  /** Subclasses that override tearDown can optionally call this method
-   * to log the fact that the tearDown process has started.  This is necessary
-   * since subclasses will want to call super.tearDown() at the *end* of their
-   * tearDown method.
-   */
-  public void preTearDown() {
-    log.info("####PRETEARDOWN " + getName());      
-  }
-
-  /**
-   * Shuts down the test harness, and makes the best attempt possible
-   * to delete dataDir, unless the system property "solr.test.leavedatadir"
-   * is set.
-   */
-  @Override
-  public void tearDown() throws Exception {
-    log.info("####TEARDOWN_START " + getName());
-    if (factoryProp == null) {
-      System.clearProperty("solr.directoryFactory");
-    }
-
-    if (h != null) { h.close(); }
-    String skip = System.getProperty("solr.test.leavedatadir");
-    if (null != skip && 0 != skip.trim().length()) {
-      System.err.println("NOTE: per solr.test.leavedatadir, dataDir will not be removed: " + dataDir.getAbsolutePath());
-    } else {
-      if (!recurseDelete(dataDir)) {
-        System.err.println("!!!! WARNING: best effort to remove " + dataDir.getAbsolutePath() + " FAILED !!!!!");
-      }
-    }
-
-    resetExceptionIgnores();  
-    super.tearDown();
-  }
-
-  /** Validates an update XML String is successful
-   */
-  public void assertU(String update) {
-    assertU(null, update);
-  }
-
-  /** Validates an update XML String is successful
-   */
-  public void assertU(String message, String update) {
-    checkUpdateU(message, update, true);
-  }
-
-  /** Validates an update XML String failed
-   */
-  public void assertFailedU(String update) {
-    assertFailedU(null, update);
-  }
-
-  /** Validates an update XML String failed
-   */
-  public void assertFailedU(String message, String update) {
-    checkUpdateU(message, update, false);
-  }
-
-  /** Checks the success or failure of an update message
-   */
-  private void checkUpdateU(String message, String update, boolean shouldSucceed) {
-    try {
-      String m = (null == message) ? "" : message + " ";
-      if (shouldSucceed) {
-           String res = h.validateUpdate(update);
-         if (res != null) fail(m + "update was not successful: " + res);
-      } else {
-           String res = h.validateErrorUpdate(update);
-         if (res != null) fail(m + "update succeeded, but should have failed: " + res);        
-      }
-    } catch (SAXException e) {
-      throw new RuntimeException("Invalid XML", e);
-    }
-  }
-
-  /** Validates a query matches some XPath test expressions and closes the query */
-  public void assertQ(SolrQueryRequest req, String... tests) {
-    assertQ(null, req, tests);
-  }
-  
-  /** Validates a query matches some XPath test expressions and closes the query */
-  public void assertQ(String message, SolrQueryRequest req, String... tests) {
-    try {
-      String m = (null == message) ? "" : message + " ";
-      String response = h.query(req);
-      String results = h.validateXPath(response, tests);
-      if (null != results) {
-        fail(m + "query failed XPath: " + results +
-             "\n xml response was: " + response +
-             "\n request was: " + req.getParamString());
-      }
-    } catch (XPathExpressionException e1) {
-      throw new RuntimeException("XPath is invalid", e1);
-    } catch (Exception e2) {
-      throw new RuntimeException("Exception during query", e2);
-    }
-  }
-
-  /** Makes sure a query throws a SolrException with the listed response code */
-  public void assertQEx(String message, SolrQueryRequest req, int code ) {
-    try {
-      h.query(req);
-      fail( message );
-    } catch (SolrException sex) {
-      assertEquals( code, sex.code() );
-    } catch (Exception e2) {
-      throw new RuntimeException("Exception during query", e2);
-    }
-  }
-
-  public void assertQEx(String message, SolrQueryRequest req, SolrException.ErrorCode code ) {
-    try {
-      h.query(req);
-      fail( message );
-    } catch (SolrException e) {
-      assertEquals( code.code, e.code() );
-    } catch (Exception e2) {
-      throw new RuntimeException("Exception during query", e2);
-    }
-  }
-
-  
-  /**
-   * @see TestHarness#optimize
-   */
-  public String optimize(String... args) {
-    return h.optimize(args);
-  }
-  /**
-   * @see TestHarness#commit
-   */
-  public String commit(String... args) {
-    return h.commit(args);
-  }
-
-  /**
-   * Generates a simple &lt;add&gt;&lt;doc&gt;... XML String with no options
-   *
-   * @param fieldsAndValues 0th and Even numbered args are fields names odds are field values.
-   * @see #add
-   * @see #doc
-   */
-  public String adoc(String... fieldsAndValues) {
-    Doc d = doc(fieldsAndValues);
-    return add(d);
-  }
-
-  /**
-   * Generates a simple &lt;add&gt;&lt;doc&gt;... XML String with no options
-   */
-  public String adoc(SolrInputDocument sdoc) {
-    List<String> fields = new ArrayList<String>();
-    for (SolrInputField sf : sdoc) {
-      for (Object o : sf.getValues()) {
-        fields.add(sf.getName());
-        fields.add(o.toString());
-      }
-    }
-    return adoc(fields.toArray(new String[fields.size()]));
-  }
-
-    
-  /**
-   * Generates an &lt;add&gt;&lt;doc&gt;... XML String with options
-   * on the add.
-   *
-   * @param doc the Document to add
-   * @param args 0th and Even numbered args are param names, Odds are param values.
-   * @see #add
-   * @see #doc
-   */
-  public String add(Doc doc, String... args) {
-    try {
-      StringWriter r = new StringWriter();
-            
-      // this is anoying
-      if (null == args || 0 == args.length) {
-        r.write("<add>");
-        r.write(doc.xml);
-        r.write("</add>");
-      } else {
-        XML.writeUnescapedXML(r, "add", doc.xml, (Object[])args);
-      }
-            
-      return r.getBuffer().toString();
-    } catch (IOException e) {
-      throw new RuntimeException
-        ("this should never happen with a StringWriter", e);
-    }
-  }
-
-  /**
-   * Generates a &lt;delete&gt;... XML string for an ID
-   *
-   * @see TestHarness#deleteById
-   */
-  public String delI(String id) {
-    return h.deleteById(id);
-  }
-  /**
-   * Generates a &lt;delete&gt;... XML string for an query
-   *
-   * @see TestHarness#deleteByQuery
-   */
-  public String delQ(String q) {
-    return h.deleteByQuery(q);
-  }
-  
-  /**
-   * Generates a simple &lt;doc&gt;... XML String with no options
-   *
-   * @param fieldsAndValues 0th and Even numbered args are fields names, Odds are field values.
-   * @see TestHarness#makeSimpleDoc
-   */
-  public Doc doc(String... fieldsAndValues) {
-    Doc d = new Doc();
-    d.xml = h.makeSimpleDoc(fieldsAndValues).toString();
-    return d;
-  }
-
-  /**
-   * Generates a SolrQueryRequest using the LocalRequestFactory
-   * @see #lrf
-   */
-  public SolrQueryRequest req(String... q) {
-    return lrf.makeRequest(q);
-  }
-
-  /**
-   * Generates a SolrQueryRequest using the LocalRequestFactory
-   * @see #lrf
-   */
-  public SolrQueryRequest req(String[] params, String... moreParams) {
-    String[] allParams = moreParams;
-    if (params.length!=0) {
-      int len = params.length + moreParams.length;
-      allParams = new String[len];
-      System.arraycopy(params,0,allParams,0,params.length);
-      System.arraycopy(moreParams,0,allParams,params.length,moreParams.length);
-    }
-
-    return lrf.makeRequest(allParams);
-  }
-
-  /** Neccessary to make method signatures un-ambiguous */
-  public static class Doc {
-    public String xml;
-    @Override
-    public String toString() { return xml; }
-  }
-
-  public static boolean recurseDelete(File f) {
-    if (f.isDirectory()) {
-      for (File sub : f.listFiles()) {
-        if (!recurseDelete(sub)) {
-          System.err.println("!!!! WARNING: best effort to remove " + sub.getAbsolutePath() + " FAILED !!!!!");
-          return false;
-        }
-      }
-    }
-    return f.delete();
-  }
-
-  /** @see SolrTestCaseJ4#getFile */
-  public static File getFile(String name) throws IOException {
-    return SolrTestCaseJ4.getFile(name);
-  }
-}
diff --git a/solr/src/test/org/apache/solr/util/ExternalPaths.java b/solr/src/test/org/apache/solr/util/ExternalPaths.java
new file mode 100644
index 0000000..9ea244c
--- /dev/null
+++ b/solr/src/test/org/apache/solr/util/ExternalPaths.java
@@ -0,0 +1,46 @@
+package org.apache.solr.util;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.File;
+
+import org.apache.solr.SolrTestCaseJ4;
+
+/**
+ * Some tests need to reach outside the classpath to get certain resources (e.g. the example configuration).
+ * This class provides some paths to allow them to do this.
+ * @lucene.internal
+ */
+public class ExternalPaths {
+  private static final String SOURCE_HOME = determineSourceHome();
+  public static String WEBAPP_HOME = new File(SOURCE_HOME, "src/webapp/web").getAbsolutePath();
+  public static String EXAMPLE_HOME = new File(SOURCE_HOME, "example/solr").getAbsolutePath();
+  public static String EXAMPLE_MULTICORE_HOME = new File(SOURCE_HOME, "example/multicore").getAbsolutePath();
+  public static String EXAMPLE_SCHEMA=EXAMPLE_HOME+"/conf/schema.xml";
+  public static String EXAMPLE_CONFIG=EXAMPLE_HOME+"/conf/solrconfig.xml";
+  
+  static String determineSourceHome() {
+    // ugly, ugly hack to determine the example home without depending on the CWD
+    // this is needed for example/multicore tests which reside outside the classpath
+    File base = SolrTestCaseJ4.getFile("solr/conf").getAbsoluteFile();
+    while (!new File(base, "solr/CHANGES.txt").exists()) {
+      base = base.getParentFile();
+    }
+    return new File(base, "solr/").getAbsolutePath();
+  }
+}

