GitDiffStart: 91c58c364e8a6999f3f730a2e959bc2f20b8b555 | Mon Jan 14 20:48:20 2013 +0000
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/diskdv/DiskDocValuesConsumer.java b/lucene/codecs/src/java/org/apache/lucene/codecs/diskdv/DiskDocValuesConsumer.java
index 6abf13e..d0f97aa 100644
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/diskdv/DiskDocValuesConsumer.java
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/diskdv/DiskDocValuesConsumer.java
@@ -37,11 +37,11 @@ class DiskDocValuesConsumer extends SimpleDVConsumer {
   final int maxDoc;
   
   DiskDocValuesConsumer(SegmentWriteState state) throws IOException {
-    String dataName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, "dvd");
+    String dataName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, "ddvd");
     data = state.directory.createOutput(dataName, state.context);
     CodecUtil.writeHeader(data, DiskDocValuesFormat.DATA_CODEC, 
                                 DiskDocValuesFormat.VERSION_CURRENT);
-    String metaName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, "dvm");
+    String metaName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, "ddvm");
     meta = state.directory.createOutput(metaName, state.context);
     CodecUtil.writeHeader(meta, DiskDocValuesFormat.METADATA_CODEC, 
                                 DiskDocValuesFormat.VERSION_CURRENT);
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/diskdv/DiskDocValuesProducer.java b/lucene/codecs/src/java/org/apache/lucene/codecs/diskdv/DiskDocValuesProducer.java
index 1a1bb48..04401a6 100644
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/diskdv/DiskDocValuesProducer.java
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/diskdv/DiskDocValuesProducer.java
@@ -44,7 +44,7 @@ class DiskDocValuesProducer extends SimpleDVProducer {
   private final IndexInput data;
   
   DiskDocValuesProducer(SegmentReadState state) throws IOException {
-    String metaName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, "dvm");
+    String metaName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, "ddvm");
     // read in the entries from the metadata file.
     IndexInput in = state.directory.openInput(metaName, state.context);
     boolean success = false;
@@ -65,7 +65,7 @@ class DiskDocValuesProducer extends SimpleDVProducer {
       }
     }
     
-    String dataName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, "dvd");
+    String dataName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, "ddvd");
     data = state.directory.openInput(dataName, state.context);
     CodecUtil.checkHeader(data, DiskDocValuesFormat.DATA_CODEC, 
                                 DiskDocValuesFormat.VERSION_START,
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41SimpleDocValuesConsumer.java b/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41SimpleDocValuesConsumer.java
new file mode 100644
index 0000000..587298e
--- /dev/null
+++ b/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41SimpleDocValuesConsumer.java
@@ -0,0 +1,177 @@
+package org.apache.lucene.codecs.lucene41;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Iterator;
+
+import org.apache.lucene.codecs.CodecUtil;
+import org.apache.lucene.codecs.SimpleDVConsumer;
+import org.apache.lucene.index.FieldInfo;
+import org.apache.lucene.index.IndexFileNames;
+import org.apache.lucene.index.SegmentWriteState;
+import org.apache.lucene.store.IndexOutput;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.packed.PackedInts;
+import org.apache.lucene.util.packed.PackedInts.FormatAndBits;
+
+/**
+ * Writes norms one of two ways:
+ * 1. packed ints as deltas from minValue
+ * 2. packed ints as ordinals to a table (if the number of values is small, e.g. <= 256)
+ * 
+ * the latter is typically much smaller with lucene's sims, as only some byte values are used,
+ * but its often a nonlinear mapping, especially if you dont use crazy boosts.
+ */
+class Lucene41SimpleDocValuesConsumer extends SimpleDVConsumer {
+  static final int VERSION_START = 0;
+  static final int VERSION_CURRENT = VERSION_START;
+  
+  final IndexOutput data, meta;
+  final int maxDoc;
+  
+  Lucene41SimpleDocValuesConsumer(SegmentWriteState state, String dataCodec, String dataExtension, String metaCodec, String metaExtension) throws IOException {
+    boolean success = false;
+    try {
+      String dataName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, dataExtension);
+      data = state.directory.createOutput(dataName, state.context);
+      CodecUtil.writeHeader(data, dataCodec, VERSION_CURRENT);
+      String metaName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, metaExtension);
+      meta = state.directory.createOutput(metaName, state.context);
+      CodecUtil.writeHeader(meta, metaCodec, VERSION_CURRENT);
+      maxDoc = state.segmentInfo.getDocCount();
+      success = true;
+    } finally {
+      if (!success) {
+        IOUtils.closeWhileHandlingException(this);
+      }
+    }
+  }
+  
+  @Override
+  public void addNumericField(FieldInfo field, Iterable<Number> values) throws IOException {
+    meta.writeVInt(field.number);
+    meta.writeLong(data.getFilePointer());
+    long minValue = Long.MAX_VALUE;
+    long maxValue = Long.MIN_VALUE;
+    int count = 0;
+    // TODO: more efficient?
+    HashSet<Long> uniqueValues = new HashSet<Long>();
+    for(Number nv : values) {
+      long v = nv.longValue();
+      minValue = Math.min(minValue, v);
+      maxValue = Math.max(maxValue, v);
+      count++;
+      if (uniqueValues != null) {
+        if (uniqueValues.add(v)) {
+          if (uniqueValues.size() > 256) {
+            uniqueValues = null;
+          }
+        }
+      }
+    }
+
+    long delta = maxValue - minValue;
+    final int bitsPerValue;
+    if (delta < 0) {
+      bitsPerValue = 64;
+      meta.writeByte((byte)0); // delta-compressed
+    } else if (uniqueValues != null && PackedInts.bitsRequired(uniqueValues.size()-1) < PackedInts.bitsRequired(delta)) {
+      // smaller to tableize
+      bitsPerValue = PackedInts.bitsRequired(uniqueValues.size()-1);
+      minValue = 0; // we will write indexes into the table instead of values
+      meta.writeByte((byte)1); // table-compressed
+      Long[] decode = uniqueValues.toArray(new Long[uniqueValues.size()]);
+      final HashMap<Long,Integer> encode = new HashMap<Long,Integer>();
+      data.writeVInt(decode.length);
+      for (int i = 0; i < decode.length; i++) {
+        data.writeLong(decode[i]);
+        encode.put(decode[i], i);
+      }
+      final Iterable<Number> original = values;
+      values = new Iterable<Number>() {
+        @Override
+        public Iterator<Number> iterator() {
+          final Iterator<Number> inner = original.iterator();
+          return new Iterator<Number>() {
+            @Override
+            public boolean hasNext() {
+              return inner.hasNext();
+            }
+
+            @Override
+            public Number next() {
+              return encode.get(inner.next());
+            }
+
+            @Override
+            public void remove() { throw new UnsupportedOperationException(); }
+          };
+        }
+      };
+    } else {
+      bitsPerValue = PackedInts.bitsRequired(delta);
+      meta.writeByte((byte)0); // delta-compressed
+    }
+
+    data.writeLong(minValue);
+
+    FormatAndBits formatAndBits = PackedInts.fastestFormatAndBits(count, bitsPerValue, PackedInts.COMPACT);   
+    final PackedInts.Writer writer = PackedInts.getWriter(data, count, formatAndBits.bitsPerValue, 0);
+    for(Number nv : values) {
+      writer.add(nv.longValue() - minValue);
+    }
+    writer.finish();
+  }
+  
+  @Override
+  public void close() throws IOException {
+    // nocommit: just write this to a RAMfile or something and flush it here, with #fields first.
+    // this meta is a tiny file so this hurts nobody
+    boolean success = false;
+    try {
+      if (meta != null) {
+        meta.writeVInt(-1);
+      }
+      success = true;
+    } finally {
+      if (success) {
+        IOUtils.close(data, meta);
+      } else {
+        IOUtils.closeWhileHandlingException(data, meta);
+      }
+    }
+  }
+
+  // nocommit: have SimpleDVConsumer extend SimpleNormsConsumer?
+  @Override
+  public void addBinaryField(FieldInfo field, Iterable<BytesRef> values) throws IOException {
+    throw new AssertionError();
+  }
+
+  @Override
+  public void addSortedField(FieldInfo field, Iterable<BytesRef> values, Iterable<Number> docToOrd) throws IOException {
+    throw new AssertionError();
+  }
+  
+  // nocommit: can/should we make override merge + make it smarter to pull the values 
+  // directly from disk for fields that arent already loaded up in ram?
+}
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41SimpleDocValuesFormat.java b/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41SimpleDocValuesFormat.java
new file mode 100644
index 0000000..ccd81e7
--- /dev/null
+++ b/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41SimpleDocValuesFormat.java
@@ -0,0 +1,44 @@
+package org.apache.lucene.codecs.lucene41;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.codecs.SimpleDVConsumer;
+import org.apache.lucene.codecs.SimpleDVProducer;
+import org.apache.lucene.codecs.SimpleNormsFormat;
+import org.apache.lucene.index.SegmentReadState;
+import org.apache.lucene.index.SegmentWriteState;
+
+public class Lucene41SimpleDocValuesFormat extends SimpleNormsFormat {
+
+  @Override
+  public SimpleDVConsumer normsConsumer(SegmentWriteState state) throws IOException {
+    return new Lucene41SimpleDocValuesConsumer(state, DATA_CODEC, DATA_EXTENSION, METADATA_CODEC, METADATA_EXTENSION);
+  }
+  
+  @Override
+  public SimpleDVProducer normsProducer(SegmentReadState state) throws IOException {
+    return new Lucene41SimpleDocValuesProducer(state, DATA_CODEC, DATA_EXTENSION, METADATA_CODEC, METADATA_EXTENSION);
+  }
+  
+  private static final String DATA_CODEC = "Lucene41DocValuesData";
+  private static final String DATA_EXTENSION = "dvd";
+  private static final String METADATA_CODEC = "Lucene41DocValuesMetadata";
+  private static final String METADATA_EXTENSION = "dvm";
+}
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41SimpleDocValuesProducer.java b/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41SimpleDocValuesProducer.java
new file mode 100644
index 0000000..f55f88b
--- /dev/null
+++ b/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41SimpleDocValuesProducer.java
@@ -0,0 +1,144 @@
+package org.apache.lucene.codecs.lucene41;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.lucene.codecs.CodecUtil;
+import org.apache.lucene.codecs.SimpleDVProducer;
+import org.apache.lucene.index.BinaryDocValues;
+import org.apache.lucene.index.FieldInfo;
+import org.apache.lucene.index.FieldInfos;
+import org.apache.lucene.index.IndexFileNames;
+import org.apache.lucene.index.NumericDocValues;
+import org.apache.lucene.index.SegmentReadState;
+import org.apache.lucene.index.SortedDocValues;
+import org.apache.lucene.store.IndexInput;
+import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.packed.PackedInts;
+
+class Lucene41SimpleDocValuesProducer extends SimpleDVProducer {
+  private final Map<Integer,NumericEntry> numerics;
+  private final IndexInput data;
+  
+  // ram instances we have already loaded
+  private final Map<Integer,NumericDocValues> ramInstances = 
+      new HashMap<Integer,NumericDocValues>();
+  
+  Lucene41SimpleDocValuesProducer(SegmentReadState state, String dataCodec, String dataExtension, String metaCodec, String metaExtension) throws IOException {
+    String metaName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, metaExtension);
+    // read in the entries from the metadata file.
+    IndexInput in = state.directory.openInput(metaName, state.context);
+    boolean success = false;
+    try {
+      CodecUtil.checkHeader(in, metaCodec, 
+                                Lucene41SimpleDocValuesConsumer.VERSION_START,
+                                Lucene41SimpleDocValuesConsumer.VERSION_START);
+      numerics = new HashMap<Integer,NumericEntry>();
+      readFields(in, state.fieldInfos);
+      success = true;
+    } finally {
+      if (success) {
+        IOUtils.close(in);
+      } else {
+        IOUtils.closeWhileHandlingException(in);
+      }
+    }
+    
+    String dataName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, dataExtension);
+    data = state.directory.openInput(dataName, state.context);
+    CodecUtil.checkHeader(data, dataCodec, 
+                                Lucene41SimpleDocValuesConsumer.VERSION_START,
+                                Lucene41SimpleDocValuesConsumer.VERSION_START);
+  }
+  
+  private void readFields(IndexInput meta, FieldInfos infos) throws IOException {
+    int fieldNumber = meta.readVInt();
+    while (fieldNumber != -1) {
+      NumericEntry entry = new NumericEntry();
+      entry.offset = meta.readLong();
+      entry.tableized = meta.readByte() != 0;
+      numerics.put(fieldNumber, entry);
+      fieldNumber = meta.readVInt();
+    }
+  }
+
+  @Override
+  public synchronized NumericDocValues getNumeric(FieldInfo field) throws IOException {
+    NumericDocValues instance = ramInstances.get(field.number);
+    if (instance == null) {
+      instance = loadNumeric(field);
+      ramInstances.put(field.number, instance);
+    }
+    return instance;
+  }
+  
+  private NumericDocValues loadNumeric(FieldInfo field) throws IOException {
+    NumericEntry entry = numerics.get(field.number);
+    final IndexInput data = this.data.clone();
+    data.seek(entry.offset);
+    if (entry.tableized) {
+      int size = data.readVInt();
+      final long decode[] = new long[size];
+      for (int i = 0; i < decode.length; i++) {
+        decode[i] = data.readLong();
+      }
+      final long minValue = data.readLong();
+      assert minValue == 0;
+      final PackedInts.Reader reader = PackedInts.getReader(data);
+      return new NumericDocValues() {
+        @Override
+        public long get(int docID) {
+          return decode[(int)reader.get(docID)];
+        }
+      };
+    } else {
+      final long minValue = data.readLong();
+      final PackedInts.Reader reader = PackedInts.getReader(data);
+      return new NumericDocValues() {
+        @Override
+        public long get(int docID) {
+          return minValue + reader.get(docID);
+        }
+      };
+    }
+  }
+
+  @Override
+  public BinaryDocValues getBinary(FieldInfo field) throws IOException {
+    throw new AssertionError();
+  }
+
+  @Override
+  public SortedDocValues getSorted(FieldInfo field) throws IOException {
+    throw new AssertionError();
+  }
+
+  @Override
+  public void close() throws IOException {
+    data.close();
+  }
+  
+  static class NumericEntry {
+    long offset;
+    boolean tableized;
+  }
+
+}
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41SimpleNormsConsumer.java b/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41SimpleNormsConsumer.java
deleted file mode 100644
index 04855c5..0000000
--- a/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41SimpleNormsConsumer.java
+++ /dev/null
@@ -1,176 +0,0 @@
-package org.apache.lucene.codecs.lucene41;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Iterator;
-
-import org.apache.lucene.codecs.CodecUtil;
-import org.apache.lucene.codecs.SimpleDVConsumer;
-import org.apache.lucene.index.FieldInfo;
-import org.apache.lucene.index.IndexFileNames;
-import org.apache.lucene.index.SegmentWriteState;
-import org.apache.lucene.store.IndexOutput;
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.IOUtils;
-import org.apache.lucene.util.packed.PackedInts;
-import org.apache.lucene.util.packed.PackedInts.FormatAndBits;
-
-/**
- * Writes norms one of two ways:
- * 1. packed ints as deltas from minValue
- * 2. packed ints as ordinals to a table (if the number of values is small, e.g. <= 256)
- * 
- * the latter is typically much smaller with lucene's sims, as only some byte values are used,
- * but its often a nonlinear mapping, especially if you dont use crazy boosts.
- */
-class Lucene41SimpleNormsConsumer extends SimpleDVConsumer {
-  final IndexOutput data, meta;
-  final int maxDoc;
-  
-  Lucene41SimpleNormsConsumer(SegmentWriteState state) throws IOException {
-    boolean success = false;
-    try {
-      String dataName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, "nvd");
-      data = state.directory.createOutput(dataName, state.context);
-      CodecUtil.writeHeader(data, Lucene41SimpleNormsFormat.DATA_CODEC, 
-                                  Lucene41SimpleNormsFormat.VERSION_CURRENT);
-      String metaName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, "nvm");
-      meta = state.directory.createOutput(metaName, state.context);
-      CodecUtil.writeHeader(meta, Lucene41SimpleNormsFormat.METADATA_CODEC, 
-                                  Lucene41SimpleNormsFormat.VERSION_CURRENT);
-      maxDoc = state.segmentInfo.getDocCount();
-      success = true;
-    } finally {
-      if (!success) {
-        IOUtils.closeWhileHandlingException(this);
-      }
-    }
-  }
-  
-  @Override
-  public void addNumericField(FieldInfo field, Iterable<Number> values) throws IOException {
-    meta.writeVInt(field.number);
-    meta.writeLong(data.getFilePointer());
-    long minValue = Long.MAX_VALUE;
-    long maxValue = Long.MIN_VALUE;
-    int count = 0;
-    // TODO: more efficient?
-    HashSet<Long> uniqueValues = new HashSet<Long>();
-    for(Number nv : values) {
-      long v = nv.longValue();
-      minValue = Math.min(minValue, v);
-      maxValue = Math.max(maxValue, v);
-      count++;
-      if (uniqueValues != null) {
-        if (uniqueValues.add(v)) {
-          if (uniqueValues.size() > 256) {
-            uniqueValues = null;
-          }
-        }
-      }
-    }
-
-    long delta = maxValue - minValue;
-    final int bitsPerValue;
-    if (delta < 0) {
-      bitsPerValue = 64;
-      meta.writeByte((byte)0); // delta-compressed
-    } else if (uniqueValues != null && PackedInts.bitsRequired(uniqueValues.size()-1) < PackedInts.bitsRequired(delta)) {
-      // smaller to tableize
-      bitsPerValue = PackedInts.bitsRequired(uniqueValues.size()-1);
-      minValue = 0; // we will write indexes into the table instead of values
-      meta.writeByte((byte)1); // table-compressed
-      Long[] decode = uniqueValues.toArray(new Long[uniqueValues.size()]);
-      final HashMap<Long,Integer> encode = new HashMap<Long,Integer>();
-      data.writeVInt(decode.length);
-      for (int i = 0; i < decode.length; i++) {
-        data.writeLong(decode[i]);
-        encode.put(decode[i], i);
-      }
-      final Iterable<Number> original = values;
-      values = new Iterable<Number>() {
-        @Override
-        public Iterator<Number> iterator() {
-          final Iterator<Number> inner = original.iterator();
-          return new Iterator<Number>() {
-            @Override
-            public boolean hasNext() {
-              return inner.hasNext();
-            }
-
-            @Override
-            public Number next() {
-              return encode.get(inner.next());
-            }
-
-            @Override
-            public void remove() { throw new UnsupportedOperationException(); }
-          };
-        }
-      };
-    } else {
-      bitsPerValue = PackedInts.bitsRequired(delta);
-      meta.writeByte((byte)0); // delta-compressed
-    }
-
-    data.writeLong(minValue);
-
-    FormatAndBits formatAndBits = PackedInts.fastestFormatAndBits(count, bitsPerValue, PackedInts.COMPACT);   
-    final PackedInts.Writer writer = PackedInts.getWriter(data, count, formatAndBits.bitsPerValue, 0);
-    for(Number nv : values) {
-      writer.add(nv.longValue() - minValue);
-    }
-    writer.finish();
-  }
-  
-  @Override
-  public void close() throws IOException {
-    // nocommit: just write this to a RAMfile or something and flush it here, with #fields first.
-    // this meta is a tiny file so this hurts nobody
-    boolean success = false;
-    try {
-      if (meta != null) {
-        meta.writeVInt(-1);
-      }
-      success = true;
-    } finally {
-      if (success) {
-        IOUtils.close(data, meta);
-      } else {
-        IOUtils.closeWhileHandlingException(data, meta);
-      }
-    }
-  }
-
-  // nocommit: have SimpleDVConsumer extend SimpleNormsConsumer?
-  @Override
-  public void addBinaryField(FieldInfo field, Iterable<BytesRef> values) throws IOException {
-    throw new AssertionError();
-  }
-
-  @Override
-  public void addSortedField(FieldInfo field, Iterable<BytesRef> values, Iterable<Number> docToOrd) throws IOException {
-    throw new AssertionError();
-  }
-  
-  // nocommit: can/should we make override merge + make it smarter to pull the values 
-  // directly from disk for fields that arent already loaded up in ram?
-}
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41SimpleNormsFormat.java b/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41SimpleNormsFormat.java
index c7a74f5..748d083fd 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41SimpleNormsFormat.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41SimpleNormsFormat.java
@@ -29,16 +29,16 @@ public class Lucene41SimpleNormsFormat extends SimpleNormsFormat {
 
   @Override
   public SimpleDVConsumer normsConsumer(SegmentWriteState state) throws IOException {
-    return new Lucene41SimpleNormsConsumer(state);
+    return new Lucene41SimpleDocValuesConsumer(state, DATA_CODEC, DATA_EXTENSION, METADATA_CODEC, METADATA_EXTENSION);
   }
   
   @Override
   public SimpleDVProducer normsProducer(SegmentReadState state) throws IOException {
-    return new Lucene41SimpleNormsProducer(state);
+    return new Lucene41SimpleDocValuesProducer(state, DATA_CODEC, DATA_EXTENSION, METADATA_CODEC, METADATA_EXTENSION);
   }
   
-  static final String DATA_CODEC = "Lucene41NormsData";
-  static final String METADATA_CODEC = "Lucene41DocValuesMetadata";
-  static final int VERSION_START = 0;
-  static final int VERSION_CURRENT = VERSION_START;
+  private static final String DATA_CODEC = "Lucene41NormsData";
+  private static final String DATA_EXTENSION = "nvd";
+  private static final String METADATA_CODEC = "Lucene41NormsMetadata";
+  private static final String METADATA_EXTENSION = "nvm";
 }
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41SimpleNormsProducer.java b/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41SimpleNormsProducer.java
deleted file mode 100644
index fce1804..0000000
--- a/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41SimpleNormsProducer.java
+++ /dev/null
@@ -1,144 +0,0 @@
-package org.apache.lucene.codecs.lucene41;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.util.HashMap;
-import java.util.Map;
-
-import org.apache.lucene.codecs.CodecUtil;
-import org.apache.lucene.codecs.SimpleDVProducer;
-import org.apache.lucene.index.BinaryDocValues;
-import org.apache.lucene.index.FieldInfo;
-import org.apache.lucene.index.FieldInfos;
-import org.apache.lucene.index.IndexFileNames;
-import org.apache.lucene.index.NumericDocValues;
-import org.apache.lucene.index.SegmentReadState;
-import org.apache.lucene.index.SortedDocValues;
-import org.apache.lucene.store.IndexInput;
-import org.apache.lucene.util.IOUtils;
-import org.apache.lucene.util.packed.PackedInts;
-
-class Lucene41SimpleNormsProducer extends SimpleDVProducer {
-  private final Map<Integer,NumericEntry> numerics;
-  private final IndexInput data;
-  
-  // ram instances we have already loaded
-  private final Map<Integer,NumericDocValues> ramInstances = 
-      new HashMap<Integer,NumericDocValues>();
-  
-  Lucene41SimpleNormsProducer(SegmentReadState state) throws IOException {
-    String metaName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, "nvm");
-    // read in the entries from the metadata file.
-    IndexInput in = state.directory.openInput(metaName, state.context);
-    boolean success = false;
-    try {
-      CodecUtil.checkHeader(in, Lucene41SimpleNormsFormat.METADATA_CODEC, 
-                                Lucene41SimpleNormsFormat.VERSION_START,
-                                Lucene41SimpleNormsFormat.VERSION_START);
-      numerics = new HashMap<Integer,NumericEntry>();
-      readFields(in, state.fieldInfos);
-      success = true;
-    } finally {
-      if (success) {
-        IOUtils.close(in);
-      } else {
-        IOUtils.closeWhileHandlingException(in);
-      }
-    }
-    
-    String dataName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, "nvd");
-    data = state.directory.openInput(dataName, state.context);
-    CodecUtil.checkHeader(data, Lucene41SimpleNormsFormat.DATA_CODEC, 
-                                Lucene41SimpleNormsFormat.VERSION_START,
-                                Lucene41SimpleNormsFormat.VERSION_START);
-  }
-  
-  private void readFields(IndexInput meta, FieldInfos infos) throws IOException {
-    int fieldNumber = meta.readVInt();
-    while (fieldNumber != -1) {
-      NumericEntry entry = new NumericEntry();
-      entry.offset = meta.readLong();
-      entry.tableized = meta.readByte() != 0;
-      numerics.put(fieldNumber, entry);
-      fieldNumber = meta.readVInt();
-    }
-  }
-
-  @Override
-  public synchronized NumericDocValues getNumeric(FieldInfo field) throws IOException {
-    NumericDocValues instance = ramInstances.get(field.number);
-    if (instance == null) {
-      instance = loadNumeric(field);
-      ramInstances.put(field.number, instance);
-    }
-    return instance;
-  }
-  
-  private NumericDocValues loadNumeric(FieldInfo field) throws IOException {
-    NumericEntry entry = numerics.get(field.number);
-    final IndexInput data = this.data.clone();
-    data.seek(entry.offset);
-    if (entry.tableized) {
-      int size = data.readVInt();
-      final long decode[] = new long[size];
-      for (int i = 0; i < decode.length; i++) {
-        decode[i] = data.readLong();
-      }
-      final long minValue = data.readLong();
-      assert minValue == 0;
-      final PackedInts.Reader reader = PackedInts.getReader(data);
-      return new NumericDocValues() {
-        @Override
-        public long get(int docID) {
-          return decode[(int)reader.get(docID)];
-        }
-      };
-    } else {
-      final long minValue = data.readLong();
-      final PackedInts.Reader reader = PackedInts.getReader(data);
-      return new NumericDocValues() {
-        @Override
-        public long get(int docID) {
-          return minValue + reader.get(docID);
-        }
-      };
-    }
-  }
-
-  @Override
-  public BinaryDocValues getBinary(FieldInfo field) throws IOException {
-    throw new AssertionError();
-  }
-
-  @Override
-  public SortedDocValues getSorted(FieldInfo field) throws IOException {
-    throw new AssertionError();
-  }
-
-  @Override
-  public void close() throws IOException {
-    data.close();
-  }
-  
-  static class NumericEntry {
-    long offset;
-    boolean tableized;
-  }
-
-}

