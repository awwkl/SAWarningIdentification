GitDiffStart: a0ad582c2954f9174a60fd4fb690ec253c4ee5e1 | Mon Aug 30 20:52:15 2004 +0000
diff --git a/src/test/org/apache/lucene/search/TestPhraseQuery.java b/src/test/org/apache/lucene/search/TestPhraseQuery.java
index cbcc803..6e498a3 100644
--- a/src/test/org/apache/lucene/search/TestPhraseQuery.java
+++ b/src/test/org/apache/lucene/search/TestPhraseQuery.java
@@ -183,12 +183,12 @@ public class TestPhraseQuery extends TestCase {
     IndexWriter writer = new IndexWriter(directory, new WhitespaceAnalyzer(), true);
     
     Document doc = new Document();
-    doc.add(new Field("source", "marketing info", true, true, true));
+    doc.add(new Field("source", "marketing info", Field.Store.YES, Field.Index.TOKENIZED));
     writer.addDocument(doc);
     
     doc = new Document();
-    doc.add(new Field("contents", "foobar", true, true, true));
-    doc.add(new Field("source", "marketing info", true, true, true)); 
+    doc.add(new Field("contents", "foobar", Field.Store.YES, Field.Index.TOKENIZED));
+    doc.add(new Field("source", "marketing info", Field.Store.YES, Field.Index.TOKENIZED)); 
     writer.addDocument(doc);
     
     writer.optimize();
@@ -213,15 +213,15 @@ public class TestPhraseQuery extends TestCase {
     
     writer = new IndexWriter(directory, new WhitespaceAnalyzer(), true);
     doc = new Document();
-    doc.add(new Field("contents", "map entry woo", true, true, true));
+    doc.add(new Field("contents", "map entry woo", Field.Store.YES, Field.Index.TOKENIZED));
     writer.addDocument(doc);
 
     doc = new Document();
-    doc.add(new Field("contents", "woo map entry", true, true, true));
+    doc.add(new Field("contents", "woo map entry", Field.Store.YES, Field.Index.TOKENIZED));
     writer.addDocument(doc);
 
     doc = new Document();
-    doc.add(new Field("contents", "map foobarword entry woo", true, true, true));
+    doc.add(new Field("contents", "map foobarword entry woo", Field.Store.YES, Field.Index.TOKENIZED));
     writer.addDocument(doc);
 
     writer.optimize();
diff --git a/src/test/org/apache/lucene/search/TestSort.java b/src/test/org/apache/lucene/search/TestSort.java
index 1c3ec13..960c577 100644
--- a/src/test/org/apache/lucene/search/TestSort.java
+++ b/src/test/org/apache/lucene/search/TestSort.java
@@ -113,13 +113,13 @@ implements Serializable {
 		IndexWriter writer = new IndexWriter (indexStore, new SimpleAnalyzer(), true);
 		for (int i=0; i<data.length; ++i) {
 			if (((i%2)==0 && even) || ((i%2)==1 && odd)) {
-				Document doc = new Document();          // store, index, token
-				doc.add (new Field ("tracer",   data[i][0], true, false, false));
-				doc.add (new Field ("contents", data[i][1], false, true, true));
-				if (data[i][2] != null) doc.add (new Field ("int",      data[i][2], false, true, false));
-				if (data[i][3] != null) doc.add (new Field ("float",    data[i][3], false, true, false));
-				if (data[i][4] != null) doc.add (new Field ("string",   data[i][4], false, true, false));
-				if (data[i][5] != null) doc.add (new Field ("custom",   data[i][5], false, true, false));
+				Document doc = new Document();
+				doc.add (new Field ("tracer",   data[i][0], Field.Store.YES, Field.Index.NO));
+				doc.add (new Field ("contents", data[i][1], Field.Store.NO, Field.Index.TOKENIZED));
+				if (data[i][2] != null) doc.add (new Field ("int",      data[i][2], Field.Store.NO, Field.Index.UN_TOKENIZED));
+				if (data[i][3] != null) doc.add (new Field ("float",    data[i][3], Field.Store.NO, Field.Index.UN_TOKENIZED));
+				if (data[i][4] != null) doc.add (new Field ("string",   data[i][4], Field.Store.NO, Field.Index.UN_TOKENIZED));
+				if (data[i][5] != null) doc.add (new Field ("custom",   data[i][5], Field.Store.NO, Field.Index.UN_TOKENIZED));
 				writer.addDocument (doc);
 			}
 		}

