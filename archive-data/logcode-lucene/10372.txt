GitDiffStart: 8347bda24a573b6c10169baecc89d505baabbf07 | Sun Dec 2 17:58:17 2012 +0000
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/BinaryDocValuesConsumer.java b/lucene/core/src/java/org/apache/lucene/codecs/BinaryDocValuesConsumer.java
index bc8c3f4..a012c4c 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/BinaryDocValuesConsumer.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/BinaryDocValuesConsumer.java
@@ -18,6 +18,7 @@ package org.apache.lucene.codecs;
  */
 
 import java.io.IOException;
+import java.util.List;
 
 import org.apache.lucene.index.AtomicReader;
 import org.apache.lucene.index.BinaryDocValues;
@@ -29,21 +30,18 @@ public abstract class BinaryDocValuesConsumer {
   public abstract void add(BytesRef value) throws IOException;
   public abstract void finish() throws IOException;
   
-  public int merge(MergeState mergeState) throws IOException {
+  public int merge(MergeState mergeState, List<BinaryDocValues> toMerge) throws IOException {
     int docCount = 0;
     final BytesRef bytes = new BytesRef();
-    for (AtomicReader reader : mergeState.readers) {
-      final int maxDoc = reader.maxDoc();
-      final Bits liveDocs = reader.getLiveDocs();
-
-      BinaryDocValues source = reader.getBinaryDocValues(mergeState.fieldInfo.name);
-      if (source == null) {
-        source = new BinaryDocValues.EMPTY(maxDoc);
-      }
+    for (int readerIDX=0;readerIDX<toMerge.size();readerIDX++) {
+      AtomicReader reader = mergeState.readers.get(readerIDX);
+      int maxDoc = reader.maxDoc();
+      Bits liveDocs = reader.getLiveDocs();
 
+      BinaryDocValues values = toMerge.get(readerIDX);
       for (int i = 0; i < maxDoc; i++) {
         if (liveDocs == null || liveDocs.get(i)) {
-          source.get(i, bytes);
+          values.get(i, bytes);
           add(bytes);
         }
         docCount++;
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/NumericDocValuesConsumer.java b/lucene/core/src/java/org/apache/lucene/codecs/NumericDocValuesConsumer.java
index ff96443..6d13fdf 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/NumericDocValuesConsumer.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/NumericDocValuesConsumer.java
@@ -18,6 +18,7 @@ package org.apache.lucene.codecs;
  */
 
 import java.io.IOException;
+import java.util.List;
 
 import org.apache.lucene.index.AtomicReader;
 import org.apache.lucene.index.MergeState;
@@ -28,19 +29,16 @@ public abstract class NumericDocValuesConsumer {
   public abstract void add(long value) throws IOException;
   public abstract void finish() throws IOException;
 
-  // nocommit bogus forceNorms
-  public int merge(MergeState mergeState, boolean forceNorms) throws IOException {
+  public int merge(MergeState mergeState, List<NumericDocValues> toMerge) throws IOException {
     int docCount = 0;
-    for (AtomicReader reader : mergeState.readers) {
-      final int maxDoc = reader.maxDoc();
-      final Bits liveDocs = reader.getLiveDocs();
-      NumericDocValues source = forceNorms ? reader.simpleNormValues(mergeState.fieldInfo.name) : reader.getNumericDocValues(mergeState.fieldInfo.name);
-      if (source == null) {
-        source = new NumericDocValues.EMPTY(maxDoc);
-      }
+    for (int readerIDX=0;readerIDX<toMerge.size();readerIDX++) {
+      AtomicReader reader = mergeState.readers.get(readerIDX);
+      int maxDoc = reader.maxDoc();
+      Bits liveDocs = reader.getLiveDocs();
+      NumericDocValues values = toMerge.get(readerIDX);
       for (int i = 0; i < maxDoc; i++) {
         if (liveDocs == null || liveDocs.get(i)) {
-          add(source.get(i));
+          add(values.get(i));
         }
         docCount++;
         mergeState.checkAbort.work(300);
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/SimpleDVConsumer.java b/lucene/core/src/java/org/apache/lucene/codecs/SimpleDVConsumer.java
index 5818513..1484de2 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/SimpleDVConsumer.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/SimpleDVConsumer.java
@@ -19,6 +19,7 @@ package org.apache.lucene.codecs;
 
 import java.io.Closeable;
 import java.io.IOException;
+import java.util.List;
 
 import org.apache.lucene.index.AtomicReader;
 import org.apache.lucene.index.BinaryDocValues;
@@ -26,6 +27,7 @@ import org.apache.lucene.index.DocValues;
 import org.apache.lucene.index.FieldInfo;
 import org.apache.lucene.index.MergeState;
 import org.apache.lucene.index.NumericDocValues;
+import org.apache.lucene.index.SortedDocValues;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 
@@ -40,90 +42,46 @@ public abstract class SimpleDVConsumer implements Closeable {
   // nocommit: figure out whats fair here.
   public abstract SortedDocValuesConsumer addSortedField(FieldInfo field, int valueCount, boolean fixedLength, int maxLength) throws IOException;
 
-  // nocommit bogus forceNorms param:
-  public void merge(MergeState mergeState, boolean forceNorms) throws IOException {
-    for (FieldInfo field : mergeState.fieldInfos) {
-      if ((!forceNorms && field.hasDocValues()) || (forceNorms && field.isIndexed() && !field.omitsNorms())) {
-        mergeState.fieldInfo = field;
-        //System.out.println("merge field=" + field.name + " forceNorms=" + forceNorms);
-        // nocommit a field can never have doc values AND norms!?
-        DocValues.Type type = forceNorms ? DocValues.Type.FIXED_INTS_8 : field.getDocValuesType();
-        switch(type) {
-          case VAR_INTS:
-          case FIXED_INTS_8:
-          case FIXED_INTS_16:
-          case FIXED_INTS_32:
-          case FIXED_INTS_64:
-          case FLOAT_64:
-          case FLOAT_32:
-            mergeNumericField(mergeState, forceNorms);
-            break;
-          case BYTES_VAR_SORTED:
-          case BYTES_FIXED_SORTED:
-          case BYTES_VAR_DEREF:
-          case BYTES_FIXED_DEREF:
-            mergeSortedField(mergeState);
-            break;
-          case BYTES_VAR_STRAIGHT:
-          case BYTES_FIXED_STRAIGHT:
-            mergeBinaryField(mergeState);
-            break;
-          default:
-            throw new AssertionError();
-        }
-      }
-    }
-  }
-
-  // nocommit bogus forceNorms:
   // dead simple impl: codec can optimize
-  protected void mergeNumericField(MergeState mergeState, boolean forceNorms) throws IOException {
+  public void mergeNumericField(FieldInfo fieldInfo, MergeState mergeState, List<NumericDocValues> toMerge) throws IOException {
     // first compute min and max value of live ones to be merged.
     long minValue = Long.MAX_VALUE;
     long maxValue = Long.MIN_VALUE;
-    for (AtomicReader reader : mergeState.readers) {
-      final int maxDoc = reader.maxDoc();
-      final Bits liveDocs = reader.getLiveDocs();
-      //System.out.println("merge field=" + mergeState.fieldInfo.name);
-      NumericDocValues docValues = forceNorms ? reader.simpleNormValues(mergeState.fieldInfo.name) : reader.getNumericDocValues(mergeState.fieldInfo.name);
-      if (docValues == null) {
-        // nocommit this isn't correct i think?  ie this one
-        // segment may have no docs containing this
-        // field... and that doesn't mean norms are omitted ...
-        //assert !forceNorms;
-        docValues = new NumericDocValues.EMPTY(maxDoc);
-      }
+    for (int readerIDX=0;readerIDX<toMerge.size();readerIDX++) {
+      AtomicReader reader = mergeState.readers.get(readerIDX);
+      int maxDoc = reader.maxDoc();
+      Bits liveDocs = reader.getLiveDocs();
+      NumericDocValues values = toMerge.get(readerIDX);
       for (int i = 0; i < maxDoc; i++) {
         if (liveDocs == null || liveDocs.get(i)) {
-          long val = docValues.get(i);
+          long val = values.get(i);
           minValue = Math.min(val, minValue);
           maxValue = Math.max(val, maxValue);
         }
         mergeState.checkAbort.work(300);
       }
     }
+
     // now we can merge
-    NumericDocValuesConsumer field = addNumericField(mergeState.fieldInfo, minValue, maxValue);
-    field.merge(mergeState, forceNorms);
+    NumericDocValuesConsumer field = addNumericField(fieldInfo, minValue, maxValue);
+    field.merge(mergeState, toMerge);
   }
   
   // dead simple impl: codec can optimize
-  protected void mergeBinaryField(MergeState mergeState) throws IOException {
+  public void mergeBinaryField(FieldInfo fieldInfo, MergeState mergeState, List<BinaryDocValues> toMerge) throws IOException {
     // first compute fixedLength and maxLength of live ones to be merged.
     // nocommit: messy, and can be simplified by using docValues.maxLength/fixedLength in many cases.
     boolean fixedLength = true;
     int maxLength = -1;
     BytesRef bytes = new BytesRef();
-    for (AtomicReader reader : mergeState.readers) {
-      final int maxDoc = reader.maxDoc();
-      final Bits liveDocs = reader.getLiveDocs();
-      BinaryDocValues docValues = reader.getBinaryDocValues(mergeState.fieldInfo.name);
-      if (docValues == null) {
-        docValues = new BinaryDocValues.EMPTY(maxDoc);
-      }
+    for (int readerIDX=0;readerIDX<toMerge.size();readerIDX++) {
+      AtomicReader reader = mergeState.readers.get(readerIDX);      
+      int maxDoc = reader.maxDoc();
+      Bits liveDocs = reader.getLiveDocs();
+      BinaryDocValues values = toMerge.get(readerIDX);
       for (int i = 0; i < maxDoc; i++) {
         if (liveDocs == null || liveDocs.get(i)) {
-          docValues.get(i, bytes);
+          values.get(i, bytes);
           if (maxLength == -1) {
             maxLength = bytes.length;
           } else {
@@ -136,14 +94,14 @@ public abstract class SimpleDVConsumer implements Closeable {
     }
     // now we can merge
     assert maxLength >= 0; // could this happen (nothing to do?)
-    BinaryDocValuesConsumer field = addBinaryField(mergeState.fieldInfo, fixedLength, maxLength);
-    field.merge(mergeState);
+    BinaryDocValuesConsumer field = addBinaryField(fieldInfo, fixedLength, maxLength);
+    field.merge(mergeState, toMerge);
   }
 
-  protected void mergeSortedField(MergeState mergeState) throws IOException {
+  public void mergeSortedField(FieldInfo fieldInfo, MergeState mergeState, List<SortedDocValues> toMerge) throws IOException {
     SortedDocValuesConsumer.Merger merger = new SortedDocValuesConsumer.Merger();
-    merger.merge(mergeState);
-    SortedDocValuesConsumer consumer = addSortedField(mergeState.fieldInfo, merger.numMergedTerms, merger.fixedLength >= 0, merger.maxLength);
+    merger.merge(mergeState, toMerge);
+    SortedDocValuesConsumer consumer = addSortedField(fieldInfo, merger.numMergedTerms, merger.fixedLength >= 0, merger.maxLength);
     consumer.merge(mergeState, merger);
   }
 }
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/SortedDocValuesConsumer.java b/lucene/core/src/java/org/apache/lucene/codecs/SortedDocValuesConsumer.java
index 0e7e3f8..3e1b13c 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/SortedDocValuesConsumer.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/SortedDocValuesConsumer.java
@@ -94,19 +94,17 @@ public abstract class SortedDocValuesConsumer {
       }
     }
 
-    public void merge(MergeState mergeState) throws IOException {
+    public void merge(MergeState mergeState, List<SortedDocValues> toMerge) throws IOException {
 
       // First pass: mark "live" terms
-      for (AtomicReader reader : mergeState.readers) {
+      for (int readerIDX=0;readerIDX<toMerge.size();readerIDX++) {
+        AtomicReader reader = mergeState.readers.get(readerIDX);      
         // nocommit what if this is null...?  need default source?
         int maxDoc = reader.maxDoc();
 
         SegmentState state = new SegmentState();
         state.reader = reader;
-        state.values = reader.getSortedDocValues(mergeState.fieldInfo.name);
-        if (state.values == null) {
-          state.values = new SortedDocValues.EMPTY(maxDoc);
-        }
+        state.values = toMerge.get(readerIDX);
 
         segStates.add(state);
         assert state.values.getValueCount() < Integer.MAX_VALUE;
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41Codec.java b/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41Codec.java
index 4c7f5fb..8375744 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41Codec.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41Codec.java
@@ -140,7 +140,9 @@ public class Lucene41Codec extends Codec {
   
   @Override
   public SimpleDocValuesFormat simpleDocValuesFormat() {
-    return simpleDocValuesFormat ;
+    // nocommit tests seem to fail if we use this:
+    //return simpleDocValuesFormat;
+    return null;
   }
 
   private final PostingsFormat defaultFormat = PostingsFormat.forName("Lucene41");
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/perfield/PerFieldDocValuesFormat.java b/lucene/core/src/java/org/apache/lucene/codecs/perfield/PerFieldDocValuesFormat.java
index 74caa45..08e4e08 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/perfield/PerFieldDocValuesFormat.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/perfield/PerFieldDocValuesFormat.java
@@ -123,7 +123,7 @@ public abstract class PerFieldDocValuesFormat extends SimpleDocValuesFormat {
       final String formatName = format.getName();
       
       String previousValue = field.putAttribute(PER_FIELD_FORMAT_KEY, formatName);
-      assert previousValue == null;
+      assert previousValue == null: "formatName=" + formatName + " prevValue=" + previousValue;
       
       Integer suffix;
       
diff --git a/lucene/core/src/java/org/apache/lucene/index/MergeState.java b/lucene/core/src/java/org/apache/lucene/index/MergeState.java
index 2d11ed0..7528e9d 100644
--- a/lucene/core/src/java/org/apache/lucene/index/MergeState.java
+++ b/lucene/core/src/java/org/apache/lucene/index/MergeState.java
@@ -218,6 +218,7 @@ public class MergeState {
   public InfoStream infoStream;
 
   /** Current field being merged. */
+  // nocommit shouldn't this be ... a param?:
   public FieldInfo fieldInfo;
   
   // TODO: get rid of this? it tells you which segments are 'aligned' (e.g. for bulk merging)
diff --git a/lucene/core/src/java/org/apache/lucene/index/SegmentMerger.java b/lucene/core/src/java/org/apache/lucene/index/SegmentMerger.java
index d35f6a1..ac2bd9d 100644
--- a/lucene/core/src/java/org/apache/lucene/index/SegmentMerger.java
+++ b/lucene/core/src/java/org/apache/lucene/index/SegmentMerger.java
@@ -109,36 +109,13 @@ final class SegmentMerger {
     
     if (mergeState.fieldInfos.hasNorms()) {
       mergeNorms(segmentWriteState);
-      if (codec.simpleNormsFormat() != null) {
-        SimpleDVConsumer consumer = codec.simpleNormsFormat().normsConsumer(segmentWriteState);
-        boolean success = false;
-        try {
-          consumer.merge(mergeState, true);
-        } finally {
-          if (success) {
-            IOUtils.close(consumer);
-          } else {
-            IOUtils.closeWhileHandlingException(consumer);            
-          }
-        }
-      }
+      mergeSimpleNorms(segmentWriteState);
     }
 
+    // Merge simple doc values:
     if (mergeState.fieldInfos.hasDocValues()) {
       // nocommit shouldn't need null check:
-      if (codec.simpleDocValuesFormat() != null) {
-        SimpleDVConsumer consumer = codec.simpleDocValuesFormat().fieldsConsumer(segmentWriteState);
-        boolean success = false;
-        try {
-          consumer.merge(mergeState, false);
-        } finally {
-          if (success) {
-            IOUtils.close(consumer);
-          } else {
-            IOUtils.closeWhileHandlingException(consumer);            
-          }
-        }
-      }
+      mergeSimpleDocValues(segmentWriteState);
     }
 
     if (mergeState.fieldInfos.hasVectors()) {
@@ -153,6 +130,88 @@ final class SegmentMerger {
     return mergeState;
   }
 
+  private void mergeSimpleDocValues(SegmentWriteState segmentWriteState) throws IOException {
+
+    if (codec.simpleDocValuesFormat() != null) {
+      SimpleDVConsumer consumer = codec.simpleDocValuesFormat().fieldsConsumer(segmentWriteState);
+      boolean success = false;
+      try {
+        for (FieldInfo field : mergeState.fieldInfos) {
+          DocValues.Type type = field.getDocValuesType();
+          if (type != null) {
+            if (DocValues.isNumber(type) || DocValues.isFloat(type)) {
+              List<NumericDocValues> toMerge = new ArrayList<NumericDocValues>();
+              for (AtomicReader reader : mergeState.readers) {
+                NumericDocValues values = reader.getNumericDocValues(field.name);
+                if (values == null) {
+                  values = new NumericDocValues.EMPTY(reader.maxDoc());
+                }
+                toMerge.add(values);
+              }
+              consumer.mergeNumericField(field, mergeState, toMerge);
+            } else if (DocValues.isBytes(type)) {
+              List<BinaryDocValues> toMerge = new ArrayList<BinaryDocValues>();
+              for (AtomicReader reader : mergeState.readers) {
+                BinaryDocValues values = reader.getBinaryDocValues(field.name);
+                if (values == null) {
+                  values = new BinaryDocValues.EMPTY(reader.maxDoc());
+                }
+                toMerge.add(values);
+              }
+              consumer.mergeBinaryField(field, mergeState, toMerge);
+            } else if (DocValues.isSortedBytes(type)) {
+              List<SortedDocValues> toMerge = new ArrayList<SortedDocValues>();
+              for (AtomicReader reader : mergeState.readers) {
+                SortedDocValues values = reader.getSortedDocValues(field.name);
+                if (values == null) {
+                  values = new SortedDocValues.EMPTY(reader.maxDoc());
+                }
+                toMerge.add(values);
+              }
+              consumer.mergeSortedField(field, mergeState, toMerge);
+            } else {
+              throw new AssertionError("type=" + type);
+            }
+          }
+        }
+      } finally {
+        if (success) {
+          IOUtils.close(consumer);
+        } else {
+          IOUtils.closeWhileHandlingException(consumer);            
+        }
+      }
+    }
+  }
+
+  private void mergeSimpleNorms(SegmentWriteState segmentWriteState) throws IOException {
+    if (codec.simpleNormsFormat() != null) {
+      SimpleDVConsumer consumer = codec.simpleNormsFormat().normsConsumer(segmentWriteState);
+      boolean success = false;
+      try {
+        for (FieldInfo field : mergeState.fieldInfos) {
+          if (field.isIndexed() && !field.omitsNorms()) {
+            List<NumericDocValues> toMerge = new ArrayList<NumericDocValues>();
+            for (AtomicReader reader : mergeState.readers) {
+              NumericDocValues norms = reader.simpleNormValues(field.name);
+              if (norms == null) {
+                norms = new NumericDocValues.EMPTY(reader.maxDoc());
+              }
+              toMerge.add(norms);
+            }
+            consumer.mergeNumericField(field, mergeState, toMerge);
+          }
+        }
+      } finally {
+        if (success) {
+          IOUtils.close(consumer);
+        } else {
+          IOUtils.closeWhileHandlingException(consumer);            
+        }
+      }
+    }
+  }
+
   private void setMatchingSegmentReaders() {
     // If the i'th reader is a SegmentReader and has
     // identical fieldName -> number mapping, then this
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestBooleanOr.java b/lucene/core/src/test/org/apache/lucene/search/TestBooleanOr.java
index 22e29b7..6812b11 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestBooleanOr.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestBooleanOr.java
@@ -18,11 +18,13 @@ package org.apache.lucene.search;
 import java.io.IOException;
 import java.util.concurrent.atomic.AtomicInteger;
 
+import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.TextField;
 import org.apache.lucene.index.AtomicReaderContext;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.index.SerialMergeScheduler;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.FixedBitSet;
@@ -160,7 +162,8 @@ public class TestBooleanOr extends LuceneTestCase {
 
   public void testBooleanScorerMax() throws IOException {
     Directory dir = newDirectory();
-    RandomIndexWriter riw = new RandomIndexWriter(random(), dir);
+    // nocommit remove SMS:
+    RandomIndexWriter riw = new RandomIndexWriter(random(), dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergeScheduler(new SerialMergeScheduler()));
 
     int docCount = atLeast(10000);
 

