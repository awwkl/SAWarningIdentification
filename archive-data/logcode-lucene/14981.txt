GitDiffStart: 993ce74121d049c2a72a9048a45d819777717e55 | Sat Aug 20 04:57:58 2011 +0000
diff --git a/dev-tools/eclipse/dot.classpath b/dev-tools/eclipse/dot.classpath
index 3957ff9..0a7a61b 100644
--- a/dev-tools/eclipse/dot.classpath
+++ b/dev-tools/eclipse/dot.classpath
@@ -14,8 +14,8 @@
 	<classpathentry kind="src" path="lucene/contrib/memory/src/test"/>
 	<classpathentry kind="src" path="lucene/contrib/misc/src/java"/>
 	<classpathentry kind="src" path="lucene/contrib/misc/src/test"/>
-	<classpathentry kind="src" path="lucene/contrib/queries/src/java"/>
-	<classpathentry kind="src" path="lucene/contrib/queries/src/test"/>
+	<classpathentry kind="src" path="lucene/contrib/sandbox/src/java"/>
+	<classpathentry kind="src" path="lucene/contrib/sandbox/src/test"/>
 	<classpathentry kind="src" path="lucene/contrib/spatial/src/java"/>
 	<classpathentry kind="src" path="lucene/contrib/spatial/src/test"/>
 	<classpathentry kind="src" path="lucene/contrib/xml-query-parser/src/java"/>
diff --git a/dev-tools/idea/.idea/modules.xml b/dev-tools/idea/.idea/modules.xml
index 44203dc..94dcb98 100644
--- a/dev-tools/idea/.idea/modules.xml
+++ b/dev-tools/idea/.idea/modules.xml
@@ -9,8 +9,8 @@
       <module filepath="$PROJECT_DIR$/lucene/contrib/instantiated/instantiated.iml" />
       <module filepath="$PROJECT_DIR$/lucene/contrib/memory/memory.iml" />
       <module filepath="$PROJECT_DIR$/lucene/contrib/misc/misc.iml" />
-      <module filepath="$PROJECT_DIR$/lucene/contrib/queries/queries-contrib.iml" />
       <module filepath="$PROJECT_DIR$/lucene/contrib/spatial/spatial.iml" />
+      <module filepath="$PROJECT_DIR$/lucene/contrib/sandbox/sandbox.iml" />
       <module filepath="$PROJECT_DIR$/lucene/contrib/xml-query-parser/xml-query-parser.iml" />
       <module filepath="$PROJECT_DIR$/modules/analysis/common/analysis-common.iml" />
       <module filepath="$PROJECT_DIR$/modules/analysis/icu/icu.iml" />
diff --git a/dev-tools/idea/.idea/workspace.xml b/dev-tools/idea/.idea/workspace.xml
index 6d1619c..e181d31 100644
--- a/dev-tools/idea/.idea/workspace.xml
+++ b/dev-tools/idea/.idea/workspace.xml
@@ -127,13 +127,6 @@
       <option name="VM_PARAMETERS" value="-ea -DtempDir=temp" />
       <option name="TEST_SEARCH_SCOPE"><value defaultName="singleModule" /></option>
     </configuration>
-    <configuration default="false" name="queries contrib" type="JUnit" factoryName="JUnit">
-      <module name="queries-contrib" />
-      <option name="TEST_OBJECT" value="package" />
-      <option name="WORKING_DIRECTORY" value="file://$PROJECT_DIR$/lucene/build/contrib/queries" />
-      <option name="VM_PARAMETERS" value="-ea -DtempDir=temp" />
-      <option name="TEST_SEARCH_SCOPE"><value defaultName="singleModule" /></option>
-    </configuration>
     <configuration default="false" name="queries module" type="JUnit" factoryName="JUnit">
       <module name="queries" />
       <option name="TEST_OBJECT" value="package" />
@@ -148,6 +141,13 @@
       <option name="VM_PARAMETERS" value="-ea -DtempDir=temp" />
       <option name="TEST_SEARCH_SCOPE"><value defaultName="singleModule" /></option>
     </configuration>
+    <configuration default="false" name="sandbox contrib" type="JUnit" factoryName="JUnit">
+      <module name="sandbox" />
+      <option name="TEST_OBJECT" value="package" />
+      <option name="WORKING_DIRECTORY" value="file://$PROJECT_DIR$/lucene/build/contrib/sandbox" />
+      <option name="VM_PARAMETERS" value="-ea -DtempDir=temp" />
+      <option name="TEST_SEARCH_SCOPE"><value defaultName="singleModule" /></option>
+    </configuration>
     <configuration default="false" name="smartcn analysis module" type="JUnit" factoryName="JUnit">
       <module name="smartcn" />
       <option name="TEST_OBJECT" value="package" />
@@ -216,9 +216,9 @@
       <item index="15" class="java.lang.String" itemvalue="JUnit.misc contrib" />
       <item index="16" class="java.lang.String" itemvalue="JUnit.morfologik analysis module" />
       <item index="17" class="java.lang.String" itemvalue="JUnit.phonetic analysis module" />
-      <item index="18" class="java.lang.String" itemvalue="JUnit.queries contrib" />
-      <item index="19" class="java.lang.String" itemvalue="JUnit.queries module" />
-      <item index="20" class="java.lang.String" itemvalue="JUnit.queryparser module" />
+      <item index="18" class="java.lang.String" itemvalue="JUnit.queries module" />
+      <item index="19" class="java.lang.String" itemvalue="JUnit.queryparser module" />
+      <item index="20" class="java.lang.String" itemvalue="JUnit.sandbox contrib" />
       <item index="21" class="java.lang.String" itemvalue="JUnit.smartcn analysis module" />
       <item index="22" class="java.lang.String" itemvalue="JUnit.solr" />
       <item index="23" class="java.lang.String" itemvalue="JUnit.spatial contrib" />
diff --git a/dev-tools/idea/lucene/contrib/highlighter/highlighter.iml b/dev-tools/idea/lucene/contrib/highlighter/highlighter.iml
index 58c4726..a78e01d 100644
--- a/dev-tools/idea/lucene/contrib/highlighter/highlighter.iml
+++ b/dev-tools/idea/lucene/contrib/highlighter/highlighter.iml
@@ -12,7 +12,6 @@
     <orderEntry type="sourceFolder" forTests="false" />
     <orderEntry type="library" scope="TEST" name="JUnit" level="project" />
     <orderEntry type="module" module-name="memory" />
-    <orderEntry type="module" module-name="queries-contrib" />
     <orderEntry type="module" module-name="misc" />
     <orderEntry type="module" module-name="lucene" />
   </component>
diff --git a/dev-tools/idea/lucene/contrib/queries/queries-contrib.iml b/dev-tools/idea/lucene/contrib/queries/queries-contrib.iml
deleted file mode 100644
index 628ddee..0000000
--- a/dev-tools/idea/lucene/contrib/queries/queries-contrib.iml
+++ /dev/null
@@ -1,26 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<module type="JAVA_MODULE" version="4">
-  <component name="NewModuleRootManager" inherit-compiler-output="false">
-    <output url="file://$MODULE_DIR$/../../build/contrib/queries/classes/java" />
-    <output-test url="file://$MODULE_DIR$/../../build/contrib/queries/classes/test" />
-    <exclude-output />
-    <content url="file://$MODULE_DIR$">
-      <sourceFolder url="file://$MODULE_DIR$/src/java" isTestSource="false" />
-      <sourceFolder url="file://$MODULE_DIR$/src/test" isTestSource="true" />
-    </content>
-    <orderEntry type="inheritedJdk" />
-    <orderEntry type="sourceFolder" forTests="false" />
-    <orderEntry type="module-library">
-      <library>
-        <CLASSES>
-          <root url="jar://$MODULE_DIR$/lib/jakarta-regexp-1.4.jar!/" />
-        </CLASSES>
-        <JAVADOC />
-        <SOURCES />
-      </library>
-    </orderEntry>
-    <orderEntry type="library" scope="TEST" name="JUnit" level="project" />
-    <orderEntry type="module" module-name="misc" />
-    <orderEntry type="module" module-name="lucene" />
-  </component>
-</module>
diff --git a/dev-tools/idea/lucene/contrib/sandbox/sandbox.iml b/dev-tools/idea/lucene/contrib/sandbox/sandbox.iml
new file mode 100644
index 0000000..3c61cb9
--- /dev/null
+++ b/dev-tools/idea/lucene/contrib/sandbox/sandbox.iml
@@ -0,0 +1,26 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<module type="JAVA_MODULE" version="4">
+  <component name="NewModuleRootManager" inherit-compiler-output="false">
+    <output url="file://$MODULE_DIR$/../../build/contrib/sandbox/classes/java" />
+    <output-test url="file://$MODULE_DIR$/../../build/contrib/sandbox/classes/test" />
+    <exclude-output />
+    <content url="file://$MODULE_DIR$">
+      <sourceFolder url="file://$MODULE_DIR$/src/java" isTestSource="false" />
+      <sourceFolder url="file://$MODULE_DIR$/src/test" isTestSource="true" />
+    </content>
+    <orderEntry type="inheritedJdk" />
+    <orderEntry type="sourceFolder" forTests="false" />
+    <orderEntry type="module-library">
+      <library>
+        <CLASSES>
+          <root url="jar://$MODULE_DIR$/lib/jakarta-regexp-1.4.jar!/" />
+        </CLASSES>
+        <JAVADOC />
+        <SOURCES />
+      </library>
+    </orderEntry>
+    <orderEntry type="library" scope="TEST" name="JUnit" level="project" />
+    <orderEntry type="module" module-name="lucene" />
+  </component>
+</module>
+
diff --git a/dev-tools/idea/lucene/contrib/spatial/spatial.iml b/dev-tools/idea/lucene/contrib/spatial/spatial.iml
index 6838f0c..cb78265 100644
--- a/dev-tools/idea/lucene/contrib/spatial/spatial.iml
+++ b/dev-tools/idea/lucene/contrib/spatial/spatial.iml
@@ -11,7 +11,6 @@
     <orderEntry type="inheritedJdk" />
     <orderEntry type="sourceFolder" forTests="false" />
     <orderEntry type="library" scope="TEST" name="JUnit" level="project" />
-    <orderEntry type="module" module-name="queries-contrib" />
     <orderEntry type="module" module-name="misc" />
     <orderEntry type="module" module-name="lucene" />
     <orderEntry type="module" module-name="queries" />
diff --git a/dev-tools/idea/lucene/contrib/xml-query-parser/xml-query-parser.iml b/dev-tools/idea/lucene/contrib/xml-query-parser/xml-query-parser.iml
index 8daaab0..5e20f9d 100644
--- a/dev-tools/idea/lucene/contrib/xml-query-parser/xml-query-parser.iml
+++ b/dev-tools/idea/lucene/contrib/xml-query-parser/xml-query-parser.iml
@@ -11,8 +11,8 @@
     <orderEntry type="inheritedJdk" />
     <orderEntry type="sourceFolder" forTests="false" />
     <orderEntry type="library" scope="TEST" name="JUnit" level="project" />
-    <orderEntry type="module" module-name="queries-contrib" />
     <orderEntry type="module" module-name="misc" />
+    <orderEntry type="module" module-name="sandbox" />
     <orderEntry type="module" module-name="analysis-common" />
     <orderEntry type="module" module-name="lucene" />
     <orderEntry type="module" module-name="queryparser" />
diff --git a/dev-tools/idea/solr/solr.iml b/dev-tools/idea/solr/solr.iml
index 25f6762..9ffb7aa 100644
--- a/dev-tools/idea/solr/solr.iml
+++ b/dev-tools/idea/solr/solr.iml
@@ -24,7 +24,6 @@
     <orderEntry type="module" module-name="grouping" />
     <orderEntry type="module" module-name="highlighter" />
     <orderEntry type="module" module-name="icu" />
-    <orderEntry type="module" module-name="queries-contrib" />
     <orderEntry type="module" module-name="queries" />
     <orderEntry type="module" module-name="misc" />
     <orderEntry type="module" module-name="phonetic" />
diff --git a/dev-tools/maven/lucene/contrib/highlighter/pom.xml.template b/dev-tools/maven/lucene/contrib/highlighter/pom.xml.template
index 2fd403b..e4c3e76 100644
--- a/dev-tools/maven/lucene/contrib/highlighter/pom.xml.template
+++ b/dev-tools/maven/lucene/contrib/highlighter/pom.xml.template
@@ -55,11 +55,6 @@
       <version>${project.version}</version>
     </dependency>
     <dependency>
-      <groupId>${project.groupId}</groupId>
-      <artifactId>lucene-queries-contrib</artifactId>
-      <version>${project.version}</version>
-    </dependency>
-    <dependency>
       <groupId>junit</groupId>
       <artifactId>junit</artifactId>
       <scope>test</scope>
diff --git a/dev-tools/maven/lucene/contrib/pom.xml.template b/dev-tools/maven/lucene/contrib/pom.xml.template
index b138041..c4e82c7 100644
--- a/dev-tools/maven/lucene/contrib/pom.xml.template
+++ b/dev-tools/maven/lucene/contrib/pom.xml.template
@@ -36,7 +36,7 @@
     <module>instantiated</module>
     <module>memory</module>
     <module>misc</module>
-    <module>queries</module>
+    <module>sandbox</module>
     <module>spatial</module>
     <module>xml-query-parser</module>
   </modules>
diff --git a/dev-tools/maven/lucene/contrib/queries/pom.xml.template b/dev-tools/maven/lucene/contrib/queries/pom.xml.template
deleted file mode 100644
index 5901d44..0000000
--- a/dev-tools/maven/lucene/contrib/queries/pom.xml.template
+++ /dev/null
@@ -1,77 +0,0 @@
-<project xmlns="http://maven.apache.org/POM/4.0.0"
-         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
-         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">
-  <!--
-    Licensed to the Apache Software Foundation (ASF) under one
-    or more contributor license agreements.  See the NOTICE file
-    distributed with this work for additional information
-    regarding copyright ownership.  The ASF licenses this file
-    to you under the Apache License, Version 2.0 (the
-    "License"); you may not use this file except in compliance
-    with the License.  You may obtain a copy of the License at
-    
-    http://www.apache.org/licenses/LICENSE-2.0
-    
-    Unless required by applicable law or agreed to in writing,
-    software distributed under the License is distributed on an
-    "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-    KIND, either express or implied.  See the License for the
-    specific language governing permissions and limitations
-    under the License.
-  -->
-  <modelVersion>4.0.0</modelVersion>
-  <parent>
-    <groupId>org.apache.lucene</groupId>
-    <artifactId>lucene-parent</artifactId>
-    <version>@version@</version>
-    <relativePath>../../pom.xml</relativePath>
-  </parent>
-  <groupId>org.apache.lucene</groupId>
-  <artifactId>lucene-queries-contrib</artifactId>
-  <packaging>jar</packaging>
-  <name>Lucene Queries Contrib</name>
-  <description>
-    Queries - various query object exotica not in core
-  </description>
-  <properties>
-    <module-directory>lucene/contrib/queries</module-directory>
-    <build-directory>../../build/contrib/queries</build-directory>
-  </properties>
-  <dependencies>
-    <dependency>
-      <groupId>${project.groupId}</groupId>
-      <artifactId>lucene-core</artifactId>
-      <version>${project.version}</version>
-    </dependency>
-    <dependency>
-      <groupId>${project.groupId}</groupId>
-      <artifactId>lucene-test-framework</artifactId>
-      <version>${project.version}</version>
-      <scope>test</scope>
-    </dependency>
-    <dependency>
-      <groupId>jakarta-regexp</groupId>
-      <artifactId>jakarta-regexp</artifactId>
-    </dependency>
-    <dependency>
-      <groupId>junit</groupId>
-      <artifactId>junit</artifactId>
-      <scope>test</scope>
-    </dependency>
-  </dependencies>
-  <build>
-    <directory>${build-directory}</directory>
-    <outputDirectory>${build-directory}/classes/java</outputDirectory>
-    <testOutputDirectory>${build-directory}/classes/test</testOutputDirectory>
-    <sourceDirectory>src/java</sourceDirectory>
-    <testSourceDirectory>src/test</testSourceDirectory>
-    <testResources>
-      <testResource>
-        <directory>${project.build.testSourceDirectory}</directory>
-        <excludes>
-          <exclude>**/*.java</exclude>
-        </excludes>
-      </testResource>
-    </testResources>
-  </build>
-</project>
diff --git a/dev-tools/maven/lucene/contrib/sandbox/pom.xml.template b/dev-tools/maven/lucene/contrib/sandbox/pom.xml.template
new file mode 100644
index 0000000..a490a28
--- /dev/null
+++ b/dev-tools/maven/lucene/contrib/sandbox/pom.xml.template
@@ -0,0 +1,71 @@
+<project xmlns="http://maven.apache.org/POM/4.0.0"
+         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
+         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">
+  <!--
+    Licensed to the Apache Software Foundation (ASF) under one
+    or more contributor license agreements.  See the NOTICE file
+    distributed with this work for additional information
+    regarding copyright ownership.  The ASF licenses this file
+    to you under the Apache License, Version 2.0 (the
+    "License"); you may not use this file except in compliance
+    with the License.  You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+    Unless required by applicable law or agreed to in writing,
+    software distributed under the License is distributed on an
+    "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+    KIND, either express or implied.  See the License for the
+    specific language governing permissions and limitations
+    under the License.
+  -->
+  <modelVersion>4.0.0</modelVersion>
+  <parent>
+    <groupId>org.apache.lucene</groupId>
+    <artifactId>lucene-parent</artifactId>
+    <version>@version@</version>
+    <relativePath>../../pom.xml</relativePath>
+  </parent>
+  <groupId>org.apache.lucene</groupId>
+  <artifactId>lucene-sandbox</artifactId>
+  <packaging>jar</packaging>
+  <name>Lucene Sandbox</name>
+  <description>Lucene Sandbox</description>
+  <properties>
+    <module-directory>lucene/contrib/sandbox</module-directory>
+    <build-directory>../../build/contrib/sandbox</build-directory>
+  </properties>
+  <dependencies>
+    <dependency>
+      <groupId>${project.groupId}</groupId>
+      <artifactId>lucene-core</artifactId>
+      <version>${project.version}</version>
+    </dependency>
+    <dependency>
+      <groupId>${project.groupId}</groupId>
+      <artifactId>lucene-test-framework</artifactId>
+      <version>${project.version}</version>
+      <scope>test</scope>
+    </dependency>
+    <dependency>
+      <groupId>junit</groupId>
+      <artifactId>junit</artifactId>
+      <scope>test</scope>
+    </dependency>
+  </dependencies>
+  <build>
+    <directory>${build-directory}</directory>
+    <outputDirectory>${build-directory}/classes/java</outputDirectory>
+    <testOutputDirectory>${build-directory}/classes/test</testOutputDirectory>
+    <sourceDirectory>src/java</sourceDirectory>
+    <testSourceDirectory>src/test</testSourceDirectory>
+    <testResources>
+      <testResource>
+        <directory>${project.build.testSourceDirectory}</directory>
+        <excludes>
+          <exclude>**/*.java</exclude>
+        </excludes>
+      </testResource>
+    </testResources>
+  </build>
+</project>
diff --git a/dev-tools/maven/lucene/contrib/spatial/pom.xml.template b/dev-tools/maven/lucene/contrib/spatial/pom.xml.template
index 1fd90b4..1b822d7 100644
--- a/dev-tools/maven/lucene/contrib/spatial/pom.xml.template
+++ b/dev-tools/maven/lucene/contrib/spatial/pom.xml.template
@@ -49,11 +49,6 @@
     </dependency>
     <dependency>
       <groupId>${project.groupId}</groupId>
-      <artifactId>lucene-queries-contrib</artifactId>
-      <version>${project.version}</version>
-    </dependency>
-    <dependency>
-      <groupId>${project.groupId}</groupId>
       <artifactId>lucene-queries</artifactId>
       <version>${project.version}</version>
     </dependency>
diff --git a/dev-tools/maven/lucene/contrib/xml-query-parser/pom.xml.template b/dev-tools/maven/lucene/contrib/xml-query-parser/pom.xml.template
index 7361a1b..40c64ff 100644
--- a/dev-tools/maven/lucene/contrib/xml-query-parser/pom.xml.template
+++ b/dev-tools/maven/lucene/contrib/xml-query-parser/pom.xml.template
@@ -49,12 +49,12 @@
     </dependency>
     <dependency>
       <groupId>${project.groupId}</groupId>
-      <artifactId>lucene-queries-contrib</artifactId>
+      <artifactId>lucene-queries</artifactId>
       <version>${project.version}</version>
     </dependency>
     <dependency>
       <groupId>${project.groupId}</groupId>
-      <artifactId>lucene-queries</artifactId>
+      <artifactId>lucene-sandbox</artifactId>
       <version>${project.version}</version>
     </dependency>
     <dependency>
diff --git a/dev-tools/maven/solr/core/pom.xml.template b/dev-tools/maven/solr/core/pom.xml.template
index 7ef0f03..c967e54 100644
--- a/dev-tools/maven/solr/core/pom.xml.template
+++ b/dev-tools/maven/solr/core/pom.xml.template
@@ -78,11 +78,6 @@
     </dependency>
     <dependency>
       <groupId>org.apache.lucene</groupId>
-      <artifactId>lucene-queries-contrib</artifactId>
-      <version>${project.version}</version>
-    </dependency>
-    <dependency>
-      <groupId>org.apache.lucene</groupId>
       <artifactId>lucene-queryparser</artifactId>
       <version>${project.version}</version>
     </dependency>
diff --git a/lucene/build.xml b/lucene/build.xml
index 4fec4ec..a096d99 100644
--- a/lucene/build.xml
+++ b/lucene/build.xml
@@ -255,7 +255,7 @@
           <packageset dir="contrib/instantiated/src/java"/>
           <packageset dir="contrib/memory/src/java"/>
           <packageset dir="contrib/misc/src/java"/>
-          <packageset dir="contrib/queries/src/java"/>
+          <packageset dir="contrib/sandbox/src/java"/>
           <packageset dir="contrib/spatial/src/java"/>
           <packageset dir="contrib/xml-query-parser/src/java"/>
           <!-- end alpha sort -->
@@ -272,7 +272,7 @@
           <group title="contrib: Instantiated" packages="org.apache.lucene.store.instantiated*"/>
           <group title="contrib: Memory" packages="org.apache.lucene.index.memory*"/>
           <group title="contrib: Misc " packages="org.apache.lucene.misc*"/>
-          <group title="contrib: Queries" packages="org.apache.lucene.search.similar*:org.apache.lucene.search.regex*:org.apache.regexp*"/>
+          <group title="contrib: Sandbox" packages="org.apache.lucene.sandbox*"/>
           <group title="contrib: Spatial" packages="org.apache.lucene.spatial*"/>
           <group title="contrib: XML Query Parser" packages="org.apache.lucene.xmlparser*"/>
           
diff --git a/lucene/contrib/contrib-build.xml b/lucene/contrib/contrib-build.xml
index 9bc7cb1..83b03fa 100644
--- a/lucene/contrib/contrib-build.xml
+++ b/lucene/contrib/contrib-build.xml
@@ -240,17 +240,6 @@
     <property name="queries.uptodate" value="true"/>
   </target>
 
-  <property name="queries-contrib.jar" value="${common.dir}/build/contrib/queries-contrib/lucene-queries-contrib-${version}.jar"/>
-  <target name="check-queries-contrib-uptodate" unless="queries-contrib.uptodate">
-    <contrib-uptodate name="queries-contrib" jarfile="${queries-contrib.jar}" contrib-src-name="queries" property="queries-contrib.uptodate"/>
-  </target>
-  <target name="jar-queries-contrib" unless="queries-contrib.uptodate" depends="check-queries-contrib-uptodate">
-    <ant dir="${common.dir}/contrib/queries" target="jar-core" inheritall="false">
-      <propertyset refid="uptodate.and.compiled.properties"/>
-    </ant>
-    <property name="queries-contrib.uptodate" value="true"/>
-  </target>
-
   <property name="queryparser.jar" value="${common.dir}/../modules/queryparser/build/lucene-queryparser-${version}.jar"/>
   <target name="check-queryparser-uptodate" unless="queryparser.uptodate">
     <module-uptodate name="queryparser" jarfile="${queryparser.jar}" property="queryparser.uptodate"/>
@@ -262,6 +251,17 @@
     <property name="queryparser.uptodate" value="true"/>
   </target>
 
+  <property name="sandbox.jar" value="${common.dir}/build/contrib/sandbox/lucene-sandbox-${version}.jar"/>
+  <target name="check-sandbox-uptodate" unless="sandbox.uptodate">
+    <contrib-uptodate name="sandbox" jarfile="${sandbox.jar}" property="sandbox.uptodate"/>
+  </target>
+  <target name="jar-sandbox" unless="sandbox.uptodate" depends="check-sandbox-uptodate">
+  	<ant dir="${common.dir}/contrib/sandbox" target="jar-core" inheritAll="false">
+      <propertyset refid="uptodate.and.compiled.properties"/>
+    </ant>
+    <property name="sandbox.uptodate" value="true"/>
+  </target>
+
   <property name="spatial.jar" value="${common.dir}/build/contrib/spatial/lucene-spatial-${version}.jar"/>
   <target name="check-spatial-uptodate" unless="spatial.uptodate">
     <contrib-uptodate name="spatial" jarfile="${spatial.jar}" property="spatial.uptodate"/>
diff --git a/lucene/contrib/highlighter/build.xml b/lucene/contrib/highlighter/build.xml
index 789d1ff..935d207 100644
--- a/lucene/contrib/highlighter/build.xml
+++ b/lucene/contrib/highlighter/build.xml
@@ -27,9 +27,8 @@
 
   <path id="classpath">
     <pathelement path="${memory.jar}"/>
-    <pathelement path="${queries-contrib.jar}"/>
     <path refid="base.classpath"/>
   </path>
 
-  <target name="compile-core" depends="jar-memory, jar-queries-contrib, common.compile-core" />
+  <target name="compile-core" depends="jar-memory, common.compile-core" />
 </project>
diff --git a/lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java b/lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java
index 85ef9ba..09a0214 100644
--- a/lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java
+++ b/lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java
@@ -55,7 +55,6 @@ import org.apache.lucene.index.IndexWriterConfig.OpenMode;
 import org.apache.lucene.search.*;
 import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.search.highlight.SynonymTokenizer.TestHighlightRunner;
-import org.apache.lucene.search.regex.RegexQuery;
 import org.apache.lucene.search.spans.*;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
@@ -337,7 +336,7 @@ public class HighlighterTest extends BaseTokenStreamTestCase implements Formatte
   }
   
   public void testSpanRegexQuery() throws Exception {
-    query = new SpanOrQuery(new SpanMultiTermQueryWrapper<RegexQuery>(new RegexQuery(new Term(FIELD_NAME, "ken.*"))));
+    query = new SpanOrQuery(new SpanMultiTermQueryWrapper<RegexpQuery>(new RegexpQuery(new Term(FIELD_NAME, "ken.*"))));
     searcher = new IndexSearcher(ramDir, true);
     hits = searcher.search(query, 100);
     int maxNumFragmentsRequired = 2;
@@ -361,7 +360,7 @@ public class HighlighterTest extends BaseTokenStreamTestCase implements Formatte
   }
   
   public void testRegexQuery() throws Exception {
-    query = new RegexQuery(new Term(FIELD_NAME, "ken.*"));
+    query = new RegexpQuery(new Term(FIELD_NAME, "ken.*"));
     searcher = new IndexSearcher(ramDir, true);
     hits = searcher.search(query, 100);
     int maxNumFragmentsRequired = 2;
diff --git a/lucene/contrib/queries/README.txt b/lucene/contrib/queries/README.txt
deleted file mode 100644
index 817969f..0000000
--- a/lucene/contrib/queries/README.txt
+++ /dev/null
@@ -1,23 +0,0 @@
-This module contains a number of filter and query objects that add to core lucene.
-
-==== The "MoreLikeThis" class from the "similarity" module has been copied into here.
-If people are generally happy with this move then the similarity module can be deleted, or at least a 
-"Moved to queries module..." note left in its place.
-
-==== FuzzyLikeThis - mixes the behaviour of FuzzyQuery and MoreLikeThis but with special consideration
-of fuzzy scoring factors. This generally produces good results for queries where users may provide details in a number of 
-fields and have no knowledge of boolean query syntax and also want a degree of fuzzy matching. The query is fast because, like
-MoreLikeThis, it optimizes the query to only the most distinguishing terms.
-
-==== BoostingQuery - effectively demotes search results that match a given query. 
-Unlike the "NOT" clause, this still selects documents that contain undesirable terms, 
-but reduces the overall score of docs containing these terms.
-
-==== TermsFilter -  Unlike a RangeFilter this can be used for filtering on multiple terms that are not necessarily in 
-a sequence. An example might be a collection of primary keys from a database query result or perhaps 
-a choice of "category" labels picked by the end user.
-
-==== RegexQuery - Implements the regular expression term search query. 
-
-Mark Harwood
-25/02/2006
diff --git a/lucene/contrib/queries/build.xml b/lucene/contrib/queries/build.xml
deleted file mode 100644
index d5cd287..0000000
--- a/lucene/contrib/queries/build.xml
+++ /dev/null
@@ -1,36 +0,0 @@
-<?xml version="1.0"?>
-
-<!--
-    Licensed to the Apache Software Foundation (ASF) under one or more
-    contributor license agreements.  See the NOTICE file distributed with
-    this work for additional information regarding copyright ownership.
-    The ASF licenses this file to You under the Apache License, Version 2.0
-    the "License"); you may not use this file except in compliance with
-    the License.  You may obtain a copy of the License at
- 
-        http://www.apache.org/licenses/LICENSE-2.0
- 
-    Unless required by applicable law or agreed to in writing, software
-    distributed under the License is distributed on an "AS IS" BASIS,
-    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-    See the License for the specific language governing permissions and
-    limitations under the License.
- -->
-
-<project name="queries-contrib" default="default">
-
-  <description>
-    Queries - various query object exotica not in core
-  </description>
-
-  <path id="additional.dependencies">
-    <fileset dir="lib" includes="*-oro-*.jar,*-regexp-*.jar"/>
-  </path>
-
-  <pathconvert property="project.classpath"
-               targetos="unix"
-               refid="additional.dependencies"
-  />
-
-  <import file="../contrib-build.xml"/>
-</project>
diff --git a/lucene/contrib/queries/lib/jakarta-regexp-1.4.jar b/lucene/contrib/queries/lib/jakarta-regexp-1.4.jar
deleted file mode 100644
index 0366f23..0000000
--- a/lucene/contrib/queries/lib/jakarta-regexp-1.4.jar
+++ /dev/null
@@ -1,2 +0,0 @@
-AnyObjectId[5d70c357a1e6c4c702af313c94aaf3168d300dcf] was removed in git history.
-Apache SVN contains full history.
\ No newline at end of file
diff --git a/lucene/contrib/queries/lib/jakarta-regexp-LICENSE-ASL.txt b/lucene/contrib/queries/lib/jakarta-regexp-LICENSE-ASL.txt
deleted file mode 100644
index 261eeb9..0000000
--- a/lucene/contrib/queries/lib/jakarta-regexp-LICENSE-ASL.txt
+++ /dev/null
@@ -1,201 +0,0 @@
-                                 Apache License
-                           Version 2.0, January 2004
-                        http://www.apache.org/licenses/
-
-   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
-
-   1. Definitions.
-
-      "License" shall mean the terms and conditions for use, reproduction,
-      and distribution as defined by Sections 1 through 9 of this document.
-
-      "Licensor" shall mean the copyright owner or entity authorized by
-      the copyright owner that is granting the License.
-
-      "Legal Entity" shall mean the union of the acting entity and all
-      other entities that control, are controlled by, or are under common
-      control with that entity. For the purposes of this definition,
-      "control" means (i) the power, direct or indirect, to cause the
-      direction or management of such entity, whether by contract or
-      otherwise, or (ii) ownership of fifty percent (50%) or more of the
-      outstanding shares, or (iii) beneficial ownership of such entity.
-
-      "You" (or "Your") shall mean an individual or Legal Entity
-      exercising permissions granted by this License.
-
-      "Source" form shall mean the preferred form for making modifications,
-      including but not limited to software source code, documentation
-      source, and configuration files.
-
-      "Object" form shall mean any form resulting from mechanical
-      transformation or translation of a Source form, including but
-      not limited to compiled object code, generated documentation,
-      and conversions to other media types.
-
-      "Work" shall mean the work of authorship, whether in Source or
-      Object form, made available under the License, as indicated by a
-      copyright notice that is included in or attached to the work
-      (an example is provided in the Appendix below).
-
-      "Derivative Works" shall mean any work, whether in Source or Object
-      form, that is based on (or derived from) the Work and for which the
-      editorial revisions, annotations, elaborations, or other modifications
-      represent, as a whole, an original work of authorship. For the purposes
-      of this License, Derivative Works shall not include works that remain
-      separable from, or merely link (or bind by name) to the interfaces of,
-      the Work and Derivative Works thereof.
-
-      "Contribution" shall mean any work of authorship, including
-      the original version of the Work and any modifications or additions
-      to that Work or Derivative Works thereof, that is intentionally
-      submitted to Licensor for inclusion in the Work by the copyright owner
-      or by an individual or Legal Entity authorized to submit on behalf of
-      the copyright owner. For the purposes of this definition, "submitted"
-      means any form of electronic, verbal, or written communication sent
-      to the Licensor or its representatives, including but not limited to
-      communication on electronic mailing lists, source code control systems,
-      and issue tracking systems that are managed by, or on behalf of, the
-      Licensor for the purpose of discussing and improving the Work, but
-      excluding communication that is conspicuously marked or otherwise
-      designated in writing by the copyright owner as "Not a Contribution."
-
-      "Contributor" shall mean Licensor and any individual or Legal Entity
-      on behalf of whom a Contribution has been received by Licensor and
-      subsequently incorporated within the Work.
-
-   2. Grant of Copyright License. Subject to the terms and conditions of
-      this License, each Contributor hereby grants to You a perpetual,
-      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
-      copyright license to reproduce, prepare Derivative Works of,
-      publicly display, publicly perform, sublicense, and distribute the
-      Work and such Derivative Works in Source or Object form.
-
-   3. Grant of Patent License. Subject to the terms and conditions of
-      this License, each Contributor hereby grants to You a perpetual,
-      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
-      (except as stated in this section) patent license to make, have made,
-      use, offer to sell, sell, import, and otherwise transfer the Work,
-      where such license applies only to those patent claims licensable
-      by such Contributor that are necessarily infringed by their
-      Contribution(s) alone or by combination of their Contribution(s)
-      with the Work to which such Contribution(s) was submitted. If You
-      institute patent litigation against any entity (including a
-      cross-claim or counterclaim in a lawsuit) alleging that the Work
-      or a Contribution incorporated within the Work constitutes direct
-      or contributory patent infringement, then any patent licenses
-      granted to You under this License for that Work shall terminate
-      as of the date such litigation is filed.
-
-   4. Redistribution. You may reproduce and distribute copies of the
-      Work or Derivative Works thereof in any medium, with or without
-      modifications, and in Source or Object form, provided that You
-      meet the following conditions:
-
-      (a) You must give any other recipients of the Work or
-          Derivative Works a copy of this License; and
-
-      (b) You must cause any modified files to carry prominent notices
-          stating that You changed the files; and
-
-      (c) You must retain, in the Source form of any Derivative Works
-          that You distribute, all copyright, patent, trademark, and
-          attribution notices from the Source form of the Work,
-          excluding those notices that do not pertain to any part of
-          the Derivative Works; and
-
-      (d) If the Work includes a "NOTICE" text file as part of its
-          distribution, then any Derivative Works that You distribute must
-          include a readable copy of the attribution notices contained
-          within such NOTICE file, excluding those notices that do not
-          pertain to any part of the Derivative Works, in at least one
-          of the following places: within a NOTICE text file distributed
-          as part of the Derivative Works; within the Source form or
-          documentation, if provided along with the Derivative Works; or,
-          within a display generated by the Derivative Works, if and
-          wherever such third-party notices normally appear. The contents
-          of the NOTICE file are for informational purposes only and
-          do not modify the License. You may add Your own attribution
-          notices within Derivative Works that You distribute, alongside
-          or as an addendum to the NOTICE text from the Work, provided
-          that such additional attribution notices cannot be construed
-          as modifying the License.
-
-      You may add Your own copyright statement to Your modifications and
-      may provide additional or different license terms and conditions
-      for use, reproduction, or distribution of Your modifications, or
-      for any such Derivative Works as a whole, provided Your use,
-      reproduction, and distribution of the Work otherwise complies with
-      the conditions stated in this License.
-
-   5. Submission of Contributions. Unless You explicitly state otherwise,
-      any Contribution intentionally submitted for inclusion in the Work
-      by You to the Licensor shall be under the terms and conditions of
-      this License, without any additional terms or conditions.
-      Notwithstanding the above, nothing herein shall supersede or modify
-      the terms of any separate license agreement you may have executed
-      with Licensor regarding such Contributions.
-
-   6. Trademarks. This License does not grant permission to use the trade
-      names, trademarks, service marks, or product names of the Licensor,
-      except as required for reasonable and customary use in describing the
-      origin of the Work and reproducing the content of the NOTICE file.
-
-   7. Disclaimer of Warranty. Unless required by applicable law or
-      agreed to in writing, Licensor provides the Work (and each
-      Contributor provides its Contributions) on an "AS IS" BASIS,
-      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
-      implied, including, without limitation, any warranties or conditions
-      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
-      PARTICULAR PURPOSE. You are solely responsible for determining the
-      appropriateness of using or redistributing the Work and assume any
-      risks associated with Your exercise of permissions under this License.
-
-   8. Limitation of Liability. In no event and under no legal theory,
-      whether in tort (including negligence), contract, or otherwise,
-      unless required by applicable law (such as deliberate and grossly
-      negligent acts) or agreed to in writing, shall any Contributor be
-      liable to You for damages, including any direct, indirect, special,
-      incidental, or consequential damages of any character arising as a
-      result of this License or out of the use or inability to use the
-      Work (including but not limited to damages for loss of goodwill,
-      work stoppage, computer failure or malfunction, or any and all
-      other commercial damages or losses), even if such Contributor
-      has been advised of the possibility of such damages.
-
-   9. Accepting Warranty or Additional Liability. While redistributing
-      the Work or Derivative Works thereof, You may choose to offer,
-      and charge a fee for, acceptance of support, warranty, indemnity,
-      or other liability obligations and/or rights consistent with this
-      License. However, in accepting such obligations, You may act only
-      on Your own behalf and on Your sole responsibility, not on behalf
-      of any other Contributor, and only if You agree to indemnify,
-      defend, and hold each Contributor harmless for any liability
-      incurred by, or claims asserted against, such Contributor by reason
-      of your accepting any such warranty or additional liability.
-
-   END OF TERMS AND CONDITIONS
-
-   APPENDIX: How to apply the Apache License to your work.
-
-      To apply the Apache License to your work, attach the following
-      boilerplate notice, with the fields enclosed by brackets "[]"
-      replaced with your own identifying information. (Don't include
-      the brackets!)  The text should be enclosed in the appropriate
-      comment syntax for the file format. We also recommend that a
-      file or class name and description of purpose be included on the
-      same "printed page" as the copyright notice for easier
-      identification within third-party archives.
-
-   Copyright [yyyy] [name of copyright owner]
-
-   Licensed under the Apache License, Version 2.0 (the "License");
-   you may not use this file except in compliance with the License.
-   You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
diff --git a/lucene/contrib/queries/lib/jakarta-regexp-NOTICE.txt b/lucene/contrib/queries/lib/jakarta-regexp-NOTICE.txt
deleted file mode 100644
index c6f1099..0000000
--- a/lucene/contrib/queries/lib/jakarta-regexp-NOTICE.txt
+++ /dev/null
@@ -1,10 +0,0 @@
-Apache Regexp
-Copyright 2001-2007 The Apache Software Foundation
-
-This product includes software developed at
-The Apache Software Foundation (http://www.apache.org/).
-          
-It consists of voluntary contributions made by many individuals
-on behalf of the Apache Software Foundation. Please visit the
-project homepage (http://jakarta.apache.org/regexp) for more
-information.
diff --git a/lucene/contrib/queries/src/java/org/apache/lucene/search/FuzzyLikeThisQuery.java b/lucene/contrib/queries/src/java/org/apache/lucene/search/FuzzyLikeThisQuery.java
deleted file mode 100644
index 2a0099b..0000000
--- a/lucene/contrib/queries/src/java/org/apache/lucene/search/FuzzyLikeThisQuery.java
+++ /dev/null
@@ -1,379 +0,0 @@
-package org.apache.lucene.search;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.io.StringReader;
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Iterator;
-
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.MultiFields;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.util.AttributeSource;
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.PriorityQueue;
-
-/**
- * Fuzzifies ALL terms provided as strings and then picks the best n differentiating terms.
- * In effect this mixes the behaviour of FuzzyQuery and MoreLikeThis but with special consideration
- * of fuzzy scoring factors.
- * This generally produces good results for queries where users may provide details in a number of 
- * fields and have no knowledge of boolean query syntax and also want a degree of fuzzy matching and
- * a fast query.
- * 
- * For each source term the fuzzy variants are held in a BooleanQuery with no coord factor (because
- * we are not looking for matches on multiple variants in any one doc). Additionally, a specialized
- * TermQuery is used for variants and does not use that variant term's IDF because this would favour rarer 
- * terms eg misspellings. Instead, all variants use the same IDF ranking (the one for the source query 
- * term) and this is factored into the variant's boost. If the source query term does not exist in the
- * index the average IDF of the variants is used.
- */
-public class FuzzyLikeThisQuery extends Query
-{
-    // TODO: generalize this query (at least it should not reuse this static sim!
-    // a better way might be to convert this into multitermquery rewrite methods.
-    // the rewrite method can 'average' the TermContext's term statistics (docfreq,totalTermFreq) 
-    // provided to TermQuery, so that the general idea is agnostic to any scoring system...
-    static TFIDFSimilarity sim=new DefaultSimilarity();
-    Query rewrittenQuery=null;
-    ArrayList<FieldVals> fieldVals=new ArrayList<FieldVals>();
-    Analyzer analyzer;
-    
-    ScoreTermQueue q;
-    int MAX_VARIANTS_PER_TERM=50;
-    boolean ignoreTF=false;
-    private int maxNumTerms;
-
-    @Override
-    public int hashCode() {
-      final int prime = 31;
-      int result = 1;
-      result = prime * result + ((analyzer == null) ? 0 : analyzer.hashCode());
-      result = prime * result
-          + ((fieldVals == null) ? 0 : fieldVals.hashCode());
-      result = prime * result + (ignoreTF ? 1231 : 1237);
-      result = prime * result + maxNumTerms;
-      return result;
-    }
-
-    @Override
-    public boolean equals(Object obj) {
-      if (this == obj)
-        return true;
-      if (obj == null)
-        return false;
-      if (getClass() != obj.getClass())
-        return false;
-      FuzzyLikeThisQuery other = (FuzzyLikeThisQuery) obj;
-      if (analyzer == null) {
-        if (other.analyzer != null)
-          return false;
-      } else if (!analyzer.equals(other.analyzer))
-        return false;
-      if (fieldVals == null) {
-        if (other.fieldVals != null)
-          return false;
-      } else if (!fieldVals.equals(other.fieldVals))
-        return false;
-      if (ignoreTF != other.ignoreTF)
-        return false;
-      if (maxNumTerms != other.maxNumTerms)
-        return false;
-      return true;
-    }
-
-
-    /**
-     * 
-     * @param maxNumTerms The total number of terms clauses that will appear once rewritten as a BooleanQuery
-     * @param analyzer
-     */
-    public FuzzyLikeThisQuery(int maxNumTerms, Analyzer analyzer)
-    {
-        q=new ScoreTermQueue(maxNumTerms);
-        this.analyzer=analyzer;
-        this.maxNumTerms = maxNumTerms;
-    }
-
-    class FieldVals
-    {
-    	String queryString;
-    	String fieldName;
-    	float minSimilarity;
-    	int prefixLength;
-		public FieldVals(String name, float similarity, int length, String queryString)
-		{
-			fieldName = name;
-			minSimilarity = similarity;
-			prefixLength = length;
-			this.queryString = queryString;
-		}
-
-    @Override
-    public int hashCode() {
-      final int prime = 31;
-      int result = 1;
-      result = prime * result
-          + ((fieldName == null) ? 0 : fieldName.hashCode());
-      result = prime * result + Float.floatToIntBits(minSimilarity);
-      result = prime * result + prefixLength;
-      result = prime * result
-          + ((queryString == null) ? 0 : queryString.hashCode());
-      return result;
-    }
-
-    @Override
-    public boolean equals(Object obj) {
-      if (this == obj)
-        return true;
-      if (obj == null)
-        return false;
-      if (getClass() != obj.getClass())
-        return false;
-      FieldVals other = (FieldVals) obj;
-      if (fieldName == null) {
-        if (other.fieldName != null)
-          return false;
-      } else if (!fieldName.equals(other.fieldName))
-        return false;
-      if (Float.floatToIntBits(minSimilarity) != Float
-          .floatToIntBits(other.minSimilarity))
-        return false;
-      if (prefixLength != other.prefixLength)
-        return false;
-      if (queryString == null) {
-        if (other.queryString != null)
-          return false;
-      } else if (!queryString.equals(other.queryString))
-        return false;
-      return true;
-    }
-    
-
-    	
-    }
-    
-    /**
-     * Adds user input for "fuzzification" 
-     * @param queryString The string which will be parsed by the analyzer and for which fuzzy variants will be parsed
-     * @param fieldName
-     * @param minSimilarity The minimum similarity of the term variants (see FuzzyTermsEnum)
-     * @param prefixLength Length of required common prefix on variant terms (see FuzzyTermsEnum)
-     */
-    public void addTerms(String queryString, String fieldName,float minSimilarity, int prefixLength) 
-    {
-    	fieldVals.add(new FieldVals(fieldName,minSimilarity,prefixLength,queryString));
-    }
-    
-    
-    private void addTerms(IndexReader reader,FieldVals f) throws IOException
-    {
-        if(f.queryString==null) return;
-        TokenStream ts=analyzer.reusableTokenStream(f.fieldName,new StringReader(f.queryString));
-        CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);
-        
-        int corpusNumDocs=reader.numDocs();
-        HashSet<String> processedTerms=new HashSet<String>();
-        ts.reset();
-        while (ts.incrementToken()) 
-        {
-                String term = termAtt.toString();
-        	if(!processedTerms.contains(term))
-        	{
-                  processedTerms.add(term);
-                  ScoreTermQueue variantsQ=new ScoreTermQueue(MAX_VARIANTS_PER_TERM); //maxNum variants considered for any one term
-                  float minScore=0;
-                  Term startTerm=new Term(f.fieldName, term);
-                  AttributeSource atts = new AttributeSource();
-                  MaxNonCompetitiveBoostAttribute maxBoostAtt =
-                    atts.addAttribute(MaxNonCompetitiveBoostAttribute.class);
-                  FuzzyTermsEnum fe = new FuzzyTermsEnum(MultiFields.getTerms(reader, startTerm.field()).iterator(), atts, startTerm, f.minSimilarity, f.prefixLength);
-                  //store the df so all variants use same idf
-                  int df = reader.docFreq(startTerm);
-                  int numVariants=0;
-                  int totalVariantDocFreqs=0;
-                  BytesRef possibleMatch;
-                  BoostAttribute boostAtt =
-                    fe.attributes().addAttribute(BoostAttribute.class);
-                  while ((possibleMatch = fe.next()) != null) {
-                      numVariants++;
-                      totalVariantDocFreqs+=fe.docFreq();
-                      float score=boostAtt.getBoost();
-                      if (variantsQ.size() < MAX_VARIANTS_PER_TERM || score > minScore){
-                        ScoreTerm st=new ScoreTerm(new Term(startTerm.field(), new BytesRef(possibleMatch)),score,startTerm);                    
-                        variantsQ.insertWithOverflow(st);
-                        minScore = variantsQ.top().score; // maintain minScore
-                      }
-                      maxBoostAtt.setMaxNonCompetitiveBoost(variantsQ.size() >= MAX_VARIANTS_PER_TERM ? minScore : Float.NEGATIVE_INFINITY);
-                    }
-
-                  if(numVariants>0)
-                    {
-                      int avgDf=totalVariantDocFreqs/numVariants;
-                      if(df==0)//no direct match we can use as df for all variants 
-	                {
-	                    df=avgDf; //use avg df of all variants
-	                }
-	                
-                    // take the top variants (scored by edit distance) and reset the score
-                    // to include an IDF factor then add to the global queue for ranking 
-                    // overall top query terms
-                    int size = variantsQ.size();
-                    for(int i = 0; i < size; i++)
-	                {
-	                  ScoreTerm st = variantsQ.pop();
-	                  st.score=(st.score*st.score)*sim.idf(df,corpusNumDocs);
-	                  q.insertWithOverflow(st);
-	                }                            
-                }
-        	}
-        }
-        ts.end();
-        ts.close();
-    }
-            
-    @Override
-    public Query rewrite(IndexReader reader) throws IOException
-    {
-        if(rewrittenQuery!=null)
-        {
-            return rewrittenQuery;
-        }
-        //load up the list of possible terms
-        for (Iterator<FieldVals> iter = fieldVals.iterator(); iter.hasNext();)
-		{
-			FieldVals f = iter.next();
-			addTerms(reader,f);			
-		}
-        //clear the list of fields
-        fieldVals.clear();
-        
-        BooleanQuery bq=new BooleanQuery();
-        
-        
-        //create BooleanQueries to hold the variants for each token/field pair and ensure it
-        // has no coord factor
-        //Step 1: sort the termqueries by term/field
-        HashMap<Term,ArrayList<ScoreTerm>> variantQueries=new HashMap<Term,ArrayList<ScoreTerm>>();
-        int size = q.size();
-        for(int i = 0; i < size; i++)
-        {
-          ScoreTerm st = q.pop();
-          ArrayList<ScoreTerm> l= variantQueries.get(st.fuzziedSourceTerm);
-          if(l==null)
-          {
-              l=new ArrayList<ScoreTerm>();
-              variantQueries.put(st.fuzziedSourceTerm,l);
-          }
-          l.add(st);
-        }
-        //Step 2: Organize the sorted termqueries into zero-coord scoring boolean queries
-        for (Iterator<ArrayList<ScoreTerm>> iter = variantQueries.values().iterator(); iter.hasNext();)
-        {
-            ArrayList<ScoreTerm> variants = iter.next();
-            if(variants.size()==1)
-            {
-                //optimize where only one selected variant
-                ScoreTerm st= variants.get(0);
-                Query tq = ignoreTF ? new ConstantScoreQuery(new TermQuery(st.term)) : new TermQuery(st.term, 1);
-                tq.setBoost(st.score); // set the boost to a mix of IDF and score
-                bq.add(tq, BooleanClause.Occur.SHOULD); 
-            }
-            else
-            {
-                BooleanQuery termVariants=new BooleanQuery(true); //disable coord and IDF for these term variants
-                for (Iterator<ScoreTerm> iterator2 = variants.iterator(); iterator2
-                        .hasNext();)
-                {
-                    ScoreTerm st = iterator2.next();
-                    // found a match
-                    Query tq = ignoreTF ? new ConstantScoreQuery(new TermQuery(st.term)) : new TermQuery(st.term, 1);                    
-                    tq.setBoost(st.score); // set the boost using the ScoreTerm's score
-                    termVariants.add(tq, BooleanClause.Occur.SHOULD);          // add to query                    
-                }
-                bq.add(termVariants, BooleanClause.Occur.SHOULD);          // add to query
-            }
-        }
-        //TODO possible alternative step 3 - organize above booleans into a new layer of field-based
-        // booleans with a minimum-should-match of NumFields-1?
-        bq.setBoost(getBoost());
-        this.rewrittenQuery=bq;
-        return bq;
-    }
-    
-    //Holds info for a fuzzy term variant - initially score is set to edit distance (for ranking best
-    // term variants) then is reset with IDF for use in ranking against all other
-    // terms/fields
-    private static class ScoreTerm{
-        public Term term;
-        public float score;
-        Term fuzziedSourceTerm;
-        
-        public ScoreTerm(Term term, float score, Term fuzziedSourceTerm){
-          this.term = term;
-          this.score = score;
-          this.fuzziedSourceTerm=fuzziedSourceTerm;
-        }
-      }
-      
-      private static class ScoreTermQueue extends PriorityQueue<ScoreTerm> {        
-        public ScoreTermQueue(int size){
-          super(size);
-        }
-        
-        /* (non-Javadoc)
-         * @see org.apache.lucene.util.PriorityQueue#lessThan(java.lang.Object, java.lang.Object)
-         */
-        @Override
-        protected boolean lessThan(ScoreTerm termA, ScoreTerm termB) {
-          if (termA.score== termB.score)
-            return termA.term.compareTo(termB.term) > 0;
-          else
-            return termA.score < termB.score;
-        }
-        
-      }    
-      
-    /* (non-Javadoc)
-     * @see org.apache.lucene.search.Query#toString(java.lang.String)
-     */
-    @Override
-    public String toString(String field)
-    {
-        return null;
-    }
-
-
-	public boolean isIgnoreTF()
-	{
-		return ignoreTF;
-	}
-
-
-	public void setIgnoreTF(boolean ignoreTF)
-	{
-		this.ignoreTF = ignoreTF;
-	}   
-    
-}
diff --git a/lucene/contrib/queries/src/java/org/apache/lucene/search/SlowCollatedStringComparator.java b/lucene/contrib/queries/src/java/org/apache/lucene/search/SlowCollatedStringComparator.java
deleted file mode 100644
index c6664a5..0000000
--- a/lucene/contrib/queries/src/java/org/apache/lucene/search/SlowCollatedStringComparator.java
+++ /dev/null
@@ -1,119 +0,0 @@
-package org.apache.lucene.search;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.text.Collator;
-
-import org.apache.lucene.index.IndexReader.AtomicReaderContext;
-import org.apache.lucene.search.FieldCache.DocTerms;
-import org.apache.lucene.util.BytesRef;
-
-/** Sorts by a field's value using the given Collator
- *
- * <p><b>WARNING</b>: this is very slow; you'll
- * get much better performance using the
- * CollationKeyAnalyzer or ICUCollationKeyAnalyzer. 
- * @deprecated Index collation keys with CollationKeyAnalyzer or ICUCollationKeyAnalyzer instead.
- * This class will be removed in Lucene 5.0
- */
-@Deprecated
-public final class SlowCollatedStringComparator extends FieldComparator<String> {
-
-  private final String[] values;
-  private DocTerms currentDocTerms;
-  private final String field;
-  final Collator collator;
-  private String bottom;
-  private final BytesRef tempBR = new BytesRef();
-
-  public SlowCollatedStringComparator(int numHits, String field, Collator collator) {
-    values = new String[numHits];
-    this.field = field;
-    this.collator = collator;
-  }
-
-  @Override
-  public int compare(int slot1, int slot2) {
-    final String val1 = values[slot1];
-    final String val2 = values[slot2];
-    if (val1 == null) {
-      if (val2 == null) {
-        return 0;
-      }
-      return -1;
-    } else if (val2 == null) {
-      return 1;
-    }
-    return collator.compare(val1, val2);
-  }
-
-  @Override
-  public int compareBottom(int doc) {
-    final String val2 = currentDocTerms.getTerm(doc, tempBR).utf8ToString();
-    if (bottom == null) {
-      if (val2 == null) {
-        return 0;
-      }
-      return -1;
-    } else if (val2 == null) {
-      return 1;
-    }
-    return collator.compare(bottom, val2);
-  }
-
-  @Override
-  public void copy(int slot, int doc) {
-    final BytesRef br = currentDocTerms.getTerm(doc, tempBR);
-    if (br == null) {
-      values[slot] = null;
-    } else {
-      values[slot] = br.utf8ToString();
-    }
-  }
-
-  @Override
-  public FieldComparator setNextReader(AtomicReaderContext context) throws IOException {
-    currentDocTerms = FieldCache.DEFAULT.getTerms(context.reader, field);
-    return this;
-  }
-  
-  @Override
-  public void setBottom(final int bottom) {
-    this.bottom = values[bottom];
-  }
-
-  @Override
-  public String value(int slot) {
-    return values[slot];
-  }
-
-  @Override
-  public int compareValues(String first, String second) {
-    if (first == null) {
-      if (second == null) {
-        return 0;
-      }
-      return -1;
-    } else if (second == null) {
-      return 1;
-    } else {
-      return collator.compare(first, second);
-    }
-  }
-}
diff --git a/lucene/contrib/queries/src/java/org/apache/lucene/search/SlowCollatedTermRangeFilter.java b/lucene/contrib/queries/src/java/org/apache/lucene/search/SlowCollatedTermRangeFilter.java
deleted file mode 100644
index 2d67d0b..0000000
--- a/lucene/contrib/queries/src/java/org/apache/lucene/search/SlowCollatedTermRangeFilter.java
+++ /dev/null
@@ -1,73 +0,0 @@
-package org.apache.lucene.search;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.text.Collator;
-
-import org.apache.lucene.search.NumericRangeFilter; // javadoc
-import org.apache.lucene.search.FieldCacheRangeFilter; // javadoc
-
-/**
- * A Filter that restricts search results to a range of term
- * values in a given field.
- *
- * <p>This filter matches the documents looking for terms that fall into the
- * supplied range according to {@link
- * String#compareTo(String)}, unless a <code>Collator</code> is provided. It is not intended
- * for numerical ranges; use {@link NumericRangeFilter} instead.
- *
- * <p>If you construct a large number of range filters with different ranges but on the 
- * same field, {@link FieldCacheRangeFilter} may have significantly better performance. 
- * @deprecated Index collation keys with CollationKeyAnalyzer or ICUCollationKeyAnalyzer instead.
- * This class will be removed in Lucene 5.0
- */
-@Deprecated
-public class SlowCollatedTermRangeFilter extends MultiTermQueryWrapperFilter<SlowCollatedTermRangeQuery> {
-  /**
-   *
-   * @param lowerTerm The lower bound on this range
-   * @param upperTerm The upper bound on this range
-   * @param includeLower Does this range include the lower bound?
-   * @param includeUpper Does this range include the upper bound?
-   * @param collator The collator to use when determining range inclusion; set
-   *  to null to use Unicode code point ordering instead of collation.
-   * @throws IllegalArgumentException if both terms are null or if
-   *  lowerTerm is null and includeLower is true (similar for upperTerm
-   *  and includeUpper)
-   */
-  public SlowCollatedTermRangeFilter(String fieldName, String lowerTerm, String upperTerm,
-                     boolean includeLower, boolean includeUpper,
-                     Collator collator) {
-      super(new SlowCollatedTermRangeQuery(fieldName, lowerTerm, upperTerm, includeLower, includeUpper, collator));
-  }
-  
-  /** Returns the lower value of this range filter */
-  public String getLowerTerm() { return query.getLowerTerm(); }
-
-  /** Returns the upper value of this range filter */
-  public String getUpperTerm() { return query.getUpperTerm(); }
-  
-  /** Returns <code>true</code> if the lower endpoint is inclusive */
-  public boolean includesLower() { return query.includesLower(); }
-  
-  /** Returns <code>true</code> if the upper endpoint is inclusive */
-  public boolean includesUpper() { return query.includesUpper(); }
-
-  /** Returns the collator used to determine range inclusion, if any. */
-  public Collator getCollator() { return query.getCollator(); }
-}
diff --git a/lucene/contrib/queries/src/java/org/apache/lucene/search/SlowCollatedTermRangeQuery.java b/lucene/contrib/queries/src/java/org/apache/lucene/search/SlowCollatedTermRangeQuery.java
deleted file mode 100644
index 59db72b..0000000
--- a/lucene/contrib/queries/src/java/org/apache/lucene/search/SlowCollatedTermRangeQuery.java
+++ /dev/null
@@ -1,178 +0,0 @@
-package org.apache.lucene.search;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.text.Collator;
-
-import org.apache.lucene.index.Terms;
-import org.apache.lucene.index.TermsEnum;
-import org.apache.lucene.search.MultiTermQuery; // javadoc
-import org.apache.lucene.search.NumericRangeQuery; // javadoc
-import org.apache.lucene.util.AttributeSource;
-import org.apache.lucene.util.ToStringUtils;
-
-/**
- * A Query that matches documents within an range of terms.
- *
- * <p>This query matches the documents looking for terms that fall into the
- * supplied range according to {@link
- * String#compareTo(String)}, unless a <code>Collator</code> is provided. It is not intended
- * for numerical ranges; use {@link NumericRangeQuery} instead.
- *
- * <p>This query uses the {@link
- * MultiTermQuery#CONSTANT_SCORE_AUTO_REWRITE_DEFAULT}
- * rewrite method.
- * @deprecated Index collation keys with CollationKeyAnalyzer or ICUCollationKeyAnalyzer instead.
- * This class will be removed in Lucene 5.0
- */
-@Deprecated
-public class SlowCollatedTermRangeQuery extends MultiTermQuery {
-  private String lowerTerm;
-  private String upperTerm;
-  private boolean includeLower;
-  private boolean includeUpper;
-  private Collator collator;
-
-  /** Constructs a query selecting all terms greater/equal than
-   * <code>lowerTerm</code> but less/equal than <code>upperTerm</code>.
-   * <p>
-   * If an endpoint is null, it is said 
-   * to be "open". Either or both endpoints may be open.  Open endpoints may not 
-   * be exclusive (you can't select all but the first or last term without 
-   * explicitly specifying the term to exclude.)
-   * <p>
-   *
-   * @param lowerTerm The Term text at the lower end of the range
-   * @param upperTerm The Term text at the upper end of the range
-   * @param includeLower
-   *          If true, the <code>lowerTerm</code> is
-   *          included in the range.
-   * @param includeUpper
-   *          If true, the <code>upperTerm</code> is
-   *          included in the range.
-   * @param collator The collator to use to collate index Terms, to determine
-   *  their membership in the range bounded by <code>lowerTerm</code> and
-   *  <code>upperTerm</code>.
-   */
-  public SlowCollatedTermRangeQuery(String field, String lowerTerm, String upperTerm, 
-      boolean includeLower, boolean includeUpper,  Collator collator) {
-    super(field);
-    this.lowerTerm = lowerTerm;
-    this.upperTerm = upperTerm;
-    this.includeLower = includeLower;
-    this.includeUpper = includeUpper;
-    this.collator = collator;
-  }
-
-  /** Returns the lower value of this range query */
-  public String getLowerTerm() { return lowerTerm; }
-
-  /** Returns the upper value of this range query */
-  public String getUpperTerm() { return upperTerm; }
-  
-  /** Returns <code>true</code> if the lower endpoint is inclusive */
-  public boolean includesLower() { return includeLower; }
-  
-  /** Returns <code>true</code> if the upper endpoint is inclusive */
-  public boolean includesUpper() { return includeUpper; }
-
-  /** Returns the collator used to determine range inclusion */
-  public Collator getCollator() { return collator; }
-  
-  @Override
-  protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {
-    if (lowerTerm != null && upperTerm != null && collator.compare(lowerTerm, upperTerm) > 0) {
-      return TermsEnum.EMPTY;
-    }
-    
-    TermsEnum tenum = terms.iterator();
-
-    if (lowerTerm == null && upperTerm == null) {
-      return tenum;
-    }
-    return new SlowCollatedTermRangeTermsEnum(tenum,
-        lowerTerm, upperTerm, includeLower, includeUpper, collator);
-  }
-
-  /** @deprecated */
-  @Deprecated
-  public String field() {
-    return getField();
-  }
-
-  /** Prints a user-readable version of this query. */
-  @Override
-  public String toString(String field) {
-      StringBuilder buffer = new StringBuilder();
-      if (!getField().equals(field)) {
-          buffer.append(getField());
-          buffer.append(":");
-      }
-      buffer.append(includeLower ? '[' : '{');
-      buffer.append(lowerTerm != null ? lowerTerm : "*");
-      buffer.append(" TO ");
-      buffer.append(upperTerm != null ? upperTerm : "*");
-      buffer.append(includeUpper ? ']' : '}');
-      buffer.append(ToStringUtils.boost(getBoost()));
-      return buffer.toString();
-  }
-
-  @Override
-  public int hashCode() {
-    final int prime = 31;
-    int result = super.hashCode();
-    result = prime * result + ((collator == null) ? 0 : collator.hashCode());
-    result = prime * result + (includeLower ? 1231 : 1237);
-    result = prime * result + (includeUpper ? 1231 : 1237);
-    result = prime * result + ((lowerTerm == null) ? 0 : lowerTerm.hashCode());
-    result = prime * result + ((upperTerm == null) ? 0 : upperTerm.hashCode());
-    return result;
-  }
-
-  @Override
-  public boolean equals(Object obj) {
-    if (this == obj)
-      return true;
-    if (!super.equals(obj))
-      return false;
-    if (getClass() != obj.getClass())
-      return false;
-    SlowCollatedTermRangeQuery other = (SlowCollatedTermRangeQuery) obj;
-    if (collator == null) {
-      if (other.collator != null)
-        return false;
-    } else if (!collator.equals(other.collator))
-      return false;
-    if (includeLower != other.includeLower)
-      return false;
-    if (includeUpper != other.includeUpper)
-      return false;
-    if (lowerTerm == null) {
-      if (other.lowerTerm != null)
-        return false;
-    } else if (!lowerTerm.equals(other.lowerTerm))
-      return false;
-    if (upperTerm == null) {
-      if (other.upperTerm != null)
-        return false;
-    } else if (!upperTerm.equals(other.upperTerm))
-      return false;
-    return true;
-  }
-}
diff --git a/lucene/contrib/queries/src/java/org/apache/lucene/search/SlowCollatedTermRangeTermsEnum.java b/lucene/contrib/queries/src/java/org/apache/lucene/search/SlowCollatedTermRangeTermsEnum.java
deleted file mode 100644
index accd2cd..0000000
--- a/lucene/contrib/queries/src/java/org/apache/lucene/search/SlowCollatedTermRangeTermsEnum.java
+++ /dev/null
@@ -1,102 +0,0 @@
-package org.apache.lucene.search;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.text.Collator;
-
-import org.apache.lucene.index.TermsEnum;
-import org.apache.lucene.util.BytesRef;
-
-/**
- * Subclass of FilteredTermEnum for enumerating all terms that match the
- * specified range parameters.
- * <p>Term enumerations are always ordered by
- * {@link #getComparator}.  Each term in the enumeration is
- * greater than all that precede it.</p>
- * @deprecated Index collation keys with CollationKeyAnalyzer or ICUCollationKeyAnalyzer instead.
- *  This class will be removed in Lucene 5.0
- */
-@Deprecated
-public class SlowCollatedTermRangeTermsEnum extends FilteredTermsEnum {
-  private Collator collator;
-  private String upperTermText;
-  private String lowerTermText;
-  private boolean includeLower;
-  private boolean includeUpper;
-
-  /**
-   * Enumerates all terms greater/equal than <code>lowerTerm</code>
-   * but less/equal than <code>upperTerm</code>. 
-   * 
-   * If an endpoint is null, it is said to be "open". Either or both 
-   * endpoints may be open.  Open endpoints may not be exclusive 
-   * (you can't select all but the first or last term without 
-   * explicitly specifying the term to exclude.)
-   * 
-   * @param tenum
-   * @param lowerTermText
-   *          The term text at the lower end of the range
-   * @param upperTermText
-   *          The term text at the upper end of the range
-   * @param includeLower
-   *          If true, the <code>lowerTerm</code> is included in the range.
-   * @param includeUpper
-   *          If true, the <code>upperTerm</code> is included in the range.
-   * @param collator
-   *          The collator to use to collate index Terms, to determine their
-   *          membership in the range bounded by <code>lowerTerm</code> and
-   *          <code>upperTerm</code>.
-   * 
-   * @throws IOException
-   */
-  public SlowCollatedTermRangeTermsEnum(TermsEnum tenum, String lowerTermText, String upperTermText, 
-    boolean includeLower, boolean includeUpper, Collator collator) throws IOException {
-    super(tenum);
-    this.collator = collator;
-    this.upperTermText = upperTermText;
-    this.lowerTermText = lowerTermText;
-    this.includeLower = includeLower;
-    this.includeUpper = includeUpper;
-
-    // do a little bit of normalization...
-    // open ended range queries should always be inclusive.
-    if (this.lowerTermText == null) {
-      this.lowerTermText = "";
-      this.includeLower = true;
-    }
-
-    // TODO: optimize
-    BytesRef startBytesRef = new BytesRef("");
-    setInitialSeekTerm(startBytesRef);
-  }
-
-  @Override
-  protected AcceptStatus accept(BytesRef term) {
-    if ((includeLower
-         ? collator.compare(term.utf8ToString(), lowerTermText) >= 0
-         : collator.compare(term.utf8ToString(), lowerTermText) > 0)
-        && (upperTermText == null
-            || (includeUpper
-                ? collator.compare(term.utf8ToString(), upperTermText) <= 0
-                : collator.compare(term.utf8ToString(), upperTermText) < 0))) {
-      return AcceptStatus.YES;
-    }
-    return AcceptStatus.NO;
-  }
-}
diff --git a/lucene/contrib/queries/src/java/org/apache/lucene/search/regex/JakartaRegexpCapabilities.java b/lucene/contrib/queries/src/java/org/apache/lucene/search/regex/JakartaRegexpCapabilities.java
deleted file mode 100644
index a7ee39c..0000000
--- a/lucene/contrib/queries/src/java/org/apache/lucene/search/regex/JakartaRegexpCapabilities.java
+++ /dev/null
@@ -1,162 +0,0 @@
-package org.apache.lucene.search.regex;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.CharsRef;
-import org.apache.lucene.util.UnicodeUtil;
-import org.apache.regexp.CharacterIterator;
-import org.apache.regexp.RE;
-import org.apache.regexp.REProgram;
-import java.lang.reflect.Field;
-import java.lang.reflect.Method;
-
-/**
- * Implementation tying <a href="http://jakarta.apache.org/regexp">Jakarta
- * Regexp</a> to RegexQuery. Jakarta Regexp internally supports a
- * {@link RegexCapabilities.RegexMatcher#prefix()} implementation which can offer 
- * performance gains under certain circumstances. Yet, the implementation appears 
- * to be rather shaky as it doesn't always provide a prefix even if one would exist.
- */
-public class JakartaRegexpCapabilities implements RegexCapabilities {
-  private static Field prefixField;
-  private static Method getPrefixMethod;
-
-  static {
-    try {
-      getPrefixMethod = REProgram.class.getMethod("getPrefix");
-    } catch (Exception e) {
-      getPrefixMethod = null;
-    }
-    try {
-      prefixField = REProgram.class.getDeclaredField("prefix");
-      prefixField.setAccessible(true);
-    } catch (Exception e) {
-      prefixField = null;
-    }
-  }
-  
-  // Define the flags that are possible. Redefine them here
-  // to avoid exposing the RE class to the caller.
-  
-  private int flags = RE.MATCH_NORMAL;
-
-  /**
-   * Flag to specify normal, case-sensitive matching behaviour. This is the default.
-   */
-  public static final int FLAG_MATCH_NORMAL = RE.MATCH_NORMAL;
-  
-  /**
-   * Flag to specify that matching should be case-independent (folded)
-   */
-  public static final int FLAG_MATCH_CASEINDEPENDENT = RE.MATCH_CASEINDEPENDENT;
- 
-  /**
-   * Constructs a RegexCapabilities with the default MATCH_NORMAL match style.
-   */
-  public JakartaRegexpCapabilities() {}
-  
-  /**
-   * Constructs a RegexCapabilities with the provided match flags.
-   * Multiple flags should be ORed together.
-   * 
-   * @param flags The matching style
-   */
-  public JakartaRegexpCapabilities(int flags) {
-    this.flags = flags;
-  }
-  
-  public RegexCapabilities.RegexMatcher compile(String regex) {
-    return new JakartaRegexMatcher(regex, flags);
-  }
-
-  @Override
-  public int hashCode() {
-    final int prime = 31;
-    int result = 1;
-    result = prime * result + flags;
-    return result;
-  }
-
-  @Override
-  public boolean equals(Object obj) {
-    if (this == obj) {
-      return true;
-    }
-    if (obj == null) {
-      return false;
-    }
-    if (getClass() != obj.getClass()) {
-      return false;
-    }
-    
-    JakartaRegexpCapabilities other = (JakartaRegexpCapabilities) obj;
-    return flags == other.flags;
-  }
-
-  class JakartaRegexMatcher implements RegexCapabilities.RegexMatcher {
-    
-    private RE regexp;
-    private final CharsRef utf16 = new CharsRef(10);
-    private final CharacterIterator utf16wrapper = new CharacterIterator() {
-
-      public char charAt(int pos) {
-        return utf16.chars[pos];
-      }
-
-      public boolean isEnd(int pos) {
-        return pos >= utf16.length;
-      }
-
-      public String substring(int beginIndex) {
-        return substring(beginIndex, utf16.length);
-      }
-
-      public String substring(int beginIndex, int endIndex) {
-        return new String(utf16.chars, beginIndex, endIndex - beginIndex);
-      }
-      
-    };
-    
-    public JakartaRegexMatcher(String regex, int flags) {
-      regexp = new RE(regex, flags);
-    }
-    
-    public boolean match(BytesRef term) {
-      UnicodeUtil.UTF8toUTF16(term.bytes, term.offset, term.length, utf16);
-      return regexp.match(utf16wrapper, 0);
-    }
-
-    public String prefix() {
-      try {
-        final char[] prefix;
-        if (getPrefixMethod != null) {
-          prefix = (char[]) getPrefixMethod.invoke(regexp.getProgram());
-        } else if (prefixField != null) {
-          prefix = (char[]) prefixField.get(regexp.getProgram());
-        } else {
-          return null;
-        }
-        return prefix == null ? null : new String(prefix);
-      } catch (Exception e) {
-        // if we cannot get the prefix, return none
-        return null;
-      }
-    }
-  }
-}
diff --git a/lucene/contrib/queries/src/java/org/apache/lucene/search/regex/JavaUtilRegexCapabilities.java b/lucene/contrib/queries/src/java/org/apache/lucene/search/regex/JavaUtilRegexCapabilities.java
deleted file mode 100644
index 2843ef7..0000000
--- a/lucene/contrib/queries/src/java/org/apache/lucene/search/regex/JavaUtilRegexCapabilities.java
+++ /dev/null
@@ -1,122 +0,0 @@
-package org.apache.lucene.search.regex;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.util.regex.Matcher;
-import java.util.regex.Pattern;
-
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.CharsRef;
-import org.apache.lucene.util.UnicodeUtil;
-
-/**
- * An implementation tying Java's built-in java.util.regex to RegexQuery.
- *
- * Note that because this implementation currently only returns null from
- * {@link RegexCapabilities.RegexMatcher#prefix()} that queries using this implementation 
- * will enumerate and attempt to {@link RegexCapabilities.RegexMatcher#match(BytesRef)} each 
- * term for the specified field in the index.
- */
-public class JavaUtilRegexCapabilities implements RegexCapabilities {
-
-  private int flags = 0;
-
-  // Define the optional flags from Pattern that can be used.
-  // Do this here to keep Pattern contained within this class.
-  
-  public static final int FLAG_CANON_EQ = Pattern.CANON_EQ;
-  public static final int FLAG_CASE_INSENSITIVE = Pattern.CASE_INSENSITIVE;
-  public static final int FLAG_COMMENTS = Pattern.COMMENTS;
-  public static final int FLAG_DOTALL = Pattern.DOTALL;
-  public static final int FLAG_LITERAL = Pattern.LITERAL;
-  public static final int FLAG_MULTILINE = Pattern.MULTILINE;
-  public static final int FLAG_UNICODE_CASE = Pattern.UNICODE_CASE;
-  public static final int FLAG_UNIX_LINES = Pattern.UNIX_LINES;
-  
-  /**
-   * Default constructor that uses java.util.regex.Pattern 
-   * with its default flags.
-   */
-  public JavaUtilRegexCapabilities()  {
-    this.flags = 0;
-  }
-  
-  /**
-   * Constructor that allows for the modification of the flags that
-   * the java.util.regex.Pattern will use to compile the regular expression.
-   * This gives the user the ability to fine-tune how the regular expression 
-   * to match the functionality that they need. 
-   * The {@link java.util.regex.Pattern Pattern} class supports specifying 
-   * these fields via the regular expression text itself, but this gives the caller
-   * another option to modify the behavior. Useful in cases where the regular expression text
-   * cannot be modified, or if doing so is undesired.
-   * 
-   * @param flags The flags that are ORed together.
-   */
-  public JavaUtilRegexCapabilities(int flags) {
-    this.flags = flags;
-  }
-  
-  public RegexCapabilities.RegexMatcher compile(String regex) {
-    return new JavaUtilRegexMatcher(regex, flags);
-  }
-  
-  @Override
-  public int hashCode() {
-    final int prime = 31;
-    int result = 1;
-    result = prime * result + flags;
-    return result;
-  }
-
-  @Override
-  public boolean equals(Object obj) {
-    if (this == obj) {
-      return true;
-    }
-    if (obj == null) {
-      return false;
-    }
-    if (getClass() != obj.getClass()) {
-      return false;
-    }
-
-    JavaUtilRegexCapabilities other = (JavaUtilRegexCapabilities) obj;
-    return flags == other.flags;
-  }
-
-  class JavaUtilRegexMatcher implements RegexCapabilities.RegexMatcher {
-    private final Pattern pattern;
-    private final Matcher matcher;
-    private final CharsRef utf16 = new CharsRef(10);
-    
-    public JavaUtilRegexMatcher(String regex, int flags) {
-      this.pattern = Pattern.compile(regex, flags);
-      this.matcher = this.pattern.matcher(utf16);
-    }
-    
-    public boolean match(BytesRef term) {
-      UnicodeUtil.UTF8toUTF16(term.bytes, term.offset, term.length, utf16);
-      return matcher.reset().matches();
-    }
-
-    public String prefix() {
-      return null;
-    }
-  }
-}
diff --git a/lucene/contrib/queries/src/java/org/apache/lucene/search/regex/RegexCapabilities.java b/lucene/contrib/queries/src/java/org/apache/lucene/search/regex/RegexCapabilities.java
deleted file mode 100644
index c14053c..0000000
--- a/lucene/contrib/queries/src/java/org/apache/lucene/search/regex/RegexCapabilities.java
+++ /dev/null
@@ -1,52 +0,0 @@
-package org.apache.lucene.search.regex;
-
-import org.apache.lucene.util.BytesRef;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-/**
- * Defines basic operations needed by {@link RegexQuery} for a regular
- * expression implementation.
- */
-public interface RegexCapabilities {
-  /**
-   * Called by the constructor of {@link RegexTermsEnum} allowing
-   * implementations to cache a compiled version of the regular
-   * expression pattern.
-   *
-   * @param pattern regular expression pattern
-   */
-  public RegexMatcher compile(String pattern);
-
-  public interface RegexMatcher {
-    /**
-     *
-     * @param term The term in bytes.
-     * @return true if string matches the pattern last passed to {@link #compile}.
-     */
-    public boolean match(BytesRef term);
-
-    /**
-     * A wise prefix implementation can reduce the term enumeration (and thus increase performance)
-     * of RegexQuery dramatically!
-     *
-     * @return static non-regex prefix of the pattern last passed to {@link #compile}.  May return null.
-     */
-    public String prefix();
-  }
-}
diff --git a/lucene/contrib/queries/src/java/org/apache/lucene/search/regex/RegexQuery.java b/lucene/contrib/queries/src/java/org/apache/lucene/search/regex/RegexQuery.java
deleted file mode 100644
index 65e1a2f..0000000
--- a/lucene/contrib/queries/src/java/org/apache/lucene/search/regex/RegexQuery.java
+++ /dev/null
@@ -1,127 +0,0 @@
-package org.apache.lucene.search.regex;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.search.MultiTermQuery;
-import org.apache.lucene.search.FilteredTermsEnum;
-import org.apache.lucene.search.RegexpQuery; // javadoc
-import org.apache.lucene.index.Term;
-import org.apache.lucene.index.Terms;
-import org.apache.lucene.util.AttributeSource;
-import org.apache.lucene.util.ToStringUtils;
-
-import java.io.IOException;
-
-/** Implements the regular expression term search query.
- * The expressions supported depend on the regular expression implementation
- * used by way of the {@link RegexCapabilities} interface.
- * <p>
- * NOTE: You may wish to consider using the regex query support 
- * in {@link RegexpQuery} instead, as it has better performance.
- * 
- * @see RegexTermsEnum
- */
-public class RegexQuery extends MultiTermQuery implements RegexQueryCapable {
-
-  private RegexCapabilities regexImpl = new JavaUtilRegexCapabilities();
-  private Term term;
-
-  /** Constructs a query for terms matching <code>term</code>. */
-  public RegexQuery(Term term) {
-    super(term.field());
-    this.term = term;
-  }
-  
-  public Term getTerm() {
-    return term;
-  }
-
-  /**
-   * Defines which {@link RegexCapabilities} implementation is used by this instance.
-   *
-   * @param impl
-   */
-  public void setRegexImplementation(RegexCapabilities impl) {
-    this.regexImpl = impl;
-  }
-
-  /**
-   * @return The implementation used by this instance.
-   */
-  public RegexCapabilities getRegexImplementation() {
-    return regexImpl;
-  }
-
-  @Override
-  protected FilteredTermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {
-    return new RegexTermsEnum(terms.iterator(), term, regexImpl);
-  }
-
-  @Override
-  public String toString(String field) {
-    StringBuilder buffer = new StringBuilder();
-    if (!term.field().equals(field)) {
-      buffer.append(term.field());
-      buffer.append(":");
-    }
-    buffer.append(term.text());
-    buffer.append(ToStringUtils.boost(getBoost()));
-    return buffer.toString();
-  }
-
-  @Override
-  public int hashCode() {
-    final int prime = 31;
-    int result = super.hashCode();
-    result = prime * result + ((regexImpl == null) ? 0 : regexImpl.hashCode());
-    result = prime * result + ((term == null) ? 0 : term.hashCode());
-    return result;
-  }
-
-  @Override
-  public boolean equals(Object obj) {
-    if (this == obj) {
-      return true;
-    }
-    if (!super.equals(obj)) {
-      return false;
-    }
-    if (getClass() != obj.getClass()) {
-      return false;
-    }
-
-    RegexQuery other = (RegexQuery) obj;
-    if (regexImpl == null) {
-      if (other.regexImpl != null) {
-        return false;
-      }
-    } else if (!regexImpl.equals(other.regexImpl)) {
-      return false;
-    }
-
-    if (term == null) {
-      if (other.term != null) {
-        return false;
-      }
-    } else if (!term.equals(other.term)) {
-      return false;
-    }
-    
-    return true;
-  }
-}
diff --git a/lucene/contrib/queries/src/java/org/apache/lucene/search/regex/RegexQueryCapable.java b/lucene/contrib/queries/src/java/org/apache/lucene/search/regex/RegexQueryCapable.java
deleted file mode 100644
index 4d8b3d1..0000000
--- a/lucene/contrib/queries/src/java/org/apache/lucene/search/regex/RegexQueryCapable.java
+++ /dev/null
@@ -1,28 +0,0 @@
-package org.apache.lucene.search.regex;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-
-/**
- * Defines methods for regular expression supporting Querys to use.
- */
-public interface RegexQueryCapable {
-  
-  void setRegexImplementation(RegexCapabilities impl);
-  RegexCapabilities getRegexImplementation();
-}
diff --git a/lucene/contrib/queries/src/java/org/apache/lucene/search/regex/RegexTermsEnum.java b/lucene/contrib/queries/src/java/org/apache/lucene/search/regex/RegexTermsEnum.java
deleted file mode 100644
index 8fb771b..0000000
--- a/lucene/contrib/queries/src/java/org/apache/lucene/search/regex/RegexTermsEnum.java
+++ /dev/null
@@ -1,64 +0,0 @@
-package org.apache.lucene.search.regex;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.search.FilteredTermsEnum;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.index.TermsEnum;
-import org.apache.lucene.util.BytesRef;
-
-import java.io.IOException;
-
-/**
- * Subclass of FilteredTermEnum for enumerating all terms that match the
- * specified regular expression term using the specified regular expression
- * implementation.
- * <p>
- * Term enumerations are always ordered by Term.compareTo().  Each term in
- * the enumeration is greater than all that precede it.
- */
-
-public class RegexTermsEnum extends FilteredTermsEnum {
-
-  private RegexCapabilities.RegexMatcher regexImpl;
-  private final BytesRef prefixRef;
-
-  public RegexTermsEnum(TermsEnum tenum, Term term, RegexCapabilities regexCap) throws IOException {
-    super(tenum);
-    String text = term.text();
-    this.regexImpl = regexCap.compile(text);
-
-    String pre = regexImpl.prefix();
-    if (pre == null) {
-      pre = "";
-    }
-
-    setInitialSeekTerm(prefixRef = new BytesRef(pre));
-  }
-
-  @Override
-  protected AcceptStatus accept(BytesRef term) {
-    if (term.startsWith(prefixRef)) {
-      // TODO: set BoostAttr based on distance of
-      // searchTerm.text() and term().text()
-      return regexImpl.match(term) ? AcceptStatus.YES : AcceptStatus.NO;
-    } else {
-      return AcceptStatus.NO;
-    }
-  }
-}
diff --git a/lucene/contrib/queries/src/java/org/apache/lucene/search/regex/package.html b/lucene/contrib/queries/src/java/org/apache/lucene/search/regex/package.html
deleted file mode 100644
index 7b54ddb..0000000
--- a/lucene/contrib/queries/src/java/org/apache/lucene/search/regex/package.html
+++ /dev/null
@@ -1,22 +0,0 @@
-<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-<html><head></head>
-<body>
-Regular expression Query.
-</body>
-</html>
diff --git a/lucene/contrib/queries/src/java/overview.html b/lucene/contrib/queries/src/java/overview.html
deleted file mode 100644
index 88e166f..0000000
--- a/lucene/contrib/queries/src/java/overview.html
+++ /dev/null
@@ -1,26 +0,0 @@
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-<html>
-  <head>
-    <title>
-      miscellaneous
-    </title>
-  </head>
-  <body>
-  miscellaneous
-  </body>
-</html>
\ No newline at end of file
diff --git a/lucene/contrib/queries/src/test/org/apache/lucene/search/FuzzyLikeThisQueryTest.java b/lucene/contrib/queries/src/test/org/apache/lucene/search/FuzzyLikeThisQueryTest.java
deleted file mode 100644
index 9e40cb0..0000000
--- a/lucene/contrib/queries/src/test/org/apache/lucene/search/FuzzyLikeThisQueryTest.java
+++ /dev/null
@@ -1,130 +0,0 @@
-package org.apache.lucene.search;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.MockAnalyzer;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.LuceneTestCase;
-
-import java.io.IOException;
-import java.util.HashSet;
-
-public class FuzzyLikeThisQueryTest extends LuceneTestCase {
-  private Directory directory;
-  private IndexSearcher searcher;
-  private IndexReader reader;
-  private Analyzer analyzer = new MockAnalyzer(random);
-
-  @Override
-  public void setUp() throws Exception {
-    super.setUp();
-    directory = newDirectory();
-    RandomIndexWriter writer = new RandomIndexWriter(random, directory, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));
-
-    //Add series of docs with misspelt names
-    addDoc(writer, "jonathon smythe", "1");
-    addDoc(writer, "jonathan smith", "2");
-    addDoc(writer, "johnathon smyth", "3");
-    addDoc(writer, "johnny smith", "4");
-    addDoc(writer, "jonny smith", "5");
-    addDoc(writer, "johnathon smythe", "6");
-    reader = writer.getReader();
-    writer.close();
-    searcher = newSearcher(reader);
-  }
-
-  @Override
-  public void tearDown() throws Exception {
-    searcher.close();
-    reader.close();
-    directory.close();
-    super.tearDown();
-  }
-
-  private void addDoc(RandomIndexWriter writer, String name, String id) throws IOException {
-    Document doc = new Document();
-    doc.add(newField("name", name, Field.Store.YES, Field.Index.ANALYZED));
-    doc.add(newField("id", id, Field.Store.YES, Field.Index.ANALYZED));
-    writer.addDocument(doc);
-  }
-
-
-  //Tests that idf ranking is not favouring rare mis-spellings over a strong edit-distance match
-  public void testClosestEditDistanceMatchComesFirst() throws Throwable {
-    FuzzyLikeThisQuery flt = new FuzzyLikeThisQuery(10, analyzer);
-    flt.addTerms("smith", "name", 0.3f, 1);
-    Query q = flt.rewrite(searcher.getIndexReader());
-    HashSet<Term> queryTerms = new HashSet<Term>();
-    q.extractTerms(queryTerms);
-    assertTrue("Should have variant smythe", queryTerms.contains(new Term("name", "smythe")));
-    assertTrue("Should have variant smith", queryTerms.contains(new Term("name", "smith")));
-    assertTrue("Should have variant smyth", queryTerms.contains(new Term("name", "smyth")));
-    TopDocs topDocs = searcher.search(flt, 1);
-    ScoreDoc[] sd = topDocs.scoreDocs;
-    assertTrue("score docs must match 1 doc", (sd != null) && (sd.length > 0));
-    Document doc = searcher.doc(sd[0].doc);
-    assertEquals("Should match most similar not most rare variant", "2", doc.get("id"));
-  }
-
-  //Test multiple input words are having variants produced
-  public void testMultiWord() throws Throwable {
-    FuzzyLikeThisQuery flt = new FuzzyLikeThisQuery(10, analyzer);
-    flt.addTerms("jonathin smoth", "name", 0.3f, 1);
-    Query q = flt.rewrite(searcher.getIndexReader());
-    HashSet<Term> queryTerms = new HashSet<Term>();
-    q.extractTerms(queryTerms);
-    assertTrue("Should have variant jonathan", queryTerms.contains(new Term("name", "jonathan")));
-    assertTrue("Should have variant smith", queryTerms.contains(new Term("name", "smith")));
-    TopDocs topDocs = searcher.search(flt, 1);
-    ScoreDoc[] sd = topDocs.scoreDocs;
-    assertTrue("score docs must match 1 doc", (sd != null) && (sd.length > 0));
-    Document doc = searcher.doc(sd[0].doc);
-    assertEquals("Should match most similar when using 2 words", "2", doc.get("id"));
-  }
-
-  //Test bug found when first query word does not match anything
-  public void testNoMatchFirstWordBug() throws Throwable {
-    FuzzyLikeThisQuery flt = new FuzzyLikeThisQuery(10, analyzer);
-    flt.addTerms("fernando smith", "name", 0.3f, 1);
-    Query q = flt.rewrite(searcher.getIndexReader());
-    HashSet<Term> queryTerms = new HashSet<Term>();
-    q.extractTerms(queryTerms);
-    assertTrue("Should have variant smith", queryTerms.contains(new Term("name", "smith")));
-    TopDocs topDocs = searcher.search(flt, 1);
-    ScoreDoc[] sd = topDocs.scoreDocs;
-    assertTrue("score docs must match 1 doc", (sd != null) && (sd.length > 0));
-    Document doc = searcher.doc(sd[0].doc);
-    assertEquals("Should match most similar when using 2 words", "2", doc.get("id"));
-  }
-
-  public void testFuzzyLikeThisQueryEquals() {
-    Analyzer analyzer = new MockAnalyzer(random);
-    FuzzyLikeThisQuery fltq1 = new FuzzyLikeThisQuery(10, analyzer);
-    fltq1.addTerms("javi", "subject", 0.5f, 2);
-    FuzzyLikeThisQuery fltq2 = new FuzzyLikeThisQuery(10, analyzer);
-    fltq2.addTerms("javi", "subject", 0.5f, 2);
-    assertEquals("FuzzyLikeThisQuery with same attributes is not equal", fltq1,
-        fltq2);
-  }
-}
diff --git a/lucene/contrib/queries/src/test/org/apache/lucene/search/TestSlowCollationMethods.java b/lucene/contrib/queries/src/test/org/apache/lucene/search/TestSlowCollationMethods.java
deleted file mode 100644
index 529a3b9..0000000
--- a/lucene/contrib/queries/src/test/org/apache/lucene/search/TestSlowCollationMethods.java
+++ /dev/null
@@ -1,148 +0,0 @@
-package org.apache.lucene.search;
-
-import java.io.IOException;
-import java.text.Collator;
-import java.util.Locale;
-
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.search.BooleanClause.Occur;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
-import org.junit.AfterClass;
-import org.junit.BeforeClass;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-/**
- * Tests SlowCollatedStringComparator, SlowCollatedTermRangeQuery, and SlowCollatedTermRangeFilter
- */
-public class TestSlowCollationMethods extends LuceneTestCase {
-  private static Collator collator;
-  private static IndexSearcher searcher;
-  private static IndexReader reader;
-  private static Directory dir;
-  private static int numDocs;
-  private static String splitDoc;
-
-  @BeforeClass
-  public static void beforeClass() throws Exception {
-    final Locale locale = LuceneTestCase.randomLocale(random);
-    collator = Collator.getInstance(locale);
-    collator.setStrength(Collator.IDENTICAL);
-    collator.setDecomposition(Collator.NO_DECOMPOSITION);
-
-    numDocs = 1000 * RANDOM_MULTIPLIER;
-    dir = newDirectory();
-    RandomIndexWriter iw = new RandomIndexWriter(random, dir);
-    for (int i = 0; i < numDocs; i++) {
-      Document doc = new Document();
-      String value = _TestUtil.randomUnicodeString(random);
-      Field field = newField("field", value, Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);
-      doc.add(field);
-      iw.addDocument(doc);
-    }
-    splitDoc = _TestUtil.randomUnicodeString(random);
-    reader = iw.getReader();
-    iw.close();
-
-    searcher = newSearcher(reader);
-  }
-  
-  @AfterClass
-  public static void afterClass() throws Exception {
-    searcher.close();
-    reader.close();
-    dir.close();
-    collator = null;
-    searcher = null;
-    reader = null;
-    dir = null;
-  }
-  
-  private void doCheckSorting(TopDocs docs) throws Exception {
-    String prev = "";
-    for (ScoreDoc doc : docs.scoreDocs) {
-      String value = reader.document(doc.doc).get("field");
-      assertTrue(collator.compare(value, prev) >= 0);
-      prev = value;
-    }
-  }
-  
-  public void testSort() throws Exception {
-    SortField sf = new SortField("field", new FieldComparatorSource() {
-      @Override
-      public FieldComparator newComparator(String fieldname, int numHits, int sortPos, boolean reversed) throws IOException {
-        return new SlowCollatedStringComparator(numHits, fieldname, collator);
-      }
-    });
-    final Sort sort = new Sort(sf);
-    
-    final TopDocs docs1 = searcher.search(TermRangeQuery.newStringRange("field", null, splitDoc, true, true), null, numDocs/(1+random.nextInt(4)), sort);
-    doCheckSorting(docs1);
-    
-    final TopDocs docs2 = searcher.search(TermRangeQuery.newStringRange("field", splitDoc, null, true, true), null, numDocs/(1+random.nextInt(4)), sort);
-    doCheckSorting(docs2);
-    
-    final TopDocs docs = TopDocs.merge(sort, numDocs/(1+random.nextInt(4)), new TopDocs[]{docs1, docs2});
-    doCheckSorting(docs);
-  }
-  
-  private void doTestRanges(String startPoint, String endPoint, Query query) throws Exception {
-    // positive test
-    TopDocs docs = searcher.search(query, numDocs);
-    for (ScoreDoc doc : docs.scoreDocs) {
-      String value = reader.document(doc.doc).get("field");
-      assertTrue(collator.compare(value, startPoint) >= 0);
-      assertTrue(collator.compare(value, endPoint) <= 0);
-    }
-    
-    // negative test
-    BooleanQuery bq = new BooleanQuery();
-    bq.add(new MatchAllDocsQuery(), Occur.SHOULD);
-    bq.add(query, Occur.MUST_NOT);
-    docs = searcher.search(bq, numDocs);
-    for (ScoreDoc doc : docs.scoreDocs) {
-      String value = reader.document(doc.doc).get("field");
-      assertTrue(collator.compare(value, startPoint) < 0 || collator.compare(value, endPoint) > 0);
-    }
-  }
-  
-  public void testRangeQuery() throws Exception {
-    int numQueries = 50*RANDOM_MULTIPLIER;
-    for (int i = 0; i < numQueries; i++) {
-      String startPoint = _TestUtil.randomUnicodeString(random);
-      String endPoint = _TestUtil.randomUnicodeString(random);
-      Query query = new SlowCollatedTermRangeQuery("field", startPoint, endPoint, true, true, collator);
-      doTestRanges(startPoint, endPoint, query);
-    }
-  }
-  
-  public void testRangeFilter() throws Exception {
-    int numQueries = 50*RANDOM_MULTIPLIER;
-    for (int i = 0; i < numQueries; i++) {
-      String startPoint = _TestUtil.randomUnicodeString(random);
-      String endPoint = _TestUtil.randomUnicodeString(random);
-      Query query = new ConstantScoreQuery(new SlowCollatedTermRangeFilter("field", startPoint, endPoint, true, true, collator));
-      doTestRanges(startPoint, endPoint, query);
-    }
-  }
-}
diff --git a/lucene/contrib/queries/src/test/org/apache/lucene/search/regex/TestJakartaRegexpCapabilities.java b/lucene/contrib/queries/src/test/org/apache/lucene/search/regex/TestJakartaRegexpCapabilities.java
deleted file mode 100644
index fc3610b..0000000
--- a/lucene/contrib/queries/src/test/org/apache/lucene/search/regex/TestJakartaRegexpCapabilities.java
+++ /dev/null
@@ -1,47 +0,0 @@
-package org.apache.lucene.search.regex;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.LuceneTestCase;
-
-/**
- * Testcase for {@link JakartaRegexpCapabilities}
- */
-public class TestJakartaRegexpCapabilities extends LuceneTestCase {
-
-  public void testGetPrefix(){
-    JakartaRegexpCapabilities cap = new JakartaRegexpCapabilities();
-    RegexCapabilities.RegexMatcher matcher = cap.compile("luc[e]?");
-    assertTrue(matcher.match(new BytesRef("luce")));
-    assertEquals("luc", matcher.prefix());
-    
-    matcher = cap.compile("lucene");
-    assertTrue(matcher.match(new BytesRef("lucene")));
-    assertEquals("lucene", matcher.prefix());
-  }
-  
-  public void testShakyPrefix(){
-    JakartaRegexpCapabilities cap = new JakartaRegexpCapabilities();
-    RegexCapabilities.RegexMatcher matcher = cap.compile("(ab|ac)");
-    assertTrue(matcher.match(new BytesRef("ab")));
-    assertTrue(matcher.match(new BytesRef("ac")));
-    // why is it not a???
-    assertNull(matcher.prefix());
-  }
-}
diff --git a/lucene/contrib/queries/src/test/org/apache/lucene/search/regex/TestRegexQuery.java b/lucene/contrib/queries/src/test/org/apache/lucene/search/regex/TestRegexQuery.java
deleted file mode 100644
index 1e7d155..0000000
--- a/lucene/contrib/queries/src/test/org/apache/lucene/search/regex/TestRegexQuery.java
+++ /dev/null
@@ -1,136 +0,0 @@
-package org.apache.lucene.search.regex;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.search.spans.SpanMultiTermQueryWrapper;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.MultiFields;
-import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.index.Terms;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.index.TermsEnum;
-
-import org.apache.lucene.search.spans.SpanNearQuery;
-import org.apache.lucene.search.spans.SpanQuery;
-import org.apache.lucene.util.AttributeSource;
-import org.apache.lucene.util.LuceneTestCase;
-
-public class TestRegexQuery extends LuceneTestCase {
-  private IndexSearcher searcher;
-  private IndexReader reader;
-  private Directory directory;
-  private final String FN = "field";
-
-
-  @Override
-  public void setUp() throws Exception {
-    super.setUp();
-    directory = newDirectory();
-    RandomIndexWriter writer = new RandomIndexWriter(random, directory);
-    Document doc = new Document();
-    doc.add(newField(FN, "the quick brown fox jumps over the lazy dog", Field.Store.NO, Field.Index.ANALYZED));
-    writer.addDocument(doc);
-    reader = writer.getReader();
-    writer.close();
-    searcher = newSearcher(reader);
-  }
-
-  @Override
-  public void tearDown() throws Exception {
-    searcher.close();
-    reader.close();
-    directory.close();
-    super.tearDown();
-  }
-
-  private Term newTerm(String value) { return new Term(FN, value); }
-
-  private int  regexQueryNrHits(String regex, RegexCapabilities capability) throws Exception {
-    RegexQuery query = new RegexQuery( newTerm(regex));
-    
-    if ( capability != null )
-      query.setRegexImplementation(capability);
-    
-    return searcher.search(query, null, 1000).totalHits;
-  }
-
-  private int  spanRegexQueryNrHits(String regex1, String regex2, int slop, boolean ordered) throws Exception {
-    SpanQuery srq1 = new SpanMultiTermQueryWrapper<RegexQuery>(new RegexQuery(newTerm(regex1)));
-    SpanQuery srq2 = new SpanMultiTermQueryWrapper<RegexQuery>(new RegexQuery(newTerm(regex2)));
-    SpanNearQuery query = new SpanNearQuery( new SpanQuery[]{srq1, srq2}, slop, ordered);
-
-    return searcher.search(query, null, 1000).totalHits;
-  }
-
-  public void testMatchAll() throws Exception {
-    Terms terms = MultiFields.getTerms(searcher.getIndexReader(), FN);
-    TermsEnum te = new RegexQuery(new Term(FN, "jum.")).getTermsEnum(terms, new AttributeSource() /*dummy*/);
-    // no term should match
-    assertNull(te.next());
-  }
-
-  public void testRegex1() throws Exception {
-    assertEquals(1, regexQueryNrHits("^q.[aeiou]c.*$", null));
-  }
-
-  public void testRegex2() throws Exception {
-    assertEquals(0, regexQueryNrHits("^.[aeiou]c.*$", null));
-  }
-
-  public void testRegex3() throws Exception {
-    assertEquals(0, regexQueryNrHits("^q.[aeiou]c$", null));
-  }
-
-  public void testSpanRegex1() throws Exception {
-    assertEquals(1, spanRegexQueryNrHits("^q.[aeiou]c.*$", "dog", 6, true));
-  }
-
-  public void testSpanRegex2() throws Exception {
-    assertEquals(0, spanRegexQueryNrHits("^q.[aeiou]c.*$", "dog", 5, true));
-  }
-
-  public void testEquals() throws Exception {
-    RegexQuery query1 = new RegexQuery( newTerm("foo.*"));
-    query1.setRegexImplementation(new JakartaRegexpCapabilities());
-
-    RegexQuery query2 = new RegexQuery( newTerm("foo.*"));
-    assertFalse(query1.equals(query2));
-  }
-  
-  public void testJakartaCaseSensativeFail() throws Exception {
-    assertEquals(0, regexQueryNrHits("^.*DOG.*$", null));
-  }
-
-  public void testJavaUtilCaseSensativeFail() throws Exception {
-    assertEquals(0, regexQueryNrHits("^.*DOG.*$", null));
-  }
-  
-  public void testJakartaCaseInsensative() throws Exception {
-    assertEquals(1, regexQueryNrHits("^.*DOG.*$", new JakartaRegexpCapabilities(JakartaRegexpCapabilities.FLAG_MATCH_CASEINDEPENDENT)));
-  }
-  
-  public void testJavaUtilCaseInsensative() throws Exception {
-    assertEquals(1, regexQueryNrHits("^.*DOG.*$", new JavaUtilRegexCapabilities(JavaUtilRegexCapabilities.FLAG_CASE_INSENSITIVE)));
-  }
-
-}
-
diff --git a/lucene/contrib/queries/src/test/org/apache/lucene/search/regex/TestSpanRegexQuery.java b/lucene/contrib/queries/src/test/org/apache/lucene/search/regex/TestSpanRegexQuery.java
deleted file mode 100644
index ae7ad5f..0000000
--- a/lucene/contrib/queries/src/test/org/apache/lucene/search/regex/TestSpanRegexQuery.java
+++ /dev/null
@@ -1,112 +0,0 @@
-package org.apache.lucene.search.regex;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-
-import org.apache.lucene.analysis.MockAnalyzer;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.index.CorruptIndexException;
-import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.index.IndexWriterConfig.OpenMode;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.spans.SpanFirstQuery;
-import org.apache.lucene.search.spans.SpanMultiTermQueryWrapper;
-import org.apache.lucene.search.spans.SpanQuery;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.store.LockObtainFailedException;
-import org.apache.lucene.util.LuceneTestCase;
-
-public class TestSpanRegexQuery extends LuceneTestCase {
-  
-  Directory indexStoreA;
-  Directory indexStoreB;
-  
-  @Override
-  public void setUp() throws Exception {
-    super.setUp();
-    indexStoreA = newDirectory();
-    indexStoreB = newDirectory();
-  }
-  
-  @Override
-  public void tearDown() throws Exception {
-    indexStoreA.close();
-    indexStoreB.close();
-    super.tearDown();
-  }
-  
-  public void testSpanRegex() throws Exception {
-    Directory directory = newDirectory();
-    IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig(
-        TEST_VERSION_CURRENT, new MockAnalyzer(random)));
-    Document doc = new Document();
-    // doc.add(newField("field", "the quick brown fox jumps over the lazy dog",
-    // Field.Store.NO, Field.Index.ANALYZED));
-    // writer.addDocument(doc);
-    // doc = new Document();
-    doc.add(newField("field", "auto update", Field.Store.NO,
-        Field.Index.ANALYZED));
-    writer.addDocument(doc);
-    doc = new Document();
-    doc.add(newField("field", "first auto update", Field.Store.NO,
-        Field.Index.ANALYZED));
-    writer.addDocument(doc);
-    writer.optimize();
-    writer.close();
-
-    IndexSearcher searcher = new IndexSearcher(directory, true);
-    SpanQuery srq = new SpanMultiTermQueryWrapper<RegexQuery>(new RegexQuery(new Term("field", "aut.*")));
-    SpanFirstQuery sfq = new SpanFirstQuery(srq, 1);
-    // SpanNearQuery query = new SpanNearQuery(new SpanQuery[] {srq, stq}, 6,
-    // true);
-    int numHits = searcher.search(sfq, null, 1000).totalHits;
-    assertEquals(1, numHits);
-    searcher.close();
-    directory.close();
-  }
-  
-  private void createRAMDirectories() throws CorruptIndexException,
-      LockObtainFailedException, IOException {
-    // creating a document to store
-    Document lDoc = new Document();
-    lDoc.add(newField("field", "a1 b1", Field.Store.NO,
-        Field.Index.ANALYZED_NO_NORMS));
-
-    // creating a document to store
-    Document lDoc2 = new Document();
-    lDoc2.add(newField("field", "a2 b2", Field.Store.NO,
-        Field.Index.ANALYZED_NO_NORMS));
-
-    // creating first index writer
-    IndexWriter writerA = new IndexWriter(indexStoreA, newIndexWriterConfig(
-        TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE));
-    writerA.addDocument(lDoc);
-    writerA.optimize();
-    writerA.close();
-
-    // creating second index writer
-    IndexWriter writerB = new IndexWriter(indexStoreB, newIndexWriterConfig(
-        TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE));
-    writerB.addDocument(lDoc2);
-    writerB.optimize();
-    writerB.close();
-  }
-}
diff --git a/lucene/contrib/sandbox/build.xml b/lucene/contrib/sandbox/build.xml
new file mode 100644
index 0000000..a934ff0
--- /dev/null
+++ b/lucene/contrib/sandbox/build.xml
@@ -0,0 +1,35 @@
+<!--
+  Licensed to the Apache Software Foundation (ASF) under one or more
+  contributor license agreements.  See the NOTICE file distributed with
+  this work for additional information regarding copyright ownership.
+  The ASF licenses this file to You under the Apache License, Version 2.0
+  (the "License"); you may not use this file except in compliance with
+  the License.  You may obtain a copy of the License at
+
+      http://www.apache.org/licenses/LICENSE-2.0
+
+  Unless required by applicable law or agreed to in writing, software
+  distributed under the License is distributed on an "AS IS" BASIS,
+  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  See the License for the specific language governing permissions and
+  limitations under the License.
+  -->
+
+<project name="sandbox" default="default">
+
+  <description>
+    Sandbox for odd contrib code
+  </description>
+
+  <path id="additional.dependencies">
+    <fileset dir="lib" includes="*-regexp-*.jar"/>
+  </path>
+
+  <pathconvert property="project.classpath"
+               targetos="unix"
+               refid="additional.dependencies"
+  />
+
+  <import file="../contrib-build.xml"/>
+
+</project>
diff --git a/lucene/contrib/sandbox/lib/jakarta-regexp-1.4.jar b/lucene/contrib/sandbox/lib/jakarta-regexp-1.4.jar
new file mode 100644
index 0000000..0366f23
--- /dev/null
+++ b/lucene/contrib/sandbox/lib/jakarta-regexp-1.4.jar
@@ -0,0 +1,2 @@
+AnyObjectId[5d70c357a1e6c4c702af313c94aaf3168d300dcf] was removed in git history.
+Apache SVN contains full history.
\ No newline at end of file
diff --git a/lucene/contrib/sandbox/lib/jakarta-regexp-LICENSE-ASL.txt b/lucene/contrib/sandbox/lib/jakarta-regexp-LICENSE-ASL.txt
new file mode 100644
index 0000000..261eeb9
--- /dev/null
+++ b/lucene/contrib/sandbox/lib/jakarta-regexp-LICENSE-ASL.txt
@@ -0,0 +1,201 @@
+                                 Apache License
+                           Version 2.0, January 2004
+                        http://www.apache.org/licenses/
+
+   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
+
+   1. Definitions.
+
+      "License" shall mean the terms and conditions for use, reproduction,
+      and distribution as defined by Sections 1 through 9 of this document.
+
+      "Licensor" shall mean the copyright owner or entity authorized by
+      the copyright owner that is granting the License.
+
+      "Legal Entity" shall mean the union of the acting entity and all
+      other entities that control, are controlled by, or are under common
+      control with that entity. For the purposes of this definition,
+      "control" means (i) the power, direct or indirect, to cause the
+      direction or management of such entity, whether by contract or
+      otherwise, or (ii) ownership of fifty percent (50%) or more of the
+      outstanding shares, or (iii) beneficial ownership of such entity.
+
+      "You" (or "Your") shall mean an individual or Legal Entity
+      exercising permissions granted by this License.
+
+      "Source" form shall mean the preferred form for making modifications,
+      including but not limited to software source code, documentation
+      source, and configuration files.
+
+      "Object" form shall mean any form resulting from mechanical
+      transformation or translation of a Source form, including but
+      not limited to compiled object code, generated documentation,
+      and conversions to other media types.
+
+      "Work" shall mean the work of authorship, whether in Source or
+      Object form, made available under the License, as indicated by a
+      copyright notice that is included in or attached to the work
+      (an example is provided in the Appendix below).
+
+      "Derivative Works" shall mean any work, whether in Source or Object
+      form, that is based on (or derived from) the Work and for which the
+      editorial revisions, annotations, elaborations, or other modifications
+      represent, as a whole, an original work of authorship. For the purposes
+      of this License, Derivative Works shall not include works that remain
+      separable from, or merely link (or bind by name) to the interfaces of,
+      the Work and Derivative Works thereof.
+
+      "Contribution" shall mean any work of authorship, including
+      the original version of the Work and any modifications or additions
+      to that Work or Derivative Works thereof, that is intentionally
+      submitted to Licensor for inclusion in the Work by the copyright owner
+      or by an individual or Legal Entity authorized to submit on behalf of
+      the copyright owner. For the purposes of this definition, "submitted"
+      means any form of electronic, verbal, or written communication sent
+      to the Licensor or its representatives, including but not limited to
+      communication on electronic mailing lists, source code control systems,
+      and issue tracking systems that are managed by, or on behalf of, the
+      Licensor for the purpose of discussing and improving the Work, but
+      excluding communication that is conspicuously marked or otherwise
+      designated in writing by the copyright owner as "Not a Contribution."
+
+      "Contributor" shall mean Licensor and any individual or Legal Entity
+      on behalf of whom a Contribution has been received by Licensor and
+      subsequently incorporated within the Work.
+
+   2. Grant of Copyright License. Subject to the terms and conditions of
+      this License, each Contributor hereby grants to You a perpetual,
+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+      copyright license to reproduce, prepare Derivative Works of,
+      publicly display, publicly perform, sublicense, and distribute the
+      Work and such Derivative Works in Source or Object form.
+
+   3. Grant of Patent License. Subject to the terms and conditions of
+      this License, each Contributor hereby grants to You a perpetual,
+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+      (except as stated in this section) patent license to make, have made,
+      use, offer to sell, sell, import, and otherwise transfer the Work,
+      where such license applies only to those patent claims licensable
+      by such Contributor that are necessarily infringed by their
+      Contribution(s) alone or by combination of their Contribution(s)
+      with the Work to which such Contribution(s) was submitted. If You
+      institute patent litigation against any entity (including a
+      cross-claim or counterclaim in a lawsuit) alleging that the Work
+      or a Contribution incorporated within the Work constitutes direct
+      or contributory patent infringement, then any patent licenses
+      granted to You under this License for that Work shall terminate
+      as of the date such litigation is filed.
+
+   4. Redistribution. You may reproduce and distribute copies of the
+      Work or Derivative Works thereof in any medium, with or without
+      modifications, and in Source or Object form, provided that You
+      meet the following conditions:
+
+      (a) You must give any other recipients of the Work or
+          Derivative Works a copy of this License; and
+
+      (b) You must cause any modified files to carry prominent notices
+          stating that You changed the files; and
+
+      (c) You must retain, in the Source form of any Derivative Works
+          that You distribute, all copyright, patent, trademark, and
+          attribution notices from the Source form of the Work,
+          excluding those notices that do not pertain to any part of
+          the Derivative Works; and
+
+      (d) If the Work includes a "NOTICE" text file as part of its
+          distribution, then any Derivative Works that You distribute must
+          include a readable copy of the attribution notices contained
+          within such NOTICE file, excluding those notices that do not
+          pertain to any part of the Derivative Works, in at least one
+          of the following places: within a NOTICE text file distributed
+          as part of the Derivative Works; within the Source form or
+          documentation, if provided along with the Derivative Works; or,
+          within a display generated by the Derivative Works, if and
+          wherever such third-party notices normally appear. The contents
+          of the NOTICE file are for informational purposes only and
+          do not modify the License. You may add Your own attribution
+          notices within Derivative Works that You distribute, alongside
+          or as an addendum to the NOTICE text from the Work, provided
+          that such additional attribution notices cannot be construed
+          as modifying the License.
+
+      You may add Your own copyright statement to Your modifications and
+      may provide additional or different license terms and conditions
+      for use, reproduction, or distribution of Your modifications, or
+      for any such Derivative Works as a whole, provided Your use,
+      reproduction, and distribution of the Work otherwise complies with
+      the conditions stated in this License.
+
+   5. Submission of Contributions. Unless You explicitly state otherwise,
+      any Contribution intentionally submitted for inclusion in the Work
+      by You to the Licensor shall be under the terms and conditions of
+      this License, without any additional terms or conditions.
+      Notwithstanding the above, nothing herein shall supersede or modify
+      the terms of any separate license agreement you may have executed
+      with Licensor regarding such Contributions.
+
+   6. Trademarks. This License does not grant permission to use the trade
+      names, trademarks, service marks, or product names of the Licensor,
+      except as required for reasonable and customary use in describing the
+      origin of the Work and reproducing the content of the NOTICE file.
+
+   7. Disclaimer of Warranty. Unless required by applicable law or
+      agreed to in writing, Licensor provides the Work (and each
+      Contributor provides its Contributions) on an "AS IS" BASIS,
+      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+      implied, including, without limitation, any warranties or conditions
+      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
+      PARTICULAR PURPOSE. You are solely responsible for determining the
+      appropriateness of using or redistributing the Work and assume any
+      risks associated with Your exercise of permissions under this License.
+
+   8. Limitation of Liability. In no event and under no legal theory,
+      whether in tort (including negligence), contract, or otherwise,
+      unless required by applicable law (such as deliberate and grossly
+      negligent acts) or agreed to in writing, shall any Contributor be
+      liable to You for damages, including any direct, indirect, special,
+      incidental, or consequential damages of any character arising as a
+      result of this License or out of the use or inability to use the
+      Work (including but not limited to damages for loss of goodwill,
+      work stoppage, computer failure or malfunction, or any and all
+      other commercial damages or losses), even if such Contributor
+      has been advised of the possibility of such damages.
+
+   9. Accepting Warranty or Additional Liability. While redistributing
+      the Work or Derivative Works thereof, You may choose to offer,
+      and charge a fee for, acceptance of support, warranty, indemnity,
+      or other liability obligations and/or rights consistent with this
+      License. However, in accepting such obligations, You may act only
+      on Your own behalf and on Your sole responsibility, not on behalf
+      of any other Contributor, and only if You agree to indemnify,
+      defend, and hold each Contributor harmless for any liability
+      incurred by, or claims asserted against, such Contributor by reason
+      of your accepting any such warranty or additional liability.
+
+   END OF TERMS AND CONDITIONS
+
+   APPENDIX: How to apply the Apache License to your work.
+
+      To apply the Apache License to your work, attach the following
+      boilerplate notice, with the fields enclosed by brackets "[]"
+      replaced with your own identifying information. (Don't include
+      the brackets!)  The text should be enclosed in the appropriate
+      comment syntax for the file format. We also recommend that a
+      file or class name and description of purpose be included on the
+      same "printed page" as the copyright notice for easier
+      identification within third-party archives.
+
+   Copyright [yyyy] [name of copyright owner]
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
diff --git a/lucene/contrib/sandbox/lib/jakarta-regexp-NOTICE.txt b/lucene/contrib/sandbox/lib/jakarta-regexp-NOTICE.txt
new file mode 100644
index 0000000..c6f1099
--- /dev/null
+++ b/lucene/contrib/sandbox/lib/jakarta-regexp-NOTICE.txt
@@ -0,0 +1,10 @@
+Apache Regexp
+Copyright 2001-2007 The Apache Software Foundation
+
+This product includes software developed at
+The Apache Software Foundation (http://www.apache.org/).
+          
+It consists of voluntary contributions made by many individuals
+on behalf of the Apache Software Foundation. Please visit the
+project homepage (http://jakarta.apache.org/regexp) for more
+information.
diff --git a/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/DuplicateFilter.java b/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/DuplicateFilter.java
new file mode 100644
index 0000000..3704918
--- /dev/null
+++ b/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/DuplicateFilter.java
@@ -0,0 +1,214 @@
+package org.apache.lucene.sandbox.queries;
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.index.*;
+import org.apache.lucene.index.IndexReader.AtomicReaderContext;
+import org.apache.lucene.search.DocIdSet;
+import org.apache.lucene.search.Filter;
+import org.apache.lucene.util.Bits;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.FixedBitSet;
+
+import java.io.IOException;
+
+public class DuplicateFilter extends Filter {
+  // TODO: make duplicate filter aware of ReaderContext such that we can
+  // filter duplicates across segments
+
+  /**
+   * KeepMode determines which document id to consider as the master, all others being
+   * identified as duplicates. Selecting the "first occurrence" can potentially save on IO.
+   */
+  public enum KeepMode {
+    KM_USE_FIRST_OCCURRENCE, KM_USE_LAST_OCCURRENCE
+  }
+
+  private KeepMode keepMode;
+
+  /**
+   * "Full" processing mode starts by setting all bits to false and only setting bits
+   * for documents that contain the given field and are identified as none-duplicates.
+   * <p/>
+   * "Fast" processing sets all bits to true then unsets all duplicate docs found for the
+   * given field. This approach avoids the need to read TermDocs for terms that are seen
+   * to have a document frequency of exactly "1" (i.e. no duplicates). While a potentially
+   * faster approach , the downside is that bitsets produced will include bits set for
+   * documents that do not actually contain the field given.
+   */
+
+  public enum ProcessingMode {
+    PM_FULL_VALIDATION, PM_FAST_INVALIDATION
+  }
+
+  private ProcessingMode processingMode;
+
+  private String fieldName;
+
+  public DuplicateFilter(String fieldName) {
+    this(fieldName, KeepMode.KM_USE_LAST_OCCURRENCE, ProcessingMode.PM_FULL_VALIDATION);
+  }
+
+  public DuplicateFilter(String fieldName, KeepMode keepMode, ProcessingMode processingMode) {
+    this.fieldName = fieldName;
+    this.keepMode = keepMode;
+    this.processingMode = processingMode;
+  }
+
+  @Override
+  public DocIdSet getDocIdSet(AtomicReaderContext context) throws IOException {
+    if (processingMode == ProcessingMode.PM_FAST_INVALIDATION) {
+      return fastBits(context.reader);
+    } else {
+      return correctBits(context.reader);
+    }
+  }
+
+  private FixedBitSet correctBits(IndexReader reader) throws IOException {
+    FixedBitSet bits = new FixedBitSet(reader.maxDoc()); //assume all are INvalid
+    final Bits liveDocs = MultiFields.getLiveDocs(reader);
+    Terms terms = reader.fields().terms(fieldName);
+
+    if (terms == null) {
+      return bits;
+    }
+
+    TermsEnum termsEnum = terms.iterator();
+    DocsEnum docs = null;
+    while (true) {
+      BytesRef currTerm = termsEnum.next();
+      if (currTerm == null) {
+        break;
+      } else {
+        docs = termsEnum.docs(liveDocs, docs);
+        int doc = docs.nextDoc();
+        if (doc != DocsEnum.NO_MORE_DOCS) {
+          if (keepMode == KeepMode.KM_USE_FIRST_OCCURRENCE) {
+            bits.set(doc);
+          } else {
+            int lastDoc = doc;
+            while (true) {
+              lastDoc = doc;
+              doc = docs.nextDoc();
+              if (doc == DocsEnum.NO_MORE_DOCS) {
+                break;
+              }
+            }
+            bits.set(lastDoc);
+          }
+        }
+      }
+    }
+    return bits;
+  }
+
+  private FixedBitSet fastBits(IndexReader reader) throws IOException {
+    FixedBitSet bits = new FixedBitSet(reader.maxDoc());
+    bits.set(0, reader.maxDoc()); //assume all are valid
+    final Bits liveDocs = MultiFields.getLiveDocs(reader);
+    Terms terms = reader.fields().terms(fieldName);
+
+    if (terms == null) {
+      return bits;
+    }
+
+    TermsEnum termsEnum = terms.iterator();
+    DocsEnum docs = null;
+    while (true) {
+      BytesRef currTerm = termsEnum.next();
+      if (currTerm == null) {
+        break;
+      } else {
+        if (termsEnum.docFreq() > 1) {
+          // unset potential duplicates
+          docs = termsEnum.docs(liveDocs, docs);
+          int doc = docs.nextDoc();
+          if (doc != DocsEnum.NO_MORE_DOCS) {
+            if (keepMode == KeepMode.KM_USE_FIRST_OCCURRENCE) {
+              doc = docs.nextDoc();
+            }
+          }
+
+          int lastDoc = -1;
+          while (true) {
+            lastDoc = doc;
+            bits.clear(lastDoc);
+            doc = docs.nextDoc();
+            if (doc == DocsEnum.NO_MORE_DOCS) {
+              break;
+            }
+          }
+
+          if (keepMode == KeepMode.KM_USE_LAST_OCCURRENCE) {
+            // restore the last bit
+            bits.set(lastDoc);
+          }
+        }
+      }
+    }
+
+    return bits;
+  }
+
+  public String getFieldName() {
+    return fieldName;
+  }
+
+  public void setFieldName(String fieldName) {
+    this.fieldName = fieldName;
+  }
+
+  public KeepMode getKeepMode() {
+    return keepMode;
+  }
+
+  public void setKeepMode(KeepMode keepMode) {
+    this.keepMode = keepMode;
+  }
+
+  @Override
+  public boolean equals(Object obj) {
+    if (this == obj) {
+      return true;
+    }
+    if ((obj == null) || (obj.getClass() != this.getClass())) {
+      return false;
+    }
+
+    DuplicateFilter other = (DuplicateFilter) obj;
+    return keepMode == other.keepMode &&
+        processingMode == other.processingMode &&
+        fieldName != null && fieldName.equals(other.fieldName);
+  }
+
+  @Override
+  public int hashCode() {
+    int hash = 217;
+    hash = 31 * hash + keepMode.hashCode();
+    hash = 31 * hash + processingMode.hashCode();
+    hash = 31 * hash + fieldName.hashCode();
+    return hash;
+  }
+
+  public ProcessingMode getProcessingMode() {
+    return processingMode;
+  }
+
+  public void setProcessingMode(ProcessingMode processingMode) {
+    this.processingMode = processingMode;
+  }
+}
diff --git a/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/FuzzyLikeThisQuery.java b/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/FuzzyLikeThisQuery.java
new file mode 100644
index 0000000..c6909cd
--- /dev/null
+++ b/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/FuzzyLikeThisQuery.java
@@ -0,0 +1,380 @@
+package org.apache.lucene.sandbox.queries;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.io.StringReader;
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Iterator;
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.MultiFields;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.*;
+import org.apache.lucene.util.AttributeSource;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.PriorityQueue;
+
+/**
+ * Fuzzifies ALL terms provided as strings and then picks the best n differentiating terms.
+ * In effect this mixes the behaviour of FuzzyQuery and MoreLikeThis but with special consideration
+ * of fuzzy scoring factors.
+ * This generally produces good results for queries where users may provide details in a number of 
+ * fields and have no knowledge of boolean query syntax and also want a degree of fuzzy matching and
+ * a fast query.
+ * 
+ * For each source term the fuzzy variants are held in a BooleanQuery with no coord factor (because
+ * we are not looking for matches on multiple variants in any one doc). Additionally, a specialized
+ * TermQuery is used for variants and does not use that variant term's IDF because this would favour rarer 
+ * terms eg misspellings. Instead, all variants use the same IDF ranking (the one for the source query 
+ * term) and this is factored into the variant's boost. If the source query term does not exist in the
+ * index the average IDF of the variants is used.
+ */
+public class FuzzyLikeThisQuery extends Query
+{
+    // TODO: generalize this query (at least it should not reuse this static sim!
+    // a better way might be to convert this into multitermquery rewrite methods.
+    // the rewrite method can 'average' the TermContext's term statistics (docfreq,totalTermFreq) 
+    // provided to TermQuery, so that the general idea is agnostic to any scoring system...
+    static TFIDFSimilarity sim=new DefaultSimilarity();
+    Query rewrittenQuery=null;
+    ArrayList<FieldVals> fieldVals=new ArrayList<FieldVals>();
+    Analyzer analyzer;
+    
+    ScoreTermQueue q;
+    int MAX_VARIANTS_PER_TERM=50;
+    boolean ignoreTF=false;
+    private int maxNumTerms;
+
+    @Override
+    public int hashCode() {
+      final int prime = 31;
+      int result = 1;
+      result = prime * result + ((analyzer == null) ? 0 : analyzer.hashCode());
+      result = prime * result
+          + ((fieldVals == null) ? 0 : fieldVals.hashCode());
+      result = prime * result + (ignoreTF ? 1231 : 1237);
+      result = prime * result + maxNumTerms;
+      return result;
+    }
+
+    @Override
+    public boolean equals(Object obj) {
+      if (this == obj)
+        return true;
+      if (obj == null)
+        return false;
+      if (getClass() != obj.getClass())
+        return false;
+      FuzzyLikeThisQuery other = (FuzzyLikeThisQuery) obj;
+      if (analyzer == null) {
+        if (other.analyzer != null)
+          return false;
+      } else if (!analyzer.equals(other.analyzer))
+        return false;
+      if (fieldVals == null) {
+        if (other.fieldVals != null)
+          return false;
+      } else if (!fieldVals.equals(other.fieldVals))
+        return false;
+      if (ignoreTF != other.ignoreTF)
+        return false;
+      if (maxNumTerms != other.maxNumTerms)
+        return false;
+      return true;
+    }
+
+
+    /**
+     * 
+     * @param maxNumTerms The total number of terms clauses that will appear once rewritten as a BooleanQuery
+     * @param analyzer
+     */
+    public FuzzyLikeThisQuery(int maxNumTerms, Analyzer analyzer)
+    {
+        q=new ScoreTermQueue(maxNumTerms);
+        this.analyzer=analyzer;
+        this.maxNumTerms = maxNumTerms;
+    }
+
+    class FieldVals
+    {
+    	String queryString;
+    	String fieldName;
+    	float minSimilarity;
+    	int prefixLength;
+		public FieldVals(String name, float similarity, int length, String queryString)
+		{
+			fieldName = name;
+			minSimilarity = similarity;
+			prefixLength = length;
+			this.queryString = queryString;
+		}
+
+    @Override
+    public int hashCode() {
+      final int prime = 31;
+      int result = 1;
+      result = prime * result
+          + ((fieldName == null) ? 0 : fieldName.hashCode());
+      result = prime * result + Float.floatToIntBits(minSimilarity);
+      result = prime * result + prefixLength;
+      result = prime * result
+          + ((queryString == null) ? 0 : queryString.hashCode());
+      return result;
+    }
+
+    @Override
+    public boolean equals(Object obj) {
+      if (this == obj)
+        return true;
+      if (obj == null)
+        return false;
+      if (getClass() != obj.getClass())
+        return false;
+      FieldVals other = (FieldVals) obj;
+      if (fieldName == null) {
+        if (other.fieldName != null)
+          return false;
+      } else if (!fieldName.equals(other.fieldName))
+        return false;
+      if (Float.floatToIntBits(minSimilarity) != Float
+          .floatToIntBits(other.minSimilarity))
+        return false;
+      if (prefixLength != other.prefixLength)
+        return false;
+      if (queryString == null) {
+        if (other.queryString != null)
+          return false;
+      } else if (!queryString.equals(other.queryString))
+        return false;
+      return true;
+    }
+    
+
+    	
+    }
+    
+    /**
+     * Adds user input for "fuzzification" 
+     * @param queryString The string which will be parsed by the analyzer and for which fuzzy variants will be parsed
+     * @param fieldName
+     * @param minSimilarity The minimum similarity of the term variants (see FuzzyTermsEnum)
+     * @param prefixLength Length of required common prefix on variant terms (see FuzzyTermsEnum)
+     */
+    public void addTerms(String queryString, String fieldName,float minSimilarity, int prefixLength) 
+    {
+    	fieldVals.add(new FieldVals(fieldName,minSimilarity,prefixLength,queryString));
+    }
+    
+    
+    private void addTerms(IndexReader reader,FieldVals f) throws IOException
+    {
+        if(f.queryString==null) return;
+        TokenStream ts=analyzer.reusableTokenStream(f.fieldName,new StringReader(f.queryString));
+        CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);
+        
+        int corpusNumDocs=reader.numDocs();
+        HashSet<String> processedTerms=new HashSet<String>();
+        ts.reset();
+        while (ts.incrementToken()) 
+        {
+                String term = termAtt.toString();
+        	if(!processedTerms.contains(term))
+        	{
+                  processedTerms.add(term);
+                  ScoreTermQueue variantsQ=new ScoreTermQueue(MAX_VARIANTS_PER_TERM); //maxNum variants considered for any one term
+                  float minScore=0;
+                  Term startTerm=new Term(f.fieldName, term);
+                  AttributeSource atts = new AttributeSource();
+                  MaxNonCompetitiveBoostAttribute maxBoostAtt =
+                    atts.addAttribute(MaxNonCompetitiveBoostAttribute.class);
+                  FuzzyTermsEnum fe = new FuzzyTermsEnum(MultiFields.getTerms(reader, startTerm.field()).iterator(), atts, startTerm, f.minSimilarity, f.prefixLength);
+                  //store the df so all variants use same idf
+                  int df = reader.docFreq(startTerm);
+                  int numVariants=0;
+                  int totalVariantDocFreqs=0;
+                  BytesRef possibleMatch;
+                  BoostAttribute boostAtt =
+                    fe.attributes().addAttribute(BoostAttribute.class);
+                  while ((possibleMatch = fe.next()) != null) {
+                      numVariants++;
+                      totalVariantDocFreqs+=fe.docFreq();
+                      float score=boostAtt.getBoost();
+                      if (variantsQ.size() < MAX_VARIANTS_PER_TERM || score > minScore){
+                        ScoreTerm st=new ScoreTerm(new Term(startTerm.field(), new BytesRef(possibleMatch)),score,startTerm);                    
+                        variantsQ.insertWithOverflow(st);
+                        minScore = variantsQ.top().score; // maintain minScore
+                      }
+                      maxBoostAtt.setMaxNonCompetitiveBoost(variantsQ.size() >= MAX_VARIANTS_PER_TERM ? minScore : Float.NEGATIVE_INFINITY);
+                    }
+
+                  if(numVariants>0)
+                    {
+                      int avgDf=totalVariantDocFreqs/numVariants;
+                      if(df==0)//no direct match we can use as df for all variants 
+	                {
+	                    df=avgDf; //use avg df of all variants
+	                }
+	                
+                    // take the top variants (scored by edit distance) and reset the score
+                    // to include an IDF factor then add to the global queue for ranking 
+                    // overall top query terms
+                    int size = variantsQ.size();
+                    for(int i = 0; i < size; i++)
+	                {
+	                  ScoreTerm st = variantsQ.pop();
+	                  st.score=(st.score*st.score)*sim.idf(df,corpusNumDocs);
+	                  q.insertWithOverflow(st);
+	                }                            
+                }
+        	}
+        }
+        ts.end();
+        ts.close();
+    }
+            
+    @Override
+    public Query rewrite(IndexReader reader) throws IOException
+    {
+        if(rewrittenQuery!=null)
+        {
+            return rewrittenQuery;
+        }
+        //load up the list of possible terms
+        for (Iterator<FieldVals> iter = fieldVals.iterator(); iter.hasNext();)
+		{
+			FieldVals f = iter.next();
+			addTerms(reader,f);			
+		}
+        //clear the list of fields
+        fieldVals.clear();
+        
+        BooleanQuery bq=new BooleanQuery();
+        
+        
+        //create BooleanQueries to hold the variants for each token/field pair and ensure it
+        // has no coord factor
+        //Step 1: sort the termqueries by term/field
+        HashMap<Term,ArrayList<ScoreTerm>> variantQueries=new HashMap<Term,ArrayList<ScoreTerm>>();
+        int size = q.size();
+        for(int i = 0; i < size; i++)
+        {
+          ScoreTerm st = q.pop();
+          ArrayList<ScoreTerm> l= variantQueries.get(st.fuzziedSourceTerm);
+          if(l==null)
+          {
+              l=new ArrayList<ScoreTerm>();
+              variantQueries.put(st.fuzziedSourceTerm,l);
+          }
+          l.add(st);
+        }
+        //Step 2: Organize the sorted termqueries into zero-coord scoring boolean queries
+        for (Iterator<ArrayList<ScoreTerm>> iter = variantQueries.values().iterator(); iter.hasNext();)
+        {
+            ArrayList<ScoreTerm> variants = iter.next();
+            if(variants.size()==1)
+            {
+                //optimize where only one selected variant
+                ScoreTerm st= variants.get(0);
+                Query tq = ignoreTF ? new ConstantScoreQuery(new TermQuery(st.term)) : new TermQuery(st.term, 1);
+                tq.setBoost(st.score); // set the boost to a mix of IDF and score
+                bq.add(tq, BooleanClause.Occur.SHOULD); 
+            }
+            else
+            {
+                BooleanQuery termVariants=new BooleanQuery(true); //disable coord and IDF for these term variants
+                for (Iterator<ScoreTerm> iterator2 = variants.iterator(); iterator2
+                        .hasNext();)
+                {
+                    ScoreTerm st = iterator2.next();
+                    // found a match
+                    Query tq = ignoreTF ? new ConstantScoreQuery(new TermQuery(st.term)) : new TermQuery(st.term, 1);                    
+                    tq.setBoost(st.score); // set the boost using the ScoreTerm's score
+                    termVariants.add(tq, BooleanClause.Occur.SHOULD);          // add to query                    
+                }
+                bq.add(termVariants, BooleanClause.Occur.SHOULD);          // add to query
+            }
+        }
+        //TODO possible alternative step 3 - organize above booleans into a new layer of field-based
+        // booleans with a minimum-should-match of NumFields-1?
+        bq.setBoost(getBoost());
+        this.rewrittenQuery=bq;
+        return bq;
+    }
+    
+    //Holds info for a fuzzy term variant - initially score is set to edit distance (for ranking best
+    // term variants) then is reset with IDF for use in ranking against all other
+    // terms/fields
+    private static class ScoreTerm{
+        public Term term;
+        public float score;
+        Term fuzziedSourceTerm;
+        
+        public ScoreTerm(Term term, float score, Term fuzziedSourceTerm){
+          this.term = term;
+          this.score = score;
+          this.fuzziedSourceTerm=fuzziedSourceTerm;
+        }
+      }
+      
+      private static class ScoreTermQueue extends PriorityQueue<ScoreTerm> {        
+        public ScoreTermQueue(int size){
+          super(size);
+        }
+        
+        /* (non-Javadoc)
+         * @see org.apache.lucene.util.PriorityQueue#lessThan(java.lang.Object, java.lang.Object)
+         */
+        @Override
+        protected boolean lessThan(ScoreTerm termA, ScoreTerm termB) {
+          if (termA.score== termB.score)
+            return termA.term.compareTo(termB.term) > 0;
+          else
+            return termA.score < termB.score;
+        }
+        
+      }    
+      
+    /* (non-Javadoc)
+     * @see org.apache.lucene.search.Query#toString(java.lang.String)
+     */
+    @Override
+    public String toString(String field)
+    {
+        return null;
+    }
+
+
+	public boolean isIgnoreTF()
+	{
+		return ignoreTF;
+	}
+
+
+	public void setIgnoreTF(boolean ignoreTF)
+	{
+		this.ignoreTF = ignoreTF;
+	}   
+    
+}
diff --git a/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/SlowCollatedStringComparator.java b/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/SlowCollatedStringComparator.java
new file mode 100644
index 0000000..5f377b2
--- /dev/null
+++ b/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/SlowCollatedStringComparator.java
@@ -0,0 +1,121 @@
+package org.apache.lucene.sandbox.queries;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.text.Collator;
+
+import org.apache.lucene.index.IndexReader.AtomicReaderContext;
+import org.apache.lucene.search.FieldCache;
+import org.apache.lucene.search.FieldCache.DocTerms;
+import org.apache.lucene.search.FieldComparator;
+import org.apache.lucene.util.BytesRef;
+
+/** Sorts by a field's value using the given Collator
+ *
+ * <p><b>WARNING</b>: this is very slow; you'll
+ * get much better performance using the
+ * CollationKeyAnalyzer or ICUCollationKeyAnalyzer. 
+ * @deprecated Index collation keys with CollationKeyAnalyzer or ICUCollationKeyAnalyzer instead.
+ * This class will be removed in Lucene 5.0
+ */
+@Deprecated
+public final class SlowCollatedStringComparator extends FieldComparator<String> {
+
+  private final String[] values;
+  private DocTerms currentDocTerms;
+  private final String field;
+  final Collator collator;
+  private String bottom;
+  private final BytesRef tempBR = new BytesRef();
+
+  public SlowCollatedStringComparator(int numHits, String field, Collator collator) {
+    values = new String[numHits];
+    this.field = field;
+    this.collator = collator;
+  }
+
+  @Override
+  public int compare(int slot1, int slot2) {
+    final String val1 = values[slot1];
+    final String val2 = values[slot2];
+    if (val1 == null) {
+      if (val2 == null) {
+        return 0;
+      }
+      return -1;
+    } else if (val2 == null) {
+      return 1;
+    }
+    return collator.compare(val1, val2);
+  }
+
+  @Override
+  public int compareBottom(int doc) {
+    final String val2 = currentDocTerms.getTerm(doc, tempBR).utf8ToString();
+    if (bottom == null) {
+      if (val2 == null) {
+        return 0;
+      }
+      return -1;
+    } else if (val2 == null) {
+      return 1;
+    }
+    return collator.compare(bottom, val2);
+  }
+
+  @Override
+  public void copy(int slot, int doc) {
+    final BytesRef br = currentDocTerms.getTerm(doc, tempBR);
+    if (br == null) {
+      values[slot] = null;
+    } else {
+      values[slot] = br.utf8ToString();
+    }
+  }
+
+  @Override
+  public FieldComparator setNextReader(AtomicReaderContext context) throws IOException {
+    currentDocTerms = FieldCache.DEFAULT.getTerms(context.reader, field);
+    return this;
+  }
+  
+  @Override
+  public void setBottom(final int bottom) {
+    this.bottom = values[bottom];
+  }
+
+  @Override
+  public String value(int slot) {
+    return values[slot];
+  }
+
+  @Override
+  public int compareValues(String first, String second) {
+    if (first == null) {
+      if (second == null) {
+        return 0;
+      }
+      return -1;
+    } else if (second == null) {
+      return 1;
+    } else {
+      return collator.compare(first, second);
+    }
+  }
+}
diff --git a/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/SlowCollatedTermRangeFilter.java b/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/SlowCollatedTermRangeFilter.java
new file mode 100644
index 0000000..2674d98
--- /dev/null
+++ b/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/SlowCollatedTermRangeFilter.java
@@ -0,0 +1,74 @@
+package org.apache.lucene.sandbox.queries;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.text.Collator;
+
+import org.apache.lucene.search.MultiTermQueryWrapperFilter;
+import org.apache.lucene.search.NumericRangeFilter; // javadoc
+import org.apache.lucene.search.FieldCacheRangeFilter; // javadoc
+
+/**
+ * A Filter that restricts search results to a range of term
+ * values in a given field.
+ *
+ * <p>This filter matches the documents looking for terms that fall into the
+ * supplied range according to {@link
+ * String#compareTo(String)}, unless a <code>Collator</code> is provided. It is not intended
+ * for numerical ranges; use {@link NumericRangeFilter} instead.
+ *
+ * <p>If you construct a large number of range filters with different ranges but on the 
+ * same field, {@link FieldCacheRangeFilter} may have significantly better performance. 
+ * @deprecated Index collation keys with CollationKeyAnalyzer or ICUCollationKeyAnalyzer instead.
+ * This class will be removed in Lucene 5.0
+ */
+@Deprecated
+public class SlowCollatedTermRangeFilter extends MultiTermQueryWrapperFilter<SlowCollatedTermRangeQuery> {
+  /**
+   *
+   * @param lowerTerm The lower bound on this range
+   * @param upperTerm The upper bound on this range
+   * @param includeLower Does this range include the lower bound?
+   * @param includeUpper Does this range include the upper bound?
+   * @param collator The collator to use when determining range inclusion; set
+   *  to null to use Unicode code point ordering instead of collation.
+   * @throws IllegalArgumentException if both terms are null or if
+   *  lowerTerm is null and includeLower is true (similar for upperTerm
+   *  and includeUpper)
+   */
+  public SlowCollatedTermRangeFilter(String fieldName, String lowerTerm, String upperTerm,
+                     boolean includeLower, boolean includeUpper,
+                     Collator collator) {
+      super(new SlowCollatedTermRangeQuery(fieldName, lowerTerm, upperTerm, includeLower, includeUpper, collator));
+  }
+  
+  /** Returns the lower value of this range filter */
+  public String getLowerTerm() { return query.getLowerTerm(); }
+
+  /** Returns the upper value of this range filter */
+  public String getUpperTerm() { return query.getUpperTerm(); }
+  
+  /** Returns <code>true</code> if the lower endpoint is inclusive */
+  public boolean includesLower() { return query.includesLower(); }
+  
+  /** Returns <code>true</code> if the upper endpoint is inclusive */
+  public boolean includesUpper() { return query.includesUpper(); }
+
+  /** Returns the collator used to determine range inclusion, if any. */
+  public Collator getCollator() { return query.getCollator(); }
+}
diff --git a/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/SlowCollatedTermRangeQuery.java b/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/SlowCollatedTermRangeQuery.java
new file mode 100644
index 0000000..0488e5e
--- /dev/null
+++ b/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/SlowCollatedTermRangeQuery.java
@@ -0,0 +1,178 @@
+package org.apache.lucene.sandbox.queries;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.text.Collator;
+
+import org.apache.lucene.index.Terms;
+import org.apache.lucene.index.TermsEnum;
+import org.apache.lucene.search.MultiTermQuery; // javadoc
+import org.apache.lucene.search.NumericRangeQuery; // javadoc
+import org.apache.lucene.util.AttributeSource;
+import org.apache.lucene.util.ToStringUtils;
+
+/**
+ * A Query that matches documents within an range of terms.
+ *
+ * <p>This query matches the documents looking for terms that fall into the
+ * supplied range according to {@link
+ * String#compareTo(String)}, unless a <code>Collator</code> is provided. It is not intended
+ * for numerical ranges; use {@link NumericRangeQuery} instead.
+ *
+ * <p>This query uses the {@link
+ * MultiTermQuery#CONSTANT_SCORE_AUTO_REWRITE_DEFAULT}
+ * rewrite method.
+ * @deprecated Index collation keys with CollationKeyAnalyzer or ICUCollationKeyAnalyzer instead.
+ * This class will be removed in Lucene 5.0
+ */
+@Deprecated
+public class SlowCollatedTermRangeQuery extends MultiTermQuery {
+  private String lowerTerm;
+  private String upperTerm;
+  private boolean includeLower;
+  private boolean includeUpper;
+  private Collator collator;
+
+  /** Constructs a query selecting all terms greater/equal than
+   * <code>lowerTerm</code> but less/equal than <code>upperTerm</code>.
+   * <p>
+   * If an endpoint is null, it is said 
+   * to be "open". Either or both endpoints may be open.  Open endpoints may not 
+   * be exclusive (you can't select all but the first or last term without 
+   * explicitly specifying the term to exclude.)
+   * <p>
+   *
+   * @param lowerTerm The Term text at the lower end of the range
+   * @param upperTerm The Term text at the upper end of the range
+   * @param includeLower
+   *          If true, the <code>lowerTerm</code> is
+   *          included in the range.
+   * @param includeUpper
+   *          If true, the <code>upperTerm</code> is
+   *          included in the range.
+   * @param collator The collator to use to collate index Terms, to determine
+   *  their membership in the range bounded by <code>lowerTerm</code> and
+   *  <code>upperTerm</code>.
+   */
+  public SlowCollatedTermRangeQuery(String field, String lowerTerm, String upperTerm, 
+      boolean includeLower, boolean includeUpper,  Collator collator) {
+    super(field);
+    this.lowerTerm = lowerTerm;
+    this.upperTerm = upperTerm;
+    this.includeLower = includeLower;
+    this.includeUpper = includeUpper;
+    this.collator = collator;
+  }
+
+  /** Returns the lower value of this range query */
+  public String getLowerTerm() { return lowerTerm; }
+
+  /** Returns the upper value of this range query */
+  public String getUpperTerm() { return upperTerm; }
+  
+  /** Returns <code>true</code> if the lower endpoint is inclusive */
+  public boolean includesLower() { return includeLower; }
+  
+  /** Returns <code>true</code> if the upper endpoint is inclusive */
+  public boolean includesUpper() { return includeUpper; }
+
+  /** Returns the collator used to determine range inclusion */
+  public Collator getCollator() { return collator; }
+  
+  @Override
+  protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {
+    if (lowerTerm != null && upperTerm != null && collator.compare(lowerTerm, upperTerm) > 0) {
+      return TermsEnum.EMPTY;
+    }
+    
+    TermsEnum tenum = terms.iterator();
+
+    if (lowerTerm == null && upperTerm == null) {
+      return tenum;
+    }
+    return new SlowCollatedTermRangeTermsEnum(tenum,
+        lowerTerm, upperTerm, includeLower, includeUpper, collator);
+  }
+
+  /** @deprecated */
+  @Deprecated
+  public String field() {
+    return getField();
+  }
+
+  /** Prints a user-readable version of this query. */
+  @Override
+  public String toString(String field) {
+      StringBuilder buffer = new StringBuilder();
+      if (!getField().equals(field)) {
+          buffer.append(getField());
+          buffer.append(":");
+      }
+      buffer.append(includeLower ? '[' : '{');
+      buffer.append(lowerTerm != null ? lowerTerm : "*");
+      buffer.append(" TO ");
+      buffer.append(upperTerm != null ? upperTerm : "*");
+      buffer.append(includeUpper ? ']' : '}');
+      buffer.append(ToStringUtils.boost(getBoost()));
+      return buffer.toString();
+  }
+
+  @Override
+  public int hashCode() {
+    final int prime = 31;
+    int result = super.hashCode();
+    result = prime * result + ((collator == null) ? 0 : collator.hashCode());
+    result = prime * result + (includeLower ? 1231 : 1237);
+    result = prime * result + (includeUpper ? 1231 : 1237);
+    result = prime * result + ((lowerTerm == null) ? 0 : lowerTerm.hashCode());
+    result = prime * result + ((upperTerm == null) ? 0 : upperTerm.hashCode());
+    return result;
+  }
+
+  @Override
+  public boolean equals(Object obj) {
+    if (this == obj)
+      return true;
+    if (!super.equals(obj))
+      return false;
+    if (getClass() != obj.getClass())
+      return false;
+    SlowCollatedTermRangeQuery other = (SlowCollatedTermRangeQuery) obj;
+    if (collator == null) {
+      if (other.collator != null)
+        return false;
+    } else if (!collator.equals(other.collator))
+      return false;
+    if (includeLower != other.includeLower)
+      return false;
+    if (includeUpper != other.includeUpper)
+      return false;
+    if (lowerTerm == null) {
+      if (other.lowerTerm != null)
+        return false;
+    } else if (!lowerTerm.equals(other.lowerTerm))
+      return false;
+    if (upperTerm == null) {
+      if (other.upperTerm != null)
+        return false;
+    } else if (!upperTerm.equals(other.upperTerm))
+      return false;
+    return true;
+  }
+}
diff --git a/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/SlowCollatedTermRangeTermsEnum.java b/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/SlowCollatedTermRangeTermsEnum.java
new file mode 100644
index 0000000..f299ff7
--- /dev/null
+++ b/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/SlowCollatedTermRangeTermsEnum.java
@@ -0,0 +1,103 @@
+package org.apache.lucene.sandbox.queries;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.text.Collator;
+
+import org.apache.lucene.index.TermsEnum;
+import org.apache.lucene.search.FilteredTermsEnum;
+import org.apache.lucene.util.BytesRef;
+
+/**
+ * Subclass of FilteredTermEnum for enumerating all terms that match the
+ * specified range parameters.
+ * <p>Term enumerations are always ordered by
+ * {@link #getComparator}.  Each term in the enumeration is
+ * greater than all that precede it.</p>
+ * @deprecated Index collation keys with CollationKeyAnalyzer or ICUCollationKeyAnalyzer instead.
+ *  This class will be removed in Lucene 5.0
+ */
+@Deprecated
+public class SlowCollatedTermRangeTermsEnum extends FilteredTermsEnum {
+  private Collator collator;
+  private String upperTermText;
+  private String lowerTermText;
+  private boolean includeLower;
+  private boolean includeUpper;
+
+  /**
+   * Enumerates all terms greater/equal than <code>lowerTerm</code>
+   * but less/equal than <code>upperTerm</code>. 
+   * 
+   * If an endpoint is null, it is said to be "open". Either or both 
+   * endpoints may be open.  Open endpoints may not be exclusive 
+   * (you can't select all but the first or last term without 
+   * explicitly specifying the term to exclude.)
+   * 
+   * @param tenum
+   * @param lowerTermText
+   *          The term text at the lower end of the range
+   * @param upperTermText
+   *          The term text at the upper end of the range
+   * @param includeLower
+   *          If true, the <code>lowerTerm</code> is included in the range.
+   * @param includeUpper
+   *          If true, the <code>upperTerm</code> is included in the range.
+   * @param collator
+   *          The collator to use to collate index Terms, to determine their
+   *          membership in the range bounded by <code>lowerTerm</code> and
+   *          <code>upperTerm</code>.
+   * 
+   * @throws IOException
+   */
+  public SlowCollatedTermRangeTermsEnum(TermsEnum tenum, String lowerTermText, String upperTermText, 
+    boolean includeLower, boolean includeUpper, Collator collator) throws IOException {
+    super(tenum);
+    this.collator = collator;
+    this.upperTermText = upperTermText;
+    this.lowerTermText = lowerTermText;
+    this.includeLower = includeLower;
+    this.includeUpper = includeUpper;
+
+    // do a little bit of normalization...
+    // open ended range queries should always be inclusive.
+    if (this.lowerTermText == null) {
+      this.lowerTermText = "";
+      this.includeLower = true;
+    }
+
+    // TODO: optimize
+    BytesRef startBytesRef = new BytesRef("");
+    setInitialSeekTerm(startBytesRef);
+  }
+
+  @Override
+  protected AcceptStatus accept(BytesRef term) {
+    if ((includeLower
+         ? collator.compare(term.utf8ToString(), lowerTermText) >= 0
+         : collator.compare(term.utf8ToString(), lowerTermText) > 0)
+        && (upperTermText == null
+            || (includeUpper
+                ? collator.compare(term.utf8ToString(), upperTermText) <= 0
+                : collator.compare(term.utf8ToString(), upperTermText) < 0))) {
+      return AcceptStatus.YES;
+    }
+    return AcceptStatus.NO;
+  }
+}
diff --git a/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/regex/JakartaRegexpCapabilities.java b/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/regex/JakartaRegexpCapabilities.java
new file mode 100644
index 0000000..d2acb4e
--- /dev/null
+++ b/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/regex/JakartaRegexpCapabilities.java
@@ -0,0 +1,162 @@
+package org.apache.lucene.sandbox.queries.regex;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.CharsRef;
+import org.apache.lucene.util.UnicodeUtil;
+import org.apache.regexp.CharacterIterator;
+import org.apache.regexp.RE;
+import org.apache.regexp.REProgram;
+import java.lang.reflect.Field;
+import java.lang.reflect.Method;
+
+/**
+ * Implementation tying <a href="http://jakarta.apache.org/regexp">Jakarta
+ * Regexp</a> to RegexQuery. Jakarta Regexp internally supports a
+ * {@link RegexCapabilities.RegexMatcher#prefix()} implementation which can offer 
+ * performance gains under certain circumstances. Yet, the implementation appears 
+ * to be rather shaky as it doesn't always provide a prefix even if one would exist.
+ */
+public class JakartaRegexpCapabilities implements RegexCapabilities {
+  private static Field prefixField;
+  private static Method getPrefixMethod;
+
+  static {
+    try {
+      getPrefixMethod = REProgram.class.getMethod("getPrefix");
+    } catch (Exception e) {
+      getPrefixMethod = null;
+    }
+    try {
+      prefixField = REProgram.class.getDeclaredField("prefix");
+      prefixField.setAccessible(true);
+    } catch (Exception e) {
+      prefixField = null;
+    }
+  }
+  
+  // Define the flags that are possible. Redefine them here
+  // to avoid exposing the RE class to the caller.
+  
+  private int flags = RE.MATCH_NORMAL;
+
+  /**
+   * Flag to specify normal, case-sensitive matching behaviour. This is the default.
+   */
+  public static final int FLAG_MATCH_NORMAL = RE.MATCH_NORMAL;
+  
+  /**
+   * Flag to specify that matching should be case-independent (folded)
+   */
+  public static final int FLAG_MATCH_CASEINDEPENDENT = RE.MATCH_CASEINDEPENDENT;
+ 
+  /**
+   * Constructs a RegexCapabilities with the default MATCH_NORMAL match style.
+   */
+  public JakartaRegexpCapabilities() {}
+  
+  /**
+   * Constructs a RegexCapabilities with the provided match flags.
+   * Multiple flags should be ORed together.
+   * 
+   * @param flags The matching style
+   */
+  public JakartaRegexpCapabilities(int flags) {
+    this.flags = flags;
+  }
+  
+  public RegexCapabilities.RegexMatcher compile(String regex) {
+    return new JakartaRegexMatcher(regex, flags);
+  }
+
+  @Override
+  public int hashCode() {
+    final int prime = 31;
+    int result = 1;
+    result = prime * result + flags;
+    return result;
+  }
+
+  @Override
+  public boolean equals(Object obj) {
+    if (this == obj) {
+      return true;
+    }
+    if (obj == null) {
+      return false;
+    }
+    if (getClass() != obj.getClass()) {
+      return false;
+    }
+    
+    JakartaRegexpCapabilities other = (JakartaRegexpCapabilities) obj;
+    return flags == other.flags;
+  }
+
+  class JakartaRegexMatcher implements RegexCapabilities.RegexMatcher {
+    
+    private RE regexp;
+    private final CharsRef utf16 = new CharsRef(10);
+    private final CharacterIterator utf16wrapper = new CharacterIterator() {
+
+      public char charAt(int pos) {
+        return utf16.chars[pos];
+      }
+
+      public boolean isEnd(int pos) {
+        return pos >= utf16.length;
+      }
+
+      public String substring(int beginIndex) {
+        return substring(beginIndex, utf16.length);
+      }
+
+      public String substring(int beginIndex, int endIndex) {
+        return new String(utf16.chars, beginIndex, endIndex - beginIndex);
+      }
+      
+    };
+    
+    public JakartaRegexMatcher(String regex, int flags) {
+      regexp = new RE(regex, flags);
+    }
+    
+    public boolean match(BytesRef term) {
+      UnicodeUtil.UTF8toUTF16(term.bytes, term.offset, term.length, utf16);
+      return regexp.match(utf16wrapper, 0);
+    }
+
+    public String prefix() {
+      try {
+        final char[] prefix;
+        if (getPrefixMethod != null) {
+          prefix = (char[]) getPrefixMethod.invoke(regexp.getProgram());
+        } else if (prefixField != null) {
+          prefix = (char[]) prefixField.get(regexp.getProgram());
+        } else {
+          return null;
+        }
+        return prefix == null ? null : new String(prefix);
+      } catch (Exception e) {
+        // if we cannot get the prefix, return none
+        return null;
+      }
+    }
+  }
+}
diff --git a/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/regex/JavaUtilRegexCapabilities.java b/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/regex/JavaUtilRegexCapabilities.java
new file mode 100644
index 0000000..d089361
--- /dev/null
+++ b/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/regex/JavaUtilRegexCapabilities.java
@@ -0,0 +1,122 @@
+package org.apache.lucene.sandbox.queries.regex;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.CharsRef;
+import org.apache.lucene.util.UnicodeUtil;
+
+/**
+ * An implementation tying Java's built-in java.util.regex to RegexQuery.
+ *
+ * Note that because this implementation currently only returns null from
+ * {@link RegexCapabilities.RegexMatcher#prefix()} that queries using this implementation 
+ * will enumerate and attempt to {@link RegexCapabilities.RegexMatcher#match(BytesRef)} each 
+ * term for the specified field in the index.
+ */
+public class JavaUtilRegexCapabilities implements RegexCapabilities {
+
+  private int flags = 0;
+
+  // Define the optional flags from Pattern that can be used.
+  // Do this here to keep Pattern contained within this class.
+  
+  public static final int FLAG_CANON_EQ = Pattern.CANON_EQ;
+  public static final int FLAG_CASE_INSENSITIVE = Pattern.CASE_INSENSITIVE;
+  public static final int FLAG_COMMENTS = Pattern.COMMENTS;
+  public static final int FLAG_DOTALL = Pattern.DOTALL;
+  public static final int FLAG_LITERAL = Pattern.LITERAL;
+  public static final int FLAG_MULTILINE = Pattern.MULTILINE;
+  public static final int FLAG_UNICODE_CASE = Pattern.UNICODE_CASE;
+  public static final int FLAG_UNIX_LINES = Pattern.UNIX_LINES;
+  
+  /**
+   * Default constructor that uses java.util.regex.Pattern 
+   * with its default flags.
+   */
+  public JavaUtilRegexCapabilities()  {
+    this.flags = 0;
+  }
+  
+  /**
+   * Constructor that allows for the modification of the flags that
+   * the java.util.regex.Pattern will use to compile the regular expression.
+   * This gives the user the ability to fine-tune how the regular expression 
+   * to match the functionality that they need. 
+   * The {@link java.util.regex.Pattern Pattern} class supports specifying 
+   * these fields via the regular expression text itself, but this gives the caller
+   * another option to modify the behavior. Useful in cases where the regular expression text
+   * cannot be modified, or if doing so is undesired.
+   * 
+   * @param flags The flags that are ORed together.
+   */
+  public JavaUtilRegexCapabilities(int flags) {
+    this.flags = flags;
+  }
+  
+  public RegexCapabilities.RegexMatcher compile(String regex) {
+    return new JavaUtilRegexMatcher(regex, flags);
+  }
+  
+  @Override
+  public int hashCode() {
+    final int prime = 31;
+    int result = 1;
+    result = prime * result + flags;
+    return result;
+  }
+
+  @Override
+  public boolean equals(Object obj) {
+    if (this == obj) {
+      return true;
+    }
+    if (obj == null) {
+      return false;
+    }
+    if (getClass() != obj.getClass()) {
+      return false;
+    }
+
+    JavaUtilRegexCapabilities other = (JavaUtilRegexCapabilities) obj;
+    return flags == other.flags;
+  }
+
+  class JavaUtilRegexMatcher implements RegexCapabilities.RegexMatcher {
+    private final Pattern pattern;
+    private final Matcher matcher;
+    private final CharsRef utf16 = new CharsRef(10);
+    
+    public JavaUtilRegexMatcher(String regex, int flags) {
+      this.pattern = Pattern.compile(regex, flags);
+      this.matcher = this.pattern.matcher(utf16);
+    }
+    
+    public boolean match(BytesRef term) {
+      UnicodeUtil.UTF8toUTF16(term.bytes, term.offset, term.length, utf16);
+      return matcher.reset().matches();
+    }
+
+    public String prefix() {
+      return null;
+    }
+  }
+}
diff --git a/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/regex/RegexCapabilities.java b/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/regex/RegexCapabilities.java
new file mode 100644
index 0000000..9337ae2
--- /dev/null
+++ b/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/regex/RegexCapabilities.java
@@ -0,0 +1,52 @@
+package org.apache.lucene.sandbox.queries.regex;
+
+import org.apache.lucene.util.BytesRef;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/**
+ * Defines basic operations needed by {@link RegexQuery} for a regular
+ * expression implementation.
+ */
+public interface RegexCapabilities {
+  /**
+   * Called by the constructor of {@link RegexTermsEnum} allowing
+   * implementations to cache a compiled version of the regular
+   * expression pattern.
+   *
+   * @param pattern regular expression pattern
+   */
+  public RegexMatcher compile(String pattern);
+
+  public interface RegexMatcher {
+    /**
+     *
+     * @param term The term in bytes.
+     * @return true if string matches the pattern last passed to {@link #compile}.
+     */
+    public boolean match(BytesRef term);
+
+    /**
+     * A wise prefix implementation can reduce the term enumeration (and thus increase performance)
+     * of RegexQuery dramatically!
+     *
+     * @return static non-regex prefix of the pattern last passed to {@link #compile}.  May return null.
+     */
+    public String prefix();
+  }
+}
diff --git a/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/regex/RegexQuery.java b/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/regex/RegexQuery.java
new file mode 100644
index 0000000..4770694
--- /dev/null
+++ b/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/regex/RegexQuery.java
@@ -0,0 +1,127 @@
+package org.apache.lucene.sandbox.queries.regex;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.search.MultiTermQuery;
+import org.apache.lucene.search.FilteredTermsEnum;
+import org.apache.lucene.search.RegexpQuery; // javadoc
+import org.apache.lucene.index.Term;
+import org.apache.lucene.index.Terms;
+import org.apache.lucene.util.AttributeSource;
+import org.apache.lucene.util.ToStringUtils;
+
+import java.io.IOException;
+
+/** Implements the regular expression term search query.
+ * The expressions supported depend on the regular expression implementation
+ * used by way of the {@link RegexCapabilities} interface.
+ * <p>
+ * NOTE: You may wish to consider using the regex query support 
+ * in {@link RegexpQuery} instead, as it has better performance.
+ * 
+ * @see RegexTermsEnum
+ */
+public class RegexQuery extends MultiTermQuery implements RegexQueryCapable {
+
+  private RegexCapabilities regexImpl = new JavaUtilRegexCapabilities();
+  private Term term;
+
+  /** Constructs a query for terms matching <code>term</code>. */
+  public RegexQuery(Term term) {
+    super(term.field());
+    this.term = term;
+  }
+  
+  public Term getTerm() {
+    return term;
+  }
+
+  /**
+   * Defines which {@link RegexCapabilities} implementation is used by this instance.
+   *
+   * @param impl
+   */
+  public void setRegexImplementation(RegexCapabilities impl) {
+    this.regexImpl = impl;
+  }
+
+  /**
+   * @return The implementation used by this instance.
+   */
+  public RegexCapabilities getRegexImplementation() {
+    return regexImpl;
+  }
+
+  @Override
+  protected FilteredTermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {
+    return new RegexTermsEnum(terms.iterator(), term, regexImpl);
+  }
+
+  @Override
+  public String toString(String field) {
+    StringBuilder buffer = new StringBuilder();
+    if (!term.field().equals(field)) {
+      buffer.append(term.field());
+      buffer.append(":");
+    }
+    buffer.append(term.text());
+    buffer.append(ToStringUtils.boost(getBoost()));
+    return buffer.toString();
+  }
+
+  @Override
+  public int hashCode() {
+    final int prime = 31;
+    int result = super.hashCode();
+    result = prime * result + ((regexImpl == null) ? 0 : regexImpl.hashCode());
+    result = prime * result + ((term == null) ? 0 : term.hashCode());
+    return result;
+  }
+
+  @Override
+  public boolean equals(Object obj) {
+    if (this == obj) {
+      return true;
+    }
+    if (!super.equals(obj)) {
+      return false;
+    }
+    if (getClass() != obj.getClass()) {
+      return false;
+    }
+
+    RegexQuery other = (RegexQuery) obj;
+    if (regexImpl == null) {
+      if (other.regexImpl != null) {
+        return false;
+      }
+    } else if (!regexImpl.equals(other.regexImpl)) {
+      return false;
+    }
+
+    if (term == null) {
+      if (other.term != null) {
+        return false;
+      }
+    } else if (!term.equals(other.term)) {
+      return false;
+    }
+    
+    return true;
+  }
+}
diff --git a/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/regex/RegexQueryCapable.java b/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/regex/RegexQueryCapable.java
new file mode 100644
index 0000000..efb2ddc
--- /dev/null
+++ b/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/regex/RegexQueryCapable.java
@@ -0,0 +1,28 @@
+package org.apache.lucene.sandbox.queries.regex;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+
+/**
+ * Defines methods for regular expression supporting Querys to use.
+ */
+public interface RegexQueryCapable {
+  
+  void setRegexImplementation(RegexCapabilities impl);
+  RegexCapabilities getRegexImplementation();
+}
diff --git a/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/regex/RegexTermsEnum.java b/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/regex/RegexTermsEnum.java
new file mode 100644
index 0000000..e67f94d
--- /dev/null
+++ b/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/regex/RegexTermsEnum.java
@@ -0,0 +1,64 @@
+package org.apache.lucene.sandbox.queries.regex;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.search.FilteredTermsEnum;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.index.TermsEnum;
+import org.apache.lucene.util.BytesRef;
+
+import java.io.IOException;
+
+/**
+ * Subclass of FilteredTermEnum for enumerating all terms that match the
+ * specified regular expression term using the specified regular expression
+ * implementation.
+ * <p>
+ * Term enumerations are always ordered by Term.compareTo().  Each term in
+ * the enumeration is greater than all that precede it.
+ */
+
+public class RegexTermsEnum extends FilteredTermsEnum {
+
+  private RegexCapabilities.RegexMatcher regexImpl;
+  private final BytesRef prefixRef;
+
+  public RegexTermsEnum(TermsEnum tenum, Term term, RegexCapabilities regexCap) throws IOException {
+    super(tenum);
+    String text = term.text();
+    this.regexImpl = regexCap.compile(text);
+
+    String pre = regexImpl.prefix();
+    if (pre == null) {
+      pre = "";
+    }
+
+    setInitialSeekTerm(prefixRef = new BytesRef(pre));
+  }
+
+  @Override
+  protected AcceptStatus accept(BytesRef term) {
+    if (term.startsWith(prefixRef)) {
+      // TODO: set BoostAttr based on distance of
+      // searchTerm.text() and term().text()
+      return regexImpl.match(term) ? AcceptStatus.YES : AcceptStatus.NO;
+    } else {
+      return AcceptStatus.NO;
+    }
+  }
+}
diff --git a/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/regex/package.html b/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/regex/package.html
new file mode 100644
index 0000000..7b54ddb
--- /dev/null
+++ b/lucene/contrib/sandbox/src/java/org/apache/lucene/sandbox/queries/regex/package.html
@@ -0,0 +1,22 @@
+<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+<html><head></head>
+<body>
+Regular expression Query.
+</body>
+</html>
diff --git a/lucene/contrib/sandbox/src/java/overview.html b/lucene/contrib/sandbox/src/java/overview.html
new file mode 100644
index 0000000..5b5aac2
--- /dev/null
+++ b/lucene/contrib/sandbox/src/java/overview.html
@@ -0,0 +1,26 @@
+<!--
+  Licensed to the Apache Software Foundation (ASF) under one or more
+  contributor license agreements.  See the NOTICE file distributed with
+  this work for additional information regarding copyright ownership.
+  The ASF licenses this file to You under the Apache License, Version 2.0
+  (the "License"); you may not use this file except in compliance with
+  the License.  You may obtain a copy of the License at
+
+      http://www.apache.org/licenses/LICENSE-2.0
+
+  Unless required by applicable law or agreed to in writing, software
+  distributed under the License is distributed on an "AS IS" BASIS,
+  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  See the License for the specific language governing permissions and
+  limitations under the License.
+  -->
+<html>
+  <head>
+    <title>
+      Sandbox
+    </title>
+  </head>
+  <body>
+  Sandbox
+  </body>
+</html>
diff --git a/lucene/contrib/sandbox/src/test/org/apache/lucene/sandbox/queries/DuplicateFilterTest.java b/lucene/contrib/sandbox/src/test/org/apache/lucene/sandbox/queries/DuplicateFilterTest.java
new file mode 100644
index 0000000..07a58fe
--- /dev/null
+++ b/lucene/contrib/sandbox/src/test/org/apache/lucene/sandbox/queries/DuplicateFilterTest.java
@@ -0,0 +1,169 @@
+package org.apache.lucene.sandbox.queries;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.MockAnalyzer;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.index.*;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.ScoreDoc;
+import org.apache.lucene.search.TermQuery;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.LuceneTestCase;
+
+import java.io.IOException;
+import java.util.HashSet;
+
+public class DuplicateFilterTest extends LuceneTestCase {
+  private static final String KEY_FIELD = "url";
+  private Directory directory;
+  private IndexReader reader;
+  TermQuery tq = new TermQuery(new Term("text", "lucene"));
+  private IndexSearcher searcher;
+
+  @Override
+  public void setUp() throws Exception {
+    super.setUp();
+    directory = newDirectory();
+    RandomIndexWriter writer = new RandomIndexWriter(random, directory, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));
+
+    //Add series of docs with filterable fields : url, text and dates  flags
+    addDoc(writer, "http://lucene.apache.org", "lucene 1.4.3 available", "20040101");
+    addDoc(writer, "http://lucene.apache.org", "New release pending", "20040102");
+    addDoc(writer, "http://lucene.apache.org", "Lucene 1.9 out now", "20050101");
+    addDoc(writer, "http://www.bar.com", "Local man bites dog", "20040101");
+    addDoc(writer, "http://www.bar.com", "Dog bites local man", "20040102");
+    addDoc(writer, "http://www.bar.com", "Dog uses Lucene", "20050101");
+    addDoc(writer, "http://lucene.apache.org", "Lucene 2.0 out", "20050101");
+    addDoc(writer, "http://lucene.apache.org", "Oops. Lucene 2.1 out", "20050102");
+
+    // Until we fix LUCENE-2348, the index must
+    // have only 1 segment:
+    writer.optimize();
+
+    reader = writer.getReader();
+    writer.close();
+    searcher = newSearcher(reader);
+
+  }
+
+  @Override
+  public void tearDown() throws Exception {
+    reader.close();
+    searcher.close();
+    directory.close();
+    super.tearDown();
+  }
+
+  private void addDoc(RandomIndexWriter writer, String url, String text, String date) throws IOException {
+    Document doc = new Document();
+    doc.add(newField(KEY_FIELD, url, Field.Store.YES, Field.Index.NOT_ANALYZED));
+    doc.add(newField("text", text, Field.Store.YES, Field.Index.ANALYZED));
+    doc.add(newField("date", date, Field.Store.YES, Field.Index.ANALYZED));
+    writer.addDocument(doc);
+  }
+
+  public void testDefaultFilter() throws Throwable {
+    DuplicateFilter df = new DuplicateFilter(KEY_FIELD);
+    HashSet<String> results = new HashSet<String>();
+    ScoreDoc[] hits = searcher.search(tq, df, 1000).scoreDocs;
+
+    for (ScoreDoc hit : hits) {
+      Document d = searcher.doc(hit.doc);
+      String url = d.get(KEY_FIELD);
+      assertFalse("No duplicate urls should be returned", results.contains(url));
+      results.add(url);
+    }
+  }
+
+  public void testNoFilter() throws Throwable {
+    HashSet<String> results = new HashSet<String>();
+    ScoreDoc[] hits = searcher.search(tq, null, 1000).scoreDocs;
+    assertTrue("Default searching should have found some matches", hits.length > 0);
+    boolean dupsFound = false;
+
+    for (ScoreDoc hit : hits) {
+      Document d = searcher.doc(hit.doc);
+      String url = d.get(KEY_FIELD);
+      if (!dupsFound)
+        dupsFound = results.contains(url);
+      results.add(url);
+    }
+    assertTrue("Default searching should have found duplicate urls", dupsFound);
+  }
+
+  public void testFastFilter() throws Throwable {
+    DuplicateFilter df = new DuplicateFilter(KEY_FIELD);
+    df.setProcessingMode(DuplicateFilter.ProcessingMode.PM_FAST_INVALIDATION);
+    HashSet<String> results = new HashSet<String>();
+    ScoreDoc[] hits = searcher.search(tq, df, 1000).scoreDocs;
+    assertTrue("Filtered searching should have found some matches", hits.length > 0);
+
+    for (ScoreDoc hit : hits) {
+      Document d = searcher.doc(hit.doc);
+      String url = d.get(KEY_FIELD);
+      assertFalse("No duplicate urls should be returned", results.contains(url));
+      results.add(url);
+    }
+    assertEquals("Two urls found", 2, results.size());
+  }
+
+  public void testKeepsLastFilter() throws Throwable {
+    DuplicateFilter df = new DuplicateFilter(KEY_FIELD);
+    df.setKeepMode(DuplicateFilter.KeepMode.KM_USE_LAST_OCCURRENCE);
+    ScoreDoc[] hits = searcher.search(tq, df, 1000).scoreDocs;
+    assertTrue("Filtered searching should have found some matches", hits.length > 0);
+    for (ScoreDoc hit : hits) {
+      Document d = searcher.doc(hit.doc);
+      String url = d.get(KEY_FIELD);
+      DocsEnum td = MultiFields.getTermDocsEnum(reader,
+          MultiFields.getLiveDocs(reader),
+          KEY_FIELD,
+          new BytesRef(url));
+      int lastDoc = 0;
+      while (td.nextDoc() != DocsEnum.NO_MORE_DOCS) {
+        lastDoc = td.docID();
+      }
+      assertEquals("Duplicate urls should return last doc", lastDoc, hit.doc);
+    }
+  }
+
+
+  public void testKeepsFirstFilter() throws Throwable {
+    DuplicateFilter df = new DuplicateFilter(KEY_FIELD);
+    df.setKeepMode(DuplicateFilter.KeepMode.KM_USE_FIRST_OCCURRENCE);
+    ScoreDoc[] hits = searcher.search(tq, df, 1000).scoreDocs;
+    assertTrue("Filtered searching should have found some matches", hits.length > 0);
+    for (ScoreDoc hit : hits) {
+      Document d = searcher.doc(hit.doc);
+      String url = d.get(KEY_FIELD);
+      DocsEnum td = MultiFields.getTermDocsEnum(reader,
+          MultiFields.getLiveDocs(reader),
+          KEY_FIELD,
+          new BytesRef(url));
+      int lastDoc = 0;
+      td.nextDoc();
+      lastDoc = td.docID();
+      assertEquals("Duplicate urls should return first doc", lastDoc, hit.doc);
+    }
+  }
+
+
+}
diff --git a/lucene/contrib/sandbox/src/test/org/apache/lucene/sandbox/queries/FuzzyLikeThisQueryTest.java b/lucene/contrib/sandbox/src/test/org/apache/lucene/sandbox/queries/FuzzyLikeThisQueryTest.java
new file mode 100644
index 0000000..6b6e578
--- /dev/null
+++ b/lucene/contrib/sandbox/src/test/org/apache/lucene/sandbox/queries/FuzzyLikeThisQueryTest.java
@@ -0,0 +1,134 @@
+package org.apache.lucene.sandbox.queries;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.MockAnalyzer;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.ScoreDoc;
+import org.apache.lucene.search.TopDocs;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.LuceneTestCase;
+
+import java.io.IOException;
+import java.util.HashSet;
+
+public class FuzzyLikeThisQueryTest extends LuceneTestCase {
+  private Directory directory;
+  private IndexSearcher searcher;
+  private IndexReader reader;
+  private Analyzer analyzer = new MockAnalyzer(random);
+
+  @Override
+  public void setUp() throws Exception {
+    super.setUp();
+    directory = newDirectory();
+    RandomIndexWriter writer = new RandomIndexWriter(random, directory, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));
+
+    //Add series of docs with misspelt names
+    addDoc(writer, "jonathon smythe", "1");
+    addDoc(writer, "jonathan smith", "2");
+    addDoc(writer, "johnathon smyth", "3");
+    addDoc(writer, "johnny smith", "4");
+    addDoc(writer, "jonny smith", "5");
+    addDoc(writer, "johnathon smythe", "6");
+    reader = writer.getReader();
+    writer.close();
+    searcher = newSearcher(reader);
+  }
+
+  @Override
+  public void tearDown() throws Exception {
+    searcher.close();
+    reader.close();
+    directory.close();
+    super.tearDown();
+  }
+
+  private void addDoc(RandomIndexWriter writer, String name, String id) throws IOException {
+    Document doc = new Document();
+    doc.add(newField("name", name, Field.Store.YES, Field.Index.ANALYZED));
+    doc.add(newField("id", id, Field.Store.YES, Field.Index.ANALYZED));
+    writer.addDocument(doc);
+  }
+
+
+  //Tests that idf ranking is not favouring rare mis-spellings over a strong edit-distance match
+  public void testClosestEditDistanceMatchComesFirst() throws Throwable {
+    FuzzyLikeThisQuery flt = new FuzzyLikeThisQuery(10, analyzer);
+    flt.addTerms("smith", "name", 0.3f, 1);
+    Query q = flt.rewrite(searcher.getIndexReader());
+    HashSet<Term> queryTerms = new HashSet<Term>();
+    q.extractTerms(queryTerms);
+    assertTrue("Should have variant smythe", queryTerms.contains(new Term("name", "smythe")));
+    assertTrue("Should have variant smith", queryTerms.contains(new Term("name", "smith")));
+    assertTrue("Should have variant smyth", queryTerms.contains(new Term("name", "smyth")));
+    TopDocs topDocs = searcher.search(flt, 1);
+    ScoreDoc[] sd = topDocs.scoreDocs;
+    assertTrue("score docs must match 1 doc", (sd != null) && (sd.length > 0));
+    Document doc = searcher.doc(sd[0].doc);
+    assertEquals("Should match most similar not most rare variant", "2", doc.get("id"));
+  }
+
+  //Test multiple input words are having variants produced
+  public void testMultiWord() throws Throwable {
+    FuzzyLikeThisQuery flt = new FuzzyLikeThisQuery(10, analyzer);
+    flt.addTerms("jonathin smoth", "name", 0.3f, 1);
+    Query q = flt.rewrite(searcher.getIndexReader());
+    HashSet<Term> queryTerms = new HashSet<Term>();
+    q.extractTerms(queryTerms);
+    assertTrue("Should have variant jonathan", queryTerms.contains(new Term("name", "jonathan")));
+    assertTrue("Should have variant smith", queryTerms.contains(new Term("name", "smith")));
+    TopDocs topDocs = searcher.search(flt, 1);
+    ScoreDoc[] sd = topDocs.scoreDocs;
+    assertTrue("score docs must match 1 doc", (sd != null) && (sd.length > 0));
+    Document doc = searcher.doc(sd[0].doc);
+    assertEquals("Should match most similar when using 2 words", "2", doc.get("id"));
+  }
+
+  //Test bug found when first query word does not match anything
+  public void testNoMatchFirstWordBug() throws Throwable {
+    FuzzyLikeThisQuery flt = new FuzzyLikeThisQuery(10, analyzer);
+    flt.addTerms("fernando smith", "name", 0.3f, 1);
+    Query q = flt.rewrite(searcher.getIndexReader());
+    HashSet<Term> queryTerms = new HashSet<Term>();
+    q.extractTerms(queryTerms);
+    assertTrue("Should have variant smith", queryTerms.contains(new Term("name", "smith")));
+    TopDocs topDocs = searcher.search(flt, 1);
+    ScoreDoc[] sd = topDocs.scoreDocs;
+    assertTrue("score docs must match 1 doc", (sd != null) && (sd.length > 0));
+    Document doc = searcher.doc(sd[0].doc);
+    assertEquals("Should match most similar when using 2 words", "2", doc.get("id"));
+  }
+
+  public void testFuzzyLikeThisQueryEquals() {
+    Analyzer analyzer = new MockAnalyzer(random);
+    FuzzyLikeThisQuery fltq1 = new FuzzyLikeThisQuery(10, analyzer);
+    fltq1.addTerms("javi", "subject", 0.5f, 2);
+    FuzzyLikeThisQuery fltq2 = new FuzzyLikeThisQuery(10, analyzer);
+    fltq2.addTerms("javi", "subject", 0.5f, 2);
+    assertEquals("FuzzyLikeThisQuery with same attributes is not equal", fltq1,
+        fltq2);
+  }
+}
diff --git a/lucene/contrib/sandbox/src/test/org/apache/lucene/sandbox/queries/TestSlowCollationMethods.java b/lucene/contrib/sandbox/src/test/org/apache/lucene/sandbox/queries/TestSlowCollationMethods.java
new file mode 100644
index 0000000..51c3d21
--- /dev/null
+++ b/lucene/contrib/sandbox/src/test/org/apache/lucene/sandbox/queries/TestSlowCollationMethods.java
@@ -0,0 +1,149 @@
+package org.apache.lucene.sandbox.queries;
+
+import java.io.IOException;
+import java.text.Collator;
+import java.util.Locale;
+
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.search.*;
+import org.apache.lucene.search.BooleanClause.Occur;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util._TestUtil;
+import org.junit.AfterClass;
+import org.junit.BeforeClass;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/**
+ * Tests SlowCollatedStringComparator, SlowCollatedTermRangeQuery, and SlowCollatedTermRangeFilter
+ */
+public class TestSlowCollationMethods extends LuceneTestCase {
+  private static Collator collator;
+  private static IndexSearcher searcher;
+  private static IndexReader reader;
+  private static Directory dir;
+  private static int numDocs;
+  private static String splitDoc;
+
+  @BeforeClass
+  public static void beforeClass() throws Exception {
+    final Locale locale = LuceneTestCase.randomLocale(random);
+    collator = Collator.getInstance(locale);
+    collator.setStrength(Collator.IDENTICAL);
+    collator.setDecomposition(Collator.NO_DECOMPOSITION);
+
+    numDocs = 1000 * RANDOM_MULTIPLIER;
+    dir = newDirectory();
+    RandomIndexWriter iw = new RandomIndexWriter(random, dir);
+    for (int i = 0; i < numDocs; i++) {
+      Document doc = new Document();
+      String value = _TestUtil.randomUnicodeString(random);
+      Field field = newField("field", value, Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);
+      doc.add(field);
+      iw.addDocument(doc);
+    }
+    splitDoc = _TestUtil.randomUnicodeString(random);
+    reader = iw.getReader();
+    iw.close();
+
+    searcher = newSearcher(reader);
+  }
+  
+  @AfterClass
+  public static void afterClass() throws Exception {
+    searcher.close();
+    reader.close();
+    dir.close();
+    collator = null;
+    searcher = null;
+    reader = null;
+    dir = null;
+  }
+  
+  private void doCheckSorting(TopDocs docs) throws Exception {
+    String prev = "";
+    for (ScoreDoc doc : docs.scoreDocs) {
+      String value = reader.document(doc.doc).get("field");
+      assertTrue(collator.compare(value, prev) >= 0);
+      prev = value;
+    }
+  }
+  
+  public void testSort() throws Exception {
+    SortField sf = new SortField("field", new FieldComparatorSource() {
+      @Override
+      public FieldComparator newComparator(String fieldname, int numHits, int sortPos, boolean reversed) throws IOException {
+        return new SlowCollatedStringComparator(numHits, fieldname, collator);
+      }
+    });
+    final Sort sort = new Sort(sf);
+    
+    final TopDocs docs1 = searcher.search(TermRangeQuery.newStringRange("field", null, splitDoc, true, true), null, numDocs/(1+random.nextInt(4)), sort);
+    doCheckSorting(docs1);
+    
+    final TopDocs docs2 = searcher.search(TermRangeQuery.newStringRange("field", splitDoc, null, true, true), null, numDocs/(1+random.nextInt(4)), sort);
+    doCheckSorting(docs2);
+    
+    final TopDocs docs = TopDocs.merge(sort, numDocs/(1+random.nextInt(4)), new TopDocs[]{docs1, docs2});
+    doCheckSorting(docs);
+  }
+  
+  private void doTestRanges(String startPoint, String endPoint, Query query) throws Exception {
+    // positive test
+    TopDocs docs = searcher.search(query, numDocs);
+    for (ScoreDoc doc : docs.scoreDocs) {
+      String value = reader.document(doc.doc).get("field");
+      assertTrue(collator.compare(value, startPoint) >= 0);
+      assertTrue(collator.compare(value, endPoint) <= 0);
+    }
+    
+    // negative test
+    BooleanQuery bq = new BooleanQuery();
+    bq.add(new MatchAllDocsQuery(), Occur.SHOULD);
+    bq.add(query, Occur.MUST_NOT);
+    docs = searcher.search(bq, numDocs);
+    for (ScoreDoc doc : docs.scoreDocs) {
+      String value = reader.document(doc.doc).get("field");
+      assertTrue(collator.compare(value, startPoint) < 0 || collator.compare(value, endPoint) > 0);
+    }
+  }
+  
+  public void testRangeQuery() throws Exception {
+    int numQueries = 50*RANDOM_MULTIPLIER;
+    for (int i = 0; i < numQueries; i++) {
+      String startPoint = _TestUtil.randomUnicodeString(random);
+      String endPoint = _TestUtil.randomUnicodeString(random);
+      Query query = new SlowCollatedTermRangeQuery("field", startPoint, endPoint, true, true, collator);
+      doTestRanges(startPoint, endPoint, query);
+    }
+  }
+  
+  public void testRangeFilter() throws Exception {
+    int numQueries = 50*RANDOM_MULTIPLIER;
+    for (int i = 0; i < numQueries; i++) {
+      String startPoint = _TestUtil.randomUnicodeString(random);
+      String endPoint = _TestUtil.randomUnicodeString(random);
+      Query query = new ConstantScoreQuery(new SlowCollatedTermRangeFilter("field", startPoint, endPoint, true, true, collator));
+      doTestRanges(startPoint, endPoint, query);
+    }
+  }
+}
diff --git a/lucene/contrib/sandbox/src/test/org/apache/lucene/sandbox/queries/regex/TestJakartaRegexpCapabilities.java b/lucene/contrib/sandbox/src/test/org/apache/lucene/sandbox/queries/regex/TestJakartaRegexpCapabilities.java
new file mode 100644
index 0000000..0d40c73
--- /dev/null
+++ b/lucene/contrib/sandbox/src/test/org/apache/lucene/sandbox/queries/regex/TestJakartaRegexpCapabilities.java
@@ -0,0 +1,47 @@
+package org.apache.lucene.sandbox.queries.regex;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.LuceneTestCase;
+
+/**
+ * Testcase for {@link JakartaRegexpCapabilities}
+ */
+public class TestJakartaRegexpCapabilities extends LuceneTestCase {
+
+  public void testGetPrefix(){
+    JakartaRegexpCapabilities cap = new JakartaRegexpCapabilities();
+    RegexCapabilities.RegexMatcher matcher = cap.compile("luc[e]?");
+    assertTrue(matcher.match(new BytesRef("luce")));
+    assertEquals("luc", matcher.prefix());
+    
+    matcher = cap.compile("lucene");
+    assertTrue(matcher.match(new BytesRef("lucene")));
+    assertEquals("lucene", matcher.prefix());
+  }
+  
+  public void testShakyPrefix(){
+    JakartaRegexpCapabilities cap = new JakartaRegexpCapabilities();
+    RegexCapabilities.RegexMatcher matcher = cap.compile("(ab|ac)");
+    assertTrue(matcher.match(new BytesRef("ab")));
+    assertTrue(matcher.match(new BytesRef("ac")));
+    // why is it not a???
+    assertNull(matcher.prefix());
+  }
+}
diff --git a/lucene/contrib/sandbox/src/test/org/apache/lucene/sandbox/queries/regex/TestRegexQuery.java b/lucene/contrib/sandbox/src/test/org/apache/lucene/sandbox/queries/regex/TestRegexQuery.java
new file mode 100644
index 0000000..7b25e04
--- /dev/null
+++ b/lucene/contrib/sandbox/src/test/org/apache/lucene/sandbox/queries/regex/TestRegexQuery.java
@@ -0,0 +1,136 @@
+package org.apache.lucene.sandbox.queries.regex;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.search.spans.SpanMultiTermQueryWrapper;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.MultiFields;
+import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.index.Terms;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.index.TermsEnum;
+
+import org.apache.lucene.search.spans.SpanNearQuery;
+import org.apache.lucene.search.spans.SpanQuery;
+import org.apache.lucene.util.AttributeSource;
+import org.apache.lucene.util.LuceneTestCase;
+
+public class TestRegexQuery extends LuceneTestCase {
+  private IndexSearcher searcher;
+  private IndexReader reader;
+  private Directory directory;
+  private final String FN = "field";
+
+
+  @Override
+  public void setUp() throws Exception {
+    super.setUp();
+    directory = newDirectory();
+    RandomIndexWriter writer = new RandomIndexWriter(random, directory);
+    Document doc = new Document();
+    doc.add(newField(FN, "the quick brown fox jumps over the lazy dog", Field.Store.NO, Field.Index.ANALYZED));
+    writer.addDocument(doc);
+    reader = writer.getReader();
+    writer.close();
+    searcher = newSearcher(reader);
+  }
+
+  @Override
+  public void tearDown() throws Exception {
+    searcher.close();
+    reader.close();
+    directory.close();
+    super.tearDown();
+  }
+
+  private Term newTerm(String value) { return new Term(FN, value); }
+
+  private int  regexQueryNrHits(String regex, RegexCapabilities capability) throws Exception {
+    RegexQuery query = new RegexQuery( newTerm(regex));
+    
+    if ( capability != null )
+      query.setRegexImplementation(capability);
+    
+    return searcher.search(query, null, 1000).totalHits;
+  }
+
+  private int  spanRegexQueryNrHits(String regex1, String regex2, int slop, boolean ordered) throws Exception {
+    SpanQuery srq1 = new SpanMultiTermQueryWrapper<RegexQuery>(new RegexQuery(newTerm(regex1)));
+    SpanQuery srq2 = new SpanMultiTermQueryWrapper<RegexQuery>(new RegexQuery(newTerm(regex2)));
+    SpanNearQuery query = new SpanNearQuery( new SpanQuery[]{srq1, srq2}, slop, ordered);
+
+    return searcher.search(query, null, 1000).totalHits;
+  }
+
+  public void testMatchAll() throws Exception {
+    Terms terms = MultiFields.getTerms(searcher.getIndexReader(), FN);
+    TermsEnum te = new RegexQuery(new Term(FN, "jum.")).getTermsEnum(terms, new AttributeSource() /*dummy*/);
+    // no term should match
+    assertNull(te.next());
+  }
+
+  public void testRegex1() throws Exception {
+    assertEquals(1, regexQueryNrHits("^q.[aeiou]c.*$", null));
+  }
+
+  public void testRegex2() throws Exception {
+    assertEquals(0, regexQueryNrHits("^.[aeiou]c.*$", null));
+  }
+
+  public void testRegex3() throws Exception {
+    assertEquals(0, regexQueryNrHits("^q.[aeiou]c$", null));
+  }
+
+  public void testSpanRegex1() throws Exception {
+    assertEquals(1, spanRegexQueryNrHits("^q.[aeiou]c.*$", "dog", 6, true));
+  }
+
+  public void testSpanRegex2() throws Exception {
+    assertEquals(0, spanRegexQueryNrHits("^q.[aeiou]c.*$", "dog", 5, true));
+  }
+
+  public void testEquals() throws Exception {
+    RegexQuery query1 = new RegexQuery( newTerm("foo.*"));
+    query1.setRegexImplementation(new JakartaRegexpCapabilities());
+
+    RegexQuery query2 = new RegexQuery( newTerm("foo.*"));
+    assertFalse(query1.equals(query2));
+  }
+  
+  public void testJakartaCaseSensativeFail() throws Exception {
+    assertEquals(0, regexQueryNrHits("^.*DOG.*$", null));
+  }
+
+  public void testJavaUtilCaseSensativeFail() throws Exception {
+    assertEquals(0, regexQueryNrHits("^.*DOG.*$", null));
+  }
+  
+  public void testJakartaCaseInsensative() throws Exception {
+    assertEquals(1, regexQueryNrHits("^.*DOG.*$", new JakartaRegexpCapabilities(JakartaRegexpCapabilities.FLAG_MATCH_CASEINDEPENDENT)));
+  }
+  
+  public void testJavaUtilCaseInsensative() throws Exception {
+    assertEquals(1, regexQueryNrHits("^.*DOG.*$", new JavaUtilRegexCapabilities(JavaUtilRegexCapabilities.FLAG_CASE_INSENSITIVE)));
+  }
+
+}
+
diff --git a/lucene/contrib/sandbox/src/test/org/apache/lucene/sandbox/queries/regex/TestSpanRegexQuery.java b/lucene/contrib/sandbox/src/test/org/apache/lucene/sandbox/queries/regex/TestSpanRegexQuery.java
new file mode 100644
index 0000000..85a7116
--- /dev/null
+++ b/lucene/contrib/sandbox/src/test/org/apache/lucene/sandbox/queries/regex/TestSpanRegexQuery.java
@@ -0,0 +1,112 @@
+package org.apache.lucene.sandbox.queries.regex;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.analysis.MockAnalyzer;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.index.CorruptIndexException;
+import org.apache.lucene.index.IndexWriter;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.index.IndexWriterConfig.OpenMode;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.spans.SpanFirstQuery;
+import org.apache.lucene.search.spans.SpanMultiTermQueryWrapper;
+import org.apache.lucene.search.spans.SpanQuery;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.store.LockObtainFailedException;
+import org.apache.lucene.util.LuceneTestCase;
+
+public class TestSpanRegexQuery extends LuceneTestCase {
+  
+  Directory indexStoreA;
+  Directory indexStoreB;
+  
+  @Override
+  public void setUp() throws Exception {
+    super.setUp();
+    indexStoreA = newDirectory();
+    indexStoreB = newDirectory();
+  }
+  
+  @Override
+  public void tearDown() throws Exception {
+    indexStoreA.close();
+    indexStoreB.close();
+    super.tearDown();
+  }
+  
+  public void testSpanRegex() throws Exception {
+    Directory directory = newDirectory();
+    IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig(
+        TEST_VERSION_CURRENT, new MockAnalyzer(random)));
+    Document doc = new Document();
+    // doc.add(newField("field", "the quick brown fox jumps over the lazy dog",
+    // Field.Store.NO, Field.Index.ANALYZED));
+    // writer.addDocument(doc);
+    // doc = new Document();
+    doc.add(newField("field", "auto update", Field.Store.NO,
+        Field.Index.ANALYZED));
+    writer.addDocument(doc);
+    doc = new Document();
+    doc.add(newField("field", "first auto update", Field.Store.NO,
+        Field.Index.ANALYZED));
+    writer.addDocument(doc);
+    writer.optimize();
+    writer.close();
+
+    IndexSearcher searcher = new IndexSearcher(directory, true);
+    SpanQuery srq = new SpanMultiTermQueryWrapper<RegexQuery>(new RegexQuery(new Term("field", "aut.*")));
+    SpanFirstQuery sfq = new SpanFirstQuery(srq, 1);
+    // SpanNearQuery query = new SpanNearQuery(new SpanQuery[] {srq, stq}, 6,
+    // true);
+    int numHits = searcher.search(sfq, null, 1000).totalHits;
+    assertEquals(1, numHits);
+    searcher.close();
+    directory.close();
+  }
+  
+  private void createRAMDirectories() throws CorruptIndexException,
+      LockObtainFailedException, IOException {
+    // creating a document to store
+    Document lDoc = new Document();
+    lDoc.add(newField("field", "a1 b1", Field.Store.NO,
+        Field.Index.ANALYZED_NO_NORMS));
+
+    // creating a document to store
+    Document lDoc2 = new Document();
+    lDoc2.add(newField("field", "a2 b2", Field.Store.NO,
+        Field.Index.ANALYZED_NO_NORMS));
+
+    // creating first index writer
+    IndexWriter writerA = new IndexWriter(indexStoreA, newIndexWriterConfig(
+        TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE));
+    writerA.addDocument(lDoc);
+    writerA.optimize();
+    writerA.close();
+
+    // creating second index writer
+    IndexWriter writerB = new IndexWriter(indexStoreB, newIndexWriterConfig(
+        TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE));
+    writerB.addDocument(lDoc2);
+    writerB.optimize();
+    writerB.close();
+  }
+}
diff --git a/lucene/contrib/spatial/build.xml b/lucene/contrib/spatial/build.xml
index 466146d..37ca1fa 100644
--- a/lucene/contrib/spatial/build.xml
+++ b/lucene/contrib/spatial/build.xml
@@ -26,10 +26,9 @@
   <import file="../contrib-build.xml"/>
 
   <path id="classpath">
-    <pathelement path="${queries-contrib.jar}"/>
     <pathelement path="${queries.jar}"/>
     <path refid="base.classpath"/>
   </path>
 
-  <target name="compile-core" depends="jar-queries-contrib, jar-queries, common.compile-core" />
+  <target name="compile-core" depends="jar-queries, common.compile-core" />
 </project>
diff --git a/lucene/contrib/xml-query-parser/build.xml b/lucene/contrib/xml-query-parser/build.xml
index c1bea22..ccd67db 100644
--- a/lucene/contrib/xml-query-parser/build.xml
+++ b/lucene/contrib/xml-query-parser/build.xml
@@ -26,11 +26,11 @@
   <import file="../contrib-build.xml"/>
 
   <path id="classpath">
-    <pathelement path="${queries-contrib.jar}"/>
     <pathelement path="${queryparser.jar}"/>
     <pathelement path="${queries.jar}"/>
+    <pathelement path="${sandbox.jar}"/>
     <path refid="base.classpath"/>
   </path>
 
-  <target name="compile-core" depends="jar-queries-contrib,jar-queryparser,jar-queries,common.compile-core" />
+  <target name="compile-core" depends="jar-sandbox,jar-queryparser,jar-queries,common.compile-core" />
 </project>
diff --git a/lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/DuplicateFilterBuilder.java b/lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/DuplicateFilterBuilder.java
index e244235..1892682 100644
--- a/lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/DuplicateFilterBuilder.java
+++ b/lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/DuplicateFilterBuilder.java
@@ -3,7 +3,7 @@
  */
 package org.apache.lucene.xmlparser.builders;
 
-import org.apache.lucene.queries.DuplicateFilter;
+import org.apache.lucene.sandbox.queries.DuplicateFilter;
 import org.apache.lucene.search.Filter;
 import org.apache.lucene.xmlparser.DOMUtils;
 import org.apache.lucene.xmlparser.FilterBuilder;
diff --git a/lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/FuzzyLikeThisQueryBuilder.java b/lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/FuzzyLikeThisQueryBuilder.java
index 027893e..775b730 100644
--- a/lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/FuzzyLikeThisQueryBuilder.java
+++ b/lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/FuzzyLikeThisQueryBuilder.java
@@ -1,7 +1,7 @@
 package org.apache.lucene.xmlparser.builders;
 
 import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.search.FuzzyLikeThisQuery;
+import org.apache.lucene.sandbox.queries.FuzzyLikeThisQuery;
 import org.apache.lucene.search.FuzzyQuery;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.xmlparser.DOMUtils;
diff --git a/modules/queries/src/java/org/apache/lucene/queries/DuplicateFilter.java b/modules/queries/src/java/org/apache/lucene/queries/DuplicateFilter.java
deleted file mode 100644
index 33305ef..0000000
--- a/modules/queries/src/java/org/apache/lucene/queries/DuplicateFilter.java
+++ /dev/null
@@ -1,214 +0,0 @@
-package org.apache.lucene.queries;
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.index.*;
-import org.apache.lucene.index.IndexReader.AtomicReaderContext;
-import org.apache.lucene.search.DocIdSet;
-import org.apache.lucene.search.Filter;
-import org.apache.lucene.util.Bits;
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.FixedBitSet;
-
-import java.io.IOException;
-
-public class DuplicateFilter extends Filter {
-  // TODO: make duplicate filter aware of ReaderContext such that we can
-  // filter duplicates across segments
-
-  /**
-   * KeepMode determines which document id to consider as the master, all others being
-   * identified as duplicates. Selecting the "first occurrence" can potentially save on IO.
-   */
-  public enum KeepMode {
-    KM_USE_FIRST_OCCURRENCE, KM_USE_LAST_OCCURRENCE
-  }
-
-  private KeepMode keepMode;
-
-  /**
-   * "Full" processing mode starts by setting all bits to false and only setting bits
-   * for documents that contain the given field and are identified as none-duplicates.
-   * <p/>
-   * "Fast" processing sets all bits to true then unsets all duplicate docs found for the
-   * given field. This approach avoids the need to read TermDocs for terms that are seen
-   * to have a document frequency of exactly "1" (i.e. no duplicates). While a potentially
-   * faster approach , the downside is that bitsets produced will include bits set for
-   * documents that do not actually contain the field given.
-   */
-
-  public enum ProcessingMode {
-    PM_FULL_VALIDATION, PM_FAST_INVALIDATION
-  }
-
-  private ProcessingMode processingMode;
-
-  private String fieldName;
-
-  public DuplicateFilter(String fieldName) {
-    this(fieldName, KeepMode.KM_USE_LAST_OCCURRENCE, ProcessingMode.PM_FULL_VALIDATION);
-  }
-
-  public DuplicateFilter(String fieldName, KeepMode keepMode, ProcessingMode processingMode) {
-    this.fieldName = fieldName;
-    this.keepMode = keepMode;
-    this.processingMode = processingMode;
-  }
-
-  @Override
-  public DocIdSet getDocIdSet(AtomicReaderContext context) throws IOException {
-    if (processingMode == ProcessingMode.PM_FAST_INVALIDATION) {
-      return fastBits(context.reader);
-    } else {
-      return correctBits(context.reader);
-    }
-  }
-
-  private FixedBitSet correctBits(IndexReader reader) throws IOException {
-    FixedBitSet bits = new FixedBitSet(reader.maxDoc()); //assume all are INvalid
-    final Bits liveDocs = MultiFields.getLiveDocs(reader);
-    Terms terms = reader.fields().terms(fieldName);
-
-    if (terms == null) {
-      return bits;
-    }
-
-    TermsEnum termsEnum = terms.iterator();
-    DocsEnum docs = null;
-    while (true) {
-      BytesRef currTerm = termsEnum.next();
-      if (currTerm == null) {
-        break;
-      } else {
-        docs = termsEnum.docs(liveDocs, docs);
-        int doc = docs.nextDoc();
-        if (doc != DocsEnum.NO_MORE_DOCS) {
-          if (keepMode == KeepMode.KM_USE_FIRST_OCCURRENCE) {
-            bits.set(doc);
-          } else {
-            int lastDoc = doc;
-            while (true) {
-              lastDoc = doc;
-              doc = docs.nextDoc();
-              if (doc == DocsEnum.NO_MORE_DOCS) {
-                break;
-              }
-            }
-            bits.set(lastDoc);
-          }
-        }
-      }
-    }
-    return bits;
-  }
-
-  private FixedBitSet fastBits(IndexReader reader) throws IOException {
-    FixedBitSet bits = new FixedBitSet(reader.maxDoc());
-    bits.set(0, reader.maxDoc()); //assume all are valid
-    final Bits liveDocs = MultiFields.getLiveDocs(reader);
-    Terms terms = reader.fields().terms(fieldName);
-
-    if (terms == null) {
-      return bits;
-    }
-
-    TermsEnum termsEnum = terms.iterator();
-    DocsEnum docs = null;
-    while (true) {
-      BytesRef currTerm = termsEnum.next();
-      if (currTerm == null) {
-        break;
-      } else {
-        if (termsEnum.docFreq() > 1) {
-          // unset potential duplicates
-          docs = termsEnum.docs(liveDocs, docs);
-          int doc = docs.nextDoc();
-          if (doc != DocsEnum.NO_MORE_DOCS) {
-            if (keepMode == KeepMode.KM_USE_FIRST_OCCURRENCE) {
-              doc = docs.nextDoc();
-            }
-          }
-
-          int lastDoc = -1;
-          while (true) {
-            lastDoc = doc;
-            bits.clear(lastDoc);
-            doc = docs.nextDoc();
-            if (doc == DocsEnum.NO_MORE_DOCS) {
-              break;
-            }
-          }
-
-          if (keepMode == KeepMode.KM_USE_LAST_OCCURRENCE) {
-            // restore the last bit
-            bits.set(lastDoc);
-          }
-        }
-      }
-    }
-
-    return bits;
-  }
-
-  public String getFieldName() {
-    return fieldName;
-  }
-
-  public void setFieldName(String fieldName) {
-    this.fieldName = fieldName;
-  }
-
-  public KeepMode getKeepMode() {
-    return keepMode;
-  }
-
-  public void setKeepMode(KeepMode keepMode) {
-    this.keepMode = keepMode;
-  }
-
-  @Override
-  public boolean equals(Object obj) {
-    if (this == obj) {
-      return true;
-    }
-    if ((obj == null) || (obj.getClass() != this.getClass())) {
-      return false;
-    }
-
-    DuplicateFilter other = (DuplicateFilter) obj;
-    return keepMode == other.keepMode &&
-        processingMode == other.processingMode &&
-        fieldName != null && fieldName.equals(other.fieldName);
-  }
-
-  @Override
-  public int hashCode() {
-    int hash = 217;
-    hash = 31 * hash + keepMode.hashCode();
-    hash = 31 * hash + processingMode.hashCode();
-    hash = 31 * hash + fieldName.hashCode();
-    return hash;
-  }
-
-  public ProcessingMode getProcessingMode() {
-    return processingMode;
-  }
-
-  public void setProcessingMode(ProcessingMode processingMode) {
-    this.processingMode = processingMode;
-  }
-}
diff --git a/modules/queries/src/test/org/apache/lucene/queries/DuplicateFilterTest.java b/modules/queries/src/test/org/apache/lucene/queries/DuplicateFilterTest.java
deleted file mode 100644
index 5e31593..0000000
--- a/modules/queries/src/test/org/apache/lucene/queries/DuplicateFilterTest.java
+++ /dev/null
@@ -1,169 +0,0 @@
-package org.apache.lucene.queries;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.MockAnalyzer;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.index.*;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.ScoreDoc;
-import org.apache.lucene.search.TermQuery;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.LuceneTestCase;
-
-import java.io.IOException;
-import java.util.HashSet;
-
-public class DuplicateFilterTest extends LuceneTestCase {
-  private static final String KEY_FIELD = "url";
-  private Directory directory;
-  private IndexReader reader;
-  TermQuery tq = new TermQuery(new Term("text", "lucene"));
-  private IndexSearcher searcher;
-
-  @Override
-  public void setUp() throws Exception {
-    super.setUp();
-    directory = newDirectory();
-    RandomIndexWriter writer = new RandomIndexWriter(random, directory, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));
-
-    //Add series of docs with filterable fields : url, text and dates  flags
-    addDoc(writer, "http://lucene.apache.org", "lucene 1.4.3 available", "20040101");
-    addDoc(writer, "http://lucene.apache.org", "New release pending", "20040102");
-    addDoc(writer, "http://lucene.apache.org", "Lucene 1.9 out now", "20050101");
-    addDoc(writer, "http://www.bar.com", "Local man bites dog", "20040101");
-    addDoc(writer, "http://www.bar.com", "Dog bites local man", "20040102");
-    addDoc(writer, "http://www.bar.com", "Dog uses Lucene", "20050101");
-    addDoc(writer, "http://lucene.apache.org", "Lucene 2.0 out", "20050101");
-    addDoc(writer, "http://lucene.apache.org", "Oops. Lucene 2.1 out", "20050102");
-
-    // Until we fix LUCENE-2348, the index must
-    // have only 1 segment:
-    writer.optimize();
-
-    reader = writer.getReader();
-    writer.close();
-    searcher = newSearcher(reader);
-
-  }
-
-  @Override
-  public void tearDown() throws Exception {
-    reader.close();
-    searcher.close();
-    directory.close();
-    super.tearDown();
-  }
-
-  private void addDoc(RandomIndexWriter writer, String url, String text, String date) throws IOException {
-    Document doc = new Document();
-    doc.add(newField(KEY_FIELD, url, Field.Store.YES, Field.Index.NOT_ANALYZED));
-    doc.add(newField("text", text, Field.Store.YES, Field.Index.ANALYZED));
-    doc.add(newField("date", date, Field.Store.YES, Field.Index.ANALYZED));
-    writer.addDocument(doc);
-  }
-
-  public void testDefaultFilter() throws Throwable {
-    DuplicateFilter df = new DuplicateFilter(KEY_FIELD);
-    HashSet<String> results = new HashSet<String>();
-    ScoreDoc[] hits = searcher.search(tq, df, 1000).scoreDocs;
-
-    for (ScoreDoc hit : hits) {
-      Document d = searcher.doc(hit.doc);
-      String url = d.get(KEY_FIELD);
-      assertFalse("No duplicate urls should be returned", results.contains(url));
-      results.add(url);
-    }
-  }
-
-  public void testNoFilter() throws Throwable {
-    HashSet<String> results = new HashSet<String>();
-    ScoreDoc[] hits = searcher.search(tq, null, 1000).scoreDocs;
-    assertTrue("Default searching should have found some matches", hits.length > 0);
-    boolean dupsFound = false;
-
-    for (ScoreDoc hit : hits) {
-      Document d = searcher.doc(hit.doc);
-      String url = d.get(KEY_FIELD);
-      if (!dupsFound)
-        dupsFound = results.contains(url);
-      results.add(url);
-    }
-    assertTrue("Default searching should have found duplicate urls", dupsFound);
-  }
-
-  public void testFastFilter() throws Throwable {
-    DuplicateFilter df = new DuplicateFilter(KEY_FIELD);
-    df.setProcessingMode(DuplicateFilter.ProcessingMode.PM_FAST_INVALIDATION);
-    HashSet<String> results = new HashSet<String>();
-    ScoreDoc[] hits = searcher.search(tq, df, 1000).scoreDocs;
-    assertTrue("Filtered searching should have found some matches", hits.length > 0);
-
-    for (ScoreDoc hit : hits) {
-      Document d = searcher.doc(hit.doc);
-      String url = d.get(KEY_FIELD);
-      assertFalse("No duplicate urls should be returned", results.contains(url));
-      results.add(url);
-    }
-    assertEquals("Two urls found", 2, results.size());
-  }
-
-  public void testKeepsLastFilter() throws Throwable {
-    DuplicateFilter df = new DuplicateFilter(KEY_FIELD);
-    df.setKeepMode(DuplicateFilter.KeepMode.KM_USE_LAST_OCCURRENCE);
-    ScoreDoc[] hits = searcher.search(tq, df, 1000).scoreDocs;
-    assertTrue("Filtered searching should have found some matches", hits.length > 0);
-    for (ScoreDoc hit : hits) {
-      Document d = searcher.doc(hit.doc);
-      String url = d.get(KEY_FIELD);
-      DocsEnum td = MultiFields.getTermDocsEnum(reader,
-          MultiFields.getLiveDocs(reader),
-          KEY_FIELD,
-          new BytesRef(url));
-      int lastDoc = 0;
-      while (td.nextDoc() != DocsEnum.NO_MORE_DOCS) {
-        lastDoc = td.docID();
-      }
-      assertEquals("Duplicate urls should return last doc", lastDoc, hit.doc);
-    }
-  }
-
-
-  public void testKeepsFirstFilter() throws Throwable {
-    DuplicateFilter df = new DuplicateFilter(KEY_FIELD);
-    df.setKeepMode(DuplicateFilter.KeepMode.KM_USE_FIRST_OCCURRENCE);
-    ScoreDoc[] hits = searcher.search(tq, df, 1000).scoreDocs;
-    assertTrue("Filtered searching should have found some matches", hits.length > 0);
-    for (ScoreDoc hit : hits) {
-      Document d = searcher.doc(hit.doc);
-      String url = d.get(KEY_FIELD);
-      DocsEnum td = MultiFields.getTermDocsEnum(reader,
-          MultiFields.getLiveDocs(reader),
-          KEY_FIELD,
-          new BytesRef(url));
-      int lastDoc = 0;
-      td.nextDoc();
-      lastDoc = td.docID();
-      assertEquals("Duplicate urls should return first doc", lastDoc, hit.doc);
-    }
-  }
-
-
-}
diff --git a/solr/common-build.xml b/solr/common-build.xml
index 8023c87..59d0075 100644
--- a/solr/common-build.xml
+++ b/solr/common-build.xml
@@ -84,7 +84,6 @@
   	<pathelement path="${highlighter.jar}"/>
   	<pathelement path="${memory.jar}"/>
   	<pathelement path="${misc.jar}"/>
-  	<pathelement path="${queries-contrib.jar}"/>
   	<pathelement path="${spatial.jar}"/>
   	<pathelement path="${suggest.jar}"/>
     <pathelement path="${grouping.jar}"/>
@@ -171,7 +170,7 @@
 
   <target name="prep-lucene-jars" 
   	      depends="jar-lucene-core, jar-analyzers-phonetic, jar-suggest, jar-highlighter, jar-memory,
-  	               jar-misc, jar-queries-contrib, jar-spatial, jar-grouping, jar-queries, jar-queryparser">
+  	               jar-misc, jar-spatial, jar-grouping, jar-queries, jar-queryparser">
   	  <property name="solr.deps.compiled" value="true"/>
   </target>
 	
@@ -192,7 +191,6 @@
       <fileset file="${highlighter.jar}" />
       <fileset file="${memory.jar}" />
       <fileset file="${misc.jar}" />
-      <fileset file="${queries-contrib.jar}" />
       <fileset file="${spatial.jar}" />
     </copy>
     </sequential>

