GitDiffStart: 3e94d0292a3f58addfcca1e215303f5197bef357 | Sun Jan 5 18:02:21 2014 +0000
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/CachedOrdinalsReader.java b/lucene/facet/src/java/org/apache/lucene/facet/CachedOrdinalsReader.java
deleted file mode 100644
index 03c1da4..0000000
--- a/lucene/facet/src/java/org/apache/lucene/facet/CachedOrdinalsReader.java
+++ /dev/null
@@ -1,150 +0,0 @@
-package org.apache.lucene.facet;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.util.Map;
-import java.util.WeakHashMap;
-
-import org.apache.lucene.codecs.DocValuesFormat;
-import org.apache.lucene.index.AtomicReaderContext;
-import org.apache.lucene.index.BinaryDocValues;
-import org.apache.lucene.util.ArrayUtil;
-import org.apache.lucene.util.IntsRef;
-import org.apache.lucene.util.RamUsageEstimator;
-
-/**
- * A per-segment cache of documents' facet ordinals. Every
- * {@link CachedOrds} holds the ordinals in a raw {@code
- * int[]}, and therefore consumes as much RAM as the total
- * number of ordinals found in the segment, but saves the
- * CPU cost of decoding ordinals during facet counting.
- * 
- * <p>
- * <b>NOTE:</b> every {@link CachedOrds} is limited to 2.1B
- * total ordinals. If that is a limitation for you then
- * consider limiting the segment size to fewer documents, or
- * use an alternative cache which pages through the category
- * ordinals.
- * 
- * <p>
- * <b>NOTE:</b> when using this cache, it is advised to use
- * a {@link DocValuesFormat} that does not cache the data in
- * memory, at least for the category lists fields, or
- * otherwise you'll be doing double-caching.
- *
- * <p>
- * <b>NOTE:</b> create one instance of this and re-use it
- * for all facet implementations (the cache is per-instance,
- * not static).
- */
-public class CachedOrdinalsReader extends OrdinalsReader {
-
-  private final OrdinalsReader source;
-
-  private final Map<Object,CachedOrds> ordsCache = new WeakHashMap<Object,CachedOrds>();
-
-  /** Sole constructor. */
-  public CachedOrdinalsReader(OrdinalsReader source) {
-    this.source = source;
-  }
-
-  private synchronized CachedOrds getCachedOrds(AtomicReaderContext context) throws IOException {
-    Object cacheKey = context.reader().getCoreCacheKey();
-    CachedOrds ords = ordsCache.get(cacheKey);
-    if (ords == null) {
-      ords = new CachedOrds(source.getReader(context), context.reader().maxDoc());
-      ordsCache.put(cacheKey, ords);
-    }
-
-    return ords;
-  }
-
-  @Override
-  public String getIndexFieldName() {
-    return source.getIndexFieldName();
-  }
-
-  @Override
-  public OrdinalsSegmentReader getReader(AtomicReaderContext context) throws IOException {
-    final CachedOrds cachedOrds = getCachedOrds(context);
-    return new OrdinalsSegmentReader() {
-      @Override
-      public void get(int docID, IntsRef ordinals) {
-        ordinals.ints = cachedOrds.ordinals;
-        ordinals.offset = cachedOrds.offsets[docID];
-        ordinals.length = cachedOrds.offsets[docID+1] - ordinals.offset;
-      }
-    };
-  }
-
-  /** Holds the cached ordinals in two paralel {@code int[]} arrays. */
-  public static final class CachedOrds {
-
-    /** Index into {@link #ordinals} for each document. */
-    public final int[] offsets;
-
-    /** Holds ords for all docs. */
-    public final int[] ordinals;
-
-    /**
-     * Creates a new {@link CachedOrds} from the {@link BinaryDocValues}.
-     * Assumes that the {@link BinaryDocValues} is not {@code null}.
-     */
-    public CachedOrds(OrdinalsSegmentReader source, int maxDoc) throws IOException {
-      offsets = new int[maxDoc + 1];
-      int[] ords = new int[maxDoc]; // let's assume one ordinal per-document as an initial size
-
-      // this aggregator is limited to Integer.MAX_VALUE total ordinals.
-      long totOrds = 0;
-      final IntsRef values = new IntsRef(32);
-      for (int docID = 0; docID < maxDoc; docID++) {
-        offsets[docID] = (int) totOrds;
-        source.get(docID, values);
-        long nextLength = totOrds + values.length;
-        if (nextLength > ords.length) {
-          if (nextLength > ArrayUtil.MAX_ARRAY_LENGTH) {
-            throw new IllegalStateException("too many ordinals (>= " + nextLength + ") to cache");
-          }
-          ords = ArrayUtil.grow(ords, (int) nextLength);
-        }
-        System.arraycopy(values.ints, 0, ords, (int) totOrds, values.length);
-        totOrds = nextLength;
-      }
-      offsets[maxDoc] = (int) totOrds;
-      
-      // if ords array is bigger by more than 10% of what we really need, shrink it
-      if ((double) totOrds / ords.length < 0.9) { 
-        this.ordinals = new int[(int) totOrds];
-        System.arraycopy(ords, 0, this.ordinals, 0, (int) totOrds);
-      } else {
-        this.ordinals = ords;
-      }
-    }
-  }
-
-  /** How many bytes is this cache using? */
-  public synchronized long ramBytesUsed() {
-    long bytes = 0;
-    for(CachedOrds ords : ordsCache.values()) {
-      bytes += RamUsageEstimator.sizeOf(ords);
-    }
-
-    return bytes;
-  }
-}
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/DocValuesOrdinalsReader.java b/lucene/facet/src/java/org/apache/lucene/facet/DocValuesOrdinalsReader.java
deleted file mode 100644
index ab257ae..0000000
--- a/lucene/facet/src/java/org/apache/lucene/facet/DocValuesOrdinalsReader.java
+++ /dev/null
@@ -1,99 +0,0 @@
-package org.apache.lucene.facet;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-
-import org.apache.lucene.index.AtomicReaderContext;
-import org.apache.lucene.index.BinaryDocValues;
-import org.apache.lucene.util.ArrayUtil;
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.IntsRef;
-
-/** Decodes ordinals previously indexed into a BinaryDocValues field */
-
-public class DocValuesOrdinalsReader extends OrdinalsReader {
-  private final String field;
-
-  /** Default constructor. */
-  public DocValuesOrdinalsReader() {
-    this(FacetsConfig.DEFAULT_INDEX_FIELD_NAME);
-  }
-
-  /** Create this, with the specified indexed field name. */
-  public DocValuesOrdinalsReader(String field) {
-    this.field = field;
-  }
-
-  @Override
-  public OrdinalsSegmentReader getReader(AtomicReaderContext context) throws IOException {
-    BinaryDocValues values0 = context.reader().getBinaryDocValues(field);
-    if (values0 == null) {
-      values0 = BinaryDocValues.EMPTY;
-    }
-
-    final BinaryDocValues values = values0;
-
-    return new OrdinalsSegmentReader() {
-      private final BytesRef bytes = new BytesRef(32);
-
-      @Override
-      public void get(int docID, IntsRef ordinals) throws IOException {
-        values.get(docID, bytes);
-        decode(bytes, ordinals);
-      }
-    };
-  }
-
-  @Override
-  public String getIndexFieldName() {
-    return field;
-  }
-
-  /** Subclass & override if you change the encoding. */
-  protected void decode(BytesRef buf, IntsRef ordinals) {
-
-    // grow the buffer up front, even if by a large number of values (buf.length)
-    // that saves the need to check inside the loop for every decoded value if
-    // the buffer needs to grow.
-    if (ordinals.ints.length < buf.length) {
-      ordinals.ints = ArrayUtil.grow(ordinals.ints, buf.length);
-    }
-
-    ordinals.offset = 0;
-    ordinals.length = 0;
-
-    // it is better if the decoding is inlined like so, and not e.g.
-    // in a utility method
-    int upto = buf.offset + buf.length;
-    int value = 0;
-    int offset = buf.offset;
-    int prev = 0;
-    while (offset < upto) {
-      byte b = buf.bytes[offset++];
-      if (b >= 0) {
-        ordinals.ints[ordinals.length] = ((value << 7) | b) + prev;
-        value = 0;
-        prev = ordinals.ints[ordinals.length];
-        ordinals.length++;
-      } else {
-        value = (value << 7) | (b & 0x7F);
-      }
-    }
-  }
-}
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/OrdinalsReader.java b/lucene/facet/src/java/org/apache/lucene/facet/OrdinalsReader.java
deleted file mode 100644
index 8a3224e..0000000
--- a/lucene/facet/src/java/org/apache/lucene/facet/OrdinalsReader.java
+++ /dev/null
@@ -1,50 +0,0 @@
-package org.apache.lucene.facet;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-
-import org.apache.lucene.index.AtomicReaderContext;
-import org.apache.lucene.util.IntsRef;
-
-/** Provides per-document ordinals. */
-
-public abstract class OrdinalsReader {
-
-  /** Returns ordinals for documents in one segment. */
-  public static abstract class OrdinalsSegmentReader {
-    /** Get the ordinals for this document.  ordinals.offset
-     *  must always be 0! */
-    public abstract void get(int doc, IntsRef ordinals) throws IOException;
-
-    /** Default constructor. */
-    public OrdinalsSegmentReader() {
-    }
-  }
-
-  /** Default constructor. */
-  public OrdinalsReader() {
-  }
-
-  /** Set current atomic reader. */
-  public abstract OrdinalsSegmentReader getReader(AtomicReaderContext context) throws IOException;
-
-  /** Returns the indexed field name this {@code
-   *  OrdinalsReader} is reading from. */
-  public abstract String getIndexFieldName();
-}
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/CachedOrdinalsReader.java b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/CachedOrdinalsReader.java
new file mode 100644
index 0000000..0abb5b9
--- /dev/null
+++ b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/CachedOrdinalsReader.java
@@ -0,0 +1,150 @@
+package org.apache.lucene.facet.taxonomy;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.Map;
+import java.util.WeakHashMap;
+
+import org.apache.lucene.codecs.DocValuesFormat;
+import org.apache.lucene.index.AtomicReaderContext;
+import org.apache.lucene.index.BinaryDocValues;
+import org.apache.lucene.util.ArrayUtil;
+import org.apache.lucene.util.IntsRef;
+import org.apache.lucene.util.RamUsageEstimator;
+
+/**
+ * A per-segment cache of documents' facet ordinals. Every
+ * {@link CachedOrds} holds the ordinals in a raw {@code
+ * int[]}, and therefore consumes as much RAM as the total
+ * number of ordinals found in the segment, but saves the
+ * CPU cost of decoding ordinals during facet counting.
+ * 
+ * <p>
+ * <b>NOTE:</b> every {@link CachedOrds} is limited to 2.1B
+ * total ordinals. If that is a limitation for you then
+ * consider limiting the segment size to fewer documents, or
+ * use an alternative cache which pages through the category
+ * ordinals.
+ * 
+ * <p>
+ * <b>NOTE:</b> when using this cache, it is advised to use
+ * a {@link DocValuesFormat} that does not cache the data in
+ * memory, at least for the category lists fields, or
+ * otherwise you'll be doing double-caching.
+ *
+ * <p>
+ * <b>NOTE:</b> create one instance of this and re-use it
+ * for all facet implementations (the cache is per-instance,
+ * not static).
+ */
+public class CachedOrdinalsReader extends OrdinalsReader {
+
+  private final OrdinalsReader source;
+
+  private final Map<Object,CachedOrds> ordsCache = new WeakHashMap<Object,CachedOrds>();
+
+  /** Sole constructor. */
+  public CachedOrdinalsReader(OrdinalsReader source) {
+    this.source = source;
+  }
+
+  private synchronized CachedOrds getCachedOrds(AtomicReaderContext context) throws IOException {
+    Object cacheKey = context.reader().getCoreCacheKey();
+    CachedOrds ords = ordsCache.get(cacheKey);
+    if (ords == null) {
+      ords = new CachedOrds(source.getReader(context), context.reader().maxDoc());
+      ordsCache.put(cacheKey, ords);
+    }
+
+    return ords;
+  }
+
+  @Override
+  public String getIndexFieldName() {
+    return source.getIndexFieldName();
+  }
+
+  @Override
+  public OrdinalsSegmentReader getReader(AtomicReaderContext context) throws IOException {
+    final CachedOrds cachedOrds = getCachedOrds(context);
+    return new OrdinalsSegmentReader() {
+      @Override
+      public void get(int docID, IntsRef ordinals) {
+        ordinals.ints = cachedOrds.ordinals;
+        ordinals.offset = cachedOrds.offsets[docID];
+        ordinals.length = cachedOrds.offsets[docID+1] - ordinals.offset;
+      }
+    };
+  }
+
+  /** Holds the cached ordinals in two paralel {@code int[]} arrays. */
+  public static final class CachedOrds {
+
+    /** Index into {@link #ordinals} for each document. */
+    public final int[] offsets;
+
+    /** Holds ords for all docs. */
+    public final int[] ordinals;
+
+    /**
+     * Creates a new {@link CachedOrds} from the {@link BinaryDocValues}.
+     * Assumes that the {@link BinaryDocValues} is not {@code null}.
+     */
+    public CachedOrds(OrdinalsSegmentReader source, int maxDoc) throws IOException {
+      offsets = new int[maxDoc + 1];
+      int[] ords = new int[maxDoc]; // let's assume one ordinal per-document as an initial size
+
+      // this aggregator is limited to Integer.MAX_VALUE total ordinals.
+      long totOrds = 0;
+      final IntsRef values = new IntsRef(32);
+      for (int docID = 0; docID < maxDoc; docID++) {
+        offsets[docID] = (int) totOrds;
+        source.get(docID, values);
+        long nextLength = totOrds + values.length;
+        if (nextLength > ords.length) {
+          if (nextLength > ArrayUtil.MAX_ARRAY_LENGTH) {
+            throw new IllegalStateException("too many ordinals (>= " + nextLength + ") to cache");
+          }
+          ords = ArrayUtil.grow(ords, (int) nextLength);
+        }
+        System.arraycopy(values.ints, 0, ords, (int) totOrds, values.length);
+        totOrds = nextLength;
+      }
+      offsets[maxDoc] = (int) totOrds;
+      
+      // if ords array is bigger by more than 10% of what we really need, shrink it
+      if ((double) totOrds / ords.length < 0.9) { 
+        this.ordinals = new int[(int) totOrds];
+        System.arraycopy(ords, 0, this.ordinals, 0, (int) totOrds);
+      } else {
+        this.ordinals = ords;
+      }
+    }
+  }
+
+  /** How many bytes is this cache using? */
+  public synchronized long ramBytesUsed() {
+    long bytes = 0;
+    for(CachedOrds ords : ordsCache.values()) {
+      bytes += RamUsageEstimator.sizeOf(ords);
+    }
+
+    return bytes;
+  }
+}
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/DocValuesOrdinalsReader.java b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/DocValuesOrdinalsReader.java
new file mode 100644
index 0000000..df89ffa
--- /dev/null
+++ b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/DocValuesOrdinalsReader.java
@@ -0,0 +1,100 @@
+package org.apache.lucene.facet.taxonomy;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.facet.FacetsConfig;
+import org.apache.lucene.index.AtomicReaderContext;
+import org.apache.lucene.index.BinaryDocValues;
+import org.apache.lucene.util.ArrayUtil;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.IntsRef;
+
+/** Decodes ordinals previously indexed into a BinaryDocValues field */
+
+public class DocValuesOrdinalsReader extends OrdinalsReader {
+  private final String field;
+
+  /** Default constructor. */
+  public DocValuesOrdinalsReader() {
+    this(FacetsConfig.DEFAULT_INDEX_FIELD_NAME);
+  }
+
+  /** Create this, with the specified indexed field name. */
+  public DocValuesOrdinalsReader(String field) {
+    this.field = field;
+  }
+
+  @Override
+  public OrdinalsSegmentReader getReader(AtomicReaderContext context) throws IOException {
+    BinaryDocValues values0 = context.reader().getBinaryDocValues(field);
+    if (values0 == null) {
+      values0 = BinaryDocValues.EMPTY;
+    }
+
+    final BinaryDocValues values = values0;
+
+    return new OrdinalsSegmentReader() {
+      private final BytesRef bytes = new BytesRef(32);
+
+      @Override
+      public void get(int docID, IntsRef ordinals) throws IOException {
+        values.get(docID, bytes);
+        decode(bytes, ordinals);
+      }
+    };
+  }
+
+  @Override
+  public String getIndexFieldName() {
+    return field;
+  }
+
+  /** Subclass & override if you change the encoding. */
+  protected void decode(BytesRef buf, IntsRef ordinals) {
+
+    // grow the buffer up front, even if by a large number of values (buf.length)
+    // that saves the need to check inside the loop for every decoded value if
+    // the buffer needs to grow.
+    if (ordinals.ints.length < buf.length) {
+      ordinals.ints = ArrayUtil.grow(ordinals.ints, buf.length);
+    }
+
+    ordinals.offset = 0;
+    ordinals.length = 0;
+
+    // it is better if the decoding is inlined like so, and not e.g.
+    // in a utility method
+    int upto = buf.offset + buf.length;
+    int value = 0;
+    int offset = buf.offset;
+    int prev = 0;
+    while (offset < upto) {
+      byte b = buf.bytes[offset++];
+      if (b >= 0) {
+        ordinals.ints[ordinals.length] = ((value << 7) | b) + prev;
+        value = 0;
+        prev = ordinals.ints[ordinals.length];
+        ordinals.length++;
+      } else {
+        value = (value << 7) | (b & 0x7F);
+      }
+    }
+  }
+}
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/OrdinalsReader.java b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/OrdinalsReader.java
new file mode 100644
index 0000000..098008e
--- /dev/null
+++ b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/OrdinalsReader.java
@@ -0,0 +1,50 @@
+package org.apache.lucene.facet.taxonomy;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.index.AtomicReaderContext;
+import org.apache.lucene.util.IntsRef;
+
+/** Provides per-document ordinals. */
+
+public abstract class OrdinalsReader {
+
+  /** Returns ordinals for documents in one segment. */
+  public static abstract class OrdinalsSegmentReader {
+    /** Get the ordinals for this document.  ordinals.offset
+     *  must always be 0! */
+    public abstract void get(int doc, IntsRef ordinals) throws IOException;
+
+    /** Default constructor. */
+    public OrdinalsSegmentReader() {
+    }
+  }
+
+  /** Default constructor. */
+  public OrdinalsReader() {
+  }
+
+  /** Set current atomic reader. */
+  public abstract OrdinalsSegmentReader getReader(AtomicReaderContext context) throws IOException;
+
+  /** Returns the indexed field name this {@code
+   *  OrdinalsReader} is reading from. */
+  public abstract String getIndexFieldName();
+}
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/TaxonomyFacetCounts.java b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/TaxonomyFacetCounts.java
index aceb5ce..7eae584 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/TaxonomyFacetCounts.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/TaxonomyFacetCounts.java
@@ -23,7 +23,6 @@ import java.util.List;
 import org.apache.lucene.facet.FacetsCollector;
 import org.apache.lucene.facet.FacetsCollector.MatchingDocs;
 import org.apache.lucene.facet.FacetsConfig;
-import org.apache.lucene.facet.OrdinalsReader;
 import org.apache.lucene.index.BinaryDocValues;
 import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.IntsRef;
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/TaxonomyFacetSumValueSource.java b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/TaxonomyFacetSumValueSource.java
index 3839177..3644d81 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/TaxonomyFacetSumValueSource.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/TaxonomyFacetSumValueSource.java
@@ -22,11 +22,9 @@ import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 
-import org.apache.lucene.facet.DocValuesOrdinalsReader;
 import org.apache.lucene.facet.FacetsCollector;
 import org.apache.lucene.facet.FacetsCollector.MatchingDocs;
 import org.apache.lucene.facet.FacetsConfig;
-import org.apache.lucene.facet.OrdinalsReader;
 import org.apache.lucene.index.AtomicReaderContext;
 import org.apache.lucene.queries.function.FunctionValues;
 import org.apache.lucene.queries.function.ValueSource;
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/FacetTestCase.java b/lucene/facet/src/test/org/apache/lucene/facet/FacetTestCase.java
index 4df86e5..0ded954 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/FacetTestCase.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/FacetTestCase.java
@@ -26,7 +26,10 @@ import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 
+import org.apache.lucene.facet.taxonomy.CachedOrdinalsReader;
+import org.apache.lucene.facet.taxonomy.DocValuesOrdinalsReader;
 import org.apache.lucene.facet.taxonomy.FastTaxonomyFacetCounts;
+import org.apache.lucene.facet.taxonomy.OrdinalsReader;
 import org.apache.lucene.facet.taxonomy.TaxonomyFacetCounts;
 import org.apache.lucene.facet.taxonomy.TaxonomyReader;
 import org.apache.lucene.util.BytesRef;
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/TestCachedOrdinalsReader.java b/lucene/facet/src/test/org/apache/lucene/facet/TestCachedOrdinalsReader.java
deleted file mode 100644
index a42d615..0000000
--- a/lucene/facet/src/test/org/apache/lucene/facet/TestCachedOrdinalsReader.java
+++ /dev/null
@@ -1,83 +0,0 @@
-package org.apache.lucene.facet;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-
-import org.apache.lucene.analysis.MockAnalyzer;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyWriter;
-import org.apache.lucene.index.AtomicReaderContext;
-import org.apache.lucene.index.DirectoryReader;
-import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.IndexWriterConfig;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.IOUtils;
-import org.junit.Test;
-
-public class TestCachedOrdinalsReader extends FacetTestCase {
-
-  @Test
-  public void testWithThreads() throws Exception {
-    // LUCENE-5303: OrdinalsCache used the ThreadLocal BinaryDV instead of reader.getCoreCacheKey().
-    Directory indexDir = newDirectory();
-    Directory taxoDir = newDirectory();
-    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));
-    IndexWriter writer = new IndexWriter(indexDir, conf);
-    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir);
-    FacetsConfig config = new FacetsConfig();
-    
-    Document doc = new Document();
-    doc.add(new FacetField("A", "1"));
-    writer.addDocument(config.build(taxoWriter, doc));
-    doc = new Document();
-    doc.add(new FacetField("A", "2"));
-    writer.addDocument(config.build(taxoWriter, doc));
-    
-    final DirectoryReader reader = DirectoryReader.open(writer, true);
-    final CachedOrdinalsReader ordsReader = new CachedOrdinalsReader(new DocValuesOrdinalsReader(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));
-    Thread[] threads = new Thread[3];
-    for (int i = 0; i < threads.length; i++) {
-      threads[i] = new Thread("CachedOrdsThread-" + i) {
-        @Override
-        public void run() {
-          for (AtomicReaderContext context : reader.leaves()) {
-            try {
-              ordsReader.getReader(context);
-            } catch (IOException e) {
-              throw new RuntimeException(e);
-            }
-          }
-        }
-      };
-    }
-
-    long ramBytesUsed = 0;
-    for (Thread t : threads) {
-      t.start();
-      t.join();
-      if (ramBytesUsed == 0) {
-        ramBytesUsed = ordsReader.ramBytesUsed();
-      } else {
-        assertEquals(ramBytesUsed, ordsReader.ramBytesUsed());
-      }
-    }
-    
-    IOUtils.close(writer, taxoWriter, reader, indexDir, taxoDir);
-  }
-}
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestCachedOrdinalsReader.java b/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestCachedOrdinalsReader.java
new file mode 100644
index 0000000..fece21b
--- /dev/null
+++ b/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestCachedOrdinalsReader.java
@@ -0,0 +1,86 @@
+package org.apache.lucene.facet.taxonomy;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.analysis.MockAnalyzer;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.facet.FacetField;
+import org.apache.lucene.facet.FacetTestCase;
+import org.apache.lucene.facet.FacetsConfig;
+import org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyWriter;
+import org.apache.lucene.index.AtomicReaderContext;
+import org.apache.lucene.index.DirectoryReader;
+import org.apache.lucene.index.IndexWriter;
+import org.apache.lucene.index.IndexWriterConfig;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.IOUtils;
+import org.junit.Test;
+
+public class TestCachedOrdinalsReader extends FacetTestCase {
+
+  @Test
+  public void testWithThreads() throws Exception {
+    // LUCENE-5303: OrdinalsCache used the ThreadLocal BinaryDV instead of reader.getCoreCacheKey().
+    Directory indexDir = newDirectory();
+    Directory taxoDir = newDirectory();
+    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));
+    IndexWriter writer = new IndexWriter(indexDir, conf);
+    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir);
+    FacetsConfig config = new FacetsConfig();
+    
+    Document doc = new Document();
+    doc.add(new FacetField("A", "1"));
+    writer.addDocument(config.build(taxoWriter, doc));
+    doc = new Document();
+    doc.add(new FacetField("A", "2"));
+    writer.addDocument(config.build(taxoWriter, doc));
+    
+    final DirectoryReader reader = DirectoryReader.open(writer, true);
+    final CachedOrdinalsReader ordsReader = new CachedOrdinalsReader(new DocValuesOrdinalsReader(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));
+    Thread[] threads = new Thread[3];
+    for (int i = 0; i < threads.length; i++) {
+      threads[i] = new Thread("CachedOrdsThread-" + i) {
+        @Override
+        public void run() {
+          for (AtomicReaderContext context : reader.leaves()) {
+            try {
+              ordsReader.getReader(context);
+            } catch (IOException e) {
+              throw new RuntimeException(e);
+            }
+          }
+        }
+      };
+    }
+
+    long ramBytesUsed = 0;
+    for (Thread t : threads) {
+      t.start();
+      t.join();
+      if (ramBytesUsed == 0) {
+        ramBytesUsed = ordsReader.ramBytesUsed();
+      } else {
+        assertEquals(ramBytesUsed, ordsReader.ramBytesUsed());
+      }
+    }
+    
+    IOUtils.close(writer, taxoWriter, reader, indexDir, taxoDir);
+  }
+}
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetCounts.java b/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetCounts.java
index 3682e7e..0a8e248 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetCounts.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetCounts.java
@@ -30,8 +30,6 @@ import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.StringField;
-import org.apache.lucene.facet.CachedOrdinalsReader;
-import org.apache.lucene.facet.DocValuesOrdinalsReader;
 import org.apache.lucene.facet.DrillDownQuery;
 import org.apache.lucene.facet.FacetField;
 import org.apache.lucene.facet.FacetResult;
@@ -40,7 +38,6 @@ import org.apache.lucene.facet.Facets;
 import org.apache.lucene.facet.FacetsCollector;
 import org.apache.lucene.facet.FacetsConfig;
 import org.apache.lucene.facet.LabelAndValue;
-import org.apache.lucene.facet.OrdinalsReader;
 import org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyReader;
 import org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyWriter;
 import org.apache.lucene.index.DirectoryReader;
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetSumValueSource.java b/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetSumValueSource.java
index 8a5b1a8..5561e6d 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetSumValueSource.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetSumValueSource.java
@@ -30,7 +30,6 @@ import org.apache.lucene.document.FloatDocValuesField;
 import org.apache.lucene.document.IntField;
 import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.document.StringField;
-import org.apache.lucene.facet.DocValuesOrdinalsReader;
 import org.apache.lucene.facet.FacetField;
 import org.apache.lucene.facet.FacetResult;
 import org.apache.lucene.facet.FacetTestCase;

