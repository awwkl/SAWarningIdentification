GitDiffStart: 5f38c1d4dec9b14f86b56740788b6ca4044d4166 | Sat Jul 7 16:41:50 2012 +0000
diff --git a/lucene/analysis/stempel/src/java/org/egothor/stemmer/Compile.java b/lucene/analysis/stempel/src/java/org/egothor/stemmer/Compile.java
index 7b522e5..a2e648b 100644
--- a/lucene/analysis/stempel/src/java/org/egothor/stemmer/Compile.java
+++ b/lucene/analysis/stempel/src/java/org/egothor/stemmer/Compile.java
@@ -63,6 +63,7 @@ import java.io.FileOutputStream;
 import java.io.IOException;
 import java.io.InputStreamReader;
 import java.io.LineNumberReader;
+import java.util.Locale;
 import java.util.StringTokenizer;
 
 /**
@@ -89,7 +90,7 @@ public class Compile {
       return;
     }
     
-    args[0].toUpperCase();
+    args[0].toUpperCase(Locale.ROOT);
     
     backward = args[0].charAt(0) == '-';
     int qq = (backward) ? 1 : 0;
@@ -127,7 +128,7 @@ public class Compile {
             new FileInputStream(args[i]), charset)));
         for (String line = in.readLine(); line != null; line = in.readLine()) {
           try {
-            line = line.toLowerCase();
+            line = line.toLowerCase(Locale.ROOT);
             StringTokenizer st = new StringTokenizer(line);
             String stem = st.nextToken();
             if (storeorig) {
diff --git a/lucene/analysis/stempel/src/java/org/egothor/stemmer/DiffIt.java b/lucene/analysis/stempel/src/java/org/egothor/stemmer/DiffIt.java
index c1dc323..5ec54b0 100644
--- a/lucene/analysis/stempel/src/java/org/egothor/stemmer/DiffIt.java
+++ b/lucene/analysis/stempel/src/java/org/egothor/stemmer/DiffIt.java
@@ -55,9 +55,11 @@
 package org.egothor.stemmer;
 
 import java.io.BufferedReader;
-import java.io.FileReader;
+import java.io.FileInputStream;
 import java.io.IOException;
+import java.io.InputStreamReader;
 import java.io.LineNumberReader;
+import java.util.Locale;
 import java.util.StringTokenizer;
 
 /**
@@ -95,10 +97,11 @@ public class DiffIt {
       // System.out.println("[" + args[i] + "]");
       Diff diff = new Diff(ins, del, rep, nop);
       try {
-        in = new LineNumberReader(new BufferedReader(new FileReader(args[i])));
+        String charset = System.getProperty("egothor.stemmer.charset", "UTF-8");
+        in = new LineNumberReader(new BufferedReader(new InputStreamReader(new FileInputStream(args[i]), charset)));
         for (String line = in.readLine(); line != null; line = in.readLine()) {
           try {
-            line = line.toLowerCase();
+            line = line.toLowerCase(Locale.ROOT);
             StringTokenizer st = new StringTokenizer(line);
             String stem = st.nextToken();
             System.out.println(stem + " -a");
diff --git a/lucene/analysis/stempel/src/test/org/egothor/stemmer/TestCompile.java b/lucene/analysis/stempel/src/test/org/egothor/stemmer/TestCompile.java
index 6a3aa6c..054365c 100644
--- a/lucene/analysis/stempel/src/test/org/egothor/stemmer/TestCompile.java
+++ b/lucene/analysis/stempel/src/test/org/egothor/stemmer/TestCompile.java
@@ -64,6 +64,7 @@ import java.io.FileReader;
 import java.io.IOException;
 import java.io.LineNumberReader;
 import java.net.URI;
+import java.util.Locale;
 import java.util.StringTokenizer;
 
 import org.apache.lucene.util.LuceneTestCase;
@@ -107,7 +108,7 @@ public class TestCompile extends LuceneTestCase {
     Trie trie;
     DataInputStream is = new DataInputStream(new BufferedInputStream(
         new FileInputStream(path)));
-    String method = is.readUTF().toUpperCase();
+    String method = is.readUTF().toUpperCase(Locale.ROOT);
     if (method.indexOf('M') < 0) {
       trie = new Trie(is);
     } else {
@@ -124,7 +125,7 @@ public class TestCompile extends LuceneTestCase {
     
     for (String line = in.readLine(); line != null; line = in.readLine()) {
       try {
-        line = line.toLowerCase();
+        line = line.toLowerCase(Locale.ROOT);
         StringTokenizer st = new StringTokenizer(line);
         String stem = st.nextToken();
         if (storeorig) {
@@ -132,7 +133,7 @@ public class TestCompile extends LuceneTestCase {
               .getLastOnPath(stem);
           StringBuilder stm = new StringBuilder(stem);
           Diff.apply(stm, cmd);
-          assertEquals(stem.toLowerCase(), stm.toString().toLowerCase());
+          assertEquals(stem.toLowerCase(Locale.ROOT), stm.toString().toLowerCase(Locale.ROOT));
         }
         while (st.hasMoreTokens()) {
           String token = st.nextToken();
@@ -143,7 +144,7 @@ public class TestCompile extends LuceneTestCase {
               .getLastOnPath(token);
           StringBuilder stm = new StringBuilder(token);
           Diff.apply(stm, cmd);
-          assertEquals(stem.toLowerCase(), stm.toString().toLowerCase());
+          assertEquals(stem.toLowerCase(Locale.ROOT), stm.toString().toLowerCase(Locale.ROOT));
         }
       } catch (java.util.NoSuchElementException x) {
         // no base token (stem) on a line
diff --git a/lucene/benchmark/src/java/org/apache/lucene/benchmark/quality/trec/QueryDriver.java b/lucene/benchmark/src/java/org/apache/lucene/benchmark/quality/trec/QueryDriver.java
index a1ee941..cc4f322 100644
--- a/lucene/benchmark/src/java/org/apache/lucene/benchmark/quality/trec/QueryDriver.java
+++ b/lucene/benchmark/src/java/org/apache/lucene/benchmark/quality/trec/QueryDriver.java
@@ -28,8 +28,9 @@ import org.apache.lucene.util.IOUtils;
 
 import java.io.BufferedReader;
 import java.io.File;
-import java.io.FileReader;
+import java.io.OutputStreamWriter;
 import java.io.PrintWriter;
+import java.nio.charset.Charset;
 import java.util.HashSet;
 import java.util.Set;
 
@@ -61,7 +62,7 @@ public class QueryDriver {
     int maxResults = 1000;
     String docNameField = "docname";
 
-    PrintWriter logger = new PrintWriter(System.out, true);
+    PrintWriter logger = new PrintWriter(new OutputStreamWriter(System.out, Charset.defaultCharset()), true);
 
     // use trec utilities to read trec topics into quality queries
     TrecTopicsReader qReader = new TrecTopicsReader();
diff --git a/lucene/benchmark/src/java/org/apache/lucene/benchmark/utils/ExtractWikipedia.java b/lucene/benchmark/src/java/org/apache/lucene/benchmark/utils/ExtractWikipedia.java
index 85138ce..387a0ad 100644
--- a/lucene/benchmark/src/java/org/apache/lucene/benchmark/utils/ExtractWikipedia.java
+++ b/lucene/benchmark/src/java/org/apache/lucene/benchmark/utils/ExtractWikipedia.java
@@ -18,8 +18,10 @@ package org.apache.lucene.benchmark.utils;
  */
 
 import java.io.File;
-import java.io.FileWriter;
+import java.io.FileOutputStream;
 import java.io.IOException;
+import java.io.OutputStreamWriter;
+import java.io.Writer;
 import java.util.Properties;
 
 import org.apache.lucene.benchmark.byTask.feeds.ContentSource;
@@ -28,6 +30,7 @@ import org.apache.lucene.benchmark.byTask.feeds.EnwikiContentSource;
 import org.apache.lucene.benchmark.byTask.feeds.NoMoreDataException;
 import org.apache.lucene.benchmark.byTask.utils.Config;
 import org.apache.lucene.document.Document;
+import org.apache.lucene.util.IOUtils;
 
 /**
  * Extract the downloaded Wikipedia dump into separate files for indexing.
@@ -83,7 +86,7 @@ public class ExtractWikipedia {
     contents.append("\n");
 
     try {
-      FileWriter writer = new FileWriter(f);
+      Writer writer = new OutputStreamWriter(new FileOutputStream(f), IOUtils.CHARSET_UTF_8);
       writer.write(contents.toString());
       writer.close();
     } catch (IOException ioe) {
diff --git a/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/feeds/DocMakerTest.java b/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/feeds/DocMakerTest.java
index 110de00..fe023c9 100644
--- a/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/feeds/DocMakerTest.java
+++ b/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/feeds/DocMakerTest.java
@@ -166,7 +166,7 @@ public class DocMakerTest extends BenchmarkTestCase {
     // DocMaker did not close its ContentSource if resetInputs was called twice,
     // leading to a file handle leak.
     File f = new File(getWorkDir(), "docMakerLeak.txt");
-    PrintStream ps = new PrintStream(f);
+    PrintStream ps = new PrintStream(f, "UTF-8");
     ps.println("one title\t" + System.currentTimeMillis() + "\tsome content");
     ps.close();
     
diff --git a/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/tasks/CreateIndexTaskTest.java b/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/tasks/CreateIndexTaskTest.java
index aad00fe..3f1d0cc 100644
--- a/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/tasks/CreateIndexTaskTest.java
+++ b/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/tasks/CreateIndexTaskTest.java
@@ -20,6 +20,7 @@ package org.apache.lucene.benchmark.byTask.tasks;
 import java.io.ByteArrayOutputStream;
 import java.io.File;
 import java.io.PrintStream;
+import java.nio.charset.Charset;
 import java.util.Properties;
 
 import org.apache.lucene.benchmark.BenchmarkTestCase;
@@ -50,7 +51,7 @@ public class CreateIndexTaskTest extends BenchmarkTestCase {
  
     PrintStream curOut = System.out;
     ByteArrayOutputStream baos = new ByteArrayOutputStream();
-    System.setOut(new PrintStream(baos));
+    System.setOut(new PrintStream(baos, false, Charset.defaultCharset().name()));
     try {
       PerfRunData runData = createPerfRunData("SystemOut");
       CreateIndexTask cit = new CreateIndexTask(runData);
@@ -63,7 +64,7 @@ public class CreateIndexTaskTest extends BenchmarkTestCase {
     
     PrintStream curErr = System.err;
     baos.reset();
-    System.setErr(new PrintStream(baos));
+    System.setErr(new PrintStream(baos, false, Charset.defaultCharset().name()));
     try {
       PerfRunData runData = createPerfRunData("SystemErr");
       CreateIndexTask cit = new CreateIndexTask(runData);
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/writercache/cl2o/TestCharBlockArray.java b/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/writercache/cl2o/TestCharBlockArray.java
index fba7a6b..b6ff021 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/writercache/cl2o/TestCharBlockArray.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/writercache/cl2o/TestCharBlockArray.java
@@ -5,9 +5,13 @@ import java.io.BufferedOutputStream;
 import java.io.File;
 import java.io.FileInputStream;
 import java.io.FileOutputStream;
+import java.nio.ByteBuffer;
+import java.nio.charset.CharsetDecoder;
+import java.nio.charset.CodingErrorAction;
 
 import org.junit.Test;
 
+import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.facet.taxonomy.writercache.cl2o.CharBlockArray;
 
@@ -41,8 +45,12 @@ public class TestCharBlockArray extends LuceneTestCase {
     for (int i = 0; i < n; i++) {
       random().nextBytes(buffer);
       int size = 1 + random().nextInt(50);
-
-      String s = new String(buffer, 0, size);
+      // This test is turning random bytes into a string,
+      // this is asking for trouble.
+      CharsetDecoder decoder = IOUtils.CHARSET_UTF_8.newDecoder()
+          .onUnmappableCharacter(CodingErrorAction.REPLACE)
+          .onMalformedInput(CodingErrorAction.REPLACE);
+      String s = decoder.decode(ByteBuffer.wrap(buffer, 0, size)).toString();
       array.append(s);
       builder.append(s);
     }
@@ -50,8 +58,12 @@ public class TestCharBlockArray extends LuceneTestCase {
     for (int i = 0; i < n; i++) {
       random().nextBytes(buffer);
       int size = 1 + random().nextInt(50);
-
-      String s = new String(buffer, 0, size);
+      // This test is turning random bytes into a string,
+      // this is asking for trouble.
+      CharsetDecoder decoder = IOUtils.CHARSET_UTF_8.newDecoder()
+          .onUnmappableCharacter(CodingErrorAction.REPLACE)
+          .onMalformedInput(CodingErrorAction.REPLACE);
+      String s = decoder.decode(ByteBuffer.wrap(buffer, 0, size)).toString();
       array.append((CharSequence)s);
       builder.append(s);
     }
@@ -59,8 +71,12 @@ public class TestCharBlockArray extends LuceneTestCase {
     for (int i = 0; i < n; i++) {
       random().nextBytes(buffer);
       int size = 1 + random().nextInt(50);
-
-      String s = new String(buffer, 0, size);
+      // This test is turning random bytes into a string,
+      // this is asking for trouble.
+      CharsetDecoder decoder = IOUtils.CHARSET_UTF_8.newDecoder()
+          .onUnmappableCharacter(CodingErrorAction.REPLACE)
+          .onMalformedInput(CodingErrorAction.REPLACE);
+      String s = decoder.decode(ByteBuffer.wrap(buffer, 0, size)).toString();
       for (int j = 0; j < s.length(); j++) {
         array.append(s.charAt(j));
       }
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/writercache/cl2o/TestCompactLabelToOrdinal.java b/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/writercache/cl2o/TestCompactLabelToOrdinal.java
index dd51856..09184e8 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/writercache/cl2o/TestCompactLabelToOrdinal.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/writercache/cl2o/TestCompactLabelToOrdinal.java
@@ -1,11 +1,15 @@
 package org.apache.lucene.facet.taxonomy.writercache.cl2o;
 
 import java.io.File;
+import java.nio.ByteBuffer;
+import java.nio.charset.CharsetDecoder;
+import java.nio.charset.CodingErrorAction;
 import java.util.HashMap;
 import java.util.Map;
 
 import org.junit.Test;
 
+import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.facet.taxonomy.CategoryPath;
 import org.apache.lucene.facet.taxonomy.writercache.cl2o.CompactLabelToOrdinal;
@@ -46,7 +50,12 @@ public class TestCompactLabelToOrdinal extends LuceneTestCase {
       random().nextBytes(buffer);
       int size = 1 + random().nextInt(50);
 
-      uniqueValues[i] = new String(buffer, 0, size);
+      // This test is turning random bytes into a string,
+      // this is asking for trouble.
+      CharsetDecoder decoder = IOUtils.CHARSET_UTF_8.newDecoder()
+          .onUnmappableCharacter(CodingErrorAction.REPLACE)
+          .onMalformedInput(CodingErrorAction.REPLACE);
+      uniqueValues[i] = decoder.decode(ByteBuffer.wrap(buffer, 0, size)).toString();
       if (uniqueValues[i].indexOf(CompactLabelToOrdinal.TerminatorChar) == -1) {
         i++;
       }
diff --git a/lucene/facet/src/test/org/apache/lucene/util/encoding/EncodingSpeed.java b/lucene/facet/src/test/org/apache/lucene/util/encoding/EncodingSpeed.java
index 2aeede1..a000b0c 100644
--- a/lucene/facet/src/test/org/apache/lucene/util/encoding/EncodingSpeed.java
+++ b/lucene/facet/src/test/org/apache/lucene/util/encoding/EncodingSpeed.java
@@ -5,6 +5,7 @@ import java.io.ByteArrayOutputStream;
 import java.io.IOException;
 import java.text.NumberFormat;
 import java.util.Arrays;
+import java.util.Locale;
 
 import org.apache.lucene.util.encoding.DGapIntEncoder;
 import org.apache.lucene.util.encoding.EightFlagsIntEncoder;
@@ -67,11 +68,11 @@ public class EncodingSpeed {
             + ") " + loopFactor + " times.");
 
     System.out.println();
-    String header = String.format(headerFormat, "Encoder", "Bits/Int",
+    String header = String.format(Locale.ROOT, headerFormat, "Encoder", "Bits/Int",
         "Encode Time", "Encode Time", "Decode Time", "Decode Time");
 
     System.out.println(header);
-    String header2 = String.format(headerFormat, "", "", "[milliseconds]",
+    String header2 = String.format(Locale.ROOT, headerFormat, "", "", "[milliseconds]",
         "[microsecond / int]", "[milliseconds]", "[microsecond / int]");
 
     System.out.println(header2);
@@ -148,7 +149,7 @@ public class EncodingSpeed {
     endTime = System.currentTimeMillis();
     long decodeTime = endTime - startTime;
 
-    System.out.println(String.format(resultsFormat, encoder, nf.format(baos
+    System.out.println(String.format(Locale.ROOT, resultsFormat, encoder, nf.format(baos
         .size()
         * 8.0 / data.length), encodeTime, nf.format(encodeTime
         * 1000000.0 / (loopFactor * data.length)), decodeTime, nf
diff --git a/lucene/join/src/java/org/apache/lucene/search/join/JoinUtil.java b/lucene/join/src/java/org/apache/lucene/search/join/JoinUtil.java
index 9502d04..4921278 100644
--- a/lucene/join/src/java/org/apache/lucene/search/join/JoinUtil.java
+++ b/lucene/join/src/java/org/apache/lucene/search/join/JoinUtil.java
@@ -21,6 +21,7 @@ import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
 
 import java.io.IOException;
+import java.util.Locale;
 
 /**
  * Utility for query time joining using TermsQuery and TermsCollector.
@@ -85,7 +86,7 @@ public final class JoinUtil {
             fromQuery
         );
       default:
-        throw new IllegalArgumentException(String.format("Score mode %s isn't supported.", scoreMode));
+        throw new IllegalArgumentException(String.format(Locale.ROOT, "Score mode %s isn't supported.", scoreMode));
     }
   }
 
diff --git a/lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery.java b/lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery.java
index e6b5d73..dd0ea9d 100644
--- a/lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery.java
+++ b/lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery.java
@@ -36,6 +36,7 @@ import org.apache.lucene.util.BytesRefHash;
 import org.apache.lucene.util.FixedBitSet;
 
 import java.io.IOException;
+import java.util.Locale;
 import java.util.Set;
 
 class TermsIncludingScoreQuery extends Query {
@@ -69,7 +70,7 @@ class TermsIncludingScoreQuery extends Query {
   }
 
   public String toString(String string) {
-    return String.format("TermsIncludingScoreQuery{field=%s;originalQuery=%s}", field, unwrittenOriginalQuery);
+    return String.format(Locale.ROOT, "TermsIncludingScoreQuery{field=%s;originalQuery=%s}", field, unwrittenOriginalQuery);
   }
 
   @Override
diff --git a/lucene/join/src/java/org/apache/lucene/search/join/ToParentBlockJoinQuery.java b/lucene/join/src/java/org/apache/lucene/search/join/ToParentBlockJoinQuery.java
index cfca569..7e4c0f1 100644
--- a/lucene/join/src/java/org/apache/lucene/search/join/ToParentBlockJoinQuery.java
+++ b/lucene/join/src/java/org/apache/lucene/search/join/ToParentBlockJoinQuery.java
@@ -20,6 +20,7 @@ package org.apache.lucene.search.join;
 import java.io.IOException;
 import java.util.Collection;
 import java.util.Collections;
+import java.util.Locale;
 import java.util.Set;
 
 import org.apache.lucene.index.AtomicReaderContext;
@@ -395,7 +396,7 @@ public class ToParentBlockJoinQuery extends Query {
       int start = docBase + prevParentDoc + 1; // +1 b/c prevParentDoc is previous parent doc
       int end = docBase + parentDoc - 1; // -1 b/c parentDoc is parent doc
       return new ComplexExplanation(
-          true, score(), String.format("Score based on child doc range from %d to %d", start, end)
+          true, score(), String.format(Locale.ROOT, "Score based on child doc range from %d to %d", start, end)
       );
     }
 
diff --git a/lucene/join/src/test/org/apache/lucene/search/join/TestJoinUtil.java b/lucene/join/src/test/org/apache/lucene/search/join/TestJoinUtil.java
index 6439770..1b539e7 100644
--- a/lucene/join/src/test/org/apache/lucene/search/join/TestJoinUtil.java
+++ b/lucene/join/src/test/org/apache/lucene/search/join/TestJoinUtil.java
@@ -319,12 +319,12 @@ public class TestJoinUtil extends LuceneTestCase {
           System.out.println("expected cardinality:" + expectedResult.cardinality());
           DocIdSetIterator iterator = expectedResult.iterator();
           for (int doc = iterator.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = iterator.nextDoc()) {
-            System.out.println(String.format("Expected doc[%d] with id value %s", doc, indexSearcher.doc(doc).get("id")));
+            System.out.println(String.format(Locale.ROOT, "Expected doc[%d] with id value %s", doc, indexSearcher.doc(doc).get("id")));
           }
           System.out.println("actual cardinality:" + actualResult.cardinality());
           iterator = actualResult.iterator();
           for (int doc = iterator.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = iterator.nextDoc()) {
-            System.out.println(String.format("Actual doc[%d] with id value %s", doc, indexSearcher.doc(doc).get("id")));
+            System.out.println(String.format(Locale.ROOT, "Actual doc[%d] with id value %s", doc, indexSearcher.doc(doc).get("id")));
           }
         }
         assertEquals(expectedResult, actualResult);

