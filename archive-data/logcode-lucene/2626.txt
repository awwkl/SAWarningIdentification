GitDiffStart: 75c7abbd99efb24e6083df0e453df82fcd256104 | Sun Oct 11 13:14:03 2015 +0000
diff --git a/solr/CHANGES.txt b/solr/CHANGES.txt
index 92bab29..c2628f7 100644
--- a/solr/CHANGES.txt
+++ b/solr/CHANGES.txt
@@ -258,6 +258,9 @@ Bug Fixes
   home directory.  Fixes the inability to use ICU analysis components with a
   "solr." prefix on the classname. (Shawn Heisey)
 
+* SOLR-8130: Solr's hdfs safe mode detection does not catch all cases of being in safe mode.
+  (Mark Miller, Mike Drob)
+  
 Optimizations
 ----------------------
 
diff --git a/solr/core/src/java/org/apache/solr/store/hdfs/HdfsDirectory.java b/solr/core/src/java/org/apache/solr/store/hdfs/HdfsDirectory.java
index 4ddad89..454927e 100644
--- a/solr/core/src/java/org/apache/solr/store/hdfs/HdfsDirectory.java
+++ b/solr/core/src/java/org/apache/solr/store/hdfs/HdfsDirectory.java
@@ -29,7 +29,8 @@ import org.apache.hadoop.fs.FileContext;
 import org.apache.hadoop.fs.FileStatus;
 import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.ipc.RemoteException;
+import org.apache.hadoop.hdfs.DistributedFileSystem;
+import org.apache.hadoop.hdfs.protocol.HdfsConstants.SafeModeAction;
 import org.apache.lucene.store.BaseDirectory;
 import org.apache.lucene.store.IOContext;
 import org.apache.lucene.store.IndexInput;
@@ -63,36 +64,29 @@ public class HdfsDirectory extends BaseDirectory {
     fileSystem = FileSystem.get(hdfsDirPath.toUri(), configuration);
     fileContext = FileContext.getFileContext(hdfsDirPath.toUri(), configuration);
     
-    while (true) {
-      try {
-        if (!fileSystem.exists(hdfsDirPath)) {
-          boolean success = fileSystem.mkdirs(hdfsDirPath);
-          if (!success) {
-            throw new RuntimeException("Could not create directory: " + hdfsDirPath);
-          }
-        } else {
-          fileSystem.mkdirs(hdfsDirPath); // check for safe mode
+    if (fileSystem instanceof DistributedFileSystem) {
+      // Make sure dfs is not in safe mode
+      while (((DistributedFileSystem) fileSystem).setSafeMode(SafeModeAction.SAFEMODE_GET, true)) {
+        LOG.warn("The NameNode is in SafeMode - Solr will wait 5 seconds and try again.");
+        try {
+          Thread.sleep(5000);
+        } catch (InterruptedException e) {
+          Thread.interrupted();
+          // continue
         }
-        
-        break;
-      } catch (RemoteException e) {
-        if (e.getClassName().equals("org.apache.hadoop.hdfs.server.namenode.SafeModeException")) {
-          LOG.warn("The NameNode is in SafeMode - Solr will wait 5 seconds and try again.");
-          try {
-            Thread.sleep(5000);
-          } catch (InterruptedException e1) {
-            Thread.interrupted();
-          }
-          continue;
+      }
+    }
+    
+    try {
+      if (!fileSystem.exists(hdfsDirPath)) {
+        boolean success = fileSystem.mkdirs(hdfsDirPath);
+        if (!success) {
+          throw new RuntimeException("Could not create directory: " + hdfsDirPath);
         }
-        org.apache.solr.common.util.IOUtils.closeQuietly(fileSystem);
-        throw new RuntimeException(
-            "Problem creating directory: " + hdfsDirPath, e);
-      } catch (Exception e) {
-        org.apache.solr.common.util.IOUtils.closeQuietly(fileSystem);
-        throw new RuntimeException(
-            "Problem creating directory: " + hdfsDirPath, e);
       }
+    } catch (Exception e) {
+      org.apache.solr.common.util.IOUtils.closeQuietly(fileSystem);
+      throw new RuntimeException("Problem creating directory: " + hdfsDirPath, e);
     }
   }
   

