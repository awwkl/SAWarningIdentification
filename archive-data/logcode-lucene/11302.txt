GitDiffStart: b2ca2895b75bd6c011583603cdd6fd13b6afa216 | Thu Aug 30 03:59:32 2012 +0000
diff --git a/lucene/build.xml b/lucene/build.xml
index 3bf2095..e4f2b9b 100644
--- a/lucene/build.xml
+++ b/lucene/build.xml
@@ -248,6 +248,9 @@
       <!-- spatial: problems -->
       <check-missing-javadocs dir="build/docs/suggest" level="class"/>
       <check-missing-javadocs dir="build/docs/test-framework" level="class"/>
+
+      <!-- too much to fix for now, but enforce full javadocs for key packages -->
+      <check-missing-javadocs dir="build/docs/core/org/apache/lucene/analysis" level="method"/>
     </sequential>
   </target>
   
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/Analyzer.java b/lucene/core/src/java/org/apache/lucene/analysis/Analyzer.java
index 4b7fd2e..613d77f 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/Analyzer.java
+++ b/lucene/core/src/java/org/apache/lucene/analysis/Analyzer.java
@@ -20,6 +20,7 @@ package org.apache.lucene.analysis;
 import org.apache.lucene.store.AlreadyClosedException;
 import org.apache.lucene.util.CloseableThreadLocal;
 
+import java.io.Closeable;
 import java.io.IOException;
 import java.io.Reader;
 import java.util.HashMap;
@@ -67,7 +68,7 @@ import java.util.Map;
  *       Analysis integration with Apache UIMA. 
  * </ul>
  */
-public abstract class Analyzer {
+public abstract class Analyzer implements Closeable {
 
   private final ReuseStrategy reuseStrategy;
 
@@ -105,20 +106,25 @@ public abstract class Analyzer {
       Reader reader);
 
   /**
-   * Creates a TokenStream that is allowed to be re-use from the previous time
-   * that the same thread called this method.  Callers that do not need to use
-   * more than one TokenStream at the same time from this analyzer should use
-   * this method for better performance.
+   * Returns a TokenStream suitable for <code>fieldName</code>, tokenizing
+   * the contents of <code>reader</code>.
    * <p>
    * This method uses {@link #createComponents(String, Reader)} to obtain an
    * instance of {@link TokenStreamComponents}. It returns the sink of the
    * components and stores the components internally. Subsequent calls to this
    * method will reuse the previously stored components after resetting them
    * through {@link TokenStreamComponents#setReader(Reader)}.
-   * </p>
+   * <p>
+   * <b>NOTE:</b> After calling this method, the consumer must follow the 
+   * workflow described in {@link TokenStream} to properly consume its contents.
+   * See the {@link org.apache.lucene.analysis Analysis package documentation} for
+   * some examples demonstrating this.
    * 
    * @param fieldName the name of the field the created TokenStream is used for
    * @param reader the reader the streams source reads from
+   * @return TokenStream for iterating the analyzed content of <code>reader</code>
+   * @throws AlreadyClosedException if the Analyzer is closed.
+   * @throws IOException if an i/o error occurs.
    */
   public final TokenStream tokenStream(final String fieldName,
                                        final Reader reader) throws IOException {
@@ -135,6 +141,13 @@ public abstract class Analyzer {
   
   /**
    * Override this if you want to add a CharFilter chain.
+   * <p>
+   * The default implementation returns <code>reader</code>
+   * unchanged.
+   * 
+   * @param fieldName IndexableField name being indexed
+   * @param reader original Reader
+   * @return reader, optionally decorated with CharFilter(s)
    */
   protected Reader initReader(String fieldName, Reader reader) {
     return reader;
@@ -151,7 +164,8 @@ public abstract class Analyzer {
    * exact PhraseQuery matches, for instance, across IndexableField instance boundaries.
    *
    * @param fieldName IndexableField name being indexed.
-   * @return position increment gap, added to the next token emitted from {@link #tokenStream(String,Reader)}
+   * @return position increment gap, added to the next token emitted from {@link #tokenStream(String,Reader)}.
+   *         This value must be {@code >= 0}.
    */
   public int getPositionIncrementGap(String fieldName) {
     return 0;
@@ -164,7 +178,8 @@ public abstract class Analyzer {
    * produced at least one token for indexing.
    *
    * @param fieldName the field just indexed
-   * @return offset gap, added to the next token emitted from {@link #tokenStream(String,Reader)}
+   * @return offset gap, added to the next token emitted from {@link #tokenStream(String,Reader)}.
+   *         This value must be {@code >= 0}.
    */
   public int getOffsetGap(String fieldName) {
     return 1;
@@ -254,10 +269,13 @@ public abstract class Analyzer {
    * Strategy defining how TokenStreamComponents are reused per call to
    * {@link Analyzer#tokenStream(String, java.io.Reader)}.
    */
-  public static abstract class ReuseStrategy {
+  public static abstract class ReuseStrategy implements Closeable {
 
     private CloseableThreadLocal<Object> storedValue = new CloseableThreadLocal<Object>();
 
+    /** Sole constructor. (For invocation by subclass constructors, typically implicit.) */
+    public ReuseStrategy() {}
+
     /**
      * Gets the reusable TokenStreamComponents for the field with the given name
      *
@@ -281,6 +299,7 @@ public abstract class Analyzer {
      * Returns the currently stored value
      *
      * @return Currently stored value or {@code null} if no value is stored
+     * @throws AlreadyClosedException if the ReuseStrategy is closed.
      */
     protected final Object getStoredValue() {
       try {
@@ -298,6 +317,7 @@ public abstract class Analyzer {
      * Sets the stored value
      *
      * @param storedValue Value to store
+     * @throws AlreadyClosedException if the ReuseStrategy is closed.
      */
     protected final void setStoredValue(Object storedValue) {
       try {
@@ -315,8 +335,10 @@ public abstract class Analyzer {
      * Closes the ReuseStrategy, freeing any resources
      */
     public void close() {
-      storedValue.close();
-      storedValue = null;
+      if (storedValue != null) {
+        storedValue.close();
+        storedValue = null;
+      }
     }
   }
 
@@ -325,6 +347,9 @@ public abstract class Analyzer {
    * every field.
    */
   public final static class GlobalReuseStrategy extends ReuseStrategy {
+    
+    /** Creates a new instance, with empty per-thread values */
+    public GlobalReuseStrategy() {}
 
     @Override
     public TokenStreamComponents getReusableComponents(String fieldName) {
@@ -343,6 +368,9 @@ public abstract class Analyzer {
    */
   public static class PerFieldReuseStrategy extends ReuseStrategy {
 
+    /** Creates a new instance, with empty per-thread-per-field values */
+    public PerFieldReuseStrategy() {}
+
     @SuppressWarnings("unchecked")
     @Override
     public TokenStreamComponents getReusableComponents(String fieldName) {
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/CharFilter.java b/lucene/core/src/java/org/apache/lucene/analysis/CharFilter.java
index 60c62bf..e6658af 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/CharFilter.java
+++ b/lucene/core/src/java/org/apache/lucene/analysis/CharFilter.java
@@ -55,6 +55,10 @@ public abstract class CharFilter extends Reader {
   
   /** 
    * Closes the underlying input stream.
+   * <p>
+   * <b>NOTE:</b> 
+   * The default implementation closes the input Reader, so
+   * be sure to call <code>super.close()</code> when overriding this method.
    */
   @Override
   public void close() throws IOException {
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/NumericTokenStream.java b/lucene/core/src/java/org/apache/lucene/analysis/NumericTokenStream.java
index d347027..e5ee6d0 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/NumericTokenStream.java
+++ b/lucene/core/src/java/org/apache/lucene/analysis/NumericTokenStream.java
@@ -144,6 +144,12 @@ public final class NumericTokenStream extends TokenStream {
     private long value = 0L;
     private int valueSize = 0, shift = 0, precisionStep = 0;
     private BytesRef bytes = new BytesRef();
+    
+    /** 
+     * Creates, but does not yet initialize this attribute instance
+     * @see #init(long, int, int, int)
+     */
+    public NumericTermAttributeImpl() {}
 
     public BytesRef getBytesRef() {
       return bytes;
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/Token.java b/lucene/core/src/java/org/apache/lucene/analysis/Token.java
index 7d33509..e1b9f3c 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/Token.java
+++ b/lucene/core/src/java/org/apache/lucene/analysis/Token.java
@@ -176,8 +176,8 @@ public class Token extends CharTermAttributeImpl
    *  instead use the char[] termBuffer methods to set the
    *  term text.
    *  @param text term text
-   *  @param start start offset
-   *  @param end end offset
+   *  @param start start offset in the source text
+   *  @param end end offset in the source text
    */
   public Token(String text, int start, int end) {
     checkOffsets(start, end);
@@ -191,8 +191,8 @@ public class Token extends CharTermAttributeImpl
    *  speed you should instead use the char[] termBuffer
    *  methods to set the term text.
    *  @param text term text
-   *  @param start start offset
-   *  @param end end offset
+   *  @param start start offset in the source text
+   *  @param end end offset in the source text
    *  @param typ token type
    */
   public Token(String text, int start, int end, String typ) {
@@ -208,9 +208,9 @@ public class Token extends CharTermAttributeImpl
    *  offsets, & type.  <b>NOTE:</b> for better indexing
    *  speed you should instead use the char[] termBuffer
    *  methods to set the term text.
-   * @param text
-   * @param start
-   * @param end
+   * @param text term text
+   * @param start start offset in the source text
+   * @param end end offset in the source text
    * @param flags token type bits
    */
   public Token(String text, int start, int end, int flags) {
@@ -225,11 +225,11 @@ public class Token extends CharTermAttributeImpl
    *  Constructs a Token with the given term buffer (offset
    *  & length), start and end
    *  offsets
-   * @param startTermBuffer
-   * @param termBufferOffset
-   * @param termBufferLength
-   * @param start
-   * @param end
+   * @param startTermBuffer buffer containing term text
+   * @param termBufferOffset the index in the buffer of the first character
+   * @param termBufferLength number of valid characters in the buffer
+   * @param start start offset in the source text
+   * @param end end offset in the source text
    */
   public Token(char[] startTermBuffer, int termBufferOffset, int termBufferLength, int start, int end) {
     checkOffsets(start, end);
@@ -238,31 +238,9 @@ public class Token extends CharTermAttributeImpl
     endOffset = end;
   }
 
-  /** Set the position increment.  This determines the position of this token
-   * relative to the previous Token in a {@link TokenStream}, used in phrase
-   * searching.
-   *
-   * <p>The default value is one.
-   *
-   * <p>Some common uses for this are:<ul>
-   *
-   * <li>Set it to zero to put multiple terms in the same position.  This is
-   * useful if, e.g., a word has multiple stems.  Searches for phrases
-   * including either stem will match.  In this case, all but the first stem's
-   * increment should be set to zero: the increment of the first instance
-   * should be one.  Repeating a token with an increment of zero can also be
-   * used to boost the scores of matches on that token.
-   *
-   * <li>Set it to values greater than one to inhibit exact phrase matches.
-   * If, for example, one does not want phrases to match across removed stop
-   * words, then one could build a stop word filter that removes stop words and
-   * also sets the increment to the number of stop words removed before each
-   * non-stop word.  Then exact phrase queries will only match when the terms
-   * occur with no intervening stop words.
-   *
-   * </ul>
-   * @param positionIncrement the distance from the prior term
-   * @see org.apache.lucene.index.DocsAndPositionsEnum
+  /**
+   * {@inheritDoc}
+   * @see PositionIncrementAttribute
    */
   public void setPositionIncrement(int positionIncrement) {
     if (positionIncrement < 0)
@@ -271,93 +249,101 @@ public class Token extends CharTermAttributeImpl
     this.positionIncrement = positionIncrement;
   }
 
-  /** Returns the position increment of this Token.
-   * @see #setPositionIncrement
+  /**
+   * {@inheritDoc}
+   * @see PositionIncrementAttribute
    */
   public int getPositionIncrement() {
     return positionIncrement;
   }
 
-  /** Set the position length.
-   * @see PositionLengthAttribute */
+  /**
+   * {@inheritDoc}
+   * @see PositionLengthAttribute
+   */
   @Override
   public void setPositionLength(int positionLength) {
     this.positionLength = positionLength;
   }
 
-  /** Get the position length.
-   * @see PositionLengthAttribute */
+  /**
+   * {@inheritDoc}
+   * @see PositionLengthAttribute
+   */
   @Override
   public int getPositionLength() {
     return positionLength;
   }
 
-  /** Returns this Token's starting offset, the position of the first character
-    corresponding to this token in the source text.
-
-    Note that the difference between endOffset() and startOffset() may not be
-    equal to {@link #length}, as the term text may have been altered by a
-    stemmer or some other filter. */
+  /**
+   * {@inheritDoc}
+   * @see OffsetAttribute
+   */
   public final int startOffset() {
     return startOffset;
   }
 
-  /** Returns this Token's ending offset, one greater than the position of the
-    last character corresponding to this token in the source text. The length
-    of the token in the source text is (endOffset - startOffset). */
+  /**
+   * {@inheritDoc}
+   * @see OffsetAttribute
+   */
   public final int endOffset() {
     return endOffset;
   }
 
-  /** Set the starting and ending offset.
-  @see #startOffset() and #endOffset()*/
+  /**
+   * {@inheritDoc}
+   * @see OffsetAttribute
+   */
   public void setOffset(int startOffset, int endOffset) {
     checkOffsets(startOffset, endOffset);
     this.startOffset = startOffset;
     this.endOffset = endOffset;
   }
 
-  /** Returns this Token's lexical type.  Defaults to "word". */
+  /**
+   * {@inheritDoc}
+   * @see TypeAttribute
+   */
   public final String type() {
     return type;
   }
 
-  /** Set the lexical type.
-      @see #type() */
+  /**
+   * {@inheritDoc}
+   * @see TypeAttribute
+   */
   public final void setType(String type) {
     this.type = type;
   }
 
   /**
-   * <p/>
-   *
-   * Get the bitset for any bits that have been set.  This is completely distinct from {@link #type()}, although they do share similar purposes.
-   * The flags can be used to encode information about the token for use by other {@link org.apache.lucene.analysis.TokenFilter}s.
-   *
-   * 
-   * @return The bits
-   * @lucene.experimental While we think this is here to stay, we may want to change it to be a long.
+   * {@inheritDoc}
+   * @see FlagsAttribute
    */
   public int getFlags() {
     return flags;
   }
 
   /**
-   * @see #getFlags()
+   * {@inheritDoc}
+   * @see FlagsAttribute
    */
   public void setFlags(int flags) {
     this.flags = flags;
   }
 
   /**
-   * Returns this Token's payload.
-   */ 
+   * {@inheritDoc}
+   * @see PayloadAttribute
+   */
   public BytesRef getPayload() {
     return this.payload;
   }
 
-  /** 
-   * Sets this Token's payload.
+  /**
+   * {@inheritDoc}
+   * @see PayloadAttribute
    */
   public void setPayload(BytesRef payload) {
     this.payload = payload;
@@ -551,8 +537,8 @@ public class Token extends CharTermAttributeImpl
 
   /**
    * Copy the prototype token's fields into this one, with a different term. Note: Payloads are shared.
-   * @param prototype
-   * @param newTerm
+   * @param prototype existing Token
+   * @param newTerm new term text
    */
   public void reinit(Token prototype, String newTerm) {
     setEmpty().append(newTerm);
@@ -566,10 +552,10 @@ public class Token extends CharTermAttributeImpl
 
   /**
    * Copy the prototype token's fields into this one, with a different term. Note: Payloads are shared.
-   * @param prototype
-   * @param newTermBuffer
-   * @param offset
-   * @param length
+   * @param prototype existing Token
+   * @param newTermBuffer buffer containing new term text
+   * @param offset the index in the buffer of the first character
+   * @param length number of valid characters in the buffer
    */
   public void reinit(Token prototype, char[] newTermBuffer, int offset, int length) {
     copyBuffer(newTermBuffer, offset, length);
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/TokenFilter.java b/lucene/core/src/java/org/apache/lucene/analysis/TokenFilter.java
index 00ab0d1..2961283 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/TokenFilter.java
+++ b/lucene/core/src/java/org/apache/lucene/analysis/TokenFilter.java
@@ -34,21 +34,37 @@ public abstract class TokenFilter extends TokenStream {
     this.input = input;
   }
   
-  /** Performs end-of-stream operations, if any, and calls then <code>end()</code> on the
-   * input TokenStream.<p/> 
-   * <b>NOTE:</b> Be sure to call <code>super.end()</code> first when overriding this method.*/
+  /** 
+   * {@inheritDoc}
+   * <p> 
+   * <b>NOTE:</b> 
+   * The default implementation chains the call to the input TokenStream, so
+   * be sure to call <code>super.end()</code> first when overriding this method.
+   */
   @Override
   public void end() throws IOException {
     input.end();
   }
   
-  /** Close the input TokenStream. */
+  /**
+   * {@inheritDoc}
+   * <p>
+   * <b>NOTE:</b> 
+   * The default implementation chains the call to the input TokenStream, so
+   * be sure to call <code>super.close()</code> when overriding this method.
+   */
   @Override
   public void close() throws IOException {
     input.close();
   }
 
-  /** Reset the filter as well as the input TokenStream. */
+  /**
+   * {@inheritDoc}
+   * <p>
+   * <b>NOTE:</b> 
+   * The default implementation chains the call to the input TokenStream, so
+   * be sure to call <code>super.reset()</code> when overriding this method.
+   */
   @Override
   public void reset() throws IOException {
     input.reset();
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/Tokenizer.java b/lucene/core/src/java/org/apache/lucene/analysis/Tokenizer.java
index 1b39489..696ba04 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/Tokenizer.java
+++ b/lucene/core/src/java/org/apache/lucene/analysis/Tokenizer.java
@@ -54,7 +54,13 @@ public abstract class Tokenizer extends TokenStream {
     this.input = input;
   }
   
-  /** By default, closes the input Reader. */
+  /**
+   * {@inheritDoc}
+   * <p>
+   * <b>NOTE:</b> 
+   * The default implementation closes the input Reader, so
+   * be sure to call <code>super.close()</code> when overriding this method.
+   */
   @Override
   public void close() throws IOException {
     if (input != null) {
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/CharTermAttribute.java b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/CharTermAttribute.java
index 2db0f58..3c4b9ff 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/CharTermAttribute.java
+++ b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/CharTermAttribute.java
@@ -38,7 +38,11 @@ public interface CharTermAttribute extends Attribute, CharSequence, Appendable {
    *  #resizeBuffer(int)} to increase it.  After
    *  altering the buffer be sure to call {@link
    *  #setLength} to record the number of valid
-   *  characters that were placed into the termBuffer. */
+   *  characters that were placed into the termBuffer. 
+   *  <p>
+   *  <b>NOTE</b>: The returned buffer may be larger than
+   *  the valid {@link #length()}.
+   */
   public char[] buffer();
 
   /** Grows the termBuffer to at least size newSize, preserving the
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/CharTermAttributeImpl.java b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/CharTermAttributeImpl.java
index afcf15a..8cab986 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/CharTermAttributeImpl.java
+++ b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/CharTermAttributeImpl.java
@@ -26,14 +26,15 @@ import org.apache.lucene.util.AttributeReflector;
 import org.apache.lucene.util.RamUsageEstimator;
 import org.apache.lucene.util.UnicodeUtil;
 
-/**
- * The term text of a Token.
- */
+/** Default implementation of {@link CharTermAttribute}. */
 public class CharTermAttributeImpl extends AttributeImpl implements CharTermAttribute, TermToBytesRefAttribute, Cloneable {
   private static int MIN_BUFFER_SIZE = 10;
   
   private char[] termBuffer = new char[ArrayUtil.oversize(MIN_BUFFER_SIZE, RamUsageEstimator.NUM_BYTES_CHAR)];
   private int termLength = 0;
+  
+  /** Initialize this attribute with empty term text */
+  public CharTermAttributeImpl() {}
 
   public final void copyBuffer(char[] buffer, int offset, int length) {
     growTermBuffer(length);
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/FlagsAttribute.java b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/FlagsAttribute.java
index 63116e3..8e05ef5 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/FlagsAttribute.java
+++ b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/FlagsAttribute.java
@@ -22,22 +22,23 @@ import org.apache.lucene.util.Attribute;
 
 /**
  * This attribute can be used to pass different flags down the {@link Tokenizer} chain,
- * eg from one TokenFilter to another one. 
+ * e.g. from one TokenFilter to another one. 
+ * <p>
+ * This is completely distinct from {@link TypeAttribute}, although they do share similar purposes.
+ * The flags can be used to encode information about the token for use by other 
+ * {@link org.apache.lucene.analysis.TokenFilter}s.
  * @lucene.experimental While we think this is here to stay, we may want to change it to be a long.
  */
 public interface FlagsAttribute extends Attribute {
   /**
-   * <p/>
-   *
-   * Get the bitset for any bits that have been set.  This is completely distinct from {@link TypeAttribute#type()}, although they do share similar purposes.
-   * The flags can be used to encode information about the token for use by other {@link org.apache.lucene.analysis.TokenFilter}s.
-   *
-   *
+   * Get the bitset for any bits that have been set.  
    * @return The bits
+   * @see #getFlags()
    */
   public int getFlags();
 
   /**
+   * Set the flags to a new bitset.
    * @see #getFlags()
    */
   public void setFlags(int flags);  
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/FlagsAttributeImpl.java b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/FlagsAttributeImpl.java
index c1ad928..337cd02 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/FlagsAttributeImpl.java
+++ b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/FlagsAttributeImpl.java
@@ -19,30 +19,17 @@ package org.apache.lucene.analysis.tokenattributes;
 
 import org.apache.lucene.util.AttributeImpl;
 
-/**
- * This attribute can be used to pass different flags down the tokenizer chain,
- * eg from one TokenFilter to another one. 
- * @lucene.experimental While we think this is here to stay, we may want to change it to be a long.
- */
+/** Default implementation of {@link FlagsAttribute}. */
 public class FlagsAttributeImpl extends AttributeImpl implements FlagsAttribute, Cloneable {
   private int flags = 0;
   
-  /**
-   * <p/>
-   *
-   * Get the bitset for any bits that have been set.  This is completely distinct from {@link TypeAttribute#type()}, although they do share similar purposes.
-   * The flags can be used to encode information about the token for use by other {@link org.apache.lucene.analysis.TokenFilter}s.
-   *
-   *
-   * @return The bits
-   */
+  /** Initialize this attribute with no bits set */
+  public FlagsAttributeImpl() {}
+  
   public int getFlags() {
     return flags;
   }
 
-  /**
-   * @see #getFlags()
-   */
   public void setFlags(int flags) {
     this.flags = flags;
   }
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/KeywordAttribute.java b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/KeywordAttribute.java
index 7e80d2a..d3906ab 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/KeywordAttribute.java
+++ b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/KeywordAttribute.java
@@ -30,20 +30,22 @@ import org.apache.lucene.util.Attribute;
 public interface KeywordAttribute extends Attribute {
 
   /**
-   * Returns <code>true</code> iff the current token is a keyword, otherwise
-   * <code>false</code>/
+   * Returns <code>true</code> if the current token is a keyword, otherwise
+   * <code>false</code>
    * 
-   * @return <code>true</code> iff the current token is a keyword, otherwise
-   *         <code>false</code>/
+   * @return <code>true</code> if the current token is a keyword, otherwise
+   *         <code>false</code>
+   * @see #setKeyword(boolean)
    */
   public boolean isKeyword();
 
   /**
-   * Marks the current token as keyword iff set to <code>true</code>.
+   * Marks the current token as keyword if set to <code>true</code>.
    * 
    * @param isKeyword
-   *          <code>true</code> iff the current token is a keyword, otherwise
+   *          <code>true</code> if the current token is a keyword, otherwise
    *          <code>false</code>.
+   * @see #isKeyword()
    */
   public void setKeyword(boolean isKeyword);
 }
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/KeywordAttributeImpl.java b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/KeywordAttributeImpl.java
index 7f2b2f4..0deaa4b 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/KeywordAttributeImpl.java
+++ b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/KeywordAttributeImpl.java
@@ -17,19 +17,15 @@ package org.apache.lucene.analysis.tokenattributes;
  * limitations under the License.
  */
 
-import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.util.AttributeImpl;
 
-/**
- *This attribute can be used to mark a token as a keyword. Keyword aware
- * {@link TokenStream}s can decide to modify a token based on the return value
- * of {@link #isKeyword()} if the token is modified. Stemming filters for
- * instance can use this attribute to conditionally skip a term if
- * {@link #isKeyword()} returns <code>true</code>.
- */
+/** Default implementation of {@link KeywordAttribute}. */
 public final class KeywordAttributeImpl extends AttributeImpl implements
     KeywordAttribute {
   private boolean keyword;
+  
+  /** Initialize this attribute with the keyword value as false. */
+  public KeywordAttributeImpl() {}
 
   @Override
   public void clear() {
@@ -57,24 +53,10 @@ public final class KeywordAttributeImpl extends AttributeImpl implements
     return keyword == other.keyword;
   }
 
-  /**
-   * Returns <code>true</code> iff the current token is a keyword, otherwise
-   * <code>false</code>/
-   * 
-   * @return <code>true</code> iff the current token is a keyword, otherwise
-   *         <code>false</code>/
-   */
   public boolean isKeyword() {
     return keyword;
   }
 
-  /**
-   * Marks the current token as keyword iff set to <code>true</code>.
-   * 
-   * @param isKeyword
-   *          <code>true</code> iff the current token is a keyword, otherwise
-   *          <code>false</code>.
-   */
   public void setKeyword(boolean isKeyword) {
     keyword = isKeyword;
   }
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/OffsetAttribute.java b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/OffsetAttribute.java
index 67612e8..a0f87d5 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/OffsetAttribute.java
+++ b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/OffsetAttribute.java
@@ -23,22 +23,34 @@ import org.apache.lucene.util.Attribute;
  * The start and end character offset of a Token. 
  */
 public interface OffsetAttribute extends Attribute {
-  /** Returns this Token's starting offset, the position of the first character
-  corresponding to this token in the source text.
-
-  Note that the difference between endOffset() and startOffset() may not be
-  equal to termText.length(), as the term text may have been altered by a
-  stemmer or some other filter. */
+  /** 
+   * Returns this Token's starting offset, the position of the first character
+   * corresponding to this token in the source text.
+   * <p>
+   * Note that the difference between {@link #endOffset()} and <code>startOffset()</code> 
+   * may not be equal to termText.length(), as the term text may have been altered by a
+   * stemmer or some other filter.
+   * @see #setOffset(int, int) 
+   */
   public int startOffset();
 
   
-  /** Set the starting and ending offset.
-    @see #startOffset() and #endOffset()*/
+  /** 
+   * Set the starting and ending offset.
+   * @throws IllegalArgumentException If <code>startOffset</code> or <code>endOffset</code>
+   *         are negative, or if <code>startOffset</code> is greater than 
+   *         <code>endOffset</code>
+   * @see #startOffset()
+   * @see #endOffset()
+   */
   public void setOffset(int startOffset, int endOffset);
   
 
-  /** Returns this Token's ending offset, one greater than the position of the
-  last character corresponding to this token in the source text. The length
-  of the token in the source text is (endOffset - startOffset). */
+  /** 
+   * Returns this Token's ending offset, one greater than the position of the
+   * last character corresponding to this token in the source text. The length
+   * of the token in the source text is (<code>endOffset()</code> - {@link #startOffset()}). 
+   * @see #setOffset(int, int)
+   */
   public int endOffset();
 }
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/OffsetAttributeImpl.java b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/OffsetAttributeImpl.java
index c2ffbf8..54f4d28 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/OffsetAttributeImpl.java
+++ b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/OffsetAttributeImpl.java
@@ -19,26 +19,18 @@ package org.apache.lucene.analysis.tokenattributes;
 
 import org.apache.lucene.util.AttributeImpl;
 
-/**
- * The start and end character offset of a Token. 
- */
+/** Default implementation of {@link OffsetAttribute}. */
 public class OffsetAttributeImpl extends AttributeImpl implements OffsetAttribute, Cloneable {
   private int startOffset;
   private int endOffset;
+  
+  /** Initialize this attribute with startOffset and endOffset of 0. */
+  public OffsetAttributeImpl() {}
 
-  /** Returns this Token's starting offset, the position of the first character
-  corresponding to this token in the source text.
-
-  Note that the difference between endOffset() and startOffset() may not be
-  equal to termText.length(), as the term text may have been altered by a
-  stemmer or some other filter. */
   public int startOffset() {
     return startOffset;
   }
 
-  
-  /** Set the starting and ending offset.
-    @see #startOffset() and #endOffset()*/
   public void setOffset(int startOffset, int endOffset) {
 
     // TODO: we could assert that this is set-once, ie,
@@ -56,10 +48,6 @@ public class OffsetAttributeImpl extends AttributeImpl implements OffsetAttribut
     this.endOffset = endOffset;
   }
   
-
-  /** Returns this Token's ending offset, one greater than the position of the
-  last character corresponding to this token in the source text. The length
-  of the token in the source text is (endOffset - startOffset). */
   public int endOffset() {
     return endOffset;
   }
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/PayloadAttribute.java b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/PayloadAttribute.java
index 658bc82..8793c94 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/PayloadAttribute.java
+++ b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/PayloadAttribute.java
@@ -17,20 +17,34 @@ package org.apache.lucene.analysis.tokenattributes;
  * limitations under the License.
  */
 
+import org.apache.lucene.index.DocsAndPositionsEnum; // javadocs
 import org.apache.lucene.util.Attribute;
 import org.apache.lucene.util.BytesRef;
 
 /**
- * The payload of a Token. 
+ * The payload of a Token.
+ * <p>
+ * The payload is stored in the index at each position, and can
+ * be used to influence scoring when using Payload-based queries 
+ * in the {@link org.apache.lucene.search.payloads} and
+ * {@link org.apache.lucene.search.spans} packages.
+ * <p>
+ * NOTE: because the payload will be stored at each position, its usually
+ * best to use the minimum number of bytes necessary. Some codec implementations
+ * may optimize payload storage when all payloads have the same length.
+ * 
+ * @see DocsAndPositionsEnum
  */
 public interface PayloadAttribute extends Attribute {
   /**
    * Returns this Token's payload.
+   * @see #setPayload(BytesRef)
    */ 
   public BytesRef getPayload();
 
   /** 
    * Sets this Token's payload.
+   * @see #getPayload()
    */
   public void setPayload(BytesRef payload);
 }
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/PayloadAttributeImpl.java b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/PayloadAttributeImpl.java
index 6053e58..5a9118f 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/PayloadAttributeImpl.java
+++ b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/PayloadAttributeImpl.java
@@ -20,9 +20,7 @@ package org.apache.lucene.analysis.tokenattributes;
 import org.apache.lucene.util.AttributeImpl;
 import org.apache.lucene.util.BytesRef;
 
-/**
- * The payload of a Token.
- */
+/** Default implementation of {@link PayloadAttribute}. */
 public class PayloadAttributeImpl extends AttributeImpl implements PayloadAttribute, Cloneable {
   private BytesRef payload;  
   
@@ -38,16 +36,10 @@ public class PayloadAttributeImpl extends AttributeImpl implements PayloadAttrib
     this.payload = payload;
   }
   
-  /**
-   * Returns this Token's payload.
-   */ 
   public BytesRef getPayload() {
     return this.payload;
   }
 
-  /** 
-   * Sets this Token's payload.
-   */
   public void setPayload(BytesRef payload) {
     this.payload = payload;
   }
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/PositionIncrementAttribute.java b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/PositionIncrementAttribute.java
index fba0750..9afd2f9 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/PositionIncrementAttribute.java
+++ b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/PositionIncrementAttribute.java
@@ -49,11 +49,14 @@ public interface PositionIncrementAttribute extends Attribute {
   /** Set the position increment. The default value is one.
    *
    * @param positionIncrement the distance from the prior term
+   * @throws IllegalArgumentException if <code>positionIncrement</code> 
+   *         is negative.
+   * @see #getPositionIncrement()
    */
   public void setPositionIncrement(int positionIncrement);
 
   /** Returns the position increment of this Token.
-   * @see #setPositionIncrement
+   * @see #setPositionIncrement(int)
    */
   public int getPositionIncrement();
 }
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/PositionIncrementAttributeImpl.java b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/PositionIncrementAttributeImpl.java
index 7cf47b1..ff0c4d4 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/PositionIncrementAttributeImpl.java
+++ b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/PositionIncrementAttributeImpl.java
@@ -17,40 +17,15 @@ package org.apache.lucene.analysis.tokenattributes;
  * limitations under the License.
  */
 
-import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.util.AttributeImpl;
 
-/** Determines the position of this token
- * relative to the previous Token in a {@link TokenStream}, used in phrase
- * searching.
- *
- * <p>The default value is one.
- *
- * <p>Some common uses for this are:<ul>
- *
- * <li>Set it to zero to put multiple terms in the same position.  This is
- * useful if, e.g., a word has multiple stems.  Searches for phrases
- * including either stem will match.  In this case, all but the first stem's
- * increment should be set to zero: the increment of the first instance
- * should be one.  Repeating a token with an increment of zero can also be
- * used to boost the scores of matches on that token.
- *
- * <li>Set it to values greater than one to inhibit exact phrase matches.
- * If, for example, one does not want phrases to match across removed stop
- * words, then one could build a stop word filter that removes stop words and
- * also sets the increment to the number of stop words removed before each
- * non-stop word.  Then exact phrase queries will only match when the terms
- * occur with no intervening stop words.
- *
- * </ul>
- */
+/** Default implementation of {@link PositionIncrementAttribute}. */
 public class PositionIncrementAttributeImpl extends AttributeImpl implements PositionIncrementAttribute, Cloneable {
   private int positionIncrement = 1;
   
-  /** Set the position increment. The default value is one.
-   *
-   * @param positionIncrement the distance from the prior term
-   */
+  /** Initialize this attribute with position increment of 1 */
+  public PositionIncrementAttributeImpl() {}
+
   public void setPositionIncrement(int positionIncrement) {
     if (positionIncrement < 0) {
       throw new IllegalArgumentException
@@ -59,9 +34,6 @@ public class PositionIncrementAttributeImpl extends AttributeImpl implements Pos
     this.positionIncrement = positionIncrement;
   }
 
-  /** Returns the position increment of this Token.
-   * @see #setPositionIncrement
-   */
   public int getPositionIncrement() {
     return positionIncrement;
   }
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/PositionLengthAttribute.java b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/PositionLengthAttribute.java
index 6facfec..b402ead 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/PositionLengthAttribute.java
+++ b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/PositionLengthAttribute.java
@@ -26,11 +26,20 @@ import org.apache.lucene.util.Attribute;
  *  produced by decompounding, word splitting/joining,
  *  synonym filtering, etc.
  *
- * <p>The default value is one. */
+ * <p>NOTE: this is optional, and most analyzers
+ *  don't change the default value (1). */
 
 public interface PositionLengthAttribute extends Attribute {
-  /** @param positionLength how many positions this token
-   *  spans. */
+  /**
+   * Set the position length of this Token.
+   * <p>
+   * The default value is one. 
+   * @param positionLength how many positions this token
+   *  spans. 
+   * @throws IllegalArgumentException if <code>positionLength</code> 
+   *         is zero or negative.
+   * @see #getPositionLength()
+   */
   public void setPositionLength(int positionLength);
 
   /** Returns the position length of this Token.
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/PositionLengthAttributeImpl.java b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/PositionLengthAttributeImpl.java
index 995261d..30d6819 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/PositionLengthAttributeImpl.java
+++ b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/PositionLengthAttributeImpl.java
@@ -19,13 +19,13 @@ package org.apache.lucene.analysis.tokenattributes;
 
 import org.apache.lucene.util.AttributeImpl;
 
-/** See {@link PositionLengthAttribute}. */
+/** Default implementation of {@link PositionLengthAttribute}. */
 public class PositionLengthAttributeImpl extends AttributeImpl implements PositionLengthAttribute, Cloneable {
   private int positionLength = 1;
   
-  /** @param positionLength how many positions this token
-   *  spans.  NOTE: this is optional, and most analyzers
-   *  don't change the default value (1). */
+  /** Initializes this attribute with position length of 1. */
+  public PositionLengthAttributeImpl() {}
+  
   public void setPositionLength(int positionLength) {
     if (positionLength < 1) {
       throw new IllegalArgumentException
@@ -34,9 +34,6 @@ public class PositionLengthAttributeImpl extends AttributeImpl implements Positi
     this.positionLength = positionLength;
   }
 
-  /** Returns the position length of this Token.
-   * @see #setPositionLength    
-   */
   public int getPositionLength() {
     return positionLength;
   }
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/TermToBytesRefAttribute.java b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/TermToBytesRefAttribute.java
index 61f82ad..0601862 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/TermToBytesRefAttribute.java
+++ b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/TermToBytesRefAttribute.java
@@ -56,7 +56,7 @@ public interface TermToBytesRefAttribute extends Attribute {
    * Updates the bytes {@link #getBytesRef()} to contain this term's
    * final encoding, and returns its hashcode.
    * @return the hashcode as defined by {@link BytesRef#hashCode}:
-   * <pre>
+   * <pre class="prettyprint">
    *  int hash = 0;
    *  for (int i = termBytes.offset; i &lt; termBytes.offset+termBytes.length; i++) {
    *    hash = 31*hash + termBytes.bytes[i];
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/TypeAttribute.java b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/TypeAttribute.java
index 5013c60..00ee0d4 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/TypeAttribute.java
+++ b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/TypeAttribute.java
@@ -27,10 +27,15 @@ public interface TypeAttribute extends Attribute {
   /** the default type */
   public static final String DEFAULT_TYPE = "word";
 
-  /** Returns this Token's lexical type.  Defaults to "word". */
+  /** 
+   * Returns this Token's lexical type.  Defaults to "word". 
+   * @see #setType(String)
+   */
   public String type();
 
-  /** Set the lexical type.
-      @see #type() */
+  /** 
+   * Set the lexical type.
+   * @see #type() 
+   */
   public void setType(String type);
 }
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/TypeAttributeImpl.java b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/TypeAttributeImpl.java
index 098d78d..238c82c 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/TypeAttributeImpl.java
+++ b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/TypeAttributeImpl.java
@@ -19,27 +19,24 @@ package org.apache.lucene.analysis.tokenattributes;
 
 import org.apache.lucene.util.AttributeImpl;
 
-/**
- * A Token's lexical type. The Default value is "word". 
- */
+/** Default implementation of {@link TypeAttribute}. */
 public class TypeAttributeImpl extends AttributeImpl implements TypeAttribute, Cloneable {
   private String type;
   
+  /** Initialize this attribute with {@link TypeAttribute#DEFAULT_TYPE} */
   public TypeAttributeImpl() {
     this(DEFAULT_TYPE); 
   }
   
+  /** Initialize this attribute with <code>type</code> */
   public TypeAttributeImpl(String type) {
     this.type = type;
   }
   
-  /** Returns this Token's lexical type.  Defaults to "word". */
   public String type() {
     return type;
   }
 
-  /** Set the lexical type.
-      @see #type() */
   public void setType(String type) {
     this.type = type;
   }
diff --git a/lucene/core/src/java/org/apache/lucene/search/Scorer.java b/lucene/core/src/java/org/apache/lucene/search/Scorer.java
index f654d74..98b7ddc 100644
--- a/lucene/core/src/java/org/apache/lucene/search/Scorer.java
+++ b/lucene/core/src/java/org/apache/lucene/search/Scorer.java
@@ -113,13 +113,26 @@ public abstract class Scorer extends DocIdSetIterator {
     return Collections.emptyList();
   }
   
-  /** a child Scorer and its relationship to its parent.
+  /** A child Scorer and its relationship to its parent.
    * the meaning of the relationship depends upon the parent query. 
    * @lucene.experimental */
   public static class ChildScorer {
+    /**
+     * Child Scorer. (note this is typically a direct child, and may
+     * itself also have children).
+     */
     public final Scorer child;
+    /**
+     * An arbitrary string relating this scorer to the parent.
+     */
     public final String relationship;
     
+    /**
+     * Creates a new ChildScorer node with the specified relationship.
+     * <p>
+     * The relationship can be any be any string that makes sense to 
+     * the parent Scorer. 
+     */
     public ChildScorer(Scorer child, String relationship) {
       this.child = child;
       this.relationship = relationship;

