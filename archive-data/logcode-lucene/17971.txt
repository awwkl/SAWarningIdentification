GitDiffStart: cd320b5f578f57fa685a137469ded508e8148e60 | Tue May 4 11:57:21 2010 +0000
diff --git a/lucene/contrib/CHANGES.txt b/lucene/contrib/CHANGES.txt
index a7df800..f5f3c4e 100644
--- a/lucene/contrib/CHANGES.txt
+++ b/lucene/contrib/CHANGES.txt
@@ -92,6 +92,9 @@ API Changes
    stemming. Add Turkish and Romanian stopwords lists to support this.
    (Robert Muir, Uwe Schindler, Simon Willnauer)
    
+ * LUCENE-2413: Deprecated PatternAnalyzer in contrib/analyzers, in favor of the 
+   pattern package (CharFilter, Tokenizer, TokenFilter).  (Robert Muir)
+   
 New features
 
  * LUCENE-2306: Add NumericRangeFilter and NumericRangeQuery support to XMLQueryParser.
@@ -165,6 +168,8 @@ New features
      into subwords and performs optional transformations on subword groups.
    - o.a.l.analysis.miscellaneous.RemoveDuplicatesTokenFilter: TokenFilter which 
      filters out Tokens at the same position and Term text as the previous token.
+   - o.a.l.analysis.pattern: Package for pattern-based analysis, containing a 
+     CharFilter, Tokenizer, and Tokenfilter for transforming text with regexes.
    (... in progress)
 
 Build
diff --git a/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/miscellaneous/PatternAnalyzer.java b/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/miscellaneous/PatternAnalyzer.java
index 4f59789..ad5fa2d 100644
--- a/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/miscellaneous/PatternAnalyzer.java
+++ b/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/miscellaneous/PatternAnalyzer.java
@@ -62,8 +62,10 @@ import org.apache.lucene.util.Version;
  *     pat.tokenStream("content", "James is running round in the woods"), 
  *     "English"));
  * </pre>
- *
+ * @deprecated use the pattern-based analysis in the analysis/pattern package instead.
+ * This analyzer will be removed in a future release (4.1)
  */
+@Deprecated
 public final class PatternAnalyzer extends Analyzer {
   
   /** <code>"\\W+"</code>; Divides text at non-letters (NOT Character.isLetter(c)) */
diff --git a/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/pattern/PatternReplaceCharFilter.java b/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/pattern/PatternReplaceCharFilter.java
new file mode 100644
index 0000000..0ccbb85
--- /dev/null
+++ b/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/pattern/PatternReplaceCharFilter.java
@@ -0,0 +1,192 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.lucene.analysis.pattern;
+
+import java.io.IOException;
+import java.util.LinkedList;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
+import org.apache.lucene.analysis.charfilter.BaseCharFilter;
+import org.apache.lucene.analysis.CharStream;
+
+/**
+ * CharFilter that uses a regular expression for the target of replace string.
+ * The pattern match will be done in each "block" in char stream.
+ * 
+ * <p>
+ * ex1) source="aa&nbsp;&nbsp;bb&nbsp;aa&nbsp;bb", pattern="(aa)\\s+(bb)" replacement="$1#$2"<br/>
+ * output="aa#bb&nbsp;aa#bb"
+ * </p>
+ * 
+ * NOTE: If you produce a phrase that has different length to source string
+ * and the field is used for highlighting for a term of the phrase, you will
+ * face a trouble.
+ * 
+ * <p>
+ * ex2) source="aa123bb", pattern="(aa)\\d+(bb)" replacement="$1&nbsp;$2"<br/>
+ * output="aa&nbsp;bb"<br/>
+ * and you want to search bb and highlight it, you will get<br/>
+ * highlight snippet="aa1&lt;em&gt;23bb&lt;/em&gt;"
+ * </p>
+ * 
+ * @since Solr 1.5
+ */
+public class PatternReplaceCharFilter extends BaseCharFilter {
+
+  private final Pattern pattern;
+  private final String replacement;
+  private final int maxBlockChars;
+  private final String blockDelimiters;
+  public static final int DEFAULT_MAX_BLOCK_CHARS = 10000;
+
+  private LinkedList<Character> buffer;
+  private int nextCharCounter;
+  private char[] blockBuffer;
+  private int blockBufferLength;
+  private String replaceBlockBuffer;
+  private int replaceBlockBufferOffset;
+  
+  public PatternReplaceCharFilter( Pattern pattern, String replacement, CharStream in ){
+    this( pattern, replacement, DEFAULT_MAX_BLOCK_CHARS, null, in );
+  }
+
+  public PatternReplaceCharFilter( Pattern pattern, String replacement,
+      int maxBlockChars, CharStream in ){
+    this( pattern, replacement, maxBlockChars, null, in );
+  }
+
+  public PatternReplaceCharFilter( Pattern pattern, String replacement,
+      String blockDelimiters, CharStream in ){
+    this( pattern, replacement, DEFAULT_MAX_BLOCK_CHARS, blockDelimiters, in );
+  }
+
+  public PatternReplaceCharFilter( Pattern pattern, String replacement,
+      int maxBlockChars, String blockDelimiters, CharStream in ){
+    super( in );
+    this.pattern = pattern;
+    this.replacement = replacement;
+    if( maxBlockChars < 1 )
+      throw new IllegalArgumentException( "maxBlockChars should be greater than 0, but it is " + maxBlockChars );
+    this.maxBlockChars = maxBlockChars;
+    this.blockDelimiters = blockDelimiters;
+    blockBuffer = new char[maxBlockChars];
+  }
+  
+  private boolean prepareReplaceBlock() throws IOException {
+    while( true ){
+      if( replaceBlockBuffer != null && replaceBlockBuffer.length() > replaceBlockBufferOffset )
+        return true;
+      // prepare block buffer
+      blockBufferLength = 0;
+      while( true ){
+        int c = nextChar();
+        if( c == -1 ) break;
+        blockBuffer[blockBufferLength++] = (char)c;
+        // end of block?
+        boolean foundDelimiter =
+          ( blockDelimiters != null ) &&
+          ( blockDelimiters.length() > 0 ) &&
+          blockDelimiters.indexOf( c ) >= 0;
+        if( foundDelimiter ||
+            blockBufferLength >= maxBlockChars ) break;
+      }
+      // block buffer available?
+      if( blockBufferLength == 0 ) return false;
+      replaceBlockBuffer = getReplaceBlock( blockBuffer, 0, blockBufferLength );
+      replaceBlockBufferOffset = 0;
+    }
+  }
+
+  public int read() throws IOException {
+    while( prepareReplaceBlock() ){
+      return replaceBlockBuffer.charAt( replaceBlockBufferOffset++ );
+    }
+    return -1;
+  }
+
+  public int read(char[] cbuf, int off, int len) throws IOException {
+    char[] tmp = new char[len];
+    int l = input.read(tmp, 0, len);
+    if (l != -1) {
+      for(int i = 0; i < l; i++)
+        pushLastChar(tmp[i]);
+    }
+    l = 0;
+    for(int i = off; i < off + len; i++) {
+      int c = read();
+      if (c == -1) break;
+      cbuf[i] = (char) c;
+      l++;
+    }
+    return l == 0 ? -1 : l;
+  }
+
+  private int nextChar() throws IOException {
+    if (buffer != null && !buffer.isEmpty()) {
+      nextCharCounter++;
+      return buffer.removeFirst().charValue();
+    }
+    int c = input.read();
+    if( c != -1 )
+      nextCharCounter++;
+    return c;
+  }
+
+  private void pushLastChar(int c) {
+    if (buffer == null) {
+      buffer = new LinkedList<Character>();
+    }
+    buffer.addLast(new Character((char) c));
+  }
+  
+  String getReplaceBlock( String block ){
+    char[] blockChars = block.toCharArray();
+    return getReplaceBlock( blockChars, 0, blockChars.length );
+  }
+    
+  String getReplaceBlock( char block[], int offset, int length ){
+    StringBuffer replaceBlock = new StringBuffer();
+    String sourceBlock = new String( block, offset, length );
+    Matcher m = pattern.matcher( sourceBlock );
+    int lastMatchOffset = 0, lastDiff = 0;
+    while( m.find() ){
+      m.appendReplacement( replaceBlock, replacement );
+      // record cumulative diff for the offset correction
+      int diff = replaceBlock.length() - lastMatchOffset - lastDiff - ( m.end( 0 ) - lastMatchOffset );
+      if (diff != 0) {
+        int prevCumulativeDiff = getLastCumulativeDiff();
+        if (diff > 0) {
+          for(int i = 0; i < diff; i++){
+            addOffCorrectMap(nextCharCounter - length + m.end( 0 ) + i - prevCumulativeDiff,
+                prevCumulativeDiff - 1 - i);
+          }
+        } else {
+          addOffCorrectMap(nextCharCounter - length + m.end( 0 ) + diff - prevCumulativeDiff,
+              prevCumulativeDiff - diff);
+        }
+      }
+      // save last offsets
+      lastMatchOffset = m.end( 0 );
+      lastDiff = diff;
+    }
+    // copy remaining of the part of source block
+    m.appendTail( replaceBlock );
+    return replaceBlock.toString();
+  }
+}
diff --git a/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/pattern/PatternReplaceFilter.java b/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/pattern/PatternReplaceFilter.java
new file mode 100644
index 0000000..150c71e
--- /dev/null
+++ b/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/pattern/PatternReplaceFilter.java
@@ -0,0 +1,83 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.lucene.analysis.pattern;
+
+import org.apache.lucene.analysis.TokenFilter;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+
+import java.util.regex.Pattern;
+import java.util.regex.Matcher;
+import java.io.IOException;
+
+/**
+ * A TokenFilter which applies a Pattern to each token in the stream,
+ * replacing match occurances with the specified replacement string.
+ *
+ * <p>
+ * <b>Note:</b> Depending on the input and the pattern used and the input
+ * TokenStream, this TokenFilter may produce Tokens whose text is the empty
+ * string.
+ * </p>
+ * 
+ * @see Pattern
+ */
+public final class PatternReplaceFilter extends TokenFilter {
+  private final Pattern p;
+  private final String replacement;
+  private final boolean all;
+  private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
+  private final Matcher m;
+
+  /**
+   * Constructs an instance to replace either the first, or all occurances
+   *
+   * @param in the TokenStream to process
+   * @param p the patterm to apply to each Token
+   * @param replacement the "replacement string" to substitute, if null a
+   *        blank string will be used. Note that this is not the literal
+   *        string that will be used, '$' and '\' have special meaning.
+   * @param all if true, all matches will be replaced otherwise just the first match.
+   * @see Matcher#quoteReplacement
+   */
+  public PatternReplaceFilter(TokenStream in,
+                              Pattern p,
+                              String replacement,
+                              boolean all) {
+    super(in);
+    this.p=p;
+    this.replacement = (null == replacement) ? "" : replacement;
+    this.all=all;
+    this.m = p.matcher(termAtt);
+  }
+
+  @Override
+  public boolean incrementToken() throws IOException {
+    if (!input.incrementToken()) return false;
+    
+    m.reset();
+    if (m.find()) {
+      // replaceAll/replaceFirst will reset() this previous find.
+      String transformed = all ? m.replaceAll(replacement) : m.replaceFirst(replacement);
+      termAtt.setEmpty().append(transformed);
+    }
+
+    return true;
+  }
+
+}
diff --git a/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/pattern/PatternTokenizer.java b/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/pattern/PatternTokenizer.java
new file mode 100644
index 0000000..3d43d17
--- /dev/null
+++ b/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/pattern/PatternTokenizer.java
@@ -0,0 +1,147 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.lucene.analysis.pattern;
+
+import java.io.IOException;
+import java.io.Reader;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
+
+/**
+ * This tokenizer uses regex pattern matching to construct distinct tokens
+ * for the input stream.  It takes two arguments:  "pattern" and "group".
+ * <p/>
+ * <ul>
+ * <li>"pattern" is the regular expression.</li>
+ * <li>"group" says which group to extract into tokens.</li>
+ *  </ul>
+ * <p>
+ * group=-1 (the default) is equivalent to "split".  In this case, the tokens will
+ * be equivalent to the output from (without empty tokens):
+ * {@link String#split(java.lang.String)}
+ * </p>
+ * <p>
+ * Using group >= 0 selects the matching group as the token.  For example, if you have:<br/>
+ * <pre>
+ *  pattern = \'([^\']+)\'
+ *  group = 0
+ *  input = aaa 'bbb' 'ccc'
+ *</pre>
+ * the output will be two tokens: 'bbb' and 'ccc' (including the ' marks).  With the same input
+ * but using group=1, the output would be: bbb and ccc (no ' marks)
+ * </p>
+ * <p>NOTE: This Tokenizer does not output tokens that are of zero length.</p>
+ *
+ * @see Pattern
+ */
+public final class PatternTokenizer extends Tokenizer {
+
+  private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
+  private final OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);
+
+  private final StringBuilder str = new StringBuilder();
+  private int index;
+  
+  private final Pattern pattern;
+  private final int group;
+  private final Matcher matcher;
+
+  /** creates a new PatternTokenizer returning tokens from group (-1 for split functionality) */
+  public PatternTokenizer(Reader input, Pattern pattern, int group) throws IOException {
+    super(input);
+    this.pattern = pattern;
+    this.group = group;
+    fillBuffer(str, input);
+    matcher = pattern.matcher(str);
+    index = 0;
+  }
+
+  @Override
+  public boolean incrementToken() throws IOException {
+    if (index >= str.length()) return false;
+    clearAttributes();
+    if (group >= 0) {
+    
+      // match a specific group
+      while (matcher.find()) {
+        index = matcher.start(group);
+        final int endIndex = matcher.end(group);
+        if (index == endIndex) continue;       
+        termAtt.setEmpty().append(str, index, endIndex);
+        offsetAtt.setOffset(correctOffset(index), correctOffset(endIndex));
+        return true;
+      }
+      
+      index = Integer.MAX_VALUE; // mark exhausted
+      return false;
+      
+    } else {
+    
+      // String.split() functionality
+      while (matcher.find()) {
+        if (matcher.start() - index > 0) {
+          // found a non-zero-length token
+          termAtt.setEmpty().append(str, index, matcher.start());
+          offsetAtt.setOffset(correctOffset(index), correctOffset(matcher.start()));
+          index = matcher.end();
+          return true;
+        }
+        
+        index = matcher.end();
+      }
+      
+      if (str.length() - index == 0) {
+        index = Integer.MAX_VALUE; // mark exhausted
+        return false;
+      }
+      
+      termAtt.setEmpty().append(str, index, str.length());
+      offsetAtt.setOffset(correctOffset(index), correctOffset(str.length()));
+      index = Integer.MAX_VALUE; // mark exhausted
+      return true;
+    }
+  }
+
+  @Override
+  public void end() throws IOException {
+    final int ofs = correctOffset(str.length());
+    offsetAtt.setOffset(ofs, ofs);
+  }
+
+  @Override
+  public void reset(Reader input) throws IOException {
+    super.reset(input);
+    fillBuffer(str, input);
+    matcher.reset(str);
+    index = 0;
+  }
+  
+  // TODO: we should see if we can make this tokenizer work without reading
+  // the entire document into RAM, perhaps with Matcher.hitEnd/requireEnd ?
+  final char[] buffer = new char[8192];
+  private void fillBuffer(StringBuilder sb, Reader input) throws IOException {
+    int len;
+    sb.setLength(0);
+    while ((len = input.read(buffer)) > 0) {
+      sb.append(buffer, 0, len);
+    }
+  }
+}
diff --git a/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/pattern/package.html b/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/pattern/package.html
new file mode 100644
index 0000000..85b56ed
--- /dev/null
+++ b/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/pattern/package.html
@@ -0,0 +1,22 @@
+<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+<html><head></head>
+<body>
+Set of components for pattern-based (regex) analysis.
+</body>
+</html>
diff --git a/lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceCharFilter.java b/lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceCharFilter.java
new file mode 100644
index 0000000..071d601
--- /dev/null
+++ b/lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceCharFilter.java
@@ -0,0 +1,167 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.lucene.analysis.pattern;
+
+import java.io.IOException;
+import java.io.StringReader;
+import java.util.regex.Pattern;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.CharReader;
+import org.apache.lucene.analysis.CharStream;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.WhitespaceTokenizer;
+
+/**
+ * Tests {@link PatternReplaceCharFilter}
+ */
+public class TestPatternReplaceCharFilter extends BaseTokenStreamTestCase {
+  
+  //           1111
+  // 01234567890123
+  // this is test.
+  public void testNothingChange() throws IOException {
+    final String BLOCK = "this is test.";
+    CharStream cs = new PatternReplaceCharFilter( pattern("(aa)\\s+(bb)\\s+(cc)"), "$1$2$3",
+          CharReader.get( new StringReader( BLOCK ) ) );
+    TokenStream ts = new WhitespaceTokenizer(TEST_VERSION_CURRENT, cs );
+    assertTokenStreamContents(ts,
+        new String[] { "this", "is", "test." },
+        new int[] { 0, 5, 8 },
+        new int[] { 4, 7, 13 });
+  }
+  
+  // 012345678
+  // aa bb cc
+  public void testReplaceByEmpty() throws IOException {
+    final String BLOCK = "aa bb cc";
+    CharStream cs = new PatternReplaceCharFilter( pattern("(aa)\\s+(bb)\\s+(cc)"), "",
+          CharReader.get( new StringReader( BLOCK ) ) );
+    TokenStream ts = new WhitespaceTokenizer(TEST_VERSION_CURRENT, cs );
+    assertFalse(ts.incrementToken());
+  }
+  
+  // 012345678
+  // aa bb cc
+  // aa#bb#cc
+  public void test1block1matchSameLength() throws IOException {
+    final String BLOCK = "aa bb cc";
+    CharStream cs = new PatternReplaceCharFilter( pattern("(aa)\\s+(bb)\\s+(cc)"), "$1#$2#$3",
+          CharReader.get( new StringReader( BLOCK ) ) );
+    TokenStream ts = new WhitespaceTokenizer(TEST_VERSION_CURRENT, cs );
+    assertTokenStreamContents(ts,
+        new String[] { "aa#bb#cc" },
+        new int[] { 0 },
+        new int[] { 8 });
+  }
+
+  //           11111
+  // 012345678901234
+  // aa bb cc dd
+  // aa##bb###cc dd
+  public void test1block1matchLonger() throws IOException {
+    final String BLOCK = "aa bb cc dd";
+    CharStream cs = new PatternReplaceCharFilter( pattern("(aa)\\s+(bb)\\s+(cc)"), "$1##$2###$3",
+          CharReader.get( new StringReader( BLOCK ) ) );
+    TokenStream ts = new WhitespaceTokenizer(TEST_VERSION_CURRENT, cs );
+    assertTokenStreamContents(ts,
+        new String[] { "aa##bb###cc", "dd" },
+        new int[] { 0, 9 },
+        new int[] { 8, 11 });
+  }
+
+  // 01234567
+  //  a  a
+  //  aa  aa
+  public void test1block2matchLonger() throws IOException {
+    final String BLOCK = " a  a";
+    CharStream cs = new PatternReplaceCharFilter( pattern("a"), "aa",
+          CharReader.get( new StringReader( BLOCK ) ) );
+    TokenStream ts = new WhitespaceTokenizer(TEST_VERSION_CURRENT, cs );
+    assertTokenStreamContents(ts,
+        new String[] { "aa", "aa" },
+        new int[] { 1, 4 },
+        new int[] { 2, 5 });
+  }
+
+  //           11111
+  // 012345678901234
+  // aa  bb   cc dd
+  // aa#bb dd
+  public void test1block1matchShorter() throws IOException {
+    final String BLOCK = "aa  bb   cc dd";
+    CharStream cs = new PatternReplaceCharFilter( pattern("(aa)\\s+(bb)\\s+(cc)"), "$1#$2",
+          CharReader.get( new StringReader( BLOCK ) ) );
+    TokenStream ts = new WhitespaceTokenizer(TEST_VERSION_CURRENT, cs );
+    assertTokenStreamContents(ts,
+        new String[] { "aa#bb", "dd" },
+        new int[] { 0, 12 },
+        new int[] { 11, 14 });
+  }
+
+  //           111111111122222222223333
+  // 0123456789012345678901234567890123
+  //   aa bb cc --- aa bb aa   bb   cc
+  //   aa  bb  cc --- aa bb aa  bb  cc
+  public void test1blockMultiMatches() throws IOException {
+    final String BLOCK = "  aa bb cc --- aa bb aa   bb   cc";
+    CharStream cs = new PatternReplaceCharFilter( pattern("(aa)\\s+(bb)\\s+(cc)"), "$1  $2  $3",
+          CharReader.get( new StringReader( BLOCK ) ) );
+    TokenStream ts = new WhitespaceTokenizer(TEST_VERSION_CURRENT, cs );
+    assertTokenStreamContents(ts,
+        new String[] { "aa", "bb", "cc", "---", "aa", "bb", "aa", "bb", "cc" },
+        new int[] { 2, 6, 9, 11, 15, 18, 21, 25, 29 },
+        new int[] { 4, 8, 10, 14, 17, 20, 23, 27, 33 });
+  }
+
+  //           11111111112222222222333333333
+  // 012345678901234567890123456789012345678
+  //   aa bb cc --- aa bb aa. bb aa   bb cc
+  //   aa##bb cc --- aa##bb aa. bb aa##bb cc
+  public void test2blocksMultiMatches() throws IOException {
+    final String BLOCK = "  aa bb cc --- aa bb aa. bb aa   bb cc";
+    CharStream cs = new PatternReplaceCharFilter( pattern("(aa)\\s+(bb)"), "$1##$2", ".",
+          CharReader.get( new StringReader( BLOCK ) ) );
+    TokenStream ts = new WhitespaceTokenizer(TEST_VERSION_CURRENT, cs );
+    assertTokenStreamContents(ts,
+        new String[] { "aa##bb", "cc", "---", "aa##bb", "aa.", "bb", "aa##bb", "cc" },
+        new int[] { 2, 8, 11, 15, 21, 25, 28, 36 },
+        new int[] { 7, 10, 14, 20, 24, 27, 35, 38 });
+  }
+
+  //           11111111112222222222333333333
+  // 012345678901234567890123456789012345678
+  //  a bb - ccc . --- bb a . ccc ccc bb
+  //  aa b - c . --- b aa . c c b
+  public void testChain() throws IOException {
+    final String BLOCK = " a bb - ccc . --- bb a . ccc ccc bb";
+    CharStream cs = new PatternReplaceCharFilter( pattern("a"), "aa", ".",
+        CharReader.get( new StringReader( BLOCK ) ) );
+    cs = new PatternReplaceCharFilter( pattern("bb"), "b", ".", cs );
+    cs = new PatternReplaceCharFilter( pattern("ccc"), "c", ".", cs );
+    TokenStream ts = new WhitespaceTokenizer(TEST_VERSION_CURRENT, cs );
+    assertTokenStreamContents(ts,
+        new String[] { "aa", "b", "-", "c", ".", "---", "b", "aa", ".", "c", "c", "b" },
+        new int[] { 1, 3, 6, 8, 12, 14, 18, 21, 23, 25, 29, 33 },
+        new int[] { 2, 5, 7, 11, 13, 17, 20, 22, 24, 28, 32, 35 });
+  }
+  
+  private Pattern pattern( String p ){
+    return Pattern.compile( p );
+  }
+}
diff --git a/lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceFilter.java b/lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceFilter.java
new file mode 100644
index 0000000..41e664b
--- /dev/null
+++ b/lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceFilter.java
@@ -0,0 +1,82 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.lucene.analysis.pattern;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.WhitespaceTokenizer;
+
+import java.io.StringReader;
+import java.util.regex.Pattern;
+
+/**
+ * @version $Id:$
+ */
+public class TestPatternReplaceFilter extends BaseTokenStreamTestCase {
+
+  public void testReplaceAll() throws Exception {
+    String input = "aabfooaabfooabfoob ab caaaaaaaaab";
+    TokenStream ts = new PatternReplaceFilter
+            (new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader(input)),
+                    Pattern.compile("a*b"),
+                    "-", true);
+    assertTokenStreamContents(ts, 
+        new String[] { "-foo-foo-foo-", "-", "c-" });
+  }
+
+  public void testReplaceFirst() throws Exception {
+    String input = "aabfooaabfooabfoob ab caaaaaaaaab";
+    TokenStream ts = new PatternReplaceFilter
+            (new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader(input)),
+                    Pattern.compile("a*b"),
+                    "-", false);
+    assertTokenStreamContents(ts, 
+        new String[] { "-fooaabfooabfoob", "-", "c-" });
+  }
+
+  public void testStripFirst() throws Exception {
+    String input = "aabfooaabfooabfoob ab caaaaaaaaab";
+    TokenStream ts = new PatternReplaceFilter
+            (new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader(input)),
+                    Pattern.compile("a*b"),
+                    null, false);
+    assertTokenStreamContents(ts,
+        new String[] { "fooaabfooabfoob", "", "c" });
+  }
+
+  public void testStripAll() throws Exception {
+    String input = "aabfooaabfooabfoob ab caaaaaaaaab";
+    TokenStream ts = new PatternReplaceFilter
+            (new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader(input)),
+                    Pattern.compile("a*b"),
+                    null, true);
+    assertTokenStreamContents(ts,
+        new String[] { "foofoofoo", "", "c" });
+  }
+
+  public void testReplaceAllWithBackRef() throws Exception {
+    String input = "aabfooaabfooabfoob ab caaaaaaaaab";
+    TokenStream ts = new PatternReplaceFilter
+            (new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader(input)),
+                    Pattern.compile("(a*)b"),
+                    "$1\\$", true);
+    assertTokenStreamContents(ts,
+        new String[] { "aa$fooaa$fooa$foo$", "a$", "caaaaaaaaa$" });
+  }
+
+}
diff --git a/lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/pattern/TestPatternTokenizer.java b/lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/pattern/TestPatternTokenizer.java
new file mode 100644
index 0000000..f3f086e
--- /dev/null
+++ b/lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/pattern/TestPatternTokenizer.java
@@ -0,0 +1,119 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.lucene.analysis.pattern;
+
+import java.io.IOException;
+import java.io.StringReader;
+import java.util.ArrayList;
+import java.util.List;
+import java.util.regex.Pattern;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.CharReader;
+import org.apache.lucene.analysis.CharStream;
+import org.apache.lucene.analysis.charfilter.MappingCharFilter;
+import org.apache.lucene.analysis.charfilter.NormalizeCharMap;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+
+public class TestPatternTokenizer extends BaseTokenStreamTestCase 
+{
+	public void testSplitting() throws Exception 
+  {
+    String qpattern = "\\'([^\\']+)\\'"; // get stuff between "'"
+    String[][] tests = {
+      // group  pattern        input                    output
+      { "-1",   "--",          "aaa--bbb--ccc",         "aaa bbb ccc" },
+      { "-1",   ":",           "aaa:bbb:ccc",           "aaa bbb ccc" },
+      { "-1",   "\\p{Space}",  "aaa   bbb \t\tccc  ",   "aaa bbb ccc" },
+      { "-1",   ":",           "boo:and:foo",           "boo and foo" },
+      { "-1",   "o",           "boo:and:foo",           "b :and:f" },
+      { "0",    ":",           "boo:and:foo",           ": :" },
+      { "0",    qpattern,      "aaa 'bbb' 'ccc'",       "'bbb' 'ccc'" },
+      { "1",    qpattern,      "aaa 'bbb' 'ccc'",       "bbb ccc" }
+    };
+    
+    for( String[] test : tests ) {     
+      TokenStream stream = new PatternTokenizer(new StringReader(test[2]), Pattern.compile(test[1]), Integer.parseInt(test[0]));
+      String out = tsToString( stream );
+      // System.out.println( test[2] + " ==> " + out );
+
+      assertEquals("pattern: "+test[1]+" with input: "+test[2], test[3], out );
+      
+      // Make sure it is the same as if we called 'split'
+      // test disabled, as we remove empty tokens
+      /*if( "-1".equals( test[0] ) ) {
+        String[] split = test[2].split( test[1] );
+        stream = tokenizer.create( new StringReader( test[2] ) );
+        int i=0;
+        for( Token t = stream.next(); null != t; t = stream.next() ) 
+        {
+          assertEquals( "split: "+test[1] + " "+i, split[i++], new String(t.termBuffer(), 0, t.termLength()) );
+        }
+      }*/
+    } 
+	}
+	
+  public void testOffsetCorrection() throws Exception {
+    final String INPUT = "G&uuml;nther G&uuml;nther is here";
+
+    // create MappingCharFilter
+    List<String> mappingRules = new ArrayList<String>();
+    mappingRules.add( "\"&uuml;\" => \"ü\"" );
+    NormalizeCharMap normMap = new NormalizeCharMap();
+    normMap.add("&uuml;", "ü");
+    CharStream charStream = new MappingCharFilter( normMap, CharReader.get( new StringReader( INPUT ) ) );
+
+    // create PatternTokenizer
+    TokenStream stream = new PatternTokenizer(charStream, Pattern.compile("[,;/\\s]+"), -1);
+    assertTokenStreamContents(stream,
+        new String[] { "Günther", "Günther", "is", "here" },
+        new int[] { 0, 13, 26, 29 },
+        new int[] { 12, 25, 28, 33 });
+    
+    charStream = new MappingCharFilter( normMap, CharReader.get( new StringReader( INPUT ) ) );
+    stream = new PatternTokenizer(charStream, Pattern.compile("Günther"), 0);
+    assertTokenStreamContents(stream,
+        new String[] { "Günther", "Günther" },
+        new int[] { 0, 13 },
+        new int[] { 12, 25 });
+  }
+  
+  /** 
+   * TODO: rewrite tests not to use string comparison.
+   * @deprecated only tests TermAttribute!
+   */
+  private static String tsToString(TokenStream in) throws IOException {
+    StringBuilder out = new StringBuilder();
+    CharTermAttribute termAtt = in.addAttribute(CharTermAttribute.class);
+    // extra safety to enforce, that the state is not preserved and also
+    // assign bogus values
+    in.clearAttributes();
+    termAtt.setEmpty().append("bogusTerm");
+    while (in.incrementToken()) {
+      if (out.length() > 0)
+        out.append(' ');
+      out.append(termAtt.toString());
+      in.clearAttributes();
+      termAtt.setEmpty().append("bogusTerm");
+    }
+
+    in.close();
+    return out.toString();
+  }
+}
diff --git a/solr/src/java/org/apache/solr/analysis/PatternReplaceCharFilter.java b/solr/src/java/org/apache/solr/analysis/PatternReplaceCharFilter.java
deleted file mode 100644
index 7f42b54..0000000
--- a/solr/src/java/org/apache/solr/analysis/PatternReplaceCharFilter.java
+++ /dev/null
@@ -1,193 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import java.io.IOException;
-import java.util.LinkedList;
-import java.util.regex.Matcher;
-import java.util.regex.Pattern;
-
-import org.apache.lucene.analysis.charfilter.BaseCharFilter;
-import org.apache.lucene.analysis.CharStream;
-
-/**
- * CharFilter that uses a regular expression for the target of replace string.
- * The pattern match will be done in each "block" in char stream.
- * 
- * <p>
- * ex1) source="aa&nbsp;&nbsp;bb&nbsp;aa&nbsp;bb", pattern="(aa)\\s+(bb)" replacement="$1#$2"<br/>
- * output="aa#bb&nbsp;aa#bb"
- * </p>
- * 
- * NOTE: If you produce a phrase that has different length to source string
- * and the field is used for highlighting for a term of the phrase, you will
- * face a trouble.
- * 
- * <p>
- * ex2) source="aa123bb", pattern="(aa)\\d+(bb)" replacement="$1&nbsp;$2"<br/>
- * output="aa&nbsp;bb"<br/>
- * and you want to search bb and highlight it, you will get<br/>
- * highlight snippet="aa1&lt;em&gt;23bb&lt;/em&gt;"
- * </p>
- * 
- * @version $Id$
- * @since Solr 1.5
- */
-public class PatternReplaceCharFilter extends BaseCharFilter {
-
-  private final Pattern pattern;
-  private final String replacement;
-  private final int maxBlockChars;
-  private final String blockDelimiters;
-  public static final int DEFAULT_MAX_BLOCK_CHARS = 10000;
-
-  private LinkedList<Character> buffer;
-  private int nextCharCounter;
-  private char[] blockBuffer;
-  private int blockBufferLength;
-  private String replaceBlockBuffer;
-  private int replaceBlockBufferOffset;
-  
-  public PatternReplaceCharFilter( Pattern pattern, String replacement, CharStream in ){
-    this( pattern, replacement, DEFAULT_MAX_BLOCK_CHARS, null, in );
-  }
-
-  public PatternReplaceCharFilter( Pattern pattern, String replacement,
-      int maxBlockChars, CharStream in ){
-    this( pattern, replacement, maxBlockChars, null, in );
-  }
-
-  public PatternReplaceCharFilter( Pattern pattern, String replacement,
-      String blockDelimiters, CharStream in ){
-    this( pattern, replacement, DEFAULT_MAX_BLOCK_CHARS, blockDelimiters, in );
-  }
-
-  public PatternReplaceCharFilter( Pattern pattern, String replacement,
-      int maxBlockChars, String blockDelimiters, CharStream in ){
-    super( in );
-    this.pattern = pattern;
-    this.replacement = replacement;
-    if( maxBlockChars < 1 )
-      throw new IllegalArgumentException( "maxBlockChars should be greater than 0, but it is " + maxBlockChars );
-    this.maxBlockChars = maxBlockChars;
-    this.blockDelimiters = blockDelimiters;
-    blockBuffer = new char[maxBlockChars];
-  }
-  
-  private boolean prepareReplaceBlock() throws IOException {
-    while( true ){
-      if( replaceBlockBuffer != null && replaceBlockBuffer.length() > replaceBlockBufferOffset )
-        return true;
-      // prepare block buffer
-      blockBufferLength = 0;
-      while( true ){
-        int c = nextChar();
-        if( c == -1 ) break;
-        blockBuffer[blockBufferLength++] = (char)c;
-        // end of block?
-        boolean foundDelimiter =
-          ( blockDelimiters != null ) &&
-          ( blockDelimiters.length() > 0 ) &&
-          blockDelimiters.indexOf( c ) >= 0;
-        if( foundDelimiter ||
-            blockBufferLength >= maxBlockChars ) break;
-      }
-      // block buffer available?
-      if( blockBufferLength == 0 ) return false;
-      replaceBlockBuffer = getReplaceBlock( blockBuffer, 0, blockBufferLength );
-      replaceBlockBufferOffset = 0;
-    }
-  }
-
-  public int read() throws IOException {
-    while( prepareReplaceBlock() ){
-      return replaceBlockBuffer.charAt( replaceBlockBufferOffset++ );
-    }
-    return -1;
-  }
-
-  public int read(char[] cbuf, int off, int len) throws IOException {
-    char[] tmp = new char[len];
-    int l = input.read(tmp, 0, len);
-    if (l != -1) {
-      for(int i = 0; i < l; i++)
-        pushLastChar(tmp[i]);
-    }
-    l = 0;
-    for(int i = off; i < off + len; i++) {
-      int c = read();
-      if (c == -1) break;
-      cbuf[i] = (char) c;
-      l++;
-    }
-    return l == 0 ? -1 : l;
-  }
-
-  private int nextChar() throws IOException {
-    if (buffer != null && !buffer.isEmpty()) {
-      nextCharCounter++;
-      return buffer.removeFirst().charValue();
-    }
-    int c = input.read();
-    if( c != -1 )
-      nextCharCounter++;
-    return c;
-  }
-
-  private void pushLastChar(int c) {
-    if (buffer == null) {
-      buffer = new LinkedList<Character>();
-    }
-    buffer.addLast(new Character((char) c));
-  }
-  
-  String getReplaceBlock( String block ){
-    char[] blockChars = block.toCharArray();
-    return getReplaceBlock( blockChars, 0, blockChars.length );
-  }
-    
-  String getReplaceBlock( char block[], int offset, int length ){
-    StringBuffer replaceBlock = new StringBuffer();
-    String sourceBlock = new String( block, offset, length );
-    Matcher m = pattern.matcher( sourceBlock );
-    int lastMatchOffset = 0, lastDiff = 0;
-    while( m.find() ){
-      m.appendReplacement( replaceBlock, replacement );
-      // record cumulative diff for the offset correction
-      int diff = replaceBlock.length() - lastMatchOffset - lastDiff - ( m.end( 0 ) - lastMatchOffset );
-      if (diff != 0) {
-        int prevCumulativeDiff = getLastCumulativeDiff();
-        if (diff > 0) {
-          for(int i = 0; i < diff; i++){
-            addOffCorrectMap(nextCharCounter - length + m.end( 0 ) + i - prevCumulativeDiff,
-                prevCumulativeDiff - 1 - i);
-          }
-        } else {
-          addOffCorrectMap(nextCharCounter - length + m.end( 0 ) + diff - prevCumulativeDiff,
-              prevCumulativeDiff - diff);
-        }
-      }
-      // save last offsets
-      lastMatchOffset = m.end( 0 );
-      lastDiff = diff;
-    }
-    // copy remaining of the part of source block
-    m.appendTail( replaceBlock );
-    return replaceBlock.toString();
-  }
-}
diff --git a/solr/src/java/org/apache/solr/analysis/PatternReplaceCharFilterFactory.java b/solr/src/java/org/apache/solr/analysis/PatternReplaceCharFilterFactory.java
index 19b97ee..bb45fa1 100644
--- a/solr/src/java/org/apache/solr/analysis/PatternReplaceCharFilterFactory.java
+++ b/solr/src/java/org/apache/solr/analysis/PatternReplaceCharFilterFactory.java
@@ -22,6 +22,7 @@ import java.util.regex.Pattern;
 import java.util.regex.PatternSyntaxException;
 
 import org.apache.lucene.analysis.CharStream;
+import org.apache.lucene.analysis.pattern.PatternReplaceCharFilter;
 
 /**
  * 
diff --git a/solr/src/java/org/apache/solr/analysis/PatternReplaceFilter.java b/solr/src/java/org/apache/solr/analysis/PatternReplaceFilter.java
deleted file mode 100644
index b9831fc..0000000
--- a/solr/src/java/org/apache/solr/analysis/PatternReplaceFilter.java
+++ /dev/null
@@ -1,84 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.TokenFilter;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-
-import java.util.regex.Pattern;
-import java.util.regex.Matcher;
-import java.io.IOException;
-
-/**
- * A TokenFilter which applies a Pattern to each token in the stream,
- * replacing match occurances with the specified replacement string.
- *
- * <p>
- * <b>Note:</b> Depending on the input and the pattern used and the input
- * TokenStream, this TokenFilter may produce Tokens whose text is the empty
- * string.
- * </p>
- * 
- * @version $Id:$
- * @see Pattern
- */
-public final class PatternReplaceFilter extends TokenFilter {
-  private final Pattern p;
-  private final String replacement;
-  private final boolean all;
-  private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
-  private final Matcher m;
-
-  /**
-   * Constructs an instance to replace either the first, or all occurances
-   *
-   * @param in the TokenStream to process
-   * @param p the patterm to apply to each Token
-   * @param replacement the "replacement string" to substitute, if null a
-   *        blank string will be used. Note that this is not the literal
-   *        string that will be used, '$' and '\' have special meaning.
-   * @param all if true, all matches will be replaced otherwise just the first match.
-   * @see Matcher#quoteReplacement
-   */
-  public PatternReplaceFilter(TokenStream in,
-                              Pattern p,
-                              String replacement,
-                              boolean all) {
-    super(in);
-    this.p=p;
-    this.replacement = (null == replacement) ? "" : replacement;
-    this.all=all;
-    this.m = p.matcher(termAtt);
-  }
-
-  @Override
-  public boolean incrementToken() throws IOException {
-    if (!input.incrementToken()) return false;
-    
-    m.reset();
-    if (m.find()) {
-      // replaceAll/replaceFirst will reset() this previous find.
-      String transformed = all ? m.replaceAll(replacement) : m.replaceFirst(replacement);
-      termAtt.setEmpty().append(transformed);
-    }
-
-    return true;
-  }
-
-}
diff --git a/solr/src/java/org/apache/solr/analysis/PatternReplaceFilterFactory.java b/solr/src/java/org/apache/solr/analysis/PatternReplaceFilterFactory.java
index c45d139..e4231ef 100644
--- a/solr/src/java/org/apache/solr/analysis/PatternReplaceFilterFactory.java
+++ b/solr/src/java/org/apache/solr/analysis/PatternReplaceFilterFactory.java
@@ -17,6 +17,7 @@
 
 package org.apache.solr.analysis;
 import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.pattern.PatternReplaceFilter;
 
 import java.util.Map;
 import java.util.regex.Pattern;
diff --git a/solr/src/java/org/apache/solr/analysis/PatternTokenizer.java b/solr/src/java/org/apache/solr/analysis/PatternTokenizer.java
deleted file mode 100644
index b387767..0000000
--- a/solr/src/java/org/apache/solr/analysis/PatternTokenizer.java
+++ /dev/null
@@ -1,139 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import java.io.IOException;
-import java.io.Reader;
-import java.util.regex.Matcher;
-import java.util.regex.Pattern;
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
-import org.apache.commons.io.IOUtils;
-
-/**
- * This tokenizer uses regex pattern matching to construct distinct tokens
- * for the input stream.  It takes two arguments:  "pattern" and "group".
- * <p/>
- * <ul>
- * <li>"pattern" is the regular expression.</li>
- * <li>"group" says which group to extract into tokens.</li>
- *  </ul>
- * <p>
- * group=-1 (the default) is equivalent to "split".  In this case, the tokens will
- * be equivalent to the output from (without empty tokens):
- * {@link String#split(java.lang.String)}
- * </p>
- * <p>
- * Using group >= 0 selects the matching group as the token.  For example, if you have:<br/>
- * <pre>
- *  pattern = \'([^\']+)\'
- *  group = 0
- *  input = aaa 'bbb' 'ccc'
- *</pre>
- * the output will be two tokens: 'bbb' and 'ccc' (including the ' marks).  With the same input
- * but using group=1, the output would be: bbb and ccc (no ' marks)
- * </p>
- * <p>NOTE: This Tokenizer does not output tokens that are of zero length.</p>
- *
- * @version $Id$
- * @see Pattern
- */
-public final class PatternTokenizer extends Tokenizer {
-
-  private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
-  private final OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);
-
-  private String str;
-  private int index;
-  
-  private final Pattern pattern;
-  private final int group;
-  private final Matcher matcher;
-
-  /** creates a new PatternTokenizer returning tokens from group (-1 for split functionality) */
-  public PatternTokenizer(Reader input, Pattern pattern, int group) throws IOException {
-    super(input);
-    this.pattern = pattern;
-    this.group = group;
-    str = IOUtils.toString(input);
-    matcher = pattern.matcher(str);
-    index = 0;
-  }
-
-  @Override
-  public boolean incrementToken() throws IOException {
-    if (index >= str.length()) return false;
-    clearAttributes();
-    if (group >= 0) {
-    
-      // match a specific group
-      while (matcher.find()) {
-        final String match = matcher.group(group);
-        if (match.length() == 0) continue;
-        termAtt.setEmpty().append(match);
-        index = matcher.start(group);
-        offsetAtt.setOffset(correctOffset(index), correctOffset(matcher.end(group)));
-        return true;
-      }
-      
-      index = Integer.MAX_VALUE; // mark exhausted
-      return false;
-      
-    } else {
-    
-      // String.split() functionality
-      while (matcher.find()) {
-        if (matcher.start() - index > 0) {
-          // found a non-zero-length token
-          termAtt.setEmpty().append(str, index, matcher.start());
-          offsetAtt.setOffset(correctOffset(index), correctOffset(matcher.start()));
-          index = matcher.end();
-          return true;
-        }
-        
-        index = matcher.end();
-      }
-      
-      if (str.length() - index == 0) {
-        index = Integer.MAX_VALUE; // mark exhausted
-        return false;
-      }
-      
-      termAtt.setEmpty().append(str, index, str.length());
-      offsetAtt.setOffset(correctOffset(index), correctOffset(str.length()));
-      index = Integer.MAX_VALUE; // mark exhausted
-      return true;
-    }
-  }
-
-  @Override
-  public void end() throws IOException {
-    final int ofs = correctOffset(str.length());
-    offsetAtt.setOffset(ofs, ofs);
-  }
-
-  @Override
-  public void reset(Reader input) throws IOException {
-    super.reset(input);
-    str = IOUtils.toString(input);
-    matcher.reset(str);
-    index = 0;
-  }
-
-}
diff --git a/solr/src/java/org/apache/solr/analysis/PatternTokenizerFactory.java b/solr/src/java/org/apache/solr/analysis/PatternTokenizerFactory.java
index 635ad7f..242f319 100644
--- a/solr/src/java/org/apache/solr/analysis/PatternTokenizerFactory.java
+++ b/solr/src/java/org/apache/solr/analysis/PatternTokenizerFactory.java
@@ -27,6 +27,7 @@ import java.util.regex.Pattern;
 
 import org.apache.lucene.analysis.Token;
 import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.pattern.PatternTokenizer;
 import org.apache.solr.common.SolrException;
 
 
diff --git a/solr/src/test/org/apache/solr/analysis/TestPatternReplaceCharFilter.java b/solr/src/test/org/apache/solr/analysis/TestPatternReplaceCharFilter.java
deleted file mode 100644
index fe35f05..0000000
--- a/solr/src/test/org/apache/solr/analysis/TestPatternReplaceCharFilter.java
+++ /dev/null
@@ -1,184 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import java.io.IOException;
-import java.io.StringReader;
-import java.util.HashMap;
-import java.util.Map;
-import java.util.regex.Pattern;
-
-import org.apache.lucene.analysis.CharReader;
-import org.apache.lucene.analysis.CharStream;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.WhitespaceTokenizer;
-
-/**
- * 
- * @version $Id$
- *
- */
-public class TestPatternReplaceCharFilter extends BaseTokenTestCase {
-  
-  //           1111
-  // 01234567890123
-  // this is test.
-  public void testNothingChange() throws IOException {
-    final String BLOCK = "this is test.";
-    PatternReplaceCharFilterFactory factory = new PatternReplaceCharFilterFactory();
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("pattern", "(aa)\\s+(bb)\\s+(cc)");
-    args.put("replacement", "$1$2$3");
-    factory.init(args);
-    CharStream cs = factory.create(
-          CharReader.get( new StringReader( BLOCK ) ) );
-    TokenStream ts = new WhitespaceTokenizer(DEFAULT_VERSION, cs );
-    assertTokenStreamContents(ts,
-        new String[] { "this", "is", "test." },
-        new int[] { 0, 5, 8 },
-        new int[] { 4, 7, 13 });
-  }
-  
-  // 012345678
-  // aa bb cc
-  public void testReplaceByEmpty() throws IOException {
-    final String BLOCK = "aa bb cc";
-    PatternReplaceCharFilterFactory factory = new PatternReplaceCharFilterFactory();
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("pattern", "(aa)\\s+(bb)\\s+(cc)");
-    factory.init(args);
-    CharStream cs = factory.create(
-          CharReader.get( new StringReader( BLOCK ) ) );
-    TokenStream ts = new WhitespaceTokenizer(DEFAULT_VERSION, cs );
-    assertFalse(ts.incrementToken());
-  }
-  
-  // 012345678
-  // aa bb cc
-  // aa#bb#cc
-  public void test1block1matchSameLength() throws IOException {
-    final String BLOCK = "aa bb cc";
-    PatternReplaceCharFilterFactory factory = new PatternReplaceCharFilterFactory();
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("pattern", "(aa)\\s+(bb)\\s+(cc)");
-    args.put("replacement", "$1#$2#$3");
-    factory.init(args);
-    CharStream cs = factory.create(
-          CharReader.get( new StringReader( BLOCK ) ) );
-    TokenStream ts = new WhitespaceTokenizer(DEFAULT_VERSION, cs );
-    assertTokenStreamContents(ts,
-        new String[] { "aa#bb#cc" },
-        new int[] { 0 },
-        new int[] { 8 });
-  }
-
-  //           11111
-  // 012345678901234
-  // aa bb cc dd
-  // aa##bb###cc dd
-  public void test1block1matchLonger() throws IOException {
-    final String BLOCK = "aa bb cc dd";
-    CharStream cs = new PatternReplaceCharFilter( pattern("(aa)\\s+(bb)\\s+(cc)"), "$1##$2###$3",
-          CharReader.get( new StringReader( BLOCK ) ) );
-    TokenStream ts = new WhitespaceTokenizer(DEFAULT_VERSION, cs );
-    assertTokenStreamContents(ts,
-        new String[] { "aa##bb###cc", "dd" },
-        new int[] { 0, 9 },
-        new int[] { 8, 11 });
-  }
-
-  // 01234567
-  //  a  a
-  //  aa  aa
-  public void test1block2matchLonger() throws IOException {
-    final String BLOCK = " a  a";
-    CharStream cs = new PatternReplaceCharFilter( pattern("a"), "aa",
-          CharReader.get( new StringReader( BLOCK ) ) );
-    TokenStream ts = new WhitespaceTokenizer(DEFAULT_VERSION, cs );
-    assertTokenStreamContents(ts,
-        new String[] { "aa", "aa" },
-        new int[] { 1, 4 },
-        new int[] { 2, 5 });
-  }
-
-  //           11111
-  // 012345678901234
-  // aa  bb   cc dd
-  // aa#bb dd
-  public void test1block1matchShorter() throws IOException {
-    final String BLOCK = "aa  bb   cc dd";
-    CharStream cs = new PatternReplaceCharFilter( pattern("(aa)\\s+(bb)\\s+(cc)"), "$1#$2",
-          CharReader.get( new StringReader( BLOCK ) ) );
-    TokenStream ts = new WhitespaceTokenizer(DEFAULT_VERSION, cs );
-    assertTokenStreamContents(ts,
-        new String[] { "aa#bb", "dd" },
-        new int[] { 0, 12 },
-        new int[] { 11, 14 });
-  }
-
-  //           111111111122222222223333
-  // 0123456789012345678901234567890123
-  //   aa bb cc --- aa bb aa   bb   cc
-  //   aa  bb  cc --- aa bb aa  bb  cc
-  public void test1blockMultiMatches() throws IOException {
-    final String BLOCK = "  aa bb cc --- aa bb aa   bb   cc";
-    CharStream cs = new PatternReplaceCharFilter( pattern("(aa)\\s+(bb)\\s+(cc)"), "$1  $2  $3",
-          CharReader.get( new StringReader( BLOCK ) ) );
-    TokenStream ts = new WhitespaceTokenizer(DEFAULT_VERSION, cs );
-    assertTokenStreamContents(ts,
-        new String[] { "aa", "bb", "cc", "---", "aa", "bb", "aa", "bb", "cc" },
-        new int[] { 2, 6, 9, 11, 15, 18, 21, 25, 29 },
-        new int[] { 4, 8, 10, 14, 17, 20, 23, 27, 33 });
-  }
-
-  //           11111111112222222222333333333
-  // 012345678901234567890123456789012345678
-  //   aa bb cc --- aa bb aa. bb aa   bb cc
-  //   aa##bb cc --- aa##bb aa. bb aa##bb cc
-  public void test2blocksMultiMatches() throws IOException {
-    final String BLOCK = "  aa bb cc --- aa bb aa. bb aa   bb cc";
-    CharStream cs = new PatternReplaceCharFilter( pattern("(aa)\\s+(bb)"), "$1##$2", ".",
-          CharReader.get( new StringReader( BLOCK ) ) );
-    TokenStream ts = new WhitespaceTokenizer(DEFAULT_VERSION, cs );
-    assertTokenStreamContents(ts,
-        new String[] { "aa##bb", "cc", "---", "aa##bb", "aa.", "bb", "aa##bb", "cc" },
-        new int[] { 2, 8, 11, 15, 21, 25, 28, 36 },
-        new int[] { 7, 10, 14, 20, 24, 27, 35, 38 });
-  }
-
-  //           11111111112222222222333333333
-  // 012345678901234567890123456789012345678
-  //  a bb - ccc . --- bb a . ccc ccc bb
-  //  aa b - c . --- b aa . c c b
-  public void testChain() throws IOException {
-    final String BLOCK = " a bb - ccc . --- bb a . ccc ccc bb";
-    CharStream cs = new PatternReplaceCharFilter( pattern("a"), "aa", ".",
-        CharReader.get( new StringReader( BLOCK ) ) );
-    cs = new PatternReplaceCharFilter( pattern("bb"), "b", ".", cs );
-    cs = new PatternReplaceCharFilter( pattern("ccc"), "c", ".", cs );
-    TokenStream ts = new WhitespaceTokenizer(DEFAULT_VERSION, cs );
-    assertTokenStreamContents(ts,
-        new String[] { "aa", "b", "-", "c", ".", "---", "b", "aa", ".", "c", "c", "b" },
-        new int[] { 1, 3, 6, 8, 12, 14, 18, 21, 23, 25, 29, 33 },
-        new int[] { 2, 5, 7, 11, 13, 17, 20, 22, 24, 28, 32, 35 });
-  }
-  
-  private Pattern pattern( String p ){
-    return Pattern.compile( p );
-  }
-}
diff --git a/solr/src/test/org/apache/solr/analysis/TestPatternReplaceCharFilterFactory.java b/solr/src/test/org/apache/solr/analysis/TestPatternReplaceCharFilterFactory.java
new file mode 100644
index 0000000..983474e
--- /dev/null
+++ b/solr/src/test/org/apache/solr/analysis/TestPatternReplaceCharFilterFactory.java
@@ -0,0 +1,86 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import java.io.IOException;
+import java.io.StringReader;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.lucene.analysis.CharReader;
+import org.apache.lucene.analysis.CharStream;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.WhitespaceTokenizer;
+
+/**
+ * Simple tests to ensure this factory is working
+ */
+public class TestPatternReplaceCharFilterFactory extends BaseTokenTestCase {
+  
+  //           1111
+  // 01234567890123
+  // this is test.
+  public void testNothingChange() throws IOException {
+    final String BLOCK = "this is test.";
+    PatternReplaceCharFilterFactory factory = new PatternReplaceCharFilterFactory();
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("pattern", "(aa)\\s+(bb)\\s+(cc)");
+    args.put("replacement", "$1$2$3");
+    factory.init(args);
+    CharStream cs = factory.create(
+          CharReader.get( new StringReader( BLOCK ) ) );
+    TokenStream ts = new WhitespaceTokenizer(DEFAULT_VERSION, cs );
+    assertTokenStreamContents(ts,
+        new String[] { "this", "is", "test." },
+        new int[] { 0, 5, 8 },
+        new int[] { 4, 7, 13 });
+  }
+  
+  // 012345678
+  // aa bb cc
+  public void testReplaceByEmpty() throws IOException {
+    final String BLOCK = "aa bb cc";
+    PatternReplaceCharFilterFactory factory = new PatternReplaceCharFilterFactory();
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("pattern", "(aa)\\s+(bb)\\s+(cc)");
+    factory.init(args);
+    CharStream cs = factory.create(
+          CharReader.get( new StringReader( BLOCK ) ) );
+    TokenStream ts = new WhitespaceTokenizer(DEFAULT_VERSION, cs );
+    assertFalse(ts.incrementToken());
+  }
+  
+  // 012345678
+  // aa bb cc
+  // aa#bb#cc
+  public void test1block1matchSameLength() throws IOException {
+    final String BLOCK = "aa bb cc";
+    PatternReplaceCharFilterFactory factory = new PatternReplaceCharFilterFactory();
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("pattern", "(aa)\\s+(bb)\\s+(cc)");
+    args.put("replacement", "$1#$2#$3");
+    factory.init(args);
+    CharStream cs = factory.create(
+          CharReader.get( new StringReader( BLOCK ) ) );
+    TokenStream ts = new WhitespaceTokenizer(DEFAULT_VERSION, cs );
+    assertTokenStreamContents(ts,
+        new String[] { "aa#bb#cc" },
+        new int[] { 0 },
+        new int[] { 8 });
+  }
+}
diff --git a/solr/src/test/org/apache/solr/analysis/TestPatternReplaceFilter.java b/solr/src/test/org/apache/solr/analysis/TestPatternReplaceFilter.java
deleted file mode 100644
index 6d9b30f..0000000
--- a/solr/src/test/org/apache/solr/analysis/TestPatternReplaceFilter.java
+++ /dev/null
@@ -1,81 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.WhitespaceTokenizer;
-
-import java.io.StringReader;
-import java.util.regex.Pattern;
-
-/**
- * @version $Id:$
- */
-public class TestPatternReplaceFilter extends BaseTokenTestCase {
-
-  public void testReplaceAll() throws Exception {
-    String input = "aabfooaabfooabfoob ab caaaaaaaaab";
-    TokenStream ts = new PatternReplaceFilter
-            (new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(input)),
-                    Pattern.compile("a*b"),
-                    "-", true);
-    assertTokenStreamContents(ts, 
-        new String[] { "-foo-foo-foo-", "-", "c-" });
-  }
-
-  public void testReplaceFirst() throws Exception {
-    String input = "aabfooaabfooabfoob ab caaaaaaaaab";
-    TokenStream ts = new PatternReplaceFilter
-            (new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(input)),
-                    Pattern.compile("a*b"),
-                    "-", false);
-    assertTokenStreamContents(ts, 
-        new String[] { "-fooaabfooabfoob", "-", "c-" });
-  }
-
-  public void testStripFirst() throws Exception {
-    String input = "aabfooaabfooabfoob ab caaaaaaaaab";
-    TokenStream ts = new PatternReplaceFilter
-            (new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(input)),
-                    Pattern.compile("a*b"),
-                    null, false);
-    assertTokenStreamContents(ts,
-        new String[] { "fooaabfooabfoob", "", "c" });
-  }
-
-  public void testStripAll() throws Exception {
-    String input = "aabfooaabfooabfoob ab caaaaaaaaab";
-    TokenStream ts = new PatternReplaceFilter
-            (new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(input)),
-                    Pattern.compile("a*b"),
-                    null, true);
-    assertTokenStreamContents(ts,
-        new String[] { "foofoofoo", "", "c" });
-  }
-
-  public void testReplaceAllWithBackRef() throws Exception {
-    String input = "aabfooaabfooabfoob ab caaaaaaaaab";
-    TokenStream ts = new PatternReplaceFilter
-            (new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(input)),
-                    Pattern.compile("(a*)b"),
-                    "$1\\$", true);
-    assertTokenStreamContents(ts,
-        new String[] { "aa$fooaa$fooa$foo$", "a$", "caaaaaaaaa$" });
-  }
-
-}
diff --git a/solr/src/test/org/apache/solr/analysis/TestPatternReplaceFilterFactory.java b/solr/src/test/org/apache/solr/analysis/TestPatternReplaceFilterFactory.java
new file mode 100644
index 0000000..485fdd7
--- /dev/null
+++ b/solr/src/test/org/apache/solr/analysis/TestPatternReplaceFilterFactory.java
@@ -0,0 +1,45 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.WhitespaceTokenizer;
+
+import java.io.StringReader;
+import java.util.HashMap;
+import java.util.Map;
+
+/**
+ * Simple tests to ensure this factory is working
+ */
+public class TestPatternReplaceFilterFactory extends BaseTokenTestCase {
+
+  public void testReplaceAll() throws Exception {
+    String input = "aabfooaabfooabfoob ab caaaaaaaaab";
+    PatternReplaceFilterFactory factory = new PatternReplaceFilterFactory();
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("pattern", "a*b");
+    args.put("replacement", "-");
+    factory.init(args);
+    TokenStream ts = factory.create
+            (new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(input)));
+                   
+    assertTokenStreamContents(ts, 
+        new String[] { "-foo-foo-foo-", "-", "c-" });
+  }
+}
diff --git a/solr/src/test/org/apache/solr/analysis/TestPatternTokenizerFactory.java b/solr/src/test/org/apache/solr/analysis/TestPatternTokenizerFactory.java
index 4dd86a2..1361775 100644
--- a/solr/src/test/org/apache/solr/analysis/TestPatternTokenizerFactory.java
+++ b/solr/src/test/org/apache/solr/analysis/TestPatternTokenizerFactory.java
@@ -17,120 +17,25 @@
 
 package org.apache.solr.analysis;
 
-import java.io.IOException;
 import java.io.StringReader;
-import java.util.ArrayList;
 import java.util.HashMap;
-import java.util.List;
 import java.util.Map;
 
-import org.apache.lucene.analysis.CharReader;
-import org.apache.lucene.analysis.CharStream;
-import org.apache.lucene.analysis.charfilter.MappingCharFilter;
-import org.apache.lucene.analysis.charfilter.NormalizeCharMap;
 import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
 
+/** Simple Tests to ensure this factory is working */
 public class TestPatternTokenizerFactory extends BaseTokenTestCase 
 {
-	public void testSplitting() throws Exception 
-  {
-    String qpattern = "\\'([^\\']+)\\'"; // get stuff between "'"
-    String[][] tests = {
-      // group  pattern        input                    output
-      { "-1",   "--",          "aaa--bbb--ccc",         "aaa bbb ccc" },
-      { "-1",   ":",           "aaa:bbb:ccc",           "aaa bbb ccc" },
-      { "-1",   "\\p{Space}",  "aaa   bbb \t\tccc  ",   "aaa bbb ccc" },
-      { "-1",   ":",           "boo:and:foo",           "boo and foo" },
-      { "-1",   "o",           "boo:and:foo",           "b :and:f" },
-      { "0",    ":",           "boo:and:foo",           ": :" },
-      { "0",    qpattern,      "aaa 'bbb' 'ccc'",       "'bbb' 'ccc'" },
-      { "1",    qpattern,      "aaa 'bbb' 'ccc'",       "bbb ccc" }
-    };
-    
-    
-    Map<String,String> args = new HashMap<String, String>();
-    for( String[] test : tests ) {
-      args.put( PatternTokenizerFactory.GROUP, test[0] );
-      args.put( PatternTokenizerFactory.PATTERN, test[1] );
-
-      PatternTokenizerFactory tokenizer = new PatternTokenizerFactory();
-      tokenizer.init( args );
-      
-      TokenStream stream = tokenizer.create( new StringReader( test[2] ) );
-      String out = tsToString( stream );
-      // System.out.println( test[2] + " ==> " + out );
-
-      assertEquals("pattern: "+test[1]+" with input: "+test[2], test[3], out );
-      
-      // Make sure it is the same as if we called 'split'
-      // test disabled, as we remove empty tokens
-      /*if( "-1".equals( test[0] ) ) {
-        String[] split = test[2].split( test[1] );
-        stream = tokenizer.create( new StringReader( test[2] ) );
-        int i=0;
-        for( Token t = stream.next(); null != t; t = stream.next() ) 
-        {
-          assertEquals( "split: "+test[1] + " "+i, split[i++], new String(t.termBuffer(), 0, t.termLength()) );
-        }
-      }*/
-    } 
-	}
-	
-  public void testOffsetCorrection() throws Exception {
-    final String INPUT = "G&uuml;nther G&uuml;nther is here";
-
-    // create MappingCharFilter
-    MappingCharFilterFactory cfFactory = new MappingCharFilterFactory();
-    List<String> mappingRules = new ArrayList<String>();
-    mappingRules.add( "\"&uuml;\" => \"ü\"" );
-    NormalizeCharMap normMap = new NormalizeCharMap();
-    cfFactory.parseRules( mappingRules, normMap );
-    CharStream charStream = new MappingCharFilter( normMap, CharReader.get( new StringReader( INPUT ) ) );
+  public void testFactory() throws Exception {
+    final String INPUT = "Günther Günther is here";
 
     // create PatternTokenizer
     Map<String,String> args = new HashMap<String, String>();
     args.put( PatternTokenizerFactory.PATTERN, "[,;/\\s]+" );
     PatternTokenizerFactory tokFactory = new PatternTokenizerFactory();
     tokFactory.init( args );
-    TokenStream stream = tokFactory.create( charStream );
+    TokenStream stream = tokFactory.create( new StringReader(INPUT) );
     assertTokenStreamContents(stream,
-        new String[] { "Günther", "Günther", "is", "here" },
-        new int[] { 0, 13, 26, 29 },
-        new int[] { 12, 25, 28, 33 });
-    
-    charStream = new MappingCharFilter( normMap, CharReader.get( new StringReader( INPUT ) ) );
-    args.put( PatternTokenizerFactory.PATTERN, "Günther" );
-    args.put( PatternTokenizerFactory.GROUP, "0" );
-    tokFactory = new PatternTokenizerFactory();
-    tokFactory.init( args );
-    stream = tokFactory.create( charStream );
-    assertTokenStreamContents(stream,
-        new String[] { "Günther", "Günther" },
-        new int[] { 0, 13 },
-        new int[] { 12, 25 });
-  }
-  
-  /** 
-   * TODO: rewrite tests not to use string comparison.
-   * @deprecated only tests TermAttribute!
-   */
-  private static String tsToString(TokenStream in) throws IOException {
-    StringBuilder out = new StringBuilder();
-    CharTermAttribute termAtt = in.addAttribute(CharTermAttribute.class);
-    // extra safety to enforce, that the state is not preserved and also
-    // assign bogus values
-    in.clearAttributes();
-    termAtt.setEmpty().append("bogusTerm");
-    while (in.incrementToken()) {
-      if (out.length() > 0)
-        out.append(' ');
-      out.append(termAtt.toString());
-      in.clearAttributes();
-      termAtt.setEmpty().append("bogusTerm");
-    }
-
-    in.close();
-    return out.toString();
+        new String[] { "Günther", "Günther", "is", "here" });
   }
 }

