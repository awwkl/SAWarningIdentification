GitDiffStart: b83dde502bc8ef4a570d53bbb3423ced8c69030a | Sat May 19 20:45:41 2012 +0000
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/Codec.java b/lucene/core/src/java/org/apache/lucene/codecs/Codec.java
index 98f130a..8735f4f 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/Codec.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/Codec.java
@@ -71,6 +71,7 @@ public abstract class Codec implements NamedSPILoader.NamedSPI {
       docValuesFormat().files(info, files);
       normsFormat().files(info, files);
     }
+    segmentInfosFormat().files(info, files);
     // never inside CFS
     liveDocsFormat().files(info, files);
   }
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/SegmentInfosFormat.java b/lucene/core/src/java/org/apache/lucene/codecs/SegmentInfosFormat.java
index bccf03a..d42f813 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/SegmentInfosFormat.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/SegmentInfosFormat.java
@@ -17,6 +17,9 @@ package org.apache.lucene.codecs;
  * limitations under the License.
  */
 
+import java.util.Set;
+
+import org.apache.lucene.index.SegmentInfo;
 import org.apache.lucene.index.SegmentInfos; // javadocs
 
 /**
@@ -29,6 +32,9 @@ import org.apache.lucene.index.SegmentInfos; // javadocs
  * @see SegmentInfos
  * @lucene.experimental
  */
+
+// nocommit rename (remove the s?)
+
 // TODO: would be great to handle this situation better.
 // ideally a custom implementation could implement two-phase commit differently,
 // (e.g. atomic rename), and ideally all versions of lucene could still read it.
@@ -39,4 +45,5 @@ import org.apache.lucene.index.SegmentInfos; // javadocs
 public abstract class SegmentInfosFormat {
   public abstract SegmentInfosReader getSegmentInfosReader();
   public abstract SegmentInfosWriter getSegmentInfosWriter();
+  public abstract void files(SegmentInfo info, Set<String> files);
 }
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/SegmentInfosReader.java b/lucene/core/src/java/org/apache/lucene/codecs/SegmentInfosReader.java
index 0aa3e65..37f24df 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/SegmentInfosReader.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/SegmentInfosReader.java
@@ -19,6 +19,7 @@ package org.apache.lucene.codecs;
 
 import java.io.IOException;
 
+import org.apache.lucene.index.SegmentInfo;
 import org.apache.lucene.index.SegmentInfos;
 import org.apache.lucene.store.ChecksumIndexInput;
 import org.apache.lucene.store.Directory;
@@ -28,6 +29,9 @@ import org.apache.lucene.store.IOContext;
  * Specifies an API for classes that can read {@link SegmentInfos} information.
  * @lucene.experimental
  */
+
+// nocommit rename (remove the s?)
+
 public abstract class SegmentInfosReader {
 
   /**
@@ -38,5 +42,5 @@ public abstract class SegmentInfosReader {
    * @param infos empty instance to be populated with data
    * @throws IOException
    */
-  public abstract void read(Directory directory, String segmentsFileName, ChecksumIndexInput header, SegmentInfos infos, IOContext context) throws IOException;
+  public abstract SegmentInfo read(Directory directory, String segmentName) throws IOException;
 }
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/SegmentInfosWriter.java b/lucene/core/src/java/org/apache/lucene/codecs/SegmentInfosWriter.java
index a00ecf9..9f4b39e 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/SegmentInfosWriter.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/SegmentInfosWriter.java
@@ -19,6 +19,8 @@ package org.apache.lucene.codecs;
 
 import java.io.IOException;
 
+import org.apache.lucene.index.FieldInfos;
+import org.apache.lucene.index.SegmentInfo;
 import org.apache.lucene.index.SegmentInfos;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IOContext;
@@ -28,6 +30,9 @@ import org.apache.lucene.store.IndexOutput;
  * Specifies an API for classes that can write out {@link SegmentInfos} data.
  * @lucene.experimental
  */
+
+// nocommit rename (remove the s?)
+
 public abstract class SegmentInfosWriter {
 
   /**
@@ -42,23 +47,5 @@ public abstract class SegmentInfosWriter {
    * phase commit" operations as described above.
    * @throws IOException
    */
-  public abstract IndexOutput writeInfos(Directory dir, String segmentsFileName, String codecID, SegmentInfos infos, IOContext context) throws IOException;
-  
-  /**
-   * First phase of the two-phase commit - ensure that all output can be
-   * successfully written out.
-   * @param out an instance of {@link IndexOutput} returned from a previous
-   * call to {@link #writeInfos(Directory, String, String, SegmentInfos, IOContext)}.
-   * @throws IOException
-   */
-  public abstract void prepareCommit(IndexOutput out) throws IOException;
-  
-  /**
-   * Second phase of the two-phase commit. In this step the output should be
-   * finalized and closed.
-   * @param out an instance of {@link IndexOutput} returned from a previous
-   * call to {@link #writeInfos(Directory, String, String, SegmentInfos, IOContext)}.
-   * @throws IOException
-   */
-  public abstract void finishCommit(IndexOutput out) throws IOException;
+  public abstract void write(SegmentInfo info, FieldInfos fis) throws IOException;
 }
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/appending/AppendingCodec.java b/lucene/core/src/java/org/apache/lucene/codecs/appending/AppendingCodec.java
index f338594..749d3f6 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/appending/AppendingCodec.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/appending/AppendingCodec.java
@@ -31,6 +31,7 @@ import org.apache.lucene.codecs.lucene40.Lucene40DocValuesFormat;
 import org.apache.lucene.codecs.lucene40.Lucene40FieldInfosFormat;
 import org.apache.lucene.codecs.lucene40.Lucene40LiveDocsFormat;
 import org.apache.lucene.codecs.lucene40.Lucene40NormsFormat;
+import org.apache.lucene.codecs.lucene40.Lucene40SegmentInfosFormat;
 import org.apache.lucene.codecs.lucene40.Lucene40StoredFieldsFormat;
 import org.apache.lucene.codecs.lucene40.Lucene40TermVectorsFormat;
 
@@ -46,7 +47,7 @@ public class AppendingCodec extends Codec {
   }
 
   private final PostingsFormat postings = new AppendingPostingsFormat();
-  private final SegmentInfosFormat infos = new AppendingSegmentInfosFormat();
+  private final SegmentInfosFormat infos = new Lucene40SegmentInfosFormat();
   private final StoredFieldsFormat fields = new Lucene40StoredFieldsFormat();
   private final FieldInfosFormat fieldInfos = new Lucene40FieldInfosFormat();
   private final TermVectorsFormat vectors = new Lucene40TermVectorsFormat();
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/appending/AppendingSegmentInfosFormat.java b/lucene/core/src/java/org/apache/lucene/codecs/appending/AppendingSegmentInfosFormat.java
deleted file mode 100644
index 17c0187..0000000
--- a/lucene/core/src/java/org/apache/lucene/codecs/appending/AppendingSegmentInfosFormat.java
+++ /dev/null
@@ -1,38 +0,0 @@
-package org.apache.lucene.codecs.appending;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.codecs.SegmentInfosWriter;
-import org.apache.lucene.codecs.lucene40.Lucene40SegmentInfosFormat;
-
-/**
- * Append-only SegmentInfos format.
- * <p>
- * Only a writer is supplied, as the format is written 
- * the same as {@link Lucene40SegmentInfosFormat}.
- * 
- * @see AppendingSegmentInfosWriter
- */
-public class AppendingSegmentInfosFormat extends Lucene40SegmentInfosFormat {
-  private final SegmentInfosWriter writer = new AppendingSegmentInfosWriter();
-
-  @Override
-  public SegmentInfosWriter getSegmentInfosWriter() {
-    return writer;
-  }
-}
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/appending/AppendingSegmentInfosWriter.java b/lucene/core/src/java/org/apache/lucene/codecs/appending/AppendingSegmentInfosWriter.java
deleted file mode 100644
index e855e5c..0000000
--- a/lucene/core/src/java/org/apache/lucene/codecs/appending/AppendingSegmentInfosWriter.java
+++ /dev/null
@@ -1,39 +0,0 @@
-package org.apache.lucene.codecs.appending;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-
-import org.apache.lucene.codecs.lucene40.Lucene40SegmentInfosWriter;
-import org.apache.lucene.store.IndexOutput;
-
-/**
- * Append-only SegmentInfos writer.
- * <p>
- * Extends {@link Lucene40SegmentInfosWriter}, writing the same
- * format, but the first phase of a two-phase commit 
- * ({@link #prepareCommit(IndexOutput)}) is not implemented.
- */
-public class AppendingSegmentInfosWriter extends Lucene40SegmentInfosWriter {
-
-  @Override
-  public void prepareCommit(IndexOutput segmentOutput) throws IOException {
-    // noop
-  }
-
-}
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xCodec.java b/lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xCodec.java
index e47cf97..947e6e0 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xCodec.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xCodec.java
@@ -148,7 +148,8 @@ public class Lucene3xCodec extends Codec {
     // never inside CFS
     liveDocsFormat().files(info, files);
     ((Lucene3xNormsFormat)normsFormat()).separateFiles(info, files);
-    
+    segmentInfosFormat().files(info, files);
+
     // shared docstores: these guys check the hair
     if (info.getDocStoreOffset() != -1) {
       storedFieldsFormat().files(info, files);
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfosFormat.java b/lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfosFormat.java
index 61d1946..6c2c73a 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfosFormat.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfosFormat.java
@@ -1,9 +1,5 @@
 package org.apache.lucene.codecs.lucene3x;
 
-import org.apache.lucene.codecs.SegmentInfosFormat;
-import org.apache.lucene.codecs.SegmentInfosReader;
-import org.apache.lucene.codecs.SegmentInfosWriter;
-
 /**
  * Licensed to the Apache Software Foundation (ASF) under one or more
  * contributor license agreements.  See the NOTICE file distributed with
@@ -21,6 +17,14 @@ import org.apache.lucene.codecs.SegmentInfosWriter;
  * limitations under the License.
  */
 
+import java.util.Set;
+
+import org.apache.lucene.codecs.SegmentInfosFormat;
+import org.apache.lucene.codecs.SegmentInfosReader;
+import org.apache.lucene.codecs.SegmentInfosWriter;
+import org.apache.lucene.index.IndexFileNames;
+import org.apache.lucene.index.SegmentInfo;
+
 /**
  * Lucene3x ReadOnly SegmentInfosFormat implementation
  * @deprecated (4.0) This is only used to read indexes created
@@ -28,9 +32,36 @@ import org.apache.lucene.codecs.SegmentInfosWriter;
  * @lucene.experimental
  */
 @Deprecated
-class Lucene3xSegmentInfosFormat extends SegmentInfosFormat {
+public class Lucene3xSegmentInfosFormat extends SegmentInfosFormat {
   private final SegmentInfosReader reader = new Lucene3xSegmentInfosReader();
+
+  // nocommit explain or remove this!:
+  public static final String SI_EXTENSION = "si";
   
+  /** This format adds optional per-segment String
+   *  diagnostics storage, and switches userData to Map */
+  public static final int FORMAT_DIAGNOSTICS = -9;
+
+  /** Each segment records whether it has term vectors */
+  public static final int FORMAT_HAS_VECTORS = -10;
+
+  /** Each segment records the Lucene version that created it. */
+  public static final int FORMAT_3_1 = -11;
+
+  // nocommit we should nuke FORMAT_4_0!?
+
+  /** Each segment records whether its postings are written
+   *  in the new flex format */
+  public static final int FORMAT_4_0 = -12;
+
+  /** This must always point to the most recent file format.
+   * whenever you add a new format, make it 1 smaller (negative version logic)! */
+  // TODO: move this, as its currently part of required preamble
+  public static final int FORMAT_CURRENT = FORMAT_4_0;
+  
+  /** This must always point to the first supported file format. */
+  public static final int FORMAT_MINIMUM = FORMAT_DIAGNOSTICS;
+
   @Override
   public SegmentInfosReader getSegmentInfosReader() {
     return reader;
@@ -40,4 +71,12 @@ class Lucene3xSegmentInfosFormat extends SegmentInfosFormat {
   public SegmentInfosWriter getSegmentInfosWriter() {
     throw new UnsupportedOperationException("this codec can only be used for reading");
   }
+
+  @Override
+  public void files(SegmentInfo info, Set<String> files) {
+    // nocommit hacky!
+    if (true || !info.getVersion().startsWith("3.")) {
+      files.add(IndexFileNames.segmentFileName(info.name, "", SI_EXTENSION));
+    }
+  }
 }
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfosReader.java b/lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfosReader.java
index bd311ca..1fd5c8b 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfosReader.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfosReader.java
@@ -24,6 +24,7 @@ import java.util.Map;
 import org.apache.lucene.codecs.Codec;
 import org.apache.lucene.codecs.SegmentInfosReader;
 import org.apache.lucene.index.IndexFileNames;
+import org.apache.lucene.index.IndexFormatTooNewException;
 import org.apache.lucene.index.IndexFormatTooOldException;
 import org.apache.lucene.index.SegmentInfo;
 import org.apache.lucene.index.SegmentInfos;
@@ -31,6 +32,8 @@ import org.apache.lucene.store.ChecksumIndexInput;
 import org.apache.lucene.store.CompoundFileDirectory;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IOContext;
+import org.apache.lucene.store.IndexInput;
+import org.apache.lucene.util.IOUtils;
 
 /**
  * Lucene 3x implementation of {@link SegmentInfosReader}.
@@ -38,15 +41,14 @@ import org.apache.lucene.store.IOContext;
  * @deprecated
  */
 @Deprecated
-class Lucene3xSegmentInfosReader extends SegmentInfosReader {
+public class Lucene3xSegmentInfosReader extends SegmentInfosReader {
 
-  @Override
-  public void read(Directory directory, String segmentsFileName, ChecksumIndexInput input, SegmentInfos infos, IOContext context) throws IOException { 
+  public static void readLegacyInfos(SegmentInfos infos, Directory directory, IndexInput input, int format) throws IOException {
     infos.version = input.readLong(); // read version
     infos.counter = input.readInt(); // read counter
-    final int format = infos.getFormat();
+    Lucene3xSegmentInfosReader reader = new Lucene3xSegmentInfosReader();
     for (int i = input.readInt(); i > 0; i--) { // read segmentInfos
-      SegmentInfo si = readSegmentInfo(directory, format, input);
+      SegmentInfo si = reader.readSegmentInfo(directory, format, input);
       if (si.getVersion() == null) {
         // Could be a 3.0 - try to open the doc stores - if it fails, it's a
         // 2.x segment, and an IndexFormatTooOldException will be thrown,
@@ -56,11 +58,11 @@ class Lucene3xSegmentInfosReader extends SegmentInfosReader {
           if (si.getDocStoreIsCompoundFile()) {
             dir = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(
                 si.getDocStoreSegment(), "",
-                Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION), context, false);
+                Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION), IOContext.READONCE, false);
           }
         } else if (si.getUseCompoundFile()) {
           dir = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(
-              si.name, "", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);
+              si.name, "", IndexFileNames.COMPOUND_FILE_EXTENSION), IOContext.READONCE, false);
         }
 
         try {
@@ -85,11 +87,47 @@ class Lucene3xSegmentInfosReader extends SegmentInfosReader {
       
     infos.userData = input.readStringStringMap();
   }
-  
-  // if we make a preflex impl we can remove a lot of this hair...
-  public SegmentInfo readSegmentInfo(Directory dir, int format, ChecksumIndexInput input) throws IOException {
+
+  @Override
+  public SegmentInfo read(Directory directory, String segmentName) throws IOException { 
+    return read(directory, segmentName, Lucene3xSegmentInfosFormat.FORMAT_4_0);
+  }
+
+  public SegmentInfo read(Directory directory, String segmentName, int format) throws IOException { 
+
+    // NOTE: this is NOT how 3.x is really written...
+    String fileName = IndexFileNames.segmentFileName(segmentName, "", Lucene3xSegmentInfosFormat.SI_EXTENSION);
+
+    // nocommit what IOCtx
+    boolean success = false;
+
+    IndexInput input = directory.openInput(fileName, IOContext.READONCE);
+
+    try {
+      SegmentInfo si = readSegmentInfo(directory, format, input);
+      success = true;
+      return si;
+    } finally {
+      if (!success) {
+        IOUtils.closeWhileHandlingException(input);
+      } else {
+        input.close();
+      }
+    }
+  }
+
+  private SegmentInfo readSegmentInfo(Directory dir, int format, IndexInput input) throws IOException {
+    // check that it is a format we can understand
+    if (format > Lucene3xSegmentInfosFormat.FORMAT_MINIMUM) {
+      throw new IndexFormatTooOldException(input, format,
+                                           Lucene3xSegmentInfosFormat.FORMAT_MINIMUM, Lucene3xSegmentInfosFormat.FORMAT_CURRENT);
+    }
+    if (format < Lucene3xSegmentInfosFormat.FORMAT_CURRENT) {
+      throw new IndexFormatTooNewException(input, format,
+                                           Lucene3xSegmentInfosFormat.FORMAT_MINIMUM, Lucene3xSegmentInfosFormat.FORMAT_CURRENT);
+    }
     final String version;
-    if (format <= SegmentInfos.FORMAT_3_1) {
+    if (format <= Lucene3xSegmentInfosFormat.FORMAT_3_1) {
       version = input.readString();
     } else {
       version = null;
@@ -110,8 +148,10 @@ class Lucene3xSegmentInfosReader extends SegmentInfosReader {
 
     // pre-4.0 indexes write a byte if there is a single norms file
     byte b = input.readByte();
-    assert 1 == b : "expected 1 but was: "+ b + " format: " + format;
 
+    System.out.println("version=" + version + " name=" + name + " docCount=" + docCount + " delGen=" + delGen + " dso=" + docStoreOffset + " dss=" + docStoreSegment + " dssCFs=" + docStoreIsCompoundFile + " b=" + b + " format=" + format);
+
+    assert 1 == b : "expected 1 but was: "+ b + " format: " + format;
     final int numNormGen = input.readInt();
     final Map<Integer,Long> normGen;
     if (numNormGen == SegmentInfo.NO) {
@@ -129,33 +169,19 @@ class Lucene3xSegmentInfosReader extends SegmentInfosReader {
 
     final boolean hasProx = input.readByte() == 1;
 
-    final Codec codec = Codec.forName("Lucene3x");
     final Map<String,String> diagnostics = input.readStringStringMap();
 
+    if (format <= Lucene3xSegmentInfosFormat.FORMAT_HAS_VECTORS) {
+      input.readByte();
+    }
+
     // nocommit we can use hasProx/hasVectors from the 3.x
     // si... if we can pass this to the other components...?
 
-    // nocommit clean up
-    final boolean hasVectors;
-    if (format <= SegmentInfos.FORMAT_HAS_VECTORS) {
-      hasVectors = input.readByte() == 1;
-    } else {
-      final String storesSegment;
-      final String ext;
-      final boolean storeIsCompoundFile;
-      if (docStoreOffset != -1) {
-        storesSegment = docStoreSegment;
-        storeIsCompoundFile = docStoreIsCompoundFile;
-        ext = Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION;
-      } else {
-        storesSegment = name;
-        storeIsCompoundFile = isCompoundFile;
-        ext = IndexFileNames.COMPOUND_FILE_EXTENSION;
-      }
-    }
-
-    return new SegmentInfo(dir, version, name, docCount, delGen, docStoreOffset,
-      docStoreSegment, docStoreIsCompoundFile, normGen, isCompoundFile,
-      delCount, codec, diagnostics);
+    SegmentInfo info = new SegmentInfo(dir, version, name, docCount, docStoreOffset,
+                                       docStoreSegment, docStoreIsCompoundFile, normGen, isCompoundFile,
+                                       delCount, null, diagnostics);
+    info.setDelGen(delGen);
+    return info;
   }
 }
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40LiveDocsFormat.java b/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40LiveDocsFormat.java
index 4907f01..df81d27 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40LiveDocsFormat.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40LiveDocsFormat.java
@@ -84,7 +84,8 @@ public class Lucene40LiveDocsFormat extends LiveDocsFormat {
   public Bits readLiveDocs(Directory dir, SegmentInfo info, IOContext context) throws IOException {
     String filename = IndexFileNames.fileNameFromGeneration(info.name, DELETES_EXTENSION, info.getDelGen());
     final BitVector liveDocs = new BitVector(dir, filename, context);
-    assert liveDocs.count() == info.docCount - info.getDelCount();
+    assert liveDocs.count() == info.docCount - info.getDelCount():
+        "liveDocs.count()=" + liveDocs.count() + " info.docCount=" + info.docCount + " info.getDelCount()=" + info.getDelCount();
     assert liveDocs.length() == info.docCount;
     return liveDocs;
   }
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40PostingsReader.java b/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40PostingsReader.java
index 6919cc0..7411bef 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40PostingsReader.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40PostingsReader.java
@@ -58,9 +58,11 @@ public class Lucene40PostingsReader extends PostingsReaderBase {
 
   // private String segment;
 
+  // nocommit don't pass FIS here...
   public Lucene40PostingsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo segmentInfo, IOContext ioContext, String segmentSuffix) throws IOException {
     freqIn = dir.openInput(IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, Lucene40PostingsFormat.FREQ_EXTENSION),
                            ioContext);
+    // nocommit we can assert FIS.hasProx == our hasProx here...
     // this.segment = segmentInfo.name;
     if (fieldInfos.hasProx()) {
       boolean success = false;
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40PostingsWriter.java b/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40PostingsWriter.java
index a63fbbf..f58ab5b 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40PostingsWriter.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40PostingsWriter.java
@@ -103,6 +103,9 @@ public final class Lucene40PostingsWriter extends PostingsWriterBase {
     freqOut = state.directory.createOutput(fileName, state.context);
     boolean success = false;
     try {
+      // nocommit this isn't quite right: it should be only
+      // the fields indexed by us...?  maybe... we shouldn't
+      // bother w/ this opto?  just create empty prx file...?
       if (state.fieldInfos.hasProx()) {
         // At least one field does not omit TF, so create the
         // prox file
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40SegmentInfosFormat.java b/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40SegmentInfosFormat.java
index 4852bbb..a8e74c5 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40SegmentInfosFormat.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40SegmentInfosFormat.java
@@ -17,6 +17,9 @@ package org.apache.lucene.codecs.lucene40;
  * limitations under the License.
  */
 
+import java.io.IOException;
+import java.util.Set;
+
 import org.apache.lucene.codecs.Codec; // javadocs
 import org.apache.lucene.codecs.LiveDocsFormat; // javadocs
 import org.apache.lucene.codecs.SegmentInfosFormat;
@@ -25,7 +28,9 @@ import org.apache.lucene.codecs.SegmentInfosWriter;
 import org.apache.lucene.codecs.StoredFieldsFormat; // javadocs
 import org.apache.lucene.codecs.TermVectorsFormat; // javadocs
 import org.apache.lucene.index.FieldInfo.IndexOptions; // javadocs
+import org.apache.lucene.index.IndexFileNames;
 import org.apache.lucene.index.IndexWriter; // javadocs
+import org.apache.lucene.index.SegmentInfo;
 import org.apache.lucene.index.SegmentInfos; // javadocs
 import org.apache.lucene.store.DataOutput; // javadocs
 
@@ -129,4 +134,11 @@ public class Lucene40SegmentInfosFormat extends SegmentInfosFormat {
   public SegmentInfosWriter getSegmentInfosWriter() {
     return writer;
   }
+
+  public final static String SI_EXTENSION = "si";
+  
+  @Override
+  public void files(SegmentInfo segmentInfo, Set<String> files) {
+    files.add(IndexFileNames.segmentFileName(segmentInfo.name, "", SI_EXTENSION));
+  }
 }
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40SegmentInfosReader.java b/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40SegmentInfosReader.java
index 935bfb6..1a85e23 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40SegmentInfosReader.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40SegmentInfosReader.java
@@ -23,11 +23,14 @@ import java.util.Map;
 
 import org.apache.lucene.codecs.Codec;
 import org.apache.lucene.codecs.SegmentInfosReader;
+import org.apache.lucene.index.IndexFileNames;
 import org.apache.lucene.index.SegmentInfo;
 import org.apache.lucene.index.SegmentInfos;
 import org.apache.lucene.store.ChecksumIndexInput;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IOContext;
+import org.apache.lucene.store.IndexInput;
+import org.apache.lucene.util.IOUtils;
 
 /**
  * Lucene 4.0 implementation of {@link SegmentInfosReader}.
@@ -38,55 +41,50 @@ import org.apache.lucene.store.IOContext;
 public class Lucene40SegmentInfosReader extends SegmentInfosReader {
 
   @Override
-  public void read(Directory directory, String segmentsFileName, ChecksumIndexInput input, SegmentInfos infos, IOContext context) throws IOException { 
-    infos.version = input.readLong(); // read version
-    infos.counter = input.readInt(); // read counter
-    final int format = infos.getFormat();
-    assert format <= SegmentInfos.FORMAT_4_0;
-    for (int i = input.readInt(); i > 0; i--) { // read segmentInfos
-      SegmentInfo si = readSegmentInfo(directory, format, input);
-      assert si.getVersion() != null;
-      infos.add(si);
-    }
-      
-    infos.userData = input.readStringStringMap();
-  }
-  
-  public SegmentInfo readSegmentInfo(Directory dir, int format, ChecksumIndexInput input) throws IOException {
-    final String version = input.readString();
-    final String name = input.readString();
-    final int docCount = input.readInt();
-    final long delGen = input.readLong();
-    // this is still written in 4.0 if we open a 3.x and upgrade the SI
-    final int docStoreOffset = input.readInt();
-    final String docStoreSegment;
-    final boolean docStoreIsCompoundFile;
-    if (docStoreOffset != -1) { 
-      docStoreSegment = input.readString();
-      docStoreIsCompoundFile = input.readByte() == SegmentInfo.YES;
-    } else {
-      docStoreSegment = name;
-      docStoreIsCompoundFile = false;
-    }
-    final int numNormGen = input.readInt();
-    final Map<Integer,Long> normGen;
-    if (numNormGen == SegmentInfo.NO) {
-      normGen = null;
-    } else {
-      normGen = new HashMap<Integer, Long>();
-      for(int j=0;j<numNormGen;j++) {
-        normGen.put(input.readInt(), input.readLong());
+  public SegmentInfo read(Directory dir, String segment) throws IOException {
+    final String fileName = IndexFileNames.segmentFileName(segment, "", Lucene40SegmentInfosFormat.SI_EXTENSION);
+    final IndexInput input = dir.openInput(fileName, IOContext.READONCE);
+    boolean success = false;
+    try {
+      final String version = input.readString();
+      final int docCount = input.readInt();
+        // this is still written in 4.0 if we open a 3.x and upgrade the SI
+      final int docStoreOffset = input.readInt();
+      final String docStoreSegment;
+      final boolean docStoreIsCompoundFile;
+      if (docStoreOffset != -1) { 
+        docStoreSegment = input.readString();
+        docStoreIsCompoundFile = input.readByte() == SegmentInfo.YES;
+      } else {
+        docStoreSegment = segment;
+        docStoreIsCompoundFile = false;
       }
-    }
-    final boolean isCompoundFile = input.readByte() == SegmentInfo.YES;
+      final int numNormGen = input.readInt();
+      final Map<Integer,Long> normGen;
+      if (numNormGen == SegmentInfo.NO) {
+        normGen = null;
+      } else {
+        normGen = new HashMap<Integer, Long>();
+        for(int j=0;j<numNormGen;j++) {
+          normGen.put(input.readInt(), input.readLong());
+        }
+      }
+      final boolean isCompoundFile = input.readByte() == SegmentInfo.YES;
+
+      final int delCount = input.readInt();
+      assert delCount <= docCount;
+      final Map<String,String> diagnostics = input.readStringStringMap();
 
-    final int delCount = input.readInt();
-    assert delCount <= docCount;
-    final Codec codec = Codec.forName(input.readString());
-    final Map<String,String> diagnostics = input.readStringStringMap();
-    
-    return new SegmentInfo(dir, version, name, docCount, delGen, docStoreOffset,
-      docStoreSegment, docStoreIsCompoundFile, normGen, isCompoundFile,
-      delCount, codec, diagnostics);
+      success = true;
+      return new SegmentInfo(dir, version, segment, docCount, docStoreOffset,
+                             docStoreSegment, docStoreIsCompoundFile, normGen, isCompoundFile,
+                             delCount, null, diagnostics);
+    } finally {
+      if (!success) {
+        IOUtils.closeWhileHandlingException(input);
+      } else {
+        input.close();
+      }
+    }
   }
 }
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40SegmentInfosWriter.java b/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40SegmentInfosWriter.java
index 32179b6..2b53368 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40SegmentInfosWriter.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40SegmentInfosWriter.java
@@ -18,10 +18,12 @@ package org.apache.lucene.codecs.lucene40;
  */
 
 import java.io.IOException;
-import java.util.Map;
 import java.util.Map.Entry;
+import java.util.Map;
 
 import org.apache.lucene.codecs.SegmentInfosWriter;
+import org.apache.lucene.index.FieldInfos;
+import org.apache.lucene.index.IndexFileNames;
 import org.apache.lucene.index.SegmentInfo;
 import org.apache.lucene.index.SegmentInfos;
 import org.apache.lucene.store.ChecksumIndexOutput;
@@ -39,81 +41,50 @@ import org.apache.lucene.util.IOUtils;
  */
 public class Lucene40SegmentInfosWriter extends SegmentInfosWriter {
 
+  /** Save a single segment's info. */
   @Override
-  public IndexOutput writeInfos(Directory dir, String segmentFileName, String codecID, SegmentInfos infos, IOContext context)
-          throws IOException {
-    IndexOutput out = createOutput(dir, segmentFileName, new IOContext(new FlushInfo(infos.size(), infos.totalDocCount())));
+  public void write(SegmentInfo si, FieldInfos fis) throws IOException {
+    assert si.getDelCount() <= si.docCount: "delCount=" + si.getDelCount() + " docCount=" + si.docCount + " segment=" + si.name;
+    final String fileName = IndexFileNames.segmentFileName(si.name, "", Lucene40SegmentInfosFormat.SI_EXTENSION);
+    // nocommit what ioctxt to pass?  cannot call .sizeInBytes()!
+    final IndexOutput output = si.dir.createOutput(fileName, new IOContext(new FlushInfo(si.docCount, 0)));
+
     boolean success = false;
     try {
-      /*
-       * TODO its not ideal that we write the format and the codecID inside the
-       * codec private classes but we read it in SegmentInfos.
-       */
-      out.writeInt(SegmentInfos.FORMAT_CURRENT); // write FORMAT
-      out.writeString(codecID); // write codecID
-      out.writeLong(infos.version);
-      out.writeInt(infos.counter); // write counter
-      out.writeInt(infos.size()); // write infos
-      for (SegmentInfo si : infos) {
-        writeInfo(out, si);
+      // Write the Lucene version that created this segment, since 3.1
+      output.writeString(si.getVersion());
+      output.writeInt(si.docCount);
+      // we still need to write this in 4.0 since we can open a 3.x with shared docStores
+      output.writeInt(si.getDocStoreOffset());
+      if (si.getDocStoreOffset() != -1) {
+        output.writeString(si.getDocStoreSegment());
+        output.writeByte((byte) (si.getDocStoreIsCompoundFile() ? 1:0));
+      }
+
+      // nocommit remove (4.0 doesn't write normGen)...
+      Map<Integer,Long> normGen = si.getNormGen();
+      if (normGen == null) {
+        output.writeInt(SegmentInfo.NO);
+      } else {
+        output.writeInt(normGen.size());
+        for (Entry<Integer,Long> entry : normGen.entrySet()) {
+          output.writeInt(entry.getKey());
+          output.writeLong(entry.getValue());
+        }
       }
-      out.writeStringStringMap(infos.getUserData());
+
+      output.writeByte((byte) (si.getUseCompoundFile() ? SegmentInfo.YES : SegmentInfo.NO));
+      output.writeInt(si.getDelCount());
+      output.writeStringStringMap(si.getDiagnostics());
+
       success = true;
-      return out;
     } finally {
       if (!success) {
-        IOUtils.closeWhileHandlingException(out);
-      }
-    }
-  }
-  
-  /** Save a single segment's info. */
-  private void writeInfo(IndexOutput output, SegmentInfo si) throws IOException {
-    assert si.getDelCount() <= si.docCount: "delCount=" + si.getDelCount() + " docCount=" + si.docCount + " segment=" + si.name;
-    // Write the Lucene version that created this segment, since 3.1
-    output.writeString(si.getVersion());
-    output.writeString(si.name);
-    output.writeInt(si.docCount);
-    output.writeLong(si.getDelGen());
-    // we still need to write this in 4.0 since we can open a 3.x with shared docStores
-    output.writeInt(si.getDocStoreOffset());
-    if (si.getDocStoreOffset() != -1) {
-      output.writeString(si.getDocStoreSegment());
-      output.writeByte((byte) (si.getDocStoreIsCompoundFile() ? 1:0));
-    }
-
-    Map<Integer,Long> normGen = si.getNormGen();
-    if (normGen == null) {
-      output.writeInt(SegmentInfo.NO);
-    } else {
-      output.writeInt(normGen.size());
-      for (Entry<Integer,Long> entry : normGen.entrySet()) {
-        output.writeInt(entry.getKey());
-        output.writeLong(entry.getValue());
+        IOUtils.closeWhileHandlingException(output);
+        si.dir.deleteFile(fileName);
+      } else {
+        output.close();
       }
     }
-
-    output.writeByte((byte) (si.getUseCompoundFile() ? SegmentInfo.YES : SegmentInfo.NO));
-    output.writeInt(si.getDelCount());
-    output.writeString(si.getCodec().getName());
-    output.writeStringStringMap(si.getDiagnostics());
-  }
-  
-  protected IndexOutput createOutput(Directory dir, String segmentFileName, IOContext context)
-      throws IOException {
-    IndexOutput plainOut = dir.createOutput(segmentFileName, context);
-    ChecksumIndexOutput out = new ChecksumIndexOutput(plainOut);
-    return out;
-  }
-
-  @Override
-  public void prepareCommit(IndexOutput segmentOutput) throws IOException {
-    ((ChecksumIndexOutput)segmentOutput).prepareCommit();
-  }
-
-  @Override
-  public void finishCommit(IndexOutput out) throws IOException {
-    ((ChecksumIndexOutput)out).finishCommit();
-    out.close();
   }
 }
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/perfield/PerFieldPostingsFormat.java b/lucene/core/src/java/org/apache/lucene/codecs/perfield/PerFieldPostingsFormat.java
index ef9138f..aefd8ff 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/perfield/PerFieldPostingsFormat.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/perfield/PerFieldPostingsFormat.java
@@ -144,6 +144,9 @@ public abstract class PerFieldPostingsFormat extends PostingsFormat {
         formats.put(format, consumerAndId);
       }
 
+      // nocommit we should only provide the "slice" of FIS
+      // that this PF actually sees ... then stuff like
+      // .hasProx could work correctly?
       return consumerAndId.fieldsConsumer.addField(field);
     }
 
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextSegmentInfosFormat.java b/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextSegmentInfosFormat.java
index 6518cf4..e2fd344 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextSegmentInfosFormat.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextSegmentInfosFormat.java
@@ -17,9 +17,13 @@ package org.apache.lucene.codecs.simpletext;
  * limitations under the License.
  */
 
+import java.util.Set;
+
 import org.apache.lucene.codecs.SegmentInfosFormat;
 import org.apache.lucene.codecs.SegmentInfosReader;
 import org.apache.lucene.codecs.SegmentInfosWriter;
+import org.apache.lucene.index.IndexFileNames;
+import org.apache.lucene.index.SegmentInfo;
 
 /**
  * plain text segments file format.
@@ -30,6 +34,8 @@ import org.apache.lucene.codecs.SegmentInfosWriter;
 public class SimpleTextSegmentInfosFormat extends SegmentInfosFormat {
   private final SegmentInfosReader reader = new SimpleTextSegmentInfosReader();
   private final SegmentInfosWriter writer = new SimpleTextSegmentInfosWriter();
+
+  public static final String SI_EXTENSION = "si";
   
   @Override
   public SegmentInfosReader getSegmentInfosReader() {
@@ -40,4 +46,9 @@ public class SimpleTextSegmentInfosFormat extends SegmentInfosFormat {
   public SegmentInfosWriter getSegmentInfosWriter() {
     return writer;
   }
+
+  @Override
+  public void files(SegmentInfo info, Set<String> files) {
+    files.add(IndexFileNames.segmentFileName(info.name, "", SI_EXTENSION));
+  }
 }
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextSegmentInfosReader.java b/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextSegmentInfosReader.java
index 31084a9..fc9eaec 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextSegmentInfosReader.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextSegmentInfosReader.java
@@ -24,12 +24,14 @@ import java.util.Map;
 import org.apache.lucene.codecs.Codec;
 import org.apache.lucene.codecs.SegmentInfosReader;
 import org.apache.lucene.index.CorruptIndexException;
+import org.apache.lucene.index.IndexFileNames;
 import org.apache.lucene.index.SegmentInfo;
 import org.apache.lucene.index.SegmentInfos;
 import org.apache.lucene.store.ChecksumIndexInput;
 import org.apache.lucene.store.DataInput;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IOContext;
+import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.StringHelper;
@@ -44,8 +46,7 @@ import static org.apache.lucene.codecs.simpletext.SimpleTextSegmentInfosWriter.*
  */
 public class SimpleTextSegmentInfosReader extends SegmentInfosReader {
 
-  @Override
-  public void read(Directory directory, String segmentsFileName, ChecksumIndexInput input, SegmentInfos infos, IOContext context) throws IOException {
+  /*
     final BytesRef scratch = new BytesRef();
     
     SimpleTextUtil.readLine(input, scratch);
@@ -80,89 +81,96 @@ public class SimpleTextSegmentInfosReader extends SegmentInfosReader {
       infos.add(readSegmentInfo(directory, input, scratch));
     }
   }
+  */
   
-  public SegmentInfo readSegmentInfo(Directory directory, DataInput input, BytesRef scratch) throws IOException {
-    SimpleTextUtil.readLine(input, scratch);
-    assert StringHelper.startsWith(scratch, SI_NAME);
-    final String name = readString(SI_NAME.length, scratch);
-    
-    SimpleTextUtil.readLine(input, scratch);
-    assert StringHelper.startsWith(scratch, SI_CODEC);
-    final Codec codec = Codec.forName(readString(SI_CODEC.length, scratch));
-    
-    SimpleTextUtil.readLine(input, scratch);
-    assert StringHelper.startsWith(scratch, SI_VERSION);
-    final String version = readString(SI_VERSION.length, scratch);
+  @Override
+  public SegmentInfo read(Directory directory, String segmentName) throws IOException {
+    BytesRef scratch = new BytesRef();
+    String fileName = IndexFileNames.segmentFileName(segmentName, "", SimpleTextSegmentInfosFormat.SI_EXTENSION);
+    IndexInput input = directory.openInput(fileName, IOContext.READONCE);
+    boolean success = false;
+    try {
+      SimpleTextUtil.readLine(input, scratch);
+      assert StringHelper.startsWith(scratch, SI_VERSION);
+      final String version = readString(SI_VERSION.length, scratch);
     
-    SimpleTextUtil.readLine(input, scratch);
-    assert StringHelper.startsWith(scratch, SI_DOCCOUNT);
-    final int docCount = Integer.parseInt(readString(SI_DOCCOUNT.length, scratch));
+      SimpleTextUtil.readLine(input, scratch);
+      assert StringHelper.startsWith(scratch, SI_DOCCOUNT);
+      final int docCount = Integer.parseInt(readString(SI_DOCCOUNT.length, scratch));
     
-    SimpleTextUtil.readLine(input, scratch);
-    assert StringHelper.startsWith(scratch, SI_DELCOUNT);
-    final int delCount = Integer.parseInt(readString(SI_DELCOUNT.length, scratch));
+      SimpleTextUtil.readLine(input, scratch);
+      assert StringHelper.startsWith(scratch, SI_DELCOUNT);
+      final int delCount = Integer.parseInt(readString(SI_DELCOUNT.length, scratch));
     
-    SimpleTextUtil.readLine(input, scratch);
-    assert StringHelper.startsWith(scratch, SI_USECOMPOUND);
-    final boolean isCompoundFile = Boolean.parseBoolean(readString(SI_USECOMPOUND.length, scratch));
+      SimpleTextUtil.readLine(input, scratch);
+      assert StringHelper.startsWith(scratch, SI_USECOMPOUND);
+      final boolean isCompoundFile = Boolean.parseBoolean(readString(SI_USECOMPOUND.length, scratch));
     
-    SimpleTextUtil.readLine(input, scratch);
-    assert StringHelper.startsWith(scratch, SI_DSOFFSET);
-    final int dsOffset = Integer.parseInt(readString(SI_DSOFFSET.length, scratch));
+      SimpleTextUtil.readLine(input, scratch);
+      assert StringHelper.startsWith(scratch, SI_DSOFFSET);
+      final int dsOffset = Integer.parseInt(readString(SI_DSOFFSET.length, scratch));
     
-    SimpleTextUtil.readLine(input, scratch);
-    assert StringHelper.startsWith(scratch, SI_DSSEGMENT);
-    final String dsSegment = readString(SI_DSSEGMENT.length, scratch);
+      SimpleTextUtil.readLine(input, scratch);
+      assert StringHelper.startsWith(scratch, SI_DSSEGMENT);
+      final String dsSegment = readString(SI_DSSEGMENT.length, scratch);
     
-    SimpleTextUtil.readLine(input, scratch);
-    assert StringHelper.startsWith(scratch, SI_DSCOMPOUND);
-    final boolean dsCompoundFile = Boolean.parseBoolean(readString(SI_DSCOMPOUND.length, scratch));
+      SimpleTextUtil.readLine(input, scratch);
+      assert StringHelper.startsWith(scratch, SI_DSCOMPOUND);
+      final boolean dsCompoundFile = Boolean.parseBoolean(readString(SI_DSCOMPOUND.length, scratch));
     
-    SimpleTextUtil.readLine(input, scratch);
-    assert StringHelper.startsWith(scratch, SI_DELGEN);
-    final long delGen = Long.parseLong(readString(SI_DELGEN.length, scratch));
+      SimpleTextUtil.readLine(input, scratch);
+      assert StringHelper.startsWith(scratch, SI_DELGEN);
+      final long delGen = Long.parseLong(readString(SI_DELGEN.length, scratch));
     
-    SimpleTextUtil.readLine(input, scratch);
-    assert StringHelper.startsWith(scratch, SI_NUM_NORMGEN);
-    final int numNormGen = Integer.parseInt(readString(SI_NUM_NORMGEN.length, scratch));
-    final Map<Integer,Long> normGen;
-    if (numNormGen == 0) {
-      normGen = null;
-    } else {
-      normGen = new HashMap<Integer,Long>();
-      for (int i = 0; i < numNormGen; i++) {
-        SimpleTextUtil.readLine(input, scratch);
-        assert StringHelper.startsWith(scratch, SI_NORMGEN_KEY);
-        int key = Integer.parseInt(readString(SI_NORMGEN_KEY.length, scratch));
+      SimpleTextUtil.readLine(input, scratch);
+      assert StringHelper.startsWith(scratch, SI_NUM_NORMGEN);
+      final int numNormGen = Integer.parseInt(readString(SI_NUM_NORMGEN.length, scratch));
+      final Map<Integer,Long> normGen;
+      if (numNormGen == 0) {
+        normGen = null;
+      } else {
+        normGen = new HashMap<Integer,Long>();
+        for (int i = 0; i < numNormGen; i++) {
+          SimpleTextUtil.readLine(input, scratch);
+          assert StringHelper.startsWith(scratch, SI_NORMGEN_KEY);
+          int key = Integer.parseInt(readString(SI_NORMGEN_KEY.length, scratch));
         
-        SimpleTextUtil.readLine(input, scratch);
-        assert StringHelper.startsWith(scratch, SI_NORMGEN_VALUE);
-        long value = Long.parseLong(readString(SI_NORMGEN_VALUE.length, scratch));
-        normGen.put(key, value);
+          SimpleTextUtil.readLine(input, scratch);
+          assert StringHelper.startsWith(scratch, SI_NORMGEN_VALUE);
+          long value = Long.parseLong(readString(SI_NORMGEN_VALUE.length, scratch));
+          normGen.put(key, value);
+        }
       }
-    }
     
-    SimpleTextUtil.readLine(input, scratch);
-    assert StringHelper.startsWith(scratch, SI_NUM_DIAG);
-    int numDiag = Integer.parseInt(readString(SI_NUM_DIAG.length, scratch));
-    Map<String,String> diagnostics = new HashMap<String,String>();
-
-    for (int i = 0; i < numDiag; i++) {
       SimpleTextUtil.readLine(input, scratch);
-      assert StringHelper.startsWith(scratch, SI_DIAG_KEY);
-      String key = readString(SI_DIAG_KEY.length, scratch);
+      assert StringHelper.startsWith(scratch, SI_NUM_DIAG);
+      int numDiag = Integer.parseInt(readString(SI_NUM_DIAG.length, scratch));
+      Map<String,String> diagnostics = new HashMap<String,String>();
+
+      for (int i = 0; i < numDiag; i++) {
+        SimpleTextUtil.readLine(input, scratch);
+        assert StringHelper.startsWith(scratch, SI_DIAG_KEY);
+        String key = readString(SI_DIAG_KEY.length, scratch);
       
-      SimpleTextUtil.readLine(input, scratch);
-      assert StringHelper.startsWith(scratch, SI_DIAG_VALUE);
-      String value = readString(SI_DIAG_VALUE.length, scratch);
-      diagnostics.put(key, value);
+        SimpleTextUtil.readLine(input, scratch);
+        assert StringHelper.startsWith(scratch, SI_DIAG_VALUE);
+        String value = readString(SI_DIAG_VALUE.length, scratch);
+        diagnostics.put(key, value);
+      }
+
+      success = true;
+      return new SegmentInfo(directory, version, segmentName, docCount, dsOffset,
+                             dsSegment, dsCompoundFile, normGen, isCompoundFile,
+                             delCount, null, diagnostics);
+    } finally {
+      if (!success) {
+        IOUtils.closeWhileHandlingException(input);
+      } else {
+        input.close();
+      }
     }
-    
-    return new SegmentInfo(directory, version, name, docCount, delGen, dsOffset,
-        dsSegment, dsCompoundFile, normGen, isCompoundFile,
-        delCount, codec, diagnostics);
   }
-  
+
   private String readString(int offset, BytesRef scratch) {
     return new String(scratch.bytes, scratch.offset+offset, scratch.length-offset, IOUtils.CHARSET_UTF_8);
   }
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextSegmentInfosWriter.java b/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextSegmentInfosWriter.java
index 069db27..c863895 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextSegmentInfosWriter.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextSegmentInfosWriter.java
@@ -18,10 +18,12 @@ package org.apache.lucene.codecs.simpletext;
  */
 
 import java.io.IOException;
-import java.util.Map;
 import java.util.Map.Entry;
+import java.util.Map;
 
 import org.apache.lucene.codecs.SegmentInfosWriter;
+import org.apache.lucene.index.FieldInfos;
+import org.apache.lucene.index.IndexFileNames;
 import org.apache.lucene.index.SegmentInfo;
 import org.apache.lucene.index.SegmentInfos;
 import org.apache.lucene.store.ChecksumIndexOutput;
@@ -46,8 +48,6 @@ public class SimpleTextSegmentInfosWriter extends SegmentInfosWriter {
   final static BytesRef USERDATA_KEY        = new BytesRef("  key ");
   final static BytesRef USERDATA_VALUE      = new BytesRef("  value ");
   final static BytesRef NUM_SEGMENTS        = new BytesRef("number of segments ");
-  final static BytesRef SI_NAME             = new BytesRef("  name ");
-  final static BytesRef SI_CODEC            = new BytesRef("    codec ");
   final static BytesRef SI_VERSION          = new BytesRef("    version ");
   final static BytesRef SI_DOCCOUNT         = new BytesRef("    number of documents ");
   final static BytesRef SI_DELCOUNT         = new BytesRef("    number of deletions ");
@@ -63,8 +63,7 @@ public class SimpleTextSegmentInfosWriter extends SegmentInfosWriter {
   final static BytesRef SI_DIAG_KEY         = new BytesRef("      key ");
   final static BytesRef SI_DIAG_VALUE       = new BytesRef("      value ");
   
-  @Override
-  public IndexOutput writeInfos(Directory dir, String segmentsFileName, String codecID, SegmentInfos infos, IOContext context) throws IOException {
+  /*
     BytesRef scratch = new BytesRef();
     IndexOutput out = new ChecksumIndexOutput(dir.createOutput(segmentsFileName, new IOContext(new FlushInfo(infos.size(), infos.totalDocCount()))));
     boolean success = false;
@@ -119,96 +118,95 @@ public class SimpleTextSegmentInfosWriter extends SegmentInfosWriter {
       }
     }
   }
+  */
   
-  private void writeInfo(IndexOutput output, SegmentInfo si) throws IOException {
+  @Override
+  public void write(SegmentInfo si, FieldInfos fis) throws IOException {
     assert si.getDelCount() <= si.docCount: "delCount=" + si.getDelCount() + " docCount=" + si.docCount + " segment=" + si.name;
-    BytesRef scratch = new BytesRef();
-    
-    SimpleTextUtil.write(output, SI_NAME);
-    SimpleTextUtil.write(output, si.name, scratch);
-    SimpleTextUtil.writeNewline(output);
-    
-    SimpleTextUtil.write(output, SI_CODEC);
-    SimpleTextUtil.write(output, si.getCodec().getName(), scratch);
-    SimpleTextUtil.writeNewline(output);
+
+    String fileName = IndexFileNames.segmentFileName(si.name, "", SimpleTextSegmentInfosFormat.SI_EXTENSION);
+    // nocommit what IOCtx
+    boolean success = false;
+    IndexOutput output = si.dir.createOutput(fileName, new IOContext(new FlushInfo(0, 0)));
+
+    try {
+      BytesRef scratch = new BytesRef();
     
-    SimpleTextUtil.write(output, SI_VERSION);
-    SimpleTextUtil.write(output, si.getVersion(), scratch);
-    SimpleTextUtil.writeNewline(output);
+      SimpleTextUtil.write(output, SI_VERSION);
+      SimpleTextUtil.write(output, si.getVersion(), scratch);
+      SimpleTextUtil.writeNewline(output);
     
-    SimpleTextUtil.write(output, SI_DOCCOUNT);
-    SimpleTextUtil.write(output, Integer.toString(si.docCount), scratch);
-    SimpleTextUtil.writeNewline(output);
+      SimpleTextUtil.write(output, SI_DOCCOUNT);
+      SimpleTextUtil.write(output, Integer.toString(si.docCount), scratch);
+      SimpleTextUtil.writeNewline(output);
     
-    SimpleTextUtil.write(output, SI_DELCOUNT);
-    SimpleTextUtil.write(output, Integer.toString(si.getDelCount()), scratch);
-    SimpleTextUtil.writeNewline(output);
+      SimpleTextUtil.write(output, SI_DELCOUNT);
+      SimpleTextUtil.write(output, Integer.toString(si.getDelCount()), scratch);
+      SimpleTextUtil.writeNewline(output);
     
-    SimpleTextUtil.write(output, SI_USECOMPOUND);
-    SimpleTextUtil.write(output, Boolean.toString(si.getUseCompoundFile()), scratch);
-    SimpleTextUtil.writeNewline(output);
+      SimpleTextUtil.write(output, SI_USECOMPOUND);
+      SimpleTextUtil.write(output, Boolean.toString(si.getUseCompoundFile()), scratch);
+      SimpleTextUtil.writeNewline(output);
     
-    SimpleTextUtil.write(output, SI_DSOFFSET);
-    SimpleTextUtil.write(output, Integer.toString(si.getDocStoreOffset()), scratch);
-    SimpleTextUtil.writeNewline(output);
+      SimpleTextUtil.write(output, SI_DSOFFSET);
+      SimpleTextUtil.write(output, Integer.toString(si.getDocStoreOffset()), scratch);
+      SimpleTextUtil.writeNewline(output);
     
-    SimpleTextUtil.write(output, SI_DSSEGMENT);
-    SimpleTextUtil.write(output, si.getDocStoreSegment(), scratch);
-    SimpleTextUtil.writeNewline(output);
+      SimpleTextUtil.write(output, SI_DSSEGMENT);
+      SimpleTextUtil.write(output, si.getDocStoreSegment(), scratch);
+      SimpleTextUtil.writeNewline(output);
     
-    SimpleTextUtil.write(output, SI_DSCOMPOUND);
-    SimpleTextUtil.write(output, Boolean.toString(si.getDocStoreIsCompoundFile()), scratch);
-    SimpleTextUtil.writeNewline(output);
+      SimpleTextUtil.write(output, SI_DSCOMPOUND);
+      SimpleTextUtil.write(output, Boolean.toString(si.getDocStoreIsCompoundFile()), scratch);
+      SimpleTextUtil.writeNewline(output);
     
-    SimpleTextUtil.write(output, SI_DELGEN);
-    SimpleTextUtil.write(output, Long.toString(si.getDelGen()), scratch);
-    SimpleTextUtil.writeNewline(output);
+      SimpleTextUtil.write(output, SI_DELGEN);
+      SimpleTextUtil.write(output, Long.toString(si.getDelGen()), scratch);
+      SimpleTextUtil.writeNewline(output);
     
-    Map<Integer,Long> normGen = si.getNormGen();
-    int numNormGen = normGen == null ? 0 : normGen.size();
-    SimpleTextUtil.write(output, SI_NUM_NORMGEN);
-    SimpleTextUtil.write(output, Integer.toString(numNormGen), scratch);
-    SimpleTextUtil.writeNewline(output);
+      Map<Integer,Long> normGen = si.getNormGen();
+      int numNormGen = normGen == null ? 0 : normGen.size();
+      SimpleTextUtil.write(output, SI_NUM_NORMGEN);
+      SimpleTextUtil.write(output, Integer.toString(numNormGen), scratch);
+      SimpleTextUtil.writeNewline(output);
     
-    if (numNormGen > 0) {
-      for (Entry<Integer,Long> entry : normGen.entrySet()) {
-        SimpleTextUtil.write(output, SI_NORMGEN_KEY);
-        SimpleTextUtil.write(output, Integer.toString(entry.getKey()), scratch);
-        SimpleTextUtil.writeNewline(output);
+      // nocommit no more:
+      if (numNormGen > 0) {
+        for (Entry<Integer,Long> entry : normGen.entrySet()) {
+          SimpleTextUtil.write(output, SI_NORMGEN_KEY);
+          SimpleTextUtil.write(output, Integer.toString(entry.getKey()), scratch);
+          SimpleTextUtil.writeNewline(output);
         
-        SimpleTextUtil.write(output, SI_NORMGEN_VALUE);
-        SimpleTextUtil.write(output, Long.toString(entry.getValue()), scratch);
-        SimpleTextUtil.writeNewline(output);
+          SimpleTextUtil.write(output, SI_NORMGEN_VALUE);
+          SimpleTextUtil.write(output, Long.toString(entry.getValue()), scratch);
+          SimpleTextUtil.writeNewline(output);
+        }
       }
-    }
     
-    Map<String,String> diagnostics = si.getDiagnostics();
-    int numDiagnostics = diagnostics == null ? 0 : diagnostics.size();
-    SimpleTextUtil.write(output, SI_NUM_DIAG);
-    SimpleTextUtil.write(output, Integer.toString(numDiagnostics), scratch);
-    SimpleTextUtil.writeNewline(output);
+      Map<String,String> diagnostics = si.getDiagnostics();
+      int numDiagnostics = diagnostics == null ? 0 : diagnostics.size();
+      SimpleTextUtil.write(output, SI_NUM_DIAG);
+      SimpleTextUtil.write(output, Integer.toString(numDiagnostics), scratch);
+      SimpleTextUtil.writeNewline(output);
     
-    if (numDiagnostics > 0) {
-      for (Map.Entry<String,String> diagEntry : diagnostics.entrySet()) {
-        SimpleTextUtil.write(output, SI_DIAG_KEY);
-        SimpleTextUtil.write(output, diagEntry.getKey(), scratch);
-        SimpleTextUtil.writeNewline(output);
+      if (numDiagnostics > 0) {
+        for (Map.Entry<String,String> diagEntry : diagnostics.entrySet()) {
+          SimpleTextUtil.write(output, SI_DIAG_KEY);
+          SimpleTextUtil.write(output, diagEntry.getKey(), scratch);
+          SimpleTextUtil.writeNewline(output);
         
-        SimpleTextUtil.write(output, SI_DIAG_VALUE);
-        SimpleTextUtil.write(output, diagEntry.getValue(), scratch);
-        SimpleTextUtil.writeNewline(output);
+          SimpleTextUtil.write(output, SI_DIAG_VALUE);
+          SimpleTextUtil.write(output, diagEntry.getValue(), scratch);
+          SimpleTextUtil.writeNewline(output);
+        }
+      }
+      success = true;
+    } finally {
+      if (!success) {
+        IOUtils.closeWhileHandlingException(output);
+      } else {
+        output.close();
       }
     }
   }
-
-  @Override
-  public void prepareCommit(IndexOutput out) throws IOException {
-    ((ChecksumIndexOutput)out).prepareCommit();
-  }
-
-  @Override
-  public void finishCommit(IndexOutput out) throws IOException {
-    ((ChecksumIndexOutput)out).finishCommit();
-    out.close();
-  }
 }
diff --git a/lucene/core/src/java/org/apache/lucene/index/CheckIndex.java b/lucene/core/src/java/org/apache/lucene/index/CheckIndex.java
index 71fdc67..62cf955 100644
--- a/lucene/core/src/java/org/apache/lucene/index/CheckIndex.java
+++ b/lucene/core/src/java/org/apache/lucene/index/CheckIndex.java
@@ -410,6 +410,8 @@ public class CheckIndex {
     String sFormat = "";
     boolean skip = false;
 
+    // nocommit fixme
+    /*
     if (format == SegmentInfos.FORMAT_DIAGNOSTICS) {
       sFormat = "FORMAT_DIAGNOSTICS [Lucene 2.9]";
     } else if (format == SegmentInfos.FORMAT_HAS_VECTORS) {
@@ -427,6 +429,8 @@ public class CheckIndex {
       sFormat = "int=" + format + " [older version of Lucene than this tool supports]";
       skip = true;
     }
+    */
+    sFormat = "nocommit not working yet";
 
     result.segmentsFileName = segmentsFileName;
     result.numSegments = numSegments;
@@ -1588,7 +1592,7 @@ public class CheckIndex {
     if (result.partial)
       throw new IllegalArgumentException("can only fix an index that was fully checked (this status checked a subset of segments)");
     result.newSegments.changed();
-    result.newSegments.commit(result.dir, codec);
+    result.newSegments.commit(result.dir);
   }
 
   private static boolean assertsOn;
diff --git a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushQueue.java b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushQueue.java
index c960201..312bf64 100644
--- a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushQueue.java
+++ b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushQueue.java
@@ -170,7 +170,7 @@ class DocumentsWriterFlushQueue {
     protected abstract boolean canPublish();
   }
   
-  static final class GlobalDeletesTicket extends FlushTicket{
+  static final class GlobalDeletesTicket extends FlushTicket {
 
     protected GlobalDeletesTicket(FrozenBufferedDeletes frozenDeletes) {
       super(frozenDeletes);
diff --git a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java
index 4d9a07b..2606ba0 100644
--- a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java
+++ b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java
@@ -114,13 +114,15 @@ class DocumentsWriterPerThread {
 
   static class FlushedSegment {
     final SegmentInfo segmentInfo;
+    final FieldInfos fieldInfos;
     final BufferedDeletes segmentDeletes;
     final MutableBits liveDocs;
     final int delCount;
 
-    private FlushedSegment(SegmentInfo segmentInfo,
+    private FlushedSegment(SegmentInfo segmentInfo, FieldInfos fieldInfos,
                            BufferedDeletes segmentDeletes, MutableBits liveDocs, int delCount) {
       this.segmentInfo = segmentInfo;
+      this.fieldInfos = fieldInfos;
       this.segmentDeletes = segmentDeletes;
       this.liveDocs = liveDocs;
       this.delCount = delCount;
@@ -476,9 +478,10 @@ class DocumentsWriterPerThread {
       consumer.flush(flushState);
       pendingDeletes.terms.clear();
       final SegmentInfo newSegment = new SegmentInfo(directory, Constants.LUCENE_MAIN_VERSION, segment, flushState.numDocs,
-                                                     SegmentInfo.NO, -1, segment, false, null, false, 0,
+                                                     0, segment, false, null, false, 0,
                                                      flushState.codec,
                                                      null);
+
       if (infoStream.isEnabled("DWPT")) {
         infoStream.message("DWPT", "new segment has " + (flushState.liveDocs == null ? 0 : (flushState.numDocs - flushState.delCountOnFlush)) + " deleted docs");
         infoStream.message("DWPT", "new segment has " +
@@ -490,6 +493,7 @@ class DocumentsWriterPerThread {
         infoStream.message("DWPT", "flushedFiles=" + newSegment.files());
         infoStream.message("DWPT", "flushed codec=" + newSegment.getCodec());
       }
+
       flushedDocCount += flushState.numDocs;
 
       final BufferedDeletes segmentDeletes;
@@ -511,7 +515,7 @@ class DocumentsWriterPerThread {
       doAfterFlush();
       success = true;
 
-      return new FlushedSegment(newSegment, segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);
+      return new FlushedSegment(newSegment, flushState.fieldInfos, segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);
     } finally {
       if (!success) {
         if (segment != null) {
diff --git a/lucene/core/src/java/org/apache/lucene/index/FieldInfo.java b/lucene/core/src/java/org/apache/lucene/index/FieldInfo.java
index 5c7e780..c69281a 100644
--- a/lucene/core/src/java/org/apache/lucene/index/FieldInfo.java
+++ b/lucene/core/src/java/org/apache/lucene/index/FieldInfo.java
@@ -96,7 +96,8 @@ public final class FieldInfo {
       assert normType == null;
       assert indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;
     } else {
-      assert omitNorms || normsType != null;
+      // nocommit this trips:
+      //assert omitNorms || normType != null;
       assert indexOptions != null;
     }
 
diff --git a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java
index 784a6ac..7fb9af3 100644
--- a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java
+++ b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java
@@ -732,6 +732,8 @@ public class IndexWriter implements Closeable, TwoPhaseCommit {
     final FieldNumberBiMap map  = new FieldNumberBiMap();
 
     if (segmentInfos.size() > 0) {
+      // nocommit fixme for 3.x indices...
+      /*
       if (segmentInfos.getFormat() > SegmentInfos.FORMAT_DIAGNOSTICS) {
         // Pre-3.1 index.  In this case we sweep all
         // segments, merging their FieldInfos:
@@ -741,12 +743,17 @@ public class IndexWriter implements Closeable, TwoPhaseCommit {
           }
         }
       } else {
+      */
         // Already >= 3.1 index; just seed the FieldInfos
         // from the last segment
         for(FieldInfo fi : getFieldInfos(segmentInfos.info(segmentInfos.size()-1))) {
           map.addOrGet(fi.name, fi.number);
         }
-      }
+
+        // nocommit we can also pull the DV types of the
+        // fields... and catch DV type change on addDoc
+        // instead of much later in merge
+        //}
     }
 
     return map;
@@ -2020,6 +2027,7 @@ public class IndexWriter implements Closeable, TwoPhaseCommit {
           infoStream.message("IW", "creating compound file " + compoundFileName);
         }
         // Now build compound file
+        // nocommit factor to use craeteCompoundFile method!?
         final Directory cfsDir = new CompoundFileDirectory(directory, compoundFileName, context, true);
         IOException prior = null;
         try {
@@ -2040,6 +2048,17 @@ public class IndexWriter implements Closeable, TwoPhaseCommit {
         newSegment.setUseCompoundFile(true);
       }
 
+      // Have codec write SegmentInfo.  Must do this after
+      // creating CFS so that 1) .si isn't slurped into CFS,
+      // and 2) .si reflects useCompoundFile=true change
+      // above:
+      codec.segmentInfosFormat().getSegmentInfosWriter().write(newSegment, flushedSegment.fieldInfos);
+      newSegment.clearFilesCache();
+
+      // nocommit ideally we would freeze merge.info here!!
+      // because any changes after writing the .si will be
+      // lost... 
+
       // Must write deleted docs after the CFS so we don't
       // slurp the del file into CFS:
       if (flushedSegment.liveDocs != null) {
@@ -2208,6 +2227,7 @@ public class IndexWriter implements Closeable, TwoPhaseCommit {
         sis.read(dir);
         final Set<String> dsFilesCopied = new HashSet<String>();
         final Map<String, String> dsNames = new HashMap<String, String>();
+        final Set<String> copiedFiles = new HashSet<String>();
         for (SegmentInfo info : sis) {
           assert !infos.contains(info): "dup info dir=" + info.dir + " name=" + info.name;
 
@@ -2220,9 +2240,7 @@ public class IndexWriter implements Closeable, TwoPhaseCommit {
 
           IOContext context = new IOContext(new MergeInfo(info.docCount, info.sizeInBytes(), true, -1));
           
-          copySegmentAsIs(info, newSegName, dsNames, dsFilesCopied, context);
-
-          infos.add(info);
+          infos.add(copySegmentAsIs(info, newSegName, dsNames, dsFilesCopied, context, copiedFiles));
         }
       }
 
@@ -2289,7 +2307,7 @@ public class IndexWriter implements Closeable, TwoPhaseCommit {
       MergeState mergeState = merger.merge();                // merge 'em
       int docCount = mergeState.mergedDocCount;
       SegmentInfo info = new SegmentInfo(directory, Constants.LUCENE_MAIN_VERSION, mergedName, docCount,
-                                         SegmentInfo.NO, -1, mergedName, false, null, false, 0,
+                                         -1, mergedName, false, null, false, 0,
                                          codec, null);
                                          
       setDiagnostics(info, "addIndexes(IndexReader...)");
@@ -2316,6 +2334,13 @@ public class IndexWriter implements Closeable, TwoPhaseCommit {
         info.setUseCompoundFile(true);
       }
 
+      // Have codec write SegmentInfo.  Must do this after
+      // creating CFS so that 1) .si isn't slurped into CFS,
+      // and 2) .si reflects useCompoundFile=true change
+      // above:
+      codec.segmentInfosFormat().getSegmentInfosWriter().write(info, mergeState.fieldInfos);
+      info.clearFilesCache();
+
       // Register the new segment
       synchronized(this) {
         if (stopMerges) {
@@ -2332,8 +2357,9 @@ public class IndexWriter implements Closeable, TwoPhaseCommit {
   }
 
   /** Copies the segment files as-is into the IndexWriter's directory. */
-  private void copySegmentAsIs(SegmentInfo info, String segName,
-      Map<String, String> dsNames, Set<String> dsFilesCopied, IOContext context)
+  private SegmentInfo copySegmentAsIs(SegmentInfo info, String segName,
+                                      Map<String, String> dsNames, Set<String> dsFilesCopied, IOContext context,
+                                      Set<String> copiedFiles)
       throws IOException {
     // Determine if the doc store of this segment needs to be copied. It's
     // only relevant for segments that share doc store with others,
@@ -2352,12 +2378,22 @@ public class IndexWriter implements Closeable, TwoPhaseCommit {
     Set<String> codecDocStoreFiles = new HashSet<String>();
     if (info.getDocStoreOffset() != -1) {
       // only violate the codec this way if its preflex
-      codec.storedFieldsFormat().files(info, codecDocStoreFiles);
-      codec.termVectorsFormat().files(info, codecDocStoreFiles);
+      info.getCodec().storedFieldsFormat().files(info, codecDocStoreFiles);
+      info.getCodec().termVectorsFormat().files(info, codecDocStoreFiles);
     }
+
+    //System.out.println("copy seg=" + info.name + " version=" + info.getVersion());
     
     // Copy the segment files
     for (String file: info.files()) {
+
+      // nocommit messy: insteda we should pull .files()
+      // from the codec's SIFormat and check if it's in
+      // there...
+      if (file.endsWith(".si")) {
+        continue;
+      }
+
       final String newFileName;
       if (codecDocStoreFiles.contains(file)) {
         newFileName = newDsName + IndexFileNames.stripSegmentName(file);
@@ -2368,14 +2404,30 @@ public class IndexWriter implements Closeable, TwoPhaseCommit {
       } else {
         newFileName = segName + IndexFileNames.stripSegmentName(file);
       }
-      
+
       assert !directory.fileExists(newFileName): "file \"" + newFileName + "\" already exists";
+      assert !copiedFiles.contains(file): "file \"" + file + "\" is being copied more than once";
+      copiedFiles.add(file);
+      //System.out.println("COPY " + file + " -> " + newFileName);
       info.dir.copy(directory, file, newFileName, context);
     }
     
-    info.setDocStore(info.getDocStoreOffset(), newDsName, info.getDocStoreIsCompoundFile());
-    info.dir = directory;
-    info.name = segName;
+    // Same SI as before but we change directory and name:
+    SegmentInfo newInfo = new SegmentInfo(directory, info.getVersion(), segName, info.docCount, info.getDocStoreOffset(),
+                                          newDsName, info.getDocStoreIsCompoundFile(), info.getNormGen(), info.getUseCompoundFile(),
+                                          info.getDelCount(), info.getCodec(), info.getDiagnostics());
+    newInfo.setDelGen(info.getDelGen());
+
+    // nocommit need to pass real FIS...
+    // nocommit maybe we don't pass FIS......?
+    // nocommit messy....
+    //if (!newInfo.getCodec().getName().equals("Lucene3x")) {
+    if (!newInfo.getVersion().startsWith("3.")) {
+      //System.out.println("  now write si for seg=" + newInfo.name + " codec=" + newInfo.getCodec());
+      newInfo.getCodec().segmentInfosFormat().getSegmentInfosWriter().write(newInfo, null);
+    }
+    
+    return newInfo;
   }
   
   /**
@@ -2614,7 +2666,7 @@ public class IndexWriter implements Closeable, TwoPhaseCommit {
         if (infoStream.isEnabled("IW")) {
           infoStream.message("IW", "commit: pendingCommit != null");
         }
-        pendingCommit.finishCommit(directory, codec);
+        pendingCommit.finishCommit(directory);
         if (infoStream.isEnabled("IW")) {
           infoStream.message("IW", "commit: wrote segments file \"" + pendingCommit.getSegmentsFileName() + "\"");
         }
@@ -3195,15 +3247,14 @@ public class IndexWriter implements Closeable, TwoPhaseCommit {
       throw new IllegalStateException("this writer hit an OutOfMemoryError; cannot merge");
     }
 
-    // TODO: is there any perf benefit to sorting
-    // merged segments?  eg biggest to smallest?
-
-    if (merge.info != null)
+    if (merge.info != null) {
       // mergeInit already done
       return;
+    }
 
-    if (merge.isAborted())
+    if (merge.isAborted()) {
       return;
+    }
 
     // Bind a new segment name here so even with
     // ConcurrentMergePolicy we keep deterministic segment
@@ -3440,6 +3491,9 @@ public class IndexWriter implements Closeable, TwoPhaseCommit {
       // ctor when we make the merge.info:
       merge.info.setCodec(codec);
 
+      // nocommit should segment merger do this!?  else
+      // other places must do so...??? addIndexes...
+
       if (infoStream.isEnabled("IW")) {
         infoStream.message("IW", "merge codec=" + codec + " docCount=" + mergedDocCount + "; merged segment has " +
                            (mergeState.fieldInfos.hasVectors() ? "vectors" : "no vectors") + "; " +
@@ -3514,6 +3568,20 @@ public class IndexWriter implements Closeable, TwoPhaseCommit {
         merge.info.setUseCompoundFile(true);
       }
 
+      // nocommit need try/success thingy...?  ie must
+      // remove all seg files if we fail to write the .si?
+
+      // Have codec write SegmentInfo.  Must do this after
+      // creating CFS so that 1) .si isn't slurped into CFS,
+      // and 2) .si reflects useCompoundFile=true change
+      // above:
+      codec.segmentInfosFormat().getSegmentInfosWriter().write(merge.info, mergeState.fieldInfos);
+      merge.info.clearFilesCache();
+
+      // nocommit ideally we would freeze merge.info here!!
+      // because any changes after writing the .si will be
+      // lost... 
+
       if (infoStream.isEnabled("IW")) {
         infoStream.message("IW", String.format("merged segment size=%.3f MB vs estimate=%.3f MB", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));
       }
@@ -3706,9 +3774,6 @@ public class IndexWriter implements Closeable, TwoPhaseCommit {
       boolean pendingCommitSet = false;
 
       try {
-        // This call can take a long time -- 10s of seconds
-        // or more.  We do it without sync:
-        directory.sync(toSync.files(directory, false));
 
         assert testPoint("midStartCommit2");
 
@@ -3721,14 +3786,33 @@ public class IndexWriter implements Closeable, TwoPhaseCommit {
           // Exception here means nothing is prepared
           // (this method unwinds everything it did on
           // an exception)
-          toSync.prepareCommit(directory, codec);
+          toSync.prepareCommit(directory);
+          //System.out.println("DONE prepareCommit");
 
           pendingCommitSet = true;
           pendingCommit = toSync;
         }
 
+        // nocommit move this back above...?  problem is
+        // prepareCommit writes on the _X.si files... which
+        // of course need to be sync'd too...
+        // This call can take a long time -- 10s of seconds
+        // or more.  We do it without sync:
+        boolean success = false;
+        final Collection<String> filesToSync = toSync.files(directory, false);
+        try {
+          directory.sync(filesToSync);
+          success = true;
+        } finally {
+          if (!success) {
+            pendingCommitSet = false;
+            pendingCommit = null;
+            toSync.rollbackCommit(directory);
+          }
+        }
+
         if (infoStream.isEnabled("IW")) {
-          infoStream.message("IW", "done all syncs");
+          infoStream.message("IW", "done all syncs: " + filesToSync);
         }
 
         assert testPoint("midStartCommitSuccess");
diff --git a/lucene/core/src/java/org/apache/lucene/index/SegmentInfo.java b/lucene/core/src/java/org/apache/lucene/index/SegmentInfo.java
index a35d5bc..4fd70ca 100644
--- a/lucene/core/src/java/org/apache/lucene/index/SegmentInfo.java
+++ b/lucene/core/src/java/org/apache/lucene/index/SegmentInfo.java
@@ -41,17 +41,19 @@ import org.apache.lucene.util.Constants;
  *
  * @lucene.experimental
  */
-public final class SegmentInfo implements Cloneable {
-  public static final int CHECK_FIELDINFO = -2;
+public class SegmentInfo implements Cloneable {
   
   // TODO: remove these from this class, for now this is the representation
   public static final int NO = -1;          // e.g. no norms; no deletes;
   public static final int YES = 1;          // e.g. have norms; have deletes;
   public static final int WITHOUT_GEN = 0;  // a file name that has no GEN in it.
 
-  public String name;				  // unique name in dir
+  public final String name;				  // unique name in dir
+  // nocommit make me final:
   public int docCount;				  // number of docs in seg
-  public Directory dir;				  // where segment resides
+  public final Directory dir;				  // where segment resides
+
+  // nocommit what other members can we make final?
 
   /*
    * Current generation of del file:
@@ -129,14 +131,14 @@ public final class SegmentInfo implements Cloneable {
    * <p>Note: this is public only to allow access from
    * the codecs package.</p>
    */
-  public SegmentInfo(Directory dir, String version, String name, int docCount, long delGen, int docStoreOffset,
-      String docStoreSegment, boolean docStoreIsCompoundFile, Map<Integer,Long> normGen, boolean isCompoundFile,
-      int delCount, Codec codec, Map<String,String> diagnostics) {
+  public SegmentInfo(Directory dir, String version, String name, int docCount, int docStoreOffset,
+                     String docStoreSegment, boolean docStoreIsCompoundFile, Map<Integer,Long> normGen, boolean isCompoundFile,
+                     int delCount, Codec codec, Map<String,String> diagnostics) {
     this.dir = dir;
     this.version = version;
     this.name = name;
     this.docCount = docCount;
-    this.delGen = delGen;
+    this.delGen = NO;
     this.docStoreOffset = docStoreOffset;
     this.docStoreSegment = docStoreSegment;
     this.docStoreIsCompoundFile = docStoreIsCompoundFile;
@@ -192,6 +194,7 @@ public final class SegmentInfo implements Cloneable {
     clearFilesCache();
   }
 
+  // nocommit this is dangerous... because we lose the codec's customzied class...
   @Override
   public SegmentInfo clone() {
     final HashMap<Integer,Long> clonedNormGen;
@@ -204,9 +207,11 @@ public final class SegmentInfo implements Cloneable {
       clonedNormGen = null;
     }
 
-    return new SegmentInfo(dir, version, name, docCount, delGen, docStoreOffset,
-                           docStoreSegment, docStoreIsCompoundFile, clonedNormGen, isCompoundFile,
-                           delCount, codec, new HashMap<String,String>(diagnostics));
+    SegmentInfo newInfo = new SegmentInfo(dir, version, name, docCount, docStoreOffset,
+                                          docStoreSegment, docStoreIsCompoundFile, clonedNormGen, isCompoundFile,
+                                          delCount, codec, new HashMap<String,String>(diagnostics));
+    newInfo.setDelGen(delGen);
+    return newInfo;
   }
 
   /**
@@ -255,6 +260,10 @@ public final class SegmentInfo implements Cloneable {
     assert delCount <= docCount;
   }
 
+  public void setDelGen(long delGen) {
+    this.delGen = delGen;
+  }
+
   /**
    * @deprecated shared doc stores are not supported in >= 4.0
    */
@@ -307,7 +316,7 @@ public final class SegmentInfo implements Cloneable {
     return codec;
   }
 
-  // nocommit move elsewhere?  IndexFileNames?
+  // noocmmit nuke this and require, once again, that a codec puts PRECISELY the files that exist into the file set...
   public static List<String> findMatchingFiles(String segmentName, Directory dir, Set<String> namesOrPatterns) {
     // nocommit need more efficient way to do this?
     List<String> files = new ArrayList<String>();
@@ -321,6 +330,10 @@ public final class SegmentInfo implements Cloneable {
     List<Pattern> compiledPatterns = new ArrayList<Pattern>();
     for(String nameOrPattern : namesOrPatterns) {
       boolean exists = false;
+      // nocommit hack -- remove (needed now because si's -1 gen will return null file name):
+      if (nameOrPattern == null) {
+        continue;
+      }
       try {
         exists = dir.fileExists(nameOrPattern);
       } catch (IOException ioe) {
@@ -368,7 +381,8 @@ public final class SegmentInfo implements Cloneable {
 
   /* Called whenever any change is made that affects which
    * files this segment has. */
-  private void clearFilesCache() {
+  // nocommit make private again
+  void clearFilesCache() {
     sizeInBytes = -1;
     files = null;
   }
diff --git a/lucene/core/src/java/org/apache/lucene/index/SegmentInfos.java b/lucene/core/src/java/org/apache/lucene/index/SegmentInfos.java
index 963a55b..2ab6ab0 100644
--- a/lucene/core/src/java/org/apache/lucene/index/SegmentInfos.java
+++ b/lucene/core/src/java/org/apache/lucene/index/SegmentInfos.java
@@ -34,13 +34,19 @@ import java.util.Set;
 import org.apache.lucene.codecs.Codec;
 import org.apache.lucene.codecs.SegmentInfosReader;
 import org.apache.lucene.codecs.SegmentInfosWriter;
+import org.apache.lucene.codecs.lucene3x.Lucene3xCodec;
+import org.apache.lucene.codecs.lucene3x.Lucene3xSegmentInfosFormat;
+import org.apache.lucene.codecs.lucene3x.Lucene3xSegmentInfosReader;
 import org.apache.lucene.store.ChecksumIndexInput;
+import org.apache.lucene.store.ChecksumIndexOutput;
+import org.apache.lucene.store.DataOutput; // javadocs
 import org.apache.lucene.store.Directory;
+import org.apache.lucene.store.FlushInfo;
 import org.apache.lucene.store.IOContext;
-import org.apache.lucene.store.DataOutput; // javadocs
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.store.IndexOutput;
 import org.apache.lucene.store.NoSuchDirectoryException;
+import org.apache.lucene.util.CodecUtil;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.ThreadInterruptedException;
 
@@ -87,43 +93,25 @@ public final class SegmentInfos implements Cloneable, Iterable<SegmentInfo> {
   // also i think this class should write this, somehow we let 
   // preflexrw hackishly override this (like seek backwards and overwrite it)
 
-  /** This format adds optional per-segment String
-   *  diagnostics storage, and switches userData to Map */
-  public static final int FORMAT_DIAGNOSTICS = -9;
-
-  /** Each segment records whether it has term vectors */
-  public static final int FORMAT_HAS_VECTORS = -10;
-
-  /** Each segment records the Lucene version that created it. */
-  public static final int FORMAT_3_1 = -11;
+  // nocommit fix to read 3.x...
 
-  /** Each segment records whether its postings are written
-   *  in the new flex format */
-  public static final int FORMAT_4_0 = -12;
+  public static final int VERSION_40 = 0;
 
-  /** This must always point to the most recent file format.
-   * whenever you add a new format, make it 1 smaller (negative version logic)! */
-  // TODO: move this, as its currently part of required preamble
-  public static final int FORMAT_CURRENT = FORMAT_4_0;
-  
-  /** This must always point to the first supported file format. */
-  public static final int FORMAT_MINIMUM = FORMAT_DIAGNOSTICS;
-  
   /** Used for the segments.gen file only!
    * Whenever you add a new format, make it 1 smaller (negative version logic)! */
   public static final int FORMAT_SEGMENTS_GEN_CURRENT = -2;
-    
+
   public int counter;    // used to name new segments
   
   /**
    * counts how often the index has been changed
    */
   public long version;
-  
+
   private long generation;     // generation of the "segments_N" for the next commit
   private long lastGeneration; // generation of the "segments_N" file we last successfully read
-                                   // or wrote; this is normally the same as generation except if
-                                   // there was an IOException that had interrupted a commit
+                               // or wrote; this is normally the same as generation except if
+                               // there was an IOException that had interrupted a commit
 
   public Map<String,String> userData = Collections.<String,String>emptyMap();       // Opaque Map<String, String> that user can specify during IndexWriter.commit
 
@@ -278,41 +266,55 @@ public final class SegmentInfos implements Cloneable, Iterable<SegmentInfo> {
     // TODO: scary to have default impl reopen the file... but to make it a bit more flexible,
     // maybe we could use a plain indexinput here... could default impl rewind/wrap with checksumII,
     // and any checksumming is then up to implementation?
-    ChecksumIndexInput input = null;
+    ChecksumIndexInput input = new ChecksumIndexInput(directory.openInput(segmentFileName, IOContext.READ));
     try {
-      input = new ChecksumIndexInput(directory.openInput(segmentFileName, IOContext.READ));
       final int format = input.readInt();
-      setFormat(format);
-    
-      // check that it is a format we can understand
-      if (format > FORMAT_MINIMUM)
-        throw new IndexFormatTooOldException(input, format,
-          FORMAT_MINIMUM, FORMAT_CURRENT);
-      if (format < FORMAT_CURRENT)
-        throw new IndexFormatTooNewException(input, format,
-          FORMAT_MINIMUM, FORMAT_CURRENT);
-
-      if (format <= FORMAT_4_0) {
-        codecFormat = Codec.forName(input.readString());
+      final boolean checkCheckSum;
+      if (format == CodecUtil.CODEC_MAGIC) {
+        // 4.0+
+        CodecUtil.checkHeaderNoMagic(input, "segments", VERSION_40, VERSION_40);
+        version = input.readLong();
+        counter = input.readInt();
+        int numSegments = input.readInt();
+        for(int seg=0;seg<numSegments;seg++) {
+          String segName = input.readString();
+          Codec codec = Codec.forName(input.readString());
+          //System.out.println("SIS.read seg=" + seg + " codec=" + codec);
+          SegmentInfo info = codec.segmentInfosFormat().getSegmentInfosReader().read(directory, segName);
+          info.setCodec(codec);
+          info.setDelGen(input.readLong());
+          info.setDelCount(input.readInt());
+          add(info);
+        }
+        userData = input.readStringStringMap();
       } else {
-        codecFormat = Codec.forName("Lucene3x");
+        // nocommit 3.x needs normGens too ... we can push
+        // down to make this 3.x private????
+        Lucene3xSegmentInfosReader.readLegacyInfos(this, directory, input, format);
+        Codec codec = Codec.forName("Lucene3x");
+        for (SegmentInfo info : this) {
+          info.setCodec(codec);
+        }
       }
-      SegmentInfosReader infosReader = codecFormat.segmentInfosFormat().getSegmentInfosReader();
-      infosReader.read(directory, segmentFileName, input, this, IOContext.READ);
+
+      // nocommit all 3.x indices have checksum right...????
+      // ie we added it during 2.x? i think so!
+
       final long checksumNow = input.getChecksum();
       final long checksumThen = input.readLong();
-      if (checksumNow != checksumThen)
+      if (checksumNow != checksumThen) {
         throw new CorruptIndexException("checksum mismatch in segments file (resource: " + input + ")");
-      success = true;
-    }
-    finally {
-      if (input != null) {
-        input.close();
       }
+
+      success = true;
+    } finally {
       if (!success) {
         // Clear any segment infos we had loaded so we
         // have a clean slate on retry:
         this.clear();
+        IOUtils.closeWhileHandlingException(input);
+      } else {
+        input.close();
       }
     }
   }
@@ -332,9 +334,9 @@ public final class SegmentInfos implements Cloneable, Iterable<SegmentInfo> {
 
   // Only non-null after prepareCommit has been called and
   // before finishCommit is called
-  IndexOutput pendingSegnOutput;
+  ChecksumIndexOutput pendingSegnOutput;
 
-  private void write(Directory directory, Codec codec) throws IOException {
+  private void write(Directory directory) throws IOException {
 
     String segmentFileName = getNextSegmentFileName();
     
@@ -345,15 +347,43 @@ public final class SegmentInfos implements Cloneable, Iterable<SegmentInfo> {
       generation++;
     }
     
-    IndexOutput segnOutput = null;
-    
-
+    ChecksumIndexOutput segnOutput = null;
     boolean success = false;
 
+    // nocommit document somewhere taht we store this
+    // list-of-segs plus delGen plus other stuff
+    // "generically" and then codec gets to write SI
+
     try {
-      SegmentInfosWriter infosWriter = codec.segmentInfosFormat().getSegmentInfosWriter();
-      segnOutput = infosWriter.writeInfos(directory, segmentFileName, codec.getName(), this, IOContext.DEFAULT);
-      infosWriter.prepareCommit(segnOutput);
+      // nocommit what IOCtx to use...
+      segnOutput = new ChecksumIndexOutput(directory.createOutput(segmentFileName, new IOContext(new FlushInfo(totalDocCount(), 0))));
+      CodecUtil.writeHeader(segnOutput, "segments", VERSION_40);
+      segnOutput.writeLong(version); 
+      segnOutput.writeInt(counter); // write counter
+      segnOutput.writeInt(size()); // write infos
+      Codec codec3X = Codec.forName("Lucene3x");
+      for (SegmentInfo si : this) {
+        segnOutput.writeString(si.name);
+        segnOutput.writeString(si.getCodec().getName());
+        segnOutput.writeLong(si.getDelGen());
+        segnOutput.writeInt(si.getDelCount());
+        assert si.dir == directory;
+
+        // nocommit hacky!
+        String version = si.getVersion();
+        if (version == null || version.startsWith("3.")) {
+          String fileName = IndexFileNames.segmentFileName(si.name, "", Lucene3xSegmentInfosFormat.SI_EXTENSION);
+          if (!directory.fileExists(fileName)) {
+            //System.out.println("write 3x info seg=" + si.name + " version=" + si.getVersion() + " codec=" + si.getCodec().getName());
+            write3xInfo(si);
+            // nocommit do this after, on success...
+            //si.setVersion("4.0");
+            si.clearFilesCache();
+          }
+        }
+      }
+      segnOutput.writeStringStringMap(userData);
+      segnOutput.prepareCommit();
       pendingSegnOutput = segnOutput;
       success = true;
     } finally {
@@ -361,6 +391,9 @@ public final class SegmentInfos implements Cloneable, Iterable<SegmentInfo> {
         // We hit an exception above; try to close the file
         // but suppress any exception:
         IOUtils.closeWhileHandlingException(segnOutput);
+
+        // nocommit must also remove any written .si files...
+
         try {
           // Try not to leave a truncated segments_N file in
           // the index:
@@ -372,6 +405,66 @@ public final class SegmentInfos implements Cloneable, Iterable<SegmentInfo> {
     }
   }
 
+  // nocommit copy of PreflexRWSegmentInfosWriter.write!!
+
+  @Deprecated
+  public void write3xInfo(SegmentInfo si) throws IOException {
+
+    // NOTE: this is NOT how 3.x is really written...
+    String fileName = IndexFileNames.segmentFileName(si.name, "", Lucene3xSegmentInfosFormat.SI_EXTENSION);
+    //System.out.println("UPGRADE write " + fileName);
+    // nocommit what IOCtx
+    boolean success = false;
+
+    IndexOutput output = si.dir.createOutput(fileName, new IOContext(new FlushInfo(0, 0)));
+    try {
+      // we are about to write this SI in 3.x format, dropping all codec information, etc.
+      // so it had better be a 3.x segment or you will get very confusing errors later.
+      assert si.getCodec() instanceof Lucene3xCodec : "broken test, trying to mix preflex with other codecs";
+      assert si.getDelCount() <= si.docCount: "delCount=" + si.getDelCount() + " docCount=" + si.docCount + " segment=" + si.name;
+      // Write the Lucene version that created this segment, since 3.1
+      output.writeString(si.getVersion());
+      output.writeString(si.name);
+      output.writeInt(si.docCount);
+      output.writeLong(si.getDelGen());
+
+      output.writeInt(si.getDocStoreOffset());
+      if (si.getDocStoreOffset() != -1) {
+        output.writeString(si.getDocStoreSegment());
+        output.writeByte((byte) (si.getDocStoreIsCompoundFile() ? 1:0));
+      }
+      // pre-4.0 indexes write a byte if there is a single norms file
+      output.writeByte((byte) 1);
+
+      Map<Integer,Long> normGen = si.getNormGen();
+      if (normGen == null) {
+        output.writeInt(SegmentInfo.NO);
+      } else {
+        output.writeInt(normGen.size());
+        for (Map.Entry<Integer,Long> entry : normGen.entrySet()) {
+          output.writeLong(entry.getValue());
+        }
+      }
+
+      output.writeByte((byte) (si.getUseCompoundFile() ? SegmentInfo.YES : SegmentInfo.NO));
+      output.writeInt(si.getDelCount());
+      // hasProx:
+      output.writeByte((byte) 1);
+      output.writeStringStringMap(si.getDiagnostics());
+      // hasVectors:
+      output.writeByte((byte) 1);
+
+      success = true;
+    } finally {
+      if (!success) {
+        IOUtils.closeWhileHandlingException(output);
+        si.dir.deleteFile(fileName);
+      } else {
+        output.close();
+      }
+    }
+  }
+
   /**
    * Returns a copy of this instance, also copying each
    * SegmentInfo.
@@ -730,10 +823,11 @@ public final class SegmentInfos implements Cloneable, Iterable<SegmentInfo> {
    *  method if changes have been made to this {@link SegmentInfos} instance
    *  </p>  
    **/
-  final void prepareCommit(Directory dir, Codec codec) throws IOException {
-    if (pendingSegnOutput != null)
+  final void prepareCommit(Directory dir) throws IOException {
+    if (pendingSegnOutput != null) {
       throw new IllegalStateException("prepareCommit was already called");
-    write(dir, codec);
+    }
+    write(dir);
   }
 
   /** Returns all file names referenced by SegmentInfo
@@ -763,18 +857,22 @@ public final class SegmentInfos implements Cloneable, Iterable<SegmentInfo> {
     return files;
   }
 
-  final void finishCommit(Directory dir, Codec codec) throws IOException {
-    if (pendingSegnOutput == null)
+  final void finishCommit(Directory dir) throws IOException {
+    if (pendingSegnOutput == null) {
       throw new IllegalStateException("prepareCommit was not called");
+    }
     boolean success = false;
     try {
-      SegmentInfosWriter infosWriter = codec.segmentInfosFormat().getSegmentInfosWriter();
-      infosWriter.finishCommit(pendingSegnOutput);
-      pendingSegnOutput = null;
+      pendingSegnOutput.finishCommit();
       success = true;
     } finally {
-      if (!success)
+      if (!success) {
+        IOUtils.closeWhileHandlingException(pendingSegnOutput);
         rollbackCommit(dir);
+      } else {
+        pendingSegnOutput.close();
+        pendingSegnOutput = null;
+      }
     }
 
     // NOTE: if we crash here, we have left a segments_N
@@ -836,9 +934,9 @@ public final class SegmentInfos implements Cloneable, Iterable<SegmentInfo> {
    *  method if changes have been made to this {@link SegmentInfos} instance
    *  </p>  
    **/
-  final void commit(Directory dir, Codec codec) throws IOException {
-    prepareCommit(dir, codec);
-    finishCommit(dir, codec);
+  final void commit(Directory dir) throws IOException {
+    prepareCommit(dir);
+    finishCommit(dir);
   }
 
   public String toString(Directory directory) {
diff --git a/lucene/core/src/java/org/apache/lucene/index/TermVectorsConsumerPerField.java b/lucene/core/src/java/org/apache/lucene/index/TermVectorsConsumerPerField.java
index 7298391..b212848 100644
--- a/lucene/core/src/java/org/apache/lucene/index/TermVectorsConsumerPerField.java
+++ b/lucene/core/src/java/org/apache/lucene/index/TermVectorsConsumerPerField.java
@@ -91,8 +91,9 @@ final class TermVectorsConsumerPerField extends TermsHashConsumerPerField {
    *  RAMOutputStream, which is then quickly flushed to
    *  the real term vectors files in the Directory. */  @Override
   void finish() throws IOException {
-    if (!doVectors || termsHashPerField.bytesHash.size() == 0)
+    if (!doVectors || termsHashPerField.bytesHash.size() == 0) {
       return;
+    }
 
     termsWriter.addFieldToFlush(this);
   }
@@ -148,7 +149,7 @@ final class TermVectorsConsumerPerField extends TermsHashConsumerPerField {
 
     termsHashPerField.reset();
 
-    // commit the termVectors once successful success - FI will otherwise reset them
+    // commit the termVectors once successful - FI will otherwise reset them
     fieldInfo.setStoreTermVectors();
   }
 
diff --git a/lucene/core/src/java/org/apache/lucene/index/TypePromoter.java b/lucene/core/src/java/org/apache/lucene/index/TypePromoter.java
index 8c9fec9..97d7372 100644
--- a/lucene/core/src/java/org/apache/lucene/index/TypePromoter.java
+++ b/lucene/core/src/java/org/apache/lucene/index/TypePromoter.java
@@ -21,6 +21,9 @@ import java.util.Map;
 
 import org.apache.lucene.index.DocValues.Type;
 
+// nocommit remove this?  (require DV type does not change
+// for a given field)
+
 /**
  * Type promoter that promotes {@link DocValues} during merge based on
  * their {@link Type} and {@link #getValueSize()}
diff --git a/lucene/core/src/java/org/apache/lucene/store/ChecksumIndexOutput.java b/lucene/core/src/java/org/apache/lucene/store/ChecksumIndexOutput.java
index ca3a17b..d7d9fc2 100644
--- a/lucene/core/src/java/org/apache/lucene/store/ChecksumIndexOutput.java
+++ b/lucene/core/src/java/org/apache/lucene/store/ChecksumIndexOutput.java
@@ -26,6 +26,7 @@ import java.util.zip.Checksum;
  *
  * @lucene.internal
  */
+// nocommit fixme to not seek backwards...
 public class ChecksumIndexOutput extends IndexOutput {
   IndexOutput main;
   Checksum digest;
@@ -84,10 +85,14 @@ public class ChecksumIndexOutput extends IndexOutput {
     // are able to write a long to the file, but 2) not
     // actually "commit" the file yet.  This (prepare
     // commit) is phase 1 of a two-phase commit.
+    // nocommit fixme... or just nuke?  appending codec
+    // fails w/ this:
+    /*
     final long pos = main.getFilePointer();
     main.writeLong(checksum-1);
     main.flush();
     main.seek(pos);
+    */
   }
 
   /** See {@link #prepareCommit} */
diff --git a/lucene/core/src/java/org/apache/lucene/util/CodecUtil.java b/lucene/core/src/java/org/apache/lucene/util/CodecUtil.java
index 014488e..e877a72 100644
--- a/lucene/core/src/java/org/apache/lucene/util/CodecUtil.java
+++ b/lucene/core/src/java/org/apache/lucene/util/CodecUtil.java
@@ -126,7 +126,11 @@ public final class CodecUtil {
     if (actualHeader != CODEC_MAGIC) {
       throw new CorruptIndexException("codec header mismatch: actual header=" + actualHeader + " vs expected header=" + CODEC_MAGIC + " (resource: " + in + ")");
     }
+    return checkHeaderNoMagic(in, codec, minVersion, maxVersion);
+  }
 
+  // nocommit jdocs
+  public static int checkHeaderNoMagic(DataInput in, String codec, int minVersion, int maxVersion) throws IOException {
     final String actualCodec = in.readString();
     if (!actualCodec.equals(codec)) {
       throw new CorruptIndexException("codec mismatch: actual codec=" + actualCodec + " vs expected codec=" + codec + " (resource: " + in + ")");
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestAddIndexes.java b/lucene/core/src/test/org/apache/lucene/index/TestAddIndexes.java
index 7177245..a7634f9 100755
--- a/lucene/core/src/test/org/apache/lucene/index/TestAddIndexes.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestAddIndexes.java
@@ -1114,8 +1114,8 @@ public class TestAddIndexes extends LuceneTestCase {
     w3.addIndexes(readers);
     w3.close();
     // we should now see segments_X,
-    // segments.gen,_Y.cfs,_Y.cfe, _Z.fnx
-    assertEquals("Only one compound segment should exist, but got: " + Arrays.toString(dir.listAll()), 4, dir.listAll().length);
+    // segments.gen,_Y.cfs,_Y.cfe, _Z.si
+    assertEquals("Only one compound segment should exist, but got: " + Arrays.toString(dir.listAll()), 5, dir.listAll().length);
     dir.close();
   }
   
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java b/lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java
index a573c62..d33a4e9 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java
@@ -230,10 +230,16 @@ public class TestBackwardsCompatibility extends LuceneTestCase {
 
   public void testAddOldIndexes() throws IOException {
     for (String name : oldNames) {
+      if (VERBOSE) {
+        System.out.println("\nTEST: old index " + name);
+      }
       Directory targetDir = newDirectory();
       IndexWriter w = new IndexWriter(targetDir, newIndexWriterConfig(
           TEST_VERSION_CURRENT, new MockAnalyzer(random())));
       w.addIndexes(oldIndexDirs.get(name));
+      if (VERBOSE) {
+        System.out.println("\nTEST: done adding indices; now close");
+      }
       w.close();
       
       targetDir.close();
@@ -510,14 +516,16 @@ public class TestBackwardsCompatibility extends LuceneTestCase {
       // Now verify file names... TODO: fix this test better, we could populate from 
       // separateFiles() or something.
       String[] expected = new String[] {"_0.cfs", "_0.cfe",
-                               "_0_1.del",
-                               "segments_2",
-                               "segments.gen"};
+                                        "_0_1.del",
+                                        "_0.si",
+                                        "segments_2",
+                                        "segments.gen"};
       
       String[] expectedSimpleText = new String[] {"_0.cfs", "_0.cfe",
-          "_0_1.liv",
-          "segments_2",
-          "segments.gen"};
+                                                  "_0_1.liv",
+                                                  "_0.si",
+                                                  "segments_2",
+                                                  "segments.gen"};
 
       String[] actual = dir.listAll();
       Arrays.sort(expected);
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestCodecs.java b/lucene/core/src/test/org/apache/lucene/index/TestCodecs.java
index 24223e1..d34d22b 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestCodecs.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestCodecs.java
@@ -312,7 +312,7 @@ public class TestCodecs extends LuceneTestCase {
 
     this.write(fieldInfos, dir, fields, false);
     Codec codec = Codec.getDefault();
-    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, -1, -1,
+    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, -1,
                                            SEGMENT, false, null, false, 0,
                                            codec, null);
 
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestDoc.java b/lucene/core/src/test/org/apache/lucene/index/TestDoc.java
index 618534d..4bae953 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestDoc.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestDoc.java
@@ -201,7 +201,7 @@ public class TestDoc extends LuceneTestCase {
       r1.close();
       r2.close();
       final SegmentInfo info = new SegmentInfo(si1.dir, Constants.LUCENE_MAIN_VERSION, merged,
-                                               si1.docCount + si2.docCount, -1, -1, merged,
+                                               si1.docCount + si2.docCount, -1, merged,
                                                false, null, false, 0, codec, null);
       
       if (useCompoundFile) {
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java
index 04e70a7..0a1f048 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java
@@ -800,6 +800,10 @@ public class TestIndexWriterExceptions extends LuceneTestCase {
         for (int i = 0; i < trace.length; i++) {
           if (doFail && MockDirectoryWrapper.class.getName().equals(trace[i].getClassName()) && "sync".equals(trace[i].getMethodName())) {
             didFail = true;
+            if (VERBOSE) {
+              System.out.println("TEST: now throw exc:");
+              new Throwable().printStackTrace(System.out);
+            }
             throw new IOException("now failing on purpose during sync");
           }
         }
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull.java b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull.java
index ffdcfdf..0129ef5 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull.java
@@ -220,8 +220,9 @@ public class TestIndexWriterOnDiskFull extends LuceneTestCase {
 
     for(int iter=0;iter<3;iter++) {
       
-      if (VERBOSE)
+      if (VERBOSE) {
         System.out.println("TEST: iter=" + iter);
+      }
       
       // Start with 100 bytes more than we are currently using:
       long diskFree = diskUsage+_TestUtil.nextInt(random(), 50, 200);
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex.java b/lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex.java
index fd61d19..06548f4 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex.java
@@ -19,15 +19,15 @@ package org.apache.lucene.index;
 
 import java.io.IOException;
 
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.LuceneTestCase;
-
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.FieldType;
 import org.apache.lucene.document.TextField;
 import org.apache.lucene.index.IndexWriterConfig.OpenMode;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util._TestUtil;
 
 /**
  * Some tests for {@link ParallelAtomicReader}s with empty indexes
@@ -89,6 +89,9 @@ public class TestParallelReaderEmptyIndex extends LuceneTestCase {
   public void testEmptyIndexWithVectors() throws IOException {
     Directory rd1 = newDirectory();
     {
+      if (VERBOSE) {
+        System.out.println("\nTEST: make 1st writer");
+      }
       IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));
       Document doc = new Document();
       Field idField = newField("id", "", TextField.TYPE_UNSTORED);
@@ -103,8 +106,14 @@ public class TestParallelReaderEmptyIndex extends LuceneTestCase {
       iw.addDocument(doc);
       iw.close();
 
+      // nocommit
+      _TestUtil.checkIndex(rd1);
+
       IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))
         .setMergePolicy(NoMergePolicy.COMPOUND_FILES);
+      if (VERBOSE) {
+        System.out.println("\nTEST: make 2nd writer");
+      }
       IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);
       
       writer.deleteDocuments(new Term("id", "1"));
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestSegmentMerger.java b/lucene/core/src/test/org/apache/lucene/index/TestSegmentMerger.java
index 297ebf9..5c21f80 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestSegmentMerger.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestSegmentMerger.java
@@ -84,7 +84,7 @@ public class TestSegmentMerger extends LuceneTestCase {
     int docsMerged = mergeState.mergedDocCount;
     assertTrue(docsMerged == 2);
     //Should be able to open a new SegmentReader against the new directory
-    SegmentReader mergedReader = new SegmentReader(new SegmentInfo(mergedDir, Constants.LUCENE_MAIN_VERSION, mergedSegment, docsMerged, -1, -1, mergedSegment,
+    SegmentReader mergedReader = new SegmentReader(new SegmentInfo(mergedDir, Constants.LUCENE_MAIN_VERSION, mergedSegment, docsMerged, -1, mergedSegment,
                                                                    false, null, false, 0, codec, null),
                                                    DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random()));
     assertTrue(mergedReader != null);
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestBoolean2.java b/lucene/core/src/test/org/apache/lucene/search/TestBoolean2.java
index c5d8bf4..5dc6bb1 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestBoolean2.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestBoolean2.java
@@ -72,7 +72,13 @@ public class TestBoolean2 extends LuceneTestCase {
     // First multiply small test index:
     mulFactor = 1;
     int docCount = 0;
+    if (VERBOSE) {
+      System.out.println("\nTEST: now copy index...");
+    }
     do {
+      if (VERBOSE) {
+        System.out.println("\nTEST: cycle...");
+      }
       final Directory copy = new MockDirectoryWrapper(random(), new RAMDirectory(dir2, IOContext.DEFAULT));
       RandomIndexWriter w = new RandomIndexWriter(random(), dir2);
       w.addIndexes(copy);
diff --git a/lucene/misc/src/java/org/apache/lucene/index/IndexSplitter.java b/lucene/misc/src/java/org/apache/lucene/index/IndexSplitter.java
index c29c704..478c145 100644
--- a/lucene/misc/src/java/org/apache/lucene/index/IndexSplitter.java
+++ b/lucene/misc/src/java/org/apache/lucene/index/IndexSplitter.java
@@ -132,7 +132,7 @@ public class IndexSplitter {
       infos.remove(idx);
     }
     infos.changed();
-    infos.commit(fsDir, infos.codecFormat());
+    infos.commit(fsDir);
   }
 
   public void split(File destDir, String[] segs) throws IOException {
@@ -142,7 +142,11 @@ public class IndexSplitter {
     destInfos.counter = infos.counter;
     for (String n : segs) {
       SegmentInfo info = getInfo(n);
-      destInfos.add(info);
+      // Same info just changing the dir:
+      SegmentInfo newInfo = new SegmentInfo(destFSDir, info.getVersion(), info.name, info.docCount, info.getDocStoreOffset(),
+                                            info.getDocStoreSegment(), info.getDocStoreIsCompoundFile(), info.getNormGen(), info.getUseCompoundFile(),
+                                            info.getDelCount(), info.getCodec(), info.getDiagnostics());
+      destInfos.add(newInfo);
       // now copy files over
       List<String> files = info.files();
       for (final String srcName : files) {
@@ -152,7 +156,7 @@ public class IndexSplitter {
       }
     }
     destInfos.changed();
-    destInfos.commit(destFSDir, infos.codecFormat());
+    destInfos.commit(destFSDir);
     // System.out.println("destDir:"+destDir.getAbsolutePath());
   }
 
diff --git a/lucene/misc/src/test/org/apache/lucene/index/TestIndexSplitter.java b/lucene/misc/src/test/org/apache/lucene/index/TestIndexSplitter.java
index e6cc7cd..3bba9ac 100644
--- a/lucene/misc/src/test/org/apache/lucene/index/TestIndexSplitter.java
+++ b/lucene/misc/src/test/org/apache/lucene/index/TestIndexSplitter.java
@@ -77,7 +77,7 @@ public class TestIndexSplitter extends LuceneTestCase {
     _TestUtil.rmDir(destDir2);
     destDir2.mkdirs();
     IndexSplitter.main(new String[] {dir.getAbsolutePath(), destDir2.getAbsolutePath(), splitSegName});
-    assertEquals(4, destDir2.listFiles().length);
+    assertEquals(5, destDir2.listFiles().length);
     Directory fsDirDest2 = newFSDirectory(destDir2);
     r = DirectoryReader.open(fsDirDest2);
     assertEquals(50, r.maxDoc());
diff --git a/lucene/test-framework/src/java/org/apache/lucene/codecs/lucene3x/PreFlexRWSegmentInfosFormat.java b/lucene/test-framework/src/java/org/apache/lucene/codecs/lucene3x/PreFlexRWSegmentInfosFormat.java
index c970f08..d49c01e 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/codecs/lucene3x/PreFlexRWSegmentInfosFormat.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/codecs/lucene3x/PreFlexRWSegmentInfosFormat.java
@@ -24,7 +24,7 @@ import org.apache.lucene.codecs.SegmentInfosWriter;
  */
 class PreFlexRWSegmentInfosFormat extends Lucene3xSegmentInfosFormat {
   private final SegmentInfosWriter writer = new PreFlexRWSegmentInfosWriter();
-  
+
   @Override
   public SegmentInfosWriter getSegmentInfosWriter() {
     return writer;
diff --git a/lucene/test-framework/src/java/org/apache/lucene/codecs/lucene3x/PreFlexRWSegmentInfosWriter.java b/lucene/test-framework/src/java/org/apache/lucene/codecs/lucene3x/PreFlexRWSegmentInfosWriter.java
index acd7a6b..6315413 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/codecs/lucene3x/PreFlexRWSegmentInfosWriter.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/codecs/lucene3x/PreFlexRWSegmentInfosWriter.java
@@ -18,10 +18,12 @@ package org.apache.lucene.codecs.lucene3x;
  */
 
 import java.io.IOException;
-import java.util.Map;
 import java.util.Map.Entry;
+import java.util.Map;
 
 import org.apache.lucene.codecs.SegmentInfosWriter;
+import org.apache.lucene.index.FieldInfos;
+import org.apache.lucene.index.IndexFileNames;
 import org.apache.lucene.index.SegmentInfo;
 import org.apache.lucene.index.SegmentInfos;
 import org.apache.lucene.store.ChecksumIndexOutput;
@@ -37,84 +39,61 @@ import org.apache.lucene.util.IOUtils;
  */
 class PreFlexRWSegmentInfosWriter extends SegmentInfosWriter {
 
+  /** Save a single segment's info. */
   @Override
-  public IndexOutput writeInfos(Directory dir, String segmentFileName, String codecID, SegmentInfos infos, IOContext context)
-          throws IOException {
-    IndexOutput out = createOutput(dir, segmentFileName, new IOContext(new FlushInfo(infos.size(), infos.totalDocCount())));
+  public void write(SegmentInfo si, FieldInfos fis) throws IOException {
+
+    // NOTE: this is NOT how 3.x is really written...
+    String fileName = IndexFileNames.segmentFileName(si.name, "", Lucene3xSegmentInfosFormat.SI_EXTENSION);
+
+    // nocommit what IOCtx
     boolean success = false;
+
+    IndexOutput output = si.dir.createOutput(fileName, new IOContext(new FlushInfo(0, 0)));
     try {
-      out.writeInt(SegmentInfos.FORMAT_3_1); // write FORMAT
-      // we don't write a codec - this is 3.x
-      out.writeLong(infos.version);
-      out.writeInt(infos.counter); // write counter
-      out.writeInt(infos.size()); // write infos
-      for (SegmentInfo si : infos) {
-        writeInfo(out, si);
+      // we are about to write this SI in 3.x format, dropping all codec information, etc.
+      // so it had better be a 3.x segment or you will get very confusing errors later.
+      assert si.getCodec() instanceof Lucene3xCodec : "broken test, trying to mix preflex with other codecs";
+      assert si.getDelCount() <= si.docCount: "delCount=" + si.getDelCount() + " docCount=" + si.docCount + " segment=" + si.name;
+      // Write the Lucene version that created this segment, since 3.1
+      output.writeString(si.getVersion());
+      output.writeString(si.name);
+      output.writeInt(si.docCount);
+      output.writeLong(si.getDelGen());
+
+      output.writeInt(si.getDocStoreOffset());
+      if (si.getDocStoreOffset() != -1) {
+        output.writeString(si.getDocStoreSegment());
+        output.writeByte((byte) (si.getDocStoreIsCompoundFile() ? 1:0));
       }
-      out.writeStringStringMap(infos.getUserData());
-      success = true;
-      return out;
-    } finally {
-      if (!success) {
-        IOUtils.closeWhileHandlingException(out);
+      // pre-4.0 indexes write a byte if there is a single norms file
+      output.writeByte((byte) 1);
+
+      Map<Integer,Long> normGen = si.getNormGen();
+      if (normGen == null) {
+        output.writeInt(SegmentInfo.NO);
+      } else {
+        output.writeInt(normGen.size());
+        for (Entry<Integer,Long> entry : normGen.entrySet()) {
+          output.writeLong(entry.getValue());
+        }
       }
-    }
-  }
-  
-  /** Save a single segment's info. */
-  private void writeInfo(IndexOutput output, SegmentInfo si) throws IOException {
-    // we are about to write this SI in 3.x format, dropping all codec information, etc.
-    // so it had better be a 3.x segment or you will get very confusing errors later.
-    assert si.getCodec() instanceof Lucene3xCodec : "broken test, trying to mix preflex with other codecs";
-    assert si.getDelCount() <= si.docCount: "delCount=" + si.getDelCount() + " docCount=" + si.docCount + " segment=" + si.name;
-    // Write the Lucene version that created this segment, since 3.1
-    output.writeString(si.getVersion());
-    output.writeString(si.name);
-    output.writeInt(si.docCount);
-    output.writeLong(si.getDelGen());
 
-    output.writeInt(si.getDocStoreOffset());
-    if (si.getDocStoreOffset() != -1) {
-      output.writeString(si.getDocStoreSegment());
-      output.writeByte((byte) (si.getDocStoreIsCompoundFile() ? 1:0));
-    }
-    // pre-4.0 indexes write a byte if there is a single norms file
-    output.writeByte((byte) 1);
+      output.writeByte((byte) (si.getUseCompoundFile() ? SegmentInfo.YES : SegmentInfo.NO));
+      output.writeInt(si.getDelCount());
+      // hasProx:
+      output.writeByte((byte) 1);
+      output.writeStringStringMap(si.getDiagnostics());
+      // hasVectors:
+      output.writeByte((byte) 1);
 
-    Map<Integer,Long> normGen = si.getNormGen();
-    if (normGen == null) {
-      output.writeInt(SegmentInfo.NO);
-    } else {
-      output.writeInt(normGen.size());
-      for (Entry<Integer,Long> entry : normGen.entrySet()) {
-        output.writeLong(entry.getValue());
+      success = true;
+    } finally {
+      if (!success) {
+        IOUtils.closeWhileHandlingException(output);
+      } else {
+        output.close();
       }
     }
-
-    output.writeByte((byte) (si.getUseCompoundFile() ? SegmentInfo.YES : SegmentInfo.NO));
-    output.writeInt(si.getDelCount());
-    // hasProx:
-    output.writeByte((byte) 1);
-    output.writeStringStringMap(si.getDiagnostics());
-    // hasVectors:
-    output.writeByte((byte) 1);
-  }
-  
-  protected IndexOutput createOutput(Directory dir, String segmentFileName, IOContext context)
-      throws IOException {
-    IndexOutput plainOut = dir.createOutput(segmentFileName, context);
-    ChecksumIndexOutput out = new ChecksumIndexOutput(plainOut);
-    return out;
-  }
-
-  @Override
-  public void prepareCommit(IndexOutput segmentOutput) throws IOException {
-    ((ChecksumIndexOutput)segmentOutput).prepareCommit();
-  }
-
-  @Override
-  public void finishCommit(IndexOutput out) throws IOException {
-    ((ChecksumIndexOutput)out).finishCommit();
-    out.close();
   }
 }
diff --git a/lucene/test-framework/src/java/org/apache/lucene/store/MockDirectoryWrapper.java b/lucene/test-framework/src/java/org/apache/lucene/store/MockDirectoryWrapper.java
index 40c4ea92..0673566 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/store/MockDirectoryWrapper.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/store/MockDirectoryWrapper.java
@@ -169,8 +169,9 @@ public class MockDirectoryWrapper extends Directory {
   public synchronized void sync(Collection<String> names) throws IOException {
     maybeYield();
     maybeThrowDeterministicException();
-    if (crashed)
+    if (crashed) {
       throw new IOException("cannot sync after crash");
+    }
     unSyncedFiles.removeAll(names);
     if (LuceneTestCase.rarely(randomState) || delegate instanceof NRTCachingDirectory) {
       // don't wear out our hardware so much in tests.
@@ -506,8 +507,9 @@ public class MockDirectoryWrapper extends Directory {
     if (failOnOpenInput) {
       maybeThrowDeterministicException();
     }
-    if (!delegate.fileExists(name))
-      throw new FileNotFoundException(name);
+    if (!delegate.fileExists(name)) {
+      throw new FileNotFoundException(name + " in dir=" + delegate);
+    }
 
     // cannot open a file for input if it's still open for
     // output, except for segments.gen and segments_N

