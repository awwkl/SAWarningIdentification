GitDiffStart: fff01837d7477eab5e52cf5f198b5ea8a71894ee | Thu May 1 15:14:48 2014 +0000
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsWriter.java b/lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsWriter.java
index d47ec99..638598a 100644
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsWriter.java
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsWriter.java
@@ -134,37 +134,27 @@ public class BlockTermsWriter extends FieldsConsumer implements Closeable {
   @Override
   public void write(Fields fields) throws IOException {
 
-    boolean success = false;
-    try {
-      for(String field : fields) {
-
-        Terms terms = fields.terms(field);
-        if (terms == null) {
-          continue;
-        }
+    for(String field : fields) {
 
-        TermsEnum termsEnum = terms.iterator(null);
+      Terms terms = fields.terms(field);
+      if (terms == null) {
+        continue;
+      }
 
-        TermsWriter termsWriter = addField(fieldInfos.fieldInfo(field));
+      TermsEnum termsEnum = terms.iterator(null);
 
-        while (true) {
-          BytesRef term = termsEnum.next();
-          if (term == null) {
-            break;
-          }
+      TermsWriter termsWriter = addField(fieldInfos.fieldInfo(field));
 
-          termsWriter.write(term, termsEnum);
+      while (true) {
+        BytesRef term = termsEnum.next();
+        if (term == null) {
+          break;
         }
 
-        termsWriter.finish();
-      }
-      success = true;
-    } finally {
-      if (success) {
-        IOUtils.close(this);
-      } else {
-        IOUtils.closeWhileHandlingException(this);
+        termsWriter.write(term, termsEnum);
       }
+
+      termsWriter.finish();
     }
   }
 
@@ -176,6 +166,7 @@ public class BlockTermsWriter extends FieldsConsumer implements Closeable {
     return new TermsWriter(fieldIndexWriter, field, postingsWriter);
   }
 
+  @Override
   public void close() throws IOException {
     if (out != null) {
       try {
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.java b/lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.java
index 785c780..3b42d36 100644
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.java
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.java
@@ -436,45 +436,45 @@ public final class BloomFilteringPostingsFormat extends PostingsFormat {
       // afterwards:
       delegateFieldsConsumer.write(fields);
 
-      try {
-        for(String field : fields) {
-          Terms terms = fields.terms(field);
-          if (terms == null) {
-            continue;
-          }
-          FieldInfo fieldInfo = state.fieldInfos.fieldInfo(field);
-          TermsEnum termsEnum = terms.iterator(null);
+      for(String field : fields) {
+        Terms terms = fields.terms(field);
+        if (terms == null) {
+          continue;
+        }
+        FieldInfo fieldInfo = state.fieldInfos.fieldInfo(field);
+        TermsEnum termsEnum = terms.iterator(null);
 
-          FuzzySet bloomFilter = null;
+        FuzzySet bloomFilter = null;
 
-          DocsEnum docsEnum = null;
-          while (true) {
-            BytesRef term = termsEnum.next();
-            if (term == null) {
-              break;
-            }
+        DocsEnum docsEnum = null;
+        while (true) {
+          BytesRef term = termsEnum.next();
+          if (term == null) {
+            break;
+          }
+          if (bloomFilter == null) {
+            bloomFilter = bloomFilterFactory.getSetForField(state, fieldInfo);
             if (bloomFilter == null) {
-              bloomFilter = bloomFilterFactory.getSetForField(state, fieldInfo);
-              if (bloomFilter == null) {
-                // Field not bloom'd
-                break;
-              }
-              assert bloomFilters.containsKey(field) == false;
-              bloomFilters.put(fieldInfo, bloomFilter);
-            }
-            // Make sure there's at least one doc for this term:
-            docsEnum = termsEnum.docs(null, docsEnum, 0);
-            if (docsEnum.nextDoc() != DocsEnum.NO_MORE_DOCS) {
-              bloomFilter.addValue(term);
+              // Field not bloom'd
+              break;
             }
+            assert bloomFilters.containsKey(field) == false;
+            bloomFilters.put(fieldInfo, bloomFilter);
+          }
+          // Make sure there's at least one doc for this term:
+          docsEnum = termsEnum.docs(null, docsEnum, 0);
+          if (docsEnum.nextDoc() != DocsEnum.NO_MORE_DOCS) {
+            bloomFilter.addValue(term);
           }
         }
-      } finally {
-        close();
       }
     }
 
+    @Override
     public void close() throws IOException {
+
+      delegateFieldsConsumer.close();
+
       // Now we are done accumulating values for these fields
       List<Entry<FieldInfo,FuzzySet>> nonSaturatedBlooms = new ArrayList<>();
       
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsWriter.java b/lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsWriter.java
index 4bb8f0c..8c3bf6b 100644
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsWriter.java
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsWriter.java
@@ -186,40 +186,37 @@ public class FSTOrdTermsWriter extends FieldsConsumer {
 
   @Override
   public void write(Fields fields) throws IOException {
-    try {
-      for(String field : fields) {
-        Terms terms = fields.terms(field);
-        if (terms == null) {
-          continue;
-        }
-        FieldInfo fieldInfo = fieldInfos.fieldInfo(field);
-        boolean hasFreq = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0;
-        TermsEnum termsEnum = terms.iterator(null);
-        TermsWriter termsWriter = new TermsWriter(fieldInfo);
+    for(String field : fields) {
+      Terms terms = fields.terms(field);
+      if (terms == null) {
+        continue;
+      }
+      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);
+      boolean hasFreq = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0;
+      TermsEnum termsEnum = terms.iterator(null);
+      TermsWriter termsWriter = new TermsWriter(fieldInfo);
 
-        long sumTotalTermFreq = 0;
-        long sumDocFreq = 0;
-        FixedBitSet docsSeen = new FixedBitSet(maxDoc);
-        while (true) {
-          BytesRef term = termsEnum.next();
-          if (term == null) {
-            break;
-          }
-          BlockTermState termState = postingsWriter.writeTerm(term, termsEnum, docsSeen);
-          if (termState != null) {
-            termsWriter.finishTerm(term, termState);
-            sumTotalTermFreq += termState.totalTermFreq;
-            sumDocFreq += termState.docFreq;
-          }
+      long sumTotalTermFreq = 0;
+      long sumDocFreq = 0;
+      FixedBitSet docsSeen = new FixedBitSet(maxDoc);
+      while (true) {
+        BytesRef term = termsEnum.next();
+        if (term == null) {
+          break;
+        }
+        BlockTermState termState = postingsWriter.writeTerm(term, termsEnum, docsSeen);
+        if (termState != null) {
+          termsWriter.finishTerm(term, termState);
+          sumTotalTermFreq += termState.totalTermFreq;
+          sumDocFreq += termState.docFreq;
         }
-
-        termsWriter.finish(hasFreq ? sumTotalTermFreq : -1, sumDocFreq, docsSeen.cardinality());
       }
-    } finally {
-      close();
+
+      termsWriter.finish(hasFreq ? sumTotalTermFreq : -1, sumDocFreq, docsSeen.cardinality());
     }
   }
 
+  @Override
   public void close() throws IOException {
     if (blockOut != null) {
       IOException ioe = null;
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsWriter.java b/lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsWriter.java
index 6e29ff5..3f5181e 100644
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsWriter.java
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsWriter.java
@@ -163,42 +163,39 @@ public class FSTTermsWriter extends FieldsConsumer {
 
   @Override
   public void write(Fields fields) throws IOException {
-    try {
-      for(String field : fields) {
-        Terms terms = fields.terms(field);
-        if (terms == null) {
-          continue;
-        }
-        FieldInfo fieldInfo = fieldInfos.fieldInfo(field);
-        boolean hasFreq = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0;
-        TermsEnum termsEnum = terms.iterator(null);
-        TermsWriter termsWriter = termsWriter = new TermsWriter(fieldInfo);
+    for(String field : fields) {
+      Terms terms = fields.terms(field);
+      if (terms == null) {
+        continue;
+      }
+      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);
+      boolean hasFreq = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0;
+      TermsEnum termsEnum = terms.iterator(null);
+      TermsWriter termsWriter = termsWriter = new TermsWriter(fieldInfo);
 
-        long sumTotalTermFreq = 0;
-        long sumDocFreq = 0;
-        FixedBitSet docsSeen = new FixedBitSet(maxDoc);
+      long sumTotalTermFreq = 0;
+      long sumDocFreq = 0;
+      FixedBitSet docsSeen = new FixedBitSet(maxDoc);
 
-        while (true) {
-          BytesRef term = termsEnum.next();
-          if (term == null) {
-            break;
-          }
+      while (true) {
+        BytesRef term = termsEnum.next();
+        if (term == null) {
+          break;
+        }
             
-          BlockTermState termState = postingsWriter.writeTerm(term, termsEnum, docsSeen);
-          if (termState != null) {
-            termsWriter.finishTerm(term, termState);
-            sumTotalTermFreq += termState.totalTermFreq;
-            sumDocFreq += termState.docFreq;
-          }
+        BlockTermState termState = postingsWriter.writeTerm(term, termsEnum, docsSeen);
+        if (termState != null) {
+          termsWriter.finishTerm(term, termState);
+          sumTotalTermFreq += termState.totalTermFreq;
+          sumDocFreq += termState.docFreq;
         }
-
-        termsWriter.finish(hasFreq ? sumTotalTermFreq : -1, sumDocFreq, docsSeen.cardinality());
       }
-    } finally {
-      close();
+
+      termsWriter.finish(hasFreq ? sumTotalTermFreq : -1, sumDocFreq, docsSeen.cardinality());
     }
   }
 
+  @Override
   public void close() throws IOException {
     if (out != null) {
       IOException ioe = null;
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat.java b/lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat.java
index 4cf947d..a93f2ca 100644
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat.java
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat.java
@@ -17,7 +17,6 @@ package org.apache.lucene.codecs.memory;
  * limitations under the License.
  */
 
-import java.io.Closeable;
 import java.io.IOException;
 import java.util.Collections;
 import java.util.Iterator;
@@ -277,7 +276,7 @@ public final class MemoryPostingsFormat extends PostingsFormat {
   private static final int VERSION_START = 0;
   private static final int VERSION_CURRENT = VERSION_START;
 
-  private class MemoryFieldsConsumer extends FieldsConsumer implements Closeable {
+  private class MemoryFieldsConsumer extends FieldsConsumer {
     private final SegmentWriteState state;
     private final IndexOutput out;
 
@@ -298,117 +297,107 @@ public final class MemoryPostingsFormat extends PostingsFormat {
 
     @Override
     public void write(Fields fields) throws IOException {
-      boolean success = false;
-      try {
-        for(String field : fields) {
-
-          Terms terms = fields.terms(field);
-          if (terms == null) {
-            continue;
-          }
+      for(String field : fields) {
 
-          TermsEnum termsEnum = terms.iterator(null);
-
-          FieldInfo fieldInfo = state.fieldInfos.fieldInfo(field);
-          TermsWriter termsWriter = new TermsWriter(out, fieldInfo,
-                                                    doPackFST, acceptableOverheadRatio);
+        Terms terms = fields.terms(field);
+        if (terms == null) {
+          continue;
+        }
 
-          FixedBitSet docsSeen = new FixedBitSet(state.segmentInfo.getDocCount());
-          long sumTotalTermFreq = 0;
-          long sumDocFreq = 0;
-          DocsEnum docsEnum = null;
-          DocsAndPositionsEnum posEnum = null;
-          int enumFlags;
+        TermsEnum termsEnum = terms.iterator(null);
+
+        FieldInfo fieldInfo = state.fieldInfos.fieldInfo(field);
+        TermsWriter termsWriter = new TermsWriter(out, fieldInfo,
+                                                  doPackFST, acceptableOverheadRatio);
+
+        FixedBitSet docsSeen = new FixedBitSet(state.segmentInfo.getDocCount());
+        long sumTotalTermFreq = 0;
+        long sumDocFreq = 0;
+        DocsEnum docsEnum = null;
+        DocsAndPositionsEnum posEnum = null;
+        int enumFlags;
+
+        IndexOptions indexOptions = fieldInfo.getIndexOptions();
+        boolean writeFreqs = indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS) >= 0;
+        boolean writePositions = indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;
+        boolean writeOffsets = indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;        
+        boolean writePayloads = fieldInfo.hasPayloads();
+
+        if (writeFreqs == false) {
+          enumFlags = 0;
+        } else if (writePositions == false) {
+          enumFlags = DocsEnum.FLAG_FREQS;
+        } else if (writeOffsets == false) {
+          if (writePayloads) {
+            enumFlags = DocsAndPositionsEnum.FLAG_PAYLOADS;
+          } else {
+            enumFlags = 0;
+          }
+        } else {
+          if (writePayloads) {
+            enumFlags = DocsAndPositionsEnum.FLAG_PAYLOADS | DocsAndPositionsEnum.FLAG_OFFSETS;
+          } else {
+            enumFlags = DocsAndPositionsEnum.FLAG_OFFSETS;
+          }
+        }
 
-          IndexOptions indexOptions = fieldInfo.getIndexOptions();
-          boolean writeFreqs = indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS) >= 0;
-          boolean writePositions = indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;
-          boolean writeOffsets = indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;        
-          boolean writePayloads = fieldInfo.hasPayloads();
+        while (true) {
+          BytesRef term = termsEnum.next();
+          if (term == null) {
+            break;
+          }
+          termsWriter.postingsWriter.reset();
 
-          if (writeFreqs == false) {
-            enumFlags = 0;
-          } else if (writePositions == false) {
-            enumFlags = DocsEnum.FLAG_FREQS;
-          } else if (writeOffsets == false) {
-            if (writePayloads) {
-              enumFlags = DocsAndPositionsEnum.FLAG_PAYLOADS;
-            } else {
-              enumFlags = 0;
-            }
+          if (writePositions) {
+            posEnum = termsEnum.docsAndPositions(null, posEnum, enumFlags);
+            docsEnum = posEnum;
           } else {
-            if (writePayloads) {
-              enumFlags = DocsAndPositionsEnum.FLAG_PAYLOADS | DocsAndPositionsEnum.FLAG_OFFSETS;
-            } else {
-              enumFlags = DocsAndPositionsEnum.FLAG_OFFSETS;
-            }
+            docsEnum = termsEnum.docs(null, docsEnum, enumFlags);
+            posEnum = null;
           }
 
+          int docFreq = 0;
+          long totalTermFreq = 0;
           while (true) {
-            BytesRef term = termsEnum.next();
-            if (term == null) {
+            int docID = docsEnum.nextDoc();
+            if (docID == DocsEnum.NO_MORE_DOCS) {
               break;
             }
-            termsWriter.postingsWriter.reset();
+            docsSeen.set(docID);
+            docFreq++;
 
-            if (writePositions) {
-              posEnum = termsEnum.docsAndPositions(null, posEnum, enumFlags);
-              docsEnum = posEnum;
+            int freq;
+            if (writeFreqs) {
+              freq = docsEnum.freq();
+              totalTermFreq += freq;
             } else {
-              docsEnum = termsEnum.docs(null, docsEnum, enumFlags);
-              posEnum = null;
+              freq = -1;
             }
 
-            int docFreq = 0;
-            long totalTermFreq = 0;
-            while (true) {
-              int docID = docsEnum.nextDoc();
-              if (docID == DocsEnum.NO_MORE_DOCS) {
-                break;
-              }
-              docsSeen.set(docID);
-              docFreq++;
-
-              int freq;
-              if (writeFreqs) {
-                freq = docsEnum.freq();
-                totalTermFreq += freq;
-              } else {
-                freq = -1;
-              }
-
-              termsWriter.postingsWriter.startDoc(docID, freq);
-              if (writePositions) {
-                for (int i=0;i<freq;i++) {
-                  int pos = posEnum.nextPosition();
-                  BytesRef payload = writePayloads ? posEnum.getPayload() : null;
-                  int startOffset;
-                  int endOffset;
-                  if (writeOffsets) {
-                    startOffset = posEnum.startOffset();
-                    endOffset = posEnum.endOffset();
-                  } else {
-                    startOffset = -1;
-                    endOffset = -1;
-                  }
-                  termsWriter.postingsWriter.addPosition(pos, payload, startOffset, endOffset);
+            termsWriter.postingsWriter.startDoc(docID, freq);
+            if (writePositions) {
+              for (int i=0;i<freq;i++) {
+                int pos = posEnum.nextPosition();
+                BytesRef payload = writePayloads ? posEnum.getPayload() : null;
+                int startOffset;
+                int endOffset;
+                if (writeOffsets) {
+                  startOffset = posEnum.startOffset();
+                  endOffset = posEnum.endOffset();
+                } else {
+                  startOffset = -1;
+                  endOffset = -1;
                 }
+                termsWriter.postingsWriter.addPosition(pos, payload, startOffset, endOffset);
               }
             }
-            termsWriter.finishTerm(term, new TermStats(docFreq, totalTermFreq));
-            sumDocFreq += docFreq;
-            sumTotalTermFreq += totalTermFreq;
           }
-
-          termsWriter.finish(sumTotalTermFreq, sumDocFreq, docsSeen.cardinality());
-        }
-        success = true;
-      } finally {
-        if (success) {
-          IOUtils.close(this);
-        } else {
-          IOUtils.closeWhileHandlingException(this);
+          termsWriter.finishTerm(term, new TermStats(docFreq, totalTermFreq));
+          sumDocFreq += docFreq;
+          sumTotalTermFreq += totalTermFreq;
         }
+
+        termsWriter.finish(sumTotalTermFreq, sumDocFreq, docsSeen.cardinality());
       }
     }
 
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextFieldsWriter.java b/lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextFieldsWriter.java
index 55ee6d4..a6ecbf6 100644
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextFieldsWriter.java
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextFieldsWriter.java
@@ -17,7 +17,6 @@ package org.apache.lucene.codecs.simpletext;
  * limitations under the License.
  */
 
-import java.io.Closeable;
 import java.io.IOException;
 
 import org.apache.lucene.codecs.FieldsConsumer;
@@ -31,9 +30,8 @@ import org.apache.lucene.index.Terms;
 import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.store.IndexOutput;
 import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.IOUtils;
 
-class SimpleTextFieldsWriter extends FieldsConsumer implements Closeable {
+class SimpleTextFieldsWriter extends FieldsConsumer {
   
   private IndexOutput out;
   private final BytesRef scratch = new BytesRef(10);
@@ -57,17 +55,7 @@ class SimpleTextFieldsWriter extends FieldsConsumer implements Closeable {
 
   @Override
   public void write(Fields fields) throws IOException {
-    boolean success = false;
-    try {
-      write(writeState.fieldInfos, fields);
-      success = true;
-    } finally {
-      if (success) {
-        IOUtils.close(this);
-      } else {
-        IOUtils.closeWhileHandlingException(this);
-      }
-    }
+    write(writeState.fieldInfos, fields);
   }
 
   public void write(FieldInfos fieldInfos, Fields fields) throws IOException {
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsWriter.java b/lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsWriter.java
index f752f8a..8ec6fe1 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsWriter.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsWriter.java
@@ -17,7 +17,6 @@ package org.apache.lucene.codecs;
  * limitations under the License.
  */
 
-import java.io.Closeable;
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.List;
@@ -184,7 +183,7 @@ import org.apache.lucene.util.packed.PackedInts;
  * @see BlockTreeTermsReader
  * @lucene.experimental
  */
-public class BlockTreeTermsWriter extends FieldsConsumer implements Closeable {
+public class BlockTreeTermsWriter extends FieldsConsumer {
 
   /** Suggested default value for the {@code
    *  minItemsInBlock} parameter to {@link
@@ -351,44 +350,34 @@ public class BlockTreeTermsWriter extends FieldsConsumer implements Closeable {
   @Override
   public void write(Fields fields) throws IOException {
 
-    boolean success = false;
-    try {
-      String lastField = null;
-      for(String field : fields) {
-        assert lastField == null || lastField.compareTo(field) < 0;
-        lastField = field;
-
-        Terms terms = fields.terms(field);
-        if (terms == null) {
-          continue;
-        }
+    String lastField = null;
+    for(String field : fields) {
+      assert lastField == null || lastField.compareTo(field) < 0;
+      lastField = field;
 
-        TermsEnum termsEnum = terms.iterator(null);
+      Terms terms = fields.terms(field);
+      if (terms == null) {
+        continue;
+      }
 
-        TermsWriter termsWriter = new TermsWriter(fieldInfos.fieldInfo(field));
-        BytesRef minTerm = null;
-        BytesRef maxTerm = new BytesRef();
-        while (true) {
-          BytesRef term = termsEnum.next();
-          if (term == null) {
-            break;
-          }
-          if (minTerm == null) {
-            minTerm = BytesRef.deepCopyOf(term);
-          }
-          maxTerm.copyBytes(term);
-          termsWriter.write(term, termsEnum);
-        }
+      TermsEnum termsEnum = terms.iterator(null);
 
-        termsWriter.finish(minTerm, minTerm == null ? null : maxTerm);
-      }
-      success = true;
-    } finally {
-      if (success) {
-        IOUtils.close(this);
-      } else {
-        IOUtils.closeWhileHandlingException(this);
+      TermsWriter termsWriter = new TermsWriter(fieldInfos.fieldInfo(field));
+      BytesRef minTerm = null;
+      BytesRef maxTerm = new BytesRef();
+      while (true) {
+        BytesRef term = termsEnum.next();
+        if (term == null) {
+          break;
+        }
+        if (minTerm == null) {
+          minTerm = BytesRef.deepCopyOf(term);
+        }
+        maxTerm.copyBytes(term);
+        termsWriter.write(term, termsEnum);
       }
+
+      termsWriter.finish(minTerm, minTerm == null ? null : maxTerm);
     }
   }
   
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/FieldsConsumer.java b/lucene/core/src/java/org/apache/lucene/codecs/FieldsConsumer.java
index 523e411..78fe917 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/FieldsConsumer.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/FieldsConsumer.java
@@ -17,6 +17,7 @@ package org.apache.lucene.codecs;
  * limitations under the License.
  */
 
+import java.io.Closeable;
 import java.io.IOException;
 
 import org.apache.lucene.index.FieldInfo; // javadocs
@@ -32,7 +33,7 @@ import org.apache.lucene.index.SegmentWriteState; // javadocs
  * @lucene.experimental
  */
 
-public abstract class FieldsConsumer {
+public abstract class FieldsConsumer implements Closeable {
 
   /** Sole constructor. (For invocation by subclass 
    *  constructors, typically implicit.) */
@@ -72,4 +73,8 @@ public abstract class FieldsConsumer {
    *  </ul>
    */
   public abstract void write(Fields fields) throws IOException;
+
+  // NOTE: strange but necessary so javadocs linting is happy:
+  @Override
+  public abstract void close() throws IOException;
 }
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/perfield/PerFieldPostingsFormat.java b/lucene/core/src/java/org/apache/lucene/codecs/perfield/PerFieldPostingsFormat.java
index 8ac6754..19b9617 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/perfield/PerFieldPostingsFormat.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/perfield/PerFieldPostingsFormat.java
@@ -17,10 +17,13 @@ package org.apache.lucene.codecs.perfield;
  * limitations under the License.
  */
 
+import java.io.Closeable;
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.Iterator;
+import java.util.List;
 import java.util.Map;
 import java.util.ServiceLoader; // javadocs
 import java.util.Set;
@@ -101,6 +104,7 @@ public abstract class PerFieldPostingsFormat extends PostingsFormat {
   
   private class FieldsWriter extends FieldsConsumer {
     final SegmentWriteState writeState;
+    final List<Closeable> toClose = new ArrayList<Closeable>();
 
     public FieldsWriter(SegmentWriteState writeState) {
       this.writeState = writeState;
@@ -163,21 +167,36 @@ public abstract class PerFieldPostingsFormat extends PostingsFormat {
       }
 
       // Second pass: write postings
-      for(Map.Entry<PostingsFormat,FieldsGroup> ent : formatToGroups.entrySet()) {
-        PostingsFormat format = ent.getKey();
-        final FieldsGroup group = ent.getValue();
-
-        // Exposes only the fields from this group:
-        Fields maskedFields = new FilterFields(fields) {
-            @Override
-            public Iterator<String> iterator() {
-              return group.fields.iterator();
-            }
-          };
+      boolean success = false;
+      try {
+        for(Map.Entry<PostingsFormat,FieldsGroup> ent : formatToGroups.entrySet()) {
+          PostingsFormat format = ent.getKey();
+          final FieldsGroup group = ent.getValue();
+
+          // Exposes only the fields from this group:
+          Fields maskedFields = new FilterFields(fields) {
+              @Override
+              public Iterator<String> iterator() {
+                return group.fields.iterator();
+              }
+            };
 
-        format.fieldsConsumer(group.state).write(maskedFields);
+          FieldsConsumer consumer = format.fieldsConsumer(group.state);
+          toClose.add(consumer);
+          consumer.write(maskedFields);
+        }
+        success = true;
+      } finally {
+        if (success == false) {
+          IOUtils.closeWhileHandlingException(toClose);
+        }
       }
     }
+
+    @Override
+    public void close() throws IOException {
+      IOUtils.close(toClose);
+    }
   }
 
   private class FieldsReader extends FieldsProducer {
diff --git a/lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter.java b/lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter.java
index b0a4155..c7c7c6d 100644
--- a/lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter.java
+++ b/lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter.java
@@ -23,7 +23,9 @@ import java.util.Collections;
 import java.util.List;
 import java.util.Map;
 
+import org.apache.lucene.codecs.FieldsConsumer;
 import org.apache.lucene.util.CollectionUtil;
+import org.apache.lucene.util.IOUtils;
 
 final class FreqProxTermsWriter extends TermsHash {
 
@@ -100,7 +102,19 @@ final class FreqProxTermsWriter extends TermsHash {
 
     applyDeletes(state, fields);
 
-    state.segmentInfo.getCodec().postingsFormat().fieldsConsumer(state).write(fields);
+    FieldsConsumer consumer = state.segmentInfo.getCodec().postingsFormat().fieldsConsumer(state);
+    boolean success = false;
+    try {
+      consumer.write(fields);
+      success = true;
+    } finally {
+      if (success) {
+        IOUtils.close(consumer);
+      } else {
+        IOUtils.closeWhileHandlingException(consumer);
+      }
+    }
+
   }
 
   @Override
diff --git a/lucene/core/src/java/org/apache/lucene/index/SegmentMerger.java b/lucene/core/src/java/org/apache/lucene/index/SegmentMerger.java
index 53bd05f..416befb 100644
--- a/lucene/core/src/java/org/apache/lucene/index/SegmentMerger.java
+++ b/lucene/core/src/java/org/apache/lucene/index/SegmentMerger.java
@@ -24,6 +24,7 @@ import java.util.List;
 import org.apache.lucene.codecs.Codec;
 import org.apache.lucene.codecs.DocValuesConsumer;
 import org.apache.lucene.codecs.FieldInfosWriter;
+import org.apache.lucene.codecs.FieldsConsumer;
 import org.apache.lucene.codecs.StoredFieldsWriter;
 import org.apache.lucene.codecs.TermVectorsWriter;
 import org.apache.lucene.index.FieldInfo.DocValuesType;
@@ -384,6 +385,17 @@ final class SegmentMerger {
                                                 new MultiFields(fields.toArray(Fields.EMPTY_ARRAY),
                                                                 slices.toArray(ReaderSlice.EMPTY_ARRAY)));
 
-    codec.postingsFormat().fieldsConsumer(segmentWriteState).write(mergedFields);
+    FieldsConsumer consumer = codec.postingsFormat().fieldsConsumer(segmentWriteState);
+    boolean success = false;
+    try {
+      consumer.write(mergedFields);
+      success = true;
+    } finally {
+      if (success) {
+        IOUtils.close(consumer);
+      } else {
+        IOUtils.closeWhileHandlingException(consumer);
+      }
+    }
   }
 }
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestCodecs.java b/lucene/core/src/test/org/apache/lucene/index/TestCodecs.java
index 57ec0dc..d07c9fd 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestCodecs.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestCodecs.java
@@ -25,6 +25,7 @@ import java.util.Random;
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.codecs.Codec;
+import org.apache.lucene.codecs.FieldsConsumer;
 import org.apache.lucene.codecs.FieldsProducer;
 import org.apache.lucene.codecs.lucene40.Lucene40RWCodec;
 import org.apache.lucene.codecs.lucene41.Lucene41RWCodec;
@@ -46,6 +47,7 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.Constants;
+import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.InfoStream;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.TestUtil;
@@ -809,7 +811,18 @@ public class TestCodecs extends LuceneTestCase {
     final SegmentWriteState state = new SegmentWriteState(InfoStream.getDefault(), dir, si, fieldInfos, null, newIOContext(random()));
 
     Arrays.sort(fields);
-    codec.postingsFormat().fieldsConsumer(state).write(new DataFields(fields));
+    FieldsConsumer consumer = codec.postingsFormat().fieldsConsumer(state);
+    boolean success = false;
+    try {
+      consumer.write(new DataFields(fields));
+      success = true;
+    } finally {
+      if (success) {
+        IOUtils.close(consumer);
+      } else {
+        IOUtils.closeWhileHandlingException(consumer);
+      }
+    }
   }
   
   public void testDocsOnlyFreq() throws Exception {
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2.java b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2.java
index 6a54c7a..b069d54 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2.java
@@ -32,7 +32,6 @@ import org.apache.lucene.document.Field;
 import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util.LuceneTestCase.AwaitsFix;
 import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.Rethrow;
 
@@ -44,16 +43,16 @@ import org.apache.lucene.util.Rethrow;
 // reproduce with: ant test  -Dtestcase=TestIndexWriterExceptions2 -Dtests.method=testSimple -Dtests.seed=9D05AC6DFF3CC9A4 -Dtests.multiplier=10 -Dtests.locale=fi_FI -Dtests.timezone=Canada/Pacific -Dtests.file.encoding=ISO-8859-1
 // also sometimes when it fails, the exception-stream printing doesnt seem to be working yet
 // 
-@AwaitsFix(bugUrl = "https://issues.apache.org/jira/browse/LUCENE-5635")
 public class TestIndexWriterExceptions2 extends LuceneTestCase {
   
   // just one thread, serial merge policy, hopefully debuggable
-  public void testSimple() throws Exception {
+  public void testBasics() throws Exception {
     Directory dir = newDirectory();
     
     // log all exceptions we hit, in case we fail (for debugging)
     ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();
     PrintStream exceptionStream = new PrintStream(exceptionLog, true, "UTF-8");
+    //PrintStream exceptionStream = System.out;
     
     // create lots of non-aborting exceptions with a broken analyzer
     final long analyzerSeed = random().nextLong();
@@ -91,7 +90,7 @@ public class TestIndexWriterExceptions2 extends LuceneTestCase {
           iw.addDocument(doc);
         } catch (Exception e) {
           if (e.getMessage() != null && e.getMessage().startsWith("Fake IOException")) {
-            System.out.println("\nTEST: got expected fake exc:" + e.getMessage());
+            exceptionStream.println("\nTEST: got expected fake exc:" + e.getMessage());
             e.printStackTrace(exceptionStream);
           } else {
             Rethrow.rethrow(e);
@@ -106,7 +105,7 @@ public class TestIndexWriterExceptions2 extends LuceneTestCase {
             }
           } catch (Exception e) {
             if (e.getMessage() != null && e.getMessage().startsWith("Fake IOException")) {
-              System.out.println("\nTEST: got expected fake exc:" + e.getMessage());
+              exceptionStream.println("\nTEST: got expected fake exc:" + e.getMessage());
               e.printStackTrace(exceptionStream);
             } else {
               Rethrow.rethrow(e);
diff --git a/lucene/test-framework/src/java/org/apache/lucene/codecs/asserting/AssertingPostingsFormat.java b/lucene/test-framework/src/java/org/apache/lucene/codecs/asserting/AssertingPostingsFormat.java
index d9bdc1c..1221c84 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/codecs/asserting/AssertingPostingsFormat.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/codecs/asserting/AssertingPostingsFormat.java
@@ -209,5 +209,10 @@ public final class AssertingPostingsFormat extends PostingsFormat {
         }
       }
     }
+
+    @Override
+    public void close() throws IOException {
+      in.close();
+    }
   }
 }
diff --git a/lucene/test-framework/src/java/org/apache/lucene/codecs/cranky/CrankyPostingsFormat.java b/lucene/test-framework/src/java/org/apache/lucene/codecs/cranky/CrankyPostingsFormat.java
index c8b7a82..3d19c37 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/codecs/cranky/CrankyPostingsFormat.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/codecs/cranky/CrankyPostingsFormat.java
@@ -68,5 +68,13 @@ class CrankyPostingsFormat extends PostingsFormat {
       }  
       delegate.write(fields);
     }
+
+    @Override
+    public void close() throws IOException {
+      delegate.close();
+      if (random.nextInt(100) == 0) {
+        throw new IOException("Fake IOException from FieldsConsumer.close()");
+      }  
+    }
   }
 }
diff --git a/lucene/test-framework/src/java/org/apache/lucene/codecs/ramonly/RAMOnlyPostingsFormat.java b/lucene/test-framework/src/java/org/apache/lucene/codecs/ramonly/RAMOnlyPostingsFormat.java
index 12f0166..2677f25 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/codecs/ramonly/RAMOnlyPostingsFormat.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/codecs/ramonly/RAMOnlyPostingsFormat.java
@@ -333,6 +333,10 @@ public final class RAMOnlyPostingsFormat extends PostingsFormat {
         termsConsumer.finish(sumTotalTermFreq, sumDocFreq, docsSeen.cardinality());
       }
     }
+
+    @Override
+    public void close() throws IOException {
+    }
   }
 
   private static class RAMTermsConsumer {
diff --git a/lucene/test-framework/src/java/org/apache/lucene/index/BasePostingsFormatTestCase.java b/lucene/test-framework/src/java/org/apache/lucene/index/BasePostingsFormatTestCase.java
index 06a8423..8a39cdb 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/index/BasePostingsFormatTestCase.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/index/BasePostingsFormatTestCase.java
@@ -32,8 +32,8 @@ import java.util.Random;
 import java.util.Set;
 import java.util.SortedMap;
 import java.util.TreeMap;
-import java.util.concurrent.atomic.AtomicLong;
 import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.atomic.AtomicLong;
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.codecs.Codec;
@@ -55,6 +55,7 @@ import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.Constants;
 import org.apache.lucene.util.FixedBitSet;
+import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.LineFileDocs;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.RamUsageEstimator;
@@ -694,7 +695,18 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
 
     Fields seedFields = new SeedFields(fields, newFieldInfos, maxAllowed, allowPayloads);
 
-    codec.postingsFormat().fieldsConsumer(writeState).write(seedFields);
+    FieldsConsumer consumer = codec.postingsFormat().fieldsConsumer(writeState);
+    boolean success = false;
+    try {
+      consumer.write(seedFields);
+      success = true;
+    } finally {
+      if (success) {
+        IOUtils.close(consumer);
+      } else {
+        IOUtils.closeWhileHandlingException(consumer);
+      }
+    }
 
     if (VERBOSE) {
       System.out.println("TEST: after indexing: files=");
@@ -1526,6 +1538,11 @@ public abstract class BasePostingsFormatTestCase extends BaseIndexFileFormatTest
                       }
                     }
                   }
+
+                  @Override
+                  public void close() throws IOException {
+                    fieldsConsumer.close();
+                  }
                 };
               }
 

