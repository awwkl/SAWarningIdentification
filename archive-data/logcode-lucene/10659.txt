GitDiffStart: 4dc097247279d49adcad06e66d2e0065af08670c | Wed Oct 31 15:12:16 2012 +0000
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsFormat.java b/lucene/codecs/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsFormat.java
index 6034c48..b68bfd9 100644
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsFormat.java
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsFormat.java
@@ -53,7 +53,7 @@ public class CompressingStoredFieldsFormat extends StoredFieldsFormat {
    * Create a new {@link CompressingStoredFieldsFormat}.
    * <p>
    * The <code>compressionMode</code> parameter allows you to choose between
-   * compression algorithms that have various compression and uncompression
+   * compression algorithms that have various compression and decompression
    * speeds so that you can pick the one that best fits your indexing and
    * searching throughput.
    * <p>
@@ -64,7 +64,7 @@ public class CompressingStoredFieldsFormat extends StoredFieldsFormat {
    * fields.
    * <p>
    * Higher values of <code>chunkSize</code> should improve the compression
-   * atio but will require more memory at indexing time and might make document
+   * ratio but will require more memory at indexing time and might make document
    * loading a little slower (depending on the size of your OS cache compared
    * to the size of your index).
    * <p>
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader.java b/lucene/codecs/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader.java
index afe06ba..4ba2375 100644
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader.java
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader.java
@@ -61,7 +61,7 @@ final class CompressingStoredFieldsReader extends StoredFieldsReader {
   private final IndexInput fieldsStream;
   private final int packedIntsVersion;
   private final CompressionMode compressionMode;
-  private final Uncompressor uncompressor;
+  private final Decompressor decompressor;
   private final BytesRef bytes;
   private final int numDocs;
   private boolean closed;
@@ -73,7 +73,7 @@ final class CompressingStoredFieldsReader extends StoredFieldsReader {
     this.indexReader = reader.indexReader.clone();
     this.packedIntsVersion = reader.packedIntsVersion;
     this.compressionMode = reader.compressionMode;
-    this.uncompressor = reader.uncompressor.clone();
+    this.decompressor = reader.decompressor.clone();
     this.numDocs = reader.numDocs;
     this.bytes = new BytesRef(reader.bytes.bytes.length);
     this.closed = false;
@@ -103,7 +103,7 @@ final class CompressingStoredFieldsReader extends StoredFieldsReader {
       packedIntsVersion = fieldsStream.readVInt();
       final int compressionModeId = fieldsStream.readVInt();
       compressionMode = CompressionMode.byId(compressionModeId);
-      uncompressor = compressionMode.newUncompressor();
+      decompressor = compressionMode.newDecompressor();
       this.bytes = new BytesRef();
 
       success = true;
@@ -209,7 +209,7 @@ final class CompressingStoredFieldsReader extends StoredFieldsReader {
     // skip the last values
     fieldsStream.seek(filePointer + (PackedInts.Format.PACKED.nblocks(bitsPerValue, chunkDocs) << 3));
 
-    uncompressor.uncompress(fieldsStream, offset, length, bytes);
+    decompressor.decompress(fieldsStream, offset, length, bytes);
 
     final ByteArrayDataInput documentInput = new ByteArrayDataInput(bytes.bytes, bytes.offset, bytes.length);
     final int numFields = documentInput.readVInt();
@@ -280,7 +280,7 @@ final class CompressingStoredFieldsReader extends StoredFieldsReader {
     }
 
     /**
-     * Return the uncompressed size of the chunk
+     * Return the decompressed size of the chunk
      */
     int chunkSize() {
       int sum = 0;
@@ -319,11 +319,11 @@ final class CompressingStoredFieldsReader extends StoredFieldsReader {
     }
 
     /**
-     * Uncompress the chunk.
+     * Decompress the chunk.
      */
-    void uncompress() throws IOException {
-      // uncompress data
-      uncompressor.uncompress(fieldsStream, bytes);
+    void decompress() throws IOException {
+      // decompress data
+      decompressor.decompress(fieldsStream, bytes);
       if (bytes.length != chunkSize()) {
         throw new CorruptIndexException("Corrupted: expected chunk size = " + chunkSize() + ", got " + bytes.length);
       }
@@ -333,7 +333,7 @@ final class CompressingStoredFieldsReader extends StoredFieldsReader {
      * Copy compressed data.
      */
     void copyCompressedData(DataOutput out) throws IOException {
-      uncompressor.copyCompressedData(fieldsStream, out);
+      decompressor.copyCompressedData(fieldsStream, out);
     }
 
   }
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsWriter.java b/lucene/codecs/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsWriter.java
index eba5945..5b4eaa8 100644
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsWriter.java
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsWriter.java
@@ -334,7 +334,7 @@ final class CompressingStoredFieldsWriter extends StoredFieldsWriter {
                 && nextDeletedDoc(it.docBase, liveDocs, it.docBase + it.chunkDocs) == it.docBase + it.chunkDocs) { // no deletion in the chunk
               assert docID == it.docBase;
 
-              // no need to uncompress, just copy data
+              // no need to decompress, just copy data
               endWithPreviousDocument();
               if (bufferedDocs.length >= chunkSize) {
                 flush();
@@ -347,8 +347,8 @@ final class CompressingStoredFieldsWriter extends StoredFieldsWriter {
               docCount += it.chunkDocs;
               mergeState.checkAbort.work(300 * it.chunkDocs);
             } else {
-              // uncompress
-              it.uncompress();
+              // decompress
+              it.decompress();
               if (startOffsets[it.chunkDocs - 1] + it.lengths[it.chunkDocs - 1] != it.bytes.length) {
                 throw new CorruptIndexException("Corrupted: expected chunk size=" + startOffsets[it.chunkDocs - 1] + it.lengths[it.chunkDocs - 1] + ", got " + it.bytes.length);
               }
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/compressing/CompressionMode.java b/lucene/codecs/src/java/org/apache/lucene/codecs/compressing/CompressionMode.java
index 52d7b44..2e5e62f 100644
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/compressing/CompressionMode.java
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/compressing/CompressionMode.java
@@ -29,14 +29,14 @@ import org.apache.lucene.util.BytesRef;
 
 /**
  * A compression mode. Tells how much effort should be spent on compression and
- * uncompression of stored fields.
+ * decompression of stored fields.
  * @lucene.experimental
  */
 public enum CompressionMode {
 
   /**
    * A compression mode that trades compression ratio for speed. Although the
-   * compression ratio might remain high, compression and uncompression are
+   * compression ratio might remain high, compression and decompression are
    * very fast. Use this mode with indices that have a high update rate but
    * should be able to load documents from disk quickly.
    */
@@ -48,15 +48,15 @@ public enum CompressionMode {
     }
 
     @Override
-    Uncompressor newUncompressor() {
-      return LZ4_UNCOMPRESSOR;
+    Decompressor newDecompressor() {
+      return LZ4_DECOMPRESSOR;
     }
 
   },
 
   /**
    * A compression mode that trades speed for compression ratio. Although
-   * compression and uncompression might be slow, this compression mode should
+   * compression and decompression might be slow, this compression mode should
    * provide a good compression ratio. This mode might be interesting if/when
    * your index size is much bigger than your OS cache.
    */
@@ -68,8 +68,8 @@ public enum CompressionMode {
     }
 
     @Override
-    Uncompressor newUncompressor() {
-      return new DeflateUncompressor();
+    Decompressor newDecompressor() {
+      return new DeflateDecompressor();
     }
 
   },
@@ -80,7 +80,7 @@ public enum CompressionMode {
    * mode is best used with indices that have a low update rate but should be
    * able to load documents from disk quickly.
    */
-  FAST_UNCOMPRESSION(2) {
+  FAST_DECOMPRESSION(2) {
 
     @Override
     Compressor newCompressor() {
@@ -88,8 +88,8 @@ public enum CompressionMode {
     }
 
     @Override
-    Uncompressor newUncompressor() {
-      return LZ4_UNCOMPRESSOR;
+    Decompressor newDecompressor() {
+      return LZ4_DECOMPRESSOR;
     }
 
   };
@@ -124,56 +124,56 @@ public enum CompressionMode {
   abstract Compressor newCompressor();
 
   /**
-   * Create a new {@link Uncompressor} instance.
+   * Create a new {@link Decompressor} instance.
    */
-  abstract Uncompressor newUncompressor();
+  abstract Decompressor newDecompressor();
 
 
-  private static final Uncompressor LZ4_UNCOMPRESSOR = new Uncompressor() {
+  private static final Decompressor LZ4_DECOMPRESSOR = new Decompressor() {
 
     @Override
-    public void uncompress(DataInput in, BytesRef bytes) throws IOException {
-      final int uncompressedLen = in.readVInt();
-      if (bytes.bytes.length < uncompressedLen + 8) {
-        bytes.bytes = ArrayUtil.grow(bytes.bytes, uncompressedLen + 8);
+    public void decompress(DataInput in, BytesRef bytes) throws IOException {
+      final int decompressedLen = in.readVInt();
+      if (bytes.bytes.length < decompressedLen + 8) {
+        bytes.bytes = ArrayUtil.grow(bytes.bytes, decompressedLen + 8);
       }
-      LZ4.uncompress(in, uncompressedLen, bytes);
-      if (bytes.length != uncompressedLen) {
+      LZ4.decompress(in, decompressedLen, bytes);
+      if (bytes.length != decompressedLen) {
         throw new IOException("Corrupted");
       }
     }
 
     @Override
-    public void uncompress(DataInput in, int offset, int length, BytesRef bytes) throws IOException {
-      final int uncompressedLen = in.readVInt();
-      if (offset > uncompressedLen) {
+    public void decompress(DataInput in, int offset, int length, BytesRef bytes) throws IOException {
+      final int decompressedLen = in.readVInt();
+      if (offset > decompressedLen) {
         bytes.length = 0;
         return;
       }
-      if (bytes.bytes.length < uncompressedLen) {
-        bytes.bytes = ArrayUtil.grow(bytes.bytes, uncompressedLen);
+      if (bytes.bytes.length < decompressedLen) {
+        bytes.bytes = ArrayUtil.grow(bytes.bytes, decompressedLen);
       }
-      LZ4.uncompress(in, offset + length, bytes);
+      LZ4.decompress(in, offset + length, bytes);
       bytes.offset = offset;
-      if (offset + length >= uncompressedLen) {
-        if (bytes.length != uncompressedLen) {
+      if (offset + length >= decompressedLen) {
+        if (bytes.length != decompressedLen) {
           throw new IOException("Corrupted");
         }
-        bytes.length = uncompressedLen - offset;
+        bytes.length = decompressedLen - offset;
       } else {
         bytes.length = length;
       }
     }
 
     public void copyCompressedData(DataInput in, DataOutput out) throws IOException {
-      final int uncompressedLen = in.readVInt();
-      out.writeVInt(uncompressedLen);
-      if (uncompressedLen == 0) {
+      final int decompressedLen = in.readVInt();
+      out.writeVInt(decompressedLen);
+      if (decompressedLen == 0) {
         out.writeByte((byte) 0); // the token
         return;
       }
       int n = 0;
-      while (n < uncompressedLen) {
+      while (n < decompressedLen) {
         // literals
         final byte token = in.readByte();
         out.writeByte(token);
@@ -189,7 +189,7 @@ public enum CompressionMode {
         }
         out.copyBytes(in, literalLen);
         n += literalLen;
-        if (n >= uncompressedLen) {
+        if (n >= decompressedLen) {
           break;
         }
 
@@ -209,13 +209,13 @@ public enum CompressionMode {
         n += matchLen;
       }
 
-      if (n != uncompressedLen) {
-        throw new IOException("Currupted compressed stream: expected " + uncompressedLen + " bytes, but got at least" + n);
+      if (n != decompressedLen) {
+        throw new IOException("Currupted compressed stream: expected " + decompressedLen + " bytes, but got at least" + n);
       }
     }
 
     @Override
-    public Uncompressor clone() {
+    public Decompressor clone() {
       return this;
     }
 
@@ -243,18 +243,18 @@ public enum CompressionMode {
 
   };
 
-  private static final class DeflateUncompressor extends Uncompressor {
+  private static final class DeflateDecompressor extends Decompressor {
 
-    final Inflater uncompressor;
+    final Inflater decompressor;
     byte[] compressed;
 
-    DeflateUncompressor() {
-      uncompressor = new Inflater();
+    DeflateDecompressor() {
+      decompressor = new Inflater();
       compressed = new byte[0];
     }
 
     @Override
-    public void uncompress(DataInput in, BytesRef bytes) throws IOException {
+    public void decompress(DataInput in, BytesRef bytes) throws IOException {
       bytes.offset = bytes.length = 0;
 
       final int compressedLength = in.readVInt();
@@ -263,9 +263,9 @@ public enum CompressionMode {
       }
       in.readBytes(compressed, 0, compressedLength);
 
-      uncompressor.reset();
-      uncompressor.setInput(compressed, 0, compressedLength);
-      if (uncompressor.needsInput()) {
+      decompressor.reset();
+      decompressor.setInput(compressed, 0, compressedLength);
+      if (decompressor.needsInput()) {
         return;
       }
 
@@ -273,12 +273,12 @@ public enum CompressionMode {
         final int count;
         try {
           final int remaining = bytes.bytes.length - bytes.length;
-          count = uncompressor.inflate(bytes.bytes, bytes.length, remaining);
+          count = decompressor.inflate(bytes.bytes, bytes.length, remaining);
         } catch (DataFormatException e) {
           throw new IOException(e);
         }
         bytes.length += count;
-        if (uncompressor.finished()) {
+        if (decompressor.finished()) {
           break;
         } else {
           bytes.bytes = ArrayUtil.grow(bytes.bytes);
@@ -294,8 +294,8 @@ public enum CompressionMode {
     }
 
     @Override
-    public Uncompressor clone() {
-      return new DeflateUncompressor();
+    public Decompressor clone() {
+      return new DeflateDecompressor();
     }
 
   }
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/compressing/Compressor.java b/lucene/codecs/src/java/org/apache/lucene/codecs/compressing/Compressor.java
index bef64b8..a652999 100644
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/compressing/Compressor.java
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/compressing/Compressor.java
@@ -28,8 +28,8 @@ abstract class Compressor {
 
   /**
    * Compress bytes into <code>out</code>. It it the responsibility of the
-   * compressor to add all necessary information so that a {@link Uncompressor}
-   * will know when to stop uncompressing bytes from the stream.
+   * compressor to add all necessary information so that a {@link Decompressor}
+   * will know when to stop decompressing bytes from the stream.
    */
   public abstract void compress(byte[] bytes, int off, int len, DataOutput out) throws IOException;
 
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/compressing/Decompressor.java b/lucene/codecs/src/java/org/apache/lucene/codecs/compressing/Decompressor.java
new file mode 100644
index 0000000..1abae2c
--- /dev/null
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/compressing/Decompressor.java
@@ -0,0 +1,56 @@
+package org.apache.lucene.codecs.compressing;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.store.DataInput;
+import org.apache.lucene.store.DataOutput;
+import org.apache.lucene.util.BytesRef;
+
+/**
+ * An decompressor.
+ */
+abstract class Decompressor implements Cloneable {
+
+  /**
+   * Decompress bytes. This method is free to resize <code>bytes</code> in case
+   * it is too small to hold all the decompressed data.
+   */
+  public abstract void decompress(DataInput in, BytesRef bytes) throws IOException;
+
+  /**
+   * Method to use if you are only interested into <code>length</code>
+   * decompressed bytes starting at offset <code>offset</code>. Some compression
+   * codecs might have optimizations for this special case.
+   */
+  public void decompress(DataInput in, int offset, int length, BytesRef bytes) throws IOException {
+    decompress(in, bytes);
+    if (bytes.length < offset + length) {
+      throw new IndexOutOfBoundsException((offset + length) + " > " + bytes.length);
+    }
+    bytes.offset += offset;
+    bytes.length = length;
+  }
+
+  public abstract void copyCompressedData(DataInput in, DataOutput out) throws IOException;
+
+  @Override
+  public abstract Decompressor clone();
+
+}
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/compressing/LZ4.java b/lucene/codecs/src/java/org/apache/lucene/codecs/compressing/LZ4.java
index 10a7446..6c012f4 100644
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/compressing/LZ4.java
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/compressing/LZ4.java
@@ -26,7 +26,7 @@ import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.packed.PackedInts;
 
 /**
- * LZ4 compression and uncompression routines.
+ * LZ4 compression and decompression routines.
  *
  * http://code.google.com/p/lz4/
  * http://fastcompression.blogspot.fr/p/lz4.html
@@ -78,17 +78,17 @@ class LZ4 {
   }
 
   /**
-   * Uncompress at least <code>uncompressedLen</code> bytes into <code>destBytes</code>.
+   * Decompress at least <code>decompressedLen</code> bytes into <code>destBytes</code>.
    * Please note that <code>destBytes</code> must be large enough to be able to hold
-   * <b>all</b> uncompressed data plus 8 bytes (meaning that you need to know the total
-   * uncompressed length).
+   * <b>all</b> decompressed data plus 8 bytes (meaning that you need to know the total
+   * decompressed length).
    */
-  public static void uncompress(DataInput compressed, int uncompressedLen, BytesRef destBytes) throws IOException {
+  public static void decompress(DataInput compressed, int decompressedLen, BytesRef destBytes) throws IOException {
     final byte[] dest = destBytes.bytes;
     final int destEnd = dest.length;
     int dOff = 0;
 
-    while (dOff < uncompressedLen) {
+    while (dOff < decompressedLen) {
       // literals
       final int token = compressed.readByte() & 0xFF;
       int literalLen = token >>> 4;
@@ -105,7 +105,7 @@ class LZ4 {
         dOff += literalLen;
       }
 
-      if (dOff >= uncompressedLen) {
+      if (dOff >= decompressedLen) {
         break;
       }
 
@@ -123,7 +123,7 @@ class LZ4 {
       }
       matchLen += MIN_MATCH;
 
-      // copying a multiple of 8 bytes can make uncompression from 5% to 10% faster
+      // copying a multiple of 8 bytes can make decompression from 5% to 10% faster
       final int fastLen = ((matchLen - 1) & 0xFFFFFFF8) + 8;
       if (matchDec < matchLen || dOff + fastLen > destEnd) {
         // overlap -> naive incremental copy
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/compressing/Uncompressor.java b/lucene/codecs/src/java/org/apache/lucene/codecs/compressing/Uncompressor.java
deleted file mode 100644
index e3fd1e6..0000000
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/compressing/Uncompressor.java
+++ /dev/null
@@ -1,56 +0,0 @@
-package org.apache.lucene.codecs.compressing;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-
-import org.apache.lucene.store.DataInput;
-import org.apache.lucene.store.DataOutput;
-import org.apache.lucene.util.BytesRef;
-
-/**
- * An uncompressor.
- */
-abstract class Uncompressor implements Cloneable {
-
-  /**
-   * Uncompress bytes. This method is free to resize <code>bytes</code> in case
-   * it is too small to hold all the uncompressed data.
-   */
-  public abstract void uncompress(DataInput in, BytesRef bytes) throws IOException;
-
-  /**
-   * Method to use if you are only interested into <code>length</code>
-   * uncompressed bytes starting at offset <code>offset</code>. Some compression
-   * codecs might have optimizations for this special case.
-   */
-  public void uncompress(DataInput in, int offset, int length, BytesRef bytes) throws IOException {
-    uncompress(in, bytes);
-    if (bytes.length < offset + length) {
-      throw new IndexOutOfBoundsException((offset + length) + " > " + bytes.length);
-    }
-    bytes.offset += offset;
-    bytes.length = length;
-  }
-
-  public abstract void copyCompressedData(DataInput in, DataOutput out) throws IOException;
-
-  @Override
-  public abstract Uncompressor clone();
-
-}
diff --git a/lucene/codecs/src/test/org/apache/lucene/codecs/compressing/AbstractTestCompressionMode.java b/lucene/codecs/src/test/org/apache/lucene/codecs/compressing/AbstractTestCompressionMode.java
index 7bb7186..5904d50 100644
--- a/lucene/codecs/src/test/org/apache/lucene/codecs/compressing/AbstractTestCompressionMode.java
+++ b/lucene/codecs/src/test/org/apache/lucene/codecs/compressing/AbstractTestCompressionMode.java
@@ -45,81 +45,81 @@ public abstract class AbstractTestCompressionMode extends LuceneTestCase {
     return arr;
   }
 
-  byte[] compress(byte[] uncompressed) throws IOException {
+  byte[] compress(byte[] decompressed) throws IOException {
     Compressor compressor = mode.newCompressor();
-    return compress(compressor, uncompressed);
+    return compress(compressor, decompressed);
   }
 
-  static byte[] compress(Compressor compressor, byte[] uncompressed) throws IOException {
-    byte[] compressed = new byte[uncompressed.length * 2 + 16]; // should be enough
+  static byte[] compress(Compressor compressor, byte[] decompressed) throws IOException {
+    byte[] compressed = new byte[decompressed.length * 2 + 16]; // should be enough
     ByteArrayDataOutput out = new ByteArrayDataOutput(compressed);
-    compressor.compress(uncompressed, 0, uncompressed.length, out);
+    compressor.compress(decompressed, 0, decompressed.length, out);
     final int compressedLen = out.getPosition();
     return Arrays.copyOf(compressed, compressedLen);
   }
 
-  byte[] uncompress(byte[] compressed) throws IOException {
-    Uncompressor uncompressor = mode.newUncompressor();
-    return uncompress(uncompressor, compressed);
+  byte[] decompress(byte[] compressed) throws IOException {
+    Decompressor decompressor = mode.newDecompressor();
+    return decompress(decompressor, compressed);
   }
 
-  static byte[] uncompress(Uncompressor uncompressor, byte[] compressed) throws IOException {
+  static byte[] decompress(Decompressor decompressor, byte[] compressed) throws IOException {
     final BytesRef bytes = new BytesRef();
-    uncompressor.uncompress(new ByteArrayDataInput(compressed), bytes);
+    decompressor.decompress(new ByteArrayDataInput(compressed), bytes);
     return Arrays.copyOfRange(bytes.bytes, bytes.offset, bytes.offset + bytes.length);
   }
 
-  byte[] uncompress(byte[] compressed, int offset, int length) throws IOException {
-    Uncompressor uncompressor = mode.newUncompressor();
+  byte[] decompress(byte[] compressed, int offset, int length) throws IOException {
+    Decompressor decompressor = mode.newDecompressor();
     final BytesRef bytes = new BytesRef();
-    uncompressor.uncompress(new ByteArrayDataInput(compressed), offset, length, bytes);
+    decompressor.decompress(new ByteArrayDataInput(compressed), offset, length, bytes);
     return Arrays.copyOfRange(bytes.bytes, bytes.offset, bytes.offset + bytes.length);
   }
 
-  static byte[] copyCompressedData(Uncompressor uncompressor, byte[] compressed) throws IOException {
+  static byte[] copyCompressedData(Decompressor decompressor, byte[] compressed) throws IOException {
     GrowableByteArrayDataOutput out = new GrowableByteArrayDataOutput(compressed.length);
-    uncompressor.copyCompressedData(new ByteArrayDataInput(compressed), out);
+    decompressor.copyCompressedData(new ByteArrayDataInput(compressed), out);
     return Arrays.copyOf(out.bytes, out.length);
   }
 
   byte[] copyCompressedData(byte[] compressed) throws IOException {
-    return copyCompressedData(mode.newUncompressor(), compressed);
+    return copyCompressedData(mode.newDecompressor(), compressed);
   }
 
-  public void testUncompress() throws IOException {
-    final byte[] uncompressed = randomArray();
-    final byte[] compressed = compress(uncompressed);
-    final byte[] restored = uncompress(compressed);
-    assertArrayEquals(uncompressed, restored);
+  public void testDecompress() throws IOException {
+    final byte[] decompressed = randomArray();
+    final byte[] compressed = compress(decompressed);
+    final byte[] restored = decompress(compressed);
+    assertArrayEquals(decompressed, restored);
   }
 
-  public void testPartialUncompress() throws IOException {
+  public void testPartialDecompress() throws IOException {
     final int iterations = atLeast(10);
     for (int i = 0; i < iterations; ++i) {
-      final byte[] uncompressed = randomArray();
-      final byte[] compressed = compress(uncompressed);
+      final byte[] decompressed = randomArray();
+      final byte[] compressed = compress(decompressed);
       final int offset, length;
-      if (uncompressed.length == 0) {
+      if (decompressed.length == 0) {
         offset = length = 0;
       } else {
-        offset = random().nextInt(uncompressed.length);
-        length = random().nextInt(uncompressed.length - offset);
+        offset = random().nextInt(decompressed.length);
+        length = random().nextInt(decompressed.length - offset);
       }
-      final byte[] restored = uncompress(compressed, offset, length);
-      assertArrayEquals(Arrays.copyOfRange(uncompressed, offset, offset + length), restored);
+      final byte[] restored = decompress(compressed, offset, length);
+      assertArrayEquals(Arrays.copyOfRange(decompressed, offset, offset + length), restored);
     }
   }
 
   public void testCopyCompressedData() throws IOException {
-    final byte[] uncompressed = randomArray();
-    final byte[] compressed = compress(uncompressed);
+    final byte[] decompressed = randomArray();
+    final byte[] compressed = compress(decompressed);
     assertArrayEquals(compressed, copyCompressedData(compressed));
   }
 
-  public void test(byte[] uncompressed) throws IOException {
-    final byte[] compressed = compress(uncompressed);
-    final byte[] restored = uncompress(compressed);
-    assertEquals(uncompressed.length, restored.length);
+  public void test(byte[] decompressed) throws IOException {
+    final byte[] compressed = compress(decompressed);
+    final byte[] restored = decompress(compressed);
+    assertEquals(decompressed.length, restored.length);
     assertArrayEquals(compressed, copyCompressedData(compressed));
   }
 
@@ -132,28 +132,28 @@ public abstract class AbstractTestCompressionMode extends LuceneTestCase {
   }
 
   public void testIncompressible() throws IOException {
-    final byte[] uncompressed = new byte[RandomInts.randomIntBetween(random(), 20, 256)];
-    for (int i = 0; i < uncompressed.length; ++i) {
-      uncompressed[i] = (byte) i;
+    final byte[] decompressed = new byte[RandomInts.randomIntBetween(random(), 20, 256)];
+    for (int i = 0; i < decompressed.length; ++i) {
+      decompressed[i] = (byte) i;
     }
-    test(uncompressed);
+    test(decompressed);
   }
 
   // for LZ compression
 
   public void testShortLiteralsAndMatchs() throws IOException {
     // literals and matchs lengths <= 15
-    final byte[] uncompressed = "1234562345673456745678910123".getBytes("UTF-8");
-    test(uncompressed);
+    final byte[] decompressed = "1234562345673456745678910123".getBytes("UTF-8");
+    test(decompressed);
   }
 
   public void testLongLiteralsAndMatchs() throws IOException {
     // literals and matchs length > 16
-    final byte[] uncompressed = new byte[RandomInts.randomIntBetween(random(), 300, 1024)];
-    for (int i = 0; i < uncompressed.length; ++i) {
-      uncompressed[i] = (byte) i;
+    final byte[] decompressed = new byte[RandomInts.randomIntBetween(random(), 300, 1024)];
+    for (int i = 0; i < decompressed.length; ++i) {
+      decompressed[i] = (byte) i;
     }
-    test(uncompressed);
+    test(decompressed);
   }
 
 }
\ No newline at end of file
diff --git a/lucene/codecs/src/test/org/apache/lucene/codecs/compressing/TestFastDecompressionMode.java b/lucene/codecs/src/test/org/apache/lucene/codecs/compressing/TestFastDecompressionMode.java
new file mode 100644
index 0000000..f525092
--- /dev/null
+++ b/lucene/codecs/src/test/org/apache/lucene/codecs/compressing/TestFastDecompressionMode.java
@@ -0,0 +1,28 @@
+package org.apache.lucene.codecs.compressing;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+
+public class TestFastDecompressionMode extends AbstractTestCompressionMode {
+
+  public void setUp() throws Exception {
+    super.setUp();
+    mode = CompressionMode.FAST_DECOMPRESSION;
+  }
+
+}
diff --git a/lucene/codecs/src/test/org/apache/lucene/codecs/compressing/TestFastUncompressionMode.java b/lucene/codecs/src/test/org/apache/lucene/codecs/compressing/TestFastUncompressionMode.java
deleted file mode 100644
index c3f5762..0000000
--- a/lucene/codecs/src/test/org/apache/lucene/codecs/compressing/TestFastUncompressionMode.java
+++ /dev/null
@@ -1,28 +0,0 @@
-package org.apache.lucene.codecs.compressing;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-
-public class TestFastUncompressionMode extends AbstractTestCompressionMode {
-
-  public void setUp() throws Exception {
-    super.setUp();
-    mode = CompressionMode.FAST_UNCOMPRESSION;
-  }
-
-}

