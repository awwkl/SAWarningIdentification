GitDiffStart: 70a7363fdb2ab12feac7ab10065198602291594a | Thu Oct 6 20:09:36 2011 +0000
diff --git a/dev-tools/idea/modules/grouping/grouping.iml b/dev-tools/idea/modules/grouping/grouping.iml
index bbd6eab..2e0b6ff 100644
--- a/dev-tools/idea/modules/grouping/grouping.iml
+++ b/dev-tools/idea/modules/grouping/grouping.iml
@@ -12,5 +12,6 @@
     <orderEntry type="sourceFolder" forTests="false" />
     <orderEntry type="library" scope="TEST" name="JUnit" level="project" />
     <orderEntry type="module" module-name="lucene" />
+    <orderEntry type="module" module-name="queries" />
   </component>
 </module>
diff --git a/lucene/src/java/org/apache/lucene/index/values/VarSortedBytesImpl.java b/lucene/src/java/org/apache/lucene/index/values/VarSortedBytesImpl.java
index 36caf0b..e352807 100644
--- a/lucene/src/java/org/apache/lucene/index/values/VarSortedBytesImpl.java
+++ b/lucene/src/java/org/apache/lucene/index/values/VarSortedBytesImpl.java
@@ -30,6 +30,7 @@ import org.apache.lucene.store.IndexOutput;
 import org.apache.lucene.util.AttributeSource;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.Counter;
+import org.apache.lucene.util.packed.Direct64;
 import org.apache.lucene.util.packed.PackedInts;
 
 // Stores variable-length byte[] by deref, ie when two docs
diff --git a/modules/build.xml b/modules/build.xml
index 62db70a..6e7dc8c 100644
--- a/modules/build.xml
+++ b/modules/build.xml
@@ -25,9 +25,9 @@
         <fileset dir="analysis" includes="build.xml" />
         <fileset dir="benchmark" includes="build.xml" />
         <fileset dir="facet" includes="build.xml" />
+        <fileset dir="queries" includes="build.xml" />
         <fileset dir="grouping" includes="build.xml" />
         <fileset dir="join" includes="build.xml" />
-        <fileset dir="queries" includes="build.xml" />
         <fileset dir="queryparser" includes="build.xml" />
         <fileset dir="suggest" includes="build.xml" />
       </subant>
@@ -40,9 +40,9 @@
         <fileset dir="analysis" includes="build.xml" />
         <fileset dir="benchmark" includes="build.xml" />
         <fileset dir="facet" includes="build.xml" />
+        <fileset dir="queries" includes="build.xml" />
         <fileset dir="grouping" includes="build.xml" />
         <fileset dir="join" includes="build.xml" />
-        <fileset dir="queries" includes="build.xml" />
         <fileset dir="queryparser" includes="build.xml" />
         <fileset dir="suggest" includes="build.xml" />
       </subant>
@@ -55,9 +55,9 @@
         <fileset dir="analysis" includes="build.xml" />
         <fileset dir="benchmark" includes="build.xml" />
         <fileset dir="facet" includes="build.xml" />
+        <fileset dir="queries" includes="build.xml" />
         <fileset dir="grouping" includes="build.xml" />
         <fileset dir="join" includes="build.xml" />
-        <fileset dir="queries" includes="build.xml" />
         <fileset dir="queryparser" includes="build.xml" />
         <fileset dir="suggest" includes="build.xml" />
       </subant>
@@ -70,9 +70,9 @@
         <fileset dir="analysis" includes="build.xml" />
         <fileset dir="benchmark" includes="build.xml" />
         <fileset dir="facet" includes="build.xml" />
+        <fileset dir="queries" includes="build.xml" />
         <fileset dir="grouping" includes="build.xml" />
         <fileset dir="join" includes="build.xml" />
-        <fileset dir="queries" includes="build.xml" />
         <fileset dir="queryparser" includes="build.xml" />
         <fileset dir="suggest" includes="build.xml" />
       </subant>
@@ -86,9 +86,9 @@
         <fileset dir="analysis" includes="build.xml" />
         <fileset dir="benchmark" includes="build.xml" />
         <fileset dir="facet" includes="build.xml" />
+        <fileset dir="queries" includes="build.xml" />
         <fileset dir="grouping" includes="build.xml" />
         <fileset dir="join" includes="build.xml" />
-        <fileset dir="queries" includes="build.xml" />
         <fileset dir="queryparser" includes="build.xml" />
         <fileset dir="suggest" includes="build.xml" />
       </subant>
@@ -100,9 +100,9 @@
         <fileset dir="analysis" includes="build.xml" />
         <fileset dir="benchmark" includes="build.xml" />
         <fileset dir="facet" includes="build.xml" />
+        <fileset dir="queries" includes="build.xml" />
         <fileset dir="grouping" includes="build.xml" />
         <fileset dir="join" includes="build.xml" />
-        <fileset dir="queries" includes="build.xml" />
         <fileset dir="queryparser" includes="build.xml" />
         <fileset dir="suggest" includes="build.xml" />
       </subant>
@@ -116,9 +116,9 @@
         <fileset dir="analysis" includes="build.xml" />
         <fileset dir="benchmark" includes="build.xml" />
         <fileset dir="facet" includes="build.xml" />
+        <fileset dir="queries" includes="build.xml" />
         <fileset dir="grouping" includes="build.xml" />
         <fileset dir="join" includes="build.xml" />
-        <fileset dir="queries" includes="build.xml" />
         <fileset dir="queryparser" includes="build.xml" />
         <fileset dir="suggest" includes="build.xml" />
       </subant>
diff --git a/modules/grouping/CHANGES.txt b/modules/grouping/CHANGES.txt
index 68e0cce..014e77d 100644
--- a/modules/grouping/CHANGES.txt
+++ b/modules/grouping/CHANGES.txt
@@ -9,3 +9,8 @@ Optimizations
 
 LUCENE-3468: Replaced last() and remove() with pollLast() in
              FirstPassGroupingCollector (Martijn van Groningen)
+
+API Changes
+
+LUCENE-3483: Move Function grouping collectors from Solr to
+             grouping module. (Martijn van Groningen)
diff --git a/modules/grouping/build.xml b/modules/grouping/build.xml
index 6aee191..b71f9d6 100644
--- a/modules/grouping/build.xml
+++ b/modules/grouping/build.xml
@@ -18,8 +18,9 @@
  -->
 
 <project name="grouping" default="default">
+  
     <description>
-        Collectors for grouping search results
+       Grouping module. Collectors for grouping search results
     </description>
 
     <property name="build.dir" location="build/" />
@@ -29,5 +30,18 @@
     <import file="../../lucene/contrib/contrib-build.xml"/>
     <property name="working.dir" location="work"/>
 
+    <path id="test.classpath">
+      <path refid="test.base.classpath" />
+      <pathelement path="${queries.jar}" />
+    </path>
+
+    <path id="classpath">
+      <pathelement path="${queries.jar}" />
+      <path refid="base.classpath"/>
+    </path>
+
     <target name="dist-maven" depends="jar-core,javadocs,contrib-build.dist-maven" />
+    <target name="compile" depends="jar-queries,common.compile-core" description="Compiles facet classes" />
+    <target name="jar-core" depends="common.jar-core" />
+
 </project>
diff --git a/modules/grouping/src/java/org/apache/lucene/search/grouping/BlockGroupingCollector.java b/modules/grouping/src/java/org/apache/lucene/search/grouping/BlockGroupingCollector.java
index 453607c..6f38fa6 100644
--- a/modules/grouping/src/java/org/apache/lucene/search/grouping/BlockGroupingCollector.java
+++ b/modules/grouping/src/java/org/apache/lucene/search/grouping/BlockGroupingCollector.java
@@ -49,7 +49,7 @@ import org.apache.lucene.util.PriorityQueue;
  *  being that the documents in each group must always be
  *  indexed as a block.  This collector also fills in
  *  TopGroups.totalGroupCount without requiring the separate
- *  {@link TermAllGroupsCollector}.  However, this collector does
+ *  {@link org.apache.lucene.search.grouping.term.TermAllGroupsCollector}.  However, this collector does
  *  not fill in the groupValue of each group; this field
  *  will always be null.
  *
diff --git a/modules/grouping/src/java/org/apache/lucene/search/grouping/SentinelIntSet.java b/modules/grouping/src/java/org/apache/lucene/search/grouping/SentinelIntSet.java
index 21da977..a9c6370 100644
--- a/modules/grouping/src/java/org/apache/lucene/search/grouping/SentinelIntSet.java
+++ b/modules/grouping/src/java/org/apache/lucene/search/grouping/SentinelIntSet.java
@@ -19,8 +19,12 @@ package org.apache.lucene.search.grouping;
 
 import java.util.Arrays;
 
-/** A native int set where one value is reserved to mean "EMPTY" */
-class SentinelIntSet {
+/**
+ * A native int set where one value is reserved to mean "EMPTY"
+ *
+ * @lucene.internal
+ */
+public class SentinelIntSet {
   public int[] keys;
   public int count;
   public final int emptyVal;
diff --git a/modules/grouping/src/java/org/apache/lucene/search/grouping/TermAllGroupHeadsCollector.java b/modules/grouping/src/java/org/apache/lucene/search/grouping/TermAllGroupHeadsCollector.java
deleted file mode 100644
index 50067d5..0000000
--- a/modules/grouping/src/java/org/apache/lucene/search/grouping/TermAllGroupHeadsCollector.java
+++ /dev/null
@@ -1,540 +0,0 @@
-package org.apache.lucene.search.grouping;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.search.*;
-import org.apache.lucene.util.BytesRef;
-
-import java.io.IOException;
-import java.util.*;
-
-/**
- * A base implementation of {@link AbstractAllGroupHeadsCollector} for retrieving the most relevant groups when grouping
- * on a string based group field. More specifically this all concrete implementations of this base implementation
- * use {@link org.apache.lucene.search.FieldCache.DocTermsIndex}.
- *
- * @lucene.experimental
- */
-public abstract class TermAllGroupHeadsCollector<GH extends AbstractAllGroupHeadsCollector.GroupHead> extends AbstractAllGroupHeadsCollector<GH> {
-
-  private static final int DEFAULT_INITIAL_SIZE = 128;
-
-  final String groupField;
-  final BytesRef scratchBytesRef = new BytesRef();
-
-  FieldCache.DocTermsIndex groupIndex;
-  IndexReader.AtomicReaderContext readerContext;
-
-  protected TermAllGroupHeadsCollector(String groupField, int numberOfSorts) {
-    super(numberOfSorts);
-    this.groupField = groupField;
-  }
-
-  /**
-   * Creates an <code>AbstractAllGroupHeadsCollector</code> instance based on the supplied arguments.
-   * This factory method decides with implementation is best suited.
-   *
-   * Delegates to {@link #create(String, org.apache.lucene.search.Sort, int)} with an initialSize of 128.
-   *
-   * @param groupField      The field to group by
-   * @param sortWithinGroup The sort within each group
-   * @return an <code>AbstractAllGroupHeadsCollector</code> instance based on the supplied arguments
-   * @throws IOException If I/O related errors occur
-   */
-  public static AbstractAllGroupHeadsCollector create(String groupField, Sort sortWithinGroup) throws IOException {
-    return create(groupField, sortWithinGroup, DEFAULT_INITIAL_SIZE);
-  }
-
-  /**
-   * Creates an <code>AbstractAllGroupHeadsCollector</code> instance based on the supplied arguments.
-   * This factory method decides with implementation is best suited.
-   *
-   * @param groupField      The field to group by
-   * @param sortWithinGroup The sort within each group
-   * @param initialSize The initial allocation size of the internal int set and group list which should roughly match
-   *                    the total number of expected unique groups. Be aware that the heap usage is
-   *                    4 bytes * initialSize.
-   * @return an <code>AbstractAllGroupHeadsCollector</code> instance based on the supplied arguments
-   * @throws IOException If I/O related errors occur
-   */
-  public static AbstractAllGroupHeadsCollector create(String groupField, Sort sortWithinGroup, int initialSize) throws IOException {
-    boolean sortAllScore = true;
-    boolean sortAllFieldValue = true;
-
-    for (SortField sortField : sortWithinGroup.getSort()) {
-      if (sortField.getType() == SortField.Type.SCORE) {
-        sortAllFieldValue = false;
-      } else if (needGeneralImpl(sortField)) {
-        return new GeneralAllGroupHeadsCollector(groupField, sortWithinGroup);
-      } else {
-        sortAllScore = false;
-      }
-    }
-
-    if (sortAllScore) {
-      return new ScoreAllGroupHeadsCollector(groupField, sortWithinGroup, initialSize);
-    } else if (sortAllFieldValue) {
-      return new OrdAllGroupHeadsCollector(groupField, sortWithinGroup, initialSize);
-    } else {
-      return new OrdScoreAllGroupHeadsCollector(groupField, sortWithinGroup, initialSize);
-    }
-  }
-
-  // Returns when a sort field needs the general impl.
-  private static boolean needGeneralImpl(SortField sortField) {
-    SortField.Type sortType = sortField.getType();
-    // Note (MvG): We can also make an optimized impl when sorting is SortField.DOC
-    return sortType != SortField.Type.STRING_VAL && sortType != SortField.Type.STRING && sortType != SortField.Type.SCORE;
-  }
-
-  // A general impl that works for any group sort.
-  static class GeneralAllGroupHeadsCollector extends TermAllGroupHeadsCollector<GeneralAllGroupHeadsCollector.GroupHead> {
-
-    private final Sort sortWithinGroup;
-    private final Map<BytesRef, GroupHead> groups;
-
-    private Scorer scorer;
-
-    GeneralAllGroupHeadsCollector(String groupField, Sort sortWithinGroup) throws IOException {
-      super(groupField, sortWithinGroup.getSort().length);
-      this.sortWithinGroup = sortWithinGroup;
-      groups = new HashMap<BytesRef, GroupHead>();
-
-      final SortField[] sortFields = sortWithinGroup.getSort();
-      for (int i = 0; i < sortFields.length; i++) {
-        reversed[i] = sortFields[i].getReverse() ? -1 : 1;
-      }
-    }
-
-    protected void retrieveGroupHeadAndAddIfNotExist(int doc) throws IOException {
-      final int ord = groupIndex.getOrd(doc);
-      final BytesRef groupValue = ord == 0 ? null : groupIndex.lookup(ord, scratchBytesRef);
-      GroupHead groupHead = groups.get(groupValue);
-      if (groupHead == null) {
-        groupHead = new GroupHead(groupValue, sortWithinGroup, doc);
-        groups.put(groupValue == null ? null : new BytesRef(groupValue), groupHead);
-        temporalResult.stop = true;
-      } else {
-        temporalResult.stop = false;
-      }
-      temporalResult.groupHead = groupHead;
-    }
-
-    protected Collection<GroupHead> getCollectedGroupHeads() {
-      return groups.values();
-    }
-
-    public void setNextReader(IndexReader.AtomicReaderContext context) throws IOException {
-      this.readerContext = context;
-      groupIndex = FieldCache.DEFAULT.getTermsIndex(context.reader, groupField);
-
-      for (GroupHead groupHead : groups.values()) {
-        for (int i = 0; i < groupHead.comparators.length; i++) {
-          groupHead.comparators[i] = groupHead.comparators[i].setNextReader(context);
-        }
-      }
-    }
-
-    public void setScorer(Scorer scorer) throws IOException {
-      this.scorer = scorer;
-      for (GroupHead groupHead : groups.values()) {
-        for (FieldComparator comparator : groupHead.comparators) {
-          comparator.setScorer(scorer);
-        }
-      }
-    }
-
-    class GroupHead extends AbstractAllGroupHeadsCollector.GroupHead<BytesRef> {
-
-      final FieldComparator[] comparators;
-
-      private GroupHead(BytesRef groupValue, Sort sort, int doc) throws IOException {
-        super(groupValue, doc + readerContext.docBase);
-        final SortField[] sortFields = sort.getSort();
-        comparators = new FieldComparator[sortFields.length];
-        for (int i = 0; i < sortFields.length; i++) {
-          comparators[i] = sortFields[i].getComparator(1, i).setNextReader(readerContext);
-          comparators[i].setScorer(scorer);
-          comparators[i].copy(0, doc);
-          comparators[i].setBottom(0);
-        }
-      }
-
-      public int compare(int compIDX, int doc) throws IOException {
-        return comparators[compIDX].compareBottom(doc);
-      }
-
-      public void updateDocHead(int doc) throws IOException {
-        for (FieldComparator comparator : comparators) {
-          comparator.copy(0, doc);
-          comparator.setBottom(0);
-        }
-        this.doc = doc + readerContext.docBase;
-      }
-    }
-  }
-
-
-  // AbstractAllGroupHeadsCollector optimized for ord fields and scores.
-  static class OrdScoreAllGroupHeadsCollector extends TermAllGroupHeadsCollector<OrdScoreAllGroupHeadsCollector.GroupHead> {
-
-    private final SentinelIntSet ordSet;
-    private final List<GroupHead> collectedGroups;
-    private final SortField[] fields;
-
-    private FieldCache.DocTermsIndex[] sortsIndex;
-    private Scorer scorer;
-    private GroupHead[] segmentGroupHeads;
-
-    OrdScoreAllGroupHeadsCollector(String groupField, Sort sortWithinGroup, int initialSize) {
-      super(groupField, sortWithinGroup.getSort().length);
-      ordSet = new SentinelIntSet(initialSize, -1);
-      collectedGroups = new ArrayList<GroupHead>(initialSize);
-
-      final SortField[] sortFields = sortWithinGroup.getSort();
-      fields = new SortField[sortFields.length];
-      sortsIndex = new FieldCache.DocTermsIndex[sortFields.length];
-      for (int i = 0; i < sortFields.length; i++) {
-        reversed[i] = sortFields[i].getReverse() ? -1 : 1;
-        fields[i] = sortFields[i];
-      }
-    }
-
-    protected Collection<GroupHead> getCollectedGroupHeads() {
-      return collectedGroups;
-    }
-
-    public void setScorer(Scorer scorer) throws IOException {
-      this.scorer = scorer;
-    }
-
-    protected void retrieveGroupHeadAndAddIfNotExist(int doc) throws IOException {
-      int key = groupIndex.getOrd(doc);
-      GroupHead groupHead;
-      if (!ordSet.exists(key)) {
-        ordSet.put(key);
-        BytesRef term = key == 0 ? null : groupIndex.getTerm(doc, new BytesRef());
-        groupHead = new GroupHead(doc, term);
-        collectedGroups.add(groupHead);
-        segmentGroupHeads[key] = groupHead;
-        temporalResult.stop = true;
-      } else {
-        temporalResult.stop = false;
-        groupHead = segmentGroupHeads[key];
-      }
-      temporalResult.groupHead = groupHead;
-    }
-
-    public void setNextReader(IndexReader.AtomicReaderContext context) throws IOException {
-      this.readerContext = context;
-      groupIndex = FieldCache.DEFAULT.getTermsIndex(context.reader, groupField);
-      for (int i = 0; i < fields.length; i++) {
-        if (fields[i].getType() == SortField.Type.SCORE) {
-          continue;
-        }
-
-        sortsIndex[i] = FieldCache.DEFAULT.getTermsIndex(context.reader, fields[i].getField());
-      }
-
-      // Clear ordSet and fill it with previous encountered groups that can occur in the current segment.
-      ordSet.clear();
-      segmentGroupHeads = new GroupHead[groupIndex.numOrd()];
-      for (GroupHead collectedGroup : collectedGroups) {
-        int ord = groupIndex.binarySearchLookup(collectedGroup.groupValue, scratchBytesRef);
-        if (ord >= 0) {
-          ordSet.put(ord);
-          segmentGroupHeads[ord] = collectedGroup;
-
-          for (int i = 0; i < sortsIndex.length; i++) {
-            if (fields[i].getType() == SortField.Type.SCORE) {
-              continue;
-            }
-
-            collectedGroup.sortOrds[i] = sortsIndex[i].binarySearchLookup(collectedGroup.sortValues[i], scratchBytesRef);
-          }
-        }
-      }
-    }
-
-    class GroupHead extends AbstractAllGroupHeadsCollector.GroupHead<BytesRef> {
-
-      BytesRef[] sortValues;
-      int[] sortOrds;
-      float[] scores;
-
-      private GroupHead(int doc, BytesRef groupValue) throws IOException {
-        super(groupValue, doc + readerContext.docBase);
-        sortValues = new BytesRef[sortsIndex.length];
-        sortOrds = new int[sortsIndex.length];
-        scores = new float[sortsIndex.length];
-        for (int i = 0; i < sortsIndex.length; i++) {
-          if (fields[i].getType() == SortField.Type.SCORE) {
-            scores[i] = scorer.score();
-          } else {
-            sortValues[i] = sortsIndex[i].getTerm(doc, new BytesRef());
-            sortOrds[i] = sortsIndex[i].getOrd(doc);
-          }
-        }
-
-      }
-
-      public int compare(int compIDX, int doc) throws IOException {
-        if (fields[compIDX].getType() == SortField.Type.SCORE) {
-          float score = scorer.score();
-          if (scores[compIDX] < score) {
-            return 1;
-          } else if (scores[compIDX] > score) {
-            return -1;
-          }
-          return 0;
-        } else {
-          if (sortOrds[compIDX] < 0) {
-            // The current segment doesn't contain the sort value we encountered before. Therefore the ord is negative.
-            return sortValues[compIDX].compareTo(sortsIndex[compIDX].getTerm(doc, scratchBytesRef));
-          } else {
-            return sortOrds[compIDX] - sortsIndex[compIDX].getOrd(doc);
-          }
-        }
-      }
-
-      public void updateDocHead(int doc) throws IOException {
-        for (int i = 0; i < sortsIndex.length; i++) {
-          if (fields[i].getType() == SortField.Type.SCORE) {
-            scores[i] = scorer.score();
-          } else {
-            sortValues[i] = sortsIndex[i].getTerm(doc, sortValues[i]);
-            sortOrds[i] = sortsIndex[i].getOrd(doc);
-          }
-        }
-        this.doc = doc + readerContext.docBase;
-      }
-
-    }
-
-  }
-
-
-  // AbstractAllGroupHeadsCollector optimized for ord fields.
-  static class OrdAllGroupHeadsCollector extends TermAllGroupHeadsCollector<OrdAllGroupHeadsCollector.GroupHead> {
-
-    private final SentinelIntSet ordSet;
-    private final List<GroupHead> collectedGroups;
-    private final SortField[] fields;
-
-    private FieldCache.DocTermsIndex[] sortsIndex;
-    private GroupHead[] segmentGroupHeads;
-
-    OrdAllGroupHeadsCollector(String groupField, Sort sortWithinGroup, int initialSize) {
-      super(groupField, sortWithinGroup.getSort().length);
-      ordSet = new SentinelIntSet(initialSize, -1);
-      collectedGroups = new ArrayList<GroupHead>(initialSize);
-
-      final SortField[] sortFields = sortWithinGroup.getSort();
-      fields = new SortField[sortFields.length];
-      sortsIndex = new FieldCache.DocTermsIndex[sortFields.length];
-      for (int i = 0; i < sortFields.length; i++) {
-        reversed[i] = sortFields[i].getReverse() ? -1 : 1;
-        fields[i] = sortFields[i];
-      }
-    }
-
-    protected Collection<GroupHead> getCollectedGroupHeads() {
-      return collectedGroups;
-    }
-
-    public void setScorer(Scorer scorer) throws IOException {
-    }
-
-    protected void retrieveGroupHeadAndAddIfNotExist(int doc) throws IOException {
-      int key = groupIndex.getOrd(doc);
-      GroupHead groupHead;
-      if (!ordSet.exists(key)) {
-        ordSet.put(key);
-        BytesRef term = key == 0 ? null : groupIndex.getTerm(doc, new BytesRef());
-        groupHead = new GroupHead(doc, term);
-        collectedGroups.add(groupHead);
-        segmentGroupHeads[key] = groupHead;
-        temporalResult.stop = true;
-      } else {
-        temporalResult.stop = false;
-        groupHead = segmentGroupHeads[key];
-      }
-      temporalResult.groupHead = groupHead;
-    }
-
-    public void setNextReader(IndexReader.AtomicReaderContext context) throws IOException {
-      this.readerContext = context;
-      groupIndex = FieldCache.DEFAULT.getTermsIndex(context.reader, groupField);
-      for (int i = 0; i < fields.length; i++) {
-        sortsIndex[i] = FieldCache.DEFAULT.getTermsIndex(context.reader, fields[i].getField());
-      }
-
-      // Clear ordSet and fill it with previous encountered groups that can occur in the current segment.
-      ordSet.clear();
-      segmentGroupHeads = new GroupHead[groupIndex.numOrd()];
-      for (GroupHead collectedGroup : collectedGroups) {
-        int groupOrd = groupIndex.binarySearchLookup(collectedGroup.groupValue, scratchBytesRef);
-        if (groupOrd >= 0) {
-          ordSet.put(groupOrd);
-          segmentGroupHeads[groupOrd] = collectedGroup;
-
-          for (int i = 0; i < sortsIndex.length; i++) {
-            collectedGroup.sortOrds[i] = sortsIndex[i].binarySearchLookup(collectedGroup.sortValues[i], scratchBytesRef);
-          }
-        }
-      }
-    }
-
-    class GroupHead extends AbstractAllGroupHeadsCollector.GroupHead<BytesRef> {
-
-      BytesRef[] sortValues;
-      int[] sortOrds;
-
-      private GroupHead(int doc, BytesRef groupValue) throws IOException {
-        super(groupValue, doc + readerContext.docBase);
-        sortValues = new BytesRef[sortsIndex.length];
-        sortOrds = new int[sortsIndex.length];
-        for (int i = 0; i < sortsIndex.length; i++) {
-          sortValues[i] = sortsIndex[i].getTerm(doc, new BytesRef());
-          sortOrds[i] = sortsIndex[i].getOrd(doc);
-        }
-      }
-
-      public int compare(int compIDX, int doc) throws IOException {
-        if (sortOrds[compIDX] < 0) {
-          // The current segment doesn't contain the sort value we encountered before. Therefore the ord is negative.
-          return sortValues[compIDX].compareTo(sortsIndex[compIDX].getTerm(doc, scratchBytesRef));
-        } else {
-          return sortOrds[compIDX] - sortsIndex[compIDX].getOrd(doc);
-        }
-      }
-
-      public void updateDocHead(int doc) throws IOException {
-        for (int i = 0; i < sortsIndex.length; i++) {
-          sortValues[i] = sortsIndex[i].getTerm(doc, sortValues[i]);
-          sortOrds[i] = sortsIndex[i].getOrd(doc);
-        }
-        this.doc = doc + readerContext.docBase;
-      }
-
-    }
-
-  }
-
-
-  // AbstractAllGroupHeadsCollector optimized for scores.
-  static class ScoreAllGroupHeadsCollector extends TermAllGroupHeadsCollector<ScoreAllGroupHeadsCollector.GroupHead> {
-
-    private final SentinelIntSet ordSet;
-    private final List<GroupHead> collectedGroups;
-    private final SortField[] fields;
-
-    private Scorer scorer;
-    private GroupHead[] segmentGroupHeads;
-
-    ScoreAllGroupHeadsCollector(String groupField, Sort sortWithinGroup, int initialSize) {
-      super(groupField, sortWithinGroup.getSort().length);
-      ordSet = new SentinelIntSet(initialSize, -1);
-      collectedGroups = new ArrayList<GroupHead>(initialSize);
-
-      final SortField[] sortFields = sortWithinGroup.getSort();
-      fields = new SortField[sortFields.length];
-      for (int i = 0; i < sortFields.length; i++) {
-        reversed[i] = sortFields[i].getReverse() ? -1 : 1;
-        fields[i] = sortFields[i];
-      }
-    }
-
-    protected Collection<GroupHead> getCollectedGroupHeads() {
-      return collectedGroups;
-    }
-
-    public void setScorer(Scorer scorer) throws IOException {
-      this.scorer = scorer;
-    }
-
-    protected void retrieveGroupHeadAndAddIfNotExist(int doc) throws IOException {
-      int key = groupIndex.getOrd(doc);
-      GroupHead groupHead;
-      if (!ordSet.exists(key)) {
-        ordSet.put(key);
-        BytesRef term = key == 0 ? null : groupIndex.getTerm(doc, new BytesRef());
-        groupHead = new GroupHead(doc, term);
-        collectedGroups.add(groupHead);
-        segmentGroupHeads[key] = groupHead;
-        temporalResult.stop = true;
-      } else {
-        temporalResult.stop = false;
-        groupHead = segmentGroupHeads[key];
-      }
-      temporalResult.groupHead = groupHead;
-    }
-
-    public void setNextReader(IndexReader.AtomicReaderContext context) throws IOException {
-      this.readerContext = context;
-      groupIndex = FieldCache.DEFAULT.getTermsIndex(context.reader, groupField);
-
-      // Clear ordSet and fill it with previous encountered groups that can occur in the current segment.
-      ordSet.clear();
-      segmentGroupHeads = new GroupHead[groupIndex.numOrd()];
-      for (GroupHead collectedGroup : collectedGroups) {
-        int ord = groupIndex.binarySearchLookup(collectedGroup.groupValue, scratchBytesRef);
-        if (ord >= 0) {
-          ordSet.put(ord);
-          segmentGroupHeads[ord] = collectedGroup;
-        }
-      }
-    }
-
-    class GroupHead extends AbstractAllGroupHeadsCollector.GroupHead<BytesRef> {
-
-      float[] scores;
-
-      private GroupHead(int doc, BytesRef groupValue) throws IOException {
-        super(groupValue, doc + readerContext.docBase);
-        scores = new float[fields.length];
-        float score = scorer.score();
-        for (int i = 0; i < scores.length; i++) {
-          scores[i] = score;
-        }
-      }
-
-      public int compare(int compIDX, int doc) throws IOException {
-        float score = scorer.score();
-        if (scores[compIDX] < score) {
-          return 1;
-        } else if (scores[compIDX] > score) {
-          return -1;
-        }
-        return 0;
-      }
-
-      public void updateDocHead(int doc) throws IOException {
-        float score = scorer.score();
-        for (int i = 0; i < scores.length; i++) {
-          scores[i] = score;
-        }
-        this.doc = doc + readerContext.docBase;
-      }
-
-    }
-
-  }
-
-}
\ No newline at end of file
diff --git a/modules/grouping/src/java/org/apache/lucene/search/grouping/TermAllGroupsCollector.java b/modules/grouping/src/java/org/apache/lucene/search/grouping/TermAllGroupsCollector.java
deleted file mode 100644
index 6d0ac38..0000000
--- a/modules/grouping/src/java/org/apache/lucene/search/grouping/TermAllGroupsCollector.java
+++ /dev/null
@@ -1,111 +0,0 @@
-package org.apache.lucene.search.grouping;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.search.FieldCache;
-import org.apache.lucene.util.BytesRef;
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.List;
-
-/**
- * A collector that collects all groups that match the
- * query. Only the group value is collected, and the order
- * is undefined.  This collector does not determine
- * the most relevant document of a group.
- *
- * <p/>
- * Implementation detail: an int hash set (SentinelIntSet)
- * is used to detect if a group is already added to the
- * total count.  For each segment the int set is cleared and filled
- * with previous counted groups that occur in the new
- * segment.
- *
- * @lucene.experimental
- */
-public class TermAllGroupsCollector extends AbstractAllGroupsCollector<BytesRef> {
-
-  private static final int DEFAULT_INITIAL_SIZE = 128;
-
-  private final String groupField;
-  private final SentinelIntSet ordSet;
-  private final List<BytesRef> groups;
-
-  private FieldCache.DocTermsIndex index;
-  private final BytesRef spareBytesRef = new BytesRef();
-
-  /**
-   * Expert: Constructs a {@link AbstractAllGroupsCollector}
-   *
-   * @param groupField  The field to group by
-   * @param initialSize The initial allocation size of the
-   *                    internal int set and group list
-   *                    which should roughly match the total
-   *                    number of expected unique groups. Be aware that the
-   *                    heap usage is 4 bytes * initialSize.
-   */
-  public TermAllGroupsCollector(String groupField, int initialSize) {
-    ordSet = new SentinelIntSet(initialSize, -1);
-    groups = new ArrayList<BytesRef>(initialSize);
-    this.groupField = groupField;
-  }
-
-  /**
-   * Constructs a {@link AbstractAllGroupsCollector}. This sets the
-   * initial allocation size for the internal int set and group
-   * list to 128.
-   *
-   * @param groupField The field to group by
-   */
-  public TermAllGroupsCollector(String groupField) {
-    this(groupField, DEFAULT_INITIAL_SIZE);
-  }
-
-  public void collect(int doc) throws IOException {
-    int key = index.getOrd(doc);
-    if (!ordSet.exists(key)) {
-      ordSet.put(key);
-      BytesRef term = key == 0 ? null : index.lookup(key, new BytesRef());
-      groups.add(term);
-    }
-  }
-
-  /**
-   * {@inheritDoc}
-   */
-  public Collection<BytesRef> getGroups() {
-    return groups;
-  }
-
-  public void setNextReader(IndexReader.AtomicReaderContext context) throws IOException {
-    index = FieldCache.DEFAULT.getTermsIndex(context.reader, groupField);
-
-    // Clear ordSet and fill it with previous encountered groups that can occur in the current segment.
-    ordSet.clear();
-    for (BytesRef countedGroup : groups) {
-      int ord = index.binarySearchLookup(countedGroup, spareBytesRef);
-      if (ord >= 0) {
-        ordSet.put(ord);
-      }
-    }
-  }
-
-}
diff --git a/modules/grouping/src/java/org/apache/lucene/search/grouping/TermFirstPassGroupingCollector.java b/modules/grouping/src/java/org/apache/lucene/search/grouping/TermFirstPassGroupingCollector.java
deleted file mode 100644
index 2ac341f..0000000
--- a/modules/grouping/src/java/org/apache/lucene/search/grouping/TermFirstPassGroupingCollector.java
+++ /dev/null
@@ -1,85 +0,0 @@
-package org.apache.lucene.search.grouping;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.index.IndexReader.AtomicReaderContext;
-import org.apache.lucene.search.FieldCache;
-import org.apache.lucene.search.Sort;
-import org.apache.lucene.util.BytesRef;
-
-import java.io.IOException;
-
-/**
- * Concrete implementation of {@link AbstractFirstPassGroupingCollector} that groups based on
- * field values and more specifically uses {@link org.apache.lucene.search.FieldCache.DocTermsIndex}
- * to collect groups.
- *
- * @lucene.experimental
- */
-public class TermFirstPassGroupingCollector extends AbstractFirstPassGroupingCollector<BytesRef> {
-
-  private final BytesRef scratchBytesRef = new BytesRef();
-  private FieldCache.DocTermsIndex index;
-
-  private String groupField;
-
-  /**
-   * Create the first pass collector.
-   *
-   *  @param groupField The field used to group
-   *    documents. This field must be single-valued and
-   *    indexed (FieldCache is used to access its value
-   *    per-document).
-   *  @param groupSort The {@link Sort} used to sort the
-   *    groups.  The top sorted document within each group
-   *    according to groupSort, determines how that group
-   *    sorts against other groups.  This must be non-null,
-   *    ie, if you want to groupSort by relevance use
-   *    Sort.RELEVANCE.
-   *  @param topNGroups How many top groups to keep.
-   *  @throws IOException When I/O related errors occur
-   */
-  public TermFirstPassGroupingCollector(String groupField, Sort groupSort, int topNGroups) throws IOException {
-    super(groupSort, topNGroups);
-    this.groupField = groupField;
-  }
-
-  @Override
-  protected BytesRef getDocGroupValue(int doc) {
-    final int ord = index.getOrd(doc);
-    return ord == 0 ? null : index.lookup(ord, scratchBytesRef);
-  }
-
-  @Override
-  protected BytesRef copyDocGroupValue(BytesRef groupValue, BytesRef reuse) {
-    if (groupValue == null) {
-      return null;
-    } else if (reuse != null) {
-      reuse.copy(groupValue);
-      return reuse;
-    } else {
-      return new BytesRef(groupValue);
-    }
-  }
-
-  @Override
-  public void setNextReader(AtomicReaderContext readerContext) throws IOException {
-    super.setNextReader(readerContext);
-    index = FieldCache.DEFAULT.getTermsIndex(readerContext.reader, groupField);
-  }
-}
diff --git a/modules/grouping/src/java/org/apache/lucene/search/grouping/TermSecondPassGroupingCollector.java b/modules/grouping/src/java/org/apache/lucene/search/grouping/TermSecondPassGroupingCollector.java
deleted file mode 100644
index bf81f98..0000000
--- a/modules/grouping/src/java/org/apache/lucene/search/grouping/TermSecondPassGroupingCollector.java
+++ /dev/null
@@ -1,76 +0,0 @@
-package org.apache.lucene.search.grouping;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.index.IndexReader.AtomicReaderContext;
-import org.apache.lucene.search.FieldCache;
-import org.apache.lucene.search.Sort;
-import org.apache.lucene.util.BytesRef;
-
-import java.io.IOException;
-import java.util.Collection;
-
-/**
- * Concrete implementation of {@link AbstractSecondPassGroupingCollector} that groups based on
- * field values and more specifically uses {@link org.apache.lucene.search.FieldCache.DocTermsIndex}
- * to collect grouped docs.
- *
- * @lucene.experimental
- */
-public class TermSecondPassGroupingCollector extends AbstractSecondPassGroupingCollector<BytesRef> {
-
-  private final SentinelIntSet ordSet;
-  private FieldCache.DocTermsIndex index;
-  private final BytesRef spareBytesRef = new BytesRef();
-  private final String groupField;
-
-  @SuppressWarnings("unchecked")
-  public TermSecondPassGroupingCollector(String groupField, Collection<SearchGroup<BytesRef>> groups, Sort groupSort, Sort withinGroupSort,
-                                         int maxDocsPerGroup, boolean getScores, boolean getMaxScores, boolean fillSortFields)
-      throws IOException {
-    super(groups, groupSort, withinGroupSort, maxDocsPerGroup, getScores, getMaxScores, fillSortFields);
-    ordSet = new SentinelIntSet(groupMap.size(), -1);
-    this.groupField = groupField;
-    groupDocs = (SearchGroupDocs<BytesRef>[]) new SearchGroupDocs[ordSet.keys.length];
-  }
-
-  @Override
-  public void setNextReader(AtomicReaderContext readerContext) throws IOException {
-    super.setNextReader(readerContext);
-    index = FieldCache.DEFAULT.getTermsIndex(readerContext.reader, groupField);
-
-    // Rebuild ordSet
-    ordSet.clear();
-    for (SearchGroupDocs<BytesRef> group : groupMap.values()) {
-//      System.out.println("  group=" + (group.groupValue == null ? "null" : group.groupValue.utf8ToString()));
-      int ord = group.groupValue == null ? 0 : index.binarySearchLookup(group.groupValue, spareBytesRef);
-      if (ord >= 0) {
-        groupDocs[ordSet.put(ord)] = group;
-      }
-    }
-  }
-
-  @Override
-  protected SearchGroupDocs<BytesRef> retrieveGroup(int doc) throws IOException {
-    int slot = ordSet.find(index.getOrd(doc));
-    if (slot >= 0) {
-      return groupDocs[slot];
-    }
-    return null;
-  }
-}
\ No newline at end of file
diff --git a/modules/grouping/src/java/org/apache/lucene/search/grouping/function/FunctionAllGroupHeadsCollector.java b/modules/grouping/src/java/org/apache/lucene/search/grouping/function/FunctionAllGroupHeadsCollector.java
new file mode 100644
index 0000000..6acc90c
--- /dev/null
+++ b/modules/grouping/src/java/org/apache/lucene/search/grouping/function/FunctionAllGroupHeadsCollector.java
@@ -0,0 +1,147 @@
+package org.apache.lucene.search.grouping.function;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.queries.function.DocValues;
+import org.apache.lucene.queries.function.ValueSource;
+import org.apache.lucene.search.FieldComparator;
+import org.apache.lucene.search.Scorer;
+import org.apache.lucene.search.Sort;
+import org.apache.lucene.search.SortField;
+import org.apache.lucene.search.grouping.AbstractAllGroupHeadsCollector;
+import org.apache.lucene.util.mutable.MutableValue;
+
+import java.io.IOException;
+import java.util.Collection;
+import java.util.HashMap;
+import java.util.Map;
+
+/**
+ * An implementation of {@link AbstractAllGroupHeadsCollector} for retrieving the most relevant groups when grouping
+ * by {@link ValueSource}.
+ *
+ * @lucene.experimental
+ */
+public class FunctionAllGroupHeadsCollector extends AbstractAllGroupHeadsCollector<FunctionAllGroupHeadsCollector.GroupHead> {
+
+  private final ValueSource groupBy;
+  private final Map vsContext;
+  private final Map<MutableValue, GroupHead> groups;
+  private final Sort sortWithinGroup;
+
+  private DocValues.ValueFiller filler;
+  private MutableValue mval;
+  private IndexReader.AtomicReaderContext readerContext;
+  private Scorer scorer;
+
+  /**
+   * Constructs a {@link FunctionAllGroupHeadsCollector} instance.
+   *
+   * @param groupBy The {@link ValueSource} to group by
+   * @param vsContext The ValueSource context
+   * @param sortWithinGroup The sort within a group
+   */
+  public FunctionAllGroupHeadsCollector(ValueSource groupBy, Map vsContext, Sort sortWithinGroup) {
+    super(sortWithinGroup.getSort().length);
+    groups = new HashMap<MutableValue, GroupHead>();
+    this.sortWithinGroup = sortWithinGroup;
+    this.groupBy = groupBy;
+    this.vsContext = vsContext;
+
+    final SortField[] sortFields = sortWithinGroup.getSort();
+    for (int i = 0; i < sortFields.length; i++) {
+      reversed[i] = sortFields[i].getReverse() ? -1 : 1;
+    }
+  }
+
+  /**
+   * {@inheritDoc}
+   */
+  protected void retrieveGroupHeadAndAddIfNotExist(int doc) throws IOException {
+    filler.fillValue(doc);
+    GroupHead groupHead = groups.get(mval);
+    if (groupHead == null) {
+      MutableValue groupValue = mval.duplicate();
+      groupHead = new GroupHead(groupValue, sortWithinGroup, doc);
+      groups.put(groupValue, groupHead);
+      temporalResult.stop = true;
+    } else {
+      temporalResult.stop = false;
+    }
+    this.temporalResult.groupHead = groupHead;
+  }
+
+   /**
+   * {@inheritDoc}
+   */
+  protected Collection<GroupHead> getCollectedGroupHeads() {
+    return groups.values();
+  }
+
+  public void setScorer(Scorer scorer) throws IOException {
+    this.scorer = scorer;
+    for (GroupHead groupHead : groups.values()) {
+      for (FieldComparator comparator : groupHead.comparators) {
+        comparator.setScorer(scorer);
+      }
+    }
+  }
+
+  public void setNextReader(IndexReader.AtomicReaderContext context) throws IOException {
+    this.readerContext = context;
+    DocValues docValues = groupBy.getValues(vsContext, context);
+    filler = docValues.getValueFiller();
+    mval = filler.getValue();
+
+    for (GroupHead groupHead : groups.values()) {
+      for (int i = 0; i < groupHead.comparators.length; i++) {
+        groupHead.comparators[i] = groupHead.comparators[i].setNextReader(context);
+      }
+    }
+  }
+
+  class GroupHead extends AbstractAllGroupHeadsCollector.GroupHead<MutableValue> {
+
+    final FieldComparator[] comparators;
+
+    private GroupHead(MutableValue groupValue, Sort sort, int doc) throws IOException {
+      super(groupValue, doc + readerContext.docBase);
+      final SortField[] sortFields = sort.getSort();
+      comparators = new FieldComparator[sortFields.length];
+      for (int i = 0; i < sortFields.length; i++) {
+        comparators[i] = sortFields[i].getComparator(1, i).setNextReader(readerContext);
+        comparators[i].setScorer(scorer);
+        comparators[i].copy(0, doc);
+        comparators[i].setBottom(0);
+      }
+    }
+
+    public int compare(int compIDX, int doc) throws IOException {
+      return comparators[compIDX].compareBottom(doc);
+    }
+
+    public void updateDocHead(int doc) throws IOException {
+      for (FieldComparator comparator : comparators) {
+        comparator.copy(0, doc);
+        comparator.setBottom(0);
+      }
+      this.doc = doc + readerContext.docBase;
+    }
+  }
+}
diff --git a/modules/grouping/src/java/org/apache/lucene/search/grouping/function/FunctionAllGroupsCollector.java b/modules/grouping/src/java/org/apache/lucene/search/grouping/function/FunctionAllGroupsCollector.java
new file mode 100644
index 0000000..f17aba3
--- /dev/null
+++ b/modules/grouping/src/java/org/apache/lucene/search/grouping/function/FunctionAllGroupsCollector.java
@@ -0,0 +1,86 @@
+package org.apache.lucene.search.grouping.function;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.queries.function.DocValues;
+import org.apache.lucene.queries.function.ValueSource;
+import org.apache.lucene.search.grouping.AbstractAllGroupsCollector;
+import org.apache.lucene.util.mutable.MutableValue;
+
+import java.io.IOException;
+import java.util.Collection;
+import java.util.Map;
+import java.util.SortedSet;
+import java.util.TreeSet;
+
+/**
+ * A collector that collects all groups that match the
+ * query. Only the group value is collected, and the order
+ * is undefined.  This collector does not determine
+ * the most relevant document of a group.
+ *
+ * <p/>
+ * Implementation detail: Uses {@link ValueSource} and {@link DocValues} to retrieve the
+ * field values to group by.
+ *
+ * @lucene.experimental
+ */
+public class FunctionAllGroupsCollector extends AbstractAllGroupsCollector<MutableValue> {
+
+  private final Map vsContext;
+  private final ValueSource groupBy;
+  private final SortedSet<MutableValue> groups = new TreeSet<MutableValue>();
+
+  private DocValues.ValueFiller filler;
+  private MutableValue mval;
+
+  /**
+   * Constructs a {@link FunctionAllGroupsCollector} instance.
+   *
+   * @param groupBy The {@link ValueSource} to group by
+   * @param vsContext The ValueSource context
+   */
+  public FunctionAllGroupsCollector(ValueSource groupBy, Map vsContext) {
+    this.vsContext = vsContext;
+    this.groupBy = groupBy;
+  }
+
+  /**
+   * {@inheritDoc}
+   */
+  public Collection<MutableValue> getGroups() {
+    return groups;
+  }
+
+  public void collect(int doc) throws IOException {
+    filler.fillValue(doc);
+    if (!groups.contains(mval)) {
+      groups.add(mval.duplicate());
+    }
+  }
+
+  /**
+   * {@inheritDoc}
+   */
+  public void setNextReader(IndexReader.AtomicReaderContext context) throws IOException {
+    DocValues docValues = groupBy.getValues(vsContext, context);
+    filler = docValues.getValueFiller();
+    mval = filler.getValue();
+  }
+}
diff --git a/modules/grouping/src/java/org/apache/lucene/search/grouping/function/FunctionFirstPassGroupingCollector.java b/modules/grouping/src/java/org/apache/lucene/search/grouping/function/FunctionFirstPassGroupingCollector.java
new file mode 100644
index 0000000..4ece622
--- /dev/null
+++ b/modules/grouping/src/java/org/apache/lucene/search/grouping/function/FunctionFirstPassGroupingCollector.java
@@ -0,0 +1,88 @@
+package org.apache.lucene.search.grouping.function;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.queries.function.DocValues;
+import org.apache.lucene.queries.function.ValueSource;
+import org.apache.lucene.search.Sort;
+import org.apache.lucene.search.grouping.AbstractFirstPassGroupingCollector;
+import org.apache.lucene.util.mutable.MutableValue;
+
+import java.io.IOException;
+import java.util.Map;
+
+/**
+ * Concrete implementation of {@link AbstractFirstPassGroupingCollector} that groups based on
+ * {@link ValueSource} instances.
+ *
+ * @lucene.experimental
+ */
+public class FunctionFirstPassGroupingCollector extends AbstractFirstPassGroupingCollector<MutableValue> {
+
+  private final ValueSource groupByVS;
+  private final Map vsContext;
+
+  private DocValues docValues;
+  private DocValues.ValueFiller filler;
+  private MutableValue mval;
+
+  /**
+   * Creates a first pass collector.
+   *
+   * @param groupByVS  The {@link ValueSource} instance to group by
+   * @param vsContext  The ValueSource context
+   * @param groupSort  The {@link Sort} used to sort the
+   *                   groups.  The top sorted document within each group
+   *                   according to groupSort, determines how that group
+   *                   sorts against other groups.  This must be non-null,
+   *                   ie, if you want to groupSort by relevance use
+   *                   Sort.RELEVANCE.
+   * @param topNGroups How many top groups to keep.
+   * @throws IOException When I/O related errors occur
+   */
+  public FunctionFirstPassGroupingCollector(ValueSource groupByVS, Map vsContext, Sort groupSort, int topNGroups) throws IOException {
+    super(groupSort, topNGroups);
+    this.groupByVS = groupByVS;
+    this.vsContext = vsContext;
+  }
+
+  @Override
+  protected MutableValue getDocGroupValue(int doc) {
+    filler.fillValue(doc);
+    return mval;
+  }
+
+  @Override
+  protected MutableValue copyDocGroupValue(MutableValue groupValue, MutableValue reuse) {
+    if (reuse != null) {
+      reuse.copy(groupValue);
+      return reuse;
+    }
+    return groupValue.duplicate();
+  }
+
+  @Override
+  public void setNextReader(IndexReader.AtomicReaderContext readerContext) throws IOException {
+    super.setNextReader(readerContext);
+    docValues = groupByVS.getValues(vsContext, readerContext);
+    filler = docValues.getValueFiller();
+    mval = filler.getValue();
+  }
+
+}
diff --git a/modules/grouping/src/java/org/apache/lucene/search/grouping/function/FunctionSecondPassGroupingCollector.java b/modules/grouping/src/java/org/apache/lucene/search/grouping/function/FunctionSecondPassGroupingCollector.java
new file mode 100644
index 0000000..a546470
--- /dev/null
+++ b/modules/grouping/src/java/org/apache/lucene/search/grouping/function/FunctionSecondPassGroupingCollector.java
@@ -0,0 +1,85 @@
+package org.apache.lucene.search.grouping.function;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.queries.function.DocValues;
+import org.apache.lucene.queries.function.ValueSource;
+import org.apache.lucene.search.Sort;
+import org.apache.lucene.search.grouping.AbstractSecondPassGroupingCollector;
+import org.apache.lucene.search.grouping.SearchGroup;
+import org.apache.lucene.util.mutable.MutableValue;
+import org.apache.lucene.search.grouping.TopGroups; //javadoc
+
+import java.io.IOException;
+import java.util.Collection;
+import java.util.Map;
+
+/**
+ * Concrete implementation of {@link AbstractSecondPassGroupingCollector} that groups based on
+ * {@link ValueSource} instances.
+ *
+ * @lucene.experimental
+ */
+public class FunctionSecondPassGroupingCollector extends AbstractSecondPassGroupingCollector<MutableValue> {
+
+  private final ValueSource groupByVS;
+  private final Map vsContext;
+
+  private DocValues.ValueFiller filler;
+  private MutableValue mval;
+
+  /**
+   * Constructs a {@link FunctionSecondPassGroupingCollector} instance.
+   *
+   * @param searchGroups The {@link SearchGroup} instances collected during the first phase.
+   * @param groupSort The group sort
+   * @param withinGroupSort The sort inside a group
+   * @param maxDocsPerGroup The maximum number of documents to collect inside a group
+   * @param getScores Whether to include the scores
+   * @param getMaxScores Whether to include the maximum score
+   * @param fillSortFields Whether to fill the sort values in {@link TopGroups#withinGroupSort}
+   * @param groupByVS The {@link ValueSource} to group by
+   * @param vsContext The value source context
+   * @throws IOException IOException When I/O related errors occur
+   */
+  public FunctionSecondPassGroupingCollector(Collection<SearchGroup<MutableValue>> searchGroups, Sort groupSort, Sort withinGroupSort, int maxDocsPerGroup, boolean getScores, boolean getMaxScores, boolean fillSortFields, ValueSource groupByVS, Map vsContext) throws IOException {
+    super(searchGroups, groupSort, withinGroupSort, maxDocsPerGroup, getScores, getMaxScores, fillSortFields);
+    this.groupByVS = groupByVS;
+    this.vsContext = vsContext;
+  }
+
+  /**
+   * {@inheritDoc}
+   */
+  protected SearchGroupDocs<MutableValue> retrieveGroup(int doc) throws IOException {
+    filler.fillValue(doc);
+    return groupMap.get(mval);
+  }
+
+  /**
+   * {@inheritDoc}
+   */
+  public void setNextReader(IndexReader.AtomicReaderContext readerContext) throws IOException {
+    super.setNextReader(readerContext);
+    DocValues docValues = groupByVS.getValues(vsContext, readerContext);
+    filler = docValues.getValueFiller();
+    mval = filler.getValue();
+  }
+
+}
diff --git a/modules/grouping/src/java/org/apache/lucene/search/grouping/package.html b/modules/grouping/src/java/org/apache/lucene/search/grouping/package.html
index 4d9e4bc..647c2be 100644
--- a/modules/grouping/src/java/org/apache/lucene/search/grouping/package.html
+++ b/modules/grouping/src/java/org/apache/lucene/search/grouping/package.html
@@ -44,9 +44,9 @@ field fall into a single group.</p>
   </ul>
 
 <p>The implementation is two-pass: the first pass ({@link
-  org.apache.lucene.search.grouping.TermFirstPassGroupingCollector})
+  org.apache.lucene.search.grouping.term.TermFirstPassGroupingCollector})
   gathers the top groups, and the second pass ({@link
-  org.apache.lucene.search.grouping.TermSecondPassGroupingCollector})
+  org.apache.lucene.search.grouping.term.TermSecondPassGroupingCollector})
   gathers documents within those groups.  If the search is costly to
   run you may want to use the {@link
   org.apache.lucene.search.CachingCollector} class, which
@@ -179,5 +179,11 @@ fields, <code>FieldCache</code>, etc.).
   FixedBitSet groupHeadsBitSet = c.retrieveGroupHeads(maxDoc)
 </pre>
 
+<p>For each of the above collectors there is also a variant that works with <code>ValueSource</code> instead of
+   of fields. Concretely this means that these variants can work with functions. These variants are slower than
+   there term based counter parts. These implementations are located in the
+   <code>org.apache.lucene.search.grouping.function</code> package.
+</p>
+
 </body>
 </html>
diff --git a/modules/grouping/src/java/org/apache/lucene/search/grouping/term/TermAllGroupHeadsCollector.java b/modules/grouping/src/java/org/apache/lucene/search/grouping/term/TermAllGroupHeadsCollector.java
new file mode 100644
index 0000000..81f26b2
--- /dev/null
+++ b/modules/grouping/src/java/org/apache/lucene/search/grouping/term/TermAllGroupHeadsCollector.java
@@ -0,0 +1,542 @@
+package org.apache.lucene.search.grouping.term;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.search.*;
+import org.apache.lucene.search.grouping.AbstractAllGroupHeadsCollector;
+import org.apache.lucene.search.grouping.SentinelIntSet;
+import org.apache.lucene.util.BytesRef;
+
+import java.io.IOException;
+import java.util.*;
+
+/**
+ * A base implementation of {@link org.apache.lucene.search.grouping.AbstractAllGroupHeadsCollector} for retrieving the most relevant groups when grouping
+ * on a string based group field. More specifically this all concrete implementations of this base implementation
+ * use {@link org.apache.lucene.search.FieldCache.DocTermsIndex}.
+ *
+ * @lucene.experimental
+ */
+public abstract class TermAllGroupHeadsCollector<GH extends AbstractAllGroupHeadsCollector.GroupHead> extends AbstractAllGroupHeadsCollector<GH> {
+
+  private static final int DEFAULT_INITIAL_SIZE = 128;
+
+  final String groupField;
+  final BytesRef scratchBytesRef = new BytesRef();
+
+  FieldCache.DocTermsIndex groupIndex;
+  IndexReader.AtomicReaderContext readerContext;
+
+  protected TermAllGroupHeadsCollector(String groupField, int numberOfSorts) {
+    super(numberOfSorts);
+    this.groupField = groupField;
+  }
+
+  /**
+   * Creates an <code>AbstractAllGroupHeadsCollector</code> instance based on the supplied arguments.
+   * This factory method decides with implementation is best suited.
+   *
+   * Delegates to {@link #create(String, org.apache.lucene.search.Sort, int)} with an initialSize of 128.
+   *
+   * @param groupField      The field to group by
+   * @param sortWithinGroup The sort within each group
+   * @return an <code>AbstractAllGroupHeadsCollector</code> instance based on the supplied arguments
+   * @throws IOException If I/O related errors occur
+   */
+  public static AbstractAllGroupHeadsCollector create(String groupField, Sort sortWithinGroup) throws IOException {
+    return create(groupField, sortWithinGroup, DEFAULT_INITIAL_SIZE);
+  }
+
+  /**
+   * Creates an <code>AbstractAllGroupHeadsCollector</code> instance based on the supplied arguments.
+   * This factory method decides with implementation is best suited.
+   *
+   * @param groupField      The field to group by
+   * @param sortWithinGroup The sort within each group
+   * @param initialSize The initial allocation size of the internal int set and group list which should roughly match
+   *                    the total number of expected unique groups. Be aware that the heap usage is
+   *                    4 bytes * initialSize.
+   * @return an <code>AbstractAllGroupHeadsCollector</code> instance based on the supplied arguments
+   * @throws IOException If I/O related errors occur
+   */
+  public static AbstractAllGroupHeadsCollector create(String groupField, Sort sortWithinGroup, int initialSize) throws IOException {
+    boolean sortAllScore = true;
+    boolean sortAllFieldValue = true;
+
+    for (SortField sortField : sortWithinGroup.getSort()) {
+      if (sortField.getType() == SortField.Type.SCORE) {
+        sortAllFieldValue = false;
+      } else if (needGeneralImpl(sortField)) {
+        return new GeneralAllGroupHeadsCollector(groupField, sortWithinGroup);
+      } else {
+        sortAllScore = false;
+      }
+    }
+
+    if (sortAllScore) {
+      return new ScoreAllGroupHeadsCollector(groupField, sortWithinGroup, initialSize);
+    } else if (sortAllFieldValue) {
+      return new OrdAllGroupHeadsCollector(groupField, sortWithinGroup, initialSize);
+    } else {
+      return new OrdScoreAllGroupHeadsCollector(groupField, sortWithinGroup, initialSize);
+    }
+  }
+
+  // Returns when a sort field needs the general impl.
+  private static boolean needGeneralImpl(SortField sortField) {
+    SortField.Type sortType = sortField.getType();
+    // Note (MvG): We can also make an optimized impl when sorting is SortField.DOC
+    return sortType != SortField.Type.STRING_VAL && sortType != SortField.Type.STRING && sortType != SortField.Type.SCORE;
+  }
+
+  // A general impl that works for any group sort.
+  static class GeneralAllGroupHeadsCollector extends TermAllGroupHeadsCollector<GeneralAllGroupHeadsCollector.GroupHead> {
+
+    private final Sort sortWithinGroup;
+    private final Map<BytesRef, GroupHead> groups;
+
+    private Scorer scorer;
+
+    GeneralAllGroupHeadsCollector(String groupField, Sort sortWithinGroup) throws IOException {
+      super(groupField, sortWithinGroup.getSort().length);
+      this.sortWithinGroup = sortWithinGroup;
+      groups = new HashMap<BytesRef, GroupHead>();
+
+      final SortField[] sortFields = sortWithinGroup.getSort();
+      for (int i = 0; i < sortFields.length; i++) {
+        reversed[i] = sortFields[i].getReverse() ? -1 : 1;
+      }
+    }
+
+    protected void retrieveGroupHeadAndAddIfNotExist(int doc) throws IOException {
+      final int ord = groupIndex.getOrd(doc);
+      final BytesRef groupValue = ord == 0 ? null : groupIndex.lookup(ord, scratchBytesRef);
+      GroupHead groupHead = groups.get(groupValue);
+      if (groupHead == null) {
+        groupHead = new GroupHead(groupValue, sortWithinGroup, doc);
+        groups.put(groupValue == null ? null : new BytesRef(groupValue), groupHead);
+        temporalResult.stop = true;
+      } else {
+        temporalResult.stop = false;
+      }
+      temporalResult.groupHead = groupHead;
+    }
+
+    protected Collection<GroupHead> getCollectedGroupHeads() {
+      return groups.values();
+    }
+
+    public void setNextReader(IndexReader.AtomicReaderContext context) throws IOException {
+      this.readerContext = context;
+      groupIndex = FieldCache.DEFAULT.getTermsIndex(context.reader, groupField);
+
+      for (GroupHead groupHead : groups.values()) {
+        for (int i = 0; i < groupHead.comparators.length; i++) {
+          groupHead.comparators[i] = groupHead.comparators[i].setNextReader(context);
+        }
+      }
+    }
+
+    public void setScorer(Scorer scorer) throws IOException {
+      this.scorer = scorer;
+      for (GroupHead groupHead : groups.values()) {
+        for (FieldComparator comparator : groupHead.comparators) {
+          comparator.setScorer(scorer);
+        }
+      }
+    }
+
+    class GroupHead extends AbstractAllGroupHeadsCollector.GroupHead<BytesRef> {
+
+      final FieldComparator[] comparators;
+
+      private GroupHead(BytesRef groupValue, Sort sort, int doc) throws IOException {
+        super(groupValue, doc + readerContext.docBase);
+        final SortField[] sortFields = sort.getSort();
+        comparators = new FieldComparator[sortFields.length];
+        for (int i = 0; i < sortFields.length; i++) {
+          comparators[i] = sortFields[i].getComparator(1, i).setNextReader(readerContext);
+          comparators[i].setScorer(scorer);
+          comparators[i].copy(0, doc);
+          comparators[i].setBottom(0);
+        }
+      }
+
+      public int compare(int compIDX, int doc) throws IOException {
+        return comparators[compIDX].compareBottom(doc);
+      }
+
+      public void updateDocHead(int doc) throws IOException {
+        for (FieldComparator comparator : comparators) {
+          comparator.copy(0, doc);
+          comparator.setBottom(0);
+        }
+        this.doc = doc + readerContext.docBase;
+      }
+    }
+  }
+
+
+  // AbstractAllGroupHeadsCollector optimized for ord fields and scores.
+  static class OrdScoreAllGroupHeadsCollector extends TermAllGroupHeadsCollector<OrdScoreAllGroupHeadsCollector.GroupHead> {
+
+    private final SentinelIntSet ordSet;
+    private final List<GroupHead> collectedGroups;
+    private final SortField[] fields;
+
+    private FieldCache.DocTermsIndex[] sortsIndex;
+    private Scorer scorer;
+    private GroupHead[] segmentGroupHeads;
+
+    OrdScoreAllGroupHeadsCollector(String groupField, Sort sortWithinGroup, int initialSize) {
+      super(groupField, sortWithinGroup.getSort().length);
+      ordSet = new SentinelIntSet(initialSize, -1);
+      collectedGroups = new ArrayList<GroupHead>(initialSize);
+
+      final SortField[] sortFields = sortWithinGroup.getSort();
+      fields = new SortField[sortFields.length];
+      sortsIndex = new FieldCache.DocTermsIndex[sortFields.length];
+      for (int i = 0; i < sortFields.length; i++) {
+        reversed[i] = sortFields[i].getReverse() ? -1 : 1;
+        fields[i] = sortFields[i];
+      }
+    }
+
+    protected Collection<GroupHead> getCollectedGroupHeads() {
+      return collectedGroups;
+    }
+
+    public void setScorer(Scorer scorer) throws IOException {
+      this.scorer = scorer;
+    }
+
+    protected void retrieveGroupHeadAndAddIfNotExist(int doc) throws IOException {
+      int key = groupIndex.getOrd(doc);
+      GroupHead groupHead;
+      if (!ordSet.exists(key)) {
+        ordSet.put(key);
+        BytesRef term = key == 0 ? null : groupIndex.getTerm(doc, new BytesRef());
+        groupHead = new GroupHead(doc, term);
+        collectedGroups.add(groupHead);
+        segmentGroupHeads[key] = groupHead;
+        temporalResult.stop = true;
+      } else {
+        temporalResult.stop = false;
+        groupHead = segmentGroupHeads[key];
+      }
+      temporalResult.groupHead = groupHead;
+    }
+
+    public void setNextReader(IndexReader.AtomicReaderContext context) throws IOException {
+      this.readerContext = context;
+      groupIndex = FieldCache.DEFAULT.getTermsIndex(context.reader, groupField);
+      for (int i = 0; i < fields.length; i++) {
+        if (fields[i].getType() == SortField.Type.SCORE) {
+          continue;
+        }
+
+        sortsIndex[i] = FieldCache.DEFAULT.getTermsIndex(context.reader, fields[i].getField());
+      }
+
+      // Clear ordSet and fill it with previous encountered groups that can occur in the current segment.
+      ordSet.clear();
+      segmentGroupHeads = new GroupHead[groupIndex.numOrd()];
+      for (GroupHead collectedGroup : collectedGroups) {
+        int ord = groupIndex.binarySearchLookup(collectedGroup.groupValue, scratchBytesRef);
+        if (ord >= 0) {
+          ordSet.put(ord);
+          segmentGroupHeads[ord] = collectedGroup;
+
+          for (int i = 0; i < sortsIndex.length; i++) {
+            if (fields[i].getType() == SortField.Type.SCORE) {
+              continue;
+            }
+
+            collectedGroup.sortOrds[i] = sortsIndex[i].binarySearchLookup(collectedGroup.sortValues[i], scratchBytesRef);
+          }
+        }
+      }
+    }
+
+    class GroupHead extends AbstractAllGroupHeadsCollector.GroupHead<BytesRef> {
+
+      BytesRef[] sortValues;
+      int[] sortOrds;
+      float[] scores;
+
+      private GroupHead(int doc, BytesRef groupValue) throws IOException {
+        super(groupValue, doc + readerContext.docBase);
+        sortValues = new BytesRef[sortsIndex.length];
+        sortOrds = new int[sortsIndex.length];
+        scores = new float[sortsIndex.length];
+        for (int i = 0; i < sortsIndex.length; i++) {
+          if (fields[i].getType() == SortField.Type.SCORE) {
+            scores[i] = scorer.score();
+          } else {
+            sortValues[i] = sortsIndex[i].getTerm(doc, new BytesRef());
+            sortOrds[i] = sortsIndex[i].getOrd(doc);
+          }
+        }
+
+      }
+
+      public int compare(int compIDX, int doc) throws IOException {
+        if (fields[compIDX].getType() == SortField.Type.SCORE) {
+          float score = scorer.score();
+          if (scores[compIDX] < score) {
+            return 1;
+          } else if (scores[compIDX] > score) {
+            return -1;
+          }
+          return 0;
+        } else {
+          if (sortOrds[compIDX] < 0) {
+            // The current segment doesn't contain the sort value we encountered before. Therefore the ord is negative.
+            return sortValues[compIDX].compareTo(sortsIndex[compIDX].getTerm(doc, scratchBytesRef));
+          } else {
+            return sortOrds[compIDX] - sortsIndex[compIDX].getOrd(doc);
+          }
+        }
+      }
+
+      public void updateDocHead(int doc) throws IOException {
+        for (int i = 0; i < sortsIndex.length; i++) {
+          if (fields[i].getType() == SortField.Type.SCORE) {
+            scores[i] = scorer.score();
+          } else {
+            sortValues[i] = sortsIndex[i].getTerm(doc, sortValues[i]);
+            sortOrds[i] = sortsIndex[i].getOrd(doc);
+          }
+        }
+        this.doc = doc + readerContext.docBase;
+      }
+
+    }
+
+  }
+
+
+  // AbstractAllGroupHeadsCollector optimized for ord fields.
+  static class OrdAllGroupHeadsCollector extends TermAllGroupHeadsCollector<OrdAllGroupHeadsCollector.GroupHead> {
+
+    private final SentinelIntSet ordSet;
+    private final List<GroupHead> collectedGroups;
+    private final SortField[] fields;
+
+    private FieldCache.DocTermsIndex[] sortsIndex;
+    private GroupHead[] segmentGroupHeads;
+
+    OrdAllGroupHeadsCollector(String groupField, Sort sortWithinGroup, int initialSize) {
+      super(groupField, sortWithinGroup.getSort().length);
+      ordSet = new SentinelIntSet(initialSize, -1);
+      collectedGroups = new ArrayList<GroupHead>(initialSize);
+
+      final SortField[] sortFields = sortWithinGroup.getSort();
+      fields = new SortField[sortFields.length];
+      sortsIndex = new FieldCache.DocTermsIndex[sortFields.length];
+      for (int i = 0; i < sortFields.length; i++) {
+        reversed[i] = sortFields[i].getReverse() ? -1 : 1;
+        fields[i] = sortFields[i];
+      }
+    }
+
+    protected Collection<GroupHead> getCollectedGroupHeads() {
+      return collectedGroups;
+    }
+
+    public void setScorer(Scorer scorer) throws IOException {
+    }
+
+    protected void retrieveGroupHeadAndAddIfNotExist(int doc) throws IOException {
+      int key = groupIndex.getOrd(doc);
+      GroupHead groupHead;
+      if (!ordSet.exists(key)) {
+        ordSet.put(key);
+        BytesRef term = key == 0 ? null : groupIndex.getTerm(doc, new BytesRef());
+        groupHead = new GroupHead(doc, term);
+        collectedGroups.add(groupHead);
+        segmentGroupHeads[key] = groupHead;
+        temporalResult.stop = true;
+      } else {
+        temporalResult.stop = false;
+        groupHead = segmentGroupHeads[key];
+      }
+      temporalResult.groupHead = groupHead;
+    }
+
+    public void setNextReader(IndexReader.AtomicReaderContext context) throws IOException {
+      this.readerContext = context;
+      groupIndex = FieldCache.DEFAULT.getTermsIndex(context.reader, groupField);
+      for (int i = 0; i < fields.length; i++) {
+        sortsIndex[i] = FieldCache.DEFAULT.getTermsIndex(context.reader, fields[i].getField());
+      }
+
+      // Clear ordSet and fill it with previous encountered groups that can occur in the current segment.
+      ordSet.clear();
+      segmentGroupHeads = new GroupHead[groupIndex.numOrd()];
+      for (GroupHead collectedGroup : collectedGroups) {
+        int groupOrd = groupIndex.binarySearchLookup(collectedGroup.groupValue, scratchBytesRef);
+        if (groupOrd >= 0) {
+          ordSet.put(groupOrd);
+          segmentGroupHeads[groupOrd] = collectedGroup;
+
+          for (int i = 0; i < sortsIndex.length; i++) {
+            collectedGroup.sortOrds[i] = sortsIndex[i].binarySearchLookup(collectedGroup.sortValues[i], scratchBytesRef);
+          }
+        }
+      }
+    }
+
+    class GroupHead extends AbstractAllGroupHeadsCollector.GroupHead<BytesRef> {
+
+      BytesRef[] sortValues;
+      int[] sortOrds;
+
+      private GroupHead(int doc, BytesRef groupValue) throws IOException {
+        super(groupValue, doc + readerContext.docBase);
+        sortValues = new BytesRef[sortsIndex.length];
+        sortOrds = new int[sortsIndex.length];
+        for (int i = 0; i < sortsIndex.length; i++) {
+          sortValues[i] = sortsIndex[i].getTerm(doc, new BytesRef());
+          sortOrds[i] = sortsIndex[i].getOrd(doc);
+        }
+      }
+
+      public int compare(int compIDX, int doc) throws IOException {
+        if (sortOrds[compIDX] < 0) {
+          // The current segment doesn't contain the sort value we encountered before. Therefore the ord is negative.
+          return sortValues[compIDX].compareTo(sortsIndex[compIDX].getTerm(doc, scratchBytesRef));
+        } else {
+          return sortOrds[compIDX] - sortsIndex[compIDX].getOrd(doc);
+        }
+      }
+
+      public void updateDocHead(int doc) throws IOException {
+        for (int i = 0; i < sortsIndex.length; i++) {
+          sortValues[i] = sortsIndex[i].getTerm(doc, sortValues[i]);
+          sortOrds[i] = sortsIndex[i].getOrd(doc);
+        }
+        this.doc = doc + readerContext.docBase;
+      }
+
+    }
+
+  }
+
+
+  // AbstractAllGroupHeadsCollector optimized for scores.
+  static class ScoreAllGroupHeadsCollector extends TermAllGroupHeadsCollector<ScoreAllGroupHeadsCollector.GroupHead> {
+
+    private final SentinelIntSet ordSet;
+    private final List<GroupHead> collectedGroups;
+    private final SortField[] fields;
+
+    private Scorer scorer;
+    private GroupHead[] segmentGroupHeads;
+
+    ScoreAllGroupHeadsCollector(String groupField, Sort sortWithinGroup, int initialSize) {
+      super(groupField, sortWithinGroup.getSort().length);
+      ordSet = new SentinelIntSet(initialSize, -1);
+      collectedGroups = new ArrayList<GroupHead>(initialSize);
+
+      final SortField[] sortFields = sortWithinGroup.getSort();
+      fields = new SortField[sortFields.length];
+      for (int i = 0; i < sortFields.length; i++) {
+        reversed[i] = sortFields[i].getReverse() ? -1 : 1;
+        fields[i] = sortFields[i];
+      }
+    }
+
+    protected Collection<GroupHead> getCollectedGroupHeads() {
+      return collectedGroups;
+    }
+
+    public void setScorer(Scorer scorer) throws IOException {
+      this.scorer = scorer;
+    }
+
+    protected void retrieveGroupHeadAndAddIfNotExist(int doc) throws IOException {
+      int key = groupIndex.getOrd(doc);
+      GroupHead groupHead;
+      if (!ordSet.exists(key)) {
+        ordSet.put(key);
+        BytesRef term = key == 0 ? null : groupIndex.getTerm(doc, new BytesRef());
+        groupHead = new GroupHead(doc, term);
+        collectedGroups.add(groupHead);
+        segmentGroupHeads[key] = groupHead;
+        temporalResult.stop = true;
+      } else {
+        temporalResult.stop = false;
+        groupHead = segmentGroupHeads[key];
+      }
+      temporalResult.groupHead = groupHead;
+    }
+
+    public void setNextReader(IndexReader.AtomicReaderContext context) throws IOException {
+      this.readerContext = context;
+      groupIndex = FieldCache.DEFAULT.getTermsIndex(context.reader, groupField);
+
+      // Clear ordSet and fill it with previous encountered groups that can occur in the current segment.
+      ordSet.clear();
+      segmentGroupHeads = new GroupHead[groupIndex.numOrd()];
+      for (GroupHead collectedGroup : collectedGroups) {
+        int ord = groupIndex.binarySearchLookup(collectedGroup.groupValue, scratchBytesRef);
+        if (ord >= 0) {
+          ordSet.put(ord);
+          segmentGroupHeads[ord] = collectedGroup;
+        }
+      }
+    }
+
+    class GroupHead extends AbstractAllGroupHeadsCollector.GroupHead<BytesRef> {
+
+      float[] scores;
+
+      private GroupHead(int doc, BytesRef groupValue) throws IOException {
+        super(groupValue, doc + readerContext.docBase);
+        scores = new float[fields.length];
+        float score = scorer.score();
+        for (int i = 0; i < scores.length; i++) {
+          scores[i] = score;
+        }
+      }
+
+      public int compare(int compIDX, int doc) throws IOException {
+        float score = scorer.score();
+        if (scores[compIDX] < score) {
+          return 1;
+        } else if (scores[compIDX] > score) {
+          return -1;
+        }
+        return 0;
+      }
+
+      public void updateDocHead(int doc) throws IOException {
+        float score = scorer.score();
+        for (int i = 0; i < scores.length; i++) {
+          scores[i] = score;
+        }
+        this.doc = doc + readerContext.docBase;
+      }
+
+    }
+
+  }
+
+}
diff --git a/modules/grouping/src/java/org/apache/lucene/search/grouping/term/TermAllGroupsCollector.java b/modules/grouping/src/java/org/apache/lucene/search/grouping/term/TermAllGroupsCollector.java
new file mode 100644
index 0000000..e22ad78
--- /dev/null
+++ b/modules/grouping/src/java/org/apache/lucene/search/grouping/term/TermAllGroupsCollector.java
@@ -0,0 +1,113 @@
+package org.apache.lucene.search.grouping.term;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.search.FieldCache;
+import org.apache.lucene.search.grouping.AbstractAllGroupsCollector;
+import org.apache.lucene.search.grouping.SentinelIntSet;
+import org.apache.lucene.util.BytesRef;
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.List;
+
+/**
+ * A collector that collects all groups that match the
+ * query. Only the group value is collected, and the order
+ * is undefined.  This collector does not determine
+ * the most relevant document of a group.
+ *
+ * <p/>
+ * Implementation detail: an int hash set (SentinelIntSet)
+ * is used to detect if a group is already added to the
+ * total count.  For each segment the int set is cleared and filled
+ * with previous counted groups that occur in the new
+ * segment.
+ *
+ * @lucene.experimental
+ */
+public class TermAllGroupsCollector extends AbstractAllGroupsCollector<BytesRef> {
+
+  private static final int DEFAULT_INITIAL_SIZE = 128;
+
+  private final String groupField;
+  private final SentinelIntSet ordSet;
+  private final List<BytesRef> groups;
+
+  private FieldCache.DocTermsIndex index;
+  private final BytesRef spareBytesRef = new BytesRef();
+
+  /**
+   * Expert: Constructs a {@link AbstractAllGroupsCollector}
+   *
+   * @param groupField  The field to group by
+   * @param initialSize The initial allocation size of the
+   *                    internal int set and group list
+   *                    which should roughly match the total
+   *                    number of expected unique groups. Be aware that the
+   *                    heap usage is 4 bytes * initialSize.
+   */
+  public TermAllGroupsCollector(String groupField, int initialSize) {
+    ordSet = new SentinelIntSet(initialSize, -1);
+    groups = new ArrayList<BytesRef>(initialSize);
+    this.groupField = groupField;
+  }
+
+  /**
+   * Constructs a {@link AbstractAllGroupsCollector}. This sets the
+   * initial allocation size for the internal int set and group
+   * list to 128.
+   *
+   * @param groupField The field to group by
+   */
+  public TermAllGroupsCollector(String groupField) {
+    this(groupField, DEFAULT_INITIAL_SIZE);
+  }
+
+  public void collect(int doc) throws IOException {
+    int key = index.getOrd(doc);
+    if (!ordSet.exists(key)) {
+      ordSet.put(key);
+      BytesRef term = key == 0 ? null : index.lookup(key, new BytesRef());
+      groups.add(term);
+    }
+  }
+
+  /**
+   * {@inheritDoc}
+   */
+  public Collection<BytesRef> getGroups() {
+    return groups;
+  }
+
+  public void setNextReader(IndexReader.AtomicReaderContext context) throws IOException {
+    index = FieldCache.DEFAULT.getTermsIndex(context.reader, groupField);
+
+    // Clear ordSet and fill it with previous encountered groups that can occur in the current segment.
+    ordSet.clear();
+    for (BytesRef countedGroup : groups) {
+      int ord = index.binarySearchLookup(countedGroup, spareBytesRef);
+      if (ord >= 0) {
+        ordSet.put(ord);
+      }
+    }
+  }
+
+}
diff --git a/modules/grouping/src/java/org/apache/lucene/search/grouping/term/TermFirstPassGroupingCollector.java b/modules/grouping/src/java/org/apache/lucene/search/grouping/term/TermFirstPassGroupingCollector.java
new file mode 100644
index 0000000..5fce689
--- /dev/null
+++ b/modules/grouping/src/java/org/apache/lucene/search/grouping/term/TermFirstPassGroupingCollector.java
@@ -0,0 +1,86 @@
+package org.apache.lucene.search.grouping.term;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.index.IndexReader.AtomicReaderContext;
+import org.apache.lucene.search.FieldCache;
+import org.apache.lucene.search.Sort;
+import org.apache.lucene.search.grouping.AbstractFirstPassGroupingCollector;
+import org.apache.lucene.util.BytesRef;
+
+import java.io.IOException;
+
+/**
+ * Concrete implementation of {@link org.apache.lucene.search.grouping.AbstractFirstPassGroupingCollector} that groups based on
+ * field values and more specifically uses {@link org.apache.lucene.search.FieldCache.DocTermsIndex}
+ * to collect groups.
+ *
+ * @lucene.experimental
+ */
+public class TermFirstPassGroupingCollector extends AbstractFirstPassGroupingCollector<BytesRef> {
+
+  private final BytesRef scratchBytesRef = new BytesRef();
+  private FieldCache.DocTermsIndex index;
+
+  private String groupField;
+
+  /**
+   * Create the first pass collector.
+   *
+   *  @param groupField The field used to group
+   *    documents. This field must be single-valued and
+   *    indexed (FieldCache is used to access its value
+   *    per-document).
+   *  @param groupSort The {@link Sort} used to sort the
+   *    groups.  The top sorted document within each group
+   *    according to groupSort, determines how that group
+   *    sorts against other groups.  This must be non-null,
+   *    ie, if you want to groupSort by relevance use
+   *    Sort.RELEVANCE.
+   *  @param topNGroups How many top groups to keep.
+   *  @throws IOException When I/O related errors occur
+   */
+  public TermFirstPassGroupingCollector(String groupField, Sort groupSort, int topNGroups) throws IOException {
+    super(groupSort, topNGroups);
+    this.groupField = groupField;
+  }
+
+  @Override
+  protected BytesRef getDocGroupValue(int doc) {
+    final int ord = index.getOrd(doc);
+    return ord == 0 ? null : index.lookup(ord, scratchBytesRef);
+  }
+
+  @Override
+  protected BytesRef copyDocGroupValue(BytesRef groupValue, BytesRef reuse) {
+    if (groupValue == null) {
+      return null;
+    } else if (reuse != null) {
+      reuse.copy(groupValue);
+      return reuse;
+    } else {
+      return new BytesRef(groupValue);
+    }
+  }
+
+  @Override
+  public void setNextReader(AtomicReaderContext readerContext) throws IOException {
+    super.setNextReader(readerContext);
+    index = FieldCache.DEFAULT.getTermsIndex(readerContext.reader, groupField);
+  }
+}
diff --git a/modules/grouping/src/java/org/apache/lucene/search/grouping/term/TermSecondPassGroupingCollector.java b/modules/grouping/src/java/org/apache/lucene/search/grouping/term/TermSecondPassGroupingCollector.java
new file mode 100644
index 0000000..d03e016
--- /dev/null
+++ b/modules/grouping/src/java/org/apache/lucene/search/grouping/term/TermSecondPassGroupingCollector.java
@@ -0,0 +1,79 @@
+package org.apache.lucene.search.grouping.term;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.index.IndexReader.AtomicReaderContext;
+import org.apache.lucene.search.FieldCache;
+import org.apache.lucene.search.Sort;
+import org.apache.lucene.search.grouping.AbstractSecondPassGroupingCollector;
+import org.apache.lucene.search.grouping.SearchGroup;
+import org.apache.lucene.search.grouping.SentinelIntSet;
+import org.apache.lucene.util.BytesRef;
+
+import java.io.IOException;
+import java.util.Collection;
+
+/**
+ * Concrete implementation of {@link org.apache.lucene.search.grouping.AbstractSecondPassGroupingCollector} that groups based on
+ * field values and more specifically uses {@link org.apache.lucene.search.FieldCache.DocTermsIndex}
+ * to collect grouped docs.
+ *
+ * @lucene.experimental
+ */
+public class TermSecondPassGroupingCollector extends AbstractSecondPassGroupingCollector<BytesRef> {
+
+  private final SentinelIntSet ordSet;
+  private FieldCache.DocTermsIndex index;
+  private final BytesRef spareBytesRef = new BytesRef();
+  private final String groupField;
+
+  @SuppressWarnings("unchecked")
+  public TermSecondPassGroupingCollector(String groupField, Collection<SearchGroup<BytesRef>> groups, Sort groupSort, Sort withinGroupSort,
+                                         int maxDocsPerGroup, boolean getScores, boolean getMaxScores, boolean fillSortFields)
+      throws IOException {
+    super(groups, groupSort, withinGroupSort, maxDocsPerGroup, getScores, getMaxScores, fillSortFields);
+    ordSet = new SentinelIntSet(groupMap.size(), -1);
+    this.groupField = groupField;
+    groupDocs = (SearchGroupDocs<BytesRef>[]) new SearchGroupDocs[ordSet.keys.length];
+  }
+
+  @Override
+  public void setNextReader(AtomicReaderContext readerContext) throws IOException {
+    super.setNextReader(readerContext);
+    index = FieldCache.DEFAULT.getTermsIndex(readerContext.reader, groupField);
+
+    // Rebuild ordSet
+    ordSet.clear();
+    for (SearchGroupDocs<BytesRef> group : groupMap.values()) {
+//      System.out.println("  group=" + (group.groupValue == null ? "null" : group.groupValue.utf8ToString()));
+      int ord = group.groupValue == null ? 0 : index.binarySearchLookup(group.groupValue, spareBytesRef);
+      if (ord >= 0) {
+        groupDocs[ordSet.put(ord)] = group;
+      }
+    }
+  }
+
+  @Override
+  protected SearchGroupDocs<BytesRef> retrieveGroup(int doc) throws IOException {
+    int slot = ordSet.find(index.getOrd(doc));
+    if (slot >= 0) {
+      return groupDocs[slot];
+    }
+    return null;
+  }
+}
diff --git a/modules/grouping/src/test/org/apache/lucene/search/grouping/AllGroupHeadsCollectorTest.java b/modules/grouping/src/test/org/apache/lucene/search/grouping/AllGroupHeadsCollectorTest.java
new file mode 100644
index 0000000..a16e9db
--- /dev/null
+++ b/modules/grouping/src/test/org/apache/lucene/search/grouping/AllGroupHeadsCollectorTest.java
@@ -0,0 +1,508 @@
+package org.apache.lucene.search.grouping;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.MockAnalyzer;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.document.NumericField;
+import org.apache.lucene.document.StringField;
+import org.apache.lucene.document.TextField;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.queries.function.ValueSource;
+import org.apache.lucene.queries.function.valuesource.BytesRefFieldSource;
+import org.apache.lucene.search.*;
+import org.apache.lucene.search.grouping.function.FunctionAllGroupHeadsCollector;
+import org.apache.lucene.search.grouping.term.TermAllGroupHeadsCollector;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.FixedBitSet;
+import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util._TestUtil;
+
+import java.io.IOException;
+import java.util.*;
+
+public class AllGroupHeadsCollectorTest extends LuceneTestCase {
+
+  public void testBasic() throws Exception {
+    final String groupField = "author";
+    Directory dir = newDirectory();
+    RandomIndexWriter w = new RandomIndexWriter(
+        random,
+        dir,
+        newIndexWriterConfig(TEST_VERSION_CURRENT,
+            new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));
+
+    // 0
+    Document doc = new Document();
+    doc.add(newField(groupField, "author1", TextField.TYPE_STORED));
+    doc.add(newField("content", "random text", TextField.TYPE_STORED));
+    doc.add(newField("id", "1", StringField.TYPE_STORED));
+    w.addDocument(doc);
+
+    // 1
+    doc = new Document();
+    doc.add(newField(groupField, "author1", TextField.TYPE_STORED));
+    doc.add(newField("content", "some more random text blob", TextField.TYPE_STORED));
+    doc.add(newField("id", "2", StringField.TYPE_STORED));
+    w.addDocument(doc);
+
+    // 2
+    doc = new Document();
+    doc.add(newField(groupField, "author1", TextField.TYPE_STORED));
+    doc.add(newField("content", "some more random textual data", TextField.TYPE_STORED));
+    doc.add(newField("id", "3", StringField.TYPE_STORED));
+    w.addDocument(doc);
+    w.commit(); // To ensure a second segment
+
+    // 3
+    doc = new Document();
+    doc.add(newField(groupField, "author2", TextField.TYPE_STORED));
+    doc.add(newField("content", "some random text", TextField.TYPE_STORED));
+    doc.add(newField("id", "4", StringField.TYPE_STORED));
+    w.addDocument(doc);
+
+    // 4
+    doc = new Document();
+    doc.add(newField(groupField, "author3", TextField.TYPE_STORED));
+    doc.add(newField("content", "some more random text", TextField.TYPE_STORED));
+    doc.add(newField("id", "5", StringField.TYPE_STORED));
+    w.addDocument(doc);
+
+    // 5
+    doc = new Document();
+    doc.add(newField(groupField, "author3", TextField.TYPE_STORED));
+    doc.add(newField("content", "random blob", TextField.TYPE_STORED));
+    doc.add(newField("id", "6", StringField.TYPE_STORED));
+    w.addDocument(doc);
+
+    // 6 -- no author field
+    doc = new Document();
+    doc.add(newField("content", "random word stuck in alot of other text", TextField.TYPE_STORED));
+    doc.add(newField("id", "6", StringField.TYPE_STORED));
+    w.addDocument(doc);
+
+    // 7 -- no author field
+    doc = new Document();
+    doc.add(newField("content", "random word stuck in alot of other text", TextField.TYPE_STORED));
+    doc.add(newField("id", "7", StringField.TYPE_STORED));
+    w.addDocument(doc);
+
+    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());
+    w.close();
+    int maxDoc = indexSearcher.maxDoc();
+
+    Sort sortWithinGroup = new Sort(new SortField("id", SortField.Type.INT, true));
+    AbstractAllGroupHeadsCollector c1 = createRandomCollector(groupField, sortWithinGroup);
+    indexSearcher.search(new TermQuery(new Term("content", "random")), c1);
+    assertTrue(arrayContains(new int[]{2, 3, 5, 7}, c1.retrieveGroupHeads()));
+    assertTrue(openBitSetContains(new int[]{2, 3, 5, 7}, c1.retrieveGroupHeads(maxDoc), maxDoc));
+
+    AbstractAllGroupHeadsCollector c2 = createRandomCollector(groupField, sortWithinGroup);
+    indexSearcher.search(new TermQuery(new Term("content", "some")), c2);
+    assertTrue(arrayContains(new int[]{2, 3, 4}, c2.retrieveGroupHeads()));
+    assertTrue(openBitSetContains(new int[]{2, 3, 4}, c2.retrieveGroupHeads(maxDoc), maxDoc));
+
+    AbstractAllGroupHeadsCollector c3 = createRandomCollector(groupField, sortWithinGroup);
+    indexSearcher.search(new TermQuery(new Term("content", "blob")), c3);
+    assertTrue(arrayContains(new int[]{1, 5}, c3.retrieveGroupHeads()));
+    assertTrue(openBitSetContains(new int[]{1, 5}, c3.retrieveGroupHeads(maxDoc), maxDoc));
+
+    // STRING sort type triggers different implementation
+    Sort sortWithinGroup2 = new Sort(new SortField("id", SortField.Type.STRING, true));
+    AbstractAllGroupHeadsCollector c4 = createRandomCollector(groupField, sortWithinGroup2);
+    indexSearcher.search(new TermQuery(new Term("content", "random")), c4);
+    assertTrue(arrayContains(new int[]{2, 3, 5, 7}, c4.retrieveGroupHeads()));
+    assertTrue(openBitSetContains(new int[]{2, 3, 5, 7}, c4.retrieveGroupHeads(maxDoc), maxDoc));
+
+    Sort sortWithinGroup3 = new Sort(new SortField("id", SortField.Type.STRING, false));
+    AbstractAllGroupHeadsCollector c5 = createRandomCollector(groupField, sortWithinGroup3);
+    indexSearcher.search(new TermQuery(new Term("content", "random")), c5);
+    // 7 b/c higher doc id wins, even if order of field is in not in reverse.
+    assertTrue(arrayContains(new int[]{0, 3, 4, 6}, c5.retrieveGroupHeads()));
+    assertTrue(openBitSetContains(new int[]{0, 3, 4, 6}, c5.retrieveGroupHeads(maxDoc), maxDoc));
+
+    indexSearcher.getIndexReader().close();
+    dir.close();
+  }
+
+  public void testRandom() throws Exception {
+    int numberOfRuns = _TestUtil.nextInt(random, 3, 6);
+    for (int iter = 0; iter < numberOfRuns; iter++) {
+      if (VERBOSE) {
+        System.out.println(String.format("TEST: iter=%d total=%d", iter, numberOfRuns));
+      }
+
+      final int numDocs = _TestUtil.nextInt(random, 100, 1000) * RANDOM_MULTIPLIER;
+      final int numGroups = _TestUtil.nextInt(random, 1, numDocs);
+
+      if (VERBOSE) {
+        System.out.println("TEST: numDocs=" + numDocs + " numGroups=" + numGroups);
+      }
+
+      final List<BytesRef> groups = new ArrayList<BytesRef>();
+      for (int i = 0; i < numGroups; i++) {
+        groups.add(new BytesRef(_TestUtil.randomRealisticUnicodeString(random)));
+      }
+      final String[] contentStrings = new String[_TestUtil.nextInt(random, 2, 20)];
+      if (VERBOSE) {
+        System.out.println("TEST: create fake content");
+      }
+      for (int contentIDX = 0; contentIDX < contentStrings.length; contentIDX++) {
+        final StringBuilder sb = new StringBuilder();
+        sb.append("real").append(random.nextInt(3)).append(' ');
+        final int fakeCount = random.nextInt(10);
+        for (int fakeIDX = 0; fakeIDX < fakeCount; fakeIDX++) {
+          sb.append("fake ");
+        }
+        contentStrings[contentIDX] = sb.toString();
+        if (VERBOSE) {
+          System.out.println("  content=" + sb.toString());
+        }
+      }
+
+      Directory dir = newDirectory();
+      RandomIndexWriter w = new RandomIndexWriter(
+          random,
+          dir,
+          newIndexWriterConfig(TEST_VERSION_CURRENT,
+              new MockAnalyzer(random)));
+
+      Document doc = new Document();
+      Document docNoGroup = new Document();
+      Field group = newField("group", "", StringField.TYPE_UNSTORED);
+      doc.add(group);
+      Field sort1 = newField("sort1", "", StringField.TYPE_UNSTORED);
+      doc.add(sort1);
+      docNoGroup.add(sort1);
+      Field sort2 = newField("sort2", "", StringField.TYPE_UNSTORED);
+      doc.add(sort2);
+      docNoGroup.add(sort2);
+      Field sort3 = newField("sort3", "", StringField.TYPE_UNSTORED);
+      doc.add(sort3);
+      docNoGroup.add(sort3);
+      Field content = newField("content", "", TextField.TYPE_UNSTORED);
+      doc.add(content);
+      docNoGroup.add(content);
+      NumericField id = new NumericField("id");
+      doc.add(id);
+      docNoGroup.add(id);
+      final GroupDoc[] groupDocs = new GroupDoc[numDocs];
+      for (int i = 0; i < numDocs; i++) {
+        final BytesRef groupValue;
+        if (random.nextInt(24) == 17) {
+          // So we test the "doc doesn't have the group'd
+          // field" case:
+          groupValue = null;
+        } else {
+          groupValue = groups.get(random.nextInt(groups.size()));
+        }
+
+        final GroupDoc groupDoc = new GroupDoc(
+            i,
+            groupValue,
+            groups.get(random.nextInt(groups.size())),
+            groups.get(random.nextInt(groups.size())),
+            new BytesRef(String.format("%05d", i)),
+            contentStrings[random.nextInt(contentStrings.length)]
+        );
+
+        if (VERBOSE) {
+          System.out.println("  doc content=" + groupDoc.content + " id=" + i + " group=" + (groupDoc.group == null ? "null" : groupDoc.group.utf8ToString()) + " sort1=" + groupDoc.sort1.utf8ToString() + " sort2=" + groupDoc.sort2.utf8ToString() + " sort3=" + groupDoc.sort3.utf8ToString());
+        }
+
+        groupDocs[i] = groupDoc;
+        if (groupDoc.group != null) {
+          group.setValue(groupDoc.group.utf8ToString());
+        }
+        sort1.setValue(groupDoc.sort1.utf8ToString());
+        sort2.setValue(groupDoc.sort2.utf8ToString());
+        sort3.setValue(groupDoc.sort3.utf8ToString());
+        content.setValue(groupDoc.content);
+        id.setIntValue(groupDoc.id);
+        if (groupDoc.group == null) {
+          w.addDocument(docNoGroup);
+        } else {
+          w.addDocument(doc);
+        }
+      }
+
+      final IndexReader r = w.getReader();
+      w.close();
+
+      // NOTE: intentional but temporary field cache insanity!
+      final int[] docIdToFieldId = FieldCache.DEFAULT.getInts(r, "id");
+      final int[] fieldIdToDocID = new int[numDocs];
+      for (int i = 0; i < docIdToFieldId.length; i++) {
+        int fieldId = docIdToFieldId[i];
+        fieldIdToDocID[fieldId] = i;
+      }
+
+      try {
+        final IndexSearcher s = newSearcher(r);
+
+        for (int contentID = 0; contentID < 3; contentID++) {
+          final ScoreDoc[] hits = s.search(new TermQuery(new Term("content", "real" + contentID)), numDocs).scoreDocs;
+          for (ScoreDoc hit : hits) {
+            final GroupDoc gd = groupDocs[docIdToFieldId[hit.doc]];
+            assertTrue(gd.score == 0.0);
+            gd.score = hit.score;
+            int docId = gd.id;
+            assertEquals(docId, docIdToFieldId[hit.doc]);
+          }
+        }
+
+        for (GroupDoc gd : groupDocs) {
+          assertTrue(gd.score != 0.0);
+        }
+
+        for (int searchIter = 0; searchIter < 100; searchIter++) {
+
+          if (VERBOSE) {
+            System.out.println("TEST: searchIter=" + searchIter);
+          }
+
+          final String searchTerm = "real" + random.nextInt(3);
+          boolean sortByScoreOnly = random.nextBoolean();
+          Sort sortWithinGroup = getRandomSort(sortByScoreOnly);
+          AbstractAllGroupHeadsCollector allGroupHeadsCollector = createRandomCollector("group", sortWithinGroup);
+          s.search(new TermQuery(new Term("content", searchTerm)), allGroupHeadsCollector);
+          int[] expectedGroupHeads = createExpectedGroupHeads(searchTerm, groupDocs, sortWithinGroup, sortByScoreOnly, fieldIdToDocID);
+          int[] actualGroupHeads = allGroupHeadsCollector.retrieveGroupHeads();
+          // The actual group heads contains Lucene ids. Need to change them into our id value.
+          for (int i = 0; i < actualGroupHeads.length; i++) {
+            actualGroupHeads[i] = docIdToFieldId[actualGroupHeads[i]];
+          }
+          // Allows us the easily iterate and assert the actual and expected results.
+          Arrays.sort(expectedGroupHeads);
+          Arrays.sort(actualGroupHeads);
+
+          if (VERBOSE) {
+            System.out.println("Collector: " + allGroupHeadsCollector.getClass().getSimpleName());
+            System.out.println("Sort within group: " + sortWithinGroup);
+            System.out.println("Num group: " + numGroups);
+            System.out.println("Num doc: " + numDocs);
+            System.out.println("\n=== Expected: \n");
+            for (int expectedDocId : expectedGroupHeads) {
+              GroupDoc expectedGroupDoc = groupDocs[expectedDocId];
+              String expectedGroup = expectedGroupDoc.group == null ? null : expectedGroupDoc.group.utf8ToString();
+              System.out.println(
+                  String.format(
+                      "Group:%10s score%5f Sort1:%10s Sort2:%10s Sort3:%10s doc:%5d",
+                      expectedGroup, expectedGroupDoc.score, expectedGroupDoc.sort1.utf8ToString(),
+                      expectedGroupDoc.sort2.utf8ToString(), expectedGroupDoc.sort3.utf8ToString(), expectedDocId
+                  )
+              );
+            }
+            System.out.println("\n=== Actual: \n");
+            for (int actualDocId : actualGroupHeads) {
+              GroupDoc actualGroupDoc = groupDocs[actualDocId];
+              String actualGroup = actualGroupDoc.group == null ? null : actualGroupDoc.group.utf8ToString();
+              System.out.println(
+                  String.format(
+                      "Group:%10s score%5f Sort1:%10s Sort2:%10s Sort3:%10s doc:%5d",
+                      actualGroup, actualGroupDoc.score, actualGroupDoc.sort1.utf8ToString(),
+                      actualGroupDoc.sort2.utf8ToString(), actualGroupDoc.sort3.utf8ToString(), actualDocId
+                  )
+              );
+            }
+            System.out.println("\n===================================================================================");
+          }
+
+          assertEquals(expectedGroupHeads.length, actualGroupHeads.length);
+          for (int i = 0; i < expectedGroupHeads.length; i++) {
+            assertEquals(expectedGroupHeads[i], actualGroupHeads[i]);
+          }
+        }
+        s.close();
+      } finally {
+        FieldCache.DEFAULT.purge(r);
+      }
+
+      r.close();
+      dir.close();
+    }
+  }
+
+
+  private boolean arrayContains(int[] expected, int[] actual) {
+    Arrays.sort(actual); // in some cases the actual docs aren't sorted by docid. This method expects that.
+    if (expected.length != actual.length) {
+      return false;
+    }
+
+    for (int e : expected) {
+      boolean found = false;
+      for (int a : actual) {
+        if (e == a) {
+          found = true;
+        }
+      }
+
+      if (!found) {
+        return false;
+      }
+    }
+
+    return true;
+  }
+
+  private boolean openBitSetContains(int[] expectedDocs, FixedBitSet actual, int maxDoc) throws IOException {
+    if (expectedDocs.length != actual.cardinality()) {
+      return false;
+    }
+
+    FixedBitSet expected = new FixedBitSet(maxDoc);
+    for (int expectedDoc : expectedDocs) {
+      expected.set(expectedDoc);
+    }
+
+    int docId;
+    DocIdSetIterator iterator = expected.iterator();
+    while ((docId = iterator.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
+      if (!actual.get(docId)) {
+        return false;
+      }
+    }
+
+    return true;
+  }
+
+  private int[] createExpectedGroupHeads(String searchTerm, GroupDoc[] groupDocs, Sort docSort, boolean sortByScoreOnly, int[] fieldIdToDocID) throws IOException {
+    Map<BytesRef, List<GroupDoc>> groupHeads = new HashMap<BytesRef, List<GroupDoc>>();
+    for (GroupDoc groupDoc : groupDocs) {
+      if (!groupDoc.content.startsWith(searchTerm)) {
+        continue;
+      }
+
+      if (!groupHeads.containsKey(groupDoc.group)) {
+        List<GroupDoc> list = new ArrayList<GroupDoc>();
+        list.add(groupDoc);
+        groupHeads.put(groupDoc.group, list);
+        continue;
+      }
+      groupHeads.get(groupDoc.group).add(groupDoc);
+    }
+
+    int[] allGroupHeads = new int[groupHeads.size()];
+    int i = 0;
+    for (BytesRef groupValue : groupHeads.keySet()) {
+      List<GroupDoc> docs = groupHeads.get(groupValue);
+      Collections.sort(docs, getComparator(docSort, sortByScoreOnly, fieldIdToDocID));
+      allGroupHeads[i++] = docs.get(0).id;
+    }
+
+    return allGroupHeads;
+  }
+
+  private Sort getRandomSort(boolean scoreOnly) {
+    final List<SortField> sortFields = new ArrayList<SortField>();
+    if (random.nextInt(7) == 2 || scoreOnly) {
+      sortFields.add(SortField.FIELD_SCORE);
+    } else {
+      if (random.nextBoolean()) {
+        if (random.nextBoolean()) {
+          sortFields.add(new SortField("sort1", SortField.Type.STRING, random.nextBoolean()));
+        } else {
+          sortFields.add(new SortField("sort2", SortField.Type.STRING, random.nextBoolean()));
+        }
+      } else if (random.nextBoolean()) {
+        sortFields.add(new SortField("sort1", SortField.Type.STRING, random.nextBoolean()));
+        sortFields.add(new SortField("sort2", SortField.Type.STRING, random.nextBoolean()));
+      }
+    }
+    // Break ties:
+    if (random.nextBoolean() && !scoreOnly) {
+      sortFields.add(new SortField("sort3", SortField.Type.STRING));
+    } else if (!scoreOnly) {
+      sortFields.add(new SortField("id", SortField.Type.INT));
+    }
+    return new Sort(sortFields.toArray(new SortField[sortFields.size()]));
+  }
+
+  private Comparator<GroupDoc> getComparator(Sort sort, final boolean sortByScoreOnly, final int[] fieldIdToDocID) {
+    final SortField[] sortFields = sort.getSort();
+    return new Comparator<GroupDoc>() {
+      @Override
+      public int compare(GroupDoc d1, GroupDoc d2) {
+        for (SortField sf : sortFields) {
+          final int cmp;
+          if (sf.getType() == SortField.Type.SCORE) {
+            if (d1.score > d2.score) {
+              cmp = -1;
+            } else if (d1.score < d2.score) {
+              cmp = 1;
+            } else {
+              cmp = sortByScoreOnly ? fieldIdToDocID[d1.id] - fieldIdToDocID[d2.id] : 0;
+            }
+          } else if (sf.getField().equals("sort1")) {
+            cmp = d1.sort1.compareTo(d2.sort1);
+          } else if (sf.getField().equals("sort2")) {
+            cmp = d1.sort2.compareTo(d2.sort2);
+          } else if (sf.getField().equals("sort3")) {
+            cmp = d1.sort3.compareTo(d2.sort3);
+          } else {
+            assertEquals(sf.getField(), "id");
+            cmp = d1.id - d2.id;
+          }
+          if (cmp != 0) {
+            return sf.getReverse() ? -cmp : cmp;
+          }
+        }
+        // Our sort always fully tie breaks:
+        fail();
+        return 0;
+      }
+    };
+  }
+
+  private AbstractAllGroupHeadsCollector createRandomCollector(String groupField, Sort sortWithinGroup) throws IOException {
+    if (random.nextBoolean()) {
+      ValueSource vs = new BytesRefFieldSource(groupField);
+      return new FunctionAllGroupHeadsCollector(vs, new HashMap(), sortWithinGroup);
+    } else {
+      return TermAllGroupHeadsCollector.create(groupField, sortWithinGroup);
+    }
+  }
+
+
+  private static class GroupDoc {
+    final int id;
+    final BytesRef group;
+    final BytesRef sort1;
+    final BytesRef sort2;
+    final BytesRef sort3;
+    // content must be "realN ..."
+    final String content;
+    float score;
+
+    public GroupDoc(int id, BytesRef group, BytesRef sort1, BytesRef sort2, BytesRef sort3, String content) {
+      this.id = id;
+      this.group = group;
+      this.sort1 = sort1;
+      this.sort2 = sort2;
+      this.sort3 = sort3;
+      this.content = content;
+    }
+
+  }
+
+}
diff --git a/modules/grouping/src/test/org/apache/lucene/search/grouping/AllGroupsCollectorTest.java b/modules/grouping/src/test/org/apache/lucene/search/grouping/AllGroupsCollectorTest.java
new file mode 100644
index 0000000..dabc487
--- /dev/null
+++ b/modules/grouping/src/test/org/apache/lucene/search/grouping/AllGroupsCollectorTest.java
@@ -0,0 +1,130 @@
+package org.apache.lucene.search.grouping;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License")); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.MockAnalyzer;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.document.FieldType;
+import org.apache.lucene.document.TextField;
+import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.queries.function.ValueSource;
+import org.apache.lucene.queries.function.valuesource.BytesRefFieldSource;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.TermQuery;
+import org.apache.lucene.search.grouping.function.FunctionAllGroupsCollector;
+import org.apache.lucene.search.grouping.term.TermAllGroupsCollector;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.LuceneTestCase;
+
+import java.io.IOException;
+import java.util.HashMap;
+
+public class AllGroupsCollectorTest extends LuceneTestCase {
+
+  public void testTotalGroupCount() throws Exception {
+
+    final String groupField = "author";
+    FieldType customType = new FieldType();
+    customType.setStored(true);
+
+    Directory dir = newDirectory();
+    RandomIndexWriter w = new RandomIndexWriter(
+                               random,
+                               dir,
+                               newIndexWriterConfig(TEST_VERSION_CURRENT,
+                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));
+    // 0
+    Document doc = new Document();
+    doc.add(new Field(groupField, "author1", TextField.TYPE_STORED));
+    doc.add(new Field("content", "random text", TextField.TYPE_STORED));
+    doc.add(new Field("id", "1", customType));
+    w.addDocument(doc);
+
+    // 1
+    doc = new Document();
+    doc.add(new Field(groupField, "author1", TextField.TYPE_STORED));
+    doc.add(new Field("content", "some more random text blob", TextField.TYPE_STORED));
+    doc.add(new Field("id", "2", customType));
+    w.addDocument(doc);
+
+    // 2
+    doc = new Document();
+    doc.add(new Field(groupField, "author1", TextField.TYPE_STORED));
+    doc.add(new Field("content", "some more random textual data", TextField.TYPE_STORED));
+    doc.add(new Field("id", "3", customType));
+    w.addDocument(doc);
+    w.commit(); // To ensure a second segment
+
+    // 3
+    doc = new Document();
+    doc.add(new Field(groupField, "author2", TextField.TYPE_STORED));
+    doc.add(new Field("content", "some random text", TextField.TYPE_STORED));
+    doc.add(new Field("id", "4", customType));
+    w.addDocument(doc);
+
+    // 4
+    doc = new Document();
+    doc.add(new Field(groupField, "author3", TextField.TYPE_STORED));
+    doc.add(new Field("content", "some more random text", TextField.TYPE_STORED));
+    doc.add(new Field("id", "5", customType));
+    w.addDocument(doc);
+
+    // 5
+    doc = new Document();
+    doc.add(new Field(groupField, "author3", TextField.TYPE_STORED));
+    doc.add(new Field("content", "random blob", TextField.TYPE_STORED));
+    doc.add(new Field("id", "6", customType));
+    w.addDocument(doc);
+
+    // 6 -- no author field
+    doc = new Document();
+    doc.add(new Field("content", "random word stuck in alot of other text", TextField.TYPE_STORED));
+    doc.add(new Field("id", "6", customType));
+    w.addDocument(doc);
+
+    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());
+    w.close();
+
+    AbstractAllGroupsCollector c1 = createRandomCollector(groupField);
+    indexSearcher.search(new TermQuery(new Term("content", "random")), c1);
+    assertEquals(4, c1.getGroupCount());
+
+    AbstractAllGroupsCollector c2 = createRandomCollector(groupField);
+    indexSearcher.search(new TermQuery(new Term("content", "some")), c2);
+    assertEquals(3, c2.getGroupCount());
+
+    AbstractAllGroupsCollector c3 = createRandomCollector(groupField);
+    indexSearcher.search(new TermQuery(new Term("content", "blob")), c3);
+    assertEquals(2, c3.getGroupCount());
+
+    indexSearcher.getIndexReader().close();
+    dir.close();
+  }
+
+  private AbstractAllGroupsCollector createRandomCollector(String groupField) throws IOException {
+    if (random.nextBoolean()) {
+      return new TermAllGroupsCollector(groupField);
+    } else {
+      ValueSource vs = new BytesRefFieldSource(groupField);
+      return new FunctionAllGroupsCollector(vs, new HashMap());
+    }
+  }
+
+}
diff --git a/modules/grouping/src/test/org/apache/lucene/search/grouping/TermAllGroupHeadsCollectorTest.java b/modules/grouping/src/test/org/apache/lucene/search/grouping/TermAllGroupHeadsCollectorTest.java
deleted file mode 100644
index 1dd6401..0000000
--- a/modules/grouping/src/test/org/apache/lucene/search/grouping/TermAllGroupHeadsCollectorTest.java
+++ /dev/null
@@ -1,494 +0,0 @@
-package org.apache.lucene.search.grouping;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.MockAnalyzer;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.document.NumericField;
-import org.apache.lucene.document.StringField;
-import org.apache.lucene.document.TextField;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.*;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.FixedBitSet;
-import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
-
-import java.io.IOException;
-import java.util.*;
-
-public class TermAllGroupHeadsCollectorTest extends LuceneTestCase {
-
-  public void testBasic() throws Exception {
-    final String groupField = "author";
-    Directory dir = newDirectory();
-    RandomIndexWriter w = new RandomIndexWriter(
-        random,
-        dir,
-        newIndexWriterConfig(TEST_VERSION_CURRENT,
-            new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));
-
-    // 0
-    Document doc = new Document();
-    doc.add(newField(groupField, "author1", TextField.TYPE_STORED));
-    doc.add(newField("content", "random text", TextField.TYPE_STORED));
-    doc.add(newField("id", "1", StringField.TYPE_STORED));
-    w.addDocument(doc);
-
-    // 1
-    doc = new Document();
-    doc.add(newField(groupField, "author1", TextField.TYPE_STORED));
-    doc.add(newField("content", "some more random text blob", TextField.TYPE_STORED));
-    doc.add(newField("id", "2", StringField.TYPE_STORED));
-    w.addDocument(doc);
-
-    // 2
-    doc = new Document();
-    doc.add(newField(groupField, "author1", TextField.TYPE_STORED));
-    doc.add(newField("content", "some more random textual data", TextField.TYPE_STORED));
-    doc.add(newField("id", "3", StringField.TYPE_STORED));
-    w.addDocument(doc);
-    w.commit(); // To ensure a second segment
-
-    // 3
-    doc = new Document();
-    doc.add(newField(groupField, "author2", TextField.TYPE_STORED));
-    doc.add(newField("content", "some random text", TextField.TYPE_STORED));
-    doc.add(newField("id", "4", StringField.TYPE_STORED));
-    w.addDocument(doc);
-
-    // 4
-    doc = new Document();
-    doc.add(newField(groupField, "author3", TextField.TYPE_STORED));
-    doc.add(newField("content", "some more random text", TextField.TYPE_STORED));
-    doc.add(newField("id", "5", StringField.TYPE_STORED));
-    w.addDocument(doc);
-
-    // 5
-    doc = new Document();
-    doc.add(newField(groupField, "author3", TextField.TYPE_STORED));
-    doc.add(newField("content", "random blob", TextField.TYPE_STORED));
-    doc.add(newField("id", "6", StringField.TYPE_STORED));
-    w.addDocument(doc);
-
-    // 6 -- no author field
-    doc = new Document();
-    doc.add(newField("content", "random word stuck in alot of other text", TextField.TYPE_STORED));
-    doc.add(newField("id", "6", StringField.TYPE_STORED));
-    w.addDocument(doc);
-
-    // 7 -- no author field
-    doc = new Document();
-    doc.add(newField("content", "random word stuck in alot of other text", TextField.TYPE_STORED));
-    doc.add(newField("id", "7", StringField.TYPE_STORED));
-    w.addDocument(doc);
-
-    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());
-    w.close();
-    int maxDoc = indexSearcher.maxDoc();
-
-    Sort sortWithinGroup = new Sort(new SortField("id", SortField.Type.INT, true));
-    AbstractAllGroupHeadsCollector c1 = TermAllGroupHeadsCollector.create(groupField, sortWithinGroup);
-    indexSearcher.search(new TermQuery(new Term("content", "random")), c1);
-    assertTrue(arrayContains(new int[]{2, 3, 5, 7}, c1.retrieveGroupHeads()));
-    assertTrue(openBitSetContains(new int[]{2, 3, 5, 7}, c1.retrieveGroupHeads(maxDoc), maxDoc));
-
-    AbstractAllGroupHeadsCollector c2 = TermAllGroupHeadsCollector.create(groupField, sortWithinGroup);
-    indexSearcher.search(new TermQuery(new Term("content", "some")), c2);
-    assertTrue(arrayContains(new int[]{2, 3, 4}, c2.retrieveGroupHeads()));
-    assertTrue(openBitSetContains(new int[]{2, 3, 4}, c2.retrieveGroupHeads(maxDoc), maxDoc));
-
-    AbstractAllGroupHeadsCollector c3 = TermAllGroupHeadsCollector.create(groupField, sortWithinGroup);
-    indexSearcher.search(new TermQuery(new Term("content", "blob")), c3);
-    assertTrue(arrayContains(new int[]{1, 5}, c3.retrieveGroupHeads()));
-    assertTrue(openBitSetContains(new int[]{1, 5}, c3.retrieveGroupHeads(maxDoc), maxDoc));
-
-    // STRING sort type triggers different implementation
-    Sort sortWithinGroup2 = new Sort(new SortField("id", SortField.Type.STRING, true));
-    AbstractAllGroupHeadsCollector c4 = TermAllGroupHeadsCollector.create(groupField, sortWithinGroup2);
-    indexSearcher.search(new TermQuery(new Term("content", "random")), c4);
-    assertTrue(arrayContains(new int[]{2, 3, 5, 7}, c4.retrieveGroupHeads()));
-    assertTrue(openBitSetContains(new int[]{2, 3, 5, 7}, c4.retrieveGroupHeads(maxDoc), maxDoc));
-
-    Sort sortWithinGroup3 = new Sort(new SortField("id", SortField.Type.STRING, false));
-    AbstractAllGroupHeadsCollector c5 = TermAllGroupHeadsCollector.create(groupField, sortWithinGroup3);
-    indexSearcher.search(new TermQuery(new Term("content", "random")), c5);
-    // 7 b/c higher doc id wins, even if order of field is in not in reverse.
-    assertTrue(arrayContains(new int[]{0, 3, 4, 6}, c5.retrieveGroupHeads()));
-    assertTrue(openBitSetContains(new int[]{0, 3, 4, 6}, c5.retrieveGroupHeads(maxDoc), maxDoc));
-
-    indexSearcher.getIndexReader().close();
-    dir.close();
-  }
-
-  public void testRandom() throws Exception {
-    int numberOfRuns = _TestUtil.nextInt(random, 3, 6);
-    for (int iter = 0; iter < numberOfRuns; iter++) {
-      if (VERBOSE) {
-        System.out.println(String.format("TEST: iter=%d total=%d", iter, numberOfRuns));
-      }
-
-      final int numDocs = _TestUtil.nextInt(random, 100, 1000) * RANDOM_MULTIPLIER;
-      final int numGroups = _TestUtil.nextInt(random, 1, numDocs);
-
-      if (VERBOSE) {
-        System.out.println("TEST: numDocs=" + numDocs + " numGroups=" + numGroups);
-      }
-
-      final List<BytesRef> groups = new ArrayList<BytesRef>();
-      for (int i = 0; i < numGroups; i++) {
-        groups.add(new BytesRef(_TestUtil.randomRealisticUnicodeString(random)));
-      }
-      final String[] contentStrings = new String[_TestUtil.nextInt(random, 2, 20)];
-      if (VERBOSE) {
-        System.out.println("TEST: create fake content");
-      }
-      for (int contentIDX = 0; contentIDX < contentStrings.length; contentIDX++) {
-        final StringBuilder sb = new StringBuilder();
-        sb.append("real").append(random.nextInt(3)).append(' ');
-        final int fakeCount = random.nextInt(10);
-        for (int fakeIDX = 0; fakeIDX < fakeCount; fakeIDX++) {
-          sb.append("fake ");
-        }
-        contentStrings[contentIDX] = sb.toString();
-        if (VERBOSE) {
-          System.out.println("  content=" + sb.toString());
-        }
-      }
-
-      Directory dir = newDirectory();
-      RandomIndexWriter w = new RandomIndexWriter(
-          random,
-          dir,
-          newIndexWriterConfig(TEST_VERSION_CURRENT,
-              new MockAnalyzer(random)));
-
-      Document doc = new Document();
-      Document docNoGroup = new Document();
-      Field group = newField("group", "", StringField.TYPE_UNSTORED);
-      doc.add(group);
-      Field sort1 = newField("sort1", "", StringField.TYPE_UNSTORED);
-      doc.add(sort1);
-      docNoGroup.add(sort1);
-      Field sort2 = newField("sort2", "", StringField.TYPE_UNSTORED);
-      doc.add(sort2);
-      docNoGroup.add(sort2);
-      Field sort3 = newField("sort3", "", StringField.TYPE_UNSTORED);
-      doc.add(sort3);
-      docNoGroup.add(sort3);
-      Field content = newField("content", "", TextField.TYPE_UNSTORED);
-      doc.add(content);
-      docNoGroup.add(content);
-      NumericField id = new NumericField("id");
-      doc.add(id);
-      docNoGroup.add(id);
-      final GroupDoc[] groupDocs = new GroupDoc[numDocs];
-      for (int i = 0; i < numDocs; i++) {
-        final BytesRef groupValue;
-        if (random.nextInt(24) == 17) {
-          // So we test the "doc doesn't have the group'd
-          // field" case:
-          groupValue = null;
-        } else {
-          groupValue = groups.get(random.nextInt(groups.size()));
-        }
-
-        final GroupDoc groupDoc = new GroupDoc(
-            i,
-            groupValue,
-            groups.get(random.nextInt(groups.size())),
-            groups.get(random.nextInt(groups.size())),
-            new BytesRef(String.format("%05d", i)),
-            contentStrings[random.nextInt(contentStrings.length)]
-        );
-
-        if (VERBOSE) {
-          System.out.println("  doc content=" + groupDoc.content + " id=" + i + " group=" + (groupDoc.group == null ? "null" : groupDoc.group.utf8ToString()) + " sort1=" + groupDoc.sort1.utf8ToString() + " sort2=" + groupDoc.sort2.utf8ToString() + " sort3=" + groupDoc.sort3.utf8ToString());
-        }
-
-        groupDocs[i] = groupDoc;
-        if (groupDoc.group != null) {
-          group.setValue(groupDoc.group.utf8ToString());
-        }
-        sort1.setValue(groupDoc.sort1.utf8ToString());
-        sort2.setValue(groupDoc.sort2.utf8ToString());
-        sort3.setValue(groupDoc.sort3.utf8ToString());
-        content.setValue(groupDoc.content);
-        id.setIntValue(groupDoc.id);
-        if (groupDoc.group == null) {
-          w.addDocument(docNoGroup);
-        } else {
-          w.addDocument(doc);
-        }
-      }
-
-      final IndexReader r = w.getReader();
-      w.close();
-
-      // NOTE: intentional but temporary field cache insanity!
-      final int[] docIdToFieldId = FieldCache.DEFAULT.getInts(r, "id");
-      final int[] fieldIdToDocID = new int[numDocs];
-      for (int i = 0; i < docIdToFieldId.length; i++) {
-        int fieldId = docIdToFieldId[i];
-        fieldIdToDocID[fieldId] = i;
-      }
-
-      try {
-        final IndexSearcher s = newSearcher(r);
-
-        for (int contentID = 0; contentID < 3; contentID++) {
-          final ScoreDoc[] hits = s.search(new TermQuery(new Term("content", "real" + contentID)), numDocs).scoreDocs;
-          for (ScoreDoc hit : hits) {
-            final GroupDoc gd = groupDocs[docIdToFieldId[hit.doc]];
-            assertTrue(gd.score == 0.0);
-            gd.score = hit.score;
-            int docId = gd.id;
-            assertEquals(docId, docIdToFieldId[hit.doc]);
-          }
-        }
-
-        for (GroupDoc gd : groupDocs) {
-          assertTrue(gd.score != 0.0);
-        }
-
-        for (int searchIter = 0; searchIter < 100; searchIter++) {
-
-          if (VERBOSE) {
-            System.out.println("TEST: searchIter=" + searchIter);
-          }
-
-          final String searchTerm = "real" + random.nextInt(3);
-          boolean sortByScoreOnly = random.nextBoolean();
-          Sort sortWithinGroup = getRandomSort(sortByScoreOnly);
-          AbstractAllGroupHeadsCollector allGroupHeadsCollector = TermAllGroupHeadsCollector.create("group", sortWithinGroup);
-          s.search(new TermQuery(new Term("content", searchTerm)), allGroupHeadsCollector);
-          int[] expectedGroupHeads = createExpectedGroupHeads(searchTerm, groupDocs, sortWithinGroup, sortByScoreOnly, fieldIdToDocID);
-          int[] actualGroupHeads = allGroupHeadsCollector.retrieveGroupHeads();
-          // The actual group heads contains Lucene ids. Need to change them into our id value.
-          for (int i = 0; i < actualGroupHeads.length; i++) {
-            actualGroupHeads[i] = docIdToFieldId[actualGroupHeads[i]];
-          }
-          // Allows us the easily iterate and assert the actual and expected results.
-          Arrays.sort(expectedGroupHeads);
-          Arrays.sort(actualGroupHeads);
-
-          if (VERBOSE) {
-            System.out.println("Collector: " + allGroupHeadsCollector.getClass().getSimpleName());
-            System.out.println("Sort within group: " + sortWithinGroup);
-            System.out.println("Num group: " + numGroups);
-            System.out.println("Num doc: " + numDocs);
-            System.out.println("\n=== Expected: \n");
-            for (int expectedDocId : expectedGroupHeads) {
-              GroupDoc expectedGroupDoc = groupDocs[expectedDocId];
-              String expectedGroup = expectedGroupDoc.group == null ? null : expectedGroupDoc.group.utf8ToString();
-              System.out.println(
-                  String.format(
-                      "Group:%10s score%5f Sort1:%10s Sort2:%10s Sort3:%10s doc:%5d",
-                      expectedGroup, expectedGroupDoc.score, expectedGroupDoc.sort1.utf8ToString(),
-                      expectedGroupDoc.sort2.utf8ToString(), expectedGroupDoc.sort3.utf8ToString(), expectedDocId
-                  )
-              );
-            }
-            System.out.println("\n=== Actual: \n");
-            for (int actualDocId : actualGroupHeads) {
-              GroupDoc actualGroupDoc = groupDocs[actualDocId];
-              String actualGroup = actualGroupDoc.group == null ? null : actualGroupDoc.group.utf8ToString();
-              System.out.println(
-                  String.format(
-                      "Group:%10s score%5f Sort1:%10s Sort2:%10s Sort3:%10s doc:%5d",
-                      actualGroup, actualGroupDoc.score, actualGroupDoc.sort1.utf8ToString(),
-                      actualGroupDoc.sort2.utf8ToString(), actualGroupDoc.sort3.utf8ToString(), actualDocId
-                  )
-              );
-            }
-            System.out.println("\n===================================================================================");
-          }
-
-          assertEquals(expectedGroupHeads.length, actualGroupHeads.length);
-          for (int i = 0; i < expectedGroupHeads.length; i++) {
-            assertEquals(expectedGroupHeads[i], actualGroupHeads[i]);
-          }
-        }
-        s.close();
-      } finally {
-        FieldCache.DEFAULT.purge(r);
-      }
-
-      r.close();
-      dir.close();
-    }
-  }
-
-
-  private boolean arrayContains(int[] expected, int[] actual) {
-    if (expected.length != actual.length) {
-      return false;
-    }
-
-    for (int e : expected) {
-      boolean found = false;
-      for (int a : actual) {
-        if (e == a) {
-          found = true;
-        }
-      }
-
-      if (!found) {
-        return false;
-      }
-    }
-
-    return true;
-  }
-
-  private boolean openBitSetContains(int[] expectedDocs, FixedBitSet actual, int maxDoc) throws IOException {
-    if (expectedDocs.length != actual.cardinality()) {
-      return false;
-    }
-
-    FixedBitSet expected = new FixedBitSet(maxDoc);
-    for (int expectedDoc : expectedDocs) {
-      expected.set(expectedDoc);
-    }
-
-    int docId;
-    DocIdSetIterator iterator = expected.iterator();
-    while ((docId = iterator.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
-      if (!actual.get(docId)) {
-        return false;
-      }
-    }
-
-    return true;
-  }
-
-  private int[] createExpectedGroupHeads(String searchTerm, GroupDoc[] groupDocs, Sort docSort, boolean sortByScoreOnly, int[] fieldIdToDocID) throws IOException {
-    Map<BytesRef, List<GroupDoc>> groupHeads = new HashMap<BytesRef, List<GroupDoc>>();
-    for (GroupDoc groupDoc : groupDocs) {
-      if (!groupDoc.content.startsWith(searchTerm)) {
-        continue;
-      }
-
-      if (!groupHeads.containsKey(groupDoc.group)) {
-        List<GroupDoc> list = new ArrayList<GroupDoc>();
-        list.add(groupDoc);
-        groupHeads.put(groupDoc.group, list);
-        continue;
-      }
-      groupHeads.get(groupDoc.group).add(groupDoc);
-    }
-
-    int[] allGroupHeads = new int[groupHeads.size()];
-    int i = 0;
-    for (BytesRef groupValue : groupHeads.keySet()) {
-      List<GroupDoc> docs = groupHeads.get(groupValue);
-      Collections.sort(docs, getComparator(docSort, sortByScoreOnly, fieldIdToDocID));
-      allGroupHeads[i++] = docs.get(0).id;
-    }
-
-    return allGroupHeads;
-  }
-
-  private Sort getRandomSort(boolean scoreOnly) {
-    final List<SortField> sortFields = new ArrayList<SortField>();
-    if (random.nextInt(7) == 2 || scoreOnly) {
-      sortFields.add(SortField.FIELD_SCORE);
-    } else {
-      if (random.nextBoolean()) {
-        if (random.nextBoolean()) {
-          sortFields.add(new SortField("sort1", SortField.Type.STRING, random.nextBoolean()));
-        } else {
-          sortFields.add(new SortField("sort2", SortField.Type.STRING, random.nextBoolean()));
-        }
-      } else if (random.nextBoolean()) {
-        sortFields.add(new SortField("sort1", SortField.Type.STRING, random.nextBoolean()));
-        sortFields.add(new SortField("sort2", SortField.Type.STRING, random.nextBoolean()));
-      }
-    }
-    // Break ties:
-    if (random.nextBoolean() && !scoreOnly) {
-      sortFields.add(new SortField("sort3", SortField.Type.STRING));
-    } else if (!scoreOnly) {
-      sortFields.add(new SortField("id", SortField.Type.INT));
-    }
-    return new Sort(sortFields.toArray(new SortField[sortFields.size()]));
-  }
-
-  private Comparator<GroupDoc> getComparator(Sort sort, final boolean sortByScoreOnly, final int[] fieldIdToDocID) {
-    final SortField[] sortFields = sort.getSort();
-    return new Comparator<GroupDoc>() {
-      @Override
-      public int compare(GroupDoc d1, GroupDoc d2) {
-        for (SortField sf : sortFields) {
-          final int cmp;
-          if (sf.getType() == SortField.Type.SCORE) {
-            if (d1.score > d2.score) {
-              cmp = -1;
-            } else if (d1.score < d2.score) {
-              cmp = 1;
-            } else {
-              cmp = sortByScoreOnly ? fieldIdToDocID[d1.id] - fieldIdToDocID[d2.id] : 0;
-            }
-          } else if (sf.getField().equals("sort1")) {
-            cmp = d1.sort1.compareTo(d2.sort1);
-          } else if (sf.getField().equals("sort2")) {
-            cmp = d1.sort2.compareTo(d2.sort2);
-          } else if (sf.getField().equals("sort3")) {
-            cmp = d1.sort3.compareTo(d2.sort3);
-          } else {
-            assertEquals(sf.getField(), "id");
-            cmp = d1.id - d2.id;
-          }
-          if (cmp != 0) {
-            return sf.getReverse() ? -cmp : cmp;
-          }
-        }
-        // Our sort always fully tie breaks:
-        fail();
-        return 0;
-      }
-    };
-  }
-
-
-  private static class GroupDoc {
-    final int id;
-    final BytesRef group;
-    final BytesRef sort1;
-    final BytesRef sort2;
-    final BytesRef sort3;
-    // content must be "realN ..."
-    final String content;
-    float score;
-
-    public GroupDoc(int id, BytesRef group, BytesRef sort1, BytesRef sort2, BytesRef sort3, String content) {
-      this.id = id;
-      this.group = group;
-      this.sort1 = sort1;
-      this.sort2 = sort2;
-      this.sort3 = sort3;
-      this.content = content;
-    }
-
-  }
-
-}
\ No newline at end of file
diff --git a/modules/grouping/src/test/org/apache/lucene/search/grouping/TermAllGroupsCollectorTest.java b/modules/grouping/src/test/org/apache/lucene/search/grouping/TermAllGroupsCollectorTest.java
deleted file mode 100644
index fdf100d..0000000
--- a/modules/grouping/src/test/org/apache/lucene/search/grouping/TermAllGroupsCollectorTest.java
+++ /dev/null
@@ -1,113 +0,0 @@
-package org.apache.lucene.search.grouping;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License")); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.MockAnalyzer;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.document.FieldType;
-import org.apache.lucene.document.TextField;
-import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.TermQuery;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.LuceneTestCase;
-
-public class TermAllGroupsCollectorTest extends LuceneTestCase {
-
-  public void testTotalGroupCount() throws Exception {
-
-    final String groupField = "author";
-    FieldType customType = new FieldType();
-    customType.setStored(true);
-
-    Directory dir = newDirectory();
-    RandomIndexWriter w = new RandomIndexWriter(
-                               random,
-                               dir,
-                               newIndexWriterConfig(TEST_VERSION_CURRENT,
-                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));
-    // 0
-    Document doc = new Document();
-    doc.add(new Field(groupField, "author1", TextField.TYPE_STORED));
-    doc.add(new Field("content", "random text", TextField.TYPE_STORED));
-    doc.add(new Field("id", "1", customType));
-    w.addDocument(doc);
-
-    // 1
-    doc = new Document();
-    doc.add(new Field(groupField, "author1", TextField.TYPE_STORED));
-    doc.add(new Field("content", "some more random text blob", TextField.TYPE_STORED));
-    doc.add(new Field("id", "2", customType));
-    w.addDocument(doc);
-
-    // 2
-    doc = new Document();
-    doc.add(new Field(groupField, "author1", TextField.TYPE_STORED));
-    doc.add(new Field("content", "some more random textual data", TextField.TYPE_STORED));
-    doc.add(new Field("id", "3", customType));
-    w.addDocument(doc);
-    w.commit(); // To ensure a second segment
-
-    // 3
-    doc = new Document();
-    doc.add(new Field(groupField, "author2", TextField.TYPE_STORED));
-    doc.add(new Field("content", "some random text", TextField.TYPE_STORED));
-    doc.add(new Field("id", "4", customType));
-    w.addDocument(doc);
-
-    // 4
-    doc = new Document();
-    doc.add(new Field(groupField, "author3", TextField.TYPE_STORED));
-    doc.add(new Field("content", "some more random text", TextField.TYPE_STORED));
-    doc.add(new Field("id", "5", customType));
-    w.addDocument(doc);
-
-    // 5
-    doc = new Document();
-    doc.add(new Field(groupField, "author3", TextField.TYPE_STORED));
-    doc.add(new Field("content", "random blob", TextField.TYPE_STORED));
-    doc.add(new Field("id", "6", customType));
-    w.addDocument(doc);
-
-    // 6 -- no author field
-    doc = new Document();
-    doc.add(new Field("content", "random word stuck in alot of other text", TextField.TYPE_STORED));
-    doc.add(new Field("id", "6", customType));
-    w.addDocument(doc);
-
-    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());
-    w.close();
-
-    TermAllGroupsCollector c1 = new TermAllGroupsCollector(groupField);
-    indexSearcher.search(new TermQuery(new Term("content", "random")), c1);
-    assertEquals(4, c1.getGroupCount());
-
-    TermAllGroupsCollector c2 = new TermAllGroupsCollector(groupField);
-    indexSearcher.search(new TermQuery(new Term("content", "some")), c2);
-    assertEquals(3, c2.getGroupCount());
-
-    TermAllGroupsCollector c3 = new TermAllGroupsCollector(groupField);
-    indexSearcher.search(new TermQuery(new Term("content", "blob")), c3);
-    assertEquals(2, c3.getGroupCount());
-
-    indexSearcher.getIndexReader().close();
-    dir.close();
-  }
-}
diff --git a/modules/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping.java b/modules/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping.java
index 154a3bc..0094170 100644
--- a/modules/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping.java
+++ b/modules/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping.java
@@ -31,12 +31,22 @@ import org.apache.lucene.document.TextField;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.index.Term;
+import org.apache.lucene.queries.function.ValueSource;
+import org.apache.lucene.queries.function.valuesource.BytesRefFieldSource;
 import org.apache.lucene.search.*;
+import org.apache.lucene.search.grouping.function.FunctionAllGroupsCollector;
+import org.apache.lucene.search.grouping.function.FunctionFirstPassGroupingCollector;
+import org.apache.lucene.search.grouping.function.FunctionSecondPassGroupingCollector;
+import org.apache.lucene.search.grouping.term.TermAllGroupsCollector;
+import org.apache.lucene.search.grouping.term.TermFirstPassGroupingCollector;
+import org.apache.lucene.search.grouping.term.TermSecondPassGroupingCollector;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.ReaderUtil;
 import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.mutable.MutableValue;
+import org.apache.lucene.util.mutable.MutableValueStr;
 
 // TODO
 //   - should test relevance sort too
@@ -111,10 +121,10 @@ public class TestGrouping extends LuceneTestCase {
     w.close();
 
     final Sort groupSort = Sort.RELEVANCE;
-    final TermFirstPassGroupingCollector c1 = new TermFirstPassGroupingCollector(groupField, groupSort, 10);
+    final AbstractFirstPassGroupingCollector c1 = createRandomFirstPassCollector(groupField, groupSort, 10);
     indexSearcher.search(new TermQuery(new Term("content", "random")), c1);
 
-    final TermSecondPassGroupingCollector c2 = new TermSecondPassGroupingCollector(groupField, c1.getTopGroups(0, true), groupSort, null, 5, true, false, true);
+    final AbstractSecondPassGroupingCollector c2 = createSecondPassCollector(c1, groupField, groupSort, null, 0, 5, true, false, true);
     indexSearcher.search(new TermQuery(new Term("content", "random")), c2);
 
     final TopGroups groups = c2.getTopGroups(0);
@@ -128,14 +138,14 @@ public class TestGrouping extends LuceneTestCase {
     // the later a document is added the higher this docId
     // value
     GroupDocs group = groups.groups[0];
-    assertEquals(new BytesRef("author3"), group.groupValue);
+    compareGroupValue("author3", group);
     assertEquals(2, group.scoreDocs.length);
     assertEquals(5, group.scoreDocs[0].doc);
     assertEquals(4, group.scoreDocs[1].doc);
     assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);
 
     group = groups.groups[1];
-    assertEquals(new BytesRef("author1"), group.groupValue);
+    compareGroupValue("author1", group);
     assertEquals(3, group.scoreDocs.length);
     assertEquals(0, group.scoreDocs[0].doc);
     assertEquals(1, group.scoreDocs[1].doc);
@@ -144,12 +154,12 @@ public class TestGrouping extends LuceneTestCase {
     assertTrue(group.scoreDocs[1].score > group.scoreDocs[2].score);
 
     group = groups.groups[2];
-    assertEquals(new BytesRef("author2"), group.groupValue);
+    compareGroupValue("author2", group);
     assertEquals(1, group.scoreDocs.length);
     assertEquals(3, group.scoreDocs[0].doc);
 
     group = groups.groups[3];
-    assertNull(group.groupValue);
+    compareGroupValue(null, group);
     assertEquals(1, group.scoreDocs.length);
     assertEquals(6, group.scoreDocs[0].doc);
 
@@ -157,6 +167,140 @@ public class TestGrouping extends LuceneTestCase {
     dir.close();
   }
 
+  private AbstractFirstPassGroupingCollector createRandomFirstPassCollector(String groupField, Sort groupSort, int topDocs) throws IOException {
+    if (random.nextBoolean()) {
+      ValueSource vs = new BytesRefFieldSource(groupField);
+      return new FunctionFirstPassGroupingCollector(vs, new HashMap(), groupSort, topDocs);
+    } else {
+      return new TermFirstPassGroupingCollector(groupField, groupSort, topDocs);
+    }
+  }
+
+  private AbstractSecondPassGroupingCollector createSecondPassCollector(AbstractFirstPassGroupingCollector firstPassGroupingCollector,
+                                                                        String groupField,
+                                                                        Sort groupSort,
+                                                                        Sort sortWithinGroup,
+                                                                        int groupOffset,
+                                                                        int maxDocsPerGroup,
+                                                                        boolean getScores,
+                                                                        boolean getMaxScores,
+                                                                        boolean fillSortFields) throws IOException {
+
+    if (firstPassGroupingCollector.getClass().isAssignableFrom(TermFirstPassGroupingCollector.class)) {
+      @SuppressWarnings("unchecked")
+      Collection<SearchGroup<BytesRef>> searchGroups = firstPassGroupingCollector.getTopGroups(groupOffset, fillSortFields);
+      return new TermSecondPassGroupingCollector(groupField, searchGroups, groupSort, sortWithinGroup, maxDocsPerGroup , getScores, getMaxScores, fillSortFields);
+    } else {
+      ValueSource vs = new BytesRefFieldSource(groupField);
+      @SuppressWarnings("unchecked")
+      Collection<SearchGroup<MutableValue>> searchGroups = firstPassGroupingCollector.getTopGroups(groupOffset, fillSortFields);
+      return new FunctionSecondPassGroupingCollector(searchGroups, groupSort, sortWithinGroup, maxDocsPerGroup, getScores, getMaxScores, fillSortFields, vs, new HashMap());
+    }
+  }
+
+  // Basically converts searchGroups from MutableValue to BytesRef if grouping by ValueSource
+  private AbstractSecondPassGroupingCollector createSecondPassCollector(AbstractFirstPassGroupingCollector firstPassGroupingCollector,
+                                                                        String groupField,
+                                                                        Collection<SearchGroup<BytesRef>> searchGroups,
+                                                                        Sort groupSort,
+                                                                        Sort sortWithinGroup,
+                                                                        int maxDocsPerGroup,
+                                                                        boolean getScores,
+                                                                        boolean getMaxScores,
+                                                                        boolean fillSortFields) throws IOException {
+
+    if (firstPassGroupingCollector.getClass().isAssignableFrom(TermFirstPassGroupingCollector.class)) {
+      return new TermSecondPassGroupingCollector(groupField, searchGroups, groupSort, sortWithinGroup, maxDocsPerGroup , getScores, getMaxScores, fillSortFields);
+    } else {
+      ValueSource vs = new BytesRefFieldSource(groupField);
+      List<SearchGroup<MutableValue>> mvalSearchGroups = new ArrayList<SearchGroup<MutableValue>>(searchGroups.size());
+      for (SearchGroup<BytesRef> mergedTopGroup : searchGroups) {
+        SearchGroup<MutableValue> sg = new SearchGroup<MutableValue>();
+        MutableValueStr groupValue = new MutableValueStr();
+        if (mergedTopGroup.groupValue != null) {
+          groupValue.value =  mergedTopGroup.groupValue;
+        } else {
+          groupValue.value = new BytesRef();
+          groupValue.exists = false;
+        }
+        sg.groupValue = groupValue;
+        sg.sortValues = mergedTopGroup.sortValues;
+        mvalSearchGroups.add(sg);
+      }
+
+      return new FunctionSecondPassGroupingCollector(mvalSearchGroups, groupSort, sortWithinGroup, maxDocsPerGroup, getScores, getMaxScores, fillSortFields, vs, new HashMap());
+    }
+  }
+
+  private AbstractAllGroupsCollector createAllGroupsCollector(AbstractFirstPassGroupingCollector firstPassGroupingCollector, String groupField) {
+    if (firstPassGroupingCollector.getClass().isAssignableFrom(TermFirstPassGroupingCollector.class)) {
+      return new TermAllGroupsCollector(groupField);
+    } else {
+      ValueSource vs = new BytesRefFieldSource(groupField);
+      return new FunctionAllGroupsCollector(vs, new HashMap());
+    }
+  }
+
+  private void compareGroupValue(String expected, GroupDocs group) {
+    if (expected == null) {
+      if (group.groupValue == null) {
+        return;
+      } else if (group.groupValue.getClass().isAssignableFrom(MutableValueStr.class)) {
+        return;
+      }
+      fail();
+    }
+
+    if (group.groupValue.getClass().isAssignableFrom(BytesRef.class)) {
+      assertEquals(new BytesRef(expected), group.groupValue);
+    } else if (group.groupValue.getClass().isAssignableFrom(MutableValueStr.class)) {
+      MutableValueStr v = new MutableValueStr();
+      v.value = new BytesRef(expected);
+      assertEquals(v, group.groupValue);
+    } else {
+      fail();
+    }
+  }
+
+  private Collection<SearchGroup<BytesRef>> getSearchGroups(AbstractFirstPassGroupingCollector c, int groupOffset, boolean fillFields) {
+    if (c.getClass().isAssignableFrom(TermFirstPassGroupingCollector.class)) {
+      return ((TermFirstPassGroupingCollector) c).getTopGroups(groupOffset, fillFields);
+    } else if (c.getClass().isAssignableFrom(FunctionFirstPassGroupingCollector.class)) {
+      Collection<SearchGroup<MutableValue>> mutableValueGroups = ((FunctionFirstPassGroupingCollector) c).getTopGroups(groupOffset, fillFields);
+      if (mutableValueGroups == null) {
+        return null;
+      }
+
+      List<SearchGroup<BytesRef>> groups = new ArrayList<SearchGroup<BytesRef>>(mutableValueGroups.size());
+      for (SearchGroup<MutableValue> mutableValueGroup : mutableValueGroups) {
+        SearchGroup<BytesRef> sg = new SearchGroup<BytesRef>();
+        sg.groupValue = mutableValueGroup.groupValue.exists() ? ((MutableValueStr) mutableValueGroup.groupValue).value : null;
+        sg.sortValues = mutableValueGroup.sortValues;
+        groups.add(sg);
+      }
+      return groups;
+    }
+    fail();
+    return null;
+  }
+
+  @SuppressWarnings("unchecked")
+  private TopGroups<BytesRef> getTopGroups(AbstractSecondPassGroupingCollector c, int withinGroupOffset) {
+    if (c.getClass().isAssignableFrom(TermSecondPassGroupingCollector.class)) {
+      return ((TermSecondPassGroupingCollector) c).getTopGroups(withinGroupOffset);
+    } else if (c.getClass().isAssignableFrom(FunctionSecondPassGroupingCollector.class)) {
+      TopGroups<MutableValue> mvalTopGroups = ((FunctionSecondPassGroupingCollector) c).getTopGroups(withinGroupOffset);
+      List<GroupDocs<BytesRef>> groups = new ArrayList<GroupDocs<BytesRef>>(mvalTopGroups.groups.length);
+      for (GroupDocs<MutableValue> mvalGd : mvalTopGroups.groups) {
+        BytesRef groupValue = mvalGd.groupValue.exists() ? ((MutableValueStr) mvalGd.groupValue).value : null;
+        groups.add(new GroupDocs<BytesRef>(mvalGd.maxScore, mvalGd.totalHits, mvalGd.scoreDocs, groupValue, mvalGd.groupSortValues));
+      }
+      return new TopGroups<BytesRef>(mvalTopGroups.groupSort, mvalTopGroups.withinGroupSort, mvalTopGroups.totalHitCount, mvalTopGroups.totalGroupedHitCount, groups.toArray(new GroupDocs[groups.size()]));
+    }
+    fail();
+    return null;
+  }
+
   private static class GroupDoc {
     final int id;
     final BytesRef group;
@@ -662,17 +806,17 @@ public class TestGrouping extends LuceneTestCase {
             System.out.println("TEST: groupSort=" + groupSort + " docSort=" + docSort + " searchTerm=" + searchTerm + " dF=" + r.docFreq("content", new BytesRef(searchTerm))  +" dFBlock=" + rBlocks.docFreq("content", new BytesRef(searchTerm)) + " topNGroups=" + topNGroups + " groupOffset=" + groupOffset + " docOffset=" + docOffset + " doCache=" + doCache + " docsPerGroup=" + docsPerGroup + " doAllGroups=" + doAllGroups + " getScores=" + getScores + " getMaxScores=" + getMaxScores);
           }
 
-          final TermAllGroupsCollector allGroupsCollector;
+          final AbstractFirstPassGroupingCollector c1 = createRandomFirstPassCollector("group", groupSort, groupOffset+topNGroups);
+          final CachingCollector cCache;
+          final Collector c;
+
+          final AbstractAllGroupsCollector allGroupsCollector;
           if (doAllGroups) {
-            allGroupsCollector = new TermAllGroupsCollector("group");
+            allGroupsCollector = createAllGroupsCollector(c1, "group");
           } else {
             allGroupsCollector = null;
           }
 
-          final TermFirstPassGroupingCollector c1 = new TermFirstPassGroupingCollector("group", groupSort, groupOffset+topNGroups);
-          final CachingCollector cCache;
-          final Collector c;
-        
           final boolean useWrappingCollector = random.nextBoolean();
         
           if (doCache) {
@@ -723,8 +867,8 @@ public class TestGrouping extends LuceneTestCase {
           }
 
           // Get 1st pass top groups
-          final Collection<SearchGroup<BytesRef>> topGroups = c1.getTopGroups(groupOffset, fillFields);
-
+          final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(c1, groupOffset, fillFields);
+          final TopGroups<BytesRef> groupsResult;
           if (VERBOSE) {
             System.out.println("TEST: first pass topGroups");
             if (topGroups == null) {
@@ -738,12 +882,17 @@ public class TestGrouping extends LuceneTestCase {
           
           // Get 1st pass top groups using shards
           final TopGroups<BytesRef> topGroupsShards = searchShards(s, shards.subSearchers, query, groupSort, docSort, groupOffset, topNGroups, docOffset, docsPerGroup, getScores, getMaxScores);
-
-          final TopGroups<BytesRef> groupsResult;
+          final AbstractSecondPassGroupingCollector c2;
           if (topGroups != null) {
 
-            // Get 2nd pass grouped result:
-            final TermSecondPassGroupingCollector c2 = new TermSecondPassGroupingCollector("group", topGroups, groupSort, docSort, docOffset+docsPerGroup, getScores, getMaxScores, fillFields);
+            if (VERBOSE) {
+              System.out.println("TEST: topGroups");
+              for (SearchGroup<BytesRef> searchGroup : topGroups) {
+                System.out.println("  " + (searchGroup.groupValue == null ? "null" : searchGroup.groupValue.utf8ToString()) + ": " + Arrays.deepToString(searchGroup.sortValues));
+              }
+            }
+
+            c2 = createSecondPassCollector(c1, "group", groupSort, docSort, groupOffset, docOffset + docsPerGroup, getScores, getMaxScores, fillFields);
             if (doCache) {
               if (cCache.isCached()) {
                 if (VERBOSE) {
@@ -761,12 +910,13 @@ public class TestGrouping extends LuceneTestCase {
             }
 
             if (doAllGroups) {
-              TopGroups<BytesRef> tempTopGroups = c2.getTopGroups(docOffset);
+              TopGroups<BytesRef> tempTopGroups = getTopGroups(c2, docOffset);
               groupsResult = new TopGroups<BytesRef>(tempTopGroups, allGroupsCollector.getGroupCount());
             } else {
-              groupsResult = c2.getTopGroups(docOffset);
+              groupsResult = getTopGroups(c2, docOffset);
             }
           } else {
+            c2 = null;
             groupsResult = null;
             if (VERBOSE) {
               System.out.println("TEST:   no results");
@@ -962,10 +1112,12 @@ public class TestGrouping extends LuceneTestCase {
     // Run 1st pass collector to get top groups per shard
     final Weight w = topSearcher.createNormalizedWeight(query);
     final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<Collection<SearchGroup<BytesRef>>>();
+    List<AbstractFirstPassGroupingCollector> firstPassGroupingCollectors = new ArrayList<AbstractFirstPassGroupingCollector>();
     for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {
-      final TermFirstPassGroupingCollector c = new TermFirstPassGroupingCollector("group", groupSort, groupOffset+topNGroups);
+      final AbstractFirstPassGroupingCollector c = createRandomFirstPassCollector("group", groupSort, groupOffset+topNGroups);
+      firstPassGroupingCollectors.add(c);
       subSearchers[shardIDX].search(w, c);
-      final Collection<SearchGroup<BytesRef>> topGroups = c.getTopGroups(0, true);
+      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(c, 0, true);
       if (topGroups != null) {
         if (VERBOSE) {
           System.out.println("  shard " + shardIDX + " s=" + subSearchers[shardIDX] + " " + topGroups.size() + " groups:");
@@ -995,10 +1147,10 @@ public class TestGrouping extends LuceneTestCase {
       @SuppressWarnings("unchecked")
         final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];
       for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {
-        final TermSecondPassGroupingCollector c = new TermSecondPassGroupingCollector("group", mergedTopGroups, groupSort, docSort,
-                                                                                      docOffset + topNDocs, getScores, getMaxScores, true);
+        final AbstractSecondPassGroupingCollector c = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),
+            "group", mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);
         subSearchers[shardIDX].search(w, c);
-        shardTopGroups[shardIDX] = c.getTopGroups(0);
+        shardTopGroups[shardIDX] = getTopGroups(c, 0);
       }
 
       return TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs);
diff --git a/modules/queries/src/java/org/apache/lucene/queries/function/valuesource/BytesRefFieldSource.java b/modules/queries/src/java/org/apache/lucene/queries/function/valuesource/BytesRefFieldSource.java
new file mode 100644
index 0000000..920ac1e
--- /dev/null
+++ b/modules/queries/src/java/org/apache/lucene/queries/function/valuesource/BytesRefFieldSource.java
@@ -0,0 +1,58 @@
+package org.apache.lucene.queries.function.valuesource;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.queries.function.DocValues;
+import org.apache.lucene.queries.function.docvalues.StringIndexDocValues;
+import org.apache.lucene.queries.function.ValueSource; //javadoc
+
+import java.io.IOException;
+import java.util.Map;
+
+/**
+ * An implementation for retrieving {@link DocValues} instances for string based fields.
+ */
+public class BytesRefFieldSource extends FieldCacheSource {
+
+  public BytesRefFieldSource(String field) {
+    super(field);
+  }
+
+  @Override
+  public DocValues getValues(Map context, IndexReader.AtomicReaderContext readerContext) throws IOException {
+    return new StringIndexDocValues(this, readerContext, field) {
+
+      @Override
+      protected String toTerm(String readableValue) {
+        return readableValue;
+      }
+
+      @Override
+      public Object objectVal(int doc) {
+        return strVal(doc);
+      }
+
+      @Override
+      public String toString(int doc) {
+        return description() + '=' + strVal(doc);
+      }
+
+    };
+  }
+}
diff --git a/solr/core/src/java/org/apache/solr/request/SimpleFacets.java b/solr/core/src/java/org/apache/solr/request/SimpleFacets.java
index a99767b..5f7ca01 100644
--- a/solr/core/src/java/org/apache/solr/request/SimpleFacets.java
+++ b/solr/core/src/java/org/apache/solr/request/SimpleFacets.java
@@ -18,13 +18,9 @@
 package org.apache.solr.request;
 
 import org.apache.lucene.index.*;
-import org.apache.lucene.queries.function.FunctionQuery;
-import org.apache.lucene.queries.function.ValueSource;
-import org.apache.lucene.queries.function.valuesource.QueryValueSource;
 import org.apache.lucene.queryparser.classic.ParseException;
 import org.apache.lucene.search.*;
 import org.apache.lucene.search.grouping.AbstractAllGroupHeadsCollector;
-import org.apache.lucene.search.grouping.TermAllGroupHeadsCollector;
 import org.apache.lucene.util.*;
 import org.apache.lucene.util.packed.Direct16;
 import org.apache.lucene.util.packed.Direct32;
diff --git a/solr/core/src/java/org/apache/solr/search/Grouping.java b/solr/core/src/java/org/apache/solr/search/Grouping.java
index 32b9aa4..6e97e62 100755
--- a/solr/core/src/java/org/apache/solr/search/Grouping.java
+++ b/solr/core/src/java/org/apache/solr/search/Grouping.java
@@ -18,15 +18,21 @@
 package org.apache.solr.search;
 
 import org.apache.commons.lang.ArrayUtils;
-import org.apache.lucene.index.IndexReader.AtomicReaderContext;
 import org.apache.lucene.index.IndexableField;
-import org.apache.lucene.queries.function.DocValues;
 import org.apache.lucene.queries.function.FunctionQuery;
 import org.apache.lucene.queries.function.ValueSource;
 import org.apache.lucene.queries.function.valuesource.QueryValueSource;
 import org.apache.lucene.queryparser.classic.ParseException;
 import org.apache.lucene.search.*;
 import org.apache.lucene.search.grouping.*;
+import org.apache.lucene.search.grouping.function.FunctionAllGroupHeadsCollector;
+import org.apache.lucene.search.grouping.function.FunctionAllGroupsCollector;
+import org.apache.lucene.search.grouping.function.FunctionFirstPassGroupingCollector;
+import org.apache.lucene.search.grouping.function.FunctionSecondPassGroupingCollector;
+import org.apache.lucene.search.grouping.term.TermAllGroupHeadsCollector;
+import org.apache.lucene.search.grouping.term.TermAllGroupsCollector;
+import org.apache.lucene.search.grouping.term.TermFirstPassGroupingCollector;
+import org.apache.lucene.search.grouping.term.TermSecondPassGroupingCollector;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.OpenBitSet;
@@ -976,213 +982,4 @@ public class Grouping {
 
   }
 
-  static class FunctionFirstPassGroupingCollector extends AbstractFirstPassGroupingCollector<MutableValue> {
-
-    private final ValueSource groupByVS;
-    private final Map vsContext;
-
-    private DocValues docValues;
-    private DocValues.ValueFiller filler;
-    private MutableValue mval;
-
-    FunctionFirstPassGroupingCollector(ValueSource groupByVS, Map vsContext, Sort groupSort, int topNGroups) throws IOException {
-      super(groupSort, topNGroups);
-      this.groupByVS = groupByVS;
-      this.vsContext = vsContext;
-    }
-
-    @Override
-    protected MutableValue getDocGroupValue(int doc) {
-      filler.fillValue(doc);
-      return mval;
-    }
-
-    @Override
-    protected MutableValue copyDocGroupValue(MutableValue groupValue, MutableValue reuse) {
-      if (reuse != null) {
-        reuse.copy(groupValue);
-        return reuse;
-      }
-      return groupValue.duplicate();
-    }
-
-    @Override
-    public void setNextReader(AtomicReaderContext readerContext) throws IOException {
-      super.setNextReader(readerContext);
-      docValues = groupByVS.getValues(vsContext, readerContext);
-      filler = docValues.getValueFiller();
-      mval = filler.getValue();
-    }
-  }
-
-  static class FunctionSecondPassGroupingCollector extends AbstractSecondPassGroupingCollector<MutableValue> {
-
-    private final ValueSource groupByVS;
-    private final Map vsContext;
-
-    private DocValues docValues;
-    private DocValues.ValueFiller filler;
-    private MutableValue mval;
-
-    FunctionSecondPassGroupingCollector(Collection<SearchGroup<MutableValue>> searchGroups, Sort groupSort, Sort withinGroupSort, int maxDocsPerGroup, boolean getScores, boolean getMaxScores, boolean fillSortFields, ValueSource groupByVS, Map vsContext) throws IOException {
-      super(searchGroups, groupSort, withinGroupSort, maxDocsPerGroup, getScores, getMaxScores, fillSortFields);
-      this.groupByVS = groupByVS;
-      this.vsContext = vsContext;
-    }
-
-    /**
-     * {@inheritDoc}
-     */
-    protected SearchGroupDocs<MutableValue> retrieveGroup(int doc) throws IOException {
-      filler.fillValue(doc);
-      return groupMap.get(mval);
-    }
-
-    /**
-     * {@inheritDoc}
-     */
-    public void setNextReader(AtomicReaderContext readerContext) throws IOException {
-      super.setNextReader(readerContext);
-      docValues = groupByVS.getValues(vsContext, readerContext);
-      filler = docValues.getValueFiller();
-      mval = filler.getValue();
-    }
-  }
-
-
-  static class FunctionAllGroupsCollector extends AbstractAllGroupsCollector<MutableValue> {
-
-    private final Map vsContext;
-    private final ValueSource groupBy;
-    private final SortedSet<MutableValue> groups = new TreeSet<MutableValue>();
-
-    private DocValues docValues;
-    private DocValues.ValueFiller filler;
-    private MutableValue mval;
-
-    FunctionAllGroupsCollector(ValueSource groupBy, Map vsContext) {
-      this.vsContext = vsContext;
-      this.groupBy = groupBy;
-    }
-
-    public Collection<MutableValue> getGroups() {
-      return groups;
-    }
-
-    public void collect(int doc) throws IOException {
-      filler.fillValue(doc);
-      if (!groups.contains(mval)) {
-        groups.add(mval.duplicate());
-      }
-    }
-
-    /**
-     * {@inheritDoc}
-     */
-    public void setNextReader(AtomicReaderContext context) throws IOException {
-      docValues = groupBy.getValues(vsContext, context);
-      filler = docValues.getValueFiller();
-      mval = filler.getValue();
-    }
-
-  }
-
-
-  static class FunctionAllGroupHeadsCollector extends AbstractAllGroupHeadsCollector<FunctionAllGroupHeadsCollector.GroupHead> {
-
-    private final ValueSource groupBy;
-    private final Map vsContext;
-    private final Map<MutableValue, GroupHead> groups;
-    private final Sort sortWithinGroup;
-
-    private DocValues docValues;
-    private DocValues.ValueFiller filler;
-    private MutableValue mval;
-    private AtomicReaderContext readerContext;
-    private Scorer scorer;
-
-    FunctionAllGroupHeadsCollector(ValueSource groupBy, Map vsContext, Sort sortWithinGroup) {
-      super(sortWithinGroup.getSort().length);
-      groups = new HashMap<MutableValue, GroupHead>();
-      this.sortWithinGroup = sortWithinGroup;
-      this.groupBy = groupBy;
-      this.vsContext = vsContext;
-
-      final SortField[] sortFields = sortWithinGroup.getSort();
-      for (int i = 0; i < sortFields.length; i++) {
-        reversed[i] = sortFields[i].getReverse() ? -1 : 1;
-      }
-    }
-
-    protected void retrieveGroupHeadAndAddIfNotExist(int doc) throws IOException {
-      filler.fillValue(doc);
-      GroupHead groupHead = groups.get(mval);
-      if (groupHead == null) {
-        MutableValue groupValue = mval.duplicate();
-        groupHead = new GroupHead(groupValue, sortWithinGroup, doc);
-        groups.put(groupValue, groupHead);
-        temporalResult.stop = true;
-      } else {
-        temporalResult.stop = false;
-      }
-      this.temporalResult.groupHead = groupHead;
-    }
-
-    protected Collection<GroupHead> getCollectedGroupHeads() {
-      return groups.values();
-    }
-
-    public void setScorer(Scorer scorer) throws IOException {
-      this.scorer = scorer;
-      for (GroupHead groupHead : groups.values()) {
-        for (FieldComparator comparator : groupHead.comparators) {
-          comparator.setScorer(scorer);
-        }
-      }
-    }
-
-    public void setNextReader(AtomicReaderContext context) throws IOException {
-      this.readerContext = context;
-      docValues = groupBy.getValues(vsContext, context);
-      filler = docValues.getValueFiller();
-      mval = filler.getValue();
-
-      for (GroupHead groupHead : groups.values()) {
-        for (int i = 0; i < groupHead.comparators.length; i++) {
-          groupHead.comparators[i] = groupHead.comparators[i].setNextReader(context);
-        }
-      }
-    }
-
-    class GroupHead extends AbstractAllGroupHeadsCollector.GroupHead<MutableValue> {
-
-      final FieldComparator[] comparators;
-
-      private GroupHead(MutableValue groupValue, Sort sort, int doc) throws IOException {
-        super(groupValue, doc + readerContext.docBase);
-        final SortField[] sortFields = sort.getSort();
-        comparators = new FieldComparator[sortFields.length];
-        for (int i = 0; i < sortFields.length; i++) {
-          comparators[i] = sortFields[i].getComparator(1, i).setNextReader(readerContext);
-          comparators[i].setScorer(scorer);
-          comparators[i].copy(0, doc);
-          comparators[i].setBottom(0);
-        }
-      }
-
-      public int compare(int compIDX, int doc) throws IOException {
-        return comparators[compIDX].compareBottom(doc);
-      }
-
-      public void updateDocHead(int doc) throws IOException {
-        for (FieldComparator comparator : comparators) {
-          comparator.copy(0, doc);
-          comparator.setBottom(0);
-        }
-        this.doc = doc + readerContext.docBase;
-      }
-    }
-
-  }
-
 }
\ No newline at end of file
diff --git a/solr/core/src/java/org/apache/solr/search/grouping/CommandHandler.java b/solr/core/src/java/org/apache/solr/search/grouping/CommandHandler.java
index 337e252..d2aed91 100644
--- a/solr/core/src/java/org/apache/solr/search/grouping/CommandHandler.java
+++ b/solr/core/src/java/org/apache/solr/search/grouping/CommandHandler.java
@@ -22,8 +22,7 @@ import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.MultiCollector;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.grouping.AbstractAllGroupHeadsCollector;
-import org.apache.lucene.search.grouping.TermAllGroupHeadsCollector;
-import org.apache.lucene.util.FixedBitSet;
+import org.apache.lucene.search.grouping.term.TermAllGroupHeadsCollector;
 import org.apache.lucene.util.OpenBitSet;
 import org.apache.solr.common.util.NamedList;
 import org.apache.solr.search.*;
diff --git a/solr/core/src/java/org/apache/solr/search/grouping/distributed/command/SearchGroupsFieldCommand.java b/solr/core/src/java/org/apache/solr/search/grouping/distributed/command/SearchGroupsFieldCommand.java
index 273843f..fd618a0 100644
--- a/solr/core/src/java/org/apache/solr/search/grouping/distributed/command/SearchGroupsFieldCommand.java
+++ b/solr/core/src/java/org/apache/solr/search/grouping/distributed/command/SearchGroupsFieldCommand.java
@@ -20,7 +20,7 @@ package org.apache.solr.search.grouping.distributed.command;
 import org.apache.lucene.search.Collector;
 import org.apache.lucene.search.Sort;
 import org.apache.lucene.search.grouping.SearchGroup;
-import org.apache.lucene.search.grouping.TermFirstPassGroupingCollector;
+import org.apache.lucene.search.grouping.term.TermFirstPassGroupingCollector;
 import org.apache.lucene.util.BytesRef;
 import org.apache.solr.schema.SchemaField;
 import org.apache.solr.search.grouping.Command;
diff --git a/solr/core/src/java/org/apache/solr/search/grouping/distributed/command/TopGroupsFieldCommand.java b/solr/core/src/java/org/apache/solr/search/grouping/distributed/command/TopGroupsFieldCommand.java
index b23bd0d..17788ce 100644
--- a/solr/core/src/java/org/apache/solr/search/grouping/distributed/command/TopGroupsFieldCommand.java
+++ b/solr/core/src/java/org/apache/solr/search/grouping/distributed/command/TopGroupsFieldCommand.java
@@ -20,8 +20,8 @@ package org.apache.solr.search.grouping.distributed.command;
 import org.apache.lucene.search.Collector;
 import org.apache.lucene.search.Sort;
 import org.apache.lucene.search.grouping.SearchGroup;
-import org.apache.lucene.search.grouping.TermAllGroupsCollector;
-import org.apache.lucene.search.grouping.TermSecondPassGroupingCollector;
+import org.apache.lucene.search.grouping.term.TermAllGroupsCollector;
+import org.apache.lucene.search.grouping.term.TermSecondPassGroupingCollector;
 import org.apache.lucene.search.grouping.TopGroups;
 import org.apache.lucene.util.BytesRef;
 import org.apache.solr.schema.SchemaField;

