GitDiffStart: b323c54f6a610cc8ccd25fd8744e7a5e2343e57b | Wed Dec 21 18:05:52 2011 +0000
diff --git a/lucene/src/java/org/apache/lucene/util/SentinelIntSet.java b/lucene/src/java/org/apache/lucene/util/SentinelIntSet.java
index 6a2e62b..6ca12bc 100644
--- a/lucene/src/java/org/apache/lucene/util/SentinelIntSet.java
+++ b/lucene/src/java/org/apache/lucene/util/SentinelIntSet.java
@@ -30,6 +30,11 @@ public class SentinelIntSet {
   public final int emptyVal;
   public int rehashCount;   // the count at which a rehash should be done
 
+  /**
+   *
+   * @param size  The minimum number of elements this set should be able to hold without re-hashing (i.e. the slots are guaranteed not to change)
+   * @param emptyVal The integer value to use for EMPTY
+   */
   public SentinelIntSet(int size, int emptyVal) {
     this.emptyVal = emptyVal;
     int tsize = Math.max(org.apache.lucene.util.BitUtil.nextHighestPowerOfTwo(size), 1);
diff --git a/solr/core/src/java/org/apache/solr/handler/component/QueryElevationComponent.java b/solr/core/src/java/org/apache/solr/handler/component/QueryElevationComponent.java
index 30260dd..e87a80a 100644
--- a/solr/core/src/java/org/apache/solr/handler/component/QueryElevationComponent.java
+++ b/solr/core/src/java/org/apache/solr/handler/component/QueryElevationComponent.java
@@ -25,6 +25,7 @@ import org.apache.lucene.document.DocumentStoredFieldVisitor;
 import org.apache.lucene.index.*;
 import org.apache.lucene.index.IndexReader.AtomicReaderContext;
 import org.apache.lucene.search.*;
+import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.SentinelIntSet;
 import org.apache.lucene.util.automaton.Automaton;
@@ -518,18 +519,23 @@ public class QueryElevationComponent extends SearchComponent implements SolrCore
         //convert the ids to Lucene doc ids, the ordSet and termValues needs to be the same size as the number of elevation docs we have
         ordSet.clear();
         Fields fields = context.reader.fields();
+        if (fields == null) return this;
         Terms terms = fields.terms(fieldname);
+        if (terms == null) return this;
         termsEnum = terms.iterator(termsEnum);
         BytesRef term = new BytesRef();
+        Bits liveDocs = context.reader.getLiveDocs();
 
         for (String id : elevations.ids) {
           term.copyChars(id);
           if (seen.contains(id) == false  && termsEnum.seekExact(term, false)) {
-            docsEnum = termsEnum.docs(null, docsEnum, false);
+            docsEnum = termsEnum.docs(liveDocs, docsEnum, false);
             if (docsEnum != null) {
               int docId = docsEnum.nextDoc();
+              if (docId == DocIdSetIterator.NO_MORE_DOCS ) continue;  // must have been deleted
               termValues[ordSet.put(docId)] = BytesRef.deepCopyOf(term);
               seen.add(id);
+              assert docsEnum.nextDoc() == DocIdSetIterator.NO_MORE_DOCS;
             }
           }
         }

