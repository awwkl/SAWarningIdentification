GitDiffStart: b393e4d0af4896d51412864f0c1337e9d9906a06 | Tue Jul 14 19:44:52 2009 +0000
diff --git a/contrib/CHANGES.txt b/contrib/CHANGES.txt
index ff39273..072c44e 100644
--- a/contrib/CHANGES.txt
+++ b/contrib/CHANGES.txt
@@ -36,6 +36,9 @@ Bug fixes
     StandardTokenizer so that stop words with mixed case are filtered
     out.  (Rafael Cunha de Almeida, Douglas Campos via Mike McCandless)
 
+ 8. LUCENE-1491: EdgeNGramTokenFilter no longer stops on tokens shorter than minimum n-gram size.
+    (Todd Teak via Otis Gospodnetic)
+
 New features
 
  1. LUCENE-1531: Added support for BoostingTermQuery to XML query parser. (Karl Wettin)
diff --git a/contrib/analyzers/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter.java b/contrib/analyzers/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter.java
index 8c98fa3..7ae055c 100644
--- a/contrib/analyzers/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter.java
+++ b/contrib/analyzers/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter.java
@@ -117,19 +117,25 @@ public class EdgeNGramTokenFilter extends TokenFilter {
   /** Returns the next token in the stream, or null at EOS. */
   public final Token next(final Token reusableToken) throws IOException {
     assert reusableToken != null;
-    if (ngrams.size() > 0) {
-      return (Token) ngrams.removeFirst();
+    if (!ngrams.isEmpty()) {
+        return (Token)ngrams.removeFirst();
     }
 
-    Token nextToken = input.next(reusableToken);
-    if (nextToken == null)
-      return null;
+    Token token = null;
 
-    ngram(nextToken);
-    if (ngrams.size() > 0)
-      return (Token) ngrams.removeFirst();
-    else
-      return null;
+    while (ngrams.isEmpty() && (token = input.next()) != null) {
+        ngram(token);
+    }
+
+    if (token == null) {
+        return null;
+    }
+
+    if (!ngrams.isEmpty()) {
+        return (Token)ngrams.removeFirst();
+    } else {
+        return null;
+    }
   }
 
   private void ngram(final Token token) {
diff --git a/contrib/analyzers/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter.java b/contrib/analyzers/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter.java
index 35b02e2..761ec18 100644
--- a/contrib/analyzers/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter.java
+++ b/contrib/analyzers/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter.java
@@ -64,19 +64,25 @@ public class NGramTokenFilter extends TokenFilter {
   /** Returns the next token in the stream, or null at EOS. */
   public final Token next(final Token reusableToken) throws IOException {
     assert reusableToken != null;
-    if (ngrams.size() > 0) {
-      return (Token) ngrams.removeFirst();
+    if (!ngrams.isEmpty()) {
+        return (Token)ngrams.removeFirst();
     }
 
-    Token nextToken = input.next(reusableToken);
-    if (nextToken == null)
-      return null;
+    Token token = null;
 
-    ngram(nextToken);
-    if (ngrams.size() > 0)
-      return (Token) ngrams.removeFirst();
-    else
-      return null;
+    while (ngrams.isEmpty() && (token = input.next()) != null) {
+        ngram(token);
+    }
+
+    if (token == null) {
+        return null;
+    }
+
+    if (!ngrams.isEmpty()) {
+        return (Token)ngrams.removeFirst();
+    } else {
+        return null;
+    }
   }
 
   private void ngram(Token token) { 
diff --git a/contrib/analyzers/src/test/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilterTest.java b/contrib/analyzers/src/test/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilterTest.java
index 944c41d..cd3aefb 100644
--- a/contrib/analyzers/src/test/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilterTest.java
+++ b/contrib/analyzers/src/test/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilterTest.java
@@ -109,4 +109,16 @@ public class EdgeNGramTokenFilterTest extends TestCase {
     assertEquals("(cde,2,5)", nextToken.toString());
     assertNull(tokenizer.next(reusableToken));
   }
+  
+  public void testSmallTokenInStream() throws Exception {
+    input = new WhitespaceTokenizer(new StringReader("abc de fgh"));
+    EdgeNGramTokenFilter tokenizer = new EdgeNGramTokenFilter(input, EdgeNGramTokenFilter.Side.FRONT, 3, 3);
+    final Token reusableToken = new Token();
+    Token nextToken = tokenizer.next(reusableToken);
+    assertEquals("(abc,0,3)", nextToken.toString());
+    nextToken = tokenizer.next(reusableToken);
+    assertNotNull(nextToken);
+    assertEquals("(fgh,0,3)", nextToken.toString());
+    assertNull(tokenizer.next(reusableToken));
+  }
 }
diff --git a/contrib/analyzers/src/test/org/apache/lucene/analysis/ngram/NGramTokenFilterTest.java b/contrib/analyzers/src/test/org/apache/lucene/analysis/ngram/NGramTokenFilterTest.java
index e29dd54..e1bf624 100644
--- a/contrib/analyzers/src/test/org/apache/lucene/analysis/ngram/NGramTokenFilterTest.java
+++ b/contrib/analyzers/src/test/org/apache/lucene/analysis/ngram/NGramTokenFilterTest.java
@@ -120,4 +120,16 @@ public class NGramTokenFilterTest extends TestCase {
 
         assertTrue(tokens.isEmpty());
     }
+    
+    public void testSmallTokenInStream() throws Exception {
+      input = new WhitespaceTokenizer(new StringReader("abc de fgh"));
+      NGramTokenFilter filter = new NGramTokenFilter(input, 3, 3);
+      final Token reusableToken = new Token();
+      Token nextToken = filter.next(reusableToken);
+      assertEquals("(abc,0,3)", nextToken.toString());
+      nextToken = filter.next(reusableToken);
+      assertNotNull(nextToken);
+      assertEquals("(fgh,0,3)", nextToken.toString());
+      assertNull(filter.next(reusableToken));
+    }
 }

