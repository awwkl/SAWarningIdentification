GitDiffStart: c039f73cde9a18465f197af1747b13d71d774e06 | Wed Feb 5 19:45:46 2014 +0000
diff --git a/lucene/CHANGES.txt b/lucene/CHANGES.txt
index 9cc2445..fe2b931 100644
--- a/lucene/CHANGES.txt
+++ b/lucene/CHANGES.txt
@@ -253,6 +253,10 @@ API Changes
   responsible for encoding/decoding a block of terms.  Instead, they
   should encode/decode each term to/from a long[] and byte[].  (Han
   Jiang, Mike McCandless)
+  
+* LUCENE-5425: FacetsCollector and MatchingDocs use a general DocIdSet, 
+  allowing for custom implementations to be used when faceting.
+  (John Wang, Lei Wang, Shai Erera) 
 
 Optimizations
 
diff --git a/lucene/core/src/java/org/apache/lucene/util/FixedBitSet.java b/lucene/core/src/java/org/apache/lucene/util/FixedBitSet.java
index 99a3ee3..e763410 100644
--- a/lucene/core/src/java/org/apache/lucene/util/FixedBitSet.java
+++ b/lucene/core/src/java/org/apache/lucene/util/FixedBitSet.java
@@ -78,7 +78,68 @@ public final class FixedBitSet extends DocIdSet implements Bits {
 
   @Override
   public DocIdSetIterator iterator() {
-    return new OpenBitSetIterator(bits, wordLength);
+    // define locally so we don't have "enclosing acces" issue
+    final long[] bits = this.bits;
+    final int wordLength = this.wordLength;
+    final int numBits = this.numBits;
+    return new DocIdSetIterator() {
+      int doc = -1;
+      @Override
+      public int nextDoc() throws IOException {
+        if (doc == NO_MORE_DOCS || ++doc >= numBits) {
+          return doc = NO_MORE_DOCS;
+        }
+        int i = doc >> 6;
+        final int subIndex = doc & 0x3f;      // index within the word
+        long word = bits[i] >> subIndex;  // skip all the bits to the right of index
+
+        if (word != 0) {
+          return doc = doc + Long.numberOfTrailingZeros(word);
+        }
+
+        while (++i < wordLength) {
+          word = bits[i];
+          if (word != 0) {
+            return doc = (i << 6) + Long.numberOfTrailingZeros(word);
+          }
+        }
+
+        return doc = NO_MORE_DOCS;
+      }
+      
+      @Override
+      public int docID() {
+        return doc;
+      }
+      
+      @Override
+      public long cost() {
+        return bits.length;
+      }
+      
+      @Override
+      public int advance(int target) throws IOException {
+        if (doc == NO_MORE_DOCS || target >= numBits) {
+          return doc = NO_MORE_DOCS;
+        }
+        int i = target >> 6;
+        final int subIndex = target & 0x3f;      // index within the word
+        long word = bits[i] >> subIndex;  // skip all the bits to the right of index
+
+        if (word != 0) {
+          return doc = target + Long.numberOfTrailingZeros(word);
+        }
+
+        while (++i < wordLength) {
+          word = bits[i];
+          if (word != 0) {
+            return doc = (i << 6) + Long.numberOfTrailingZeros(word);
+          }
+        }
+
+        return doc = NO_MORE_DOCS;
+      }
+    };
   }
 
   @Override
@@ -166,7 +227,7 @@ public final class FixedBitSet extends DocIdSet implements Bits {
     long word = bits[i] >> subIndex;  // skip all the bits to the right of index
 
     if (word!=0) {
-      return (i<<6) + subIndex + Long.numberOfTrailingZeros(word);
+      return index + Long.numberOfTrailingZeros(word);
     }
 
     while(++i < wordLength) {
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/FacetsCollector.java b/lucene/facet/src/java/org/apache/lucene/facet/FacetsCollector.java
index 4f52d57..bf02d62 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/FacetsCollector.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/FacetsCollector.java
@@ -23,6 +23,7 @@ import java.util.List;
 
 import org.apache.lucene.index.AtomicReaderContext;
 import org.apache.lucene.search.Collector;
+import org.apache.lucene.search.DocIdSet;
 import org.apache.lucene.search.FieldDoc;
 import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.FilteredQuery;
@@ -46,17 +47,33 @@ import org.apache.lucene.util.FixedBitSet;
  *  counting.  Use the {@code search} utility methods to
  *  perform an "ordinary" search but also collect into a
  *  {@link Collector}. */
-public final class FacetsCollector extends Collector {
+public class FacetsCollector extends Collector {
 
   private AtomicReaderContext context;
   private Scorer scorer;
-  private FixedBitSet bits;
   private int totalHits;
   private float[] scores;
   private final boolean keepScores;
   private final List<MatchingDocs> matchingDocs = new ArrayList<MatchingDocs>();
+  private Docs docs;
   
   /**
+   * Used during collection to record matching docs and then return a
+   * {@link DocIdSet} that contains them.
+   */
+  protected static abstract class Docs {
+    
+    /** Solr constructor. */
+    public Docs() {}
+    
+    /** Record the given document. */
+    public abstract void addDoc(int docId) throws IOException;
+    
+    /** Return the {@link DocIdSet} which contains all the recorded docs. */
+    public abstract DocIdSet getDocIdSet();
+  }
+
+  /**
    * Holds the documents that were matched in the {@link AtomicReaderContext}.
    * If scores were required, then {@code scores} is not null.
    */
@@ -66,7 +83,7 @@ public final class FacetsCollector extends Collector {
     public final AtomicReaderContext context;
 
     /** Which documents were seen. */
-    public final FixedBitSet bits;
+    public final DocIdSet bits;
 
     /** Non-sparse scores array. */
     public final float[] scores;
@@ -75,7 +92,7 @@ public final class FacetsCollector extends Collector {
     public final int totalHits;
 
     /** Sole constructor. */
-    public MatchingDocs(AtomicReaderContext context, FixedBitSet bits, int totalHits, float[] scores) {
+    public MatchingDocs(AtomicReaderContext context, DocIdSet bits, int totalHits, float[] scores) {
       this.context = context;
       this.bits = bits;
       this.scores = scores;
@@ -93,9 +110,30 @@ public final class FacetsCollector extends Collector {
   public FacetsCollector(boolean keepScores) {
     this.keepScores = keepScores;
   }
+  
+  /**
+   * Creates a {@link Docs} to record hits. The default uses {@link FixedBitSet}
+   * to record hits and you can override to e.g. record the docs in your own
+   * {@link DocIdSet}.
+   */
+  protected Docs createDocs(final int maxDoc) {
+    return new Docs() {
+      private final FixedBitSet bits = new FixedBitSet(maxDoc);
+      
+      @Override
+      public void addDoc(int docId) throws IOException {
+        bits.set(docId);
+      }
+      
+      @Override
+      public DocIdSet getDocIdSet() {
+        return bits;
+      }
+    };
+  }
 
   /** True if scores were saved. */
-  public boolean getKeepScores() {
+  public final boolean getKeepScores() {
     return keepScores;
   }
   
@@ -104,9 +142,9 @@ public final class FacetsCollector extends Collector {
    * visited segment.
    */
   public List<MatchingDocs> getMatchingDocs() {
-    if (bits != null) {
-      matchingDocs.add(new MatchingDocs(this.context, bits, totalHits, scores));
-      bits = null;
+    if (docs != null) {
+      matchingDocs.add(new MatchingDocs(this.context, docs.getDocIdSet(), totalHits, scores));
+      docs = null;
       scores = null;
       context = null;
     }
@@ -124,7 +162,7 @@ public final class FacetsCollector extends Collector {
 
   @Override
   public final void collect(int doc) throws IOException {
-    bits.set(doc);
+    docs.addDoc(doc);
     if (keepScores) {
       if (totalHits >= scores.length) {
         float[] newScores = new float[ArrayUtil.oversize(totalHits + 1, 4)];
@@ -143,10 +181,10 @@ public final class FacetsCollector extends Collector {
     
   @Override
   public final void setNextReader(AtomicReaderContext context) throws IOException {
-    if (bits != null) {
-      matchingDocs.add(new MatchingDocs(this.context, bits, totalHits, scores));
+    if (docs != null) {
+      matchingDocs.add(new MatchingDocs(this.context, docs.getDocIdSet(), totalHits, scores));
     }
-    bits = new FixedBitSet(context.reader().maxDoc());
+    docs = createDocs(context.reader().maxDoc());
     totalHits = 0;
     if (keepScores) {
       scores = new float[64]; // some initial size
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/range/DoubleRangeFacetCounts.java b/lucene/facet/src/java/org/apache/lucene/facet/range/DoubleRangeFacetCounts.java
index dac45d0..a804187 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/range/DoubleRangeFacetCounts.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/range/DoubleRangeFacetCounts.java
@@ -30,6 +30,7 @@ import org.apache.lucene.queries.function.FunctionValues;
 import org.apache.lucene.queries.function.ValueSource;
 import org.apache.lucene.queries.function.valuesource.DoubleFieldSource;
 import org.apache.lucene.queries.function.valuesource.FloatFieldSource; // javadocs
+import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.util.NumericUtils;
 
 /** {@link Facets} implementation that computes counts for
@@ -81,17 +82,18 @@ public class DoubleRangeFacetCounts extends RangeFacetCounts {
     int missingCount = 0;
     for (MatchingDocs hits : matchingDocs) {
       FunctionValues fv = valueSource.getValues(Collections.emptyMap(), hits.context);
-      final int length = hits.bits.length();
-      int doc = 0;
+      
       totCount += hits.totalHits;
-      while (doc < length && (doc = hits.bits.nextSetBit(doc)) != -1) {
+      DocIdSetIterator docs = hits.bits.iterator();
+      
+      int doc;
+      while ((doc = docs.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
         // Skip missing docs:
         if (fv.exists(doc)) {
           counter.add(NumericUtils.doubleToSortableLong(fv.doubleVal(doc)));
         } else {
           missingCount++;
         }
-        doc++;
       }
     }
 
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/range/LongRangeFacetCounts.java b/lucene/facet/src/java/org/apache/lucene/facet/range/LongRangeFacetCounts.java
index a0c807d..2244137 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/range/LongRangeFacetCounts.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/range/LongRangeFacetCounts.java
@@ -27,6 +27,7 @@ import org.apache.lucene.facet.FacetsCollector.MatchingDocs;
 import org.apache.lucene.queries.function.FunctionValues;
 import org.apache.lucene.queries.function.ValueSource;
 import org.apache.lucene.queries.function.valuesource.LongFieldSource;
+import org.apache.lucene.search.DocIdSetIterator;
 
 /** {@link Facets} implementation that computes counts for
  *  dynamic long ranges from a provided {@link ValueSource},
@@ -62,18 +63,17 @@ public class LongRangeFacetCounts extends RangeFacetCounts {
     int missingCount = 0;
     for (MatchingDocs hits : matchingDocs) {
       FunctionValues fv = valueSource.getValues(Collections.emptyMap(), hits.context);
-      final int length = hits.bits.length();
-      int doc = 0;
+      
       totCount += hits.totalHits;
-      while (doc < length && (doc = hits.bits.nextSetBit(doc)) != -1) {
+      DocIdSetIterator docs = hits.bits.iterator();      
+      int doc;
+      while ((doc = docs.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
         // Skip missing docs:
         if (fv.exists(doc)) {
           counter.add(fv.longVal(doc));
         } else {
           missingCount++;
         }
-
-        doc++;
       }
     }
     
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/sortedset/SortedSetDocValuesFacetCounts.java b/lucene/facet/src/java/org/apache/lucene/facet/sortedset/SortedSetDocValuesFacetCounts.java
index a8fcfc6..7a40fcf 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/sortedset/SortedSetDocValuesFacetCounts.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/sortedset/SortedSetDocValuesFacetCounts.java
@@ -38,6 +38,7 @@ import org.apache.lucene.index.MultiDocValues;
 import org.apache.lucene.index.MultiDocValues.MultiSortedSetDocValues;
 import org.apache.lucene.index.ReaderUtil;
 import org.apache.lucene.index.SortedSetDocValues;
+import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.util.BytesRef;
 
 /** Compute facets counts from previously
@@ -175,9 +176,7 @@ public class SortedSetDocValuesFacetCounts extends Facets {
         continue;
       }
 
-      final int maxDoc = reader.maxDoc();
-      assert maxDoc == hits.bits.length();
-      //System.out.println("  dv=" + dv);
+      DocIdSetIterator docs = hits.bits.iterator();
 
       // TODO: yet another option is to count all segs
       // first, only in seg-ord space, and then do a
@@ -196,8 +195,8 @@ public class SortedSetDocValuesFacetCounts extends Facets {
         if (hits.totalHits < numSegOrds/10) {
           //System.out.println("    remap as-we-go");
           // Remap every ord to global ord as we iterate:
-          int doc = 0;
-          while (doc < maxDoc && (doc = hits.bits.nextSetBit(doc)) != -1) {
+          int doc;
+          while ((doc = docs.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
             //System.out.println("    doc=" + doc);
             segValues.setDocument(doc);
             int term = (int) segValues.nextOrd();
@@ -206,15 +205,14 @@ public class SortedSetDocValuesFacetCounts extends Facets {
               counts[(int) ordinalMap.getGlobalOrd(segOrd, term)]++;
               term = (int) segValues.nextOrd();
             }
-            ++doc;
           }
         } else {
           //System.out.println("    count in seg ord first");
 
           // First count in seg-ord space:
           final int[] segCounts = new int[numSegOrds];
-          int doc = 0;
-          while (doc < maxDoc && (doc = hits.bits.nextSetBit(doc)) != -1) {
+          int doc;
+          while ((doc = docs.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
             //System.out.println("    doc=" + doc);
             segValues.setDocument(doc);
             int term = (int) segValues.nextOrd();
@@ -223,7 +221,6 @@ public class SortedSetDocValuesFacetCounts extends Facets {
               segCounts[term]++;
               term = (int) segValues.nextOrd();
             }
-            ++doc;
           }
 
           // Then, migrate to global ords:
@@ -238,16 +235,14 @@ public class SortedSetDocValuesFacetCounts extends Facets {
       } else {
         // No ord mapping (e.g., single segment index):
         // just aggregate directly into counts:
-
-        int doc = 0;
-        while (doc < maxDoc && (doc = hits.bits.nextSetBit(doc)) != -1) {
+        int doc;
+        while ((doc = docs.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
           segValues.setDocument(doc);
           int term = (int) segValues.nextOrd();
           while (term != SortedSetDocValues.NO_MORE_ORDS) {
             counts[term]++;
             term = (int) segValues.nextOrd();
           }
-          ++doc;
         }
       }
     }
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/FastTaxonomyFacetCounts.java b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/FastTaxonomyFacetCounts.java
index bfe276d..dae4435 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/FastTaxonomyFacetCounts.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/FastTaxonomyFacetCounts.java
@@ -21,11 +21,11 @@ import java.io.IOException;
 import java.util.List;
 
 import org.apache.lucene.facet.FacetsCollector;
-import org.apache.lucene.facet.FacetsConfig;
 import org.apache.lucene.facet.FacetsCollector.MatchingDocs;
+import org.apache.lucene.facet.FacetsConfig;
 import org.apache.lucene.index.BinaryDocValues;
+import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.FixedBitSet;
 
 /** Computes facets counts, assuming the default encoding
  *  into DocValues was used.
@@ -55,12 +55,12 @@ public class FastTaxonomyFacetCounts extends IntTaxonomyFacets {
       if (dv == null) { // this reader does not have DocValues for the requested category list
         continue;
       }
-      FixedBitSet bits = hits.bits;
-    
-      final int length = hits.bits.length();
-      int doc = 0;
+      
       BytesRef scratch = new BytesRef();
-      while (doc < length && (doc = bits.nextSetBit(doc)) != -1) {
+      DocIdSetIterator docs = hits.bits.iterator();
+      
+      int doc;
+      while ((doc = docs.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
         dv.get(doc, scratch);
         byte[] bytes = scratch.bytes;
         int end = scratch.offset + scratch.length;
@@ -77,7 +77,6 @@ public class FastTaxonomyFacetCounts extends IntTaxonomyFacets {
             ord = (ord << 7) | (b & 0x7F);
           }
         }
-        ++doc;
       }
     }
 
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/TaxonomyFacetCounts.java b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/TaxonomyFacetCounts.java
index 7eae584..cbb7491 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/TaxonomyFacetCounts.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/TaxonomyFacetCounts.java
@@ -24,7 +24,7 @@ import org.apache.lucene.facet.FacetsCollector;
 import org.apache.lucene.facet.FacetsCollector.MatchingDocs;
 import org.apache.lucene.facet.FacetsConfig;
 import org.apache.lucene.index.BinaryDocValues;
-import org.apache.lucene.util.FixedBitSet;
+import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.util.IntsRef;
 
 /** Reads from any {@link OrdinalsReader}; use {@link
@@ -49,16 +49,14 @@ public class TaxonomyFacetCounts extends IntTaxonomyFacets {
     IntsRef scratch  = new IntsRef();
     for(MatchingDocs hits : matchingDocs) {
       OrdinalsReader.OrdinalsSegmentReader ords = ordinalsReader.getReader(hits.context);
-      FixedBitSet bits = hits.bits;
-    
-      final int length = hits.bits.length();
-      int doc = 0;
-      while (doc < length && (doc = bits.nextSetBit(doc)) != -1) {
+      DocIdSetIterator docs = hits.bits.iterator();
+      
+      int doc;
+      while ((doc = docs.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
         ords.get(doc, scratch);
         for(int i=0;i<scratch.length;i++) {
           values[scratch.ints[scratch.offset+i]]++;
         }
-        ++doc;
       }
     }
 
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/TaxonomyFacetSumFloatAssociations.java b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/TaxonomyFacetSumFloatAssociations.java
index b9ca10b..4f27b3d 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/TaxonomyFacetSumFloatAssociations.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/TaxonomyFacetSumFloatAssociations.java
@@ -21,11 +21,11 @@ import java.io.IOException;
 import java.util.List;
 
 import org.apache.lucene.facet.FacetsCollector;
-import org.apache.lucene.facet.FacetsConfig;
 import org.apache.lucene.facet.FacetsCollector.MatchingDocs;
+import org.apache.lucene.facet.FacetsConfig;
 import org.apache.lucene.index.BinaryDocValues;
+import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.FixedBitSet;
 
 /** Aggregates sum of int values previously indexed with
  *  {@link FloatAssociationFacetField}, assuming the default
@@ -54,13 +54,12 @@ public class TaxonomyFacetSumFloatAssociations extends FloatTaxonomyFacets {
       if (dv == null) { // this reader does not have DocValues for the requested category list
         continue;
       }
-      FixedBitSet bits = hits.bits;
     
-      final int length = hits.bits.length();
-      int doc = 0;
       BytesRef scratch = new BytesRef();
-      //System.out.println("count seg=" + hits.context.reader());
-      while (doc < length && (doc = bits.nextSetBit(doc)) != -1) {
+      DocIdSetIterator docs = hits.bits.iterator();
+      
+      int doc;
+      while ((doc = docs.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
         //System.out.println("  doc=" + doc);
         // TODO: use OrdinalsReader?  we'd need to add a
         // BytesRef getAssociation()?
@@ -81,7 +80,6 @@ public class TaxonomyFacetSumFloatAssociations extends FloatTaxonomyFacets {
           offset += 4;
           values[ord] += Float.intBitsToFloat(value);
         }
-        ++doc;
       }
     }
 
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/TaxonomyFacetSumIntAssociations.java b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/TaxonomyFacetSumIntAssociations.java
index 801e6f6..03a0e85 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/TaxonomyFacetSumIntAssociations.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/TaxonomyFacetSumIntAssociations.java
@@ -21,11 +21,11 @@ import java.io.IOException;
 import java.util.List;
 
 import org.apache.lucene.facet.FacetsCollector;
-import org.apache.lucene.facet.FacetsConfig;
 import org.apache.lucene.facet.FacetsCollector.MatchingDocs;
+import org.apache.lucene.facet.FacetsConfig;
 import org.apache.lucene.index.BinaryDocValues;
+import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.FixedBitSet;
 
 /** Aggregates sum of int values previously indexed with
  *  {@link IntAssociationFacetField}, assuming the default
@@ -54,13 +54,12 @@ public class TaxonomyFacetSumIntAssociations extends IntTaxonomyFacets {
       if (dv == null) { // this reader does not have DocValues for the requested category list
         continue;
       }
-      FixedBitSet bits = hits.bits;
-    
-      final int length = hits.bits.length();
-      int doc = 0;
+      
       BytesRef scratch = new BytesRef();
-      //System.out.println("count seg=" + hits.context.reader());
-      while (doc < length && (doc = bits.nextSetBit(doc)) != -1) {
+      DocIdSetIterator docs = hits.bits.iterator();
+      
+      int doc;
+      while ((doc = docs.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
         //System.out.println("  doc=" + doc);
         // TODO: use OrdinalsReader?  we'd need to add a
         // BytesRef getAssociation()?
@@ -81,7 +80,6 @@ public class TaxonomyFacetSumIntAssociations extends IntTaxonomyFacets {
           offset += 4;
           values[ord] += value;
         }
-        ++doc;
       }
     }
 
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/TaxonomyFacetSumValueSource.java b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/TaxonomyFacetSumValueSource.java
index 3644d81..bb04db1 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/TaxonomyFacetSumValueSource.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/TaxonomyFacetSumValueSource.java
@@ -29,8 +29,8 @@ import org.apache.lucene.index.AtomicReaderContext;
 import org.apache.lucene.queries.function.FunctionValues;
 import org.apache.lucene.queries.function.ValueSource;
 import org.apache.lucene.queries.function.docvalues.DoubleDocValues;
+import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.search.Scorer;
-import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.IntsRef;
 
 /** Aggregates sum of values from {@link
@@ -81,15 +81,15 @@ public class TaxonomyFacetSumValueSource extends FloatTaxonomyFacets {
     IntsRef scratch = new IntsRef();
     for(MatchingDocs hits : matchingDocs) {
       OrdinalsReader.OrdinalsSegmentReader ords = ordinalsReader.getReader(hits.context);
-      FixedBitSet bits = hits.bits;
-    
-      final int length = hits.bits.length();
-      int doc = 0;
+      
       int scoresIdx = 0;
       float[] scores = hits.scores;
 
       FunctionValues functionValues = valueSource.getValues(context, hits.context);
-      while (doc < length && (doc = bits.nextSetBit(doc)) != -1) {
+      DocIdSetIterator docs = hits.bits.iterator();
+      
+      int doc;
+      while ((doc = docs.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
         ords.get(doc, scratch);
         if (keepScores) {
           scorer.docID = doc;
@@ -99,7 +99,6 @@ public class TaxonomyFacetSumValueSource extends FloatTaxonomyFacets {
         for(int i=0;i<scratch.length;i++) {
           values[scratch.ints[i]] += value;
         }
-        ++doc;
       }
     }
 

