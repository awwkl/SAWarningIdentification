GitDiffStart: 5fd5169a6f820f60fc3331a56eadc334557d499e | Fri May 6 00:31:11 2005 +0000
diff --git a/contrib/WordNet/README.txt b/contrib/WordNet/README.txt
deleted file mode 100644
index 55266d8..0000000
--- a/contrib/WordNet/README.txt
+++ /dev/null
@@ -1,5 +0,0 @@
-As of 2002-11-13 WordNet Lucene contribution contains a single Java class:
-	org.apache.lucene.wordnet.Syns2Index.
-
-This class creates a Lucene index with synonyms for English words from
-a Prolog file, which is a part of WordNet database.
diff --git a/contrib/WordNet/build.xml b/contrib/WordNet/build.xml
deleted file mode 100644
index ae3b0c8..0000000
--- a/contrib/WordNet/build.xml
+++ /dev/null
@@ -1,73 +0,0 @@
-<?xml version="1.0"?>
-
-<project name="wordnet" default="default">
-
-  <description>
-    WordNet
-  </description>
-
-  <property name="prolog.file" location="prologwn/wn_s.pl"/>
-  <property name="synindex.dir" location="index"/>
-
-  <available property="synindex.exists" file="${synindex.dir}" type="dir"/>
-
-  <import file="../contrib-build.xml"/>
-
-  <target name="index" depends="compile" description="Build WordNet index">
-    <fail if="synindex.exists">
-      Index already exists - must remove first.
-    </fail>
-
-    <java classname="org.apache.lucene.wordnet.Syns2Index">
-      <classpath>
-        <path refid="compile.classpath"/>
-        <pathelement location="${build.dir}/classes"/>
-      </classpath>
-
-      <arg file="${prolog.file}"/>
-      <arg file="${synindex.dir}"/>
-    </java>
-  </target>
-
-
-  <target name="synonym" description="Find synonyms for word">
-    <fail unless="synindex.exists">
-      Index does not exist.
-    </fail>
-
-    <fail unless="word">
-      Must specify 'word' property.
-    </fail>
-    
-    <java classname="org.apache.lucene.wordnet.SynLookup">
-      <classpath>
-        <path refid="compile.classpath"/>
-        <pathelement location="${build.dir}/classes"/>
-      </classpath>
-
-      <arg file="${synindex.dir}"/>
-      <arg value="${word}"/>
-    </java>
-  </target>
-
-  <target name="expand" description="Perform synonym expansion on a query">
-    <fail unless="synindex.exists">
-      Index does not exist.
-    </fail>
-
-    <fail unless="query">
-      Must specify 'query' property.
-    </fail>
-    
-    <java classname="org.apache.lucene.wordnet.SynExpand">
-      <classpath>
-        <path refid="compile.classpath"/>
-        <pathelement location="${build.dir}/classes"/>
-      </classpath>
-
-      <arg file="${synindex.dir}"/>
-      <arg value="${query}"/>
-    </java>
-  </target>
-
-</project>
diff --git a/contrib/WordNet/src/java/org/apache/lucene/wordnet/SynExpand.java b/contrib/WordNet/src/java/org/apache/lucene/wordnet/SynExpand.java
deleted file mode 100755
index fa05929..0000000
--- a/contrib/WordNet/src/java/org/apache/lucene/wordnet/SynExpand.java
+++ /dev/null
@@ -1,127 +0,0 @@
-package org.apache.lucene.wordnet;
-
-import org.apache.lucene.store.*;
-import org.apache.lucene.search.*;
-import org.apache.lucene.index.*;
-import org.apache.lucene.document.*;
-import org.apache.lucene.analysis.*;
-import org.apache.lucene.analysis.standard.*;
-import java.io.*;
-import java.util.*;
-
-
-/**
- * Expand a query by looking up synonyms for every term.
- * You need to invoke {@link Syns2Index} first to build the synonym index.
- *
- * @see Syns2Index
- */
-public final class SynExpand {
-
-	/**
-	 * Test driver for synonym expansion.
-	 * Uses boost factor of 0.9 for illustrative purposes.
-	 *
-	 * If you pass in the query "big dog" then it prints out:
-	 *
-	 * <code><pre>
-	 * Query: big adult^0.9 bad^0.9 bighearted^0.9 boastful^0.9 boastfully^0.9 bounteous^0.9 bountiful^0.9 braggy^0.9 crowing^0.9 freehanded^0.9 giving^0.9 grown^0.9 grownup^0.9 handsome^0.9 large^0.9 liberal^0.9 magnanimous^0.9 momentous^0.9 openhanded^0.9 prominent^0.9 swelled^0.9 vainglorious^0.9 vauntingly^0.9
-	 * dog andiron^0.9 blackguard^0.9 bounder^0.9 cad^0.9 chase^0.9 click^0.9 detent^0.9 dogtooth^0.9 firedog^0.9 frank^0.9 frankfurter^0.9 frump^0.9 heel^0.9 hotdog^0.9 hound^0.9 pawl^0.9 tag^0.9 tail^0.9 track^0.9 trail^0.9 weenie^0.9 wiener^0.9 wienerwurst^0.9
-	 * </pre></code>
-	 */
-	public static void main(String[] args) throws IOException
-	{
-		if (args.length != 2)
-		{
-			System.out.println(
-							   "java org.apache.lucene.wordnet.SynExpand <index path> <query>");
-		}
-
-		FSDirectory directory = FSDirectory.getDirectory(args[0], false);
-		IndexSearcher searcher = new IndexSearcher(directory);
-
-		String query = args[1];
-		String field = "contents";
-
-		Query q = expand( query, searcher, new StandardAnalyzer(), field, 0.9f);
-		System.out.println( "Query: " + q.toString( field));
-
-
-
-		searcher.close();
-		directory.close();
-	}
-
-
-	/**
-	 * Perform synonym expansion on a query.
-	 *
-	 * @param query users query that is assumed to not have any "special" query syntax, thus it should be just normal words, so "big dog" makes sense, but a query like "title:foo^1.2" doesn't as this should presumably be passed directly to the default query parser.
-	 *
-	 * @param syns a opened to the Lucene index you previously created with {@link Syns2Index}. The searcher is not closed or otherwise altered.
-	 *
-	 * @param a optional analyzer used to parse the users query else {@link StandardAnalyzer} is used
-	 *
-	 * @param field optional field name to search in or null if you want the default of "contents"
-	 *
-	 * @param boost optional boost applied to synonyms else no boost is applied
-	 *
-	 * @return the expanded Query
-	 */ 
-	public static Query expand( String query,
-								Searcher syns,
-								Analyzer a,
-								String field,
-								float boost)
-		throws IOException
-	{
-		Set already = new HashSet(); // avoid dups 
-		List top = new LinkedList(); // needs to be separately listed..
-		if ( field == null) field = "contents";
-		if ( a == null) a = new StandardAnalyzer();
-
-		// [1] Parse query into separate words so that when we expand we can avoid dups
-		TokenStream ts = a.tokenStream( field, new StringReader( query));
-		org.apache.lucene.analysis.Token t;
-		while ( (t = ts.next()) != null)
-		{
-			String word = t.termText();
-			if ( already.add( word))
-				top.add( word);
-		}
-		BooleanQuery tmp = new BooleanQuery();
-		
-		// [2] form query
-		Iterator it = top.iterator();
-		while ( it.hasNext())
-		{
-			// [2a] add to level words in
-			String word = (String) it.next();
-			TermQuery tq = new TermQuery( new Term( field, word));
-			tmp.add( tq, BooleanClause.Occur.SHOULD);
-
-			// [2b] add in unique synonums
-			Hits hits = syns.search( new TermQuery( new Term(Syns2Index.F_WORD, word)));
-			for (int i = 0; i < hits.length(); i++)
-			{
-				Document doc = hits.doc(i);
-				String[] values = doc.getValues( Syns2Index.F_SYN);
-				for ( int j = 0; j < values.length; j++)
-				{
-					String syn = values[ j];
-					if ( already.add( syn)) // avoid dups of top level words and synonyms
-					{
-						tq = new TermQuery( new Term( field, syn));
-						if ( boost > 0) // else keep normal 1.0
-							tq.setBoost( boost);
-						tmp.add( tq, BooleanClause.Occur.SHOULD); 
-					}
-				}
-			}
-		}
-
-
-		return tmp;
-	}
-								
-}
diff --git a/contrib/WordNet/src/java/org/apache/lucene/wordnet/SynLookup.java b/contrib/WordNet/src/java/org/apache/lucene/wordnet/SynLookup.java
deleted file mode 100644
index 887afd5..0000000
--- a/contrib/WordNet/src/java/org/apache/lucene/wordnet/SynLookup.java
+++ /dev/null
@@ -1,114 +0,0 @@
-package org.apache.lucene.wordnet;
-
-import org.apache.lucene.store.*;
-import org.apache.lucene.search.*;
-import org.apache.lucene.index.*;
-import org.apache.lucene.document.*;
-import org.apache.lucene.analysis.*;
-import java.io.*;
-import java.util.*;
-
-
-/**
- * Test program to look up synonyms.
- */
-public class SynLookup {
-
-	public static void main(String[] args) throws IOException {
-		if (args.length != 2) {
-			System.out.println(
-							   "java org.apache.lucene.wordnet.SynLookup <index path> <word>");
-		}
-
-		FSDirectory directory = FSDirectory.getDirectory(args[0], false);
-		IndexSearcher searcher = new IndexSearcher(directory);
-
-		String word = args[1];
-		Hits hits = searcher.search(
-									new TermQuery(new Term(Syns2Index.F_WORD, word)));
-
-		if (hits.length() == 0) {
-			System.out.println("No synonyms found for " + word);
-		} else {
-			System.out.println("Synonyms found for \"" + word + "\":");
-		}
-
-		for (int i = 0; i < hits.length(); i++) {
-			Document doc = hits.doc(i);
-
-			String[] values = doc.getValues(Syns2Index.F_SYN);
-
-			for (int j = 0; j < values.length; j++) {
-				System.out.println(values[j]);
-			}
-		}
-
-		searcher.close();
-		directory.close();
-	}
-
-
-	/**
-	 * Perform synonym expansion on a query.
-	 *
-	 * @param query
-	 * @param syns
-	 * @param a
-	 * @param field
-	 * @param boost
-	 */ 
-	public static Query expand( String query,
-								Searcher syns,
-								Analyzer a,
-								String field,
-								float boost)
-		throws IOException
-	{
-		Set already = new HashSet(); // avoid dups		
-		List top = new LinkedList(); // needs to be separately listed..
-
-		// [1] Parse query into separate words so that when we expand we can avoid dups
-		TokenStream ts = a.tokenStream( field, new StringReader( query));
-		org.apache.lucene.analysis.Token t;
-		while ( (t = ts.next()) != null)
-		{
-			String word = t.termText();
-			if ( already.add( word))
-				top.add( word);
-		}
-		BooleanQuery tmp = new BooleanQuery();
-		
-		// [2] form query
-		Iterator it = top.iterator();
-		while ( it.hasNext())
-		{
-			// [2a] add to level words in
-			String word = (String) it.next();
-			TermQuery tq = new TermQuery( new Term( field, word));
-			tmp.add( tq, BooleanClause.Occur.SHOULD);
-
-			// [2b] add in unique synonums
-			Hits hits = syns.search( new TermQuery( new Term(Syns2Index.F_WORD, word)));
-			for (int i = 0; i < hits.length(); i++)
-			{
-				Document doc = hits.doc(i);
-				String[] values = doc.getValues( Syns2Index.F_SYN);
-				for ( int j = 0; j < values.length; j++)
-				{
-					String syn = values[ j];
-					if ( already.add( syn))
-					{
-						tq = new TermQuery( new Term( field, syn));
-						if ( boost > 0) // else keep normal 1.0
-							tq.setBoost( boost);
-						tmp.add( tq, BooleanClause.Occur.SHOULD); 
-					}
-				}
-			}
-		}
-
-
-		return tmp;
-	}
-								
-}
diff --git a/contrib/WordNet/src/java/org/apache/lucene/wordnet/Syns2Index.java b/contrib/WordNet/src/java/org/apache/lucene/wordnet/Syns2Index.java
deleted file mode 100644
index 56e3dfd..0000000
--- a/contrib/WordNet/src/java/org/apache/lucene/wordnet/Syns2Index.java
+++ /dev/null
@@ -1,301 +0,0 @@
-package org.apache.lucene.wordnet;
-
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.standard.StandardAnalyzer;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.index.IndexWriter;
-
-import java.io.BufferedReader;
-import java.io.BufferedOutputStream;
-import java.io.FileOutputStream;
-import java.io.File;
-import java.io.PrintStream;
-import java.io.FileInputStream;
-import java.io.InputStreamReader;
-import java.util.HashMap;
-import java.util.Iterator;
-import java.util.LinkedList;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
-import java.util.TreeSet;
-import java.util.TreeMap;
-
-/**
- * Convert the prolog file wn_s.pl from the <a href="http://www.cogsci.princeton.edu/2.0/WNprolog-2.0.tar.gz">WordNet prolog download</a>
- * into a Lucene index suitable for looking up synonyms and performing query expansion ({@link SynExpand#expand SynExpand.expand(...)}).
- *
- * This has been tested with WordNet 2.0.
- *
- * The index has fields named "word" ({@link #F_WORD})
- * and "syn" ({@link #F_SYN}).
- * <p>
- * The source word (such as 'big') can be looked up in the
- * "word" field, and if present there will be fields named "syn"
- * for every synonym. What's tricky here is that there could be <b>multiple</b>
- * fields with the same name, in the general case for words that have multiple synonyms.
- * That's not a problem with Lucene, you just use {@link org.apache.lucene.document.Document#getValues}
- * </p>
- * <p>
- * While the WordNet file distinguishes groups of synonyms with
- * related meanings we don't do that here.
- * </p>
- *
- * This can take 4 minutes to execute and build an index on a "fast" system and the index takes up almost 3 MB.
- *
- * @author Dave Spencer, dave&#064;searchmorph.com
- * @see <a href="http://www.cogsci.princeton.edu/~wn/">WordNet home page</a>
- * @see <a href="http://www.cogsci.princeton.edu/~wn/man/prologdb.5WN.html">prologdb man page</a>
- * @see <a href="http://www.hostmon.com/rfc/advanced.jsp">sample site that uses it</a>
- */
-public class Syns2Index
-{
-	/**
-	 *
-	 */
-	private static final PrintStream o = System.out;
-
-	/**
-	 *
-	 */
-	private static final PrintStream err = System.err;
-	
-	/**
-	 *
-	 */
-	public static final String F_SYN = "syn";
-
-	/**
-	 *
-	 */
-	public static final String F_WORD = "word";
-
-	/**
-	 *
-	 */
-    private static final Analyzer ana = new StandardAnalyzer();
-
-    /**
-     * Takes arg of prolog file name and index directory.
-     */
-    public static void main(String[] args)
-        throws Throwable
-    {
-        // get command line arguments
-        String prologFilename = null; // name of file "wn_s.pl"
-        String indexDir = null;
-        if (args.length == 2)
-        {
-            prologFilename = args[0];
-            indexDir = args[1];
-        }
-        else
-        {
-            usage();
-            System.exit(1);
-        }
-
-        // ensure that the prolog file is readable
-        if (! (new File(prologFilename)).canRead())
-        {
-            err.println("Error: cannot read Prolog file: " + prologFilename);
-            System.exit(1);
-        }
-        // exit if the target index directory already exists
-        if ((new File(indexDir)).isDirectory())
-        {
-            err.println("Error: index directory already exists: " + indexDir);
-            err.println("Please specify a name of a non-existent directory");
-            System.exit(1);
-        }
-
-        o.println("Opening Prolog file " + prologFilename);
-        final FileInputStream fis = new FileInputStream(prologFilename);
-        final BufferedReader br = new BufferedReader(new InputStreamReader(fis));
-        String line;
-
-        // maps a word to all the "groups" it's in
-        final Map word2Nums = new TreeMap();
-        // maps a group to all the words in it
-        final Map num2Words = new TreeMap();
-        // number of rejected words
-        int ndecent = 0;
-
-        // status output
-        int mod = 1;
-        int row = 1;
-        // parse prolog file
-		o.println( "[1/2] Parsing " + prologFilename);
-        while ((line = br.readLine()) != null)
-        {
-            // occasional progress
-            if ((++row) % mod == 0) // periodically print out line we read in
-            {
-                mod *= 2;
-                o.println("\t" + row + " " + line + " " + word2Nums.size()
-                    + " " + num2Words.size() + " ndecent=" + ndecent);
-            }
-
-            // syntax check
-            if (! line.startsWith("s("))
-            {
-                err.println("OUCH: " + line);
-                System.exit(1);
-            }
-
-            // parse line
-            line = line.substring(2);
-            int comma = line.indexOf(',');
-            String num = line.substring(0, comma);
-            int q1 = line.indexOf('\'');
-            line = line.substring(q1 + 1);
-            int q2 = line.indexOf('\'');
-            String word = line.substring(0, q2).toLowerCase();
-
-            // make sure is a normal word
-            if (! isDecent(word))
-            {
-                ndecent++;
-                continue; // don't store words w/ spaces
-            }
-
-            // 1/2: word2Nums map
-            // append to entry or add new one
-            List lis =(List) word2Nums.get(word);
-            if (lis == null)
-            {
-                lis = new LinkedList();
-                lis.add(num);
-                word2Nums.put(word, lis);
-            }
-            else
-                lis.add(num);
-
-            // 2/2: num2Words map
-            lis = (List) num2Words.get(num);
-            if (lis == null)
-            {
-                lis = new LinkedList();
-                lis.add(word);
-                num2Words.put(num, lis);
-            }
-            else
-                lis.add(word);
-        }
-
-        // close the streams
-        fis.close();
-        br.close();
-
-        // create the index
-		o.println( "[2/2] Building index to store synonyms, " +
-				   " map sizes are " + word2Nums.size() + " and " + num2Words.size());
-        index(indexDir, word2Nums, num2Words);
-    }
-
-    /**
-     * Checks to see if a word contains only alphabetic characters by
-     * checking it one character at a time.
-     *
-     * @param s string to check
-     * @return <code>true</code> if the string is decent
-     */
-    private static boolean isDecent(String s)
-    {
-        int len = s.length();
-        for (int i = 0; i < len; i++)
-        {
-            if (!Character.isLetter(s.charAt(i)))
-            {
-                return false;
-            }
-        }
-        return true;
-    }
-
-    /**
-     * Forms a Lucene index based on the 2 maps.
-     *
-     * @param indexDir the direcotry where the index should be created
-     * @param word2Nums
-     * @param num2Words
-     */
-    private static void index(String indexDir, Map word2Nums, Map num2Words)
-        throws Throwable
-    {
-        int row = 0;
-        int mod = 1;
-
-        // override the specific index if it already exists
-        IndexWriter writer = new IndexWriter(indexDir, ana, true);
-        writer.setUseCompoundFile(true); // why?
-		// blindly up these parameters for speed
-		writer.setMergeFactor( writer.getMergeFactor() * 2);
-		writer.setMaxBufferedDocs( writer.getMaxBufferedDocs() * 2);
-        Iterator i1 = word2Nums.keySet().iterator();
-        while (i1.hasNext()) // for each word
-        {
-            String g = (String) i1.next();
-            Document doc = new Document();
-
-            int n = index(word2Nums, num2Words, g, doc);
-            if (n > 0)
-            {
-				doc.add( new Field( F_WORD, g, Field.Store.YES, Field.Index.UN_TOKENIZED));
-                if ((++row % mod) == 0)
-                {
-                    o.println("\trow=" + row + "/" + word2Nums.size() + " doc= " + doc);
-                    mod *= 2;
-                }
-                writer.addDocument(doc);
-            } // else degenerate
-        }
-		o.println( "Optimizing..");
-        writer.optimize();
-        writer.close();
-    }
-
-    /**
-     * Given the 2 maps fills a document for 1 word.
-     */
-    private static int index(Map word2Nums, Map num2Words, String g, Document doc)
-        throws Throwable
-    {
-        List keys = (List) word2Nums.get(g); // get list of key#'s
-        Iterator i2 = keys.iterator();
-
-        Set already = new TreeSet(); // keep them sorted
-
-        // pass 1: fill up 'already' with all words
-        while (i2.hasNext()) // for each key#
-        {
-            already.addAll((List) num2Words.get(i2.next())); // get list of words
-        }
-        int num = 0;
-        already.remove(g); // of course a word is it's own syn
-        Iterator it = already.iterator();
-        while (it.hasNext())
-        {
-            String cur = (String) it.next();
-            // don't store things like 'pit bull' -> 'american pit bull'
-            if (!isDecent(cur))
-            {
-                continue;
-            }
-            num++;
-			doc.add( new Field( F_SYN, cur, Field.Store.YES, Field.Index.NO));
-        }
-        return num;
-    }
-
-	/**
-	 *
-	 */
-    private static void usage()
-    {
-        o.println("\n\n" +
-            "java org.apache.lucene.wordnet.Syn2Index <prolog file> <index dir>\n\n");
-    }
-
-}
diff --git a/contrib/WordNet/src/java/org/apache/lucene/wordnet/package.html b/contrib/WordNet/src/java/org/apache/lucene/wordnet/package.html
deleted file mode 100755
index 8625a7d..0000000
--- a/contrib/WordNet/src/java/org/apache/lucene/wordnet/package.html
+++ /dev/null
@@ -1,25 +0,0 @@
-<html>
-    <head>
-<title>WordNet Lucene Synonyms Integration</title>
-</head>
-<body>
-
-    This package uses synonyms defined by <a href="http://www.cogsci.princeton.edu/~wn/">WordNet</a> to build a
-    Lucene index storing them, which in turn can be used for query expansion.
-
-    You normally run {@link org.apache.lucene.wordnet.Syns2Index} once to build the query index/"database", and then call
-    {@link org.apache.lucene.wordnet.SynExpand#expand SynExpand.expand(...)} to expand a query.
-
-    <p>
-
-	<h3> Instructions </h3>
-	<ol>
-	    <li> Download the <a href="http://www.cogsci.princeton.edu/2.0/WNprolog-2.0.tar.gz">WordNet prolog database</a> , gunzip, untar etc.
-	<li> Invoke Syn2Index as appropriate to build a synonym index.
-	    It'll take 2 arguments, the path to wn_s.pl from that WordNet downlaod, and the index name.
-   
-	 <li> Update your UI so that as appropriate you call SynExpand.expand(...) to expand user queries with synonyms.
-       </ol>
-
-</body>
-    </html>
\ No newline at end of file
diff --git a/contrib/wordnetlc/README.txt b/contrib/wordnetlc/README.txt
new file mode 100644
index 0000000..55266d8
--- /dev/null
+++ b/contrib/wordnetlc/README.txt
@@ -0,0 +1,5 @@
+As of 2002-11-13 WordNet Lucene contribution contains a single Java class:
+	org.apache.lucene.wordnet.Syns2Index.
+
+This class creates a Lucene index with synonyms for English words from
+a Prolog file, which is a part of WordNet database.
diff --git a/contrib/wordnetlc/build.xml b/contrib/wordnetlc/build.xml
new file mode 100644
index 0000000..ae3b0c8
--- /dev/null
+++ b/contrib/wordnetlc/build.xml
@@ -0,0 +1,73 @@
+<?xml version="1.0"?>
+
+<project name="wordnet" default="default">
+
+  <description>
+    WordNet
+  </description>
+
+  <property name="prolog.file" location="prologwn/wn_s.pl"/>
+  <property name="synindex.dir" location="index"/>
+
+  <available property="synindex.exists" file="${synindex.dir}" type="dir"/>
+
+  <import file="../contrib-build.xml"/>
+
+  <target name="index" depends="compile" description="Build WordNet index">
+    <fail if="synindex.exists">
+      Index already exists - must remove first.
+    </fail>
+
+    <java classname="org.apache.lucene.wordnet.Syns2Index">
+      <classpath>
+        <path refid="compile.classpath"/>
+        <pathelement location="${build.dir}/classes"/>
+      </classpath>
+
+      <arg file="${prolog.file}"/>
+      <arg file="${synindex.dir}"/>
+    </java>
+  </target>
+
+
+  <target name="synonym" description="Find synonyms for word">
+    <fail unless="synindex.exists">
+      Index does not exist.
+    </fail>
+
+    <fail unless="word">
+      Must specify 'word' property.
+    </fail>
+    
+    <java classname="org.apache.lucene.wordnet.SynLookup">
+      <classpath>
+        <path refid="compile.classpath"/>
+        <pathelement location="${build.dir}/classes"/>
+      </classpath>
+
+      <arg file="${synindex.dir}"/>
+      <arg value="${word}"/>
+    </java>
+  </target>
+
+  <target name="expand" description="Perform synonym expansion on a query">
+    <fail unless="synindex.exists">
+      Index does not exist.
+    </fail>
+
+    <fail unless="query">
+      Must specify 'query' property.
+    </fail>
+    
+    <java classname="org.apache.lucene.wordnet.SynExpand">
+      <classpath>
+        <path refid="compile.classpath"/>
+        <pathelement location="${build.dir}/classes"/>
+      </classpath>
+
+      <arg file="${synindex.dir}"/>
+      <arg value="${query}"/>
+    </java>
+  </target>
+
+</project>
diff --git a/contrib/wordnetlc/src/java/org/apache/lucene/wordnet/SynExpand.java b/contrib/wordnetlc/src/java/org/apache/lucene/wordnet/SynExpand.java
new file mode 100755
index 0000000..fa05929
--- /dev/null
+++ b/contrib/wordnetlc/src/java/org/apache/lucene/wordnet/SynExpand.java
@@ -0,0 +1,127 @@
+package org.apache.lucene.wordnet;
+
+import org.apache.lucene.store.*;
+import org.apache.lucene.search.*;
+import org.apache.lucene.index.*;
+import org.apache.lucene.document.*;
+import org.apache.lucene.analysis.*;
+import org.apache.lucene.analysis.standard.*;
+import java.io.*;
+import java.util.*;
+
+
+/**
+ * Expand a query by looking up synonyms for every term.
+ * You need to invoke {@link Syns2Index} first to build the synonym index.
+ *
+ * @see Syns2Index
+ */
+public final class SynExpand {
+
+	/**
+	 * Test driver for synonym expansion.
+	 * Uses boost factor of 0.9 for illustrative purposes.
+	 *
+	 * If you pass in the query "big dog" then it prints out:
+	 *
+	 * <code><pre>
+	 * Query: big adult^0.9 bad^0.9 bighearted^0.9 boastful^0.9 boastfully^0.9 bounteous^0.9 bountiful^0.9 braggy^0.9 crowing^0.9 freehanded^0.9 giving^0.9 grown^0.9 grownup^0.9 handsome^0.9 large^0.9 liberal^0.9 magnanimous^0.9 momentous^0.9 openhanded^0.9 prominent^0.9 swelled^0.9 vainglorious^0.9 vauntingly^0.9
+	 * dog andiron^0.9 blackguard^0.9 bounder^0.9 cad^0.9 chase^0.9 click^0.9 detent^0.9 dogtooth^0.9 firedog^0.9 frank^0.9 frankfurter^0.9 frump^0.9 heel^0.9 hotdog^0.9 hound^0.9 pawl^0.9 tag^0.9 tail^0.9 track^0.9 trail^0.9 weenie^0.9 wiener^0.9 wienerwurst^0.9
+	 * </pre></code>
+	 */
+	public static void main(String[] args) throws IOException
+	{
+		if (args.length != 2)
+		{
+			System.out.println(
+							   "java org.apache.lucene.wordnet.SynExpand <index path> <query>");
+		}
+
+		FSDirectory directory = FSDirectory.getDirectory(args[0], false);
+		IndexSearcher searcher = new IndexSearcher(directory);
+
+		String query = args[1];
+		String field = "contents";
+
+		Query q = expand( query, searcher, new StandardAnalyzer(), field, 0.9f);
+		System.out.println( "Query: " + q.toString( field));
+
+
+
+		searcher.close();
+		directory.close();
+	}
+
+
+	/**
+	 * Perform synonym expansion on a query.
+	 *
+	 * @param query users query that is assumed to not have any "special" query syntax, thus it should be just normal words, so "big dog" makes sense, but a query like "title:foo^1.2" doesn't as this should presumably be passed directly to the default query parser.
+	 *
+	 * @param syns a opened to the Lucene index you previously created with {@link Syns2Index}. The searcher is not closed or otherwise altered.
+	 *
+	 * @param a optional analyzer used to parse the users query else {@link StandardAnalyzer} is used
+	 *
+	 * @param field optional field name to search in or null if you want the default of "contents"
+	 *
+	 * @param boost optional boost applied to synonyms else no boost is applied
+	 *
+	 * @return the expanded Query
+	 */ 
+	public static Query expand( String query,
+								Searcher syns,
+								Analyzer a,
+								String field,
+								float boost)
+		throws IOException
+	{
+		Set already = new HashSet(); // avoid dups 
+		List top = new LinkedList(); // needs to be separately listed..
+		if ( field == null) field = "contents";
+		if ( a == null) a = new StandardAnalyzer();
+
+		// [1] Parse query into separate words so that when we expand we can avoid dups
+		TokenStream ts = a.tokenStream( field, new StringReader( query));
+		org.apache.lucene.analysis.Token t;
+		while ( (t = ts.next()) != null)
+		{
+			String word = t.termText();
+			if ( already.add( word))
+				top.add( word);
+		}
+		BooleanQuery tmp = new BooleanQuery();
+		
+		// [2] form query
+		Iterator it = top.iterator();
+		while ( it.hasNext())
+		{
+			// [2a] add to level words in
+			String word = (String) it.next();
+			TermQuery tq = new TermQuery( new Term( field, word));
+			tmp.add( tq, BooleanClause.Occur.SHOULD);
+
+			// [2b] add in unique synonums
+			Hits hits = syns.search( new TermQuery( new Term(Syns2Index.F_WORD, word)));
+			for (int i = 0; i < hits.length(); i++)
+			{
+				Document doc = hits.doc(i);
+				String[] values = doc.getValues( Syns2Index.F_SYN);
+				for ( int j = 0; j < values.length; j++)
+				{
+					String syn = values[ j];
+					if ( already.add( syn)) // avoid dups of top level words and synonyms
+					{
+						tq = new TermQuery( new Term( field, syn));
+						if ( boost > 0) // else keep normal 1.0
+							tq.setBoost( boost);
+						tmp.add( tq, BooleanClause.Occur.SHOULD); 
+					}
+				}
+			}
+		}
+
+
+		return tmp;
+	}
+								
+}
diff --git a/contrib/wordnetlc/src/java/org/apache/lucene/wordnet/SynLookup.java b/contrib/wordnetlc/src/java/org/apache/lucene/wordnet/SynLookup.java
new file mode 100644
index 0000000..887afd5
--- /dev/null
+++ b/contrib/wordnetlc/src/java/org/apache/lucene/wordnet/SynLookup.java
@@ -0,0 +1,114 @@
+package org.apache.lucene.wordnet;
+
+import org.apache.lucene.store.*;
+import org.apache.lucene.search.*;
+import org.apache.lucene.index.*;
+import org.apache.lucene.document.*;
+import org.apache.lucene.analysis.*;
+import java.io.*;
+import java.util.*;
+
+
+/**
+ * Test program to look up synonyms.
+ */
+public class SynLookup {
+
+	public static void main(String[] args) throws IOException {
+		if (args.length != 2) {
+			System.out.println(
+							   "java org.apache.lucene.wordnet.SynLookup <index path> <word>");
+		}
+
+		FSDirectory directory = FSDirectory.getDirectory(args[0], false);
+		IndexSearcher searcher = new IndexSearcher(directory);
+
+		String word = args[1];
+		Hits hits = searcher.search(
+									new TermQuery(new Term(Syns2Index.F_WORD, word)));
+
+		if (hits.length() == 0) {
+			System.out.println("No synonyms found for " + word);
+		} else {
+			System.out.println("Synonyms found for \"" + word + "\":");
+		}
+
+		for (int i = 0; i < hits.length(); i++) {
+			Document doc = hits.doc(i);
+
+			String[] values = doc.getValues(Syns2Index.F_SYN);
+
+			for (int j = 0; j < values.length; j++) {
+				System.out.println(values[j]);
+			}
+		}
+
+		searcher.close();
+		directory.close();
+	}
+
+
+	/**
+	 * Perform synonym expansion on a query.
+	 *
+	 * @param query
+	 * @param syns
+	 * @param a
+	 * @param field
+	 * @param boost
+	 */ 
+	public static Query expand( String query,
+								Searcher syns,
+								Analyzer a,
+								String field,
+								float boost)
+		throws IOException
+	{
+		Set already = new HashSet(); // avoid dups		
+		List top = new LinkedList(); // needs to be separately listed..
+
+		// [1] Parse query into separate words so that when we expand we can avoid dups
+		TokenStream ts = a.tokenStream( field, new StringReader( query));
+		org.apache.lucene.analysis.Token t;
+		while ( (t = ts.next()) != null)
+		{
+			String word = t.termText();
+			if ( already.add( word))
+				top.add( word);
+		}
+		BooleanQuery tmp = new BooleanQuery();
+		
+		// [2] form query
+		Iterator it = top.iterator();
+		while ( it.hasNext())
+		{
+			// [2a] add to level words in
+			String word = (String) it.next();
+			TermQuery tq = new TermQuery( new Term( field, word));
+			tmp.add( tq, BooleanClause.Occur.SHOULD);
+
+			// [2b] add in unique synonums
+			Hits hits = syns.search( new TermQuery( new Term(Syns2Index.F_WORD, word)));
+			for (int i = 0; i < hits.length(); i++)
+			{
+				Document doc = hits.doc(i);
+				String[] values = doc.getValues( Syns2Index.F_SYN);
+				for ( int j = 0; j < values.length; j++)
+				{
+					String syn = values[ j];
+					if ( already.add( syn))
+					{
+						tq = new TermQuery( new Term( field, syn));
+						if ( boost > 0) // else keep normal 1.0
+							tq.setBoost( boost);
+						tmp.add( tq, BooleanClause.Occur.SHOULD); 
+					}
+				}
+			}
+		}
+
+
+		return tmp;
+	}
+								
+}
diff --git a/contrib/wordnetlc/src/java/org/apache/lucene/wordnet/Syns2Index.java b/contrib/wordnetlc/src/java/org/apache/lucene/wordnet/Syns2Index.java
new file mode 100644
index 0000000..56e3dfd
--- /dev/null
+++ b/contrib/wordnetlc/src/java/org/apache/lucene/wordnet/Syns2Index.java
@@ -0,0 +1,301 @@
+package org.apache.lucene.wordnet;
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.standard.StandardAnalyzer;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.index.IndexWriter;
+
+import java.io.BufferedReader;
+import java.io.BufferedOutputStream;
+import java.io.FileOutputStream;
+import java.io.File;
+import java.io.PrintStream;
+import java.io.FileInputStream;
+import java.io.InputStreamReader;
+import java.util.HashMap;
+import java.util.Iterator;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.TreeSet;
+import java.util.TreeMap;
+
+/**
+ * Convert the prolog file wn_s.pl from the <a href="http://www.cogsci.princeton.edu/2.0/WNprolog-2.0.tar.gz">WordNet prolog download</a>
+ * into a Lucene index suitable for looking up synonyms and performing query expansion ({@link SynExpand#expand SynExpand.expand(...)}).
+ *
+ * This has been tested with WordNet 2.0.
+ *
+ * The index has fields named "word" ({@link #F_WORD})
+ * and "syn" ({@link #F_SYN}).
+ * <p>
+ * The source word (such as 'big') can be looked up in the
+ * "word" field, and if present there will be fields named "syn"
+ * for every synonym. What's tricky here is that there could be <b>multiple</b>
+ * fields with the same name, in the general case for words that have multiple synonyms.
+ * That's not a problem with Lucene, you just use {@link org.apache.lucene.document.Document#getValues}
+ * </p>
+ * <p>
+ * While the WordNet file distinguishes groups of synonyms with
+ * related meanings we don't do that here.
+ * </p>
+ *
+ * This can take 4 minutes to execute and build an index on a "fast" system and the index takes up almost 3 MB.
+ *
+ * @author Dave Spencer, dave&#064;searchmorph.com
+ * @see <a href="http://www.cogsci.princeton.edu/~wn/">WordNet home page</a>
+ * @see <a href="http://www.cogsci.princeton.edu/~wn/man/prologdb.5WN.html">prologdb man page</a>
+ * @see <a href="http://www.hostmon.com/rfc/advanced.jsp">sample site that uses it</a>
+ */
+public class Syns2Index
+{
+	/**
+	 *
+	 */
+	private static final PrintStream o = System.out;
+
+	/**
+	 *
+	 */
+	private static final PrintStream err = System.err;
+	
+	/**
+	 *
+	 */
+	public static final String F_SYN = "syn";
+
+	/**
+	 *
+	 */
+	public static final String F_WORD = "word";
+
+	/**
+	 *
+	 */
+    private static final Analyzer ana = new StandardAnalyzer();
+
+    /**
+     * Takes arg of prolog file name and index directory.
+     */
+    public static void main(String[] args)
+        throws Throwable
+    {
+        // get command line arguments
+        String prologFilename = null; // name of file "wn_s.pl"
+        String indexDir = null;
+        if (args.length == 2)
+        {
+            prologFilename = args[0];
+            indexDir = args[1];
+        }
+        else
+        {
+            usage();
+            System.exit(1);
+        }
+
+        // ensure that the prolog file is readable
+        if (! (new File(prologFilename)).canRead())
+        {
+            err.println("Error: cannot read Prolog file: " + prologFilename);
+            System.exit(1);
+        }
+        // exit if the target index directory already exists
+        if ((new File(indexDir)).isDirectory())
+        {
+            err.println("Error: index directory already exists: " + indexDir);
+            err.println("Please specify a name of a non-existent directory");
+            System.exit(1);
+        }
+
+        o.println("Opening Prolog file " + prologFilename);
+        final FileInputStream fis = new FileInputStream(prologFilename);
+        final BufferedReader br = new BufferedReader(new InputStreamReader(fis));
+        String line;
+
+        // maps a word to all the "groups" it's in
+        final Map word2Nums = new TreeMap();
+        // maps a group to all the words in it
+        final Map num2Words = new TreeMap();
+        // number of rejected words
+        int ndecent = 0;
+
+        // status output
+        int mod = 1;
+        int row = 1;
+        // parse prolog file
+		o.println( "[1/2] Parsing " + prologFilename);
+        while ((line = br.readLine()) != null)
+        {
+            // occasional progress
+            if ((++row) % mod == 0) // periodically print out line we read in
+            {
+                mod *= 2;
+                o.println("\t" + row + " " + line + " " + word2Nums.size()
+                    + " " + num2Words.size() + " ndecent=" + ndecent);
+            }
+
+            // syntax check
+            if (! line.startsWith("s("))
+            {
+                err.println("OUCH: " + line);
+                System.exit(1);
+            }
+
+            // parse line
+            line = line.substring(2);
+            int comma = line.indexOf(',');
+            String num = line.substring(0, comma);
+            int q1 = line.indexOf('\'');
+            line = line.substring(q1 + 1);
+            int q2 = line.indexOf('\'');
+            String word = line.substring(0, q2).toLowerCase();
+
+            // make sure is a normal word
+            if (! isDecent(word))
+            {
+                ndecent++;
+                continue; // don't store words w/ spaces
+            }
+
+            // 1/2: word2Nums map
+            // append to entry or add new one
+            List lis =(List) word2Nums.get(word);
+            if (lis == null)
+            {
+                lis = new LinkedList();
+                lis.add(num);
+                word2Nums.put(word, lis);
+            }
+            else
+                lis.add(num);
+
+            // 2/2: num2Words map
+            lis = (List) num2Words.get(num);
+            if (lis == null)
+            {
+                lis = new LinkedList();
+                lis.add(word);
+                num2Words.put(num, lis);
+            }
+            else
+                lis.add(word);
+        }
+
+        // close the streams
+        fis.close();
+        br.close();
+
+        // create the index
+		o.println( "[2/2] Building index to store synonyms, " +
+				   " map sizes are " + word2Nums.size() + " and " + num2Words.size());
+        index(indexDir, word2Nums, num2Words);
+    }
+
+    /**
+     * Checks to see if a word contains only alphabetic characters by
+     * checking it one character at a time.
+     *
+     * @param s string to check
+     * @return <code>true</code> if the string is decent
+     */
+    private static boolean isDecent(String s)
+    {
+        int len = s.length();
+        for (int i = 0; i < len; i++)
+        {
+            if (!Character.isLetter(s.charAt(i)))
+            {
+                return false;
+            }
+        }
+        return true;
+    }
+
+    /**
+     * Forms a Lucene index based on the 2 maps.
+     *
+     * @param indexDir the direcotry where the index should be created
+     * @param word2Nums
+     * @param num2Words
+     */
+    private static void index(String indexDir, Map word2Nums, Map num2Words)
+        throws Throwable
+    {
+        int row = 0;
+        int mod = 1;
+
+        // override the specific index if it already exists
+        IndexWriter writer = new IndexWriter(indexDir, ana, true);
+        writer.setUseCompoundFile(true); // why?
+		// blindly up these parameters for speed
+		writer.setMergeFactor( writer.getMergeFactor() * 2);
+		writer.setMaxBufferedDocs( writer.getMaxBufferedDocs() * 2);
+        Iterator i1 = word2Nums.keySet().iterator();
+        while (i1.hasNext()) // for each word
+        {
+            String g = (String) i1.next();
+            Document doc = new Document();
+
+            int n = index(word2Nums, num2Words, g, doc);
+            if (n > 0)
+            {
+				doc.add( new Field( F_WORD, g, Field.Store.YES, Field.Index.UN_TOKENIZED));
+                if ((++row % mod) == 0)
+                {
+                    o.println("\trow=" + row + "/" + word2Nums.size() + " doc= " + doc);
+                    mod *= 2;
+                }
+                writer.addDocument(doc);
+            } // else degenerate
+        }
+		o.println( "Optimizing..");
+        writer.optimize();
+        writer.close();
+    }
+
+    /**
+     * Given the 2 maps fills a document for 1 word.
+     */
+    private static int index(Map word2Nums, Map num2Words, String g, Document doc)
+        throws Throwable
+    {
+        List keys = (List) word2Nums.get(g); // get list of key#'s
+        Iterator i2 = keys.iterator();
+
+        Set already = new TreeSet(); // keep them sorted
+
+        // pass 1: fill up 'already' with all words
+        while (i2.hasNext()) // for each key#
+        {
+            already.addAll((List) num2Words.get(i2.next())); // get list of words
+        }
+        int num = 0;
+        already.remove(g); // of course a word is it's own syn
+        Iterator it = already.iterator();
+        while (it.hasNext())
+        {
+            String cur = (String) it.next();
+            // don't store things like 'pit bull' -> 'american pit bull'
+            if (!isDecent(cur))
+            {
+                continue;
+            }
+            num++;
+			doc.add( new Field( F_SYN, cur, Field.Store.YES, Field.Index.NO));
+        }
+        return num;
+    }
+
+	/**
+	 *
+	 */
+    private static void usage()
+    {
+        o.println("\n\n" +
+            "java org.apache.lucene.wordnet.Syn2Index <prolog file> <index dir>\n\n");
+    }
+
+}
diff --git a/contrib/wordnetlc/src/java/org/apache/lucene/wordnet/package.html b/contrib/wordnetlc/src/java/org/apache/lucene/wordnet/package.html
new file mode 100755
index 0000000..8625a7d
--- /dev/null
+++ b/contrib/wordnetlc/src/java/org/apache/lucene/wordnet/package.html
@@ -0,0 +1,25 @@
+<html>
+    <head>
+<title>WordNet Lucene Synonyms Integration</title>
+</head>
+<body>
+
+    This package uses synonyms defined by <a href="http://www.cogsci.princeton.edu/~wn/">WordNet</a> to build a
+    Lucene index storing them, which in turn can be used for query expansion.
+
+    You normally run {@link org.apache.lucene.wordnet.Syns2Index} once to build the query index/"database", and then call
+    {@link org.apache.lucene.wordnet.SynExpand#expand SynExpand.expand(...)} to expand a query.
+
+    <p>
+
+	<h3> Instructions </h3>
+	<ol>
+	    <li> Download the <a href="http://www.cogsci.princeton.edu/2.0/WNprolog-2.0.tar.gz">WordNet prolog database</a> , gunzip, untar etc.
+	<li> Invoke Syn2Index as appropriate to build a synonym index.
+	    It'll take 2 arguments, the path to wn_s.pl from that WordNet downlaod, and the index name.
+   
+	 <li> Update your UI so that as appropriate you call SynExpand.expand(...) to expand user queries with synonyms.
+       </ol>
+
+</body>
+    </html>
\ No newline at end of file

