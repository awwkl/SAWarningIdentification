GitDiffStart: 845944c44652e6f4c8fb705a87006bd3b35cf5fa | Wed Jul 1 16:34:44 2015 +0000
diff --git a/lucene/CHANGES.txt b/lucene/CHANGES.txt
index 360d86e..6332e57 100644
--- a/lucene/CHANGES.txt
+++ b/lucene/CHANGES.txt
@@ -164,6 +164,10 @@ API Changes
 * LUCENE-6648: All lucene/facet APIs now take Query objects where they used to
   take Filter objects. (Adrien Grand)
 
+* LUCENE-6640: Suggesters now take a BitsProducer object instead of a Filter
+  object to reduce the scope of doc IDs that may be returned, emphasizing the
+  fact that these objects need to support random-access. (Adrien Grand)
+
 Bug fixes
 
 * LUCENE-6500: ParallelCompositeReader did not always call
diff --git a/lucene/suggest/src/java/org/apache/lucene/search/suggest/BitsProducer.java b/lucene/suggest/src/java/org/apache/lucene/search/suggest/BitsProducer.java
new file mode 100644
index 0000000..5da9647
--- /dev/null
+++ b/lucene/suggest/src/java/org/apache/lucene/search/suggest/BitsProducer.java
@@ -0,0 +1,34 @@
+package org.apache.lucene.search.suggest;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.index.LeafReader;
+import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.util.Bits;
+
+/** A producer of {@link Bits} per segment. */
+public abstract class BitsProducer {
+
+  /** Return {@link Bits} for the given leaf. The returned instance must
+   *  be non-null and have a {@link Bits#length() length} equal to
+   *  {@link LeafReader#maxDoc() maxDoc}. */
+  public abstract Bits getBits(LeafReaderContext context) throws IOException;
+
+}
diff --git a/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionQuery.java b/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionQuery.java
index eb2ba22..464fbf5 100644
--- a/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionQuery.java
+++ b/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionQuery.java
@@ -24,15 +24,15 @@ import org.apache.lucene.index.LeafReader;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.index.Terms;
-import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.Query;
+import org.apache.lucene.search.suggest.BitsProducer;
 
 import static org.apache.lucene.search.suggest.document.CompletionAnalyzer.HOLE_CHARACTER;
 import static org.apache.lucene.search.suggest.document.CompletionAnalyzer.SEP_LABEL;
 
 /**
  * Abstract {@link Query} that match documents containing terms with a specified prefix
- * filtered by {@link Filter}. This should be used to query against any {@link SuggestField}s
+ * filtered by {@link BitsProducer}. This should be used to query against any {@link SuggestField}s
  * or {@link ContextSuggestField}s of documents.
  * <p>
  * Use {@link SuggestIndexSearcher#suggest(CompletionQuery, int)} to execute any query
@@ -56,25 +56,25 @@ public abstract class CompletionQuery extends Query {
   private final Term term;
 
   /**
-   * Filter for document scoping
+   * {@link BitsProducer} which is used to filter the document scope.
    */
-  private final Filter filter;
+  private final BitsProducer filter;
 
   /**
    * Creates a base Completion query against a <code>term</code>
    * with a <code>filter</code> to scope the documents
    */
-  protected CompletionQuery(Term term, Filter filter) {
+  protected CompletionQuery(Term term, BitsProducer filter) {
     validate(term.text());
     this.term = term;
     this.filter = filter;
   }
 
   /**
-   * Returns the filter for the query, used to
-   * suggest completions on a subset of indexed documents
+   * Returns a {@link BitsProducer}. Only suggestions matching the returned
+   * bits will be returned.
    */
-  public Filter getFilter() {
+  public BitsProducer getFilter() {
     return filter;
   }
 
@@ -148,7 +148,7 @@ public abstract class CompletionQuery extends Query {
       buffer.append(",");
       buffer.append("filter");
       buffer.append(":");
-      buffer.append(filter.toString(field));
+      buffer.append(filter.toString());
     }
     return buffer.toString();
   }
diff --git a/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionWeight.java b/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionWeight.java
index 813b283..19171b6 100644
--- a/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionWeight.java
+++ b/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionWeight.java
@@ -25,11 +25,10 @@ import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.index.Terms;
 import org.apache.lucene.search.BulkScorer;
-import org.apache.lucene.search.DocIdSet;
 import org.apache.lucene.search.Explanation;
-import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.Scorer;
 import org.apache.lucene.search.Weight;
+import org.apache.lucene.search.suggest.BitsProducer;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.IntsRef;
 import org.apache.lucene.util.automaton.Automaton;
@@ -88,19 +87,15 @@ public class CompletionWeight extends Weight {
       throw new IllegalArgumentException(completionQuery.getField() + " is not a SuggestField");
     }
 
-    DocIdSet docIdSet = null;
-    Filter filter = completionQuery.getFilter();
+    BitsProducer filter = completionQuery.getFilter();
+    Bits filteredDocs = null;
     if (filter != null) {
-      docIdSet = filter.getDocIdSet(context, null);
-      if (docIdSet == null || docIdSet.iterator() == null) {
-        // filter matches no docs in current leave
+      filteredDocs = filter.getBits(context);
+      if (filteredDocs.getClass() == Bits.MatchNoBits.class) {
         return null;
-      } else if (docIdSet.bits() == null) {
-        throw new IllegalArgumentException("DocIDSet does not provide random access interface");
       }
     }
-    Bits acceptDocBits = (docIdSet != null) ? docIdSet.bits() : null;
-    return new CompletionScorer(this, suggester, reader, acceptDocBits, filter != null, automaton);
+    return new CompletionScorer(this, suggester, reader, filteredDocs, filter != null, automaton);
   }
 
   /**
diff --git a/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/FuzzyCompletionQuery.java b/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/FuzzyCompletionQuery.java
index 3489815..0a38196 100644
--- a/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/FuzzyCompletionQuery.java
+++ b/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/FuzzyCompletionQuery.java
@@ -23,9 +23,9 @@ import java.util.Set;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.index.Term;
-import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Weight;
+import org.apache.lucene.search.suggest.BitsProducer;
 import org.apache.lucene.util.IntsRef;
 import org.apache.lucene.util.UnicodeUtil;
 import org.apache.lucene.util.automaton.Automata;
@@ -88,7 +88,7 @@ public class FuzzyCompletionQuery extends PrefixCompletionQuery {
   private final int maxDeterminizedStates;
 
   /**
-   * Calls {@link FuzzyCompletionQuery#FuzzyCompletionQuery(Analyzer, Term, Filter)}
+   * Calls {@link FuzzyCompletionQuery#FuzzyCompletionQuery(Analyzer, Term, BitsProducer)}
    * with no filter
    */
   public FuzzyCompletionQuery(Analyzer analyzer, Term term) {
@@ -96,7 +96,7 @@ public class FuzzyCompletionQuery extends PrefixCompletionQuery {
   }
 
   /**
-   * Calls {@link FuzzyCompletionQuery#FuzzyCompletionQuery(Analyzer, Term, Filter,
+   * Calls {@link FuzzyCompletionQuery#FuzzyCompletionQuery(Analyzer, Term, BitsProducer,
    * int, boolean, int, int, boolean, int)}
    * with defaults for <code>maxEdits</code>, <code>transpositions</code>,
    * <code>nonFuzzyPrefix</code>, <code>minFuzzyLength</code>,
@@ -107,7 +107,7 @@ public class FuzzyCompletionQuery extends PrefixCompletionQuery {
    * {@link #DEFAULT_UNICODE_AWARE} and {@link Operations#DEFAULT_MAX_DETERMINIZED_STATES}
    * for defaults
    */
-  public FuzzyCompletionQuery(Analyzer analyzer, Term term, Filter filter) {
+  public FuzzyCompletionQuery(Analyzer analyzer, Term term, BitsProducer filter) {
     this(analyzer, term, filter, DEFAULT_MAX_EDITS, DEFAULT_TRANSPOSITIONS, DEFAULT_NON_FUZZY_PREFIX,
         DEFAULT_MIN_FUZZY_LENGTH, DEFAULT_UNICODE_AWARE, Operations.DEFAULT_MAX_DETERMINIZED_STATES
     );
@@ -127,7 +127,7 @@ public class FuzzyCompletionQuery extends PrefixCompletionQuery {
    * @param unicodeAware treat prefix as unicode rather than bytes
    * @param maxDeterminizedStates maximum automaton states allowed for {@link LevenshteinAutomata}
    */
-  public FuzzyCompletionQuery(Analyzer analyzer, Term term, Filter filter, int maxEdits,
+  public FuzzyCompletionQuery(Analyzer analyzer, Term term, BitsProducer filter, int maxEdits,
                               boolean transpositions, int nonFuzzyPrefix, int minFuzzyLength,
                               boolean unicodeAware, int maxDeterminizedStates) {
     super(analyzer, term, filter);
@@ -208,7 +208,7 @@ public class FuzzyCompletionQuery extends PrefixCompletionQuery {
     if (getFilter() != null) {
       buffer.append(",");
       buffer.append("filter");
-      buffer.append(getFilter().toString(field));
+      buffer.append(getFilter().toString());
     }
     return buffer.toString();
   }
diff --git a/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/PrefixCompletionQuery.java b/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/PrefixCompletionQuery.java
index 24590f7..49d707c 100644
--- a/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/PrefixCompletionQuery.java
+++ b/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/PrefixCompletionQuery.java
@@ -21,9 +21,9 @@ import java.io.IOException;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.index.Term;
-import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Weight;
+import org.apache.lucene.search.suggest.BitsProducer;
 
 /**
  * A {@link CompletionQuery} which takes an {@link Analyzer}
@@ -42,7 +42,7 @@ public class PrefixCompletionQuery extends CompletionQuery {
   protected final CompletionAnalyzer analyzer;
 
   /**
-   * Calls {@link PrefixCompletionQuery#PrefixCompletionQuery(Analyzer, Term, Filter)}
+   * Calls {@link PrefixCompletionQuery#PrefixCompletionQuery(Analyzer, Term, BitsProducer)}
    * with no filter
    */
   public PrefixCompletionQuery(Analyzer analyzer, Term term) {
@@ -57,7 +57,7 @@ public class PrefixCompletionQuery extends CompletionQuery {
    *             is analyzed with <code>analyzer</code>
    * @param filter used to query on a sub set of documents
    */
-  public PrefixCompletionQuery(Analyzer analyzer, Term term, Filter filter) {
+  public PrefixCompletionQuery(Analyzer analyzer, Term term, BitsProducer filter) {
     super(term, filter);
     if (!(analyzer instanceof CompletionAnalyzer)) {
       this.analyzer = new CompletionAnalyzer(analyzer);
diff --git a/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/RegexCompletionQuery.java b/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/RegexCompletionQuery.java
index efbaea4..b9b5ae6 100644
--- a/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/RegexCompletionQuery.java
+++ b/lucene/suggest/src/java/org/apache/lucene/search/suggest/document/RegexCompletionQuery.java
@@ -20,9 +20,9 @@ package org.apache.lucene.search.suggest.document;
 import java.io.IOException;
 
 import org.apache.lucene.index.Term;
-import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Weight;
+import org.apache.lucene.search.suggest.BitsProducer;
 import org.apache.lucene.util.automaton.Operations;
 import org.apache.lucene.util.automaton.RegExp;
 
@@ -50,7 +50,7 @@ public class RegexCompletionQuery extends CompletionQuery {
   private final int maxDeterminizedStates;
 
   /**
-   * Calls {@link RegexCompletionQuery#RegexCompletionQuery(Term, Filter)}
+   * Calls {@link RegexCompletionQuery#RegexCompletionQuery(Term, BitsProducer)}
    * with no filter
    */
   public RegexCompletionQuery(Term term) {
@@ -58,15 +58,15 @@ public class RegexCompletionQuery extends CompletionQuery {
   }
 
   /**
-   * Calls {@link RegexCompletionQuery#RegexCompletionQuery(Term, int, int, Filter)}
+   * Calls {@link RegexCompletionQuery#RegexCompletionQuery(Term, int, int, BitsProducer)}
    * enabling all optional regex syntax and <code>maxDeterminizedStates</code> of
    * {@value Operations#DEFAULT_MAX_DETERMINIZED_STATES}
    */
-  public RegexCompletionQuery(Term term, Filter filter) {
+  public RegexCompletionQuery(Term term, BitsProducer filter) {
     this(term, RegExp.ALL, Operations.DEFAULT_MAX_DETERMINIZED_STATES, filter);
   }
   /**
-   * Calls {@link RegexCompletionQuery#RegexCompletionQuery(Term, int, int, Filter)}
+   * Calls {@link RegexCompletionQuery#RegexCompletionQuery(Term, int, int, BitsProducer)}
    * with no filter
    */
   public RegexCompletionQuery(Term term, int flags, int maxDeterminizedStates) {
@@ -82,7 +82,7 @@ public class RegexCompletionQuery extends CompletionQuery {
    * @param maxDeterminizedStates used in {@link RegExp#toAutomaton(int)}
    * @param filter used to query on a sub set of documents
    */
-  public RegexCompletionQuery(Term term, int flags, int maxDeterminizedStates, Filter filter) {
+  public RegexCompletionQuery(Term term, int flags, int maxDeterminizedStates, BitsProducer filter) {
     super(term, filter);
     this.flags = flags;
     this.maxDeterminizedStates = maxDeterminizedStates;
diff --git a/lucene/suggest/src/test/org/apache/lucene/search/suggest/document/TestPrefixCompletionQuery.java b/lucene/suggest/src/test/org/apache/lucene/search/suggest/document/TestPrefixCompletionQuery.java
index 2dba6a0..20a2df1 100644
--- a/lucene/suggest/src/test/org/apache/lucene/search/suggest/document/TestPrefixCompletionQuery.java
+++ b/lucene/suggest/src/test/org/apache/lucene/search/suggest/document/TestPrefixCompletionQuery.java
@@ -18,27 +18,23 @@ package org.apache.lucene.search.suggest.document;
  */
 
 import java.io.IOException;
+import java.util.Objects;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.analysis.MockTokenFilter;
 import org.apache.lucene.analysis.MockTokenizer;
 import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.document.IntField;
+import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.index.DirectoryReader;
+import org.apache.lucene.index.DocValues;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.index.SortedNumericDocValues;
 import org.apache.lucene.index.Term;
-import org.apache.lucene.search.DocIdSet;
-import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.search.Filter;
-import org.apache.lucene.search.NumericRangeQuery;
-import org.apache.lucene.search.QueryWrapperFilter;
+import org.apache.lucene.search.suggest.BitsProducer;
 import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.BitDocIdSet;
 import org.apache.lucene.util.Bits;
-import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.LuceneTestCase;
 import org.junit.After;
 import org.junit.Before;
@@ -50,6 +46,68 @@ import static org.apache.lucene.search.suggest.document.TestSuggestField.iwcWith
 import static org.hamcrest.core.IsEqual.equalTo;
 
 public class TestPrefixCompletionQuery extends LuceneTestCase {
+
+  private static class NumericRangeBitsProducer extends BitsProducer {
+
+    private final String field;
+    private final long min, max;
+
+    public NumericRangeBitsProducer(String field, long min, long max) {
+      this.field = field;
+      this.min = min;
+      this.max = max;
+    }
+
+    @Override
+    public String toString() {
+      return field + "[" + min + ".." + max + "]";
+    }
+
+    @Override
+    public boolean equals(Object obj) {
+      if (obj == null || getClass() != obj.getClass()) {
+        return false;
+      }
+      NumericRangeBitsProducer that = (NumericRangeBitsProducer) obj;
+      return field.equals(that.field)
+          && min == that.min
+          && max == that.max;
+    }
+
+    @Override
+    public int hashCode() {
+      return Objects.hash(getClass(), field, min, max);
+    }
+
+    @Override
+    public Bits getBits(final LeafReaderContext context) throws IOException {
+      final int maxDoc = context.reader().maxDoc();
+      final SortedNumericDocValues values = DocValues.getSortedNumeric(context.reader(), field);
+      return new Bits() {
+
+        @Override
+        public boolean get(int doc) {
+          values.setDocument(doc);
+          final int count = values.count();
+          for (int i = 0; i < count; ++i) {
+            final long v = values.valueAt(i);
+            if (v >= min && v <= max) {
+              return true;
+            }
+          }
+          return false;
+        }
+
+        @Override
+        public int length() {
+          return maxDoc;
+        }
+        
+      };
+    }
+
+  }
+
   public Directory dir;
 
   @Before
@@ -99,7 +157,7 @@ public class TestPrefixCompletionQuery extends LuceneTestCase {
     for (int i = 0; i < num; i++) {
       Document document = new Document();
       document.add(new SuggestField("suggest_field", "abc_" + i, i));
-      document.add(new IntField("filter_int_fld", i, Field.Store.NO));
+      document.add(new NumericDocValuesField("filter_int_fld", i));
       iw.addDocument(document);
 
       if (usually()) {
@@ -111,8 +169,7 @@ public class TestPrefixCompletionQuery extends LuceneTestCase {
     SuggestIndexSearcher indexSearcher = new SuggestIndexSearcher(reader);
 
     int topScore = num/2;
-    QueryWrapperFilter filterWrapper = new QueryWrapperFilter(NumericRangeQuery.newIntRange("filter_int_fld", 0, topScore, true, true));
-    Filter filter = randomAccessFilter(filterWrapper);
+    BitsProducer filter = new NumericRangeBitsProducer("filter_int_fld", 0, topScore);
     PrefixCompletionQuery query = new PrefixCompletionQuery(analyzer, new Term("suggest_field", "abc_"), filter);
     // if at most half of the top scoring documents have been filtered out
     // the search should be admissible for a single segment
@@ -121,16 +178,14 @@ public class TestPrefixCompletionQuery extends LuceneTestCase {
     assertThat(suggest.scoreLookupDocs()[0].key.toString(), equalTo("abc_" + topScore));
     assertThat(suggest.scoreLookupDocs()[0].score, equalTo((float) topScore));
 
-    filterWrapper = new QueryWrapperFilter(NumericRangeQuery.newIntRange("filter_int_fld", 0, 0, true, true));
-    filter = randomAccessFilter(filterWrapper);
+    filter = new NumericRangeBitsProducer("filter_int_fld", 0, 0);
     query = new PrefixCompletionQuery(analyzer, new Term("suggest_field", "abc_"), filter);
     // if more than half of the top scoring documents have been filtered out
     // search is not admissible, so # of suggestions requested is num instead of 1
     suggest = indexSearcher.suggest(query, num);
     assertSuggestions(suggest, new Entry("abc_0", 0));
 
-    filterWrapper = new QueryWrapperFilter(NumericRangeQuery.newIntRange("filter_int_fld", num - 1, num - 1, true, true));
-    filter = randomAccessFilter(filterWrapper);
+    filter = new NumericRangeBitsProducer("filter_int_fld", num - 1, num - 1);
     query = new PrefixCompletionQuery(analyzer, new Term("suggest_field", "abc_"), filter);
     // if only lower scoring documents are filtered out
     // search is admissible
@@ -147,17 +202,17 @@ public class TestPrefixCompletionQuery extends LuceneTestCase {
     RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwcWithSuggestField(analyzer, "suggest_field"));
 
     Document document = new Document();
-    document.add(new IntField("filter_int_fld", 9, Field.Store.NO));
+    document.add(new NumericDocValuesField("filter_int_fld", 9));
     document.add(new SuggestField("suggest_field", "apples", 3));
     iw.addDocument(document);
 
     document = new Document();
-    document.add(new IntField("filter_int_fld", 10, Field.Store.NO));
+    document.add(new NumericDocValuesField("filter_int_fld", 10));
     document.add(new SuggestField("suggest_field", "applle", 4));
     iw.addDocument(document);
 
     document = new Document();
-    document.add(new IntField("filter_int_fld", 4, Field.Store.NO));
+    document.add(new NumericDocValuesField("filter_int_fld", 4));
     document.add(new SuggestField("suggest_field", "apple", 5));
     iw.addDocument(document);
 
@@ -174,8 +229,7 @@ public class TestPrefixCompletionQuery extends LuceneTestCase {
     assertSuggestions(suggest, new Entry("apple", 5), new Entry("applle", 4), new Entry("apples", 3));
 
     // suggest with filter
-    QueryWrapperFilter filterWrapper = new QueryWrapperFilter(NumericRangeQuery.newIntRange("filter_int_fld", 5, 12, true, true));
-    Filter filter = randomAccessFilter(filterWrapper);
+    BitsProducer filter = new NumericRangeBitsProducer("filter_int_fld", 5, 12);
     query = new PrefixCompletionQuery(analyzer, new Term("suggest_field", "app"), filter);
     suggest = indexSearcher.suggest(query, 3);
     assertSuggestions(suggest, new Entry("applle", 4), new Entry("apples", 3));
@@ -256,45 +310,4 @@ public class TestPrefixCompletionQuery extends LuceneTestCase {
     iw.close();
   }
 
-  private static class RandomAccessFilter extends Filter {
-    private final Filter in;
-
-    private RandomAccessFilter(Filter in) {
-      this.in = in;
-    }
-
-    @Override
-    public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) throws IOException {
-      DocIdSet docIdSet = in.getDocIdSet(context, acceptDocs);
-      DocIdSetIterator iterator = docIdSet.iterator();
-      FixedBitSet bits = new FixedBitSet(context.reader().maxDoc());
-      if (iterator != null) {
-        bits.or(iterator);
-      }
-      return new BitDocIdSet(bits);
-    }
-
-    @Override
-    public String toString(String field) {
-      return in.toString(field);
-    }
-
-    @Override
-    public boolean equals(Object obj) {
-      if (super.equals(obj) == false) {
-        return false;
-      }
-      return in.equals(((RandomAccessFilter) obj).in);
-    }
-
-    @Override
-    public int hashCode() {
-      return 31 * super.hashCode() + in.hashCode();
-    }
-  }
-
-  private static Filter randomAccessFilter(Filter filter) {
-    return new RandomAccessFilter(filter);
-  }
-
 }
diff --git a/lucene/suggest/src/test/org/apache/lucene/search/suggest/document/TestSuggestField.java b/lucene/suggest/src/test/org/apache/lucene/search/suggest/document/TestSuggestField.java
index 6d7d938..294f0a7 100644
--- a/lucene/suggest/src/test/org/apache/lucene/search/suggest/document/TestSuggestField.java
+++ b/lucene/suggest/src/test/org/apache/lucene/search/suggest/document/TestSuggestField.java
@@ -17,6 +17,7 @@ package org.apache.lucene.search.suggest.document;
  * limitations under the License.
  */
 
+import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.HashMap;
@@ -37,17 +38,16 @@ import org.apache.lucene.document.IntField;
 import org.apache.lucene.index.DirectoryReader;
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.IndexWriterConfig;
+import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.Term;
-import org.apache.lucene.queries.TermsQuery;
-import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.NumericRangeQuery;
-import org.apache.lucene.search.QueryWrapperFilter;
 import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.TopDocs;
+import org.apache.lucene.search.suggest.BitsProducer;
 import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.CharsRefBuilder;
 import org.apache.lucene.util.LineFileDocs;
 import org.apache.lucene.util.LuceneTestCase;
@@ -223,7 +223,12 @@ public class TestSuggestField extends LuceneTestCase {
       }
     }
 
-    Filter filter = new QueryWrapperFilter(new TermsQuery("str_fld", new BytesRef("non_existent")));
+    BitsProducer filter = new BitsProducer() {
+      @Override
+      public Bits getBits(LeafReaderContext context) throws IOException {
+        return new Bits.MatchNoBits(context.reader().maxDoc());
+      }
+    };
     DirectoryReader reader = iw.getReader();
     SuggestIndexSearcher indexSearcher = new SuggestIndexSearcher(reader);
     // no random access required;

