GitDiffStart: 537bb742cd93af4e6718637ecd9174945592cc56 | Fri Jan 29 15:44:54 2010 +0000
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cn/ChineseAnalyzer.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cn/ChineseAnalyzer.java
index 2d5c6a7..cb44755 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cn/ChineseAnalyzer.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cn/ChineseAnalyzer.java
@@ -21,15 +21,17 @@ import java.io.Reader;
 
 import org.apache.lucene.analysis.ReusableAnalyzerBase;
 import org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents; // javadoc @link
+import org.apache.lucene.analysis.standard.StandardAnalyzer; // javadoc @link
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.Tokenizer;
 
 /**
  * An {@link Analyzer} that tokenizes text with {@link ChineseTokenizer} and
  * filters with {@link ChineseFilter}
- *
+ * @deprecated Use {@link StandardAnalyzer} instead, which has the same functionality.
+ * This analyzer will be removed in Lucene 4.0
  */
-
+@Deprecated
 public final class ChineseAnalyzer extends ReusableAnalyzerBase {
 
   /**
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cn/ChineseFilter.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cn/ChineseFilter.java
index 53c0b24..5ed043b 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cn/ChineseFilter.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cn/ChineseFilter.java
@@ -23,6 +23,7 @@ import java.util.Arrays;
 import org.apache.lucene.analysis.CharArraySet;
 import org.apache.lucene.analysis.TokenFilter;
 import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.StopFilter;
 import org.apache.lucene.analysis.tokenattributes.TermAttribute;
 import org.apache.lucene.util.Version;
 
@@ -41,9 +42,10 @@ import org.apache.lucene.util.Version;
  * </ol>
  * 
  * @version 1.0
- *
+ * @deprecated Use {@link StopFilter} instead, which has the same functionality.
+ * This filter will be removed in Lucene 4.0
  */
-
+@Deprecated
 public final class ChineseFilter extends TokenFilter {
 
 
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cn/ChineseTokenizer.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cn/ChineseTokenizer.java
index 1e25ac5..7af1d4d 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cn/ChineseTokenizer.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cn/ChineseTokenizer.java
@@ -21,6 +21,7 @@ package org.apache.lucene.analysis.cn;
 import java.io.IOException;
 import java.io.Reader;
 
+import org.apache.lucene.analysis.standard.StandardTokenizer;
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
 import org.apache.lucene.analysis.tokenattributes.TermAttribute;
@@ -52,9 +53,10 @@ import org.apache.lucene.util.AttributeSource;
  * CJKTokenizer will not work.
  * </p>
  * @version 1.0
- *
+ * @deprecated Use {@link StandardTokenizer} instead, which has the same functionality.
+ * This filter will be removed in Lucene 4.0
  */
-
+@Deprecated
 public final class ChineseTokenizer extends Tokenizer {
 
 
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cn/package.html b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cn/package.html
index c513a29..6d9ea04 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cn/package.html
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cn/package.html
@@ -24,14 +24,14 @@ Analyzer for Chinese, which indexes unigrams (individual chinese characters).
 <p>
 Three analyzers are provided for Chinese, each of which treats Chinese text in a different way.
 <ul>
-	<li>ChineseAnalyzer (in this package): Index unigrams (individual Chinese characters) as a token.
+	<li>StandardAnalyzer: Index unigrams (individual Chinese characters) as a token.
 	<li>CJKAnalyzer (in the analyzers/cjk package): Index bigrams (overlapping groups of two adjacent Chinese characters) as tokens.
 	<li>SmartChineseAnalyzer (in the analyzers/smartcn package): Index words (attempt to segment Chinese text into words) as tokens.
 </ul>
 
 Example phraseï¼? "???ä¸??äº?"
 <ol>
-	<li>ChineseAnalyzer: ??????ä¸???½ï?äº?</li>
+	<li>StandardAnalyzer: ??????ä¸???½ï?äº?</li>
 	<li>CJKAnalyzer: ???ï¼??ä¸??ä¸??ï¼??äº?</li>
 	<li>SmartChineseAnalyzer: ??????ä¸??ï¼?ºº</li>
 </ol>
diff --git a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/cn/TestChineseTokenizer.java b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/cn/TestChineseTokenizer.java
index 63e4552..8f5d104 100644
--- a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/cn/TestChineseTokenizer.java
+++ b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/cn/TestChineseTokenizer.java
@@ -24,11 +24,12 @@ import java.io.StringReader;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.WhitespaceTokenizer;
 import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
 
 
+/** @deprecated Remove this test when ChineseAnalyzer is removed. */
+@Deprecated
 public class TestChineseTokenizer extends BaseTokenStreamTestCase
 {
     public void testOtherLetterOffset() throws IOException
diff --git a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/package.html b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/package.html
index bd6b632..86cc8d5 100644
--- a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/package.html
+++ b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/package.html
@@ -33,14 +33,14 @@ in such a case.
 <div>
 Three analyzers are provided for Chinese, each of which treats Chinese text in a different way.
 <ul>
-	<li>ChineseAnalyzer (in the analyzers/cn package): Index unigrams (individual Chinese characters) as a token.
+	<li>StandardAnalyzer: Index unigrams (individual Chinese characters) as a token.
 	<li>CJKAnalyzer (in the analyzers/cjk package): Index bigrams (overlapping groups of two adjacent Chinese characters) as tokens.
 	<li>SmartChineseAnalyzer (in this package): Index words (attempt to segment Chinese text into words) as tokens.
 </ul>
 
 Example phraseï¼? "???ä¸??äº?"
 <ol>
-	<li>ChineseAnalyzer: ??????ä¸???½ï?äº?</li>
+	<li>StandardAnalyzer: ??????ä¸???½ï?äº?</li>
 	<li>CJKAnalyzer: ???ï¼??ä¸??ä¸??ï¼??äº?</li>
 	<li>SmartChineseAnalyzer: ??????ä¸??ï¼?ºº</li>
 </ol>

