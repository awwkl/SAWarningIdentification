GitDiffStart: c56f4c224f997dbea0b4171f82fdfc76adb8f8ae | Thu Sep 3 18:31:41 2009 +0000
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ar/ArabicLetterTokenizer.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ar/ArabicLetterTokenizer.java
index f2bb46c..018509c 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ar/ArabicLetterTokenizer.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ar/ArabicLetterTokenizer.java
@@ -22,9 +22,11 @@ import org.apache.lucene.analysis.LetterTokenizer;
 import org.apache.lucene.util.AttributeSource;
 
 /**
+ * Tokenizer that breaks text into runs of letters and diacritics.
+ * <p>
  * The problem with the standard Letter tokenizer is that it fails on diacritics.
  * Handling similar to this is necessary for Indic Scripts, Hebrew, Thaana, etc.
- * 
+ * </p>
  *
  */
 public class ArabicLetterTokenizer extends LetterTokenizer {
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/br/BrazilianStemmer.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/br/BrazilianStemmer.java
index aaea8cc..095773b 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/br/BrazilianStemmer.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/br/BrazilianStemmer.java
@@ -36,7 +36,7 @@ public class BrazilianStemmer {
 	}
 
 	/**
-	 * Stemms the given term to an unique <tt>discriminator</tt>.
+	 * Stems the given term to an unique <tt>discriminator</tt>.
 	 *
 	 * @param term  The term that should be stemmed.
 	 * @return      Discriminator for <tt>term</tt>
@@ -115,7 +115,7 @@ public class BrazilianStemmer {
 	/**
 	 * Gets R1
    *
-   * R1 - is the region after the first non-vowel follwing a vowel,
+   * R1 - is the region after the first non-vowel following a vowel,
    *      or is the null region at the end of the word if there is
    *      no such non-vowel.
    *
@@ -159,13 +159,13 @@ public class BrazilianStemmer {
 	/**
 	 * Gets RV
    *
-   * RV - IF the second letter is a consoant, RV is the region after
+   * RV - IF the second letter is a consonant, RV is the region after
    *      the next following vowel,
    *
    *      OR if the first two letters are vowels, RV is the region
-   *      after the next consoant,
+   *      after the next consonant,
    *
-   *      AND otherwise (consoant-vowel case) RV is the region after
+   *      AND otherwise (consonant-vowel case) RV is the region after
    *      the third letter.
    *
    *      BUT RV is the end of the word if this positions cannot be
@@ -184,7 +184,7 @@ public class BrazilianStemmer {
 
     i = value.length()-1 ;
 
-    // RV - IF the second letter is a consoant, RV is the region after
+    // RV - IF the second letter is a consonant, RV is the region after
     //      the next following vowel,
     if ((i > 0) && !isVowel(value.charAt(1))) {
       // find 1st vowel
@@ -201,7 +201,7 @@ public class BrazilianStemmer {
 
 
     // RV - OR if the first two letters are vowels, RV is the region
-    //      after the next consoant,
+    //      after the next consonant,
     if ((i > 1) &&
         isVowel(value.charAt(0)) &&
         isVowel(value.charAt(1))) {
@@ -217,7 +217,7 @@ public class BrazilianStemmer {
       }
     }
 
-    // RV - AND otherwise (consoant-vowel case) RV is the region after
+    // RV - AND otherwise (consonant-vowel case) RV is the region after
     //      the third letter.
     if (i > 2) {
       return value.substring(3) ;
@@ -394,7 +394,7 @@ public class BrazilianStemmer {
 
 
 	/**
-	 * Standart suffix removal.
+	 * Standard suffix removal.
    * Search for the longest among the following suffixes, and perform
    * the following actions:
    *
@@ -403,12 +403,12 @@ public class BrazilianStemmer {
 	private boolean step1() {
     if (CT == null) return false ;
 
-    // suffix lenght = 7
+    // suffix length = 7
     if (suffix(CT,"uciones") && suffix(R2,"uciones")) {
         CT = replaceSuffix(CT,"uciones","u") ; return true;
     }
 
-    // suffix lenght = 6
+    // suffix length = 6
     if (CT.length() >= 6) {
       if (suffix(CT,"imentos") && suffix(R2,"imentos")) {
           CT = removeSuffix(CT,"imentos") ; return true;
@@ -436,7 +436,7 @@ public class BrazilianStemmer {
       }
     }
 
-    // suffix lenght = 5
+    // suffix length = 5
     if (CT.length() >= 5) {
       if (suffix(CT,"acoes") && suffix(R2,"acoes")) {
           CT = removeSuffix(CT,"acoes") ; return true;
@@ -473,7 +473,7 @@ public class BrazilianStemmer {
       }
     }
 
-    // suffix lenght = 4
+    // suffix length = 4
     if (CT.length() >= 4) {
       if (suffix(CT,"acao") && suffix(R2,"acao")) {
           CT = removeSuffix(CT,"acao") ; return true;
@@ -521,7 +521,7 @@ public class BrazilianStemmer {
       }
     }
 
-    // suffix lenght = 3
+    // suffix length = 3
     if (CT.length() >= 3) {
       if (suffix(CT,"eza") && suffix(R2,"eza")) {
           CT = removeSuffix(CT,"eza") ; return true ;
@@ -589,7 +589,7 @@ public class BrazilianStemmer {
       }
     }
 
-    // suffix lenght = 6
+    // suffix length = 6
     if (RV.length() >= 6) {
       if (suffix(RV,"iremos")) {
         CT = removeSuffix(CT,"iremos") ; return true;
@@ -633,7 +633,7 @@ public class BrazilianStemmer {
     }
 
 
-    // suffix lenght = 5
+    // suffix length = 5
     if (RV.length() >= 5) {
       if (suffix(RV,"irmos")) {
         CT = removeSuffix(CT,"irmos") ; return true;
@@ -718,7 +718,7 @@ public class BrazilianStemmer {
       }
     }
 
-    // suffix lenght = 4
+    // suffix length = 4
     if (RV.length() >= 4) {
       if (suffix(RV,"aria")) {
         CT = removeSuffix(CT,"aria") ; return true;
@@ -845,7 +845,7 @@ public class BrazilianStemmer {
       }
     }
 
-    // suffix lenght = 3
+    // suffix length = 3
     if (RV.length() >= 3) {
       if (suffix(RV,"ada")) {
         CT = removeSuffix(CT,"ada") ; return true;
@@ -888,7 +888,7 @@ public class BrazilianStemmer {
       }
     }
 
-    // suffix lenght = 2
+    // suffix length = 2
     if (RV.length() >= 2) {
       if (suffix(RV,"ia")) {
         CT = removeSuffix(CT,"ia") ; return true;
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilter.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilter.java
index 06d10ea..a41072b 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilter.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilter.java
@@ -150,7 +150,7 @@ public class HyphenationCompoundWordTokenFilter extends
   }
 
   protected void decomposeInternal(final Token token) {
-    // get the hpyphenation points
+    // get the hyphenation points
     Hyphenation hyphens = hyphenator.hyphenate(token.termBuffer(), 0, token
         .termLength(), 1, 1);
     // No hyphen points found -> exit
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/hyphenation/TernaryTree.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/hyphenation/TernaryTree.java
index b327cd7..385ff47 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/hyphenation/TernaryTree.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/hyphenation/TernaryTree.java
@@ -25,7 +25,7 @@ import java.io.Serializable;
  * <h2>Ternary Search Tree.</h2>
  * 
  * <p>
- * A ternary search tree is a hibrid between a binary tree and a digital search
+ * A ternary search tree is a hybrid between a binary tree and a digital search
  * tree (trie). Keys are limited to strings. A data value of type char is stored
  * in each leaf node. It can be used as an index (or pointer) to the data.
  * Branches that only contain one key are compressed to one node by storing a
@@ -45,7 +45,7 @@ import java.io.Serializable;
  * requires from 5000 to 15000 hyphenation patterns which will be keys in this
  * tree. The strings patterns are usually small (from 2 to 5 characters), but
  * each char in the tree is stored in a node. Thus memory usage is the main
- * concern. We will sacrify 'elegance' to keep memory requirenments to the
+ * concern. We will sacrifice 'elegance' to keep memory requirements to the
  * minimum. Using java's char type as pointer (yes, I know pointer it is a
  * forbidden word in java) we can keep the size of the node to be just 8 bytes
  * (3 pointers and the data char). This gives room for about 65000 nodes. In my
@@ -100,7 +100,7 @@ public class TernaryTree implements Cloneable, Serializable {
    * </ul>
    * <p>
    * This shouldn't be a problem if we give the usual semantics to strings since
-   * 0xFFFF is garanteed not to be an Unicode character.
+   * 0xFFFF is guaranteed not to be an Unicode character.
    * </p>
    */
   protected char[] sc;
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/hyphenation/package.html b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/hyphenation/package.html
index a3b5bb5..3ed4ef0 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/hyphenation/package.html
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/hyphenation/package.html
@@ -17,7 +17,7 @@
 
 <html>
   <head>
-    <title>Hypenation code for the CompoundWordTokenFilter</title>
+    <title>Hyphenation code for the CompoundWordTokenFilter</title>
   </head>
   <body>
     <p>
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/package.html b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/package.html
index b8de9ee..e513b23 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/package.html
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/package.html
@@ -69,7 +69,7 @@ The input token is always preserved and the filters do not alter the case of wor
 filter available:
 <ul>
 	<li><i>HyphenationCompoundWordTokenFilter</i>: it uses a
-	hyphenation grammer based approach to find potential word parts of a
+	hyphenation grammar based approach to find potential word parts of a
 	given word.</li>
 	<li><i>DictionaryCompoundWordTokenFilter</i>: it uses a
 	brute-force dictionary-only based approach to find the word parts of a given
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fr/FrenchStemmer.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fr/FrenchStemmer.java
index 8dc6bf5..987df98 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fr/FrenchStemmer.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fr/FrenchStemmer.java
@@ -79,7 +79,7 @@ public class FrenchStemmer {
 
 
     /**
-     * Stemms the given term to a unique <tt>discriminator</tt>.
+     * Stems the given term to a unique <tt>discriminator</tt>.
      *
      * @param term  java.langString The term that should be stemmed
      * @return java.lang.String  Discriminator for <tt>term</tt>
@@ -148,7 +148,7 @@ public class FrenchStemmer {
 	}
 
 	/**
-	 * First step of the Porter Algorithmn<br>
+	 * First step of the Porter Algorithm<br>
 	 * refer to http://snowball.sourceforge.net/french/stemmer.html for an explanation
 	 */
 	private void step1( ) {
@@ -202,7 +202,7 @@ public class FrenchStemmer {
 	}
 
 	/**
-	 * Second step (A) of the Porter Algorithmn<br>
+	 * Second step (A) of the Porter Algorithm<br>
 	 * Will be performed if nothing changed from the first step
 	 * or changed were done in the amment, emment, ments or ment suffixes<br>
 	 * refer to http://snowball.sourceforge.net/french/stemmer.html for an explanation
@@ -219,7 +219,7 @@ public class FrenchStemmer {
 	}
 
 	/**
-	 * Second step (B) of the Porter Algorithmn<br>
+	 * Second step (B) of the Porter Algorithm<br>
 	 * Will be performed if step 2 A was performed unsuccessfully<br>
 	 * refer to http://snowball.sourceforge.net/french/stemmer.html for an explanation
 	 */
@@ -238,7 +238,7 @@ public class FrenchStemmer {
 	}
 
 	/**
-	 * Third step of the Porter Algorithmn<br>
+	 * Third step of the Porter Algorithm<br>
 	 * refer to http://snowball.sourceforge.net/french/stemmer.html for an explanation
 	 */
 	private void step3() {
@@ -259,7 +259,7 @@ public class FrenchStemmer {
 	}
 
 	/**
-	 * Fourth step of the Porter Algorithmn<br>
+	 * Fourth step of the Porter Algorithm<br>
 	 * refer to http://snowball.sourceforge.net/french/stemmer.html for an explanation
 	 */
 	private void step4() {
@@ -286,7 +286,7 @@ public class FrenchStemmer {
 	}
 
 	/**
-	 * Fifth step of the Porter Algorithmn<br>
+	 * Fifth step of the Porter Algorithm<br>
 	 * refer to http://snowball.sourceforge.net/french/stemmer.html for an explanation
 	 */
 	private void step5() {
@@ -301,7 +301,7 @@ public class FrenchStemmer {
 	}
 
 	/**
-	 * Sixth (and last!) step of the Porter Algorithmn<br>
+	 * Sixth (and last!) step of the Porter Algorithm<br>
 	 * refer to http://snowball.sourceforge.net/french/stemmer.html for an explanation
 	 */
 	private void step6() {
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/nl/DutchStemmer.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/nl/DutchStemmer.java
index 84f35f0..35a6c2a 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/nl/DutchStemmer.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/nl/DutchStemmer.java
@@ -41,7 +41,7 @@ public class DutchStemmer {
 
   //TODO convert to internal
   /*
-   * Stemms the given term to an unique <tt>discriminator</tt>.
+   * Stems the given term to an unique <tt>discriminator</tt>.
    *
    * @param term The term that should be stemmed.
    * @return Discriminator for <tt>term</tt>
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ru/RussianStemmer.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ru/RussianStemmer.java
index 42f076d..1cf4f17 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ru/RussianStemmer.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ru/RussianStemmer.java
@@ -372,7 +372,7 @@ class RussianStemmer
 
     /**
      * Finds the ending among the given class of endings, then checks if this ending was
-     * preceded by any of given predessors, and if so, removes it from stemming zone.
+     * preceded by any of given predecessors, and if so, removes it from stemming zone.
      * Creation date: (17/03/2002 8:18:34 PM)
      */
     private boolean findAndRemoveEnding(StringBuffer stemmingZone,
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/shingle/ShingleMatrixFilter.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/shingle/ShingleMatrixFilter.java
index 9388e5b..799548d 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/shingle/ShingleMatrixFilter.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/shingle/ShingleMatrixFilter.java
@@ -51,10 +51,10 @@ import org.apache.lucene.index.Payload;
  * be used to replace phrase queries, especially them with 0 slop.
  *
  * <p>Without a spacer character
- * it can be used to handle composition and decomposion of words
+ * it can be used to handle composition and decomposition of words
  * such as searching for "multi dimensional" instead of "multidimensional".
  * It is a rather common human problem at query time
- * in several languages, notebly the northern Germanic branch.
+ * in several languages, notably the northern Germanic branch.
  *
  * <p>Shingles are amongst many things also known to solve problems
  * in spell checking, language detection and document clustering.
@@ -108,7 +108,7 @@ import org.apache.lucene.index.Payload;
  * so it never created the same shingle more than once in the first place.
  *
  * <p>The filter also has basic support for calculating weights for the shingles
- * based on the weights of the tokens from the input stream, output shingle size, et c.
+ * based on the weights of the tokens from the input stream, output shingle size, etc.
  * See {@link #calculateShingleWeight(org.apache.lucene.analysis.Token, java.util.List, int, java.util.List, java.util.List)}.
  * <p/>
  * <b>NOTE:</b> This filter might not behave correctly if used with custom Attributes, i.e. Attributes other than
@@ -253,7 +253,7 @@ public class ShingleMatrixFilter extends TokenStream {
    * @see #ignoringSinglePrefixOrSuffixShingleByDefault
    * @see #defaultSettingsCodec
    *
-   * @param input stream from wich to construct the matrix
+   * @param input stream from which to construct the matrix
    * @param minimumShingleSize minimum number of tokens in any shingle.
    * @param maximumShingleSize maximum number of tokens in any shingle.
    */
@@ -268,7 +268,7 @@ public class ShingleMatrixFilter extends TokenStream {
    * @see #ignoringSinglePrefixOrSuffixShingleByDefault
    * @see #defaultSettingsCodec
    *
-   * @param input stream from wich to construct the matrix
+   * @param input stream from which to construct the matrix
    * @param minimumShingleSize minimum number of tokens in any shingle.
    * @param maximumShingleSize maximum number of tokens in any shingle.
    * @param spacerCharacter character to use between texts of the token parts in a shingle. null for none.
@@ -282,7 +282,7 @@ public class ShingleMatrixFilter extends TokenStream {
    *
    * @see #defaultSettingsCodec
    *
-   * @param input stream from wich to construct the matrix
+   * @param input stream from which to construct the matrix
    * @param minimumShingleSize minimum number of tokens in any shingle.
    * @param maximumShingleSize maximum number of tokens in any shingle.
    * @param spacerCharacter character to use between texts of the token parts in a shingle. null for none.
@@ -296,7 +296,7 @@ public class ShingleMatrixFilter extends TokenStream {
   /**
    * Creates a shingle filter with ad hoc parameter settings.
    *
-   * @param input stream from wich to construct the matrix
+   * @param input stream from which to construct the matrix
    * @param minimumShingleSize minimum number of tokens in any shingle.
    * @param maximumShingleSize maximum number of tokens in any shingle.
    * @param spacerCharacter character to use between texts of the token parts in a shingle. null for none.
@@ -408,8 +408,8 @@ public class ShingleMatrixFilter extends TokenStream {
   private static final Token request_next_token = new Token();
 
   /**
-   * This method exists in order to avoid reursive calls to the method
-   * as the complexity of a fairlt small matrix then easily would require
+   * This method exists in order to avoid recursive calls to the method
+   * as the complexity of a fairly small matrix then easily would require
    * a gigabyte sized stack per thread.
    *
    * @param reusableToken
@@ -490,7 +490,7 @@ public class ShingleMatrixFilter extends TokenStream {
             // don't really care, we just read it.
           }
 
-          // get rith of resources
+          // get rid of resources
 
           // delete the first column in the matrix
           Matrix.Column deletedColumn = (Matrix.Column) matrix.columns.remove(0);
diff --git a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/BigramDictionary.java b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/BigramDictionary.java
index 8fa8e9d..127a2ff 100644
--- a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/BigramDictionary.java
+++ b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/BigramDictionary.java
@@ -147,7 +147,7 @@ class BigramDictionary extends AbstractDictionary {
   /**
    * Load the datafile into this BigramDictionary
    * 
-   * @param dctFilePath path to the Bigramdictionary (bigramdict.mem)
+   * @param dctFilePath path to the Bigramdictionary (bigramdict.dct)
    * @throws FileNotFoundException
    * @throws IOException
    * @throws UnsupportedEncodingException
diff --git a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/WordDictionary.java b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/WordDictionary.java
index c76b1a3..cdc8871 100644
--- a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/WordDictionary.java
+++ b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/WordDictionary.java
@@ -184,7 +184,7 @@ class WordDictionary extends AbstractDictionary {
   /**
    * Load the datafile into this WordDictionary
    * 
-   * @param dctFilePath path to word dictionary (coredict.mem)
+   * @param dctFilePath path to word dictionary (coredict.dct)
    * @return number of words read
    * @throws FileNotFoundException
    * @throws IOException
diff --git a/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/NoMoreDataException.java b/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/NoMoreDataException.java
index 4fa1109..a4e9ed8 100755
--- a/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/NoMoreDataException.java
+++ b/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/NoMoreDataException.java
@@ -20,7 +20,7 @@ package org.apache.lucene.benchmark.byTask.feeds;
 /**
  * Exception indicating there is no more data.
  * Thrown by Docs Makers if doc.maker.forever is false and docs sources of that maker where exhausted.
- * This is usefull for iterating all document of a source, in case we don't know in advance how many docs there are.
+ * This is useful for iterating all document of a source, in case we don't know in advance how many docs there are.
  */
 public class NoMoreDataException extends Exception {
 
diff --git a/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/SimpleQueryMaker.java b/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/SimpleQueryMaker.java
index d440a71..77d1812 100644
--- a/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/SimpleQueryMaker.java
+++ b/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/SimpleQueryMaker.java
@@ -36,9 +36,9 @@ public class SimpleQueryMaker extends AbstractQueryMaker implements QueryMaker {
 
   /**
    * Prepare the queries for this test.
-   * Extending classes can overide this method for preparing different queries. 
+   * Extending classes can override this method for preparing different queries. 
    * @return prepared queries.
-   * @throws Exception if canot prepare the queries.
+   * @throws Exception if cannot prepare the queries.
    */
   protected Query[] prepareQueries() throws Exception {
     // analyzer (default is standard analyzer)
diff --git a/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/SimpleSloppyPhraseQueryMaker.java b/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/SimpleSloppyPhraseQueryMaker.java
index 73feda9..8da8d91 100644
--- a/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/SimpleSloppyPhraseQueryMaker.java
+++ b/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/SimpleSloppyPhraseQueryMaker.java
@@ -33,7 +33,7 @@ public class SimpleSloppyPhraseQueryMaker extends SimpleQueryMaker {
    * @see org.apache.lucene.benchmark.byTask.feeds.SimpleQueryMaker#prepareQueries()
    */
   protected Query[] prepareQueries() throws Exception {
-    // exatract some 100 words from doc text to an array
+    // extract some 100 words from doc text to an array
     String words[];
     ArrayList w = new ArrayList();
     StringTokenizer st = new StringTokenizer(SingleDocSource.DOC_TEXT);
@@ -60,7 +60,7 @@ public class SimpleSloppyPhraseQueryMaker extends SimpleQueryMaker {
             }
           }
           queries.add(q);
-          // reveresed
+          // reversed
           remainedSlop = slop;
           q = new PhraseQuery();
           q.setSlop(slop+2*qlen);
diff --git a/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/programmatic/Sample.java b/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/programmatic/Sample.java
index dbf99b6..6a1a603 100644
--- a/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/programmatic/Sample.java
+++ b/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/programmatic/Sample.java
@@ -28,7 +28,7 @@ import org.apache.lucene.benchmark.byTask.tasks.TaskSequence;
 import org.apache.lucene.benchmark.byTask.utils.Config;
 
 /**
- * Sample performance test written programatically - no algorithm file is needed here.
+ * Sample performance test written programmatically - no algorithm file is needed here.
  */
 public class Sample {
 
@@ -43,7 +43,7 @@ public class Sample {
     PerfRunData runData = new PerfRunData(conf);
     
     // 1. top sequence
-    TaskSequence top = new TaskSequence(runData,null,null,false); // top level, not parralel
+    TaskSequence top = new TaskSequence(runData,null,null,false); // top level, not parallel
     
     // 2. task to create the index
     CreateIndexTask create = new CreateIndexTask(runData);
diff --git a/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/programmatic/package.html b/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/programmatic/package.html
index a66bb36..7221c42 100644
--- a/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/programmatic/package.html
+++ b/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/programmatic/package.html
@@ -17,6 +17,6 @@
 -->
 <html>
 <body>
-Sample performance test written programatically - no algorithm file is needed here.
+Sample performance test written programmatically - no algorithm file is needed here.
 </body>
 </html>
\ No newline at end of file
diff --git a/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/stats/Report.java b/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/stats/Report.java
index 05cff53..1db8f6e 100644
--- a/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/stats/Report.java
+++ b/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/stats/Report.java
@@ -42,7 +42,7 @@ public class Report {
   }
 
   /**
-   * Returns number of lines in the reoprt.
+   * Returns number of lines in the report.
    */
   public int getSize() {
     return size;
diff --git a/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/stats/TaskStats.java b/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/stats/TaskStats.java
index 7138b9a..61f94ca 100644
--- a/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/stats/TaskStats.java
+++ b/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/stats/TaskStats.java
@@ -171,7 +171,7 @@ public class TaskStats implements Cloneable {
     maxUsedMem += stat2.getMaxUsedMem();
     count += stat2.getCount();
     if (round != stat2.round) {
-      round = -1; // no meaning if agregating tasks of different ruond. 
+      round = -1; // no meaning if aggregating tasks of different round. 
     }
   }
 
diff --git a/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/OpenReaderTask.java b/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/OpenReaderTask.java
index a2a8b0f..c6fe4ae 100644
--- a/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/OpenReaderTask.java
+++ b/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/OpenReaderTask.java
@@ -31,7 +31,7 @@ import org.apache.lucene.store.Directory;
 
 /**
  * Open an index reader.
- * <br>Other side effects: index redaer object in perfRunData is set.
+ * <br>Other side effects: index reader object in perfRunData is set.
  * <br> Optional params readOnly,commitUserData eg. OpenReader(false,commit1)
  */
 public class OpenReaderTask extends PerfTask {
diff --git a/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/PerfTask.java b/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/PerfTask.java
index dcfc49f..fe4968f 100644
--- a/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/PerfTask.java
+++ b/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/PerfTask.java
@@ -28,8 +28,8 @@ import org.apache.lucene.benchmark.byTask.utils.Format;
 /**
  * An abstract task to be tested for performance. <br>
  * Every performance task extends this class, and provides its own
- * {@link #doLogic()} method, which performss the actual task. <br>
- * Tasks performing some work that should be measured for the task, can overide
+ * {@link #doLogic()} method, which performs the actual task. <br>
+ * Tasks performing some work that should be measured for the task, can override
  * {@link #setup()} and/or {@link #tearDown()} and place that work there. <br>
  * Relevant properties: <code>task.max.depth.log</code>.<br>
  * Also supports the following logging attributes:
@@ -40,7 +40,7 @@ import org.apache.lucene.benchmark.byTask.utils.Format;
  * <li>log.step.[class Task Name] - specifies the same as 'log.step', only for a
  * particular task name. For example, log.step.AddDoc will be applied only for
  * {@link AddDocTask}, but not for {@link DeleteDocTask}. It's a way to control
- * per task logging settings. If you want to ommit logging for any other task,
+ * per task logging settings. If you want to omit logging for any other task,
  * include log.step=-1. The syntax is "log.step." together with the Task's
  * 'short' name (i.e., without the 'Task' part).
  * </ul>
@@ -118,8 +118,8 @@ public abstract class PerfTask implements Cloneable {
   }
   
   protected Object clone() throws CloneNotSupportedException {
-    // tasks having non primitive data structures should overide this.
-    // otherwise parallel running of a task sequence might not run crrectly. 
+    // tasks having non primitive data structures should override this.
+    // otherwise parallel running of a task sequence might not run correctly. 
     return super.clone();
   }
 
@@ -152,7 +152,7 @@ public abstract class PerfTask implements Cloneable {
   }
 
   /**
-   * Perform the task once (ignoring repetions specification)
+   * Perform the task once (ignoring repetitions specification)
    * Return number of work items done by this task.
    * For indexing that can be number of docs added.
    * For warming that can be number of scanned items, etc.
@@ -230,7 +230,7 @@ public abstract class PerfTask implements Cloneable {
   }
   
   /**
-   * Tasks that should never log at start can overide this.  
+   * Tasks that should never log at start can override this.  
    * @return true if this task should never log when it start.
    */
   protected boolean shouldNeverLogAtStart () {
@@ -238,7 +238,7 @@ public abstract class PerfTask implements Cloneable {
   }
   
   /**
-   * Tasks that should not record statistics can overide this.  
+   * Tasks that should not record statistics can override this.  
    * @return true if this task should never record its statistics.
    */
   protected boolean shouldNotRecordStats () {
@@ -274,7 +274,7 @@ public abstract class PerfTask implements Cloneable {
   }
 
   /**
-   * Sub classes that supports parameters must overide this method to return true.
+   * Sub classes that supports parameters must override this method to return true.
    * @return true iff this task supports command line params.
    */
   public boolean supportsParams () {
diff --git a/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTask.java b/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTask.java
index 6d95d63..815749a 100644
--- a/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTask.java
+++ b/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTask.java
@@ -250,7 +250,7 @@ public abstract class ReadTask extends PerfTask {
   }
 
   /**
-   * @return the maxiumum number of highlighter fragments
+   * @return the maximum number of highlighter fragments
    * @deprecated Please define getBenchmarkHighlighter instead
    */
   final int maxNumFragments(){
diff --git a/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ResetSystemEraseTask.java b/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ResetSystemEraseTask.java
index 1da7490..f9a9a4c 100644
--- a/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ResetSystemEraseTask.java
+++ b/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ResetSystemEraseTask.java
@@ -24,7 +24,7 @@ import org.apache.lucene.benchmark.byTask.PerfRunData;
 /**
  * Reset all index and input data and call gc, erase index and dir, does NOT clear statistics.
  * <br>This contains ResetInputs.
- * <br>Other side effects: writers/readers nulified, deleted, closed.
+ * <br>Other side effects: writers/readers nullified, deleted, closed.
  * Index is erased.
  * Directory is erased.
  */
diff --git a/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ResetSystemSoftTask.java b/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ResetSystemSoftTask.java
index ac684cd..f0bb219 100644
--- a/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ResetSystemSoftTask.java
+++ b/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ResetSystemSoftTask.java
@@ -24,7 +24,7 @@ import org.apache.lucene.benchmark.byTask.PerfRunData;
 /**
  * Reset all index and input data and call gc, does NOT erase index/dir, does NOT clear statistics.
  * This contains ResetInputs.
- * <br>Other side effects: writers/readers nulified, closed.
+ * <br>Other side effects: writers/readers nullified, closed.
  * Index is NOT erased.
  * Directory is NOT erased.
  */
diff --git a/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/SetPropTask.java b/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/SetPropTask.java
index 6a5ad08..e9baf69 100644
--- a/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/SetPropTask.java
+++ b/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/SetPropTask.java
@@ -21,7 +21,7 @@ import org.apache.lucene.benchmark.byTask.PerfRunData;
 
 /**
  * Set a performance test configuration property.
- * A property may have a single value, or a sequence of values, seprated by ":". 
+ * A property may have a single value, or a sequence of values, separated by ":". 
  * If a sequence of values is specified, each time a new round starts, 
  * the next (cyclic) value is taken.  
  * <br>Other side effects: none.
diff --git a/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/TaskSequence.java b/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/TaskSequence.java
index 3bea29b..8340d1c 100644
--- a/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/TaskSequence.java
+++ b/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/TaskSequence.java
@@ -251,7 +251,7 @@ public class TaskSequence extends PerfTask {
     }
   }
 
-  // run threadsm with rate
+  // run threads with rate
   private void startlThreadsWithRate(Thread[] t) throws InterruptedException {
     long delayStep = (perMin ? 60000 : 1000) /rate;
     long nextStartTime = System.currentTimeMillis();
@@ -261,7 +261,7 @@ public class TaskSequence extends PerfTask {
         //System.out.println("thread wait: "+waitMore+" for rate: "+ratePerMin+" (delayStep="+delayStep+")");
         Thread.sleep(waitMore);
       }
-      nextStartTime += delayStep; // this aims at avarage rate of starting threads. 
+      nextStartTime += delayStep; // this aims at average rate of starting threads. 
       t[i].start();
     }
   }
@@ -346,7 +346,7 @@ public class TaskSequence extends PerfTask {
   }
 
   public String getName() {
-    return seqName; // overide to include more info 
+    return seqName; // override to include more info 
   }
 
   /**
diff --git a/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.java b/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.java
index 9daabd5..3f883ce 100644
--- a/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.java
+++ b/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.java
@@ -35,9 +35,9 @@ import org.apache.lucene.document.Field;
 /**
  * A task which writes documents, one line per document. Each line is in the
  * following format: title &lt;TAB&gt; date &lt;TAB&gt; body. The output of this
- * taske can be consumed by
+ * task can be consumed by
  * {@link org.apache.lucene.benchmark.byTask.feeds.LineDocMaker} and is intended
- * to save the IO overhead of opening a file per doument to be indexed.<br>
+ * to save the IO overhead of opening a file per document to be indexed.<br>
  * Supports the following parameters:
  * <ul>
  * <li>line.file.out - the name of the file to write the output to. That
@@ -47,7 +47,7 @@ import org.apache.lucene.document.Field;
  * false).
  * </ul>
  * <b>NOTE:</b> this class is not thread-safe and if used by multiple threads the
- * output is unspecified (as all will write to the same ouput file in a
+ * output is unspecified (as all will write to the same output file in a
  * non-synchronized way).
  */
 public class WriteLineDocTask extends PerfTask {
diff --git a/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/utils/Config.java b/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/utils/Config.java
index bcb4b47..8f2bd7c 100644
--- a/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/utils/Config.java
+++ b/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/utils/Config.java
@@ -32,7 +32,7 @@ import java.util.StringTokenizer;
 /**
  * Perf run configuration properties.
  * <p>
- * Numeric peroperty containing ":", e.g. "10:100:5" is interpreted 
+ * Numeric property containing ":", e.g. "10:100:5" is interpreted 
  * as array of numeric values. It is extracted once, on first use, and 
  * maintain a round number to return the appropriate value.
  * <p>
@@ -99,7 +99,7 @@ public class Config {
   }
 
   /**
-   * Create config without algorithm - usefull for a programmatic perf test.
+   * Create config without algorithm - useful for a programmatic perf test.
    * @param props - configuration properties.
    * @throws IOException
    */
@@ -135,7 +135,7 @@ public class Config {
    * Set a property.
    * Note: once a multiple values property is set, it can no longer be modified.
    * @param name name of property.
-   * @param value either single or multiple propery value (multple values are separated by ":")
+   * @param value either single or multiple property value (multiple values are separated by ":")
    * @throws Exception 
    */
   public void set (String name, String value) throws Exception {
@@ -208,7 +208,7 @@ public class Config {
   /**
    * Return a boolean property.
    * If the property contain ":", e.g. "true.true.false", it is interpreted 
-   * as array of boleans. It is extracted once, on first call
+   * as array of booleans. It is extracted once, on first call
    * to get() it, and a by-round-value is returned. 
    * @param name name of property
    * @param dflt default value
diff --git a/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/utils/Format.java b/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/utils/Format.java
index e689f6c..f0e8163 100644
--- a/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/utils/Format.java
+++ b/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/utils/Format.java
@@ -58,7 +58,7 @@ public class Format {
   }
 
   /**
-   * Padd a number from right.
+   * Pad a number from right.
    * @param numFracDigits number of digits in fraction part - must be 0 or 1 or 2.
    * @param f number to be formatted.
    * @param col column name (used for deciding on length).
@@ -75,7 +75,7 @@ public class Format {
   }
 
   /**
-   * Padd a number from left.
+   * Pad a number from left.
    * @param n number to be formatted.
    * @param col column name (used for deciding on length).
    * @return formatted string.
@@ -86,7 +86,7 @@ public class Format {
   }
 
   /**
-   * Padd a string from right.
+   * Pad a string from right.
    * @param s string to be formatted.
    * @param col column name (used for deciding on length).
    * @return formatted string.
@@ -97,7 +97,7 @@ public class Format {
   }
 
   /**
-   * Padd a string from left.
+   * Pad a string from left.
    * @param s string to be formatted.
    * @param col column name (used for deciding on length).
    * @return formatted string.
diff --git a/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/utils/StringBufferReader.java b/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/utils/StringBufferReader.java
index 097b89f..3aef8c8 100644
--- a/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/utils/StringBufferReader.java
+++ b/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/utils/StringBufferReader.java
@@ -37,7 +37,7 @@ import java.io.Reader;
  * <pre>
  * StringBuffer sb = new StringBuffer("some text");
  * Reader reader = new StringBufferReader(sb);
- * ... read from reader - dont close it ! ...
+ * ... read from reader - don't close it ! ...
  * sb.setLength(0);
  * sb.append("some new text");
  * reader.reset();
diff --git a/contrib/benchmark/src/java/org/apache/lucene/benchmark/quality/QualityBenchmark.java b/contrib/benchmark/src/java/org/apache/lucene/benchmark/quality/QualityBenchmark.java
index 3ed30d0..73a76b5 100644
--- a/contrib/benchmark/src/java/org/apache/lucene/benchmark/quality/QualityBenchmark.java
+++ b/contrib/benchmark/src/java/org/apache/lucene/benchmark/quality/QualityBenchmark.java
@@ -63,7 +63,7 @@ public class QualityBenchmark {
    * @param qqs quality queries to run.
    * @param qqParser parser for turning QualityQueries into Lucene Queries. 
    * @param searcher index to be searched.
-   * @param docNameField name of field containg the document name.
+   * @param docNameField name of field containing the document name.
    *        This allows to extract the doc name for search results,
    *        and is important for judging the results.  
    */
@@ -114,7 +114,7 @@ public class QualityBenchmark {
   private QualityStats analyzeQueryResults(QualityQuery qq, Query q, TopDocs td, Judge judge, PrintWriter logger, long searchTime) throws IOException {
     QualityStats stts = new QualityStats(judge.maxRecall(qq),searchTime);
     ScoreDoc sd[] = td.scoreDocs;
-    long t1 = System.currentTimeMillis(); // extraction of first doc name we meassure also construction of doc name extractor, just in case.
+    long t1 = System.currentTimeMillis(); // extraction of first doc name we measure also construction of doc name extractor, just in case.
     DocNameExtractor xt = new DocNameExtractor(docNameField);
     for (int i=0; i<sd.length; i++) {
       String docName = xt.docName(searcher,sd[i].doc);
diff --git a/contrib/benchmark/src/java/org/apache/lucene/benchmark/quality/QualityStats.java b/contrib/benchmark/src/java/org/apache/lucene/benchmark/quality/QualityStats.java
index 12c9182..cfea796 100644
--- a/contrib/benchmark/src/java/org/apache/lucene/benchmark/quality/QualityStats.java
+++ b/contrib/benchmark/src/java/org/apache/lucene/benchmark/quality/QualityStats.java
@@ -215,7 +215,7 @@ public class QualityStats {
       }
     }
     assert m>0 : "Fishy: no \"good\" queries!";
-    // take average: times go by all queries, other meassures go by "good" queries noly.
+    // take average: times go by all queries, other measures go by "good" queries only.
     avg.searchTime /= stats.length;
     avg.docNamesExtractTime /= stats.length;
     avg.numGoodPoints /= m;
diff --git a/contrib/benchmark/src/java/org/apache/lucene/benchmark/quality/utils/QualityQueriesFinder.java b/contrib/benchmark/src/java/org/apache/lucene/benchmark/quality/utils/QualityQueriesFinder.java
index 632d790..820b832 100755
--- a/contrib/benchmark/src/java/org/apache/lucene/benchmark/quality/utils/QualityQueriesFinder.java
+++ b/contrib/benchmark/src/java/org/apache/lucene/benchmark/quality/utils/QualityQueriesFinder.java
@@ -36,7 +36,7 @@ public class QualityQueriesFinder {
   private Directory dir;
   
   /**
-   * Constrctor over a directory containing the index.
+   * Constructor over a directory containing the index.
    * @param dir directory containing the index we search for the quality test. 
    */
   private QualityQueriesFinder(Directory dir) {
diff --git a/contrib/benchmark/src/java/org/apache/lucene/benchmark/stats/TestData.java b/contrib/benchmark/src/java/org/apache/lucene/benchmark/stats/TestData.java
index 0ed7e41..d4d76af 100644
--- a/contrib/benchmark/src/java/org/apache/lucene/benchmark/stats/TestData.java
+++ b/contrib/benchmark/src/java/org/apache/lucene/benchmark/stats/TestData.java
@@ -177,7 +177,7 @@ public class TestData
                     }
                     dc.count++;
                     //dc.total += td.getRate();
-                    dc.total += (td.count>0 && td.elapsed<=0 ? 1 : td.elapsed); // assume atleast 1ms for any countable op
+                    dc.total += (td.count>0 && td.elapsed<=0 ? 1 : td.elapsed); // assume at least 1ms for any countable op
                     dc.recordCount += td.count;
                 }
             }
@@ -204,7 +204,7 @@ public class TestData
             }
             ldc.Dcount += dc.count;
             ldc.DrecordCount += dc.recordCount;
-            ldc.Dtotal += (dc.count>0 && dc.total<=0 ? 1 : dc.total); // assume atleast 1ms for any countable op 
+            ldc.Dtotal += (dc.count>0 && dc.total<=0 ? 1 : dc.total); // assume at least 1ms for any countable op 
         }
         it = mapMem.keySet().iterator();
         while (it.hasNext())
@@ -281,20 +281,20 @@ public class TestData
       numFormat[1].setMinimumFractionDigits(1);
     }
 
-    // padd number from left
+    // pad number from left
     // numFracDigits must be 0 or 1.
     static String format(int numFracDigits, float f, String col) {
       String res = padd + numFormat[numFracDigits].format(f);
       return res.substring(res.length() - col.length());
     }
 
-    // padd number from left
+    // pad number from left
     static String format(int n, String col) {
       String res = padd + n;
       return res.substring(res.length() - col.length());
     }
 
-    // padd string from right
+    // pad string from right
     static String format(String s, String col) {
       return (s + padd).substring(0,col.length());
     }
@@ -350,7 +350,7 @@ public class TestData
     /**
      * Similar to {@link #getAll(java.io.File[], org.apache.lucene.analysis.Analyzer[])} but only uses
      * maxBufferedDocs of 10 and 100 and same for mergeFactor, thus reducing the number of permutations significantly.
-     * It also only uses compund file and optimize is always true.
+     * It also only uses compound file and optimize is always true.
      *
      * @param sources
      * @param analyzers
diff --git a/contrib/benchmark/src/java/org/apache/lucene/benchmark/stats/TimeData.java b/contrib/benchmark/src/java/org/apache/lucene/benchmark/stats/TimeData.java
index 81b0685..e037778 100644
--- a/contrib/benchmark/src/java/org/apache/lucene/benchmark/stats/TimeData.java
+++ b/contrib/benchmark/src/java/org/apache/lucene/benchmark/stats/TimeData.java
@@ -77,7 +77,7 @@ public class TimeData {
 
   /** Get rate of processing, defined as number of processed records per second. */
   public double getRate() {
-    double rps = (double) count * 1000.0 / (double) (elapsed>0 ? elapsed : 1); // assume atleast 1ms for any countable op
+    double rps = (double) count * 1000.0 / (double) (elapsed>0 ? elapsed : 1); // assume at least 1ms for any countable op
     return rps;
   }
 
@@ -88,7 +88,7 @@ public class TimeData {
 
   public String toString() { return toString(true); }
   /**
-   * Return a tab-seprated string containing this data.
+   * Return a tab-separated string containing this data.
    * @param withMem if true, append also memory information
    * @return The String
    */
diff --git a/contrib/fast-vector-highlighter/src/java/org/apache/lucene/search/vectorhighlight/ScoreOrderFragmentsBuilder.java b/contrib/fast-vector-highlighter/src/java/org/apache/lucene/search/vectorhighlight/ScoreOrderFragmentsBuilder.java
index b626c8e..04edd12 100644
--- a/contrib/fast-vector-highlighter/src/java/org/apache/lucene/search/vectorhighlight/ScoreOrderFragmentsBuilder.java
+++ b/contrib/fast-vector-highlighter/src/java/org/apache/lucene/search/vectorhighlight/ScoreOrderFragmentsBuilder.java
@@ -38,7 +38,7 @@ public class ScoreOrderFragmentsBuilder extends BaseFragmentsBuilder {
   /**
    * a constructor.
    * 
-   * @param preTags aray of pre-tags for markup terms.
+   * @param preTags array of pre-tags for markup terms.
    * @param postTags array of post-tags for markup terms.
    */
   public ScoreOrderFragmentsBuilder( String[] preTags, String[] postTags ){
diff --git a/contrib/highlighter/src/java/org/apache/lucene/search/highlight/GradientFormatter.java b/contrib/highlighter/src/java/org/apache/lucene/search/highlight/GradientFormatter.java
index c3c8dd2..f02bbdd 100644
--- a/contrib/highlighter/src/java/org/apache/lucene/search/highlight/GradientFormatter.java
+++ b/contrib/highlighter/src/java/org/apache/lucene/search/highlight/GradientFormatter.java
@@ -42,7 +42,7 @@ public class GradientFormatter implements Formatter
      * 
      * @param maxScore
      *            The score (and above) displayed as maxColor (See QueryScorer.getMaxWeight 
-     * 			  which can be used to callibrate scoring scale)
+     * 			  which can be used to calibrate scoring scale)
      * @param minForegroundColor
      *            The hex color used for representing IDF scores of zero eg
      *            #FFFFFF (white) or null if no foreground color required
@@ -194,7 +194,7 @@ public class GradientFormatter implements Formatter
      * input is nonnegative unless there is a preceding minus sign. This method
      * reads the input as twos complement instead, so if the input is 8 bytes
      * long, it will correctly restore a negative int produced by
-     * Integer.toHexString() but not neccesarily one produced by
+     * Integer.toHexString() but not necessarily one produced by
      * Integer.toString(x,16) since that method will produce a string like '-FF'
      * for negative integer values.
      * 
diff --git a/contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter.java b/contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter.java
index fbc97ed..8f7cc98 100644
--- a/contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter.java
+++ b/contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter.java
@@ -93,7 +93,7 @@ public class Highlighter
 	 *
 	 * @param tokenStream   a stream of tokens identified in the text parameter, including offset information.
 	 * This is typically produced by an analyzer re-parsing a document's
-	 * text. Some work may be done on retrieving TokenStreams more efficently
+	 * text. Some work may be done on retrieving TokenStreams more efficiently
 	 * by adding support for storing original text position data in the Lucene
 	 * index but this support is not currently available (as of Lucene 1.4 rc2).
 	 * @param text text to highlight terms in
diff --git a/contrib/highlighter/src/java/org/apache/lucene/search/highlight/QueryTermExtractor.java b/contrib/highlighter/src/java/org/apache/lucene/search/highlight/QueryTermExtractor.java
index f8eb418..ebd2569 100644
--- a/contrib/highlighter/src/java/org/apache/lucene/search/highlight/QueryTermExtractor.java
+++ b/contrib/highlighter/src/java/org/apache/lucene/search/highlight/QueryTermExtractor.java
@@ -54,7 +54,7 @@ public final class QueryTermExtractor
 	 *
 	 * @param query      Query to extract term texts from
 	 * @param reader used to compute IDF which can be used to a) score selected fragments better 
-	 * b) use graded highlights eg chaning intensity of font color
+	 * b) use graded highlights eg changing intensity of font color
 	 * @param fieldName the field on which Inverse Document Frequency (IDF) calculations are based
 	 * @return an array of the terms used in a query, plus their weights.
 	 */
diff --git a/contrib/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources.java b/contrib/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources.java
index 19ae9bc..b56b90a 100644
--- a/contrib/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources.java
+++ b/contrib/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources.java
@@ -130,7 +130,7 @@ public class TokenSources
      * 	   stemmer/lowercaser/stopword combo)
      *  2) The  number of other fields (Lucene reads ALL fields off the disk 
      *     when accessing just one document field - can cost dear!)
-     *  3) Use of compression on field storage - could be faster cos of compression (less disk IO)
+     *  3) Use of compression on field storage - could be faster due to compression (less disk IO)
      *     or slower (more CPU burn) depending on the content.
      *
      * @param tpv
diff --git a/contrib/highlighter/src/java/org/apache/lucene/search/highlight/package.html b/contrib/highlighter/src/java/org/apache/lucene/search/highlight/package.html
index 47dab1a..a2e7d85 100755
--- a/contrib/highlighter/src/java/org/apache/lucene/search/highlight/package.html
+++ b/contrib/highlighter/src/java/org/apache/lucene/search/highlight/package.html
@@ -87,7 +87,7 @@ A subtle use of color can help emphasise the reasons for matching (useful when d
 you want to see what the basis of the similarities are).</p>
 
 <p>The QueryScorer class has a new constructor which can use an IndexReader to derive the IDF (inverse document frequency)
-for each term in order to influcence the score. This is useful for helping to extracting the most significant sections
+for each term in order to influence the score. This is useful for helping to extracting the most significant sections
 of a document and in supplying scores used by the new GradientFormatter to color significant words more strongly.
 The QueryScorer.getMaxWeight method is useful when passed to the GradientFormatter constructor to define the top score
 which is associated with the top color.</p>
diff --git a/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/FieldSettings.java b/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/FieldSettings.java
index 5659d3a..34fc045 100644
--- a/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/FieldSettings.java
+++ b/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/FieldSettings.java
@@ -23,7 +23,7 @@ import java.io.Serializable;
  */
 
 /**
- * Essetially a Map<FieldName, {@link org.apache.lucene.store.instantiated.FieldSetting}> 
+ * Essentially a Map<FieldName, {@link org.apache.lucene.store.instantiated.FieldSetting}> 
  */
 class FieldSettings implements Serializable {
 
diff --git a/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex.java b/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex.java
index aeb40fa..bc65e7c 100644
--- a/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex.java
+++ b/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex.java
@@ -92,7 +92,7 @@ public class InstantiatedIndex
    * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.
    *
    * @param sourceIndexReader the source index this new instantiated index will be copied from.
-   * @throws IOException if the source index is not optimized, or when accesing the source.
+   * @throws IOException if the source index is not optimized, or when accessing the source.
    */
   public InstantiatedIndex(IndexReader sourceIndexReader) throws IOException {
     this(sourceIndexReader, null);
@@ -105,7 +105,7 @@ public class InstantiatedIndex
    *
    * @param sourceIndexReader the source index this new instantiated index will be copied from.
    * @param fields fields to be added, or null for all
-   * @throws IOException if the source index is not optimized, or when accesing the source.
+   * @throws IOException if the source index is not optimized, or when accessing the source.
    */
   public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {
 
diff --git a/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndexReader.java b/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndexReader.java
index 80ef5a5..3d21e48 100644
--- a/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndexReader.java
+++ b/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndexReader.java
@@ -224,8 +224,8 @@ public class InstantiatedIndexReader extends IndexReader {
    * over a {@link org.apache.lucene.store.Directory}.
    * I.e., if you need to touch the document, clone it first!
    * <p>
-   * This can also be seen as a feature for live canges of stored values,
-   * but be carful! Adding a field with an name unknown to the index
+   * This can also be seen as a feature for live changes of stored values,
+   * but be careful! Adding a field with an name unknown to the index
    * or to a field with previously no stored values will make
    * {@link org.apache.lucene.store.instantiated.InstantiatedIndexReader#getFieldNames(org.apache.lucene.index.IndexReader.FieldOption)}
    * out of sync, causing problems for instance when merging the
@@ -259,8 +259,8 @@ public class InstantiatedIndexReader extends IndexReader {
    * over a {@link org.apache.lucene.store.Directory}.
    * I.e., if you need to touch the document, clone it first!
    * <p>
-   * This can also be seen as a feature for live canges of stored values,
-   * but be carful! Adding a field with an name unknown to the index
+   * This can also be seen as a feature for live changes of stored values,
+   * but be careful! Adding a field with an name unknown to the index
    * or to a field with previously no stored values will make
    * {@link org.apache.lucene.store.instantiated.InstantiatedIndexReader#getFieldNames(org.apache.lucene.index.IndexReader.FieldOption)}
    * out of sync, causing problems for instance when merging the
diff --git a/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndexWriter.java b/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndexWriter.java
index 350bcfd..a580904 100644
--- a/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndexWriter.java
+++ b/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndexWriter.java
@@ -281,7 +281,7 @@ public class InstantiatedIndexWriter {
             }
           }
 
-          // create association term document infomation
+          // create association term document information
           //
           // [Term]-- {0..*} | {0..* ordered} --(field)[Document]
           //
@@ -302,7 +302,7 @@ public class InstantiatedIndexWriter {
 
           InstantiatedTermDocumentInformation info = new InstantiatedTermDocumentInformation(term, document, /*eTermText_TermDocInfoFactory.getValue().termFrequency,*/ positions, payloads);
 
-          // todo optimize, this should be chached and updated to array in batches rather than appending the array once for every position!
+          // todo optimize, this should be cached and updated to array in batches rather than appending the array once for every position!
           InstantiatedTermDocumentInformation[] associatedDocuments;
           if (term.getAssociatedDocuments() != null) {
             associatedDocuments = new InstantiatedTermDocumentInformation[term.getAssociatedDocuments().length + 1];
@@ -363,7 +363,7 @@ public class InstantiatedIndexWriter {
 
     // order document informations in dirty terms
     for (InstantiatedTerm term : dirtyTerms) {
-      // todo optimize, i belive this is useless, that the natural order is document number?
+      // todo optimize, i believe this is useless, that the natural order is document number?
       Arrays.sort(term.getAssociatedDocuments(), InstantiatedTermDocumentInformation.documentNumberComparator);
 
 //      // update association class reference for speedy skipTo()
diff --git a/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedTerm.java b/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedTerm.java
index b982ed8..6b609e5 100644
--- a/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedTerm.java
+++ b/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedTerm.java
@@ -74,10 +74,10 @@ public class InstantiatedTerm
   private InstantiatedTermDocumentInformation[] associatedDocuments;
 
   /**
-   * Meta data per document in wich this term is occuring.
+   * Meta data per document in which this term is occurring.
    * Ordered by document number.
    *
-   * @return Meta data per document in wich this term is occuring.
+   * @return Meta data per document in which this term is occurring.
    */
   public InstantiatedTermDocumentInformation[] getAssociatedDocuments() {
     return associatedDocuments;
@@ -85,10 +85,10 @@ public class InstantiatedTerm
 
 
   /**
-   * Meta data per document in wich this term is occuring.
+   * Meta data per document in which this term is occurring.
    * Ordered by document number.
    *
-   * @param associatedDocuments meta data per document in wich this term is occuring, ordered by document number
+   * @param associatedDocuments meta data per document in which this term is occurring, ordered by document number
    */
   void setAssociatedDocuments(InstantiatedTermDocumentInformation[] associatedDocuments) {
     this.associatedDocuments = associatedDocuments;
@@ -182,7 +182,7 @@ public class InstantiatedTerm
       // A typical binarySearch algorithm uses pivot = (min + max) / 2.
       // The pivot we use here tries to be smarter and to choose a pivot close to the expectable location of the key.
       // This reduces dramatically the number of steps needed to get to the key.
-      // However, it does not work well with a logaritmic distribution of values, for instance.
+      // However, it does not work well with a logarithmic distribution of values, for instance.
       // When the key is not found quickly the smart way, we switch to the standard pivot.
       if (nPreviousSteps > 2) {
         pivot = (min + max) >> 1;
@@ -214,7 +214,7 @@ public class InstantiatedTerm
 
 
   /**
-   * Navigates to the view of this occurances of this term in a specific document. 
+   * Navigates to the view of this occurrences of this term in a specific document. 
    *
    * This method is only used by InstantiatedIndex(IndexReader) and
    * should not be optimized for less CPU at the cost of more RAM.
diff --git a/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedTermDocumentInformation.java b/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedTermDocumentInformation.java
index 409d33d..d2cff35 100644
--- a/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedTermDocumentInformation.java
+++ b/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedTermDocumentInformation.java
@@ -23,7 +23,7 @@ import java.util.Comparator;
 
 /**
  * There is one instance of this class per indexed term in a document
- * and it contains the meta data about each occurance of a term in a docment.
+ * and it contains the meta data about each occurrence of a term in a document.
  *
  * It is the inner glue of the inverted index.
  *
diff --git a/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedTermPositions.java b/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedTermPositions.java
index 3af9283..73ebb1c 100644
--- a/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedTermPositions.java
+++ b/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedTermPositions.java
@@ -62,7 +62,7 @@ public class InstantiatedTermPositions
   public int nextPosition() {
     currentTermPositionIndex++;
     // if you get an array out of index exception here,
-    // it might be due to currentDocumentInformation.getIndexFromTerm not beeing set!!
+    // it might be due to currentDocumentInformation.getIndexFromTerm not being set!!
     return currentDocumentInformation.getTermPositions()[currentTermPositionIndex];
   }
 
diff --git a/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/package.html b/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/package.html
index 8d3b5a2..174f394 100644
--- a/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/package.html
+++ b/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/package.html
@@ -49,8 +49,8 @@
 
 <p>
   At a few thousand ~160 characters long documents
-  InstantiaedIndex outperforms RAMDirectory some 50x,
-  15x at 100 documents of 2000 charachters length,
+  InstantiatedIndex outperforms RAMDirectory some 50x,
+  15x at 100 documents of 2000 characters length,
   and is linear to RAMDirectory at 10,000 documents of 2000 characters length.
 </p>
 
@@ -84,7 +84,7 @@
   Could replace any small index that could do with greater response time.
   spell check a priori index,
   the index of new documents exposed to user search agent queries,
-  to compile classifiers in machine learning environments, et c.
+  to compile classifiers in machine learning environments, etc.
 </p>
 
 <h2>Class diagram</h2>
diff --git a/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier.java b/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier.java
index 9f25b36..12b833e 100644
--- a/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier.java
+++ b/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier.java
@@ -81,11 +81,11 @@ public class FieldNormModifier {
   private Similarity sim;
   
   /**
-   * Constructor for code that wishes to use this class programatically
+   * Constructor for code that wishes to use this class programmatically
    * If Similarity is null, kill the field norms.
    *
    * @param d the Directory to modify
-   * @param s the Similiary to use (can be null)
+   * @param s the Similarity to use (can be null)
    */
   public FieldNormModifier(Directory d, Similarity s) {
     dir = d;
diff --git a/contrib/misc/src/java/org/apache/lucene/misc/ChainedFilter.java b/contrib/misc/src/java/org/apache/lucene/misc/ChainedFilter.java
index e18e561..5d61d1d 100644
--- a/contrib/misc/src/java/org/apache/lucene/misc/ChainedFilter.java
+++ b/contrib/misc/src/java/org/apache/lucene/misc/ChainedFilter.java
@@ -85,7 +85,7 @@ public class ChainedFilter extends Filter
     /**
      * Ctor.
      * @param chain The chain of filters
-     * @param logic Logicial operation to apply to ALL filters
+     * @param logic Logical operation to apply to ALL filters
      */
     public ChainedFilter(Filter[] chain, int logic)
     {
diff --git a/contrib/misc/src/java/org/apache/lucene/misc/SweetSpotSimilarity.java b/contrib/misc/src/java/org/apache/lucene/misc/SweetSpotSimilarity.java
index e59ee57..12c2324 100644
--- a/contrib/misc/src/java/org/apache/lucene/misc/SweetSpotSimilarity.java
+++ b/contrib/misc/src/java/org/apache/lucene/misc/SweetSpotSimilarity.java
@@ -97,7 +97,7 @@ public class SweetSpotSimilarity extends DefaultSimilarity {
     
   /**
    * Sets the default function variables used by lengthNorm when no field
-   * specifc variables have been set.
+   * specific variables have been set.
    *
    * @see #lengthNorm
    */
@@ -233,7 +233,7 @@ public class SweetSpotSimilarity extends DefaultSimilarity {
    * </code>
    *
    * <p>
-   * This code is provided as a convincience for subclasses that want
+   * This code is provided as a convenience for subclasses that want
    * to use a hyperbolic tf function.
    * </p>
    *
diff --git a/contrib/misc/src/java/org/apache/lucene/queryParser/complexPhrase/ComplexPhraseQueryParser.java b/contrib/misc/src/java/org/apache/lucene/queryParser/complexPhrase/ComplexPhraseQueryParser.java
index 9db2b2f..b304f8e 100644
--- a/contrib/misc/src/java/org/apache/lucene/queryParser/complexPhrase/ComplexPhraseQueryParser.java
+++ b/contrib/misc/src/java/org/apache/lucene/queryParser/complexPhrase/ComplexPhraseQueryParser.java
@@ -40,9 +40,9 @@ import org.apache.lucene.search.spans.SpanQuery;
 import org.apache.lucene.search.spans.SpanTermQuery;
 
 /**
- * QueryParser which permits complex phrase query syntax e.g. "(john jon
- * jonathan~) peters*"
- * 
+ * QueryParser which permits complex phrase query syntax eg "(john jon
+ * jonathan~) peters*".
+ * <p>
  * Performs potentially multiple passes over Query text to parse any nested
  * logic in PhraseQueries. - First pass takes any PhraseQuery content between
  * quotes and stores for subsequent pass. All other query content is parsed as
@@ -50,13 +50,14 @@ import org.apache.lucene.search.spans.SpanTermQuery;
  * embedded clauses are referring to the same field and therefore can be
  * rewritten as Span queries. All PhraseQuery clauses are expressed as
  * ComplexPhraseQuery objects
- * 
+ * </p>
+ * <p>
  * This could arguably be done in one pass using a new QueryParser but here I am
  * working within the constraints of the existing parser as a base class. This
  * currently simply feeds all phrase content through an analyzer to select
  * phrase terms - any "special" syntax such as * ~ * etc are not given special
  * status
- * 
+ * </p>
  * 
  */
 public class ComplexPhraseQueryParser extends QueryParser {
diff --git a/contrib/misc/src/java/org/apache/lucene/queryParser/precedence/PrecedenceQueryParser.jj b/contrib/misc/src/java/org/apache/lucene/queryParser/precedence/PrecedenceQueryParser.jj
index 9d090b8..479c528 100644
--- a/contrib/misc/src/java/org/apache/lucene/queryParser/precedence/PrecedenceQueryParser.jj
+++ b/contrib/misc/src/java/org/apache/lucene/queryParser/precedence/PrecedenceQueryParser.jj
@@ -232,7 +232,7 @@ public class PrecedenceQueryParser {
    * In default mode (<code>OR_OPERATOR</code>) terms without any modifiers
    * are considered optional: for example <code>capital of Hungary</code> is equal to
    * <code>capital OR of OR Hungary</code>.<br/>
-   * In <code>AND_OPERATOR</code> mode terms are considered to be in conjuction: the
+   * In <code>AND_OPERATOR</code> mode terms are considered to be in conjunction: the
    * above mentioned query is parsed as <code>capital AND of AND Hungary</code>
    */
   public void setDefaultOperator(Operator op) {
diff --git a/contrib/queries/src/java/org/apache/lucene/search/similar/MoreLikeThis.java b/contrib/queries/src/java/org/apache/lucene/search/similar/MoreLikeThis.java
index ba9ed35..098ec74 100644
--- a/contrib/queries/src/java/org/apache/lucene/search/similar/MoreLikeThis.java
+++ b/contrib/queries/src/java/org/apache/lucene/search/similar/MoreLikeThis.java
@@ -87,7 +87,7 @@ import java.util.ArrayList;
  *
  * This class has lots of options to try to make it efficient and flexible.
  * See the body of {@link #main main()} below in the source for real code, or
- * if you want pseudo code, the simpliest possible usage is as follows. The bold
+ * if you want pseudo code, the simplest possible usage is as follows. The bold
  * fragment is specific to this class.
  *
  * <code><pre>
@@ -109,7 +109,7 @@ import java.util.ArrayList;
  * <ol>
  * <li> do your normal, Lucene setup for searching,
  * <li> create a MoreLikeThis,
- * <li> get the text of the doc you want to find similaries to
+ * <li> get the text of the doc you want to find similarities to
  * <li> then call one of the like() calls to generate a similarity query
  * <li> call the searcher to find the similar docs
  * </ol>
@@ -139,7 +139,7 @@ import java.util.ArrayList;
  * Some bugfixing, some refactoring, some optimisation.
  *  - bugfix: retrieveTerms(int docNum) was not working for indexes without a termvector -added missing code
  *  - bugfix: No significant terms being created for fields with a termvector - because 
- *            was only counting one occurence per term/field pair in calculations(ie not including frequency info from TermVector) 
+ *            was only counting one occurrence per term/field pair in calculations(ie not including frequency info from TermVector) 
  *  - refactor: moved common code into isNoiseWord()
  *  - optimise: when no termvector support available - used maxNumTermsParsed to limit amount of tokenization
  * </pre>
@@ -230,7 +230,7 @@ public final class MoreLikeThis {
     private Analyzer analyzer = DEFAULT_ANALYZER;
 
     /**
-     * Ignore words less freqent that this.
+     * Ignore words less frequent that this.
      */
     private int minTermFreq = DEFAULT_MIN_TERM_FREQ;
 
diff --git a/contrib/queries/src/java/org/apache/lucene/search/similar/SimilarityQueries.java b/contrib/queries/src/java/org/apache/lucene/search/similar/SimilarityQueries.java
index 090d52c..9b6d4ce 100644
--- a/contrib/queries/src/java/org/apache/lucene/search/similar/SimilarityQueries.java
+++ b/contrib/queries/src/java/org/apache/lucene/search/similar/SimilarityQueries.java
@@ -63,7 +63,7 @@ public final class SimilarityQueries
 	 *
 	 * <p>
 	 * The philosophy behind this method is "two documents are similar if they share lots of words".
-	 * Note that behind the scenes, Lucenes scoring algorithm will tend to give two documents a higher similarity score if the share more uncommon words.
+	 * Note that behind the scenes, Lucene's scoring algorithm will tend to give two documents a higher similarity score if the share more uncommon words.
 	 *
 	 * <P>
 	 * This method is fail-safe in that if a long 'body' is passed in and
diff --git a/contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/ModifierQueryNode.java b/contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/ModifierQueryNode.java
index 8b8529f..9faff8d 100644
--- a/contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/ModifierQueryNode.java
+++ b/contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/ModifierQueryNode.java
@@ -27,11 +27,12 @@ import org.apache.lucene.queryParser.core.parser.EscapeQuerySyntax;
 
 /**
  * A {@link ModifierQueryNode} indicates the modifier value (+,-,?,NONE) for
- * each term on the query string for example "+t1 -t2 t3" will have a tree of
- * <BooleanQueryNode> <ModifierQueryNode modifier="MOD_REQ"> <t1/>
- * </ModifierQueryNode> <ModifierQueryNode modifier="MOD_NOT"> <t2/>
- * </ModifierQueryNode> <t3/> </BooleanQueryNode>
- * 
+ * each term on the query string. For example "+t1 -t2 t3" will have a tree of:
+ * <blockquote>
+ * &lt;BooleanQueryNode&gt; &lt;ModifierQueryNode modifier="MOD_REQ"&gt; &lt;t1/&gt;
+ * &lt;/ModifierQueryNode&gt; &lt;ModifierQueryNode modifier="MOD_NOT"&gt; &lt;t2/&gt;
+ * &lt;/ModifierQueryNode&gt; &lt;t3/&gt; &lt;/BooleanQueryNode&gt;
+ * </blockquote>
  */
 public class ModifierQueryNode extends QueryNodeImpl {
 
diff --git a/contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/PathQueryNode.java b/contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/PathQueryNode.java
index 859095f..1c79529 100644
--- a/contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/PathQueryNode.java
+++ b/contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/PathQueryNode.java
@@ -25,17 +25,19 @@ import org.apache.lucene.queryParser.core.parser.EscapeQuerySyntax;
 import org.apache.lucene.queryParser.core.parser.EscapeQuerySyntax.Type;
 
 /**
- * A {@link PathQueryNode} is used for to store queries like
- * /company/USA/California /product/shoes/brown QueryText are objects that
+ * A {@link PathQueryNode} is used to store queries like
+ * /company/USA/California /product/shoes/brown. QueryText are objects that
  * contain the text, begin position and end position in the query.
- * 
+ * <p>
  * Example how the text parser creates these objects:
- * 
- * List values = ArrayList(); values.add(new PathQueryNode.QueryText("company",
- * 1, 7)); values.add(new PathQueryNode.QueryText("USA", 9, 12)); values.add(new
- * PathQueryNode.QueryText("California", 14, 23)); QueryNode q = new
- * PathQueryNode(values);
- * 
+ * </p>
+ * <pre>
+ * List values = ArrayList(); 
+ * values.add(new PathQueryNode.QueryText("company", 1, 7)); 
+ * values.add(new PathQueryNode.QueryText("USA", 9, 12)); 
+ * values.add(new PathQueryNode.QueryText("California", 14, 23)); 
+ * QueryNode q = new PathQueryNode(values);
+ * </pre>
  */
 public class PathQueryNode extends QueryNodeImpl {
 
diff --git a/contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/QueryNodeImpl.java b/contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/QueryNodeImpl.java
index bf5525b..ad2bfd2 100644
--- a/contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/QueryNodeImpl.java
+++ b/contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/QueryNodeImpl.java
@@ -106,7 +106,7 @@ public abstract class QueryNodeImpl implements QueryNode, Cloneable {
     // allocate new children list
     allocate();
 
-    // add new childs and set parent
+    // add new children and set parent
     for (QueryNode child : children) {
       add(child);
     }
diff --git a/contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/TextableQueryNode.java b/contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/TextableQueryNode.java
index 7bf9c55..d77bdfa 100644
--- a/contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/TextableQueryNode.java
+++ b/contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/TextableQueryNode.java
@@ -17,6 +17,9 @@ package org.apache.lucene.queryParser.core.nodes;
  * the License.
  */
 
+/**
+ * 
+ */
 public interface TextableQueryNode {
 
   CharSequence getText();
diff --git a/contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/TokenizedPhraseQueryNode.java b/contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/TokenizedPhraseQueryNode.java
index cf652ce..36cd1ee 100644
--- a/contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/TokenizedPhraseQueryNode.java
+++ b/contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/TokenizedPhraseQueryNode.java
@@ -23,7 +23,7 @@ import org.apache.lucene.queryParser.core.parser.EscapeQuerySyntax;
 
 /**
  * A {@link TokenizedPhraseQueryNode} represents a node created by a code that
- * tokenizes/lemmatizes/analizes.
+ * tokenizes/lemmatizes/analyzes.
  */
 public class TokenizedPhraseQueryNode extends QueryNodeImpl implements
     FieldableNode {
diff --git a/contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/package.html b/contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/package.html
index 0591916..a03738e 100644
--- a/contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/package.html
+++ b/contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/package.html
@@ -61,7 +61,7 @@ Grouping nodes:
 <li>FuzzyQueryNode - fuzzy node</li>
 <li>ParametricRangeQueryNode - used for parametric field:[low_value TO high_value]</li>
 <li>ProximityQueryNode - used for proximity search</li>
-<li>TokenizedPhraseQueryNode - used by tokenizers/lemmatizers/analizers for phrases/autophrases</li>
+<li>TokenizedPhraseQueryNode - used by tokenizers/lemmatizers/analyzers for phrases/autophrases</li>
 </ul>
 </p>
 <p>
@@ -82,7 +82,7 @@ Utility Nodes:
 <li>DeletedQueryNode - used by processors on optimizations</li>
 <li>MatchAllDocsQueryNode - used by processors on optimizations</li>
 <li>MatchNoDocsQueryNode - used by processors on optimizations</li>
-<li>NoTokenFoundQueryNode - used by tokenizers/lemmatizers/analizers</li>
+<li>NoTokenFoundQueryNode - used by tokenizers/lemmatizers/analyzers</li>
 </ul>
 </p>
 </body>
diff --git a/contrib/queryparser/src/java/org/apache/lucene/queryParser/core/package.html b/contrib/queryparser/src/java/org/apache/lucene/queryParser/core/package.html
index ff80c35..7a7dfcc 100644
--- a/contrib/queryparser/src/java/org/apache/lucene/queryParser/core/package.html
+++ b/contrib/queryparser/src/java/org/apache/lucene/queryParser/core/package.html
@@ -44,7 +44,7 @@ which is an object structure that represents the elements defined in the query s
 <p>
 The query processing phase is performed by a query processor, which implements {@link org.apache.lucene.queryParser.core.processors.QueryNodeProcessor}.
 A query processor is responsible to perform any processing on a {@link org.apache.lucene.queryParser.core.nodes.QueryNode} tree. This phase
-is optional and is used only if an extra processing, validation, query expansion, etc needs to be perfomed in a {@link org.apache.lucene.queryParser.core.nodes.QueryNode} tree.
+is optional and is used only if an extra processing, validation, query expansion, etc needs to be performed in a {@link org.apache.lucene.queryParser.core.nodes.QueryNode} tree.
 The {@link org.apache.lucene.queryParser.core.nodes.QueryNode} tree can be either be generated by a text parser or programmatically created.
 </p>
 
diff --git a/contrib/regex/src/java/org/apache/lucene/search/regex/JakartaRegexpCapabilities.java b/contrib/regex/src/java/org/apache/lucene/search/regex/JakartaRegexpCapabilities.java
index 71692f5..830b6d4 100644
--- a/contrib/regex/src/java/org/apache/lucene/search/regex/JakartaRegexpCapabilities.java
+++ b/contrib/regex/src/java/org/apache/lucene/search/regex/JakartaRegexpCapabilities.java
@@ -29,7 +29,7 @@ public class JakartaRegexpCapabilities implements RegexCapabilities {
   private RE regexp;
   
   // Define the flags that are possible. Redefine them here
-  // to avoid exposign the RE class to the caller.
+  // to avoid exposing the RE class to the caller.
   
   private int flags = RE.MATCH_NORMAL;
 
@@ -44,7 +44,7 @@ public class JakartaRegexpCapabilities implements RegexCapabilities {
   public static final int FLAG_MATCH_CASEINDEPENDENT = RE.MATCH_CASEINDEPENDENT;
  
   /**
-   * Contructs a RegexCapabilities with the default MATCH_NORMAL match style.
+   * Constructs a RegexCapabilities with the default MATCH_NORMAL match style.
    */
   public JakartaRegexpCapabilities() {}
   
diff --git a/contrib/regex/src/java/org/apache/lucene/search/regex/JavaUtilRegexCapabilities.java b/contrib/regex/src/java/org/apache/lucene/search/regex/JavaUtilRegexCapabilities.java
index 1c56e35..8121cf8 100644
--- a/contrib/regex/src/java/org/apache/lucene/search/regex/JavaUtilRegexCapabilities.java
+++ b/contrib/regex/src/java/org/apache/lucene/search/regex/JavaUtilRegexCapabilities.java
@@ -54,7 +54,7 @@ public class JavaUtilRegexCapabilities implements RegexCapabilities {
    * Constructor that allows for the modification of the flags that
    * the java.util.regex.Pattern will use to compile the regular expression.
    * This gives the user the ability to fine-tune how the regular expression 
-   * to match the functionlity that they need. 
+   * to match the functionality that they need. 
    * The {@link java.util.regex.Pattern Pattern} class supports specifying 
    * these fields via the regular expression text itself, but this gives the caller
    * another option to modify the behavior. Useful in cases where the regular expression text
diff --git a/contrib/spatial/src/java/org/apache/lucene/spatial/geometry/FloatLatLng.java b/contrib/spatial/src/java/org/apache/lucene/spatial/geometry/FloatLatLng.java
index a58a130..1ac6fb6 100644
--- a/contrib/spatial/src/java/org/apache/lucene/spatial/geometry/FloatLatLng.java
+++ b/contrib/spatial/src/java/org/apache/lucene/spatial/geometry/FloatLatLng.java
@@ -28,7 +28,7 @@ public class FloatLatLng extends LatLng {
   private boolean normalized;
   
   public FloatLatLng(double lat, double lng) {
-    if (lat>90.0 || lat<-90.0) throw new IllegalArgumentException("Illegal lattitude value " + lat);
+    if (lat>90.0 || lat<-90.0) throw new IllegalArgumentException("Illegal latitude value " + lat);
     this.lat=lat;
     this.lng=lng;
   }
diff --git a/contrib/spatial/src/java/org/apache/lucene/spatial/geometry/LatLng.java b/contrib/spatial/src/java/org/apache/lucene/spatial/geometry/LatLng.java
index 01d1784..dfb1aa7 100644
--- a/contrib/spatial/src/java/org/apache/lucene/spatial/geometry/LatLng.java
+++ b/contrib/spatial/src/java/org/apache/lucene/spatial/geometry/LatLng.java
@@ -108,7 +108,7 @@ public abstract class LatLng {
    * @param ll2
    *            Second lat,lng position to calculate distance to.
    * @param lUnits
-   *            Units to calculate distace, defaults to miles
+   *            Units to calculate distance, defaults to miles
    * 
    * @return Returns the distance in meters or miles.
    */
@@ -123,7 +123,7 @@ public abstract class LatLng {
     if (lat1 == lat2 && lng1 == lng2)
       return 0.0;
 
-    // Get the m_dLongitude diffeernce. Don't need to worry about
+    // Get the m_dLongitude difference. Don't need to worry about
     // crossing 180 since cos(x) = cos(-x)
     double dLon = lng2 - lng1;
 
diff --git a/contrib/spatial/src/java/org/apache/lucene/spatial/geometry/shape/Ellipse.java b/contrib/spatial/src/java/org/apache/lucene/spatial/geometry/shape/Ellipse.java
index 1485b06..e8e6571 100644
--- a/contrib/spatial/src/java/org/apache/lucene/spatial/geometry/shape/Ellipse.java
+++ b/contrib/spatial/src/java/org/apache/lucene/spatial/geometry/shape/Ellipse.java
@@ -109,7 +109,7 @@ public class Ellipse implements Geometry2D {
     if (pt1 == null)
       pt1 = new Point2D();
 
-    // Solution is found by paramterizing the line segment and
+    // Solution is found by parameterizing the line segment and
     // substituting those values into the ellipse equation.
     // Results in a quadratic equation.
     double x1 = center.x();
diff --git a/contrib/spatial/src/java/org/apache/lucene/spatial/geometry/shape/LineSegment.java b/contrib/spatial/src/java/org/apache/lucene/spatial/geometry/shape/LineSegment.java
index d0a439f..ff22004 100644
--- a/contrib/spatial/src/java/org/apache/lucene/spatial/geometry/shape/LineSegment.java
+++ b/contrib/spatial/src/java/org/apache/lucene/spatial/geometry/shape/LineSegment.java
@@ -41,7 +41,7 @@ public class LineSegment {
 
   /**
    * Finds the distance of a specified point from the line segment and the
-   * closest point on the segement to the specified point.
+   * closest point on the segment to the specified point.
    * 
    * @param P
    *            Test point.
diff --git a/contrib/spatial/src/java/org/apache/lucene/spatial/tier/projections/CartesianTierPlotter.java b/contrib/spatial/src/java/org/apache/lucene/spatial/tier/projections/CartesianTierPlotter.java
index 837a24a..c5a5d62 100644
--- a/contrib/spatial/src/java/org/apache/lucene/spatial/tier/projections/CartesianTierPlotter.java
+++ b/contrib/spatial/src/java/org/apache/lucene/spatial/tier/projections/CartesianTierPlotter.java
@@ -79,7 +79,7 @@ public class CartesianTierPlotter {
   
   /**
    * TierBoxId is latitude box id + longitude box id
-   * where latitude box id, and longitude box id are transposded in to position
+   * where latitude box id, and longitude box id are transposed in to position
    * coordinates.
    * 
    * @param latitude
diff --git a/contrib/spatial/src/java/org/apache/lucene/spatial/tier/projections/SinusoidalProjector.java b/contrib/spatial/src/java/org/apache/lucene/spatial/tier/projections/SinusoidalProjector.java
index 7be1f37..aaf720d 100644
--- a/contrib/spatial/src/java/org/apache/lucene/spatial/tier/projections/SinusoidalProjector.java
+++ b/contrib/spatial/src/java/org/apache/lucene/spatial/tier/projections/SinusoidalProjector.java
@@ -19,7 +19,7 @@ package org.apache.lucene.spatial.tier.projections;
 
 /**
  * Based on Sinusoidal Projections
- * Project a latitude / longitude on a 2D cartisian map
+ * Project a latitude / longitude on a 2D cartesian map
  *
  * <p><font color="red"><b>NOTE:</b> This API is still in
  * flux and might change in incompatible ways in the next
diff --git a/contrib/spellchecker/src/java/org/apache/lucene/search/spell/JaroWinklerDistance.java b/contrib/spellchecker/src/java/org/apache/lucene/search/spell/JaroWinklerDistance.java
index f3f40f6..5833199 100644
--- a/contrib/spellchecker/src/java/org/apache/lucene/search/spell/JaroWinklerDistance.java
+++ b/contrib/spellchecker/src/java/org/apache/lucene/search/spell/JaroWinklerDistance.java
@@ -103,7 +103,7 @@ public class JaroWinklerDistance implements StringDistance {
 
   /**
    * Returns the current value of the threshold used for adding the Winkler bonus.
-   * The deafult value is 0.7.
+   * The default value is 0.7.
    * @return the current value of the threshold
    */
   public float getThreshold() {
diff --git a/contrib/surround/src/java/org/apache/lucene/queryParser/surround/parser/QueryParser.jj b/contrib/surround/src/java/org/apache/lucene/queryParser/surround/parser/QueryParser.jj
index 6532567..15b95e5 100644
--- a/contrib/surround/src/java/org/apache/lucene/queryParser/surround/parser/QueryParser.jj
+++ b/contrib/surround/src/java/org/apache/lucene/queryParser/surround/parser/QueryParser.jj
@@ -64,7 +64,7 @@ public class QueryParser {
   final char quote = '\"';
   final char fieldOperator = ':';
   final char comma = ','; /* prefix list separator */
-  final char carat = '^'; /* weight oparator */
+  final char carat = '^'; /* weight operator */
  
   static public SrndQuery parse(String query) throws ParseException {
     QueryParser parser = new QueryParser();
diff --git a/contrib/swing/src/java/org/apache/lucene/swing/models/ListSearcher.java b/contrib/swing/src/java/org/apache/lucene/swing/models/ListSearcher.java
index ac87a17..ae916ef 100644
--- a/contrib/swing/src/java/org/apache/lucene/swing/models/ListSearcher.java
+++ b/contrib/swing/src/java/org/apache/lucene/swing/models/ListSearcher.java
@@ -118,7 +118,7 @@ public class ListSearcher extends AbstractListModel {
                 //for each row make a new document
                 Document document = new Document();
                 //add the row number of this row in the decorated list model
-                //this will allow us to retrive the results later
+                //this will allow us to retrieve the results later
                 //and map this list model's row to a row in the decorated
                 //list model
                 document.add(new Field(ROW_NUMBER, "" + row, Field.Store.YES, Field.Index.ANALYZED));
@@ -187,7 +187,7 @@ public class ListSearcher extends AbstractListModel {
             //iterate through the hits
             //get the row number stored at the index
             //that number is the row number of the decorated
-            //tabble model row that we are mapping to
+            //table model row that we are mapping to
             for (int t=0; t<hits.length(); t++){
                 Document document = hits.doc(t);
                 Fieldable field = document.getField(ROW_NUMBER);
diff --git a/contrib/swing/src/java/org/apache/lucene/swing/models/TableSearcher.java b/contrib/swing/src/java/org/apache/lucene/swing/models/TableSearcher.java
index bd915bb..30c2509 100644
--- a/contrib/swing/src/java/org/apache/lucene/swing/models/TableSearcher.java
+++ b/contrib/swing/src/java/org/apache/lucene/swing/models/TableSearcher.java
@@ -43,7 +43,7 @@ import java.util.ArrayList;
  * a TableModel and provides sorting functionality. The benefit
  * of this architecture is that you can decorate any TableModel
  * implementation with this searching table model -- making it
- * easy to add searching functionaliy to existing JTables -- or
+ * easy to add searching functionality to existing JTables -- or
  * making new search capable table lucene.
  *
  * <p>This decorator works by holding a reference to a decorated ot inner
@@ -169,7 +169,7 @@ public class TableSearcher extends AbstractTableModel {
                 //for each row make a new document
                 Document document = new Document();
                 //add the row number of this row in the decorated table model
-                //this will allow us to retrive the results later
+                //this will allow us to retrieve the results later
                 //and map this table model's row to a row in the decorated
                 //table model
                 document.add(new Field(ROW_NUMBER, "" + row, Field.Store.YES, Field.Index.ANALYZED));
@@ -268,7 +268,7 @@ public class TableSearcher extends AbstractTableModel {
             //iterate through the hits
             //get the row number stored at the index
             //that number is the row number of the decorated
-            //tabble model row that we are mapping to
+            //table model row that we are mapping to
             for (int t=0; t<hits.length(); t++){
                 Document document = hits.doc(t);
                 Fieldable field = document.getField(ROW_NUMBER);
diff --git a/contrib/wikipedia/src/java/org/apache/lucene/wikipedia/analysis/WikipediaTokenizer.java b/contrib/wikipedia/src/java/org/apache/lucene/wikipedia/analysis/WikipediaTokenizer.java
index a0e4b75..7b9efbd 100644
--- a/contrib/wikipedia/src/java/org/apache/lucene/wikipedia/analysis/WikipediaTokenizer.java
+++ b/contrib/wikipedia/src/java/org/apache/lucene/wikipedia/analysis/WikipediaTokenizer.java
@@ -142,8 +142,8 @@ public class WikipediaTokenizer extends Tokenizer {
   }
 
   /**
-   * Createa a new instance of the {@link org.apache.lucene.wikipedia.analysis.WikipediaTokenizer}.  Attaches the
-   * <conde>input</code> to a the newly created JFlex scanner.
+   * Creates a new instance of the {@link org.apache.lucene.wikipedia.analysis.WikipediaTokenizer}.  Attaches the
+   * <code>input</code> to a the newly created JFlex scanner.
    *
    * @param input The input
    * @param tokenOutput One of {@link #TOKENS_ONLY}, {@link #UNTOKENIZED_ONLY}, {@link #BOTH}
@@ -156,8 +156,8 @@ public class WikipediaTokenizer extends Tokenizer {
   }
 
   /**
-   * Createa a new instance of the {@link org.apache.lucene.wikipedia.analysis.WikipediaTokenizer}.  Attaches the
-   * <conde>input</code> to a the newly created JFlex scanner. Uses the given {@link org.apache.lucene.util.AttributeSource.AttributeFactory}.
+   * Creates a new instance of the {@link org.apache.lucene.wikipedia.analysis.WikipediaTokenizer}.  Attaches the
+   * <code>input</code> to a the newly created JFlex scanner. Uses the given {@link org.apache.lucene.util.AttributeSource.AttributeFactory}.
    *
    * @param input The input
    * @param tokenOutput One of {@link #TOKENS_ONLY}, {@link #UNTOKENIZED_ONLY}, {@link #BOTH}
@@ -170,8 +170,8 @@ public class WikipediaTokenizer extends Tokenizer {
   }
 
   /**
-   * Createa a new instance of the {@link org.apache.lucene.wikipedia.analysis.WikipediaTokenizer}.  Attaches the
-   * <conde>input</code> to a the newly created JFlex scanner. Uses the given {@link AttributeSource}.
+   * Creates a new instance of the {@link org.apache.lucene.wikipedia.analysis.WikipediaTokenizer}.  Attaches the
+   * <code>input</code> to a the newly created JFlex scanner. Uses the given {@link AttributeSource}.
    *
    * @param input The input
    * @param tokenOutput One of {@link #TOKENS_ONLY}, {@link #UNTOKENIZED_ONLY}, {@link #BOTH}
diff --git a/contrib/wordnet/src/java/org/apache/lucene/wordnet/Syns2Index.java b/contrib/wordnet/src/java/org/apache/lucene/wordnet/Syns2Index.java
index 6d516d5..48708ca 100644
--- a/contrib/wordnet/src/java/org/apache/lucene/wordnet/Syns2Index.java
+++ b/contrib/wordnet/src/java/org/apache/lucene/wordnet/Syns2Index.java
@@ -230,7 +230,7 @@ public class Syns2Index
     /**
      * Forms a Lucene index based on the 2 maps.
      *
-     * @param indexDir the direcotry where the index should be created
+     * @param indexDir the directory where the index should be created
      * @param word2Nums
      * @param num2Words
      */
diff --git a/contrib/wordnet/src/java/org/apache/lucene/wordnet/package.html b/contrib/wordnet/src/java/org/apache/lucene/wordnet/package.html
index 4907135..631fb90 100755
--- a/contrib/wordnet/src/java/org/apache/lucene/wordnet/package.html
+++ b/contrib/wordnet/src/java/org/apache/lucene/wordnet/package.html
@@ -33,7 +33,7 @@
 	<ol>
 	    <li> Download the <a href="http://www.cogsci.princeton.edu/2.0/WNprolog-2.0.tar.gz">WordNet prolog database</a> , gunzip, untar etc.
 	<li> Invoke Syn2Index as appropriate to build a synonym index.
-	    It'll take 2 arguments, the path to wn_s.pl from that WordNet downlaod, and the index name.
+	    It'll take 2 arguments, the path to wn_s.pl from that WordNet download, and the index name.
    
 	 <li> Update your UI so that as appropriate you call SynExpand.expand(...) to expand user queries with synonyms.
        </ol>
diff --git a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/CorePlusExtensionsParser.java b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/CorePlusExtensionsParser.java
index fe4c8bc..37022b3 100644
--- a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/CorePlusExtensionsParser.java
+++ b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/CorePlusExtensionsParser.java
@@ -24,12 +24,16 @@ import org.apache.lucene.xmlparser.builders.TermsFilterBuilder;
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
+/**
+ * 
+ */
 public class CorePlusExtensionsParser extends CoreParser
 {
 
 	/**
 	 * Construct an XML parser that uses a single instance QueryParser for handling 
-	 * UserQuery tags - all parse operations are synchronised on this parser
+	 * UserQuery tags - all parse operations are synchronized on this parser
 	 * @param analyzer
 	 * @param parser A QueryParser which will be synchronized on during parse calls.
 	 */
diff --git a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/DOMUtils.java b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/DOMUtils.java
index 2f67d88..b09192d 100644
--- a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/DOMUtils.java
+++ b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/DOMUtils.java
@@ -24,6 +24,10 @@ import org.xml.sax.InputSource;
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
+/**
+ * 
+ */
 public class DOMUtils
 {
     public static Element getChildByTagOrFail(Element e, String name)	throws ParserException
diff --git a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/FilterBuilder.java b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/FilterBuilder.java
index e36e371..71dd481 100644
--- a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/FilterBuilder.java
+++ b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/FilterBuilder.java
@@ -22,6 +22,9 @@ import org.w3c.dom.Element;
  * limitations under the License.
  */
 
+/**
+ * 
+ */
 public interface FilterBuilder {
 	 public Filter getFilter(Element e) throws ParserException;
 }
diff --git a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/FilterBuilderFactory.java b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/FilterBuilderFactory.java
index 04b2788..f04cd19 100644
--- a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/FilterBuilderFactory.java
+++ b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/FilterBuilderFactory.java
@@ -24,6 +24,9 @@ import org.w3c.dom.Element;
  * limitations under the License.
  */
 
+/**
+ * 
+ */
 public class FilterBuilderFactory implements FilterBuilder {
 
 	HashMap builders=new HashMap();
diff --git a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/ParserException.java b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/ParserException.java
index 49af7c3..36715eb 100644
--- a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/ParserException.java
+++ b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/ParserException.java
@@ -19,6 +19,9 @@ package org.apache.lucene.xmlparser;
  * limitations under the License.
  */
 
+/**
+ * 
+ */
 public class ParserException extends Exception {
 
 	/**
diff --git a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/QueryBuilderFactory.java b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/QueryBuilderFactory.java
index 8c4ca17..cc9fc5d 100644
--- a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/QueryBuilderFactory.java
+++ b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/QueryBuilderFactory.java
@@ -24,6 +24,9 @@ import org.w3c.dom.Element;
  * limitations under the License.
  */
 
+/**
+ * 
+ */
 public class QueryBuilderFactory implements QueryBuilder {
 
 	HashMap builders=new HashMap();
diff --git a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/BooleanFilterBuilder.java b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/BooleanFilterBuilder.java
index a5465fa..43cf6d8 100644
--- a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/BooleanFilterBuilder.java
+++ b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/BooleanFilterBuilder.java
@@ -31,6 +31,9 @@ import org.w3c.dom.NodeList;
  * limitations under the License.
  */
 
+/**
+ * 
+ */
 public class BooleanFilterBuilder implements FilterBuilder {
 	
 	private FilterBuilder factory;
diff --git a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/BooleanQueryBuilder.java b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/BooleanQueryBuilder.java
index dffd3ad..fc020fc 100644
--- a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/BooleanQueryBuilder.java
+++ b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/BooleanQueryBuilder.java
@@ -29,7 +29,9 @@ import org.w3c.dom.NodeList;
  * limitations under the License.
  */
 
-
+/**
+ * 
+ */
 public class BooleanQueryBuilder implements QueryBuilder {
 	
 	private QueryBuilder factory;
diff --git a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/BoostingQueryBuilder.java b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/BoostingQueryBuilder.java
index 5ca17cb..d19ba79 100644
--- a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/BoostingQueryBuilder.java
+++ b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/BoostingQueryBuilder.java
@@ -23,6 +23,9 @@ import org.w3c.dom.Element;
  * limitations under the License.
  */
 
+/**
+ * 
+ */
 public class BoostingQueryBuilder implements QueryBuilder
 {
 	
diff --git a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/BoostingTermBuilder.java b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/BoostingTermBuilder.java
index f4d979b..59ca5c4 100644
--- a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/BoostingTermBuilder.java
+++ b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/BoostingTermBuilder.java
@@ -24,6 +24,10 @@ import org.w3c.dom.Element;
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
+/**
+ * 
+ */
 public class BoostingTermBuilder extends SpanBuilderBase
 {
 
diff --git a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/ConstantScoreQueryBuilder.java b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/ConstantScoreQueryBuilder.java
index c80ae56..aaa7612 100644
--- a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/ConstantScoreQueryBuilder.java
+++ b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/ConstantScoreQueryBuilder.java
@@ -23,6 +23,10 @@ import org.w3c.dom.Element;
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
+/**
+ * 
+ */
 public class ConstantScoreQueryBuilder implements QueryBuilder
 {
 	private FilterBuilderFactory filterFactory;
diff --git a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/DuplicateFilterBuilder.java b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/DuplicateFilterBuilder.java
index fad8f2e..18a9676 100644
--- a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/DuplicateFilterBuilder.java
+++ b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/DuplicateFilterBuilder.java
@@ -32,6 +32,9 @@ import org.w3c.dom.NodeList;
  * limitations under the License.
  */
 
+/**
+ * 
+ */
 public class DuplicateFilterBuilder implements FilterBuilder {
 	
 
diff --git a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/FilteredQueryBuilder.java b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/FilteredQueryBuilder.java
index c68a59a..1aebd31 100644
--- a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/FilteredQueryBuilder.java
+++ b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/FilteredQueryBuilder.java
@@ -29,6 +29,9 @@ import org.w3c.dom.Element;
  * limitations under the License.
  */
 
+/**
+ * 
+ */
 public class FilteredQueryBuilder implements QueryBuilder {
 	
 	private FilterBuilder filterFactory;
diff --git a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/FuzzyLikeThisQueryBuilder.java b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/FuzzyLikeThisQueryBuilder.java
index 4a8681f..3df1513 100644
--- a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/FuzzyLikeThisQueryBuilder.java
+++ b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/FuzzyLikeThisQueryBuilder.java
@@ -25,6 +25,10 @@ import org.w3c.dom.NodeList;
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
+/**
+ * 
+ */
 public class FuzzyLikeThisQueryBuilder implements QueryBuilder
 {
 	int defaultMaxNumTerms=50;
diff --git a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder.java b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder.java
index 13bfdbc..d04c221 100644
--- a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder.java
+++ b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder.java
@@ -34,7 +34,9 @@ import org.w3c.dom.Element;
  * limitations under the License.
  */
 
-
+/**
+ * 
+ */
 public class LikeThisQueryBuilder implements QueryBuilder {
 
 	private Analyzer analyzer;
diff --git a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/MatchAllDocsQueryBuilder.java b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/MatchAllDocsQueryBuilder.java
index 01aec2e..b619c99 100644
--- a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/MatchAllDocsQueryBuilder.java
+++ b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/MatchAllDocsQueryBuilder.java
@@ -21,6 +21,10 @@ import org.w3c.dom.Element;
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
+/**
+ * 
+ */
 public class MatchAllDocsQueryBuilder implements QueryBuilder
 {
 	public Query getQuery(Element e) throws ParserException
diff --git a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/RangeFilterBuilder.java b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/RangeFilterBuilder.java
index 7c1b7b2..c226794 100644
--- a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/RangeFilterBuilder.java
+++ b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/RangeFilterBuilder.java
@@ -27,7 +27,9 @@ import org.w3c.dom.Element;
  */
 
 
-
+/**
+ * 
+ */
 public class RangeFilterBuilder implements FilterBuilder {
 
 
diff --git a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanBuilderBase.java b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanBuilderBase.java
index e7fde61..ba716c5 100644
--- a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanBuilderBase.java
+++ b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanBuilderBase.java
@@ -19,6 +19,10 @@ import org.w3c.dom.Element;
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
+/**
+ * 
+ */
 public abstract class SpanBuilderBase implements SpanQueryBuilder
 {
 	public Query getQuery(Element e) throws ParserException
diff --git a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanFirstBuilder.java b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanFirstBuilder.java
index 79c95f1..fe51f56 100644
--- a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanFirstBuilder.java
+++ b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanFirstBuilder.java
@@ -21,6 +21,10 @@ import org.w3c.dom.Element;
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
+/**
+ * 
+ */
 public class SpanFirstBuilder extends SpanBuilderBase
 {
     SpanQueryBuilder factory;
diff --git a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanNearBuilder.java b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanNearBuilder.java
index b9bd750..25e1909 100644
--- a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanNearBuilder.java
+++ b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanNearBuilder.java
@@ -24,6 +24,10 @@ import org.w3c.dom.Node;
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
+/**
+ * 
+ */
 public class SpanNearBuilder extends SpanBuilderBase
 {
 	SpanQueryBuilder factory;
diff --git a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanNotBuilder.java b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanNotBuilder.java
index 5092eaf..47a9793 100644
--- a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanNotBuilder.java
+++ b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanNotBuilder.java
@@ -21,6 +21,10 @@ import org.w3c.dom.Element;
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
+/**
+ * 
+ */
 public class SpanNotBuilder extends SpanBuilderBase
 {
     
diff --git a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanOrBuilder.java b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanOrBuilder.java
index f284aaa..9780a3e 100644
--- a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanOrBuilder.java
+++ b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanOrBuilder.java
@@ -24,6 +24,10 @@ import org.w3c.dom.Node;
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
+/**
+ * 
+ */
 public class SpanOrBuilder extends SpanBuilderBase
 {
     
diff --git a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanOrTermsBuilder.java b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanOrTermsBuilder.java
index 1c5bdaf..2a0bad7 100644
--- a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanOrTermsBuilder.java
+++ b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanOrTermsBuilder.java
@@ -30,6 +30,10 @@ import org.w3c.dom.Element;
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
+/**
+ * 
+ */
 public class SpanOrTermsBuilder extends SpanBuilderBase
 {
     Analyzer analyzer;
diff --git a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanQueryBuilderFactory.java b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanQueryBuilderFactory.java
index e272368..b8bf819 100644
--- a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanQueryBuilderFactory.java
+++ b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanQueryBuilderFactory.java
@@ -23,6 +23,9 @@ import org.w3c.dom.Element;
  * limitations under the License.
  */
 
+/**
+ * 
+ */
 public class SpanQueryBuilderFactory implements SpanQueryBuilder {
 
 	HashMap builders=new HashMap();
diff --git a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanTermBuilder.java b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanTermBuilder.java
index 3a31d8f..472958f 100644
--- a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanTermBuilder.java
+++ b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanTermBuilder.java
@@ -22,6 +22,10 @@ import org.w3c.dom.Element;
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
+/**
+ * 
+ */
 public class SpanTermBuilder extends SpanBuilderBase
 {
 
diff --git a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/TermQueryBuilder.java b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/TermQueryBuilder.java
index 37df375..e641fc9 100644
--- a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/TermQueryBuilder.java
+++ b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/TermQueryBuilder.java
@@ -24,7 +24,9 @@ import org.w3c.dom.Element;
  * limitations under the License.
  */
 
-
+/**
+ * 
+ */
 public class TermQueryBuilder implements QueryBuilder {
 
 	public Query getQuery(Element e) throws ParserException {
diff --git a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/TermsFilterBuilder.java b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/TermsFilterBuilder.java
index 93e27fd..1761d10 100644
--- a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/TermsFilterBuilder.java
+++ b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/TermsFilterBuilder.java
@@ -31,6 +31,9 @@ import org.w3c.dom.Element;
  * limitations under the License.
  */
 
+/**
+ * 
+ */
 public class TermsFilterBuilder implements FilterBuilder
 {
 	Analyzer analyzer;
diff --git a/src/java/org/apache/lucene/analysis/CharReader.java b/src/java/org/apache/lucene/analysis/CharReader.java
index 2da0233..606e430 100644
--- a/src/java/org/apache/lucene/analysis/CharReader.java
+++ b/src/java/org/apache/lucene/analysis/CharReader.java
@@ -23,7 +23,7 @@ import java.io.Reader;
 /**
  * CharReader is a Reader wrapper. It reads chars from
  * Reader and outputs {@link CharStream}, defining an
- * identify fucntion {@link #correctOffset} method that
+ * identify function {@link #correctOffset} method that
  * simply returns the provided offset.
  */
 public final class CharReader extends CharStream {
diff --git a/src/java/org/apache/lucene/analysis/CharacterCache.java b/src/java/org/apache/lucene/analysis/CharacterCache.java
index 1116cc3..c8c908c 100644
--- a/src/java/org/apache/lucene/analysis/CharacterCache.java
+++ b/src/java/org/apache/lucene/analysis/CharacterCache.java
@@ -36,7 +36,7 @@ class CharacterCache {
    * 
    * @param c
    *          a char value
-   * @return a Charater representation of the given char value.
+   * @return a Character representation of the given char value.
    */
   public static Character valueOf(char c) {
     if (c < cache.length) {
diff --git a/src/java/org/apache/lucene/analysis/TeeSinkTokenFilter.java b/src/java/org/apache/lucene/analysis/TeeSinkTokenFilter.java
index 895eb37..e9625ca 100644
--- a/src/java/org/apache/lucene/analysis/TeeSinkTokenFilter.java
+++ b/src/java/org/apache/lucene/analysis/TeeSinkTokenFilter.java
@@ -119,7 +119,7 @@ public final class TeeSinkTokenFilter extends TokenFilter {
   
   /**
    * <code>TeeSinkTokenFilter</code> passes all tokens to the added sinks
-   * when itsself is consumed. To be sure, that all tokens from the input
+   * when itself is consumed. To be sure, that all tokens from the input
    * stream are passed to the sinks, you can call this methods.
    * This instance is exhausted after this, but all sinks are instant available.
    */
diff --git a/src/java/org/apache/lucene/analysis/standard/StandardAnalyzer.java b/src/java/org/apache/lucene/analysis/standard/StandardAnalyzer.java
index c30737f..5401bcb 100644
--- a/src/java/org/apache/lucene/analysis/standard/StandardAnalyzer.java
+++ b/src/java/org/apache/lucene/analysis/standard/StandardAnalyzer.java
@@ -86,7 +86,7 @@ public class StandardAnalyzer extends Analyzer {
    *
    * @param replaceInvalidAcronym Set to true to have new
    * instances of StandardTokenizer replace mischaracterized
-   * acronyms by default.  Set to false to preseve the
+   * acronyms by default.  Set to false to preserve the
    * previous (before 2.4) buggy behavior.  Alternatively,
    * set the system property
    * org.apache.lucene.analysis.standard.StandardAnalyzer.replaceInvalidAcronym
diff --git a/src/java/org/apache/lucene/analysis/standard/StandardTokenizerImpl.jflex b/src/java/org/apache/lucene/analysis/standard/StandardTokenizerImpl.jflex
index 939fd81..2aa7944 100644
--- a/src/java/org/apache/lucene/analysis/standard/StandardTokenizerImpl.jflex
+++ b/src/java/org/apache/lucene/analysis/standard/StandardTokenizerImpl.jflex
@@ -86,7 +86,7 @@ THAI       = [\u0E00-\u0E59]
 ALPHANUM   = ({LETTER}|{THAI}|[:digit:])+
 
 // internal apostrophes: O'Reilly, you're, O'Reilly's
-// use a post-filter to remove possesives
+// use a post-filter to remove possessives
 APOSTROPHE =  {ALPHA} ("'" {ALPHA})+
 
 // acronyms: U.S.A., I.B.M., etc.
diff --git a/src/java/org/apache/lucene/analysis/tokenattributes/FlagsAttributeImpl.java b/src/java/org/apache/lucene/analysis/tokenattributes/FlagsAttributeImpl.java
index 2c69a9a..2554ac9 100644
--- a/src/java/org/apache/lucene/analysis/tokenattributes/FlagsAttributeImpl.java
+++ b/src/java/org/apache/lucene/analysis/tokenattributes/FlagsAttributeImpl.java
@@ -23,7 +23,7 @@ import org.apache.lucene.util.AttributeImpl;
 
 /**
  * This attribute can be used to pass different flags down the tokenizer chain,
- * e. g. from one TokenFilter to another one. 
+ * eg from one TokenFilter to another one. 
  */
 public class FlagsAttributeImpl extends AttributeImpl implements FlagsAttribute, Cloneable, Serializable {
   private int flags = 0;
diff --git a/src/java/org/apache/lucene/document/AbstractField.java b/src/java/org/apache/lucene/document/AbstractField.java
index 09309e6..e16fc8e 100755
--- a/src/java/org/apache/lucene/document/AbstractField.java
+++ b/src/java/org/apache/lucene/document/AbstractField.java
@@ -204,7 +204,7 @@ public abstract class AbstractField implements Fieldable {
 
   /**
    * True iff terms are stored as term vector together with their offsets 
-   * (start and end positon in source text).
+   * (start and end position in source text).
    */
   public boolean isStoreOffsetWithTermVector(){
     return storeOffsetWithTermVector;
diff --git a/src/java/org/apache/lucene/document/DateTools.java b/src/java/org/apache/lucene/document/DateTools.java
index e45ab05..126d8af 100644
--- a/src/java/org/apache/lucene/document/DateTools.java
+++ b/src/java/org/apache/lucene/document/DateTools.java
@@ -84,7 +84,7 @@ public class DateTools {
    * @param resolution the desired resolution, see
    *  {@link #round(Date, DateTools.Resolution)}
    * @return a string in format <code>yyyyMMddHHmmssSSS</code> or shorter,
-   *  depeding on <code>resolution</code>; using GMT as timezone 
+   *  depending on <code>resolution</code>; using GMT as timezone 
    */
   public static synchronized String dateToString(Date date, Resolution resolution) {
     return timeToString(date.getTime(), resolution);
@@ -97,7 +97,7 @@ public class DateTools {
    * @param resolution the desired resolution, see
    *  {@link #round(long, DateTools.Resolution)}
    * @return a string in format <code>yyyyMMddHHmmssSSS</code> or shorter,
-   *  depeding on <code>resolution</code>; using GMT as timezone
+   *  depending on <code>resolution</code>; using GMT as timezone
    */
   public static synchronized String timeToString(long time, Resolution resolution) {
     calInstance.setTimeInMillis(round(time, resolution));
diff --git a/src/java/org/apache/lucene/document/Field.java b/src/java/org/apache/lucene/document/Field.java
index 062e50b..2dbb3b6 100644
--- a/src/java/org/apache/lucene/document/Field.java
+++ b/src/java/org/apache/lucene/document/Field.java
@@ -46,7 +46,7 @@ public final class Field extends AbstractField implements Fieldable, Serializabl
      * useful for long documents and for binary valued fields.
      * @deprecated Please use {@link CompressionTools} instead.
      * For string fields that were previously indexed and stored using compression,
-     * the new way to achive this is: First add the field indexed-only (no store)
+     * the new way to achieve this is: First add the field indexed-only (no store)
      * and additionally using the same field name as a binary, stored field
      * with {@link CompressionTools#compressString}.
      */
@@ -132,7 +132,7 @@ public final class Field extends AbstractField implements Fieldable, Serializabl
     public static final TermVector NO = new TermVector("NO");
     
     /** Store the term vectors of each document. A term vector is a list
-     * of the document's terms and their number of occurences in that document. */
+     * of the document's terms and their number of occurrences in that document. */
     public static final TermVector YES = new TermVector("YES");
     
     /**
diff --git a/src/java/org/apache/lucene/document/FieldSelectorResult.java b/src/java/org/apache/lucene/document/FieldSelectorResult.java
index b1224a4..263da87 100755
--- a/src/java/org/apache/lucene/document/FieldSelectorResult.java
+++ b/src/java/org/apache/lucene/document/FieldSelectorResult.java
@@ -25,7 +25,7 @@ import java.io.Serializable;
 public final class FieldSelectorResult implements Serializable {
 
     /**
-     * Load this {@link Field} every time the {@link Document} is loaded, reading in the data as it is encounterd.
+     * Load this {@link Field} every time the {@link Document} is loaded, reading in the data as it is encountered.
      *  {@link Document#getField(String)} and {@link Document#getFieldable(String)} should not return null.
      *<p/>
      * {@link Document#add(Fieldable)} should be called by the Reader.
diff --git a/src/java/org/apache/lucene/document/Fieldable.java b/src/java/org/apache/lucene/document/Fieldable.java
index 11cf31b..b8770a0 100755
--- a/src/java/org/apache/lucene/document/Fieldable.java
+++ b/src/java/org/apache/lucene/document/Fieldable.java
@@ -43,7 +43,7 @@ public interface Fieldable extends Serializable {
    * used to compute the norm factor for the field.  By
    * default, in the {@link
    * org.apache.lucene.search.Similarity#computeNorm(String,
-   * FieldInvertState)} method, the boost value is multipled
+   * FieldInvertState)} method, the boost value is multiplied
    * by the {@link
    * org.apache.lucene.search.Similarity#lengthNorm(String,
    * int)} and then rounded by {@link org.apache.lucene.search.Similarity#encodeNorm(float)} before it is stored in the
diff --git a/src/java/org/apache/lucene/document/NumberTools.java b/src/java/org/apache/lucene/document/NumberTools.java
index cba4f13..9652cba 100644
--- a/src/java/org/apache/lucene/document/NumberTools.java
+++ b/src/java/org/apache/lucene/document/NumberTools.java
@@ -77,7 +77,7 @@ public class NumberTools {
     public static String longToString(long l) {
 
         if (l == Long.MIN_VALUE) {
-            // special case, because long is not symetric around zero
+            // special case, because long is not symmetric around zero
             return MIN_STRING_VALUE;
         }
 
diff --git a/src/java/org/apache/lucene/document/NumericField.java b/src/java/org/apache/lucene/document/NumericField.java
index 4e46dbb..6890b07 100644
--- a/src/java/org/apache/lucene/document/NumericField.java
+++ b/src/java/org/apache/lucene/document/NumericField.java
@@ -86,7 +86,7 @@ import org.apache.lucene.search.FieldCache; // javadocs
  * you should separately index a single-valued <code>NumericField</code>.</p>
  *
  * <p>A <code>NumericField</code> will consume somewhat more disk space
- * in the index than an ordindary single-valued field.
+ * in the index than an ordinary single-valued field.
  * However, for a typical index that includes substantial
  * textual content per document, this increase will likely
  * be in the noise. </p>
@@ -146,7 +146,7 @@ public final class NumericField extends AbstractField {
    * {@link NumericUtils#PRECISION_STEP_DEFAULT} (4). The instance is not yet initialized with
    * a numeric value, before indexing a document containing this field,
    * set a value using the various set<em>???</em>Value() methods.
-   * This constrcutor creates an indexed, but not stored field.
+   * This constructor creates an indexed, but not stored field.
    * @param name the field name
    */
   public NumericField(String name) {
@@ -172,7 +172,7 @@ public final class NumericField extends AbstractField {
    * <code>precisionStep</code>. The instance is not yet initialized with
    * a numeric value, before indexing a document containing this field,
    * set a value using the various set<em>???</em>Value() methods.
-   * This constrcutor creates an indexed, but not stored field.
+   * This constructor creates an indexed, but not stored field.
    * @param name the field name
    * @param precisionStep the used <a href="../search/NumericRangeQuery.html#precisionStepDesc">precision step</a>
    */
@@ -217,7 +217,7 @@ public final class NumericField extends AbstractField {
     return null;
   }
     
-  /** Returns the numeric value as a string (how it is stored, when {@link Field.Store#YES} is choosen). */
+  /** Returns the numeric value as a string (how it is stored, when {@link Field.Store#YES} is chosen). */
   public String stringValue()   {
     return (fieldsData == null) ? null : fieldsData.toString();
   }
diff --git a/src/java/org/apache/lucene/index/DirectoryReader.java b/src/java/org/apache/lucene/index/DirectoryReader.java
index 60d4525..5b232f4 100644
--- a/src/java/org/apache/lucene/index/DirectoryReader.java
+++ b/src/java/org/apache/lucene/index/DirectoryReader.java
@@ -173,7 +173,7 @@ class DirectoryReader extends IndexReader implements Cloneable {
     initialize(readers);
   }
 
-  /** This contructor is only used for {@link #reopen()} */
+  /** This constructor is only used for {@link #reopen()} */
   DirectoryReader(Directory directory, SegmentInfos infos, SegmentReader[] oldReaders, int[] oldStarts,
                   Map oldNormsCache, boolean readOnly, boolean doClone, int termInfosIndexDivisor) throws IOException {
     this.directory = directory;
diff --git a/src/java/org/apache/lucene/index/FieldInfos.java b/src/java/org/apache/lucene/index/FieldInfos.java
index b8fcf10..27c94a5 100644
--- a/src/java/org/apache/lucene/index/FieldInfos.java
+++ b/src/java/org/apache/lucene/index/FieldInfos.java
@@ -137,7 +137,7 @@ final class FieldInfos {
    * 
    * @param names The names of the fields
    * @param storeTermVectors Whether the fields store term vectors or not
-   * @param storePositionWithTermVector treu if positions should be stored.
+   * @param storePositionWithTermVector true if positions should be stored.
    * @param storeOffsetWithTermVector true if offsets should be stored
    */
   synchronized public void addIndexed(Collection names, boolean storeTermVectors, boolean storePositionWithTermVector, 
diff --git a/src/java/org/apache/lucene/index/FreqProxTermsWriter.java b/src/java/org/apache/lucene/index/FreqProxTermsWriter.java
index b873b9f..ce41f9c 100644
--- a/src/java/org/apache/lucene/index/FreqProxTermsWriter.java
+++ b/src/java/org/apache/lucene/index/FreqProxTermsWriter.java
@@ -61,7 +61,7 @@ final class FreqProxTermsWriter extends TermsHashConsumer {
   void abort() {}
 
 
-  // TODO: would be nice to factor out morme of this, eg the
+  // TODO: would be nice to factor out more of this, eg the
   // FreqProxFieldMergeState, and code to visit all Fields
   // under the same FieldInfo together, up into TermsHash*.
   // Other writers would presumably share alot of this...
diff --git a/src/java/org/apache/lucene/index/IndexModifier.java b/src/java/org/apache/lucene/index/IndexModifier.java
index 75acaaf..0c69946 100644
--- a/src/java/org/apache/lucene/index/IndexModifier.java
+++ b/src/java/org/apache/lucene/index/IndexModifier.java
@@ -450,7 +450,7 @@ public class IndexModifier {
    * running out of memory.<p/>
    * Note that this effectively truncates large documents, excluding from the
    * index terms that occur further in the document.  If you know your source
-   * documents are large, be sure to set this value high enough to accomodate
+   * documents are large, be sure to set this value high enough to accommodate
    * the expected size.  If you set it to Integer.MAX_VALUE, then the only limit
    * is your memory, but you should anticipate an OutOfMemoryError.<p/>
    * By default, no more than 10,000 terms will be indexed for a field.
diff --git a/src/java/org/apache/lucene/index/IndexReader.java b/src/java/org/apache/lucene/index/IndexReader.java
index 0af3f56..495f72c 100644
--- a/src/java/org/apache/lucene/index/IndexReader.java
+++ b/src/java/org/apache/lucene/index/IndexReader.java
@@ -386,7 +386,7 @@ public abstract class IndexReader implements Cloneable {
    *  if you use this reader to perform deletes or to set
    *  norms); see {@link IndexWriter} for details.
    * @param readOnly true if no changes (deletions, norms) will be made with this IndexReader
-   * @param termInfosIndexDivisor Subsambles which indexed
+   * @param termInfosIndexDivisor Subsamples which indexed
    *  terms are loaded into RAM. This has the same effect as {@link
    *  IndexWriter#setTermIndexInterval} except that setting
    *  must be done at indexing time while this setting can be
@@ -455,7 +455,7 @@ public abstract class IndexReader implements Cloneable {
    *  if you use this reader to perform deletes or to set
    *  norms); see {@link IndexWriter} for details.
    * @param readOnly true if no changes (deletions, norms) will be made with this IndexReader
-   * @param termInfosIndexDivisor Subsambles which indexed
+   * @param termInfosIndexDivisor Subsamples which indexed
    *  terms are loaded into RAM. This has the same effect as {@link
    *  IndexWriter#setTermIndexInterval} except that setting
    *  must be done at indexing time while this setting can be
@@ -1393,7 +1393,7 @@ public abstract class IndexReader implements Cloneable {
 
           FileOutputStream f = new FileOutputStream(files[i]);
 
-          // read and write with a small buffer, which is more effectiv than reading byte by byte
+          // read and write with a small buffer, which is more effective than reading byte by byte
           byte[] buffer = new byte[1024];
           int chunk = buffer.length;
           while(len > 0) {
diff --git a/src/java/org/apache/lucene/index/IndexWriter.java b/src/java/org/apache/lucene/index/IndexWriter.java
index 4df50e6..591507e 100644
--- a/src/java/org/apache/lucene/index/IndexWriter.java
+++ b/src/java/org/apache/lucene/index/IndexWriter.java
@@ -399,7 +399,7 @@ public class IndexWriter {
    * feature, please report back on your findings so we can
    * learn, improve and iterate.</p>
    *
-   * <p>The resulting reader suppports {@link
+   * <p>The resulting reader supports {@link
    * IndexReader#reopen}, but that call will simply forward
    * back to this method (though this may change in the
    * future).</p>
@@ -440,7 +440,7 @@ public class IndexWriter {
   /** Expert: like {@link #getReader}, except you can
    *  specify which termInfosIndexDivisor should be used for
    *  any newly opened readers.
-   * @param termInfosIndexDivisor Subsambles which indexed
+   * @param termInfosIndexDivisor Subsamples which indexed
    *  terms are loaded into RAM. This has the same effect as {@link
    *  IndexWriter#setTermIndexInterval} except that setting
    *  must be done at indexing time while this setting can be
@@ -481,8 +481,8 @@ public class IndexWriter {
 
     private final Map readerMap = new HashMap();
 
-    /** Forcefully clear changes for the specifed segments,
-     *  and remove from the pool.   This is called on succesful merge. */
+    /** Forcefully clear changes for the specified segments,
+     *  and remove from the pool.   This is called on successful merge. */
     synchronized void clear(SegmentInfos infos) throws IOException {
       if (infos == null) {
         Iterator iter = readerMap.entrySet().iterator();
@@ -2371,7 +2371,7 @@ public class IndexWriter {
    * running out of memory.<p/>
    * Note that this effectively truncates large documents, excluding from the
    * index terms that occur further in the document.  If you know your source
-   * documents are large, be sure to set this value high enough to accomodate
+   * documents are large, be sure to set this value high enough to accommodate
    * the expected size.  If you set it to Integer.MAX_VALUE, then the only limit
    * is your memory, but you should anticipate an OutOfMemoryError.<p/>
    * By default, no more than 10,000 terms will be indexed for a field.
@@ -5328,7 +5328,7 @@ public class IndexWriter {
     // against thread timing hazards where notifyAll()
     // falls to be called, we wait for at most 1 second
     // and then return so caller can check if wait
-    // conditions are satisified:
+    // conditions are satisfied:
     try {
       wait(1000);
     } catch (InterruptedException ie) {
diff --git a/src/java/org/apache/lucene/index/LogByteSizeMergePolicy.java b/src/java/org/apache/lucene/index/LogByteSizeMergePolicy.java
index 1e7111a..4750331 100644
--- a/src/java/org/apache/lucene/index/LogByteSizeMergePolicy.java
+++ b/src/java/org/apache/lucene/index/LogByteSizeMergePolicy.java
@@ -54,7 +54,7 @@ public class LogByteSizeMergePolicy extends LogMergePolicy {
     maxMergeSize = (long) (mb*1024*1024);
   }
 
-  /** Returns the largest segment (meaured by total byte
+  /** Returns the largest segment (measured by total byte
    *  size of the segment's files, in MB) that may be merged
    *  with other segments.
    *  @see #setMaxMergeMB */
diff --git a/src/java/org/apache/lucene/index/MultiLevelSkipListWriter.java b/src/java/org/apache/lucene/index/MultiLevelSkipListWriter.java
index bded80e..f4f43e2 100644
--- a/src/java/org/apache/lucene/index/MultiLevelSkipListWriter.java
+++ b/src/java/org/apache/lucene/index/MultiLevelSkipListWriter.java
@@ -40,7 +40,7 @@ import org.apache.lucene.store.RAMOutputStream;
  * Therefore the number of entries on level i is: floor(df / ((skipInterval ^ (i + 1))).
  * 
  * Each skip entry on a level i>0 contains a pointer to the corresponding skip entry in list i-1.
- * This guarantess a logarithmic amount of skips to find the target document.
+ * This guarantees a logarithmic amount of skips to find the target document.
  * 
  * While this class takes care of writing the different skip levels,
  * subclasses must define the actual format of the skip data.
@@ -89,7 +89,7 @@ abstract class MultiLevelSkipListWriter {
   /**
    * Subclasses must implement the actual skip data encoding in this method.
    *  
-   * @param level the level skip data shall be writting for
+   * @param level the level skip data shall be writing for
    * @param skipBuffer the skip buffer to write to
    */
   protected abstract void writeSkipData(int level, IndexOutput skipBuffer) throws IOException;
diff --git a/src/java/org/apache/lucene/index/ParallelReader.java b/src/java/org/apache/lucene/index/ParallelReader.java
index 427f0c6..7c222a5 100644
--- a/src/java/org/apache/lucene/index/ParallelReader.java
+++ b/src/java/org/apache/lucene/index/ParallelReader.java
@@ -78,7 +78,7 @@ public class ParallelReader extends IndexReader {
   }
 
  /** Add an IndexReader whose stored fields will not be returned.  This can
-  * accellerate search when stored fields are only needed from a subset of
+  * accelerate search when stored fields are only needed from a subset of
   * the IndexReaders.
   *
   * @throws IllegalArgumentException if not all indexes contain the same number
diff --git a/src/java/org/apache/lucene/index/SegmentInfos.java b/src/java/org/apache/lucene/index/SegmentInfos.java
index 96753a3..fb70cde 100644
--- a/src/java/org/apache/lucene/index/SegmentInfos.java
+++ b/src/java/org/apache/lucene/index/SegmentInfos.java
@@ -85,7 +85,7 @@ public final class SegmentInfos extends Vector {
   public static final int FORMAT_USER_DATA = -8;
 
   /** This format adds optional per-segment String
-   *  dianostics storage, and switches userData to Map */
+   *  diagnostics storage, and switches userData to Map */
   public static final int FORMAT_DIAGNOSTICS = -9;
 
   /* This must always point to the most recent file format. */
@@ -756,7 +756,7 @@ public final class SegmentInfos extends Vector {
   }
 
   /**
-   * Returns a new SegmentInfos containg the SegmentInfo
+   * Returns a new SegmentInfos containing the SegmentInfo
    * instances in the specified range first (inclusive) to
    * last (exclusive), so total number of segments returned
    * is last-first.
diff --git a/src/java/org/apache/lucene/index/SegmentReader.java b/src/java/org/apache/lucene/index/SegmentReader.java
index 6735b33..70b786b 100644
--- a/src/java/org/apache/lucene/index/SegmentReader.java
+++ b/src/java/org/apache/lucene/index/SegmentReader.java
@@ -76,7 +76,7 @@ public class SegmentReader extends IndexReader implements Cloneable {
     // Counts how many other reader share the core objects
     // (freqStream, proxStream, tis, etc.) of this reader;
     // when coreRef drops to 0, these core objects may be
-    // closed.  A given insance of SegmentReader may be
+    // closed.  A given instance of SegmentReader may be
     // closed, even those it shares core objects with other
     // SegmentReaders:
     private final Ref ref = new Ref();
@@ -802,7 +802,7 @@ public class SegmentReader extends IndexReader implements Cloneable {
       success = true;
     } finally {
       if (!success) {
-        // An exception occured during reopen, we have to decRef the norms
+        // An exception occurred during reopen, we have to decRef the norms
         // that we incRef'ed already and close singleNormsStream and FieldsReader
         clone.decRef();
       }
diff --git a/src/java/org/apache/lucene/index/SegmentTermPositions.java b/src/java/org/apache/lucene/index/SegmentTermPositions.java
index 693c4f3..8b04d00 100644
--- a/src/java/org/apache/lucene/index/SegmentTermPositions.java
+++ b/src/java/org/apache/lucene/index/SegmentTermPositions.java
@@ -29,7 +29,7 @@ extends SegmentTermDocs implements TermPositions {
   
   // the current payload length
   private int payloadLength;
-  // indicates whether the payload of the currend position has
+  // indicates whether the payload of the current position has
   // been read from the proxStream yet
   private boolean needToLoadPayload;
   
@@ -63,7 +63,7 @@ extends SegmentTermDocs implements TermPositions {
     if (currentFieldOmitTermFreqAndPositions)
       // This field does not store term freq, positions, payloads
       return 0;
-    // perform lazy skips if neccessary
+    // perform lazy skips if necessary
     lazySkip();
     proxCount--;
     return position += readDeltaPosition();
@@ -133,7 +133,7 @@ extends SegmentTermDocs implements TermPositions {
     needToLoadPayload = false;
   }
 
-  // It is not always neccessary to move the prox pointer
+  // It is not always necessary to move the prox pointer
   // to a new document after the freq pointer has been moved.
   // Consider for example a phrase query with two terms:
   // the freq pointer for term 1 has to move to document x
diff --git a/src/java/org/apache/lucene/index/Term.java b/src/java/org/apache/lucene/index/Term.java
index 4551b66..b0a1e23 100644
--- a/src/java/org/apache/lucene/index/Term.java
+++ b/src/java/org/apache/lucene/index/Term.java
@@ -22,7 +22,7 @@ import org.apache.lucene.util.StringHelper;
 /**
   A Term represents a word from text.  This is the unit of search.  It is
   composed of two elements, the text of the word, as a string, and the name of
-  the field that the text occured in, an interned string.
+  the field that the text occurred in, an interned string.
 
   Note that terms may represent more than words from text fields, but also
   things like dates, email addresses, urls, etc.  */
diff --git a/src/java/org/apache/lucene/index/TermFreqVector.java b/src/java/org/apache/lucene/index/TermFreqVector.java
index 11e2d5e..5187665 100644
--- a/src/java/org/apache/lucene/index/TermFreqVector.java
+++ b/src/java/org/apache/lucene/index/TermFreqVector.java
@@ -18,7 +18,7 @@ package org.apache.lucene.index;
  */
 
 /** Provides access to stored term vector of 
- *  a document field.  The vector consists of the name of the field, an array of the terms tha occur in the field of the
+ *  a document field.  The vector consists of the name of the field, an array of the terms that occur in the field of the
  * {@link org.apache.lucene.document.Document} and a parallel array of frequencies.  Thus, getTermFrequencies()[5] corresponds with the
  * frequency of getTerms()[5], assuming there are at least 5 terms in the Document.
  */
diff --git a/src/java/org/apache/lucene/index/TermInfosWriter.java b/src/java/org/apache/lucene/index/TermInfosWriter.java
index a15309c..b476f96 100644
--- a/src/java/org/apache/lucene/index/TermInfosWriter.java
+++ b/src/java/org/apache/lucene/index/TermInfosWriter.java
@@ -57,7 +57,7 @@ final class TermInfosWriter {
   int indexInterval = 128;
 
   /** Expert: The fraction of {@link TermDocs} entries stored in skip tables,
-   * used to accellerate {@link TermDocs#skipTo(int)}.  Larger values result in
+   * used to accelerate {@link TermDocs#skipTo(int)}.  Larger values result in
    * smaller indexes, greater acceleration, but fewer accelerable cases, while
    * smaller values result in bigger indexes, less acceleration and more
    * accelerable cases. More detailed experiments would be useful here. */
diff --git a/src/java/org/apache/lucene/index/TermVectorsTermsWriterPerField.java b/src/java/org/apache/lucene/index/TermVectorsTermsWriterPerField.java
index 0d7f0af..50d694c 100644
--- a/src/java/org/apache/lucene/index/TermVectorsTermsWriterPerField.java
+++ b/src/java/org/apache/lucene/index/TermVectorsTermsWriterPerField.java
@@ -113,7 +113,7 @@ final class TermVectorsTermsWriterPerField extends TermsHashConsumerPerField {
 
     final IndexOutput tvf = perThread.doc.tvf;
 
-    // This is called once, after inverting all occurences
+    // This is called once, after inverting all occurrences
     // of a given field in the doc.  At this point we flush
     // our hash into the DocWriter.
 
diff --git a/src/java/org/apache/lucene/queryParser/QueryParser.jj b/src/java/org/apache/lucene/queryParser/QueryParser.jj
index a481998..099752f 100644
--- a/src/java/org/apache/lucene/queryParser/QueryParser.jj
+++ b/src/java/org/apache/lucene/queryParser/QueryParser.jj
@@ -783,7 +783,7 @@ public class QueryParser {
       DateTools.Resolution resolution = getDateResolution(field);
       if (resolution == null) {
         // no default or field specific date resolution has been set,
-        // use deprecated DateField to maintain compatibilty with
+        // use deprecated DateField to maintain compatibility with
         // pre-1.9 Lucene versions.
         part1 = DateField.dateToString(d1);
         part2 = DateField.dateToString(d2);
diff --git a/src/java/org/apache/lucene/search/BooleanQuery.java b/src/java/org/apache/lucene/search/BooleanQuery.java
index 4c2e347..88fb469 100644
--- a/src/java/org/apache/lucene/search/BooleanQuery.java
+++ b/src/java/org/apache/lucene/search/BooleanQuery.java
@@ -129,7 +129,7 @@ public class BooleanQuery extends Query {
 
   /**
    * Gets the minimum number of the optional BooleanClauses
-   * which must be satisifed.
+   * which must be satisfied.
    */
   public int getMinimumNumberShouldMatch() {
     return minNrShouldMatch;
diff --git a/src/java/org/apache/lucene/search/ComplexExplanation.java b/src/java/org/apache/lucene/search/ComplexExplanation.java
index 128fbdb..1acb768 100644
--- a/src/java/org/apache/lucene/search/ComplexExplanation.java
+++ b/src/java/org/apache/lucene/search/ComplexExplanation.java
@@ -27,7 +27,7 @@ public class ComplexExplanation extends Explanation {
   }
 
   public ComplexExplanation(boolean match, float value, String description) {
-    // NOTE: use of "boolean" instead of "Boolean" in params is concious
+    // NOTE: use of "boolean" instead of "Boolean" in params is conscious
     // choice to encourage clients to be specific.
     super(value, description);
     this.match = Boolean.valueOf(match);
diff --git a/src/java/org/apache/lucene/search/DisjunctionMaxScorer.java b/src/java/org/apache/lucene/search/DisjunctionMaxScorer.java
index e75a528..7c6aa9b 100644
--- a/src/java/org/apache/lucene/search/DisjunctionMaxScorer.java
+++ b/src/java/org/apache/lucene/search/DisjunctionMaxScorer.java
@@ -19,7 +19,7 @@ package org.apache.lucene.search;
 import java.io.IOException;
 
 /**
- * The Scorer for DisjunctionMaxQuery's.  The union of all documents generated by the the subquery scorers
+ * The Scorer for DisjunctionMaxQuery.  The union of all documents generated by the the subquery scorers
  * is generated in document number order.  The score for each document is the maximum of the scores computed
  * by the subquery scorers that generate that document, plus tieBreakerMultiplier times the sum of the scores
  * for the other subqueries that generate the document.
diff --git a/src/java/org/apache/lucene/search/DocIdSetIterator.java b/src/java/org/apache/lucene/search/DocIdSetIterator.java
index f4c6ae5..530f2dc 100644
--- a/src/java/org/apache/lucene/search/DocIdSetIterator.java
+++ b/src/java/org/apache/lucene/search/DocIdSetIterator.java
@@ -125,7 +125,7 @@ public abstract class DocIdSetIterator {
    * 
    * Some implementations are considerably more efficient than that.
    * <p>
-   * <b>NOTE:</b> certain implemenations may return a different value (each
+   * <b>NOTE:</b> certain implementations may return a different value (each
    * time) if called several times in a row with the same target.
    * <p>
    * <b>NOTE:</b> this method may be called with {@value #NO_MORE_DOCS} for
diff --git a/src/java/org/apache/lucene/search/FieldCache.java b/src/java/org/apache/lucene/search/FieldCache.java
index e3740c1..93ca62e 100644
--- a/src/java/org/apache/lucene/search/FieldCache.java
+++ b/src/java/org/apache/lucene/search/FieldCache.java
@@ -584,8 +584,8 @@ public interface FieldCache {
    * EXPERT: Generates an array of CacheEntry objects representing all items 
    * currently in the FieldCache.
    * <p>
-   * NOTE: These CacheEntry objects maintain a strong refrence to the 
-   * Cached Values.  Maintaining refrences to a CacheEntry the IndexReader 
+   * NOTE: These CacheEntry objects maintain a strong reference to the 
+   * Cached Values.  Maintaining references to a CacheEntry the IndexReader 
    * associated with it has garbage collected will prevent the Value itself
    * from being garbage collected when the Cache drops the WeakRefrence.
    * </p>
diff --git a/src/java/org/apache/lucene/search/FieldComparator.java b/src/java/org/apache/lucene/search/FieldComparator.java
index 566ecde..d034858 100644
--- a/src/java/org/apache/lucene/search/FieldComparator.java
+++ b/src/java/org/apache/lucene/search/FieldComparator.java
@@ -402,7 +402,7 @@ public abstract class FieldComparator {
 
   /** Sorts by descending relevance.  NOTE: if you are
    *  sorting only by descending relevance and then
-   *  secondarily by ascending docID, peformance is faster
+   *  secondarily by ascending docID, performance is faster
    *  using {@link TopScoreDocCollector} directly (which {@link
    *  IndexSearcher#search} uses when no {@link Sort} is
    *  specified). */
diff --git a/src/java/org/apache/lucene/search/FieldSortedHitQueue.java b/src/java/org/apache/lucene/search/FieldSortedHitQueue.java
index 38cd244..350ee4c 100644
--- a/src/java/org/apache/lucene/search/FieldSortedHitQueue.java
+++ b/src/java/org/apache/lucene/search/FieldSortedHitQueue.java
@@ -233,7 +233,7 @@ extends PriorityQueue {
    /**
    * Returns a comparator for sorting hits according to a field containing bytes.
    * @param reader  Index to use.
-   * @param fieldname  Fieldable containg integer values.
+   * @param fieldname  Fieldable containing integer values.
    * @return  Comparator for sorting hits.
    * @throws IOException If an error occurs reading the index.
    */
@@ -264,7 +264,7 @@ extends PriorityQueue {
   /**
    * Returns a comparator for sorting hits according to a field containing shorts.
    * @param reader  Index to use.
-   * @param fieldname  Fieldable containg integer values.
+   * @param fieldname  Fieldable containing integer values.
    * @return  Comparator for sorting hits.
    * @throws IOException If an error occurs reading the index.
    */
@@ -295,7 +295,7 @@ extends PriorityQueue {
   /**
    * Returns a comparator for sorting hits according to a field containing integers.
    * @param reader  Index to use.
-   * @param fieldname  Fieldable containg integer values.
+   * @param fieldname  Fieldable containing integer values.
    * @return  Comparator for sorting hits.
    * @throws IOException If an error occurs reading the index.
    */
@@ -326,7 +326,7 @@ extends PriorityQueue {
   /**
    * Returns a comparator for sorting hits according to a field containing integers.
    * @param reader  Index to use.
-   * @param fieldname  Fieldable containg integer values.
+   * @param fieldname  Fieldable containing integer values.
    * @return  Comparator for sorting hits.
    * @throws IOException If an error occurs reading the index.
    */
@@ -358,7 +358,7 @@ extends PriorityQueue {
   /**
    * Returns a comparator for sorting hits according to a field containing floats.
    * @param reader  Index to use.
-   * @param fieldname  Fieldable containg float values.
+   * @param fieldname  Fieldable containing float values.
    * @return  Comparator for sorting hits.
    * @throws IOException If an error occurs reading the index.
    */
@@ -389,7 +389,7 @@ extends PriorityQueue {
   /**
    * Returns a comparator for sorting hits according to a field containing doubles.
    * @param reader  Index to use.
-   * @param fieldname  Fieldable containg float values.
+   * @param fieldname  Fieldable containing float values.
    * @return  Comparator for sorting hits.
    * @throws IOException If an error occurs reading the index.
    */
@@ -420,7 +420,7 @@ extends PriorityQueue {
   /**
    * Returns a comparator for sorting hits according to a field containing strings.
    * @param reader  Index to use.
-   * @param fieldname  Fieldable containg string values.
+   * @param fieldname  Fieldable containing string values.
    * @return  Comparator for sorting hits.
    * @throws IOException If an error occurs reading the index.
    */
@@ -451,7 +451,7 @@ extends PriorityQueue {
   /**
    * Returns a comparator for sorting hits according to a field containing strings.
    * @param reader  Index to use.
-   * @param fieldname  Fieldable containg string values.
+   * @param fieldname  Fieldable containing string values.
    * @return  Comparator for sorting hits.
    * @throws IOException If an error occurs reading the index.
    */
@@ -492,7 +492,7 @@ extends PriorityQueue {
    * floats or strings.  Once the type is determined, one of the other static methods
    * in this class is called to get the comparator.
    * @param reader  Index to use.
-   * @param fieldname  Fieldable containg values.
+   * @param fieldname  Fieldable containing values.
    * @return  Comparator for sorting hits.
    * @throws IOException If an error occurs reading the index.
    */
diff --git a/src/java/org/apache/lucene/search/FilterManager.java b/src/java/org/apache/lucene/search/FilterManager.java
index 06b6fc4..fece0dc 100644
--- a/src/java/org/apache/lucene/search/FilterManager.java
+++ b/src/java/org/apache/lucene/search/FilterManager.java
@@ -27,8 +27,8 @@ import java.util.TreeSet;
 /**
  * Filter caching singleton.  It can be used 
  * to save filters locally for reuse.
- * This class makes it possble to cache Filters even when using RMI, as it
- * keeps the cache on the seaercher side of the RMI connection.
+ * This class makes it possible to cache Filters even when using RMI, as it
+ * keeps the cache on the searcher side of the RMI connection.
  * 
  * Also could be used as a persistent storage for any filter as long as the
  * filter provides a proper hashCode(), as that is used as the key in the cache.
@@ -42,7 +42,7 @@ public class FilterManager {
   
   /** The default maximum number of Filters in the cache */
   protected static final int  DEFAULT_CACHE_CLEAN_SIZE = 100;
-  /** The default frequency of cache clenup */
+  /** The default frequency of cache cleanup */
   protected static final long DEFAULT_CACHE_SLEEP_TIME = 1000 * 60 * 10;
 
   /** The cache itself */
@@ -71,7 +71,7 @@ public class FilterManager {
 
     filterCleaner   = new FilterCleaner();
     Thread fcThread = new Thread(filterCleaner);
-    // setto be a Daemon so it doesn't have to be stopped
+    // set to be a Daemon so it doesn't have to be stopped
     fcThread.setDaemon(true);
     fcThread.start();
   }
@@ -86,7 +86,7 @@ public class FilterManager {
 
   /**
    * Sets the cache cleaning frequency in milliseconds.
-   * @param cleanSleepTime cleaning frequency in millioseconds
+   * @param cleanSleepTime cleaning frequency in milliseconds
    */
   public void setCleanThreadSleepTime(long cleanSleepTime) {
     this.cleanSleepTime  = cleanSleepTime;
diff --git a/src/java/org/apache/lucene/search/FuzzyTermEnum.java b/src/java/org/apache/lucene/search/FuzzyTermEnum.java
index c12872c..1f40527 100644
--- a/src/java/org/apache/lucene/search/FuzzyTermEnum.java
+++ b/src/java/org/apache/lucene/search/FuzzyTermEnum.java
@@ -22,7 +22,7 @@ import org.apache.lucene.index.Term;
 
 import java.io.IOException;
 
-/** Subclass of FilteredTermEnum for enumerating all terms that are similiar
+/** Subclass of FilteredTermEnum for enumerating all terms that are similar
  * to the specified filter term.
  *
  * <p>Term enumerations are always ordered by Term.compareTo().  Each term in
@@ -37,7 +37,7 @@ public final class FuzzyTermEnum extends FilteredTermEnum {
   private static final int TYPICAL_LONGEST_WORD_IN_INDEX = 19;
 
   /* Allows us save time required to create a new array
-   * everytime similarity is called.
+   * every time similarity is called.
    */
   private int[][] d;
 
@@ -181,20 +181,20 @@ public final class FuzzyTermEnum extends FilteredTermEnum {
    * <p>Embedded within this algorithm is a fail-fast Levenshtein distance
    * algorithm.  The fail-fast algorithm differs from the standard Levenshtein
    * distance algorithm in that it is aborted if it is discovered that the
-   * mimimum distance between the words is greater than some threshold.
+   * minimum distance between the words is greater than some threshold.
    *
    * <p>To calculate the maximum distance threshold we use the following formula:
    * <pre>
    *     (1 - minimumSimilarity) * length</pre>
    * where length is the shortest term including any prefix that is not part of the
-   * similarity comparision.  This formula was derived by solving for what maximum value
+   * similarity comparison.  This formula was derived by solving for what maximum value
    * of distance returns false for the following statements:
    * <pre>
    *   similarity = 1 - ((float)distance / (float) (prefixLength + Math.min(textlen, targetlen)));
    *   return (similarity > minimumSimilarity);</pre>
    * where distance is the Levenshtein distance for the two words.
    * </p>
-   * <p>Levenshtein distance (also known as edit distance) is a measure of similiarity
+   * <p>Levenshtein distance (also known as edit distance) is a measure of similarity
    * between two strings where the distance is measured as the number of character
    * deletions, insertions or substitutions required to transform one string to
    * the other string.
@@ -221,7 +221,7 @@ public final class FuzzyTermEnum extends FilteredTermEnum {
       //too many edits
       //for example "pre" length is 3 and "prefixes" length is 8.  We can see that
       //given this optimal circumstance, the edit distance cannot be less than 5.
-      //which is 8-3 or more precisesly Math.abs(3-8).
+      //which is 8-3 or more precisely Math.abs(3-8).
       //if our maximum edit distance is 4, then we can discard this word
       //without looking at it.
       return 0.0f;
diff --git a/src/java/org/apache/lucene/search/MultiTermQuery.java b/src/java/org/apache/lucene/search/MultiTermQuery.java
index bf1a7dd..b8f93d8 100644
--- a/src/java/org/apache/lucene/search/MultiTermQuery.java
+++ b/src/java/org/apache/lucene/search/MultiTermQuery.java
@@ -356,7 +356,7 @@ public abstract class MultiTermQuery extends Query {
    * with {@link #clearTotalNumberOfTerms}.
    * <p>On optimized indexes / no MultiReaders, you get the correct number of
    * unique terms for the whole index. Use this number to compare different queries.
-   * For non-optimized indexes this number can also be achived in
+   * For non-optimized indexes this number can also be achieved in
    * non-constant-score mode. In constant-score mode you get the total number of
    * terms seeked for all segments / sub-readers.
    * @see #clearTotalNumberOfTerms
diff --git a/src/java/org/apache/lucene/search/NumericRangeQuery.java b/src/java/org/apache/lucene/search/NumericRangeQuery.java
index c51f569..280654b 100644
--- a/src/java/org/apache/lucene/search/NumericRangeQuery.java
+++ b/src/java/org/apache/lucene/search/NumericRangeQuery.java
@@ -108,7 +108,7 @@ import org.apache.lucene.index.Term;
  * <code>7*255*2 + 255 = 3825</code> distinct terms (when there is a term for every distinct value of an
  * 8-byte-number in the index and the range covers almost all of them; a maximum of 255 distinct values is used
  * because it would always be possible to reduce the full 256 values to one term with degraded precision).
- * In practise, we have seen up to 300 terms in most cases (index with 500,000 metadata records
+ * In practice, we have seen up to 300 terms in most cases (index with 500,000 metadata records
  * and a uniform value distribution).</p>
  *
  * <a name="precisionStepDesc"><h3>Precision Step</h3>
@@ -141,7 +141,7 @@ import org.apache.lucene.index.Term;
  *  Sorting is also possible with range query optimized fields using one of the above <code>precisionSteps</code>.
  * </ul>
  *
- * <p>Comparisions of the different types of RangeQueries on an index with about 500,000 docs showed
+ * <p>Comparisons of the different types of RangeQueries on an index with about 500,000 docs showed
  * that {@link TermRangeQuery} in boolean rewrite mode (with raised {@link BooleanQuery} clause count)
  * took about 30-40 secs to complete, {@link TermRangeQuery} in constant score filter rewrite mode took 5 secs
  * and executing this class took &lt;100ms to complete (on an Opteron64 machine, Java 1.5, 8 bit
diff --git a/src/java/org/apache/lucene/search/PhraseScorer.java b/src/java/org/apache/lucene/search/PhraseScorer.java
index 2e526f6..1271086 100644
--- a/src/java/org/apache/lucene/search/PhraseScorer.java
+++ b/src/java/org/apache/lucene/search/PhraseScorer.java
@@ -23,7 +23,7 @@ import org.apache.lucene.index.TermPositions;
 
 /** Expert: Scoring functionality for phrase queries.
  * <br>A document is considered matching if it contains the phrase-query terms  
- * at "valid" positons. What "valid positions" are
+ * at "valid" positions. What "valid positions" are
  * depends on the type of the phrase query: for an exact phrase query terms are required 
  * to appear in adjacent locations, while for a sloppy phrase query some distance between 
  * the terms is allowed. The abstract method {@link #phraseFreq()} of extending classes
@@ -41,7 +41,7 @@ abstract class PhraseScorer extends Scorer {
   protected PhraseQueue pq;
   protected PhrasePositions first, last;
 
-  private float freq; //prhase frequency in current doc as computed by phraseFreq().
+  private float freq; //phrase frequency in current doc as computed by phraseFreq().
 
   PhraseScorer(Weight weight, TermPositions[] tps, int[] offsets,
       Similarity similarity, byte[] norms) {
diff --git a/src/java/org/apache/lucene/search/Query.java b/src/java/org/apache/lucene/search/Query.java
index 1edd79f..0cf2793 100644
--- a/src/java/org/apache/lucene/search/Query.java
+++ b/src/java/org/apache/lucene/search/Query.java
@@ -160,7 +160,7 @@ public abstract class Query implements java.io.Serializable, Cloneable {
   
 
   /**
-   * Expert: adds all terms occuring in this query to the terms set. Only
+   * Expert: adds all terms occurring in this query to the terms set. Only
    * works if this query is in its {@link #rewrite rewritten} form.
    * 
    * @throws UnsupportedOperationException if this query is not yet rewritten
diff --git a/src/java/org/apache/lucene/search/SimilarityDelegator.java b/src/java/org/apache/lucene/search/SimilarityDelegator.java
index 48a1d27..33bd2ea 100644
--- a/src/java/org/apache/lucene/search/SimilarityDelegator.java
+++ b/src/java/org/apache/lucene/search/SimilarityDelegator.java
@@ -21,7 +21,7 @@ import org.apache.lucene.index.FieldInvertState;
 
 /** Expert: Delegating scoring implementation.  Useful in {@link
  * Query#getSimilarity(Searcher)} implementations, to override only certain
- * methods of a Searcher's Similiarty implementation.. */
+ * methods of a Searcher's Similarity implementation.. */
 public class SimilarityDelegator extends Similarity {
 
   private Similarity delegee;
diff --git a/src/java/org/apache/lucene/search/TimeLimitedCollector.java b/src/java/org/apache/lucene/search/TimeLimitedCollector.java
index dd7d711..b968ac9 100755
--- a/src/java/org/apache/lucene/search/TimeLimitedCollector.java
+++ b/src/java/org/apache/lucene/search/TimeLimitedCollector.java
@@ -53,7 +53,7 @@ public class TimeLimitedCollector extends HitCollector {
     // * use of volatile keyword ensures that it does not reside in
     //   a register, but in main memory (so that changes are visible to
     //   other threads).
-    // * visibility of changes does not need to be instantanous, we can
+    // * visibility of changes does not need to be instantaneous, we can
     //   afford losing a tick or two.
     //
     // See section 17 of the Java Language Specification for details.
diff --git a/src/java/org/apache/lucene/search/TimeLimitingCollector.java b/src/java/org/apache/lucene/search/TimeLimitingCollector.java
index a67b9f2..a697909 100644
--- a/src/java/org/apache/lucene/search/TimeLimitingCollector.java
+++ b/src/java/org/apache/lucene/search/TimeLimitingCollector.java
@@ -53,7 +53,7 @@ public class TimeLimitingCollector extends Collector {
     // * use of volatile keyword ensures that it does not reside in
     //   a register, but in main memory (so that changes are visible to
     //   other threads).
-    // * visibility of changes does not need to be instantanous, we can
+    // * visibility of changes does not need to be instantaneous, we can
     //   afford losing a tick or two.
     //
     // See section 17 of the Java Language Specification for details.
diff --git a/src/java/org/apache/lucene/search/TopDocsCollector.java b/src/java/org/apache/lucene/search/TopDocsCollector.java
index ba89ec3..dec3374 100644
--- a/src/java/org/apache/lucene/search/TopDocsCollector.java
+++ b/src/java/org/apache/lucene/search/TopDocsCollector.java
@@ -85,7 +85,7 @@ public abstract class TopDocsCollector extends Collector {
    * Returns the documents in the rage [start .. pq.size()) that were collected
    * by this collector. Note that if start >= pq.size(), an empty TopDocs is
    * returned.<br>
-   * This method is convenient to call if the application allways asks for the
+   * This method is convenient to call if the application always asks for the
    * last results, starting from the last 'page'.<br>
    * <b>NOTE:</b> you cannot call this method more than once for each search
    * execution. If you need to call it more than once, passing each time a
diff --git a/src/java/org/apache/lucene/search/function/CustomScoreQuery.java b/src/java/org/apache/lucene/search/function/CustomScoreQuery.java
index 2803bfb..a394c01 100755
--- a/src/java/org/apache/lucene/search/function/CustomScoreQuery.java
+++ b/src/java/org/apache/lucene/search/function/CustomScoreQuery.java
@@ -61,9 +61,9 @@ public class CustomScoreQuery extends Query {
 
   /**
    * Create a CustomScoreQuery over input subQuery and a {@link ValueSourceQuery}.
-   * @param subQuery the sub query whose score is being customed. Must not be null.
+   * @param subQuery the sub query whose score is being customized. Must not be null.
    * @param valSrcQuery a value source query whose scores are used in the custom score
-   * computation. For most simple/convineient use case this would be a 
+   * computation. For most simple/convenient use case this would be a 
    * {@link org.apache.lucene.search.function.FieldScoreQuery FieldScoreQuery}.
    * This parameter is optional - it can be null.
    */
diff --git a/src/java/org/apache/lucene/search/function/DocValues.java b/src/java/org/apache/lucene/search/function/DocValues.java
index c637e7e..9a0f01f 100755
--- a/src/java/org/apache/lucene/search/function/DocValues.java
+++ b/src/java/org/apache/lucene/search/function/DocValues.java
@@ -86,7 +86,7 @@ public abstract class DocValues {
   }
   
   /**
-   * Return a string representation of a doc value, as reuired for Explanations.
+   * Return a string representation of a doc value, as required for Explanations.
    */
   public abstract String toString(int doc);
   
diff --git a/src/java/org/apache/lucene/search/function/FieldCacheSource.java b/src/java/org/apache/lucene/search/function/FieldCacheSource.java
index 876e0d1..0e71066 100644
--- a/src/java/org/apache/lucene/search/function/FieldCacheSource.java
+++ b/src/java/org/apache/lucene/search/function/FieldCacheSource.java
@@ -26,7 +26,7 @@ import org.apache.lucene.search.FieldCache;
  * Expert: A base class for ValueSource implementations that retrieve values for
  * a single field from the {@link org.apache.lucene.search.FieldCache FieldCache}.
  * <p>
- * Fields used herein nust be indexed (doesn't matter if these fields are stored or not).
+ * Fields used herein must be indexed (doesn't matter if these fields are stored or not).
  * <p> 
  * It is assumed that each such indexed field is untokenized, or at least has a single token in a document.
  * For documents with multiple tokens of the same field, behavior is undefined (It is likely that current 
diff --git a/src/java/org/apache/lucene/search/function/FieldScoreQuery.java b/src/java/org/apache/lucene/search/function/FieldScoreQuery.java
index 7bbbcd5..df63db0 100755
--- a/src/java/org/apache/lucene/search/function/FieldScoreQuery.java
+++ b/src/java/org/apache/lucene/search/function/FieldScoreQuery.java
@@ -28,7 +28,7 @@ package org.apache.lucene.search.function;
  *  <li>The field used here is indexed, and has exactly 
  *      one token in every scored document.</li> 
  *  <li>Best if this field is un_tokenized.</li>
- *  <li>That token is parsable to the selected type.</li>
+ *  <li>That token is parseable to the selected type.</li>
  * </ul>
  * <p>  
  * Combining this query in a FunctionQuery allows much freedom in affecting document scores.
@@ -36,7 +36,7 @@ package org.apache.lucene.search.function;
  * default Lucene scoring is superior in quality to scoring modified as explained here.
  * However, in some cases, and certainly for research experiments, this capability may turn useful.
  * <p>
- * When contructing this query, select the appropriate type. That type should match the data stored in the
+ * When constructing this query, select the appropriate type. That type should match the data stored in the
  * field. So in fact the "right" type should be selected before indexing. Type selection
  * has effect on the RAM usage: 
  * <ul>
diff --git a/src/java/org/apache/lucene/search/function/ValueSourceQuery.java b/src/java/org/apache/lucene/search/function/ValueSourceQuery.java
index bd1ffa1..228885f 100644
--- a/src/java/org/apache/lucene/search/function/ValueSourceQuery.java
+++ b/src/java/org/apache/lucene/search/function/ValueSourceQuery.java
@@ -105,7 +105,7 @@ public class ValueSourceQuery extends Query {
 
   /**
    * A scorer that (simply) matches all documents, and scores each document with 
-   * the value of the value soure in effect. As an example, if the value source 
+   * the value of the value source in effect. As an example, if the value source 
    * is a (cached) field source, then value of that field in that document will 
    * be used. (assuming field is indexed for this doc, with a single token.)   
    */
diff --git a/src/java/org/apache/lucene/search/payloads/PayloadTermQuery.java b/src/java/org/apache/lucene/search/payloads/PayloadTermQuery.java
index 9b6d244..1539117 100644
--- a/src/java/org/apache/lucene/search/payloads/PayloadTermQuery.java
+++ b/src/java/org/apache/lucene/search/payloads/PayloadTermQuery.java
@@ -139,7 +139,7 @@ public class PayloadTermQuery extends SpanTermQuery {
       /**
        * Returns the SpanScorer score only.
        * <p/>
-       * Should not be overriden without good cause!
+       * Should not be overridden without good cause!
        * 
        * @return the score for just the Span part w/o the payload
        * @throws IOException
diff --git a/src/java/org/apache/lucene/search/spans/FieldMaskingSpanQuery.java b/src/java/org/apache/lucene/search/spans/FieldMaskingSpanQuery.java
index 6b94302..9861ef8 100644
--- a/src/java/org/apache/lucene/search/spans/FieldMaskingSpanQuery.java
+++ b/src/java/org/apache/lucene/search/spans/FieldMaskingSpanQuery.java
@@ -88,7 +88,7 @@ public class FieldMaskingSpanQuery extends SpanQuery {
   }
 
   // :NOTE: getBoost and setBoost are not proxied to the maskedQuery
-  // ...this is done to be more consistent with thigns like SpanFirstQuery
+  // ...this is done to be more consistent with things like SpanFirstQuery
   
   public Spans getSpans(IndexReader reader) throws IOException {
     return maskedQuery.getSpans(reader);
diff --git a/src/java/org/apache/lucene/search/spans/SpanNotQuery.java b/src/java/org/apache/lucene/search/spans/SpanNotQuery.java
index 2094c3a..5fb036e 100644
--- a/src/java/org/apache/lucene/search/spans/SpanNotQuery.java
+++ b/src/java/org/apache/lucene/search/spans/SpanNotQuery.java
@@ -136,7 +136,7 @@ public class SpanNotQuery extends SpanQuery implements Cloneable {
         public int start() { return includeSpans.start(); }
         public int end() { return includeSpans.end(); }
 
-      // TODO: Remove warning after API has been finalizedb
+      // TODO: Remove warning after API has been finalized
       public Collection/*<byte[]>*/ getPayload() throws IOException {
         ArrayList result = null;
         if (includeSpans.isPayloadAvailable()) {
diff --git a/src/java/org/apache/lucene/store/Directory.java b/src/java/org/apache/lucene/store/Directory.java
index 4ea9de7..01b5ced 100644
--- a/src/java/org/apache/lucene/store/Directory.java
+++ b/src/java/org/apache/lucene/store/Directory.java
@@ -60,7 +60,7 @@ public abstract class Directory {
    *  filtering of the contents in a directory, and it will
    *  never return null (throws IOException instead).
    *
-   *  Currently this method simply fallsback to {@link
+   *  Currently this method simply falls back to {@link
    *  #list} for Directory impls outside of Lucene's core &
    *  contrib, but in 3.0 that method will be removed and
    *  this method will become abstract. */
diff --git a/src/java/org/apache/lucene/store/FSDirectory.java b/src/java/org/apache/lucene/store/FSDirectory.java
index 935d23b..113b66d 100644
--- a/src/java/org/apache/lucene/store/FSDirectory.java
+++ b/src/java/org/apache/lucene/store/FSDirectory.java
@@ -42,7 +42,7 @@ import org.apache.lucene.index.IndexWriter;
  *
  * <ul>
  *
- *  <li> {@link SimpleFSDirectory} is a straighforward
+ *  <li> {@link SimpleFSDirectory} is a straightforward
  *       implementation using java.io.RandomAccessFile.
  *       However, it has poor concurrent performance
  *       (multiple threads will bottleneck) as it
diff --git a/src/java/org/apache/lucene/store/FileSwitchDirectory.java b/src/java/org/apache/lucene/store/FileSwitchDirectory.java
index 0112eab..83bcf2f 100644
--- a/src/java/org/apache/lucene/store/FileSwitchDirectory.java
+++ b/src/java/org/apache/lucene/store/FileSwitchDirectory.java
@@ -23,7 +23,7 @@ import java.util.List;
 import java.util.Set;
 
 /**
- * Expert: A Directory instance that switches files betweeen
+ * Expert: A Directory instance that switches files between
  * two other Directory instances.
 
  * <p>Files with the specified extensions are placed in the
diff --git a/src/java/org/apache/lucene/store/IndexInput.java b/src/java/org/apache/lucene/store/IndexInput.java
index cd9b1703..da539cb 100644
--- a/src/java/org/apache/lucene/store/IndexInput.java
+++ b/src/java/org/apache/lucene/store/IndexInput.java
@@ -190,7 +190,7 @@ public abstract class IndexInput implements Cloneable {
   }
   
 
-  /** Closes the stream to futher operations. */
+  /** Closes the stream to further operations. */
   public abstract void close() throws IOException;
 
   /** Returns the current position in this file, where the next read will
diff --git a/src/java/org/apache/lucene/store/MMapDirectory.java b/src/java/org/apache/lucene/store/MMapDirectory.java
index 42eb649..af52860 100644
--- a/src/java/org/apache/lucene/store/MMapDirectory.java
+++ b/src/java/org/apache/lucene/store/MMapDirectory.java
@@ -44,7 +44,7 @@ import org.apache.lucene.util.Constants;
  * guaranteed to fit within the address space.
  * On 32 bit platforms also consult {@link #setMaxChunkSize}
  * if you have problems with mmap failing because of fragmented
- * address space. If you get an OutOfMemoryException, it is recommened
+ * address space. If you get an OutOfMemoryException, it is recommended
  * to reduce the chunk size, until it works.
  *
  * <p>Due to <a href="http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=4724038">
@@ -101,7 +101,7 @@ public class MMapDirectory extends FSDirectory {
   private int maxBBuf = Constants.JRE_IS_64BIT ? Integer.MAX_VALUE : (256*1024*1024);
   
   /**
-   * <code>true</code>, if this platform supports unmapping mmaped files.
+   * <code>true</code>, if this platform supports unmapping mmapped files.
    */
   public static final boolean UNMAP_SUPPORTED;
   static {
@@ -124,7 +124,7 @@ public class MMapDirectory extends FSDirectory {
    * It forcefully unmaps the buffer on close by using
    * an undocumented internal cleanup functionality.
    * <p><b>NOTE:</b> Enabling this is completely unsupported
-   * by Java and may lead to JVM crashs if <code>IndexInput</code>
+   * by Java and may lead to JVM crashes if <code>IndexInput</code>
    * is closed while another thread is still accessing it (SIGSEGV).
    * @throws IllegalArgumentException if {@link #UNMAP_SUPPORTED}
    * is <code>false</code> and the workaround cannot be enabled.
@@ -181,7 +181,7 @@ public class MMapDirectory extends FSDirectory {
    * bit slower (as the correct chunk must be resolved on each seek)
    * but the chance is higher that mmap does not fail. On 64 bit
    * Java platforms, this parameter should always be {@link Integer#MAX_VALUE},
-   * as the adress space is big enough.
+   * as the address space is big enough.
    */
   public void setMaxChunkSize(final int maxBBuf) {
     if (maxBBuf<=0)
diff --git a/src/java/org/apache/lucene/store/NativeFSLockFactory.java b/src/java/org/apache/lucene/store/NativeFSLockFactory.java
index bf12abf..665f1ba 100755
--- a/src/java/org/apache/lucene/store/NativeFSLockFactory.java
+++ b/src/java/org/apache/lucene/store/NativeFSLockFactory.java
@@ -231,7 +231,7 @@ class NativeFSLock extends Lock {
       try {
         f = new RandomAccessFile(path, "rw");
       } catch (IOException e) {
-        // On Windows, we can get intermittant "Access
+        // On Windows, we can get intermittent "Access
         // Denied" here.  So, we treat this as failure to
         // acquire the lock, but, store the reason in case
         // there is in fact a real error case.
@@ -246,7 +246,7 @@ class NativeFSLock extends Lock {
             lock = channel.tryLock();
           } catch (IOException e) {
             // At least on OS X, we will sometimes get an
-            // intermittant "Permission Denied" IOException,
+            // intermittent "Permission Denied" IOException,
             // which seems to simply mean "you failed to get
             // the lock".  But other IOExceptions could be
             // "permanent" (eg, locking is not supported via
diff --git a/src/java/org/apache/lucene/util/ArrayUtil.java b/src/java/org/apache/lucene/util/ArrayUtil.java
index 26a9c54..191973e 100644
--- a/src/java/org/apache/lucene/util/ArrayUtil.java
+++ b/src/java/org/apache/lucene/util/ArrayUtil.java
@@ -17,6 +17,9 @@ package org.apache.lucene.util;
  * limitations under the License.
  */
 
+/**
+ * Methods for manipulating arrays.
+ */
 public final class ArrayUtil {
   /*
      Begin Apache Harmony code
diff --git a/src/java/org/apache/lucene/util/BitUtil.java b/src/java/org/apache/lucene/util/BitUtil.java
index 6f1a447..a720c04 100644
--- a/src/java/org/apache/lucene/util/BitUtil.java
+++ b/src/java/org/apache/lucene/util/BitUtil.java
@@ -17,7 +17,7 @@
 
 package org.apache.lucene.util; // from org.apache.solr.util rev 555343
 
-/**  A variety of high efficiencly bit twiddling routines.
+/**  A variety of high efficiency bit twiddling routines.
  *
  * @version $Id$
  */
diff --git a/src/java/org/apache/lucene/util/CloseableThreadLocal.java b/src/java/org/apache/lucene/util/CloseableThreadLocal.java
index 65a9ca3..4aa72ab 100644
--- a/src/java/org/apache/lucene/util/CloseableThreadLocal.java
+++ b/src/java/org/apache/lucene/util/CloseableThreadLocal.java
@@ -33,7 +33,7 @@ import java.lang.ref.WeakReference;
  *  While not technically a memory leak, because eventually
  *  the memory will be reclaimed, it can take a long time
  *  and you can easily hit OutOfMemoryError because from the
- *  GC's standpoint the stale entries are not reclaimaible.
+ *  GC's standpoint the stale entries are not reclaimable.
  * 
  *  This class works around that, by only enrolling
  *  WeakReference values into the ThreadLocal, and
diff --git a/src/java/org/apache/lucene/util/FieldCacheSanityChecker.java b/src/java/org/apache/lucene/util/FieldCacheSanityChecker.java
index 0ba1f7c..a17b44e 100644
--- a/src/java/org/apache/lucene/util/FieldCacheSanityChecker.java
+++ b/src/java/org/apache/lucene/util/FieldCacheSanityChecker.java
@@ -154,7 +154,7 @@ public final class FieldCacheSanityChecker {
    * Internal helper method used by check that iterates over 
    * valMismatchKeys and generates a Collection of Insanity 
    * instances accordingly.  The MapOfSets are used to populate 
-   * the Insantiy objects. 
+   * the Insanity objects. 
    * @see InsanityType#VALUEMISMATCH
    */
   private Collection checkValueMismatch(MapOfSets valIdToItems,
@@ -195,7 +195,7 @@ public final class FieldCacheSanityChecker {
    * Internal helper method used by check that iterates over 
    * the keys of readerFieldToValIds and generates a Collection 
    * of Insanity instances whenever two (or more) ReaderField instances are 
-   * found that have an ancestery relationships.  
+   * found that have an ancestry relationships.  
    *
    * @see InsanityType#SUBREADER
    */
@@ -327,7 +327,7 @@ public final class FieldCacheSanityChecker {
 
   /**
    * Simple container for a collection of related CacheEntry objects that 
-   * in conjunction with eachother represent some "insane" usage of the 
+   * in conjunction with each other represent some "insane" usage of the 
    * FieldCache.
    */
   public final static class Insanity {
@@ -384,7 +384,7 @@ public final class FieldCacheSanityChecker {
   }
 
   /**
-   * An Enumaration of the differnet types of "insane" behavior that 
+   * An Enumeration of the different types of "insane" behavior that 
    * may be detected in a FieldCache.
    *
    * @see InsanityType#SUBREADER
diff --git a/src/java/org/apache/lucene/util/IndexableBinaryStringTools.java b/src/java/org/apache/lucene/util/IndexableBinaryStringTools.java
index 9b5db08..05dd903 100644
--- a/src/java/org/apache/lucene/util/IndexableBinaryStringTools.java
+++ b/src/java/org/apache/lucene/util/IndexableBinaryStringTools.java
@@ -43,7 +43,7 @@ import java.nio.ByteBuffer;
  * on the CharBuffers and ByteBuffers it uses, so only wrapped arrays may be
  * used.  This class interprets the arrayOffset() and limit() values returned by
  * its input buffers as beginning and end+1 positions on the wrapped array,
- * resprectively; similarly, on the output buffer, arrayOffset() is the first
+ * respectively; similarly, on the output buffer, arrayOffset() is the first
  * position written to, and limit() is set to one past the final output array
  * position.
  */
diff --git a/src/java/org/apache/lucene/util/MapOfSets.java b/src/java/org/apache/lucene/util/MapOfSets.java
index eadb2fe..00c1279 100644
--- a/src/java/org/apache/lucene/util/MapOfSets.java
+++ b/src/java/org/apache/lucene/util/MapOfSets.java
@@ -24,7 +24,7 @@ import java.util.HashSet;
 import java.util.Map;
 
 /**
- * Helper class for keeping Listss of Objects associated with keys. <b>WARNING: THIS CLASS IS NOT THREAD SAFE</b>
+ * Helper class for keeping Lists of Objects associated with keys. <b>WARNING: THIS CLASS IS NOT THREAD SAFE</b>
  */
 public class MapOfSets {
 
diff --git a/src/java/org/apache/lucene/util/NumericUtils.java b/src/java/org/apache/lucene/util/NumericUtils.java
index 34e9755..656c363 100644
--- a/src/java/org/apache/lucene/util/NumericUtils.java
+++ b/src/java/org/apache/lucene/util/NumericUtils.java
@@ -31,7 +31,7 @@ import org.apache.lucene.search.NumericRangeFilter; // for javadocs
  * the lowest possible precision in the trie, while the boundaries are matched
  * more exactly. This reduces the number of terms dramatically.
  *
- * <p>This class generates terms to achive this: First the numerical integer values need to
+ * <p>This class generates terms to achieve this: First the numerical integer values need to
  * be converted to strings. For that integer values (32 bit or 64 bit) are made unsigned
  * and the bits are converted to ASCII chars with each 7 bit. The resulting string is
  * sortable like the original integer value. Each value is also prefixed
diff --git a/src/java/org/apache/lucene/util/ReaderUtil.java b/src/java/org/apache/lucene/util/ReaderUtil.java
index 3450a1f..f912439 100644
--- a/src/java/org/apache/lucene/util/ReaderUtil.java
+++ b/src/java/org/apache/lucene/util/ReaderUtil.java
@@ -72,7 +72,7 @@ public class ReaderUtil {
    * 
    * @param reader parent reader
    * @param subIndex index of desired sub reader
-   * @return the subreader at subINdex
+   * @return the subreader at subIndex
    */
   public static IndexReader subReader(IndexReader reader, int subIndex) {
     List subReadersList = new ArrayList();
diff --git a/src/java/org/apache/lucene/util/ToStringUtils.java b/src/java/org/apache/lucene/util/ToStringUtils.java
index 75dcfea..761bab5 100644
--- a/src/java/org/apache/lucene/util/ToStringUtils.java
+++ b/src/java/org/apache/lucene/util/ToStringUtils.java
@@ -17,6 +17,9 @@ package org.apache.lucene.util;
  * limitations under the License.
  */
 
+/**
+ * Helper methods to ease implementing {@link Object#toString()}.
+ */
 public class ToStringUtils {
   /** for printing boost only if not 1.0 */ 
   public static String boost(float boost) {
diff --git a/src/java/org/apache/lucene/util/UnicodeUtil.java b/src/java/org/apache/lucene/util/UnicodeUtil.java
index 020bc69..6f219e6 100644
--- a/src/java/org/apache/lucene/util/UnicodeUtil.java
+++ b/src/java/org/apache/lucene/util/UnicodeUtil.java
@@ -410,10 +410,10 @@ final public class UnicodeUtil {
           if (nextCH >= UNI_SUR_LOW_START && nextCH <= UNI_SUR_LOW_END) {
             // Valid surrogate pair
           } else
-            // Unmatched hight surrogate
+            // Unmatched high surrogate
             return false;
         } else
-          // Unmatched hight surrogate
+          // Unmatched high surrogate
           return false;
       } else if (ch >= UNI_SUR_LOW_START && ch <= UNI_SUR_LOW_END)
         // Unmatched low surrogate

