GitDiffStart: 27502aa0459e0469e15becb6d35fefc28a3b4cf1 | Tue May 4 17:07:28 2010 +0000
diff --git a/lucene/contrib/CHANGES.txt b/lucene/contrib/CHANGES.txt
index d3bf8ad..30686fc 100644
--- a/lucene/contrib/CHANGES.txt
+++ b/lucene/contrib/CHANGES.txt
@@ -57,6 +57,12 @@ New features
      into subwords and performs optional transformations on subword groups.
    - o.a.l.analysis.miscellaneous.RemoveDuplicatesTokenFilter: TokenFilter which 
      filters out Tokens at the same position and Term text as the previous token.
+   - o.a.l.analysis.miscellaneous.TrimFilter: Trims leading and trailing whitespace 
+     from Tokens in the stream.
+   - o.a.l.analysis.miscellaneous.KeepWordFilter: A TokenFilter that only keeps tokens 
+     with text contained in the required words (inverse of StopFilter).
+   - o.a.l.analysis.miscellaneous.HyphenatedWordsFilter: A TokenFilter that puts 
+     hyphenated words broken into two lines back together.
    - o.a.l.analysis.pattern: Package for pattern-based analysis, containing a 
      CharFilter, Tokenizer, and Tokenfilter for transforming text with regexes.
    (... in progress)
diff --git a/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/miscellaneous/HyphenatedWordsFilter.java b/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/miscellaneous/HyphenatedWordsFilter.java
new file mode 100755
index 0000000..66137a1
--- /dev/null
+++ b/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/miscellaneous/HyphenatedWordsFilter.java
@@ -0,0 +1,142 @@
+package org.apache.lucene.analysis.miscellaneous;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.analysis.*;
+import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+
+/**
+ * When the plain text is extracted from documents, we will often have many words hyphenated and broken into
+ * two lines. This is often the case with documents where narrow text columns are used, such as newsletters.
+ * In order to increase search efficiency, this filter puts hyphenated words broken into two lines back together.
+ * This filter should be used on indexing time only.
+ * Example field definition in schema.xml:
+ * <pre>
+ * &lt;fieldtype name="text" class="solr.TextField" positionIncrementGap="100"&gt;
+ * 	&lt;analyzer type="index"&gt;
+ * 		&lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
+ *      &lt;filter class="solr.SynonymFilterFactory" synonyms="index_synonyms.txt" ignoreCase="true" expand="false"/&gt;
+ *      &lt;filter class="solr.StopFilterFactory" ignoreCase="true"/&gt;
+ *      &lt;filter class="solr.HyphenatedWordsFilterFactory"/&gt;
+ *      &lt;filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="1" catenateNumbers="1" catenateAll="0"/&gt;
+ *      &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
+ *      &lt;filter class="solr.RemoveDuplicatesTokenFilterFactory"/&gt;
+ *  &lt;/analyzer&gt;
+ *  &lt;analyzer type="query"&gt;
+ *      &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
+ *      &lt;filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt" ignoreCase="true" expand="true"/&gt;
+ *      &lt;filter class="solr.StopFilterFactory" ignoreCase="true"/&gt;
+ *      &lt;filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="0" catenateNumbers="0" catenateAll="0"/&gt;
+ *      &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
+ *      &lt;filter class="solr.RemoveDuplicatesTokenFilterFactory"/&gt;
+ *  &lt;/analyzer&gt;
+ * &lt;/fieldtype&gt;
+ * </pre>
+ * 
+ */
+public final class HyphenatedWordsFilter extends TokenFilter {
+
+  private final CharTermAttribute termAttribute = addAttribute(CharTermAttribute.class);
+  private final OffsetAttribute offsetAttribute = addAttribute(OffsetAttribute.class);
+  
+  private final StringBuilder hyphenated = new StringBuilder();
+  private State savedState;
+
+  /**
+   * Creates a new HyphenatedWordsFilter
+   *
+   * @param in TokenStream that will be filtered
+   */
+  public HyphenatedWordsFilter(TokenStream in) {
+    super(in);
+  }
+
+  /**
+   * {@inheritDoc}
+   */
+  @Override
+  public boolean incrementToken() throws IOException {
+    while (input.incrementToken()) {
+      char[] term = termAttribute.buffer();
+      int termLength = termAttribute.length();
+      
+      if (termLength > 0 && term[termLength - 1] == '-') {
+        // a hyphenated word
+        // capture the state of the first token only
+        if (savedState == null) {
+          savedState = captureState();
+        }
+        hyphenated.append(term, 0, termLength - 1);
+      } else if (savedState == null) {
+        // not part of a hyphenated word.
+        return true;
+      } else {
+        // the final portion of a hyphenated word
+        hyphenated.append(term, 0, termLength);
+        unhyphenate();
+        return true;
+      }
+    }
+    
+    if (savedState != null) {
+      // the final term ends with a hyphen
+      // add back the hyphen, for backwards compatibility.
+      hyphenated.append('-');
+      unhyphenate();
+      return true;
+    }
+    
+    return false;
+  }
+
+  /**
+   * {@inheritDoc}
+   */
+  @Override
+  public void reset() throws IOException {
+    super.reset();
+    hyphenated.setLength(0);
+    savedState = null;
+  }
+
+  // ================================================= Helper Methods ================================================
+
+  /**
+   * Writes the joined unhyphenated term
+   */
+  private void unhyphenate() {
+    int endOffset = offsetAttribute.endOffset();
+    
+    restoreState(savedState);
+    savedState = null;
+    
+    char term[] = termAttribute.buffer();
+    int length = hyphenated.length();
+    if (length > termAttribute.length()) {
+      term = termAttribute.resizeBuffer(length);
+    }
+    
+    hyphenated.getChars(0, length, term, 0);
+    termAttribute.setLength(length);
+    offsetAttribute.setOffset(offsetAttribute.startOffset(), endOffset);
+    hyphenated.setLength(0);
+  }
+}
diff --git a/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/miscellaneous/KeepWordFilter.java b/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/miscellaneous/KeepWordFilter.java
new file mode 100644
index 0000000..0909dd7
--- /dev/null
+++ b/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/miscellaneous/KeepWordFilter.java
@@ -0,0 +1,58 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.lucene.analysis.miscellaneous;
+
+import org.apache.lucene.analysis.TokenFilter;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.CharArraySet;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+
+import java.io.IOException;
+import java.util.Set;
+
+/**
+ * A TokenFilter that only keeps tokens with text contained in the
+ * required words.  This filter behaves like the inverse of StopFilter.
+ * 
+ * @since solr 1.3
+ */
+public final class KeepWordFilter extends TokenFilter {
+  private final CharArraySet words;
+  private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
+
+  /** @deprecated Use {@link #KeepWordFilter(TokenStream, CharArraySet)} instead */
+  @Deprecated
+  public KeepWordFilter(TokenStream in, Set<String> words, boolean ignoreCase ) {
+    this(in, new CharArraySet(words, ignoreCase));
+  }
+
+  /** The words set passed to this constructor will be directly used by this filter
+   * and should not be modified, */
+  public KeepWordFilter(TokenStream in, CharArraySet words) {
+    super(in);
+    this.words = words;
+  }
+
+  @Override
+  public boolean incrementToken() throws IOException {
+    while (input.incrementToken()) {
+      if (words.contains(termAtt.buffer(), 0, termAtt.length())) return true;
+    }
+    return false;
+  }
+}
diff --git a/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/miscellaneous/TrimFilter.java b/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/miscellaneous/TrimFilter.java
new file mode 100644
index 0000000..3f7e068
--- /dev/null
+++ b/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/miscellaneous/TrimFilter.java
@@ -0,0 +1,80 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.lucene.analysis.miscellaneous;
+
+import org.apache.lucene.analysis.TokenFilter;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
+
+import java.io.IOException;
+
+/**
+ * Trims leading and trailing whitespace from Tokens in the stream.
+ */
+public final class TrimFilter extends TokenFilter {
+
+  final boolean updateOffsets;
+  private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
+  private final OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);
+
+
+  public TrimFilter(TokenStream in, boolean updateOffsets) {
+    super(in);
+    this.updateOffsets = updateOffsets;
+  }
+
+  @Override
+  public boolean incrementToken() throws IOException {
+    if (!input.incrementToken()) return false;
+
+    char[] termBuffer = termAtt.buffer();
+    int len = termAtt.length();
+    //TODO: Is this the right behavior or should we return false?  Currently, "  ", returns true, so I think this should
+    //also return true
+    if (len == 0){
+      return true;
+    }
+    int start = 0;
+    int end = 0;
+    int endOff = 0;
+
+    // eat the first characters
+    //QUESTION: Should we use Character.isWhitespace() instead?
+    for (start = 0; start < len && termBuffer[start] <= ' '; start++) {
+    }
+    // eat the end characters
+    for (end = len; end >= start && termBuffer[end - 1] <= ' '; end--) {
+      endOff++;
+    }
+    if (start > 0 || end < len) {
+      if (start < end) {
+        termAtt.copyBuffer(termBuffer, start, (end - start));
+      } else {
+        termAtt.setEmpty();
+      }
+      if (updateOffsets) {
+        int newStart = offsetAtt.startOffset()+start;
+        int newEnd = offsetAtt.endOffset() - (start<end ? endOff:0);
+        offsetAtt.setOffset(newStart, newEnd);
+      }
+    }
+
+    return true;
+  }
+}
diff --git a/lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/miscellaneous/TestHyphenatedWordsFilter.java b/lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/miscellaneous/TestHyphenatedWordsFilter.java
new file mode 100755
index 0000000..5545fa8
--- /dev/null
+++ b/lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/miscellaneous/TestHyphenatedWordsFilter.java
@@ -0,0 +1,50 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.lucene.analysis.miscellaneous;
+
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.WhitespaceTokenizer;
+
+/**
+ * HyphenatedWordsFilter test
+ */
+public class TestHyphenatedWordsFilter extends BaseTokenStreamTestCase {
+	public void testHyphenatedWords() throws Exception {
+		String input = "ecologi-\r\ncal devel-\r\n\r\nop compre-\u0009hensive-hands-on and ecologi-\ncal";
+		// first test
+		TokenStream ts = new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader(input));
+		ts = new HyphenatedWordsFilter(ts);
+		assertTokenStreamContents(ts, 
+		    new String[] { "ecological", "develop", "comprehensive-hands-on", "and", "ecological" });
+	}
+	
+	/**
+	 * Test that HyphenatedWordsFilter behaves correctly with a final hyphen
+	 */
+	public void testHyphenAtEnd() throws Exception {
+	    String input = "ecologi-\r\ncal devel-\r\n\r\nop compre-\u0009hensive-hands-on and ecology-";
+	    // first test
+	    TokenStream ts = new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader(input));
+	    ts = new HyphenatedWordsFilter(ts);
+	    assertTokenStreamContents(ts, 
+	        new String[] { "ecological", "develop", "comprehensive-hands-on", "and", "ecology-" });
+	  }
+}
diff --git a/lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/miscellaneous/TestKeepWordFilter.java b/lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/miscellaneous/TestKeepWordFilter.java
new file mode 100644
index 0000000..bea2a48
--- /dev/null
+++ b/lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/miscellaneous/TestKeepWordFilter.java
@@ -0,0 +1,49 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.lucene.analysis.miscellaneous;
+
+import java.io.StringReader;
+import java.util.HashSet;
+import java.util.Set;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.WhitespaceTokenizer;
+
+/** Test {@link KeepWordFilter} */
+public class TestKeepWordFilter extends BaseTokenStreamTestCase {
+  
+  public void testStopAndGo() throws Exception 
+  {  
+    Set<String> words = new HashSet<String>();
+    words.add( "aaa" );
+    words.add( "bbb" );
+    
+    String input = "aaa BBB ccc ddd EEE";
+    
+    // Test Stopwords
+    TokenStream stream = new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader(input));
+    stream = new KeepWordFilter(stream, words, true);
+    assertTokenStreamContents(stream, new String[] { "aaa", "BBB" });
+       
+    // Now force case
+    stream = new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader(input));
+    stream = new KeepWordFilter(stream, words, false);
+    assertTokenStreamContents(stream, new String[] { "aaa" });
+  }
+}
diff --git a/lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTrimFilter.java b/lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTrimFilter.java
new file mode 100644
index 0000000..6439d6b
--- /dev/null
+++ b/lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTrimFilter.java
@@ -0,0 +1,110 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.lucene.analysis.miscellaneous;
+
+import java.io.IOException;
+import java.util.Collection;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.Token;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.tokenattributes.FlagsAttribute;
+import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
+import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;
+import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.TypeAttribute;
+
+/**
+ * @version $Id:$
+ */
+public class TestTrimFilter extends BaseTokenStreamTestCase {
+
+  public void testTrim() throws Exception {
+    char[] a = " a ".toCharArray();
+    char[] b = "b   ".toCharArray();
+    char[] ccc = "cCc".toCharArray();
+    char[] whitespace = "   ".toCharArray();
+    char[] empty = "".toCharArray();
+
+    TokenStream ts = new IterTokenStream(new Token(a, 0, a.length, 1, 5),
+                    new Token(b, 0, b.length, 6, 10),
+                    new Token(ccc, 0, ccc.length, 11, 15),
+                    new Token(whitespace, 0, whitespace.length, 16, 20),
+                    new Token(empty, 0, empty.length, 21, 21));
+    ts = new TrimFilter(ts, false);
+
+    assertTokenStreamContents(ts, new String[] { "a", "b", "cCc", "", ""});
+
+    a = " a".toCharArray();
+    b = "b ".toCharArray();
+    ccc = " c ".toCharArray();
+    whitespace = "   ".toCharArray();
+    ts = new IterTokenStream(
+            new Token(a, 0, a.length, 0, 2),
+            new Token(b, 0, b.length, 0, 2),
+            new Token(ccc, 0, ccc.length, 0, 3),
+            new Token(whitespace, 0, whitespace.length, 0, 3));
+    ts = new TrimFilter(ts, true);
+    
+    assertTokenStreamContents(ts, 
+        new String[] { "a", "b", "c", "" },
+        new int[] { 1, 0, 1, 3 },
+        new int[] { 2, 1, 2, 3 },
+        new int[] { 1, 1, 1, 1 });
+  }
+  
+  /**
+   * @deprecated does not support custom attributes
+   */
+  private static class IterTokenStream extends TokenStream {
+    final Token tokens[];
+    int index = 0;
+    CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
+    OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);
+    PositionIncrementAttribute posIncAtt = addAttribute(PositionIncrementAttribute.class);
+    FlagsAttribute flagsAtt = addAttribute(FlagsAttribute.class);
+    TypeAttribute typeAtt = addAttribute(TypeAttribute.class);
+    PayloadAttribute payloadAtt = addAttribute(PayloadAttribute.class);
+    
+    public IterTokenStream(Token... tokens) {
+      super();
+      this.tokens = tokens;
+    }
+    
+    public IterTokenStream(Collection<Token> tokens) {
+      this(tokens.toArray(new Token[tokens.size()]));
+    }
+    
+    public boolean incrementToken() throws IOException {
+      if (index >= tokens.length)
+        return false;
+      else {
+        clearAttributes();
+        Token token = tokens[index++];
+        termAtt.setEmpty().append(token.term());
+        offsetAtt.setOffset(token.startOffset(), token.endOffset());
+        posIncAtt.setPositionIncrement(token.getPositionIncrement());
+        flagsAtt.setFlags(token.getFlags());
+        typeAtt.setType(token.type());
+        payloadAtt.setPayload(token.getPayload());
+        return true;
+      }
+    }
+  }
+}
diff --git a/solr/src/java/org/apache/solr/analysis/HyphenatedWordsFilter.java b/solr/src/java/org/apache/solr/analysis/HyphenatedWordsFilter.java
deleted file mode 100755
index ec9d77b..0000000
--- a/solr/src/java/org/apache/solr/analysis/HyphenatedWordsFilter.java
+++ /dev/null
@@ -1,142 +0,0 @@
-package org.apache.solr.analysis;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-
-import org.apache.lucene.analysis.*;
-import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-
-/**
- * When the plain text is extracted from documents, we will often have many words hyphenated and broken into
- * two lines. This is often the case with documents where narrow text columns are used, such as newsletters.
- * In order to increase search efficiency, this filter puts hyphenated words broken into two lines back together.
- * This filter should be used on indexing time only.
- * Example field definition in schema.xml:
- * <pre>
- * &lt;fieldtype name="text" class="solr.TextField" positionIncrementGap="100"&gt;
- * 	&lt;analyzer type="index"&gt;
- * 		&lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
- *      &lt;filter class="solr.SynonymFilterFactory" synonyms="index_synonyms.txt" ignoreCase="true" expand="false"/&gt;
- *      &lt;filter class="solr.StopFilterFactory" ignoreCase="true"/&gt;
- *      &lt;filter class="solr.HyphenatedWordsFilterFactory"/&gt;
- *      &lt;filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="1" catenateNumbers="1" catenateAll="0"/&gt;
- *      &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
- *      &lt;filter class="solr.RemoveDuplicatesTokenFilterFactory"/&gt;
- *  &lt;/analyzer&gt;
- *  &lt;analyzer type="query"&gt;
- *      &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
- *      &lt;filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt" ignoreCase="true" expand="true"/&gt;
- *      &lt;filter class="solr.StopFilterFactory" ignoreCase="true"/&gt;
- *      &lt;filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="0" catenateNumbers="0" catenateAll="0"/&gt;
- *      &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
- *      &lt;filter class="solr.RemoveDuplicatesTokenFilterFactory"/&gt;
- *  &lt;/analyzer&gt;
- * &lt;/fieldtype&gt;
- * </pre>
- * 
- */
-public final class HyphenatedWordsFilter extends TokenFilter {
-
-  private final CharTermAttribute termAttribute = addAttribute(CharTermAttribute.class);
-  private final OffsetAttribute offsetAttribute = addAttribute(OffsetAttribute.class);
-  
-  private final StringBuilder hyphenated = new StringBuilder();
-  private State savedState;
-
-  /**
-   * Creates a new HyphenatedWordsFilter
-   *
-   * @param in TokenStream that will be filtered
-   */
-  public HyphenatedWordsFilter(TokenStream in) {
-    super(in);
-  }
-
-  /**
-   * {@inheritDoc}
-   */
-  @Override
-  public boolean incrementToken() throws IOException {
-    while (input.incrementToken()) {
-      char[] term = termAttribute.buffer();
-      int termLength = termAttribute.length();
-      
-      if (termLength > 0 && term[termLength - 1] == '-') {
-        // a hyphenated word
-        // capture the state of the first token only
-        if (savedState == null) {
-          savedState = captureState();
-        }
-        hyphenated.append(term, 0, termLength - 1);
-      } else if (savedState == null) {
-        // not part of a hyphenated word.
-        return true;
-      } else {
-        // the final portion of a hyphenated word
-        hyphenated.append(term, 0, termLength);
-        unhyphenate();
-        return true;
-      }
-    }
-    
-    if (savedState != null) {
-      // the final term ends with a hyphen
-      // add back the hyphen, for backwards compatibility.
-      hyphenated.append('-');
-      unhyphenate();
-      return true;
-    }
-    
-    return false;
-  }
-
-  /**
-   * {@inheritDoc}
-   */
-  @Override
-  public void reset() throws IOException {
-    super.reset();
-    hyphenated.setLength(0);
-    savedState = null;
-  }
-
-  // ================================================= Helper Methods ================================================
-
-  /**
-   * Writes the joined unhyphenated term
-   */
-  private void unhyphenate() {
-    int endOffset = offsetAttribute.endOffset();
-    
-    restoreState(savedState);
-    savedState = null;
-    
-    char term[] = termAttribute.buffer();
-    int length = hyphenated.length();
-    if (length > termAttribute.length()) {
-      term = termAttribute.resizeBuffer(length);
-    }
-    
-    hyphenated.getChars(0, length, term, 0);
-    termAttribute.setLength(length);
-    offsetAttribute.setOffset(offsetAttribute.startOffset(), endOffset);
-    hyphenated.setLength(0);
-  }
-}
diff --git a/solr/src/java/org/apache/solr/analysis/HyphenatedWordsFilterFactory.java b/solr/src/java/org/apache/solr/analysis/HyphenatedWordsFilterFactory.java
index e6923cd..8e1170d 100755
--- a/solr/src/java/org/apache/solr/analysis/HyphenatedWordsFilterFactory.java
+++ b/solr/src/java/org/apache/solr/analysis/HyphenatedWordsFilterFactory.java
@@ -18,6 +18,7 @@ package org.apache.solr.analysis;
  */
 
 import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.miscellaneous.HyphenatedWordsFilter;
 import org.apache.solr.analysis.BaseTokenFilterFactory;
 
 /**
diff --git a/solr/src/java/org/apache/solr/analysis/KeepWordFilter.java b/solr/src/java/org/apache/solr/analysis/KeepWordFilter.java
deleted file mode 100644
index 4a78a94..0000000
--- a/solr/src/java/org/apache/solr/analysis/KeepWordFilter.java
+++ /dev/null
@@ -1,59 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.TokenFilter;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.CharArraySet;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-
-import java.io.IOException;
-import java.util.Set;
-
-/**
- * A TokenFilter that only keeps tokens with text contained in the
- * required words.  This filter behaves like the inverse of StopFilter.
- * 
- * @version $Id$
- * @since solr 1.3
- */
-public final class KeepWordFilter extends TokenFilter {
-  private final CharArraySet words;
-  private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
-
-  /** @deprecated Use {@link #KeepWordFilter(TokenStream, Set, boolean)} instead */
-  @Deprecated
-  public KeepWordFilter(TokenStream in, Set<String> words, boolean ignoreCase ) {
-    this(in, new CharArraySet(words, ignoreCase));
-  }
-
-  /** The words set passed to this constructor will be directly used by this filter
-   * and should not be modified, */
-  public KeepWordFilter(TokenStream in, CharArraySet words) {
-    super(in);
-    this.words = words;
-  }
-
-  @Override
-  public boolean incrementToken() throws IOException {
-    while (input.incrementToken()) {
-      if (words.contains(termAtt.buffer(), 0, termAtt.length())) return true;
-    }
-    return false;
-  }
-}
diff --git a/solr/src/java/org/apache/solr/analysis/KeepWordFilterFactory.java b/solr/src/java/org/apache/solr/analysis/KeepWordFilterFactory.java
index ab170bd..3a633ed 100644
--- a/solr/src/java/org/apache/solr/analysis/KeepWordFilterFactory.java
+++ b/solr/src/java/org/apache/solr/analysis/KeepWordFilterFactory.java
@@ -21,6 +21,7 @@ import org.apache.solr.common.ResourceLoader;
 import org.apache.solr.util.plugin.ResourceLoaderAware;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.CharArraySet;
+import org.apache.lucene.analysis.miscellaneous.KeepWordFilter;
 
 import java.util.Set;
 import java.io.IOException;
diff --git a/solr/src/java/org/apache/solr/analysis/TrimFilter.java b/solr/src/java/org/apache/solr/analysis/TrimFilter.java
deleted file mode 100644
index b0cc7c3..0000000
--- a/solr/src/java/org/apache/solr/analysis/TrimFilter.java
+++ /dev/null
@@ -1,82 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.TokenFilter;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
-
-import java.io.IOException;
-
-/**
- * Trims leading and trailing whitespace from Tokens in the stream.
- *
- * @version $Id:$
- */
-public final class TrimFilter extends TokenFilter {
-
-  final boolean updateOffsets;
-  private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
-  private final OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);
-
-
-  public TrimFilter(TokenStream in, boolean updateOffsets) {
-    super(in);
-    this.updateOffsets = updateOffsets;
-  }
-
-  @Override
-  public boolean incrementToken() throws IOException {
-    if (!input.incrementToken()) return false;
-
-    char[] termBuffer = termAtt.buffer();
-    int len = termAtt.length();
-    //TODO: Is this the right behavior or should we return false?  Currently, "  ", returns true, so I think this should
-    //also return true
-    if (len == 0){
-      return true;
-    }
-    int start = 0;
-    int end = 0;
-    int endOff = 0;
-
-    // eat the first characters
-    //QUESTION: Should we use Character.isWhitespace() instead?
-    for (start = 0; start < len && termBuffer[start] <= ' '; start++) {
-    }
-    // eat the end characters
-    for (end = len; end >= start && termBuffer[end - 1] <= ' '; end--) {
-      endOff++;
-    }
-    if (start > 0 || end < len) {
-      if (start < end) {
-        termAtt.copyBuffer(termBuffer, start, (end - start));
-      } else {
-        termAtt.setEmpty();
-      }
-      if (updateOffsets) {
-        int newStart = offsetAtt.startOffset()+start;
-        int newEnd = offsetAtt.endOffset() - (start<end ? endOff:0);
-        offsetAtt.setOffset(newStart, newEnd);
-      }
-    }
-
-    return true;
-  }
-}
diff --git a/solr/src/java/org/apache/solr/analysis/TrimFilterFactory.java b/solr/src/java/org/apache/solr/analysis/TrimFilterFactory.java
index 62fbf70..ea1b690 100644
--- a/solr/src/java/org/apache/solr/analysis/TrimFilterFactory.java
+++ b/solr/src/java/org/apache/solr/analysis/TrimFilterFactory.java
@@ -20,6 +20,7 @@ package org.apache.solr.analysis;
 import java.util.Map;
 
 import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.miscellaneous.TrimFilter;
 import org.apache.solr.common.SolrException;
 
 /**
diff --git a/solr/src/test/org/apache/solr/analysis/TestHyphenatedWordsFilter.java b/solr/src/test/org/apache/solr/analysis/TestHyphenatedWordsFilter.java
deleted file mode 100755
index 0652eba..0000000
--- a/solr/src/test/org/apache/solr/analysis/TestHyphenatedWordsFilter.java
+++ /dev/null
@@ -1,51 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.WhitespaceTokenizer;
-
-/**
- * HyphenatedWordsFilter test
- */
-public class TestHyphenatedWordsFilter extends BaseTokenTestCase {
-	public void testHyphenatedWords() throws Exception {
-		String input = "ecologi-\r\ncal devel-\r\n\r\nop compre-\u0009hensive-hands-on and ecologi-\ncal";
-		// first test
-		TokenStream ts = new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(input));
-		HyphenatedWordsFilterFactory factory = new HyphenatedWordsFilterFactory();
-		ts = factory.create(ts);
-		assertTokenStreamContents(ts, 
-		    new String[] { "ecological", "develop", "comprehensive-hands-on", "and", "ecological" });
-	}
-	
-	/**
-	 * Test that HyphenatedWordsFilter behaves correctly with a final hyphen
-	 */
-	public void testHyphenAtEnd() throws Exception {
-	    String input = "ecologi-\r\ncal devel-\r\n\r\nop compre-\u0009hensive-hands-on and ecology-";
-	    // first test
-	    TokenStream ts = new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(input));
-	    HyphenatedWordsFilterFactory factory = new HyphenatedWordsFilterFactory();
-	    ts = factory.create(ts);
-	    assertTokenStreamContents(ts, 
-	        new String[] { "ecological", "develop", "comprehensive-hands-on", "and", "ecology-" });
-	  }
-}
diff --git a/solr/src/test/org/apache/solr/analysis/TestKeepWordFilter.java b/solr/src/test/org/apache/solr/analysis/TestKeepWordFilter.java
deleted file mode 100644
index 7a880de..0000000
--- a/solr/src/test/org/apache/solr/analysis/TestKeepWordFilter.java
+++ /dev/null
@@ -1,79 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import java.io.StringReader;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Map;
-import java.util.Set;
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.WhitespaceTokenizer;
-import org.apache.solr.common.ResourceLoader;
-import org.apache.solr.core.SolrResourceLoader;
-
-
-/**
- * @version $Id$
- */
-public class TestKeepWordFilter extends BaseTokenTestCase {
-  
-  public void testStopAndGo() throws Exception 
-  {  
-    Set<String> words = new HashSet<String>();
-    words.add( "aaa" );
-    words.add( "bbb" );
-    
-    String input = "aaa BBB ccc ddd EEE";
-    Map<String,String> args = new HashMap<String, String>(DEFAULT_VERSION_PARAM);
-    ResourceLoader loader = new SolrResourceLoader(null, null);
-    
-    // Test Stopwords
-    KeepWordFilterFactory factory = new KeepWordFilterFactory();
-    args.put( "ignoreCase", "true" );
-    factory.init( args );
-    factory.inform( loader );
-    factory.setWords( words );
-    assertTrue(factory.isIgnoreCase());
-    TokenStream stream = factory.create(new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(input)));
-    assertTokenStreamContents(stream, new String[] { "aaa", "BBB" });
-    
-    // Test Stopwords (ignoreCase via the setter instead)
-    factory = new KeepWordFilterFactory();
-    args = new HashMap<String, String>(DEFAULT_VERSION_PARAM);
-    factory.init( args );
-    factory.inform( loader );
-    factory.setIgnoreCase(true);
-    factory.setWords( words );
-    assertTrue(factory.isIgnoreCase());
-    stream = factory.create(new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(input)));
-    assertTokenStreamContents(stream, new String[] { "aaa", "BBB" });
-    
-    // Now force case
-    factory = new KeepWordFilterFactory();
-    args = new HashMap<String, String>(DEFAULT_VERSION_PARAM);
-    args.put( "ignoreCase", "false" );
-    factory.init( args );
-    factory.inform( loader );
-    factory.setWords( words );    
-    assertFalse(factory.isIgnoreCase());
-    stream = factory.create(new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(input)));
-    assertTokenStreamContents(stream, new String[] { "aaa" });
-  }
-}
diff --git a/solr/src/test/org/apache/solr/analysis/TestTrimFilter.java b/solr/src/test/org/apache/solr/analysis/TestTrimFilter.java
deleted file mode 100644
index 39616ce..0000000
--- a/solr/src/test/org/apache/solr/analysis/TestTrimFilter.java
+++ /dev/null
@@ -1,116 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import java.io.IOException;
-import java.util.Collection;
-import java.util.HashMap;
-import java.util.Map;
-
-import org.apache.lucene.analysis.Token;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.tokenattributes.FlagsAttribute;
-import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
-import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;
-import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-import org.apache.lucene.analysis.tokenattributes.TypeAttribute;
-
-/**
- * @version $Id:$
- */
-public class TestTrimFilter extends BaseTokenTestCase {
-
-  public void testTrim() throws Exception {
-    char[] a = " a ".toCharArray();
-    char[] b = "b   ".toCharArray();
-    char[] ccc = "cCc".toCharArray();
-    char[] whitespace = "   ".toCharArray();
-    char[] empty = "".toCharArray();
-    TrimFilterFactory factory = new TrimFilterFactory();
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("updateOffsets", "false");
-    factory.init(args);
-    TokenStream ts = factory.create(new IterTokenStream(new Token(a, 0, a.length, 1, 5),
-                    new Token(b, 0, b.length, 6, 10),
-                    new Token(ccc, 0, ccc.length, 11, 15),
-                    new Token(whitespace, 0, whitespace.length, 16, 20),
-                    new Token(empty, 0, empty.length, 21, 21)));
-
-    assertTokenStreamContents(ts, new String[] { "a", "b", "cCc", "", ""});
-
-    a = " a".toCharArray();
-    b = "b ".toCharArray();
-    ccc = " c ".toCharArray();
-    whitespace = "   ".toCharArray();
-    factory = new TrimFilterFactory();
-    args = new HashMap<String,String>();
-    args.put("updateOffsets", "true");
-    factory.init(args);
-    ts = factory.create(new IterTokenStream(
-            new Token(a, 0, a.length, 0, 2),
-            new Token(b, 0, b.length, 0, 2),
-            new Token(ccc, 0, ccc.length, 0, 3),
-            new Token(whitespace, 0, whitespace.length, 0, 3)));
-    
-    assertTokenStreamContents(ts, 
-        new String[] { "a", "b", "c", "" },
-        new int[] { 1, 0, 1, 3 },
-        new int[] { 2, 1, 2, 3 },
-        new int[] { 1, 1, 1, 1 });
-  }
-  
-  /**
-   * @deprecated does not support custom attributes
-   */
-  private static class IterTokenStream extends TokenStream {
-    final Token tokens[];
-    int index = 0;
-    CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
-    OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);
-    PositionIncrementAttribute posIncAtt = addAttribute(PositionIncrementAttribute.class);
-    FlagsAttribute flagsAtt = addAttribute(FlagsAttribute.class);
-    TypeAttribute typeAtt = addAttribute(TypeAttribute.class);
-    PayloadAttribute payloadAtt = addAttribute(PayloadAttribute.class);
-    
-    public IterTokenStream(Token... tokens) {
-      super();
-      this.tokens = tokens;
-    }
-    
-    public IterTokenStream(Collection<Token> tokens) {
-      this(tokens.toArray(new Token[tokens.size()]));
-    }
-    
-    public boolean incrementToken() throws IOException {
-      if (index >= tokens.length)
-        return false;
-      else {
-        clearAttributes();
-        Token token = tokens[index++];
-        termAtt.setEmpty().append(token.term());
-        offsetAtt.setOffset(token.startOffset(), token.endOffset());
-        posIncAtt.setPositionIncrement(token.getPositionIncrement());
-        flagsAtt.setFlags(token.getFlags());
-        typeAtt.setType(token.type());
-        payloadAtt.setPayload(token.getPayload());
-        return true;
-      }
-    }
-  }
-}
diff --git a/solr/src/test/org/apache/solr/analysis/TestTrimFilterFactory.java b/solr/src/test/org/apache/solr/analysis/TestTrimFilterFactory.java
new file mode 100644
index 0000000..9e1c684
--- /dev/null
+++ b/solr/src/test/org/apache/solr/analysis/TestTrimFilterFactory.java
@@ -0,0 +1,48 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import java.io.IOException;
+import java.io.StringReader;
+import java.util.Collection;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.lucene.analysis.KeywordTokenizer;
+import org.apache.lucene.analysis.Token;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.tokenattributes.FlagsAttribute;
+import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
+import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;
+import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.TypeAttribute;
+
+/**
+ * Simple tests to ensure this factory is working
+ */
+public class TestTrimFilterFactory extends BaseTokenTestCase {
+  public void testTrimming() throws Exception {
+    TrimFilterFactory factory = new TrimFilterFactory();
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("updateOffsets", "false");
+    factory.init(args);
+    TokenStream ts = factory.create(new KeywordTokenizer(new StringReader("trim me    ")));
+    assertTokenStreamContents(ts, new String[] { "trim me" });
+  }
+}

