GitDiffStart: 51779f7671e25d02ea3f719c340a879ef76d3d1b | Mon May 21 16:38:51 2012 +0000
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfosReader.java b/lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfosReader.java
index d688ee6..67c83bc 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfosReader.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfosReader.java
@@ -203,30 +203,30 @@ public class Lucene3xSegmentInfosReader extends SegmentInfosReader {
       if (isCompoundFile) {
         files.add(IndexFileNames.segmentFileName(name, "", IndexFileNames.COMPOUND_FILE_EXTENSION));
       } else {
-        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, "", "fnm"));
-        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, "", "frq"));
-        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, "", "prx"));
-        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, "", "tis"));
-        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, "", "tii"));
-        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, "", "nrm"));
+        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, "", Lucene3xFieldInfosReader.FIELD_INFOS_EXTENSION));
+        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, "", Lucene3xPostingsFormat.FREQ_EXTENSION));
+        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, "", Lucene3xPostingsFormat.PROX_EXTENSION));
+        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, "", Lucene3xPostingsFormat.TERMS_EXTENSION));
+        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, "", Lucene3xPostingsFormat.TERMS_INDEX_EXTENSION));
+        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, "", Lucene3xNormsProducer.NORMS_EXTENSION));
       }
 
       if (docStoreOffset != -1) {
         if (docStoreIsCompoundFile) {
-          files.add(IndexFileNames.segmentFileName(docStoreSegment, "", "cfx"));
+          files.add(IndexFileNames.segmentFileName(docStoreSegment, "", Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION));
         } else {
-          files.add(IndexFileNames.segmentFileName(docStoreSegment, "", "fdx"));
-          files.add(IndexFileNames.segmentFileName(docStoreSegment, "", "fdt"));
-          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, "", "tvx"));
-          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, "", "tvf"));
-          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, "", "tvd"));
+          files.add(IndexFileNames.segmentFileName(docStoreSegment, "", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));
+          files.add(IndexFileNames.segmentFileName(docStoreSegment, "", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));
+          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, "", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));
+          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, "", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));
+          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, "", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));
         }
       } else if (!isCompoundFile) {
-        files.add(IndexFileNames.segmentFileName(segmentName, "", "fdx"));
-        files.add(IndexFileNames.segmentFileName(segmentName, "", "fdt"));
-        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, "", "tvx"));
-        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, "", "tvf"));
-        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, "", "tvd"));
+        files.add(IndexFileNames.segmentFileName(segmentName, "", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));
+        files.add(IndexFileNames.segmentFileName(segmentName, "", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));
+        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, "", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));
+        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, "", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));
+        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, "", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));
       }
 
       if (normGen != null) {
diff --git a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java
index fdd6215..78d643f 100644
--- a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java
+++ b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java
@@ -3276,11 +3276,6 @@ public class IndexWriter implements Closeable, TwoPhaseCommit {
       return;
     }
 
-    // Bind a new segment name here so even with
-    // ConcurrentMergePolicy we keep deterministic segment
-    // names.
-    merge.info = new SegmentInfo(newSegmentName(), 0, directory, false, null);
-
     // TODO: in the non-pool'd case this is somewhat
     // wasteful, because we open these readers, close them,
     // and then open them again for merging.  Maybe  we
@@ -3308,14 +3303,20 @@ public class IndexWriter implements Closeable, TwoPhaseCommit {
       checkpoint();
     }
 
+    Map<String,String> details = new HashMap<String,String>();
+    details.put("mergeMaxNumSegments", ""+merge.maxNumSegments);
+    details.put("mergeFactor", Integer.toString(merge.segments.size()));
+
+    // Bind a new segment name here so even with
+    // ConcurrentMergePolicy we keep deterministic segment
+    // names.
+    final String mergeSegmentName = newSegmentName();
+    merge.info = new SegmentInfo(directory, Constants.LUCENE_MAIN_VERSION, mergeSegmentName, 0, -1, mergeSegmentName, false, null, false, 0, codec, details);
+
     merge.info.setBufferedDeletesGen(result.gen);
 
     // Lock order: IW -> BD
     bufferedDeletesStream.prune(segmentInfos);
-    Map<String,String> details = new HashMap<String,String>();
-    details.put("mergeMaxNumSegments", ""+merge.maxNumSegments);
-    details.put("mergeFactor", Integer.toString(merge.segments.size()));
-    setDiagnostics(merge.info, "merge", details);
 
     if (infoStream.isEnabled("IW")) {
       infoStream.message("IW", "merge seg=" + merge.info.name);
@@ -3506,10 +3507,6 @@ public class IndexWriter implements Closeable, TwoPhaseCommit {
 
       // Record which codec was used to write the segment
 
-      // nocommit stop doing this once we call non-wimpy
-      // ctor when we make the merge.info:
-      merge.info.setCodec(codec);
-
       if (infoStream.isEnabled("IW")) {
         infoStream.message("IW", "merge codec=" + codec + " docCount=" + merge.info.docCount + "; merged segment has " +
                            (mergeState.fieldInfos.hasVectors() ? "vectors" : "no vectors") + "; " +
diff --git a/lucene/core/src/java/org/apache/lucene/index/SegmentInfo.java b/lucene/core/src/java/org/apache/lucene/index/SegmentInfo.java
index a40677a..ee22c57 100644
--- a/lucene/core/src/java/org/apache/lucene/index/SegmentInfo.java
+++ b/lucene/core/src/java/org/apache/lucene/index/SegmentInfo.java
@@ -40,7 +40,6 @@ import org.apache.lucene.util.Constants;
  *
  * @lucene.experimental
  */
-// nocommit final...?
 public class SegmentInfo implements Cloneable {
   
   // TODO: remove these from this class, for now this is the representation
@@ -60,6 +59,7 @@ public class SegmentInfo implements Cloneable {
    * - NO if there are no deletes
    * - YES or higher if there are deletes at generation N
    */
+  // nocommit move this "out" somewhere...
   // nocommit explain that codec need not save this....:
   private long delGen;
 
@@ -87,6 +87,7 @@ public class SegmentInfo implements Cloneable {
   //TODO: LUCENE-2555: remove once we don't need to support shared doc stores (pre 4.0)
   private final boolean docStoreIsCompoundFile;         // whether doc store files are stored in compound file (*.cfx)
 
+  // nocommit move this out:
   // nocommit explain that codec need not save this....:
   private int delCount;                           // How many deleted docs in this segment
   
@@ -99,31 +100,15 @@ public class SegmentInfo implements Cloneable {
   // The format expected is "x.y" - "2.x" for pre-3.0 indexes (or null), and
   // specific versions afterwards ("3.0", "3.1" etc.).
   // see Constants.LUCENE_MAIN_VERSION.
+  // nocommit why does ctor even take this?  shuldn't we
+  // always be the current version!?
+  // nocommit final?
   private String version;
 
   // NOTE: only used in-RAM by IW to track buffered deletes;
   // this is never written to/read from the Directory
   private long bufferedDeletesGen;
   
-  // nocommit why do we have this wimpy ctor...?
-  public SegmentInfo(String name, int docCount, Directory dir, boolean isCompoundFile,
-                     Codec codec) {
-    // nocommit
-    /*
-    this.name = name;
-    this.docCount = docCount;
-    this.dir = dir;
-    delGen = NO;
-    this.isCompoundFile = isCompoundFile;
-    this.docStoreOffset = -1;
-    this.docStoreSegment = name;
-    this.codec = codec;
-    delCount = 0;
-    version = Constants.LUCENE_MAIN_VERSION;
-    */
-    this(dir, Constants.LUCENE_MAIN_VERSION, name, docCount, -1, name, false, null, isCompoundFile, 0, codec, new HashMap<String,String>());
-  }
-
   void setDiagnostics(Map<String, String> diagnostics) {
     this.diagnostics = diagnostics;
   }
@@ -506,23 +491,12 @@ public class SegmentInfo implements Cloneable {
   // nocommit now on building a CFS we erase the files that
   // are in it... maybe we should somehow preserve it...
   public void setFiles(Set<String> files) {
-    //System.out.println("set files=" + files);
-    //if (files.size() == 0) {
-    //new Throwable().printStackTrace(System.out);
-    //}
     setFiles = files;
   }
 
+  // nocommit remove this!  it's only needed for
+  // clearing/adding the files set...
   public Set<String> getFiles() {
     return setFiles;
   }
-
-  public Set<String> getFiles2() throws IOException {
-    Set<String> files = new HashSet<String>(setFiles);
-
-    // nocommit make this take list instead...?
-    // Must separately add any live docs files:
-    codec.liveDocsFormat().files(this, files);
-    return files;
-  }
 }
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestCodecs.java b/lucene/core/src/test/org/apache/lucene/index/TestCodecs.java
index d34d22b..7c9d404 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestCodecs.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestCodecs.java
@@ -256,7 +256,8 @@ public class TestCodecs extends LuceneTestCase {
     final Directory dir = newDirectory();
     this.write(fieldInfos, dir, fields, true);
     Codec codec = Codec.getDefault();
-    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec);
+    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, -1, SEGMENT, false, null, false,
+                                           0, codec, null);
 
     final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));
 

