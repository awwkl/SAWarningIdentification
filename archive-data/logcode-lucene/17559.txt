GitDiffStart: a43f67ddab42a509777d9a15ae0320a9a20ec9df | Thu Aug 12 10:31:37 2010 +0000
diff --git a/lucene/CHANGES.txt b/lucene/CHANGES.txt
index 7f00e27..e9f4158 100644
--- a/lucene/CHANGES.txt
+++ b/lucene/CHANGES.txt
@@ -555,6 +555,12 @@ New features
 * LUCENE-2589: Add a VariableSizedIntIndexInput, which, when used w/
   Sep*, makes it simple to take any variable sized int block coders
   (like Simple9/16) and use them in a codec.  (Mike McCandless)
+
+* LUCENE-2597: Add oal.index.SlowMultiReaderWrapper, to wrap a
+  composite reader (eg MultiReader or DirectoryReader), making it
+  pretend it's an atomic reader.  This is a convenience class (you can
+  use MultiFields static methods directly, instead) if you need to use
+  the flex APIs directly on a composite reader.  (Mike McCandless)
   
 Optimizations
 
diff --git a/lucene/contrib/queries/src/java/org/apache/lucene/search/TermsFilter.java b/lucene/contrib/queries/src/java/org/apache/lucene/search/TermsFilter.java
index 94df30d..5ab5834 100644
--- a/lucene/contrib/queries/src/java/org/apache/lucene/search/TermsFilter.java
+++ b/lucene/contrib/queries/src/java/org/apache/lucene/search/TermsFilter.java
@@ -27,7 +27,6 @@ import org.apache.lucene.index.Term;
 import org.apache.lucene.index.DocsEnum;
 import org.apache.lucene.index.Terms;
 import org.apache.lucene.index.TermsEnum;
-import org.apache.lucene.index.MultiFields;
 import org.apache.lucene.index.Fields;
 import org.apache.lucene.util.OpenBitSet;
 import org.apache.lucene.util.BytesRef;
@@ -60,9 +59,9 @@ public class TermsFilter extends Filter
   @Override
   public DocIdSet getDocIdSet(IndexReader reader) throws IOException {
     OpenBitSet result=new OpenBitSet(reader.maxDoc());
-    Fields fields = MultiFields.getFields(reader);
+    Fields fields = reader.fields();
     BytesRef br = new BytesRef();
-    Bits delDocs = MultiFields.getDeletedDocs(reader);
+    Bits delDocs = reader.getDeletedDocs();
     if (fields != null) {
       String lastField = null;
       Terms termsC = null;
diff --git a/lucene/contrib/queries/src/test/org/apache/lucene/search/BooleanFilterTest.java b/lucene/contrib/queries/src/test/org/apache/lucene/search/BooleanFilterTest.java
index 3192f2a..7aaf1c6 100644
--- a/lucene/contrib/queries/src/test/org/apache/lucene/search/BooleanFilterTest.java
+++ b/lucene/contrib/queries/src/test/org/apache/lucene/search/BooleanFilterTest.java
@@ -18,7 +18,6 @@ package org.apache.lucene.search;
  */
 
 import java.io.IOException;
-import java.util.Random;
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.analysis.MockTokenizer;
@@ -26,12 +25,14 @@ import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.index.SlowMultiReaderWrapper;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.store.MockRAMDirectory;
 import org.apache.lucene.util.LuceneTestCase;
 
 public class BooleanFilterTest extends LuceneTestCase {
 	private MockRAMDirectory directory;
+	private IndexReader mainReader;
 	private IndexReader reader;
 
 	@Override
@@ -46,13 +47,14 @@ public class BooleanFilterTest extends LuceneTestCase {
 		addDoc(writer, "guest", "020", "20050101","Y");
 		addDoc(writer, "admin", "020", "20050101","Maybe");
 		addDoc(writer, "admin guest", "030", "20050101","N");
-		reader = writer.getReader();
+		mainReader = writer.getReader();
+		reader = SlowMultiReaderWrapper.wrap(mainReader);
 		writer.close();	
 	}
 	
 	@Override
 	protected void tearDown() throws Exception {
-	  reader.close();
+	  mainReader.close();
 	  directory.close();
 	  super.tearDown();
 	}
diff --git a/lucene/contrib/queries/src/test/org/apache/lucene/search/TermsFilterTest.java b/lucene/contrib/queries/src/test/org/apache/lucene/search/TermsFilterTest.java
index 9cc19eb..dbccd25 100644
--- a/lucene/contrib/queries/src/test/org/apache/lucene/search/TermsFilterTest.java
+++ b/lucene/contrib/queries/src/test/org/apache/lucene/search/TermsFilterTest.java
@@ -25,6 +25,7 @@ import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.store.MockRAMDirectory;
+import org.apache.lucene.index.SlowMultiReaderWrapper;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.OpenBitSet;
 
@@ -58,8 +59,10 @@ public class TermsFilterTest extends LuceneTestCase {
 			doc.add(new Field(fieldName,""+term,Field.Store.YES,Field.Index.NOT_ANALYZED));
 			w.addDocument(doc);			
 		}
-		IndexReader reader = w.getReader();
+		IndexReader mainReader = w.getReader();
 		w.close();
+
+                IndexReader reader = SlowMultiReaderWrapper.wrap(mainReader);
 		
 		TermsFilter tf=new TermsFilter();
 		tf.addTerm(new Term(fieldName,"19"));
@@ -78,7 +81,7 @@ public class TermsFilterTest extends LuceneTestCase {
 		bits = (OpenBitSet)tf.getDocIdSet(reader);
 		assertEquals("Must match 2", 2, bits.cardinality());
 		
-		reader.close();
+		mainReader.close();
 		rd.close();
 	}
 }
diff --git a/lucene/contrib/spatial/src/java/org/apache/lucene/spatial/tier/CartesianShapeFilter.java b/lucene/contrib/spatial/src/java/org/apache/lucene/spatial/tier/CartesianShapeFilter.java
index 20e951c..11527f3 100644
--- a/lucene/contrib/spatial/src/java/org/apache/lucene/spatial/tier/CartesianShapeFilter.java
+++ b/lucene/contrib/spatial/src/java/org/apache/lucene/spatial/tier/CartesianShapeFilter.java
@@ -21,7 +21,6 @@ import java.util.List;
 
 import org.apache.lucene.index.DocsEnum;
 import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.MultiFields;
 import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.DocIdSet;
 import org.apache.lucene.search.DocIdSetIterator;
@@ -47,7 +46,7 @@ public class CartesianShapeFilter extends Filter {
   
   @Override
   public DocIdSet getDocIdSet(final IndexReader reader) throws IOException {
-    final Bits delDocs = MultiFields.getDeletedDocs(reader);
+    final Bits delDocs = reader.getDeletedDocs();
     final List<Double> area = shape.getArea();
     final int sz = area.size();
     
@@ -59,7 +58,7 @@ public class CartesianShapeFilter extends Filter {
       return new DocIdSet() {
         @Override
         public DocIdSetIterator iterator() throws IOException {
-          return MultiFields.getTermDocsEnum(reader, delDocs, fieldName, bytesRef);
+          return reader.termDocsEnum(delDocs, fieldName, bytesRef);
         }
         
         @Override
@@ -72,7 +71,7 @@ public class CartesianShapeFilter extends Filter {
       for (int i =0; i< sz; i++) {
         double boxId = area.get(i).doubleValue();
         NumericUtils.longToPrefixCoded(NumericUtils.doubleToSortableLong(boxId), 0, bytesRef);
-        final DocsEnum docsEnum = MultiFields.getTermDocsEnum(reader, delDocs, fieldName, bytesRef);
+        final DocsEnum docsEnum = reader.termDocsEnum(delDocs, fieldName, bytesRef);
         if (docsEnum == null) continue;
         // iterate through all documents
         // which have this boxId
diff --git a/lucene/src/java/org/apache/lucene/index/DirectoryReader.java b/lucene/src/java/org/apache/lucene/index/DirectoryReader.java
index 0e55f3a..b4b1ddd 100644
--- a/lucene/src/java/org/apache/lucene/index/DirectoryReader.java
+++ b/lucene/src/java/org/apache/lucene/index/DirectoryReader.java
@@ -371,7 +371,7 @@ class DirectoryReader extends IndexReader implements Cloneable {
 
   @Override
   public Bits getDeletedDocs() {
-    throw new UnsupportedOperationException("please use MultiFields.getDeletedDocs if you really need a top level Bits deletedDocs (NOTE that it's usually better to work per segment instead)");
+    throw new UnsupportedOperationException("please use MultiFields.getDeletedDocs, or wrap your IndexReader with SlowMultiReaderWrapper, if you really need a top level Bits deletedDocs");
   }
 
   @Override
@@ -714,7 +714,7 @@ class DirectoryReader extends IndexReader implements Cloneable {
 
   @Override
   public Fields fields() throws IOException {
-    throw new UnsupportedOperationException("please use MultiFields.getFields if you really need a top level Fields (NOTE that it's usually better to work per segment instead)");
+    throw new UnsupportedOperationException("please use MultiFields.getFields, or wrap your IndexReader with SlowMultiReaderWrapper, if you really need a top level Fields");
   }
 
   /**
diff --git a/lucene/src/java/org/apache/lucene/index/IndexFileDeleter.java b/lucene/src/java/org/apache/lucene/index/IndexFileDeleter.java
index fc8a4a4..4785024 100644
--- a/lucene/src/java/org/apache/lucene/index/IndexFileDeleter.java
+++ b/lucene/src/java/org/apache/lucene/index/IndexFileDeleter.java
@@ -106,7 +106,7 @@ final class IndexFileDeleter {
 
   /** Change to true to see details of reference counts when
    *  infoStream != null */
-  public static boolean VERBOSE_REF_COUNTS = false;
+  public static boolean VERBOSE_REF_COUNTS = true;
 
   void setInfoStream(PrintStream infoStream) {
     this.infoStream = infoStream;
diff --git a/lucene/src/java/org/apache/lucene/index/MultiReader.java b/lucene/src/java/org/apache/lucene/index/MultiReader.java
index e6c8116..60fee25 100644
--- a/lucene/src/java/org/apache/lucene/index/MultiReader.java
+++ b/lucene/src/java/org/apache/lucene/index/MultiReader.java
@@ -107,7 +107,7 @@ public class MultiReader extends IndexReader implements Cloneable {
 
   @Override
   public Fields fields() throws IOException {
-    throw new UnsupportedOperationException("please use MultiFields.getFields if you really need a top level Fields (NOTE that it's usually better to work per segment instead)");
+    throw new UnsupportedOperationException("please use MultiFields.getFields, or wrap your IndexReader with SlowMultiReaderWrapper, if you really need a top level Fields");
   }
 
   /**
@@ -154,7 +154,7 @@ public class MultiReader extends IndexReader implements Cloneable {
   
   @Override
   public Bits getDeletedDocs() throws IOException {
-    throw new UnsupportedOperationException("please use MultiFields.getDeletedDocs if you really need a top level Bits deletedDocs (NOTE that it's usually better to work per segment instead)");
+    throw new UnsupportedOperationException("please use MultiFields.getDeletedDocs, or wrap your IndexReader with SlowMultiReaderWrapper, if you really need a top level Bits deletedDocs");
   }
 
   /**
diff --git a/lucene/src/java/org/apache/lucene/index/SlowMultiReaderWrapper.java b/lucene/src/java/org/apache/lucene/index/SlowMultiReaderWrapper.java
new file mode 100644
index 0000000..28a7cd7
--- /dev/null
+++ b/lucene/src/java/org/apache/lucene/index/SlowMultiReaderWrapper.java
@@ -0,0 +1,82 @@
+package org.apache.lucene.index;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.List;
+import java.util.ArrayList;
+import org.apache.lucene.util.Bits;
+import org.apache.lucene.util.ReaderUtil;
+
+/**
+ * This class forces a composite reader (eg a {@link
+ * MultiReader} or {@link DirectoryReader} or any other
+ * IndexReader subclass that returns non-null from {@link
+ * IndexReader#getSequentialSubReaders}) to emulate an
+ * atomic reader.  This requires implementing the postings
+ * APIs on-the-fly, using the static methods in {@link
+ * MultiFields}, by stepping through the sub-readers to
+ * merge fields/terms, appending docs, etc.
+ *
+ * <p>If you ever hit an UnsupportedOperationException saying
+ * "please use MultiFields.XXX instead", the simple
+ * but non-performant workaround is to wrap your reader
+ * using this class.</p>
+ *
+ * <p><b>NOTE</b>: this class almost always results in a
+ * performance hit.  If this is important to your use case,
+ * it's better to get the sequential sub readers (see {@link
+ * ReaderUtil#gatherSubReaders}, instead, and iterate through them
+ * yourself.</p>
+ */
+
+public final class SlowMultiReaderWrapper extends FilterIndexReader {
+  /** This method may return the reader back, if the
+   *  incoming reader is already atomic. */
+  public static IndexReader wrap(IndexReader reader) {
+    final List<IndexReader> subs = new ArrayList<IndexReader>();
+    ReaderUtil.gatherSubReaders(subs, reader);
+    if (subs == null) {
+      // already an atomic reader
+      return reader;
+    } else if (subs.size() == 1) {
+      return subs.get(0);
+    } else {
+      return new SlowMultiReaderWrapper(reader);
+    }
+  }
+
+  private SlowMultiReaderWrapper(IndexReader other) {
+    super(other);
+  }
+
+  @Override
+  public Fields fields() throws IOException {
+    return MultiFields.getFields(in);
+  }
+
+  @Override
+  public Bits getDeletedDocs() throws IOException {
+    return MultiFields.getDeletedDocs(in);
+  }
+
+  @Override
+  public void doClose() throws IOException {
+    throw new UnsupportedOperationException("please call close on the original reader instead");
+  }
+}
diff --git a/lucene/src/java/org/apache/lucene/search/AutomatonQuery.java b/lucene/src/java/org/apache/lucene/search/AutomatonQuery.java
index ed14f77..d779634 100644
--- a/lucene/src/java/org/apache/lucene/search/AutomatonQuery.java
+++ b/lucene/src/java/org/apache/lucene/search/AutomatonQuery.java
@@ -92,6 +92,8 @@ public class AutomatonQuery extends MultiTermQuery {
     
     // matches all possible strings
     if (BasicOperations.isTotal(automaton)) {
+      // NOTE: for now, MultiTermQuery enums terms at the
+      // MultiReader level, so we must use MultiFields here:
       return MultiFields.getTerms(reader, getField()).iterator();
     }
     
diff --git a/lucene/src/java/org/apache/lucene/search/MultiPhraseQuery.java b/lucene/src/java/org/apache/lucene/search/MultiPhraseQuery.java
index f3be46b..ea774b8 100644
--- a/lucene/src/java/org/apache/lucene/search/MultiPhraseQuery.java
+++ b/lucene/src/java/org/apache/lucene/search/MultiPhraseQuery.java
@@ -23,7 +23,6 @@ import java.util.*;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.index.DocsEnum;
-import org.apache.lucene.index.MultiFields;
 import org.apache.lucene.index.DocsAndPositionsEnum;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.ToStringUtils;
@@ -171,7 +170,7 @@ public class MultiPhraseQuery extends Query {
       if (termArrays.size() == 0)                  // optimize zero-term case
         return null;
 
-      final Bits delDocs = MultiFields.getDeletedDocs(reader);
+      final Bits delDocs = reader.getDeletedDocs();
       
       PhraseQuery.PostingsAndFreq[] postingsFreqs = new PhraseQuery.PostingsAndFreq[termArrays.size()];
 
@@ -191,22 +190,22 @@ public class MultiPhraseQuery extends Query {
             docFreq += reader.docFreq(terms[termIdx]);
           }
         } else {
-          final BytesRef text = new BytesRef(terms[0].text());
+          final Term term = terms[0];
           postingsEnum = reader.termPositionsEnum(delDocs,
-                                                  terms[0].field(),
-                                                  text);
+                                                  term.field(),
+                                                  term.bytes());
 
           if (postingsEnum == null) {
-            if (MultiFields.getTermDocsEnum(reader, delDocs, terms[0].field(), text) != null) {
+            if (reader.termDocsEnum(delDocs, term.field(), term.bytes()) != null) {
               // term does exist, but has no positions
-              throw new IllegalStateException("field \"" + terms[0].field() + "\" was indexed with Field.omitTermFreqAndPositions=true; cannot run PhraseQuery (term=" + terms[0].text() + ")");
+              throw new IllegalStateException("field \"" + term.field() + "\" was indexed with Field.omitTermFreqAndPositions=true; cannot run PhraseQuery (term=" + term.text() + ")");
             } else {
               // term does not exist
               return null;
             }
           }
 
-          docFreq = reader.docFreq(terms[0].field(), text);
+          docFreq = reader.docFreq(term.field(), term.bytes());
         }
 
         postingsFreqs[pos] = new PhraseQuery.PostingsAndFreq(postingsEnum, docFreq, positions.get(pos).intValue());
@@ -497,7 +496,7 @@ class UnionDocsAndPositionsEnum extends DocsAndPositionsEnum {
 
   public UnionDocsAndPositionsEnum(IndexReader indexReader, Term[] terms) throws IOException {
     List<DocsAndPositionsEnum> docsEnums = new LinkedList<DocsAndPositionsEnum>();
-    final Bits delDocs = MultiFields.getDeletedDocs(indexReader);
+    final Bits delDocs = indexReader.getDeletedDocs();
     for (int i = 0; i < terms.length; i++) {
       DocsAndPositionsEnum postings = indexReader.termPositionsEnum(delDocs,
                                                                     terms[i].field(),
@@ -505,7 +504,7 @@ class UnionDocsAndPositionsEnum extends DocsAndPositionsEnum {
       if (postings != null) {
         docsEnums.add(postings);
       } else {
-        if (MultiFields.getTermDocsEnum(indexReader, delDocs, terms[i].field(), terms[i].bytes()) != null) {
+        if (indexReader.termDocsEnum(delDocs, terms[i].field(), terms[i].bytes()) != null) {
           // term does exist, but has no positions
           throw new IllegalStateException("field \"" + terms[i].field() + "\" was indexed with Field.omitTermFreqAndPositions=true; cannot run PhraseQuery (term=" + terms[i].text() + ")");
         }
diff --git a/lucene/src/java/org/apache/lucene/search/PhraseQuery.java b/lucene/src/java/org/apache/lucene/search/PhraseQuery.java
index 1c498cd..e24178a 100644
--- a/lucene/src/java/org/apache/lucene/search/PhraseQuery.java
+++ b/lucene/src/java/org/apache/lucene/search/PhraseQuery.java
@@ -23,10 +23,8 @@ import java.util.ArrayList;
 import java.util.Arrays;
 
 import org.apache.lucene.index.Term;
-import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.index.DocsAndPositionsEnum;
 import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.MultiFields;
 import org.apache.lucene.search.Explanation.IDFExplanation;
 import org.apache.lucene.util.ToStringUtils;
 import org.apache.lucene.util.Bits;
@@ -181,17 +179,16 @@ public class PhraseQuery extends Query {
         return null;
 
       PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.size()];
-      final Bits delDocs = MultiFields.getDeletedDocs(reader);
+      final Bits delDocs = reader.getDeletedDocs();
       for (int i = 0; i < terms.size(); i++) {
         final Term t = terms.get(i);
-        DocsAndPositionsEnum postingsEnum = MultiFields.getTermPositionsEnum(reader,
-                                                                             delDocs,
-                                                                             t.field(),
-                                                                             t.bytes());
+        DocsAndPositionsEnum postingsEnum = reader.termPositionsEnum(delDocs,
+                                                                     t.field(),
+                                                                     t.bytes());
         // PhraseQuery on a field that did not index
         // positions.
         if (postingsEnum == null) {
-          if (MultiFields.getTermDocsEnum(reader, delDocs, t.field(), t.bytes()) != null) {
+          if (reader.termDocsEnum(delDocs, t.field(), t.bytes()) != null) {
             // term does exist, but has no positions
             throw new IllegalStateException("field \"" + t.field() + "\" was indexed with Field.omitTermFreqAndPositions=true; cannot run PhraseQuery (term=" + t.text() + ")");
           } else {
diff --git a/lucene/src/java/org/apache/lucene/search/PrefixQuery.java b/lucene/src/java/org/apache/lucene/search/PrefixQuery.java
index 02ea963..e3b08bd 100644
--- a/lucene/src/java/org/apache/lucene/search/PrefixQuery.java
+++ b/lucene/src/java/org/apache/lucene/search/PrefixQuery.java
@@ -48,6 +48,8 @@ public class PrefixQuery extends MultiTermQuery {
   protected TermsEnum getTermsEnum(IndexReader reader) throws IOException {
     if (prefix.bytes().length == 0) {
       // no prefix -- match all terms for this field:
+      // NOTE: for now, MultiTermQuery enums terms at the
+      // MultiReader level, so we must use MultiFields here:
       final Terms terms = MultiFields.getTerms(reader, getField());
       return (terms != null) ? terms.iterator() : TermsEnum.EMPTY;
     }
diff --git a/lucene/src/java/org/apache/lucene/search/TermQuery.java b/lucene/src/java/org/apache/lucene/search/TermQuery.java
index c55d0f1..549317a 100644
--- a/lucene/src/java/org/apache/lucene/search/TermQuery.java
+++ b/lucene/src/java/org/apache/lucene/search/TermQuery.java
@@ -22,8 +22,6 @@ import java.util.Set;
 
 import org.apache.lucene.index.DocsEnum;
 import org.apache.lucene.index.Term;
-import org.apache.lucene.index.MultiFields;
-import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.search.Explanation.IDFExplanation;
 import org.apache.lucene.util.ToStringUtils;
@@ -73,9 +71,10 @@ public class TermQuery extends Query {
 
     @Override
     public Scorer scorer(IndexReader reader, boolean scoreDocsInOrder, boolean topScorer) throws IOException {
-      // NOTE: debateably, the caller should never pass in a
-      // multi reader...
-      DocsEnum docs = MultiFields.getTermDocsEnum(reader, MultiFields.getDeletedDocs(reader), term.field(), term.bytes());
+      DocsEnum docs = reader.termDocsEnum(reader.getDeletedDocs(),
+                                          term.field(),
+                                          term.bytes());
+
       if (docs == null) {
         return null;
       }
@@ -118,7 +117,7 @@ public class TermQuery extends Query {
 
       Explanation tfExplanation = new Explanation();
       int tf = 0;
-      DocsEnum docs = reader.termDocsEnum(MultiFields.getDeletedDocs(reader), term.field(), term.bytes());
+      DocsEnum docs = reader.termDocsEnum(reader.getDeletedDocs(), term.field(), term.bytes());
       if (docs != null) {
           int newDoc = docs.advance(doc);
           if (newDoc == doc) {
diff --git a/lucene/src/java/org/apache/lucene/search/TermRangeQuery.java b/lucene/src/java/org/apache/lucene/search/TermRangeQuery.java
index bcec3e3..394145a 100644
--- a/lucene/src/java/org/apache/lucene/search/TermRangeQuery.java
+++ b/lucene/src/java/org/apache/lucene/search/TermRangeQuery.java
@@ -135,8 +135,8 @@ public class TermRangeQuery extends MultiTermQuery {
       return TermsEnum.EMPTY;
     }
     if ((lowerTerm == null || (collator == null && includeLower && "".equals(lowerTerm))) && upperTerm == null) {
-      // NOTE: debateably, the caller should never pass in a
-      // multi reader...
+      // NOTE: for now, MultiTermQuery enums terms at the
+      // MultiReader level, so we must use MultiFields here:
       final Terms terms = MultiFields.getTerms(reader, field);
       return (terms != null) ? terms.iterator() : null;
     }
diff --git a/lucene/src/java/org/apache/lucene/search/spans/SpanTermQuery.java b/lucene/src/java/org/apache/lucene/search/spans/SpanTermQuery.java
index 9d69561..a016e3d 100644
--- a/lucene/src/java/org/apache/lucene/search/spans/SpanTermQuery.java
+++ b/lucene/src/java/org/apache/lucene/search/spans/SpanTermQuery.java
@@ -20,8 +20,6 @@ package org.apache.lucene.search.spans;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.index.DocsAndPositionsEnum;
-import org.apache.lucene.index.MultiFields;
-import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.ToStringUtils;
 
 import java.io.IOException;
@@ -83,17 +81,14 @@ public class SpanTermQuery extends SpanQuery {
 
   @Override
   public Spans getSpans(final IndexReader reader) throws IOException {
-    // NOTE: debateably, the caller should never pass in a
-    // multi reader...
-    final DocsAndPositionsEnum postings = MultiFields.getTermPositionsEnum(reader,
-                                                                           MultiFields.getDeletedDocs(reader),
-                                                                           term.field(),
-                                                                           term.bytes());
+    final DocsAndPositionsEnum postings = reader.termPositionsEnum(reader.getDeletedDocs(),
+                                                                   term.field(),
+                                                                   term.bytes());
 
     if (postings != null) {
       return new TermSpans(postings, term);
     } else {
-      if (MultiFields.getTermDocsEnum(reader, MultiFields.getDeletedDocs(reader), term.field(), term.bytes()) != null) {
+      if (reader.termDocsEnum(reader.getDeletedDocs(), term.field(), term.bytes()) != null) {
         // term does exist, but has no positions
         throw new IllegalStateException("field \"" + term.field() + "\" was indexed with Field.omitTermFreqAndPositions=true; cannot run SpanTermQuery (term=" + term.text() + ")");
       } else {
diff --git a/lucene/src/java/org/apache/lucene/util/ReaderUtil.java b/lucene/src/java/org/apache/lucene/util/ReaderUtil.java
index f6e677b..7d971e9 100644
--- a/lucene/src/java/org/apache/lucene/util/ReaderUtil.java
+++ b/lucene/src/java/org/apache/lucene/util/ReaderUtil.java
@@ -62,7 +62,7 @@ public class ReaderUtil {
     try {
       new Gather(reader) {
         @Override
-          protected void add(int base, IndexReader r) {
+        protected void add(int base, IndexReader r) {
           allSubReaders.add(r);
         }
       }.run();
diff --git a/lucene/src/test/org/apache/lucene/index/RandomIndexWriter.java b/lucene/src/test/org/apache/lucene/index/RandomIndexWriter.java
index 9c9fe81..fa3e855 100644
--- a/lucene/src/test/org/apache/lucene/index/RandomIndexWriter.java
+++ b/lucene/src/test/org/apache/lucene/index/RandomIndexWriter.java
@@ -90,6 +90,9 @@ public class RandomIndexWriter implements Closeable {
   public void addDocument(Document doc) throws IOException {
     w.addDocument(doc);
     if (docCount++ == flushAt) {
+      if (LuceneTestCaseJ4.VERBOSE) {
+        System.out.println("RIW.addDocument: now doing a commit");
+      }
       w.commit();
       flushAt += _TestUtil.nextInt(r, 10, 1000);
     }
diff --git a/lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter.java b/lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter.java
index 33355dd..fda343b 100644
--- a/lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter.java
+++ b/lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter.java
@@ -17,27 +17,33 @@ package org.apache.lucene.search;
  * limitations under the License.
  */
 
+import java.util.Random;
 import java.io.IOException;
 
-import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.IndexWriterConfig;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
+import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.index.SlowMultiReaderWrapper;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.MockRAMDirectory;
-import org.apache.lucene.store.MockRAMDirectory;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.OpenBitSet;
 import org.apache.lucene.util.OpenBitSetDISI;
 
 public class TestCachingWrapperFilter extends LuceneTestCase {
+  Random rand;
+
+  @Override
+  public void setUp() throws Exception {
+    super.setUp();
+    rand = newRandom();
+  }
+
   public void testCachingWorks() throws Exception {
     Directory dir = new MockRAMDirectory();
-    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(
-        TEST_VERSION_CURRENT, new MockAnalyzer()));
+    RandomIndexWriter writer = new RandomIndexWriter(rand, dir);
     writer.close();
 
     IndexReader reader = IndexReader.open(dir, true);
@@ -62,8 +68,7 @@ public class TestCachingWrapperFilter extends LuceneTestCase {
   
   public void testNullDocIdSet() throws Exception {
     Directory dir = new MockRAMDirectory();
-    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(
-        TEST_VERSION_CURRENT, new MockAnalyzer()));
+    RandomIndexWriter writer = new RandomIndexWriter(rand, dir);
     writer.close();
 
     IndexReader reader = IndexReader.open(dir, true);
@@ -84,8 +89,7 @@ public class TestCachingWrapperFilter extends LuceneTestCase {
   
   public void testNullDocIdSetIterator() throws Exception {
     Directory dir = new MockRAMDirectory();
-    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(
-        TEST_VERSION_CURRENT, new MockAnalyzer()));
+    RandomIndexWriter writer = new RandomIndexWriter(rand, dir);
     writer.close();
 
     IndexReader reader = IndexReader.open(dir, true);
@@ -125,19 +129,21 @@ public class TestCachingWrapperFilter extends LuceneTestCase {
   
   public void testIsCacheAble() throws Exception {
     Directory dir = new MockRAMDirectory();
-    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
+    RandomIndexWriter writer = new RandomIndexWriter(rand, dir);
+    writer.addDocument(new Document());
     writer.close();
 
     IndexReader reader = IndexReader.open(dir, true);
+    IndexReader slowReader = SlowMultiReaderWrapper.wrap(reader);
 
     // not cacheable:
-    assertDocIdSetCacheable(reader, new QueryWrapperFilter(new TermQuery(new Term("test","value"))), false);
+    assertDocIdSetCacheable(slowReader, new QueryWrapperFilter(new TermQuery(new Term("test","value"))), false);
     // returns default empty docidset, always cacheable:
-    assertDocIdSetCacheable(reader, NumericRangeFilter.newIntRange("test", Integer.valueOf(10000), Integer.valueOf(-10000), true, true), true);
+    assertDocIdSetCacheable(slowReader, NumericRangeFilter.newIntRange("test", Integer.valueOf(10000), Integer.valueOf(-10000), true, true), true);
     // is cacheable:
-    assertDocIdSetCacheable(reader, FieldCacheRangeFilter.newIntRange("test", Integer.valueOf(10), Integer.valueOf(20), true, true), true);
+    assertDocIdSetCacheable(slowReader, FieldCacheRangeFilter.newIntRange("test", Integer.valueOf(10), Integer.valueOf(20), true, true), true);
     // a openbitset filter is always cacheable
-    assertDocIdSetCacheable(reader, new Filter() {
+    assertDocIdSetCacheable(slowReader, new Filter() {
       @Override
       public DocIdSet getDocIdSet(IndexReader reader) {
         return new OpenBitSet();
@@ -149,8 +155,13 @@ public class TestCachingWrapperFilter extends LuceneTestCase {
 
   public void testEnforceDeletions() throws Exception {
     Directory dir = new MockRAMDirectory();
-    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
-    IndexReader reader = writer.getReader();
+    RandomIndexWriter writer = new RandomIndexWriter(rand, dir);
+
+    // NOTE: cannot use writer.getReader because RIW (on
+    // flipping a coin) may give us a newly opened reader,
+    // but we use .reopen on this reader below and expect to
+    // (must) get an NRT reader:
+    IndexReader reader = writer.w.getReader();
     IndexSearcher searcher = new IndexSearcher(reader);
 
     // add a doc, refresh the reader, and check that its there
diff --git a/lucene/src/test/org/apache/lucene/search/TestDisjunctionMaxQuery.java b/lucene/src/test/org/apache/lucene/search/TestDisjunctionMaxQuery.java
index 3605877..7c2ce15 100644
--- a/lucene/src/test/org/apache/lucene/search/TestDisjunctionMaxQuery.java
+++ b/lucene/src/test/org/apache/lucene/search/TestDisjunctionMaxQuery.java
@@ -22,6 +22,7 @@ import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.SlowMultiReaderWrapper;
 import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.store.Directory;
@@ -147,7 +148,7 @@ public class TestDisjunctionMaxQuery extends LuceneTestCase {
     
     r = writer.getReader();
     writer.close();
-    s = new IndexSearcher(r);
+    s = new IndexSearcher(SlowMultiReaderWrapper.wrap(r));
     s.setSimilarity(sim);
   }
   
@@ -167,7 +168,7 @@ public class TestDisjunctionMaxQuery extends LuceneTestCase {
     QueryUtils.check(dq, s);
     
     final Weight dw = dq.weight(s);
-    final Scorer ds = dw.scorer(r, true, false);
+    final Scorer ds = dw.scorer(s.getIndexReader(), true, false);
     final boolean skipOk = ds.advance(3) != DocIdSetIterator.NO_MORE_DOCS;
     if (skipOk) {
       fail("firsttime skipTo found a match? ... "
@@ -183,7 +184,7 @@ public class TestDisjunctionMaxQuery extends LuceneTestCase {
     QueryUtils.check(dq, s);
     
     final Weight dw = dq.weight(s);
-    final Scorer ds = dw.scorer(r, true, false);
+    final Scorer ds = dw.scorer(s.getIndexReader(), true, false);
     assertTrue("firsttime skipTo found no match",
         ds.advance(3) != DocIdSetIterator.NO_MORE_DOCS);
     assertEquals("found wrong docid", "d4", r.document(ds.docID()).get("id"));
diff --git a/lucene/src/test/org/apache/lucene/search/TestPositionIncrement.java b/lucene/src/test/org/apache/lucene/search/TestPositionIncrement.java
index 9a63286..738d3df 100644
--- a/lucene/src/test/org/apache/lucene/search/TestPositionIncrement.java
+++ b/lucene/src/test/org/apache/lucene/search/TestPositionIncrement.java
@@ -36,6 +36,7 @@ import org.apache.lucene.index.MultiFields;
 import org.apache.lucene.index.DocsAndPositionsEnum;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.index.SlowMultiReaderWrapper;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.queryParser.QueryParser;
 import org.apache.lucene.store.MockRAMDirectory;
@@ -266,7 +267,7 @@ public class TestPositionIncrement extends LuceneTestCase {
     // only one doc has "a"
     assertEquals(tp.NO_MORE_DOCS, tp.nextDoc());
 
-    IndexSearcher is = new IndexSearcher(r);
+    IndexSearcher is = new IndexSearcher(SlowMultiReaderWrapper.wrap(r));
   
     SpanTermQuery stq1 = new SpanTermQuery(new Term("content", "a"));
     SpanTermQuery stq2 = new SpanTermQuery(new Term("content", "k"));
diff --git a/lucene/src/test/org/apache/lucene/search/TestSpanQueryFilter.java b/lucene/src/test/org/apache/lucene/search/TestSpanQueryFilter.java
index 1485366..2e81004 100644
--- a/lucene/src/test/org/apache/lucene/search/TestSpanQueryFilter.java
+++ b/lucene/src/test/org/apache/lucene/search/TestSpanQueryFilter.java
@@ -22,6 +22,7 @@ import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.index.SlowMultiReaderWrapper;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.spans.SpanTermQuery;
 import org.apache.lucene.store.Directory;
@@ -50,7 +51,7 @@ public class TestSpanQueryFilter extends LuceneTestCase {
 
     SpanTermQuery query = new SpanTermQuery(new Term("field", English.intToEnglish(10).trim()));
     SpanQueryFilter filter = new SpanQueryFilter(query);
-    SpanFilterResult result = filter.bitSpans(reader);
+    SpanFilterResult result = filter.bitSpans(SlowMultiReaderWrapper.wrap(reader));
     DocIdSet docIdSet = result.getDocIdSet();
     assertTrue("docIdSet is null and it shouldn't be", docIdSet != null);
     assertContainsDocId("docIdSet doesn't contain docId 10", docIdSet, 10);
diff --git a/lucene/src/test/org/apache/lucene/search/TestTermScorer.java b/lucene/src/test/org/apache/lucene/search/TestTermScorer.java
index 9d03ee7..aef5c62 100644
--- a/lucene/src/test/org/apache/lucene/search/TestTermScorer.java
+++ b/lucene/src/test/org/apache/lucene/search/TestTermScorer.java
@@ -27,6 +27,7 @@ import org.apache.lucene.document.Field;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.index.Term;
+import org.apache.lucene.index.SlowMultiReaderWrapper;
 import org.apache.lucene.store.MockRAMDirectory;
 
 public class TestTermScorer extends LuceneTestCase {
@@ -57,7 +58,7 @@ public class TestTermScorer extends LuceneTestCase {
     }
     indexReader = writer.getReader();
     writer.close();
-    indexSearcher = new IndexSearcher(indexReader);
+    indexSearcher = new IndexSearcher(SlowMultiReaderWrapper.wrap(indexReader));
   }
   
   @Override
diff --git a/lucene/src/test/org/apache/lucene/search/payloads/PayloadHelper.java b/lucene/src/test/org/apache/lucene/search/payloads/PayloadHelper.java
index 043f0ce..4a4e7fa 100644
--- a/lucene/src/test/org/apache/lucene/search/payloads/PayloadHelper.java
+++ b/lucene/src/test/org/apache/lucene/search/payloads/PayloadHelper.java
@@ -26,6 +26,8 @@ import org.apache.lucene.store.MockRAMDirectory;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.util.English;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.SlowMultiReaderWrapper;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Similarity;
 import static org.apache.lucene.util.LuceneTestCaseJ4.TEST_VERSION_CURRENT;
@@ -46,6 +48,8 @@ public class PayloadHelper {
   public static final String MULTI_FIELD = "multiField";
   public static final String FIELD = "field";
 
+  public IndexReader reader;
+
   public final class PayloadAnalyzer extends Analyzer {
 
 
@@ -106,6 +110,8 @@ public class PayloadHelper {
   public IndexSearcher setUp(Similarity similarity, int numDocs) throws IOException {
     MockRAMDirectory directory = new MockRAMDirectory();
     PayloadAnalyzer analyzer = new PayloadAnalyzer();
+
+    // TODO randomize this
     IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(
         TEST_VERSION_CURRENT, analyzer).setSimilarity(similarity));
     // writer.infoStream = System.out;
@@ -116,11 +122,15 @@ public class PayloadHelper {
       doc.add(new Field(NO_PAYLOAD_FIELD, English.intToEnglish(i), Field.Store.YES, Field.Index.ANALYZED));
       writer.addDocument(doc);
     }
-    //writer.optimize();
+    reader = writer.getReader();
     writer.close();
 
-    IndexSearcher searcher = new IndexSearcher(directory, true);
+    IndexSearcher searcher = new IndexSearcher(SlowMultiReaderWrapper.wrap(reader));
     searcher.setSimilarity(similarity);
     return searcher;
   }
+
+  public void tearDown() throws Exception {
+    reader.close();
+  }
 }
diff --git a/lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery.java b/lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery.java
index 6ec19e5..9964daf 100644
--- a/lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery.java
+++ b/lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery.java
@@ -35,10 +35,10 @@ import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.TokenFilter;
 import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;
 import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.IndexWriterConfig;
 import org.apache.lucene.index.Payload;
 import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.index.Term;
+import org.apache.lucene.index.SlowMultiReaderWrapper;
 import org.apache.lucene.store.MockRAMDirectory;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
@@ -130,7 +130,7 @@ public class TestPayloadTermQuery extends LuceneTestCase {
     reader = writer.getReader();
     writer.close();
 
-    searcher = new IndexSearcher(reader);
+    searcher = new IndexSearcher(SlowMultiReaderWrapper.wrap(reader));
     searcher.setSimilarity(similarity);
   }
 
diff --git a/lucene/src/test/org/apache/lucene/search/spans/TestBasics.java b/lucene/src/test/org/apache/lucene/search/spans/TestBasics.java
index 0e07958..19b9dce 100644
--- a/lucene/src/test/org/apache/lucene/search/spans/TestBasics.java
+++ b/lucene/src/test/org/apache/lucene/search/spans/TestBasics.java
@@ -25,6 +25,7 @@ import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.index.SlowMultiReaderWrapper;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.BooleanClause;
 import org.apache.lucene.search.BooleanQuery;
@@ -69,7 +70,7 @@ public class TestBasics extends LuceneTestCase {
       writer.addDocument(doc);
     }
     reader = writer.getReader();
-    searcher = new IndexSearcher(reader);
+    searcher = new IndexSearcher(SlowMultiReaderWrapper.wrap(reader));
     writer.close();
   }
 
diff --git a/lucene/src/test/org/apache/lucene/search/spans/TestFieldMaskingSpanQuery.java b/lucene/src/test/org/apache/lucene/search/spans/TestFieldMaskingSpanQuery.java
index 2c7018d..b355f52 100644
--- a/lucene/src/test/org/apache/lucene/search/spans/TestFieldMaskingSpanQuery.java
+++ b/lucene/src/test/org/apache/lucene/search/spans/TestFieldMaskingSpanQuery.java
@@ -24,6 +24,7 @@ import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.index.SlowMultiReaderWrapper;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.CheckHits;
 import org.apache.lucene.search.IndexSearcher;
@@ -112,7 +113,7 @@ public class TestFieldMaskingSpanQuery extends LuceneTestCase {
                                          field("last",   "jones")     }));
     reader = writer.getReader();
     writer.close();
-    searcher = new IndexSearcher(reader);
+    searcher = new IndexSearcher(SlowMultiReaderWrapper.wrap(reader));
   }
 
   @Override
diff --git a/lucene/src/test/org/apache/lucene/search/spans/TestNearSpansOrdered.java b/lucene/src/test/org/apache/lucene/search/spans/TestNearSpansOrdered.java
index a5dfdb0..e053ea2 100644
--- a/lucene/src/test/org/apache/lucene/search/spans/TestNearSpansOrdered.java
+++ b/lucene/src/test/org/apache/lucene/search/spans/TestNearSpansOrdered.java
@@ -21,6 +21,7 @@ import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.SlowMultiReaderWrapper;
 import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.queryParser.QueryParser;
@@ -62,7 +63,7 @@ public class TestNearSpansOrdered extends LuceneTestCase {
     }
     reader = writer.getReader();
     writer.close();
-    searcher = new IndexSearcher(reader);
+    searcher = new IndexSearcher(SlowMultiReaderWrapper.wrap(reader));
   }
 
   protected String[] docFields = {
diff --git a/lucene/src/test/org/apache/lucene/search/spans/TestPayloadSpans.java b/lucene/src/test/org/apache/lucene/search/spans/TestPayloadSpans.java
index 34c8e66..e68375d 100644
--- a/lucene/src/test/org/apache/lucene/search/spans/TestPayloadSpans.java
+++ b/lucene/src/test/org/apache/lucene/search/spans/TestPayloadSpans.java
@@ -22,9 +22,9 @@ import java.io.StringReader;
 import java.util.Collection;
 import java.util.HashSet;
 import java.util.Set;
+import java.util.Random;
 
 import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.analysis.MockTokenizer;
 import org.apache.lucene.analysis.TokenFilter;
 import org.apache.lucene.analysis.TokenStream;
@@ -34,9 +34,9 @@ import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.index.CorruptIndexException;
+import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.IndexWriterConfig;
+import org.apache.lucene.index.SlowMultiReaderWrapper;
 import org.apache.lucene.index.Payload;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.DefaultSimilarity;
@@ -54,6 +54,8 @@ public class TestPayloadSpans extends LuceneTestCase {
   private IndexSearcher searcher;
   private Similarity similarity = new DefaultSimilarity();
   protected IndexReader indexReader;
+  private IndexReader closeIndexReader;
+  private Random rand;
 
   public TestPayloadSpans(String s) {
     super(s);
@@ -62,6 +64,7 @@ public class TestPayloadSpans extends LuceneTestCase {
   @Override
   protected void setUp() throws Exception {
     super.setUp();
+    rand = newRandom();
     PayloadHelper helper = new PayloadHelper();
     searcher = helper.setUp(similarity, 1000);
     indexReader = searcher.getIndexReader();
@@ -109,27 +112,22 @@ public class TestPayloadSpans extends LuceneTestCase {
     clauses[1] = new SpanTermQuery(new Term(PayloadHelper.FIELD, "three"));
     SpanQuery spq = new SpanNearQuery(clauses, 5, true);
     SpanNotQuery snq = new SpanNotQuery(spq, new SpanTermQuery(new Term(PayloadHelper.FIELD, "two")));
-    checkSpans(snq.getSpans(getSpanNotSearcher().getIndexReader()), 1,new int[]{2});
-  }
-  
-  public IndexSearcher getSpanNotSearcher()
-      throws IOException {
+
+
+
     MockRAMDirectory directory = new MockRAMDirectory();
-    IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(
-        TEST_VERSION_CURRENT, new PayloadAnalyzer()).setSimilarity(
-        similarity));
+    RandomIndexWriter writer = new RandomIndexWriter(rand, directory,
+                                                     newIndexWriterConfig(rand, TEST_VERSION_CURRENT, new PayloadAnalyzer()).setSimilarity(similarity));
 
     Document doc = new Document();
     doc.add(new Field(PayloadHelper.FIELD, "one two three one four three",
         Field.Store.YES, Field.Index.ANALYZED));
     writer.addDocument(doc);
-
+    IndexReader reader = writer.getReader();
     writer.close();
 
-    IndexSearcher searcher = new IndexSearcher(directory, true);
-    searcher.setSimilarity(similarity);
-    return searcher;
-
+    checkSpans(snq.getSpans(SlowMultiReaderWrapper.wrap(reader)), 1,new int[]{2});
+    reader.close();
   }
   
   public void testNestedSpans() throws Exception {
@@ -185,6 +183,7 @@ public class TestPayloadSpans extends LuceneTestCase {
     spans = nestedSpanNearQuery.getSpans(searcher.getIndexReader());
     assertTrue("spans is null and it shouldn't be", spans != null);
     checkSpans(spans, 2, new int[]{3,3});
+    closeIndexReader.close();
   }
   
   public void testFirstClauseWithoutPayload() throws Exception {
@@ -215,6 +214,7 @@ public class TestPayloadSpans extends LuceneTestCase {
     spans = nestedSpanNearQuery.getSpans(searcher.getIndexReader());
     assertTrue("spans is null and it shouldn't be", spans != null);
     checkSpans(spans, 1, new int[]{3});
+    closeIndexReader.close();
   }
   
   public void testHeavilyNestedSpanQuery() throws Exception {
@@ -250,19 +250,22 @@ public class TestPayloadSpans extends LuceneTestCase {
     spans = nestedSpanNearQuery.getSpans(searcher.getIndexReader());
     assertTrue("spans is null and it shouldn't be", spans != null);
     checkSpans(spans, 2, new int[]{8, 8});
+    closeIndexReader.close();
   }
   
   public void testShrinkToAfterShortestMatch() throws CorruptIndexException,
       LockObtainFailedException, IOException {
     MockRAMDirectory directory = new MockRAMDirectory();
-    IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(
-        TEST_VERSION_CURRENT, new TestPayloadAnalyzer()));
+    RandomIndexWriter writer = new RandomIndexWriter(rand, directory,
+                                                     newIndexWriterConfig(rand, TEST_VERSION_CURRENT, new TestPayloadAnalyzer()));
+
     Document doc = new Document();
     doc.add(new Field("content", new StringReader("a b c d e f g h i j a k")));
     writer.addDocument(doc);
-    writer.close();
 
-    IndexSearcher is = new IndexSearcher(directory, true);
+    IndexReader reader = writer.getReader();
+    IndexSearcher is = new IndexSearcher(SlowMultiReaderWrapper.wrap(reader));
+    writer.close();
 
     SpanTermQuery stq1 = new SpanTermQuery(new Term("content", "a"));
     SpanTermQuery stq2 = new SpanTermQuery(new Term("content", "k"));
@@ -284,20 +287,22 @@ public class TestPayloadSpans extends LuceneTestCase {
     assertEquals(2, payloadSet.size());
     assertTrue(payloadSet.contains("a:Noise:10"));
     assertTrue(payloadSet.contains("k:Noise:11"));
+    reader.close();
   }
   
   public void testShrinkToAfterShortestMatch2() throws CorruptIndexException,
       LockObtainFailedException, IOException {
     MockRAMDirectory directory = new MockRAMDirectory();
-    IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(
-        TEST_VERSION_CURRENT, new TestPayloadAnalyzer()));
+    RandomIndexWriter writer = new RandomIndexWriter(rand, directory,
+                                                     newIndexWriterConfig(rand, TEST_VERSION_CURRENT, new TestPayloadAnalyzer()));
+
     Document doc = new Document();
     doc.add(new Field("content", new StringReader("a b a d k f a h i k a k")));
     writer.addDocument(doc);
+    IndexReader reader = writer.getReader();
+    IndexSearcher is = new IndexSearcher(SlowMultiReaderWrapper.wrap(reader));
     writer.close();
 
-    IndexSearcher is = new IndexSearcher(directory, true);
-
     SpanTermQuery stq1 = new SpanTermQuery(new Term("content", "a"));
     SpanTermQuery stq2 = new SpanTermQuery(new Term("content", "k"));
     SpanQuery[] sqs = { stq1, stq2 };
@@ -317,20 +322,22 @@ public class TestPayloadSpans extends LuceneTestCase {
     assertEquals(2, payloadSet.size());
     assertTrue(payloadSet.contains("a:Noise:10"));
     assertTrue(payloadSet.contains("k:Noise:11"));
+    reader.close();
   }
   
   public void testShrinkToAfterShortestMatch3() throws CorruptIndexException,
       LockObtainFailedException, IOException {
     MockRAMDirectory directory = new MockRAMDirectory();
-    IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(
-        TEST_VERSION_CURRENT, new TestPayloadAnalyzer()));
+    RandomIndexWriter writer = new RandomIndexWriter(rand, directory,
+                                                     newIndexWriterConfig(rand, TEST_VERSION_CURRENT, new TestPayloadAnalyzer()));
+
     Document doc = new Document();
     doc.add(new Field("content", new StringReader("j k a l f k k p a t a k l k t a")));
     writer.addDocument(doc);
+    IndexReader reader = writer.getReader();
+    IndexSearcher is = new IndexSearcher(SlowMultiReaderWrapper.wrap(reader));
     writer.close();
 
-    IndexSearcher is = new IndexSearcher(directory, true);
-
     SpanTermQuery stq1 = new SpanTermQuery(new Term("content", "a"));
     SpanTermQuery stq2 = new SpanTermQuery(new Term("content", "k"));
     SpanQuery[] sqs = { stq1, stq2 };
@@ -356,23 +363,23 @@ public class TestPayloadSpans extends LuceneTestCase {
     }
     assertTrue(payloadSet.contains("a:Noise:10"));
     assertTrue(payloadSet.contains("k:Noise:11"));
+    reader.close();
   }
   
   public void testPayloadSpanUtil() throws Exception {
     MockRAMDirectory directory = new MockRAMDirectory();
-    IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(
-        TEST_VERSION_CURRENT, new PayloadAnalyzer()).setSimilarity(
-        similarity));
+    RandomIndexWriter writer = new RandomIndexWriter(rand, directory,
+                                                     newIndexWriterConfig(rand, TEST_VERSION_CURRENT, new PayloadAnalyzer()).setSimilarity(similarity));
+
     Document doc = new Document();
     doc.add(new Field(PayloadHelper.FIELD,"xx rr yy mm  pp", Field.Store.YES, Field.Index.ANALYZED));
     writer.addDocument(doc);
   
+    IndexReader reader = writer.getReader();
     writer.close();
+    IndexSearcher searcher = new IndexSearcher(SlowMultiReaderWrapper.wrap(reader));
 
-    IndexSearcher searcher = new IndexSearcher(directory, true);
-
-    IndexReader reader = searcher.getIndexReader();
-    PayloadSpanUtil psu = new PayloadSpanUtil(reader);
+    PayloadSpanUtil psu = new PayloadSpanUtil(searcher.getIndexReader());
     
     Collection<byte[]> payloads = psu.getPayloadsForQuery(new TermQuery(new Term(PayloadHelper.FIELD, "rr")));
     if(VERBOSE)
@@ -381,7 +388,7 @@ public class TestPayloadSpans extends LuceneTestCase {
       if(VERBOSE)
         System.out.println(new String(bytes));
     }
-    
+    reader.close();
   }
 
   private void checkSpans(Spans spans, int expectedNumSpans, int expectedNumPayloads,
@@ -420,8 +427,8 @@ public class TestPayloadSpans extends LuceneTestCase {
   private IndexSearcher getSearcher() throws Exception {
     MockRAMDirectory directory = new MockRAMDirectory();
     String[] docs = new String[]{"xx rr yy mm  pp","xx yy mm rr pp", "nopayload qq ss pp np", "one two three four five six seven eight nine ten eleven", "nine one two three four five six seven eight eleven ten"};
-    IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(
-        TEST_VERSION_CURRENT, new PayloadAnalyzer()).setSimilarity(similarity));
+    RandomIndexWriter writer = new RandomIndexWriter(rand, directory,
+                                                     newIndexWriterConfig(rand, TEST_VERSION_CURRENT, new PayloadAnalyzer()).setSimilarity(similarity));
 
     Document doc = null;
     for(int i = 0; i < docs.length; i++) {
@@ -431,9 +438,10 @@ public class TestPayloadSpans extends LuceneTestCase {
       writer.addDocument(doc);
     }
 
+    closeIndexReader = writer.getReader();
     writer.close();
 
-    IndexSearcher searcher = new IndexSearcher(directory, true);
+    IndexSearcher searcher = new IndexSearcher(SlowMultiReaderWrapper.wrap(closeIndexReader));
     return searcher;
   }
   
diff --git a/lucene/src/test/org/apache/lucene/search/spans/TestSpans.java b/lucene/src/test/org/apache/lucene/search/spans/TestSpans.java
index 63cbeac..b542f74 100644
--- a/lucene/src/test/org/apache/lucene/search/spans/TestSpans.java
+++ b/lucene/src/test/org/apache/lucene/search/spans/TestSpans.java
@@ -26,12 +26,12 @@ import org.apache.lucene.search.DefaultSimilarity;
 import org.apache.lucene.search.Scorer;
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.search.Searcher;
-import org.apache.lucene.store.MockRAMDirectory;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.MockRAMDirectory;
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.SlowMultiReaderWrapper;
 import org.apache.lucene.index.IndexWriterConfig;
 import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.index.Term;
@@ -197,7 +197,7 @@ public class TestSpans extends LuceneTestCase {
                                 makeSpanTermQuery("t3") },
                               slop,
                               ordered);
-    Spans spans = snq.getSpans(searcher.getIndexReader());
+    Spans spans = snq.getSpans(SlowMultiReaderWrapper.wrap(searcher.getIndexReader()));
 
     assertTrue("first range", spans.next());
     assertEquals("first doc", 11, spans.doc());
@@ -223,7 +223,7 @@ public class TestSpans extends LuceneTestCase {
                                 makeSpanTermQuery("u2") },
                               0,
                               false);
-    Spans spans = snq.getSpans(searcher.getIndexReader());
+    Spans spans = snq.getSpans(SlowMultiReaderWrapper.wrap(searcher.getIndexReader()));
     assertTrue("Does not have next and it should", spans.next());
     assertEquals("doc", 4, spans.doc());
     assertEquals("start", 1, spans.start());
@@ -259,7 +259,7 @@ public class TestSpans extends LuceneTestCase {
                               },
                               1,
                               false);
-    spans = snq.getSpans(searcher.getIndexReader());
+    spans = snq.getSpans(SlowMultiReaderWrapper.wrap(searcher.getIndexReader()));
     assertTrue("Does not have next and it should", spans.next());
     assertEquals("doc", 4, spans.doc());
     assertEquals("start", 0, spans.start());
@@ -317,7 +317,7 @@ public class TestSpans extends LuceneTestCase {
     for (int i = 0; i < terms.length; i++) {
       sqa[i] = makeSpanTermQuery(terms[i]);
     }
-    return (new SpanOrQuery(sqa)).getSpans(searcher.getIndexReader());
+    return (new SpanOrQuery(sqa)).getSpans(SlowMultiReaderWrapper.wrap(searcher.getIndexReader()));
   }
 
   private void tstNextSpans(Spans spans, int doc, int start, int end)
@@ -422,7 +422,7 @@ public class TestSpans extends LuceneTestCase {
       }
     };
 
-    Scorer spanScorer = snq.weight(searcher).scorer(searcher.getIndexReader(), true, false);
+    Scorer spanScorer = snq.weight(searcher).scorer(SlowMultiReaderWrapper.wrap(searcher.getIndexReader()), true, false);
 
     assertTrue("first doc", spanScorer.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
     assertEquals("first doc number", spanScorer.docID(), 11);

