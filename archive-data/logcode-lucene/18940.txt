GitDiffStart: 8861ba2ffda71bab956eb6903b79b71d8593c748 | Fri Oct 30 03:26:44 2009 +0000
diff --git a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer.java b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer.java
index aae0163..cf8a09a 100644
--- a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer.java
+++ b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer.java
@@ -90,6 +90,26 @@ public class TestThaiAnalyzer extends BaseTokenStreamTestCase {
 			new String[] { "à¸?¸£à¸°à?à¸¢à?", "à¸§à?à¸?", "quick", "brown", "fox", "jumped", "over", "lazy", "dogs" });
 	}
 	
+	/*
+	 * Test that position increments are adjusted correctly for stopwords.
+	 */
+	public void testPositionIncrements() throws Exception {
+	  ThaiAnalyzer analyzer = new ThaiAnalyzer(Version.LUCENE_CURRENT);
+
+	  assertAnalyzesTo(analyzer, "à¸?¸£à¸°à?à¸¢à?à¸§à?à¸? the à¸?¸£à¸°à?à¸¢à?à¸§à?à¸?",
+	          new String[] { "à¸?¸£à¸°à?à¸¢à?", "à¸§à?à¸?", "à¸?¸£à¸°à?à¸¢à?", "à¸§à?à¸?" },
+	          new int[] { 0, 6, 14, 20 },
+	          new int[] { 6, 9, 20, 23 },
+	          new int[] { 1, 1, 2, 1 });
+	 
+	  // case that a stopword is adjacent to thai text, with no whitespace
+	  assertAnalyzesTo(analyzer, "à¸?¸£à¸°à?à¸¢à?à¸§à?à¸?heà¸?¸£à¸°à?à¸¢à?à¸§à?à¸?",
+	      new String[] { "à¸?¸£à¸°à?à¸¢à?", "à¸§à?à¸?", "à¸?¸£à¸°à?à¸¢à?", "à¸§à?à¸?" },
+	      new int[] { 0, 6, 12, 18 },
+	      new int[] { 6, 9, 18, 21 },
+	      new int[] { 1, 1, 2, 1 });
+	}
+	
 	public void testReusableTokenStream() throws Exception {
 	  ThaiAnalyzer analyzer = new ThaiAnalyzer(Version.LUCENE_CURRENT);
 	  assertAnalyzesToReuse(analyzer, "", new String[] {});

