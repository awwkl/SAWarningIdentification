GitDiffStart: 1d1331fa033fd7f4d20b3c3443d4a2957b4368fa | Tue May 4 07:50:41 2010 +0000
diff --git a/lucene/contrib/CHANGES.txt b/lucene/contrib/CHANGES.txt
index c6a5c6a..576f587 100644
--- a/lucene/contrib/CHANGES.txt
+++ b/lucene/contrib/CHANGES.txt
@@ -155,6 +155,12 @@ New features
    of AttributeSource.cloneAttributes() instances and the new copyTo() method.
    (Steven Rowe via Uwe Schindler)
 
+ * LUCENE-2413: Consolidated Solr analysis components into contrib/analyzers. 
+   New features from Solr now available to Lucene users include:
+   - o.a.l.analysis.commongrams: Constructs n-grams for frequently occurring terms
+     and phrases. 
+   (... in progress)
+
 Build
 
  * LUCENE-2124: Moved the JDK-based collation support from contrib/collation 
diff --git a/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/commongrams/CommonGramsFilter.java b/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/commongrams/CommonGramsFilter.java
new file mode 100644
index 0000000..ad80606
--- /dev/null
+++ b/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/commongrams/CommonGramsFilter.java
@@ -0,0 +1,270 @@
+/*
+ * Licensed under the Apache License, 
+ * Version 2.0 (the "License"); you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0
+ * Unless required by applicable law or agreed to in writing, software distributed under the License 
+ * is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. 
+ * See the License for the specific language governing permissions and limitations under the License. 
+ */
+
+package org.apache.lucene.analysis.commongrams;
+
+import java.io.IOException;
+import java.util.Arrays;
+import java.util.Set;
+
+import org.apache.lucene.analysis.CharArraySet;
+import org.apache.lucene.analysis.TokenFilter;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
+import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.TypeAttribute;
+import org.apache.lucene.util.Version;
+
+/*
+ * TODO: Consider implementing https://issues.apache.org/jira/browse/LUCENE-1688 changes to stop list and associated constructors 
+ */
+
+/**
+ * Construct bigrams for frequently occurring terms while indexing. Single terms
+ * are still indexed too, with bigrams overlaid. This is achieved through the
+ * use of {@link PositionIncrementAttribute#setPositionIncrement(int)}. Bigrams have a type
+ * of {@link #GRAM_TYPE} Example:
+ * <ul>
+ * <li>input:"the quick brown fox"</li>
+ * <li>output:|"the","the-quick"|"brown"|"fox"|</li>
+ * <li>"the-quick" has a position increment of 0 so it is in the same position
+ * as "the" "the-quick" has a term.type() of "gram"</li>
+ * 
+ * </ul>
+ */
+
+/*
+ * Constructors and makeCommonSet based on similar code in StopFilter
+ */
+public final class CommonGramsFilter extends TokenFilter {
+
+  static final String GRAM_TYPE = "gram";
+  private static final char SEPARATOR = '_';
+
+  private final CharArraySet commonWords;
+
+  private final StringBuilder buffer = new StringBuilder();
+  
+  private final CharTermAttribute termAttribute = addAttribute(CharTermAttribute.class);
+  private final OffsetAttribute offsetAttribute = addAttribute(OffsetAttribute.class);
+  private final TypeAttribute typeAttribute = addAttribute(TypeAttribute.class);
+  private final PositionIncrementAttribute posIncAttribute = addAttribute(PositionIncrementAttribute.class);
+
+  private int lastStartOffset;
+  private boolean lastWasCommon;
+  private State savedState;
+
+  /** @deprecated Use {@link #CommonGramsFilter(Version, TokenStream, Set)} instead */
+  public CommonGramsFilter(TokenStream input, Set<?> commonWords) {
+    this(Version.LUCENE_29, input, commonWords);
+  }
+  
+  /** @deprecated Use {@link #CommonGramsFilter(Version, TokenStream, Set, boolean)} instead */
+  public CommonGramsFilter(TokenStream input, Set<?> commonWords, boolean ignoreCase) {
+    this(Version.LUCENE_29, input, commonWords, ignoreCase);
+  }
+  
+  /**
+   * Construct a token stream filtering the given input using a Set of common
+   * words to create bigrams. Outputs both unigrams with position increment and
+   * bigrams with position increment 0 type=gram where one or both of the words
+   * in a potential bigram are in the set of common words .
+   * 
+   * @param input TokenStream input in filter chain
+   * @param commonWords The set of common words.
+   */
+  public CommonGramsFilter(Version matchVersion, TokenStream input, Set<?> commonWords) {
+    this(matchVersion, input, commonWords, false);
+  }
+
+  /**
+   * Construct a token stream filtering the given input using a Set of common
+   * words to create bigrams, case-sensitive if ignoreCase is false (unless Set
+   * is CharArraySet). If <code>commonWords</code> is an instance of
+   * {@link CharArraySet} (true if <code>makeCommonSet()</code> was used to
+   * construct the set) it will be directly used and <code>ignoreCase</code>
+   * will be ignored since <code>CharArraySet</code> directly controls case
+   * sensitivity.
+   * <p/>
+   * If <code>commonWords</code> is not an instance of {@link CharArraySet}, a
+   * new CharArraySet will be constructed and <code>ignoreCase</code> will be
+   * used to specify the case sensitivity of that set.
+   * 
+   * @param input TokenStream input in filter chain.
+   * @param commonWords The set of common words.
+   * @param ignoreCase -Ignore case when constructing bigrams for common words.
+   */
+  public CommonGramsFilter(Version matchVersion, TokenStream input, Set<?> commonWords, boolean ignoreCase) {
+    super(input);
+    if (commonWords instanceof CharArraySet) {
+      this.commonWords = (CharArraySet) commonWords;
+    } else {
+      this.commonWords = new CharArraySet(matchVersion, commonWords.size(), ignoreCase);
+      this.commonWords.addAll(commonWords);
+    }
+  }
+
+  /**
+   * Construct a token stream filtering the given input using an Array of common
+   * words to create bigrams.
+   * 
+   * @param input Tokenstream in filter chain
+   * @param commonWords words to be used in constructing bigrams
+   * @deprecated Use {@link #CommonGramsFilter(Version, TokenStream, Set)} instead.
+   */
+  @Deprecated
+  public CommonGramsFilter(TokenStream input, String[] commonWords) {
+    this(input, commonWords, false);
+  }
+
+  /**
+   * Construct a token stream filtering the given input using an Array of common
+   * words to create bigrams and is case-sensitive if ignoreCase is false.
+   * 
+   * @param input Tokenstream in filter chain
+   * @param commonWords words to be used in constructing bigrams
+   * @param ignoreCase -Ignore case when constructing bigrams for common words.
+   * @deprecated Use {@link #CommonGramsFilter(Version, TokenStream, Set, boolean)} instead.
+   */
+  @Deprecated
+  public CommonGramsFilter(TokenStream input, String[] commonWords, boolean ignoreCase) {
+    super(input);
+    this.commonWords = makeCommonSet(commonWords, ignoreCase);
+  }
+
+  /**
+   * Build a CharArraySet from an array of common words, appropriate for passing
+   * into the CommonGramsFilter constructor. This permits this commonWords
+   * construction to be cached once when an Analyzer is constructed.
+   *
+   * @param commonWords Array of common words which will be converted into the CharArraySet
+   * @return CharArraySet of the given words, appropriate for passing into the CommonGramFilter constructor
+   * @see #makeCommonSet(java.lang.String[], boolean) passing false to ignoreCase
+   * @deprecated create a CharArraySet with CharArraySet instead
+   */
+  @Deprecated
+  public static CharArraySet makeCommonSet(String[] commonWords) {
+    return makeCommonSet(commonWords, false);
+  }
+
+  /**
+   * Build a CharArraySet from an array of common words, appropriate for passing
+   * into the CommonGramsFilter constructor,case-sensitive if ignoreCase is
+   * false.
+   * 
+   * @param commonWords Array of common words which will be converted into the CharArraySet
+   * @param ignoreCase If true, all words are lower cased first.
+   * @return a Set containing the words
+   * @deprecated create a CharArraySet with CharArraySet instead
+   */
+  @Deprecated
+  public static CharArraySet makeCommonSet(String[] commonWords, boolean ignoreCase) {
+    CharArraySet commonSet = new CharArraySet(commonWords.length, ignoreCase);
+    commonSet.addAll(Arrays.asList(commonWords));
+    return commonSet;
+  }
+
+  /**
+   * Inserts bigrams for common words into a token stream. For each input token,
+   * output the token. If the token and/or the following token are in the list
+   * of common words also output a bigram with position increment 0 and
+   * type="gram"
+   *
+   * TODO:Consider adding an option to not emit unigram stopwords
+   * as in CDL XTF BigramStopFilter, CommonGramsQueryFilter would need to be
+   * changed to work with this.
+   *
+   * TODO: Consider optimizing for the case of three
+   * commongrams i.e "man of the year" normally produces 3 bigrams: "man-of",
+   * "of-the", "the-year" but with proper management of positions we could
+   * eliminate the middle bigram "of-the"and save a disk seek and a whole set of
+   * position lookups.
+   */
+  public boolean incrementToken() throws IOException {
+    // get the next piece of input
+    if (savedState != null) {
+      restoreState(savedState);
+      savedState = null;
+      saveTermBuffer();
+      return true;
+    } else if (!input.incrementToken()) {
+        return false;
+    }
+    
+    /* We build n-grams before and after stopwords. 
+     * When valid, the buffer always contains at least the separator.
+     * If its empty, there is nothing before this stopword.
+     */
+    if (lastWasCommon || (isCommon() && buffer.length() > 0)) {
+      savedState = captureState();
+      gramToken();
+      return true;      
+    }
+
+    saveTermBuffer();
+    return true;
+  }
+
+  /**
+   * {@inheritDoc}
+   */
+  @Override
+  public void reset() throws IOException {
+    super.reset();
+    lastWasCommon = false;
+    savedState = null;
+    buffer.setLength(0);
+  }
+
+  // ================================================= Helper Methods ================================================
+
+  /**
+   * Determines if the current token is a common term
+   *
+   * @return {@code true} if the current token is a common term, {@code false} otherwise
+   */
+  private boolean isCommon() {
+    return commonWords != null && commonWords.contains(termAttribute.buffer(), 0, termAttribute.length());
+  }
+
+  /**
+   * Saves this information to form the left part of a gram
+   */
+  private void saveTermBuffer() {
+    buffer.setLength(0);
+    buffer.append(termAttribute.buffer(), 0, termAttribute.length());
+    buffer.append(SEPARATOR);
+    lastStartOffset = offsetAttribute.startOffset();
+    lastWasCommon = isCommon();
+  }
+
+  /**
+   * Constructs a compound token.
+   */
+  private void gramToken() {
+    buffer.append(termAttribute.buffer(), 0, termAttribute.length());
+    int endOffset = offsetAttribute.endOffset();
+
+    clearAttributes();
+
+    int length = buffer.length();
+    char termText[] = termAttribute.buffer();
+    if (length > termText.length) {
+      termText = termAttribute.resizeBuffer(length);
+    }
+    
+    buffer.getChars(0, length, termText, 0);
+    termAttribute.setLength(length);
+    posIncAttribute.setPositionIncrement(0);
+    offsetAttribute.setOffset(lastStartOffset, endOffset);
+    typeAttribute.setType(GRAM_TYPE);
+    buffer.setLength(0);
+  }
+}
diff --git a/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/commongrams/CommonGramsQueryFilter.java b/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/commongrams/CommonGramsQueryFilter.java
new file mode 100644
index 0000000..9a3f080
--- /dev/null
+++ b/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/commongrams/CommonGramsQueryFilter.java
@@ -0,0 +1,120 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.lucene.analysis.commongrams;
+
+import java.io.IOException;
+
+import org.apache.lucene.analysis.TokenFilter;
+import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
+import org.apache.lucene.analysis.tokenattributes.TypeAttribute;
+
+import static org.apache.lucene.analysis.commongrams.CommonGramsFilter.GRAM_TYPE;
+
+/**
+ * Wrap a CommonGramsFilter optimizing phrase queries by only returning single
+ * words when they are not a member of a bigram.
+ * 
+ * Example:
+ * <ul>
+ * <li>query input to CommonGramsFilter: "the rain in spain falls mainly"
+ * <li>output of CommomGramsFilter/input to CommonGramsQueryFilter:
+ * |"the, "the-rain"|"rain" "rain-in"|"in, "in-spain"|"spain"|"falls"|"mainly"
+ * <li>output of CommonGramsQueryFilter:"the-rain", "rain-in" ,"in-spain",
+ * "falls", "mainly"
+ * </ul>
+ */
+
+/*
+ * See:http://hudson.zones.apache.org/hudson/job/Lucene-trunk/javadoc//all/org/apache/lucene/analysis/TokenStream.html and
+ * http://svn.apache.org/viewvc/lucene/dev/trunk/lucene/src/java/org/apache/lucene/analysis/package.html?revision=718798
+ */
+public final class CommonGramsQueryFilter extends TokenFilter {
+
+  private final TypeAttribute typeAttribute = addAttribute(TypeAttribute.class);
+  private final PositionIncrementAttribute posIncAttribute = addAttribute(PositionIncrementAttribute.class);
+  
+  private State previous;
+  private String previousType;
+
+  /**
+   * Constructs a new CommonGramsQueryFilter based on the provided CommomGramsFilter 
+   * 
+   * @param input CommonGramsFilter the QueryFilter will use
+   */
+  public CommonGramsQueryFilter(CommonGramsFilter input) {
+    super(input);
+  }
+
+  /**
+   * {@inheritDoc}
+   */
+  public void reset() throws IOException {
+    super.reset();
+    previous = null;
+    previousType = null;
+  }
+  
+  /**
+   * Output bigrams whenever possible to optimize queries. Only output unigrams
+   * when they are not a member of a bigram. Example:
+   * <ul>
+   * <li>input: "the rain in spain falls mainly"
+   * <li>output:"the-rain", "rain-in" ,"in-spain", "falls", "mainly"
+   * </ul>
+   */
+  public boolean incrementToken() throws IOException {
+    while (input.incrementToken()) {
+      State current = captureState();
+
+      if (previous != null && !isGramType()) {
+        restoreState(previous);
+        previous = current;
+        previousType = typeAttribute.type();
+        
+        if (isGramType()) {
+          posIncAttribute.setPositionIncrement(1);
+        }
+        return true;
+      }
+
+      previous = current;
+    }
+
+    if (previous == null || GRAM_TYPE.equals(previousType)) {
+      return false;
+    }
+    
+    restoreState(previous);
+    previous = null;
+    
+    if (isGramType()) {
+      posIncAttribute.setPositionIncrement(1);
+    }
+    return true;
+  }
+
+  // ================================================= Helper Methods ================================================
+
+  /**
+   * Convenience method to check if the current type is a gram type
+   * 
+   * @return {@code true} if the current type is a gram type, {@code false} otherwise
+   */
+  public boolean isGramType() {
+    return GRAM_TYPE.equals(typeAttribute.type());
+  }
+}
diff --git a/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/commongrams/package.html b/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/commongrams/package.html
new file mode 100644
index 0000000..a729d58
--- /dev/null
+++ b/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/commongrams/package.html
@@ -0,0 +1,22 @@
+<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+<html><head></head>
+<body>
+Construct n-grams for frequently occurring terms and phrases.
+</body>
+</html>
diff --git a/lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/commongrams/CommonGramsFilterTest.java b/lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/commongrams/CommonGramsFilterTest.java
new file mode 100644
index 0000000..dc7d0b3
--- /dev/null
+++ b/lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/commongrams/CommonGramsFilterTest.java
@@ -0,0 +1,309 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.lucene.analysis.commongrams;
+
+import java.io.Reader;
+import java.io.StringReader;
+import java.util.Set;
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.TokenFilter;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.WhitespaceTokenizer;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+
+/**
+ * Tests CommonGrams(Query)Filter
+ */
+public class CommonGramsFilterTest extends BaseTokenStreamTestCase {
+  private static final String[] commonWords = { "s", "a", "b", "c", "d", "the",
+      "of" };
+  
+  public void testReset() throws Exception {
+    final String input = "How the s a brown s cow d like A B thing?";
+    WhitespaceTokenizer wt = new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader(input));
+    CommonGramsFilter cgf = new CommonGramsFilter(wt, commonWords);
+    
+    CharTermAttribute term = cgf.addAttribute(CharTermAttribute.class);
+    assertTrue(cgf.incrementToken());
+    assertEquals("How", term.toString());
+    assertTrue(cgf.incrementToken());
+    assertEquals("How_the", term.toString());
+    assertTrue(cgf.incrementToken());
+    assertEquals("the", term.toString());
+    assertTrue(cgf.incrementToken());
+    assertEquals("the_s", term.toString());
+    
+    wt.reset(new StringReader(input));
+    cgf.reset();
+    assertTrue(cgf.incrementToken());
+    assertEquals("How", term.toString());
+  }
+  
+  public void testQueryReset() throws Exception {
+    final String input = "How the s a brown s cow d like A B thing?";
+    WhitespaceTokenizer wt = new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader(input));
+    CommonGramsFilter cgf = new CommonGramsFilter(wt, commonWords);
+    CommonGramsQueryFilter nsf = new CommonGramsQueryFilter(cgf);
+    
+    CharTermAttribute term = wt.addAttribute(CharTermAttribute.class);
+    assertTrue(nsf.incrementToken());
+    assertEquals("How_the", term.toString());
+    assertTrue(nsf.incrementToken());
+    assertEquals("the_s", term.toString());
+    
+    wt.reset(new StringReader(input));
+    nsf.reset();
+    assertTrue(nsf.incrementToken());
+    assertEquals("How_the", term.toString());
+  }
+  
+  /**
+   * This is for testing CommonGramsQueryFilter which outputs a set of tokens
+   * optimized for querying with only one token at each position, either a
+   * unigram or a bigram It also will not return a token for the final position
+   * if the final word is already in the preceding bigram Example:(three
+   * tokens/positions in)
+   * "foo bar the"=>"foo:1|bar:2,bar-the:2|the:3=> "foo" "bar-the" (2 tokens
+   * out)
+   * 
+   * @return Map<String,String>
+   */
+  public void testCommonGramsQueryFilter() throws Exception {
+    Analyzer a = new Analyzer() {    
+      @Override
+      public TokenStream tokenStream(String field, Reader in) {
+        return new CommonGramsQueryFilter(new CommonGramsFilter(
+            new WhitespaceTokenizer(TEST_VERSION_CURRENT, in), commonWords));
+      } 
+    };
+
+    // Stop words used below are "of" "the" and "s"
+    
+    // two word queries
+    assertAnalyzesTo(a, "brown fox", 
+        new String[] { "brown", "fox" });
+    assertAnalyzesTo(a, "the fox", 
+        new String[] { "the_fox" });
+    assertAnalyzesTo(a, "fox of", 
+        new String[] { "fox_of" });
+    assertAnalyzesTo(a, "of the", 
+        new String[] { "of_the" });
+    
+    // one word queries
+    assertAnalyzesTo(a, "the", 
+        new String[] { "the" });
+    assertAnalyzesTo(a, "foo", 
+        new String[] { "foo" });
+
+    // 3 word combinations s=stopword/common word n=not a stop word
+    assertAnalyzesTo(a, "n n n", 
+        new String[] { "n", "n", "n" });
+    assertAnalyzesTo(a, "quick brown fox", 
+        new String[] { "quick", "brown", "fox" });
+
+    assertAnalyzesTo(a, "n n s", 
+        new String[] { "n", "n_s" });
+    assertAnalyzesTo(a, "quick brown the", 
+        new String[] { "quick", "brown_the" });
+
+    assertAnalyzesTo(a, "n s n", 
+        new String[] { "n_s", "s_n" });
+    assertAnalyzesTo(a, "quick the brown", 
+        new String[] { "quick_the", "the_brown" });
+
+    assertAnalyzesTo(a, "n s s", 
+        new String[] { "n_s", "s_s" });
+    assertAnalyzesTo(a, "fox of the", 
+        new String[] { "fox_of", "of_the" });
+
+    assertAnalyzesTo(a, "s n n", 
+        new String[] { "s_n", "n", "n" });
+    assertAnalyzesTo(a, "the quick brown", 
+        new String[] { "the_quick", "quick", "brown" });
+
+    assertAnalyzesTo(a, "s n s", 
+        new String[] { "s_n", "n_s" });
+    assertAnalyzesTo(a, "the fox of", 
+        new String[] { "the_fox", "fox_of" });
+
+    assertAnalyzesTo(a, "s s n", 
+        new String[] { "s_s", "s_n" });
+    assertAnalyzesTo(a, "of the fox", 
+        new String[] { "of_the", "the_fox" });
+
+    assertAnalyzesTo(a, "s s s", 
+        new String[] { "s_s", "s_s" });
+    assertAnalyzesTo(a, "of the of", 
+        new String[] { "of_the", "the_of" });
+  }
+  
+  public void testCommonGramsFilter() throws Exception {
+    Analyzer a = new Analyzer() {    
+      @Override
+      public TokenStream tokenStream(String field, Reader in) {
+        return new CommonGramsFilter(
+            new WhitespaceTokenizer(TEST_VERSION_CURRENT, in), commonWords);
+      } 
+    };
+
+    // Stop words used below are "of" "the" and "s"
+    // one word queries
+    assertAnalyzesTo(a, "the", new String[] { "the" });
+    assertAnalyzesTo(a, "foo", new String[] { "foo" });
+
+    // two word queries
+    assertAnalyzesTo(a, "brown fox", 
+        new String[] { "brown", "fox" }, 
+        new int[] { 1, 1 });
+    assertAnalyzesTo(a, "the fox", 
+        new String[] { "the", "the_fox", "fox" }, 
+        new int[] { 1, 0, 1 });
+    assertAnalyzesTo(a, "fox of", 
+        new String[] { "fox", "fox_of", "of" }, 
+        new int[] { 1, 0, 1 });
+    assertAnalyzesTo(a, "of the", 
+        new String[] { "of", "of_the", "the" }, 
+        new int[] { 1, 0, 1 });
+
+    // 3 word combinations s=stopword/common word n=not a stop word
+    assertAnalyzesTo(a, "n n n", 
+        new String[] { "n", "n", "n" }, 
+        new int[] { 1, 1, 1 });
+    assertAnalyzesTo(a, "quick brown fox", 
+        new String[] { "quick", "brown", "fox" }, 
+        new int[] { 1, 1, 1 });
+
+    assertAnalyzesTo(a, "n n s", 
+        new String[] { "n", "n", "n_s", "s" }, 
+        new int[] { 1, 1, 0, 1 });
+    assertAnalyzesTo(a, "quick brown the", 
+        new String[] { "quick", "brown", "brown_the", "the" }, 
+        new int[] { 1, 1, 0, 1 });
+
+    assertAnalyzesTo(a, "n s n", 
+        new String[] { "n", "n_s", "s", "s_n", "n" }, 
+        new int[] { 1, 0, 1, 0, 1 });
+    assertAnalyzesTo(a, "quick the fox", 
+        new String[] { "quick", "quick_the", "the", "the_fox", "fox" }, 
+        new int[] { 1, 0, 1, 0, 1 });
+
+    assertAnalyzesTo(a, "n s s", 
+        new String[] { "n", "n_s", "s", "s_s", "s" }, 
+        new int[] { 1, 0, 1, 0, 1 });
+    assertAnalyzesTo(a, "fox of the", 
+        new String[] { "fox", "fox_of", "of", "of_the", "the" }, 
+        new int[] { 1, 0, 1, 0, 1 });
+
+    assertAnalyzesTo(a, "s n n", 
+        new String[] { "s", "s_n", "n", "n" }, 
+        new int[] { 1, 0, 1, 1 });
+    assertAnalyzesTo(a, "the quick brown", 
+        new String[] { "the", "the_quick", "quick", "brown" }, 
+        new int[] { 1, 0, 1, 1 });
+
+    assertAnalyzesTo(a, "s n s", 
+        new String[] { "s", "s_n", "n", "n_s", "s" }, 
+        new int[] { 1, 0, 1, 0, 1 });
+    assertAnalyzesTo(a, "the fox of", 
+        new String[] { "the", "the_fox", "fox", "fox_of", "of" }, 
+        new int[] { 1, 0, 1, 0, 1 });
+
+    assertAnalyzesTo(a, "s s n", 
+        new String[] { "s", "s_s", "s", "s_n", "n" }, 
+        new int[] { 1, 0, 1, 0, 1 });
+    assertAnalyzesTo(a, "of the fox", 
+        new String[] { "of", "of_the", "the", "the_fox", "fox" }, 
+        new int[] { 1, 0, 1, 0, 1 });
+
+    assertAnalyzesTo(a, "s s s", 
+        new String[] { "s", "s_s", "s", "s_s", "s" }, 
+        new int[] { 1, 0, 1, 0, 1 });
+    assertAnalyzesTo(a, "of the of", 
+        new String[] { "of", "of_the", "the", "the_of", "of" }, 
+        new int[] { 1, 0, 1, 0, 1 });
+  }
+  
+  /**
+   * Test that CommonGramsFilter works correctly in case-insensitive mode
+   */
+  public void testCaseSensitive() throws Exception {
+    final String input = "How The s a brown s cow d like A B thing?";
+    WhitespaceTokenizer wt = new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader(input));
+    Set common = CommonGramsFilter.makeCommonSet(commonWords);
+    TokenFilter cgf = new CommonGramsFilter(wt, common, false);
+    assertTokenStreamContents(cgf, new String[] {"How", "The", "The_s", "s",
+        "s_a", "a", "a_brown", "brown", "brown_s", "s", "s_cow", "cow",
+        "cow_d", "d", "d_like", "like", "A", "B", "thing?"});
+  }
+  
+  /**
+   * Test CommonGramsQueryFilter in the case that the last word is a stopword
+   */
+  public void testLastWordisStopWord() throws Exception {
+    final String input = "dog the";
+    WhitespaceTokenizer wt = new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader(input));
+    CommonGramsFilter cgf = new CommonGramsFilter(wt, commonWords);
+    TokenFilter nsf = new CommonGramsQueryFilter(cgf);
+    assertTokenStreamContents(nsf, new String[] { "dog_the" });
+  }
+  
+  /**
+   * Test CommonGramsQueryFilter in the case that the first word is a stopword
+   */
+  public void testFirstWordisStopWord() throws Exception {
+    final String input = "the dog";
+    WhitespaceTokenizer wt = new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader(input));
+    CommonGramsFilter cgf = new CommonGramsFilter(wt, commonWords);
+    TokenFilter nsf = new CommonGramsQueryFilter(cgf);
+    assertTokenStreamContents(nsf, new String[] { "the_dog" });
+  }
+  
+  /**
+   * Test CommonGramsQueryFilter in the case of a single (stop)word query
+   */
+  public void testOneWordQueryStopWord() throws Exception {
+    final String input = "the";
+    WhitespaceTokenizer wt = new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader(input));
+    CommonGramsFilter cgf = new CommonGramsFilter(wt, commonWords);
+    TokenFilter nsf = new CommonGramsQueryFilter(cgf);
+    assertTokenStreamContents(nsf, new String[] { "the" });
+  }
+  
+  /**
+   * Test CommonGramsQueryFilter in the case of a single word query
+   */
+  public void testOneWordQuery() throws Exception {
+    final String input = "monster";
+    WhitespaceTokenizer wt = new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader(input));
+    CommonGramsFilter cgf = new CommonGramsFilter(wt, commonWords);
+    TokenFilter nsf = new CommonGramsQueryFilter(cgf);
+    assertTokenStreamContents(nsf, new String[] { "monster" });
+  }
+  
+  /**
+   * Test CommonGramsQueryFilter when first and last words are stopwords.
+   */
+  public void TestFirstAndLastStopWord() throws Exception {
+    final String input = "the of";
+    WhitespaceTokenizer wt = new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader(input));
+    CommonGramsFilter cgf = new CommonGramsFilter(wt, commonWords);
+    TokenFilter nsf = new CommonGramsQueryFilter(cgf);
+    assertTokenStreamContents(nsf, new String[] { "the_of" });
+  }
+}
diff --git a/solr/src/java/org/apache/solr/analysis/CommonGramsFilter.java b/solr/src/java/org/apache/solr/analysis/CommonGramsFilter.java
deleted file mode 100644
index fb34a1b..0000000
--- a/solr/src/java/org/apache/solr/analysis/CommonGramsFilter.java
+++ /dev/null
@@ -1,270 +0,0 @@
-/*
- * Licensed under the Apache License, 
- * Version 2.0 (the "License"); you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0
- * Unless required by applicable law or agreed to in writing, software distributed under the License 
- * is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. 
- * See the License for the specific language governing permissions and limitations under the License. 
- */
-
-package org.apache.solr.analysis;
-
-import java.io.IOException;
-import java.util.Arrays;
-import java.util.Set;
-
-import org.apache.lucene.analysis.CharArraySet;
-import org.apache.lucene.analysis.TokenFilter;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
-import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-import org.apache.lucene.analysis.tokenattributes.TypeAttribute;
-import org.apache.lucene.util.Version;
-
-/*
- * TODO: Consider implementing https://issues.apache.org/jira/browse/LUCENE-1688 changes to stop list and associated constructors 
- */
-
-/**
- * Construct bigrams for frequently occurring terms while indexing. Single terms
- * are still indexed too, with bigrams overlaid. This is achieved through the
- * use of {@link PositionIncrementAttribute#setPositionIncrement(int)}. Bigrams have a type
- * of {@link #GRAM_TYPE} Example:
- * <ul>
- * <li>input:"the quick brown fox"</li>
- * <li>output:|"the","the-quick"|"brown"|"fox"|</li>
- * <li>"the-quick" has a position increment of 0 so it is in the same position
- * as "the" "the-quick" has a term.type() of "gram"</li>
- * 
- * </ul>
- */
-
-/*
- * Constructors and makeCommonSet based on similar code in StopFilter
- */
-public final class CommonGramsFilter extends TokenFilter {
-
-  static final String GRAM_TYPE = "gram";
-  private static final char SEPARATOR = '_';
-
-  private final CharArraySet commonWords;
-
-  private final StringBuilder buffer = new StringBuilder();
-  
-  private final CharTermAttribute termAttribute = addAttribute(CharTermAttribute.class);
-  private final OffsetAttribute offsetAttribute = addAttribute(OffsetAttribute.class);
-  private final TypeAttribute typeAttribute = addAttribute(TypeAttribute.class);
-  private final PositionIncrementAttribute posIncAttribute = addAttribute(PositionIncrementAttribute.class);
-
-  private int lastStartOffset;
-  private boolean lastWasCommon;
-  private State savedState;
-
-  /** @deprecated Use {@link #CommonGramsFilter(Version, TokenStream, Set)} instead */
-  public CommonGramsFilter(TokenStream input, Set<?> commonWords) {
-    this(Version.LUCENE_29, input, commonWords);
-  }
-  
-  /** @deprecated Use {@link #CommonGramsFilter(Version, TokenStream, Set, boolean)} instead */
-  public CommonGramsFilter(TokenStream input, Set<?> commonWords, boolean ignoreCase) {
-    this(Version.LUCENE_29, input, commonWords, ignoreCase);
-  }
-  
-  /**
-   * Construct a token stream filtering the given input using a Set of common
-   * words to create bigrams. Outputs both unigrams with position increment and
-   * bigrams with position increment 0 type=gram where one or both of the words
-   * in a potential bigram are in the set of common words .
-   * 
-   * @param input TokenStream input in filter chain
-   * @param commonWords The set of common words.
-   */
-  public CommonGramsFilter(Version matchVersion, TokenStream input, Set<?> commonWords) {
-    this(matchVersion, input, commonWords, false);
-  }
-
-  /**
-   * Construct a token stream filtering the given input using a Set of common
-   * words to create bigrams, case-sensitive if ignoreCase is false (unless Set
-   * is CharArraySet). If <code>commonWords</code> is an instance of
-   * {@link CharArraySet} (true if <code>makeCommonSet()</code> was used to
-   * construct the set) it will be directly used and <code>ignoreCase</code>
-   * will be ignored since <code>CharArraySet</code> directly controls case
-   * sensitivity.
-   * <p/>
-   * If <code>commonWords</code> is not an instance of {@link CharArraySet}, a
-   * new CharArraySet will be constructed and <code>ignoreCase</code> will be
-   * used to specify the case sensitivity of that set.
-   * 
-   * @param input TokenStream input in filter chain.
-   * @param commonWords The set of common words.
-   * @param ignoreCase -Ignore case when constructing bigrams for common words.
-   */
-  public CommonGramsFilter(Version matchVersion, TokenStream input, Set<?> commonWords, boolean ignoreCase) {
-    super(input);
-    if (commonWords instanceof CharArraySet) {
-      this.commonWords = (CharArraySet) commonWords;
-    } else {
-      this.commonWords = new CharArraySet(matchVersion, commonWords.size(), ignoreCase);
-      this.commonWords.addAll(commonWords);
-    }
-  }
-
-  /**
-   * Construct a token stream filtering the given input using an Array of common
-   * words to create bigrams.
-   * 
-   * @param input Tokenstream in filter chain
-   * @param commonWords words to be used in constructing bigrams
-   * @deprecated Use {@link #CommonGramsFilter(Version, TokenStream, Set)} instead.
-   */
-  @Deprecated
-  public CommonGramsFilter(TokenStream input, String[] commonWords) {
-    this(input, commonWords, false);
-  }
-
-  /**
-   * Construct a token stream filtering the given input using an Array of common
-   * words to create bigrams and is case-sensitive if ignoreCase is false.
-   * 
-   * @param input Tokenstream in filter chain
-   * @param commonWords words to be used in constructing bigrams
-   * @param ignoreCase -Ignore case when constructing bigrams for common words.
-   * @deprecated Use {@link #CommonGramsFilter(Version, TokenStream, Set, boolean)} instead.
-   */
-  @Deprecated
-  public CommonGramsFilter(TokenStream input, String[] commonWords, boolean ignoreCase) {
-    super(input);
-    this.commonWords = makeCommonSet(commonWords, ignoreCase);
-  }
-
-  /**
-   * Build a CharArraySet from an array of common words, appropriate for passing
-   * into the CommonGramsFilter constructor. This permits this commonWords
-   * construction to be cached once when an Analyzer is constructed.
-   *
-   * @param commonWords Array of common words which will be converted into the CharArraySet
-   * @return CharArraySet of the given words, appropriate for passing into the CommonGramFilter constructor
-   * @see #makeCommonSet(java.lang.String[], boolean) passing false to ignoreCase
-   * @deprecated create a CharArraySet with CharArraySet instead
-   */
-  @Deprecated
-  public static CharArraySet makeCommonSet(String[] commonWords) {
-    return makeCommonSet(commonWords, false);
-  }
-
-  /**
-   * Build a CharArraySet from an array of common words, appropriate for passing
-   * into the CommonGramsFilter constructor,case-sensitive if ignoreCase is
-   * false.
-   * 
-   * @param commonWords Array of common words which will be converted into the CharArraySet
-   * @param ignoreCase If true, all words are lower cased first.
-   * @return a Set containing the words
-   * @deprecated create a CharArraySet with CharArraySet instead
-   */
-  @Deprecated
-  public static CharArraySet makeCommonSet(String[] commonWords, boolean ignoreCase) {
-    CharArraySet commonSet = new CharArraySet(commonWords.length, ignoreCase);
-    commonSet.addAll(Arrays.asList(commonWords));
-    return commonSet;
-  }
-
-  /**
-   * Inserts bigrams for common words into a token stream. For each input token,
-   * output the token. If the token and/or the following token are in the list
-   * of common words also output a bigram with position increment 0 and
-   * type="gram"
-   *
-   * TODO:Consider adding an option to not emit unigram stopwords
-   * as in CDL XTF BigramStopFilter, CommonGramsQueryFilter would need to be
-   * changed to work with this.
-   *
-   * TODO: Consider optimizing for the case of three
-   * commongrams i.e "man of the year" normally produces 3 bigrams: "man-of",
-   * "of-the", "the-year" but with proper management of positions we could
-   * eliminate the middle bigram "of-the"and save a disk seek and a whole set of
-   * position lookups.
-   */
-  public boolean incrementToken() throws IOException {
-    // get the next piece of input
-    if (savedState != null) {
-      restoreState(savedState);
-      savedState = null;
-      saveTermBuffer();
-      return true;
-    } else if (!input.incrementToken()) {
-        return false;
-    }
-    
-    /* We build n-grams before and after stopwords. 
-     * When valid, the buffer always contains at least the separator.
-     * If its empty, there is nothing before this stopword.
-     */
-    if (lastWasCommon || (isCommon() && buffer.length() > 0)) {
-      savedState = captureState();
-      gramToken();
-      return true;      
-    }
-
-    saveTermBuffer();
-    return true;
-  }
-
-  /**
-   * {@inheritDoc}
-   */
-  @Override
-  public void reset() throws IOException {
-    super.reset();
-    lastWasCommon = false;
-    savedState = null;
-    buffer.setLength(0);
-  }
-
-  // ================================================= Helper Methods ================================================
-
-  /**
-   * Determines if the current token is a common term
-   *
-   * @return {@code true} if the current token is a common term, {@code false} otherwise
-   */
-  private boolean isCommon() {
-    return commonWords != null && commonWords.contains(termAttribute.buffer(), 0, termAttribute.length());
-  }
-
-  /**
-   * Saves this information to form the left part of a gram
-   */
-  private void saveTermBuffer() {
-    buffer.setLength(0);
-    buffer.append(termAttribute.buffer(), 0, termAttribute.length());
-    buffer.append(SEPARATOR);
-    lastStartOffset = offsetAttribute.startOffset();
-    lastWasCommon = isCommon();
-  }
-
-  /**
-   * Constructs a compound token.
-   */
-  private void gramToken() {
-    buffer.append(termAttribute.buffer(), 0, termAttribute.length());
-    int endOffset = offsetAttribute.endOffset();
-
-    clearAttributes();
-
-    int length = buffer.length();
-    char termText[] = termAttribute.buffer();
-    if (length > termText.length) {
-      termText = termAttribute.resizeBuffer(length);
-    }
-    
-    buffer.getChars(0, length, termText, 0);
-    termAttribute.setLength(length);
-    posIncAttribute.setPositionIncrement(0);
-    offsetAttribute.setOffset(lastStartOffset, endOffset);
-    typeAttribute.setType(GRAM_TYPE);
-    buffer.setLength(0);
-  }
-}
diff --git a/solr/src/java/org/apache/solr/analysis/CommonGramsFilterFactory.java b/solr/src/java/org/apache/solr/analysis/CommonGramsFilterFactory.java
index 3a84708..2116cdd 100644
--- a/solr/src/java/org/apache/solr/analysis/CommonGramsFilterFactory.java
+++ b/solr/src/java/org/apache/solr/analysis/CommonGramsFilterFactory.java
@@ -22,6 +22,7 @@ import java.util.Set;
 import org.apache.lucene.analysis.CharArraySet;
 import org.apache.lucene.analysis.StopAnalyzer;
 import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.commongrams.CommonGramsFilter;
 import org.apache.solr.common.ResourceLoader;
 import org.apache.solr.util.plugin.ResourceLoaderAware;
 
diff --git a/solr/src/java/org/apache/solr/analysis/CommonGramsQueryFilter.java b/solr/src/java/org/apache/solr/analysis/CommonGramsQueryFilter.java
deleted file mode 100644
index 8adb00a..0000000
--- a/solr/src/java/org/apache/solr/analysis/CommonGramsQueryFilter.java
+++ /dev/null
@@ -1,120 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.solr.analysis;
-
-import java.io.IOException;
-
-import org.apache.lucene.analysis.TokenFilter;
-import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
-import org.apache.lucene.analysis.tokenattributes.TypeAttribute;
-
-import static org.apache.solr.analysis.CommonGramsFilter.GRAM_TYPE;
-
-/**
- * Wrap a CommonGramsFilter optimizing phrase queries by only returning single
- * words when they are not a member of a bigram.
- * 
- * Example:
- * <ul>
- * <li>query input to CommonGramsFilter: "the rain in spain falls mainly"
- * <li>output of CommomGramsFilter/input to CommonGramsQueryFilter:
- * |"the, "the-rain"|"rain" "rain-in"|"in, "in-spain"|"spain"|"falls"|"mainly"
- * <li>output of CommonGramsQueryFilter:"the-rain", "rain-in" ,"in-spain",
- * "falls", "mainly"
- * </ul>
- */
-
-/*
- * See:http://hudson.zones.apache.org/hudson/job/Lucene-trunk/javadoc//all/org/apache/lucene/analysis/TokenStream.html and
- * http://svn.apache.org/viewvc/lucene/dev/trunk/lucene/src/java/org/apache/lucene/analysis/package.html?revision=718798
- */
-public final class CommonGramsQueryFilter extends TokenFilter {
-
-  private final TypeAttribute typeAttribute = addAttribute(TypeAttribute.class);
-  private final PositionIncrementAttribute posIncAttribute = addAttribute(PositionIncrementAttribute.class);
-  
-  private State previous;
-  private String previousType;
-
-  /**
-   * Constructs a new CommonGramsQueryFilter based on the provided CommomGramsFilter 
-   * 
-   * @param input CommonGramsFilter the QueryFilter will use
-   */
-  public CommonGramsQueryFilter(CommonGramsFilter input) {
-    super(input);
-  }
-
-  /**
-   * {@inheritDoc}
-   */
-  public void reset() throws IOException {
-    super.reset();
-    previous = null;
-    previousType = null;
-  }
-  
-  /**
-   * Output bigrams whenever possible to optimize queries. Only output unigrams
-   * when they are not a member of a bigram. Example:
-   * <ul>
-   * <li>input: "the rain in spain falls mainly"
-   * <li>output:"the-rain", "rain-in" ,"in-spain", "falls", "mainly"
-   * </ul>
-   */
-  public boolean incrementToken() throws IOException {
-    while (input.incrementToken()) {
-      State current = captureState();
-
-      if (previous != null && !isGramType()) {
-        restoreState(previous);
-        previous = current;
-        previousType = typeAttribute.type();
-        
-        if (isGramType()) {
-          posIncAttribute.setPositionIncrement(1);
-        }
-        return true;
-      }
-
-      previous = current;
-    }
-
-    if (previous == null || GRAM_TYPE.equals(previousType)) {
-      return false;
-    }
-    
-    restoreState(previous);
-    previous = null;
-    
-    if (isGramType()) {
-      posIncAttribute.setPositionIncrement(1);
-    }
-    return true;
-  }
-
-  // ================================================= Helper Methods ================================================
-
-  /**
-   * Convenience method to check if the current type is a gram type
-   * 
-   * @return {@code true} if the current type is a gram type, {@code false} otherwise
-   */
-  public boolean isGramType() {
-    return GRAM_TYPE.equals(typeAttribute.type());
-  }
-}
diff --git a/solr/src/java/org/apache/solr/analysis/CommonGramsQueryFilterFactory.java b/solr/src/java/org/apache/solr/analysis/CommonGramsQueryFilterFactory.java
index 7f61e1d..7b0397f 100644
--- a/solr/src/java/org/apache/solr/analysis/CommonGramsQueryFilterFactory.java
+++ b/solr/src/java/org/apache/solr/analysis/CommonGramsQueryFilterFactory.java
@@ -23,6 +23,8 @@ import java.util.Set;
 import org.apache.lucene.analysis.CharArraySet;
 import org.apache.lucene.analysis.StopAnalyzer;
 import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.commongrams.CommonGramsFilter;
+import org.apache.lucene.analysis.commongrams.CommonGramsQueryFilter;
 import org.apache.solr.common.ResourceLoader;
 import org.apache.solr.util.plugin.ResourceLoaderAware;
 
diff --git a/solr/src/test/org/apache/solr/analysis/CommonGramsFilterTest.java b/solr/src/test/org/apache/solr/analysis/CommonGramsFilterTest.java
deleted file mode 100644
index 4dfbcbe..0000000
--- a/solr/src/test/org/apache/solr/analysis/CommonGramsFilterTest.java
+++ /dev/null
@@ -1,308 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.solr.analysis;
-
-import java.io.Reader;
-import java.io.StringReader;
-import java.util.Set;
-
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.TokenFilter;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.WhitespaceTokenizer;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-
-/**
- * Tests CommonGramsQueryFilter
- */
-public class CommonGramsFilterTest extends BaseTokenTestCase {
-  private static final String[] commonWords = { "s", "a", "b", "c", "d", "the",
-      "of" };
-  
-  public void testReset() throws Exception {
-    final String input = "How the s a brown s cow d like A B thing?";
-    WhitespaceTokenizer wt = new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(input));
-    CommonGramsFilter cgf = new CommonGramsFilter(wt, commonWords);
-    
-    CharTermAttribute term = cgf.addAttribute(CharTermAttribute.class);
-    assertTrue(cgf.incrementToken());
-    assertEquals("How", term.toString());
-    assertTrue(cgf.incrementToken());
-    assertEquals("How_the", term.toString());
-    assertTrue(cgf.incrementToken());
-    assertEquals("the", term.toString());
-    assertTrue(cgf.incrementToken());
-    assertEquals("the_s", term.toString());
-    
-    wt.reset(new StringReader(input));
-    cgf.reset();
-    assertTrue(cgf.incrementToken());
-    assertEquals("How", term.toString());
-  }
-  
-  public void testQueryReset() throws Exception {
-    final String input = "How the s a brown s cow d like A B thing?";
-    WhitespaceTokenizer wt = new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(input));
-    CommonGramsFilter cgf = new CommonGramsFilter(wt, commonWords);
-    CommonGramsQueryFilter nsf = new CommonGramsQueryFilter(cgf);
-    
-    CharTermAttribute term = wt.addAttribute(CharTermAttribute.class);
-    assertTrue(nsf.incrementToken());
-    assertEquals("How_the", term.toString());
-    assertTrue(nsf.incrementToken());
-    assertEquals("the_s", term.toString());
-    
-    wt.reset(new StringReader(input));
-    nsf.reset();
-    assertTrue(nsf.incrementToken());
-    assertEquals("How_the", term.toString());
-  }
-  
-  /**
-   * This is for testing CommonGramsQueryFilter which outputs a set of tokens
-   * optimized for querying with only one token at each position, either a
-   * unigram or a bigram It also will not return a token for the final position
-   * if the final word is already in the preceding bigram Example:(three
-   * tokens/positions in)
-   * "foo bar the"=>"foo:1|bar:2,bar-the:2|the:3=> "foo" "bar-the" (2 tokens
-   * out)
-   * 
-   * @return Map<String,String>
-   */
-  public void testCommonGramsQueryFilter() throws Exception {
-    Analyzer a = new Analyzer() {    
-      @Override
-      public TokenStream tokenStream(String field, Reader in) {
-        return new CommonGramsQueryFilter(new CommonGramsFilter(
-            new WhitespaceTokenizer(DEFAULT_VERSION, in), commonWords));
-      } 
-    };
-
-    // Stop words used below are "of" "the" and "s"
-    
-    // two word queries
-    assertAnalyzesTo(a, "brown fox", 
-        new String[] { "brown", "fox" });
-    assertAnalyzesTo(a, "the fox", 
-        new String[] { "the_fox" });
-    assertAnalyzesTo(a, "fox of", 
-        new String[] { "fox_of" });
-    assertAnalyzesTo(a, "of the", 
-        new String[] { "of_the" });
-    
-    // one word queries
-    assertAnalyzesTo(a, "the", 
-        new String[] { "the" });
-    assertAnalyzesTo(a, "foo", 
-        new String[] { "foo" });
-
-    // 3 word combinations s=stopword/common word n=not a stop word
-    assertAnalyzesTo(a, "n n n", 
-        new String[] { "n", "n", "n" });
-    assertAnalyzesTo(a, "quick brown fox", 
-        new String[] { "quick", "brown", "fox" });
-
-    assertAnalyzesTo(a, "n n s", 
-        new String[] { "n", "n_s" });
-    assertAnalyzesTo(a, "quick brown the", 
-        new String[] { "quick", "brown_the" });
-
-    assertAnalyzesTo(a, "n s n", 
-        new String[] { "n_s", "s_n" });
-    assertAnalyzesTo(a, "quick the brown", 
-        new String[] { "quick_the", "the_brown" });
-
-    assertAnalyzesTo(a, "n s s", 
-        new String[] { "n_s", "s_s" });
-    assertAnalyzesTo(a, "fox of the", 
-        new String[] { "fox_of", "of_the" });
-
-    assertAnalyzesTo(a, "s n n", 
-        new String[] { "s_n", "n", "n" });
-    assertAnalyzesTo(a, "the quick brown", 
-        new String[] { "the_quick", "quick", "brown" });
-
-    assertAnalyzesTo(a, "s n s", 
-        new String[] { "s_n", "n_s" });
-    assertAnalyzesTo(a, "the fox of", 
-        new String[] { "the_fox", "fox_of" });
-
-    assertAnalyzesTo(a, "s s n", 
-        new String[] { "s_s", "s_n" });
-    assertAnalyzesTo(a, "of the fox", 
-        new String[] { "of_the", "the_fox" });
-
-    assertAnalyzesTo(a, "s s s", 
-        new String[] { "s_s", "s_s" });
-    assertAnalyzesTo(a, "of the of", 
-        new String[] { "of_the", "the_of" });
-  }
-  
-  public void testCommonGramsFilter() throws Exception {
-    Analyzer a = new Analyzer() {    
-      @Override
-      public TokenStream tokenStream(String field, Reader in) {
-        return new CommonGramsFilter(
-            new WhitespaceTokenizer(DEFAULT_VERSION, in), commonWords);
-      } 
-    };
-
-    // Stop words used below are "of" "the" and "s"
-    // one word queries
-    assertAnalyzesTo(a, "the", new String[] { "the" });
-    assertAnalyzesTo(a, "foo", new String[] { "foo" });
-
-    // two word queries
-    assertAnalyzesTo(a, "brown fox", 
-        new String[] { "brown", "fox" }, 
-        new int[] { 1, 1 });
-    assertAnalyzesTo(a, "the fox", 
-        new String[] { "the", "the_fox", "fox" }, 
-        new int[] { 1, 0, 1 });
-    assertAnalyzesTo(a, "fox of", 
-        new String[] { "fox", "fox_of", "of" }, 
-        new int[] { 1, 0, 1 });
-    assertAnalyzesTo(a, "of the", 
-        new String[] { "of", "of_the", "the" }, 
-        new int[] { 1, 0, 1 });
-
-    // 3 word combinations s=stopword/common word n=not a stop word
-    assertAnalyzesTo(a, "n n n", 
-        new String[] { "n", "n", "n" }, 
-        new int[] { 1, 1, 1 });
-    assertAnalyzesTo(a, "quick brown fox", 
-        new String[] { "quick", "brown", "fox" }, 
-        new int[] { 1, 1, 1 });
-
-    assertAnalyzesTo(a, "n n s", 
-        new String[] { "n", "n", "n_s", "s" }, 
-        new int[] { 1, 1, 0, 1 });
-    assertAnalyzesTo(a, "quick brown the", 
-        new String[] { "quick", "brown", "brown_the", "the" }, 
-        new int[] { 1, 1, 0, 1 });
-
-    assertAnalyzesTo(a, "n s n", 
-        new String[] { "n", "n_s", "s", "s_n", "n" }, 
-        new int[] { 1, 0, 1, 0, 1 });
-    assertAnalyzesTo(a, "quick the fox", 
-        new String[] { "quick", "quick_the", "the", "the_fox", "fox" }, 
-        new int[] { 1, 0, 1, 0, 1 });
-
-    assertAnalyzesTo(a, "n s s", 
-        new String[] { "n", "n_s", "s", "s_s", "s" }, 
-        new int[] { 1, 0, 1, 0, 1 });
-    assertAnalyzesTo(a, "fox of the", 
-        new String[] { "fox", "fox_of", "of", "of_the", "the" }, 
-        new int[] { 1, 0, 1, 0, 1 });
-
-    assertAnalyzesTo(a, "s n n", 
-        new String[] { "s", "s_n", "n", "n" }, 
-        new int[] { 1, 0, 1, 1 });
-    assertAnalyzesTo(a, "the quick brown", 
-        new String[] { "the", "the_quick", "quick", "brown" }, 
-        new int[] { 1, 0, 1, 1 });
-
-    assertAnalyzesTo(a, "s n s", 
-        new String[] { "s", "s_n", "n", "n_s", "s" }, 
-        new int[] { 1, 0, 1, 0, 1 });
-    assertAnalyzesTo(a, "the fox of", 
-        new String[] { "the", "the_fox", "fox", "fox_of", "of" }, 
-        new int[] { 1, 0, 1, 0, 1 });
-
-    assertAnalyzesTo(a, "s s n", 
-        new String[] { "s", "s_s", "s", "s_n", "n" }, 
-        new int[] { 1, 0, 1, 0, 1 });
-    assertAnalyzesTo(a, "of the fox", 
-        new String[] { "of", "of_the", "the", "the_fox", "fox" }, 
-        new int[] { 1, 0, 1, 0, 1 });
-
-    assertAnalyzesTo(a, "s s s", 
-        new String[] { "s", "s_s", "s", "s_s", "s" }, 
-        new int[] { 1, 0, 1, 0, 1 });
-    assertAnalyzesTo(a, "of the of", 
-        new String[] { "of", "of_the", "the", "the_of", "of" }, 
-        new int[] { 1, 0, 1, 0, 1 });
-  }
-  
-  /**
-   * Test that CommonGramsFilter works correctly in case-insensitive mode
-   */
-  public void testCaseSensitive() throws Exception {
-    final String input = "How The s a brown s cow d like A B thing?";
-    WhitespaceTokenizer wt = new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(input));
-    Set common = CommonGramsFilter.makeCommonSet(commonWords);
-    TokenFilter cgf = new CommonGramsFilter(wt, common, false);
-    assertTokenStreamContents(cgf, new String[] {"How", "The", "The_s", "s",
-        "s_a", "a", "a_brown", "brown", "brown_s", "s", "s_cow", "cow",
-        "cow_d", "d", "d_like", "like", "A", "B", "thing?"});
-  }
-  
-  /**
-   * Test CommonGramsQueryFilter in the case that the last word is a stopword
-   */
-  public void testLastWordisStopWord() throws Exception {
-    final String input = "dog the";
-    WhitespaceTokenizer wt = new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(input));
-    CommonGramsFilter cgf = new CommonGramsFilter(wt, commonWords);
-    TokenFilter nsf = new CommonGramsQueryFilter(cgf);
-    assertTokenStreamContents(nsf, new String[] { "dog_the" });
-  }
-  
-  /**
-   * Test CommonGramsQueryFilter in the case that the first word is a stopword
-   */
-  public void testFirstWordisStopWord() throws Exception {
-    final String input = "the dog";
-    WhitespaceTokenizer wt = new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(input));
-    CommonGramsFilter cgf = new CommonGramsFilter(wt, commonWords);
-    TokenFilter nsf = new CommonGramsQueryFilter(cgf);
-    assertTokenStreamContents(nsf, new String[] { "the_dog" });
-  }
-  
-  /**
-   * Test CommonGramsQueryFilter in the case of a single (stop)word query
-   */
-  public void testOneWordQueryStopWord() throws Exception {
-    final String input = "the";
-    WhitespaceTokenizer wt = new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(input));
-    CommonGramsFilter cgf = new CommonGramsFilter(wt, commonWords);
-    TokenFilter nsf = new CommonGramsQueryFilter(cgf);
-    assertTokenStreamContents(nsf, new String[] { "the" });
-  }
-  
-  /**
-   * Test CommonGramsQueryFilter in the case of a single word query
-   */
-  public void testOneWordQuery() throws Exception {
-    final String input = "monster";
-    WhitespaceTokenizer wt = new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(input));
-    CommonGramsFilter cgf = new CommonGramsFilter(wt, commonWords);
-    TokenFilter nsf = new CommonGramsQueryFilter(cgf);
-    assertTokenStreamContents(nsf, new String[] { "monster" });
-  }
-  
-  /**
-   * Test CommonGramsQueryFilter when first and last words are stopwords.
-   */
-  public void TestFirstAndLastStopWord() throws Exception {
-    final String input = "the of";
-    WhitespaceTokenizer wt = new WhitespaceTokenizer(DEFAULT_VERSION, new StringReader(input));
-    CommonGramsFilter cgf = new CommonGramsFilter(wt, commonWords);
-    TokenFilter nsf = new CommonGramsQueryFilter(cgf);
-    assertTokenStreamContents(nsf, new String[] { "the_of" });
-  }
-}

