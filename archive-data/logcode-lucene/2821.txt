GitDiffStart: 679dd8f7902d0c607cc020d17b40b93b950c2939 | Thu Aug 27 02:18:36 2015 +0000
diff --git a/solr/CHANGES.txt b/solr/CHANGES.txt
index 736fa63..cfe005c 100644
--- a/solr/CHANGES.txt
+++ b/solr/CHANGES.txt
@@ -129,6 +129,8 @@ New Features
 
 * SOLR-7961: Print Solr's version with command bin/solr version (janhoy)
 
+* SOLR-7889: Introduce a ConfigSet management API (Gregory Chanan)
+
 Bug Fixes
 ----------------------
 
diff --git a/solr/core/src/java/org/apache/solr/cloud/LeaderElector.java b/solr/core/src/java/org/apache/solr/cloud/LeaderElector.java
index 760fdbd..fc0fb5f 100644
--- a/solr/core/src/java/org/apache/solr/cloud/LeaderElector.java
+++ b/solr/core/src/java/org/apache/solr/cloud/LeaderElector.java
@@ -280,7 +280,7 @@ public  class LeaderElector {
       try {
         if(joinAtHead){
           log.info("Node {} trying to join election at the head", id);
-          List<String> nodes = OverseerProcessor.getSortedElectionNodes(zkClient, shardsElectZkPath);
+          List<String> nodes = OverseerTaskProcessor.getSortedElectionNodes(zkClient, shardsElectZkPath);
           if(nodes.size() <2){
             leaderSeqPath = zkClient.create(shardsElectZkPath + "/" + id + "-n_", null,
                 CreateMode.EPHEMERAL_SEQUENTIAL, false);
diff --git a/solr/core/src/java/org/apache/solr/cloud/Overseer.java b/solr/core/src/java/org/apache/solr/cloud/Overseer.java
index c7dd0e0..5805335 100644
--- a/solr/core/src/java/org/apache/solr/cloud/Overseer.java
+++ b/solr/core/src/java/org/apache/solr/cloud/Overseer.java
@@ -309,7 +309,7 @@ public class Overseer implements Closeable {
       try {
         Map m = (Map) Utils.fromJSON(data);
         String id = (String) m.get("id");
-        if(overseerCollectionProcessor.getId().equals(id)){
+        if(overseerCollectionConfigSetProcessor.getId().equals(id)){
           try {
             log.info("I'm exiting , but I'm still the leader");
             zkClient.delete(path,stat.getVersion(),true);
@@ -390,7 +390,7 @@ public class Overseer implements Closeable {
           case QUIT:
             if (myId.equals(message.get("id"))) {
               log.info("Quit command received {}", LeaderElector.getNodeName(myId));
-              overseerCollectionProcessor.close();
+              overseerCollectionConfigSetProcessor.close();
               close();
             } else {
               log.warn("Overseer received wrong QUIT message {}", message);
@@ -786,7 +786,7 @@ public class Overseer implements Closeable {
 
   private final String adminPath;
 
-  private OverseerCollectionProcessor overseerCollectionProcessor;
+  private OverseerCollectionConfigSetProcessor overseerCollectionConfigSetProcessor;
 
   private ZkController zkController;
 
@@ -824,8 +824,8 @@ public class Overseer implements Closeable {
     ThreadGroup ccTg = new ThreadGroup("Overseer collection creation process.");
 
     OverseerNodePrioritizer overseerPrioritizer = new OverseerNodePrioritizer(reader, adminPath, shardHandler.getShardHandlerFactory());
-    overseerCollectionProcessor = new OverseerCollectionProcessor(reader, id, shardHandler, adminPath, stats, Overseer.this, overseerPrioritizer);
-    ccThread = new OverseerThread(ccTg, overseerCollectionProcessor, "OverseerCollectionProcessor-" + id);
+    overseerCollectionConfigSetProcessor = new OverseerCollectionConfigSetProcessor(reader, id, shardHandler, adminPath, stats, Overseer.this, overseerPrioritizer);
+    ccThread = new OverseerThread(ccTg, overseerCollectionConfigSetProcessor, "OverseerCollectionConfigSetProcessor-" + id);
     ccThread.setDaemon(true);
     
     ThreadGroup ohcfTg = new ThreadGroup("Overseer Hdfs SolrCore Failover Thread.");
@@ -922,15 +922,27 @@ public class Overseer implements Closeable {
   }
   
   /* Collection creation queue */
-  static OverseerCollectionQueue getCollectionQueue(final SolrZkClient zkClient) {
+  static OverseerTaskQueue getCollectionQueue(final SolrZkClient zkClient) {
     return getCollectionQueue(zkClient, new Stats());
   }
 
-  static OverseerCollectionQueue getCollectionQueue(final SolrZkClient zkClient, Stats zkStats)  {
+  static OverseerTaskQueue getCollectionQueue(final SolrZkClient zkClient, Stats zkStats)  {
     createOverseerNode(zkClient);
-    return new OverseerCollectionQueue(zkClient, "/overseer/collection-queue-work", zkStats);
+    return new OverseerTaskQueue(zkClient, "/overseer/collection-queue-work", zkStats);
   }
-  
+
+  /* The queue for ConfigSet related operations */
+  static OverseerTaskQueue getConfigSetQueue(final SolrZkClient zkClient)  {
+    return getConfigSetQueue(zkClient, new Stats());
+  }
+
+  static OverseerTaskQueue getConfigSetQueue(final SolrZkClient zkClient, Stats zkStats)  {
+    // For now, we use the same queue as the collection queue, but ensure
+    // that the actions are prefixed with a unique string.
+    createOverseerNode(zkClient);
+    return getCollectionQueue(zkClient, zkStats);
+  }
+
   private static void createOverseerNode(final SolrZkClient zkClient) {
     try {
       zkClient.create("/overseer", new byte[0], CreateMode.PERSISTENT, true);
diff --git a/solr/core/src/java/org/apache/solr/cloud/OverseerCollectionConfigSetProcessor.java b/solr/core/src/java/org/apache/solr/cloud/OverseerCollectionConfigSetProcessor.java
new file mode 100644
index 0000000..eef56c6
--- /dev/null
+++ b/solr/core/src/java/org/apache/solr/cloud/OverseerCollectionConfigSetProcessor.java
@@ -0,0 +1,100 @@
+package org.apache.solr.cloud;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.solr.common.cloud.ZkNodeProps;
+import org.apache.solr.common.cloud.ZkStateReader;
+import org.apache.solr.handler.component.ShardHandler;
+import org.apache.solr.handler.component.ShardHandlerFactory;
+import static org.apache.solr.cloud.OverseerConfigSetMessageHandler.CONFIGSETS_ACTION_PREFIX;
+
+/**
+ * An {@link OverseerTaskProcessor} that handles:
+ * 1) collection-related Overseer messages
+ * 2) configset-related Overseer messages
+ */
+public class OverseerCollectionConfigSetProcessor extends OverseerTaskProcessor {
+
+   public OverseerCollectionConfigSetProcessor(ZkStateReader zkStateReader, String myId,
+                                     final ShardHandler shardHandler,
+                                     String adminPath, Overseer.Stats stats, Overseer overseer,
+                                     OverseerNodePrioritizer overseerNodePrioritizer) {
+    this(
+        zkStateReader,
+        myId,
+        shardHandler.getShardHandlerFactory(),
+        adminPath,
+        stats,
+        overseer,
+        overseerNodePrioritizer,
+        Overseer.getCollectionQueue(zkStateReader.getZkClient(), stats),
+        Overseer.getRunningMap(zkStateReader.getZkClient()),
+        Overseer.getCompletedMap(zkStateReader.getZkClient()),
+        Overseer.getFailureMap(zkStateReader.getZkClient())
+    );
+  }
+
+  protected OverseerCollectionConfigSetProcessor(ZkStateReader zkStateReader, String myId,
+                                        final ShardHandlerFactory shardHandlerFactory,
+                                        String adminPath,
+                                        Overseer.Stats stats,
+                                        Overseer overseer,
+                                        OverseerNodePrioritizer overseerNodePrioritizer,
+                                        OverseerTaskQueue workQueue,
+                                        DistributedMap runningMap,
+                                        DistributedMap completedMap,
+                                        DistributedMap failureMap) {
+    super(
+        zkStateReader,
+        myId,
+        shardHandlerFactory,
+        adminPath,
+        stats,
+        getOverseerMessageHandlerSelector(zkStateReader, myId, shardHandlerFactory,
+            adminPath, stats, overseer, overseerNodePrioritizer),
+        overseerNodePrioritizer,
+        workQueue,
+        runningMap,
+        completedMap,
+        failureMap);
+  }
+
+  private static OverseerMessageHandlerSelector getOverseerMessageHandlerSelector(
+      ZkStateReader zkStateReader,
+      String myId,
+      final ShardHandlerFactory shardHandlerFactory,
+      String adminPath,
+      Overseer.Stats stats,
+      Overseer overseer,
+      OverseerNodePrioritizer overseerNodePrioritizer) {
+    final OverseerCollectionMessageHandler collMessageHandler = new OverseerCollectionMessageHandler(
+        zkStateReader, myId, shardHandlerFactory, adminPath, stats, overseer, overseerNodePrioritizer);
+    final OverseerConfigSetMessageHandler configMessageHandler = new OverseerConfigSetMessageHandler(
+        zkStateReader);
+    return new OverseerMessageHandlerSelector() {
+      @Override
+      public OverseerMessageHandler selectOverseerMessageHandler(ZkNodeProps message) {
+        String operation = message.getStr(Overseer.QUEUE_OPERATION);
+        if (operation != null && operation.startsWith(CONFIGSETS_ACTION_PREFIX)) {
+          return configMessageHandler;
+        }
+        return collMessageHandler;
+      }
+    };
+  }
+}
diff --git a/solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler.java b/solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler.java
index 8b2256e..4997782 100644
--- a/solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler.java
+++ b/solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler.java
@@ -121,7 +121,10 @@ import static org.apache.solr.common.params.CommonParams.NAME;
 import static org.apache.solr.common.util.StrUtils.formatString;
 import static org.apache.solr.common.util.Utils.makeMap;
 
-
+/**
+ * A {@link OverseerMessageHandler} that handles Collections API related
+ * overseer messages.
+ */
 public class OverseerCollectionMessageHandler implements OverseerMessageHandler {
 
   public static final String NUM_SLICES = "numShards";
@@ -203,7 +206,7 @@ public class OverseerCollectionMessageHandler implements OverseerMessageHandler
   @Override
   @SuppressWarnings("unchecked")
   public SolrResponse processMessage(ZkNodeProps message, String operation) {
-    log.warn("OverseerCollectionProcessor.processMessage : "+ operation + " , "+ message.toString());
+    log.warn("OverseerCollectionMessageHandler.processMessage : "+ operation + " , "+ message.toString());
 
     NamedList results = new NamedList();
     try {
@@ -371,7 +374,7 @@ public class OverseerCollectionMessageHandler implements OverseerMessageHandler
 
   @SuppressWarnings("unchecked")
   private void getOverseerStatus(ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {
-    String leaderNode = OverseerProcessor.getLeaderNode(zkStateReader.getZkClient());
+    String leaderNode = OverseerTaskProcessor.getLeaderNode(zkStateReader.getZkClient());
     results.add("leader", leaderNode);
     Stat stat = new Stat();
     zkStateReader.getZkClient().getData("/overseer/queue",null, stat, true);
@@ -2470,7 +2473,7 @@ public class OverseerCollectionMessageHandler implements OverseerMessageHandler
 
   @Override
   public String getName() {
-    return "Overseer Collection Processor";
+    return "Overseer Collection Message Handler";
   }
 
   @Override
@@ -2495,7 +2498,7 @@ public class OverseerCollectionMessageHandler implements OverseerMessageHandler
   }
 
   @Override
-  public void unmarkExclusiveTask(String collectionName, String operation) {
+  public void unmarkExclusiveTask(String collectionName, String operation, ZkNodeProps message) {
     if(!CLUSTERSTATUS.isEqual(operation) && collectionName != null) {
       synchronized (collectionWip) {
         collectionWip.remove(collectionName);
@@ -2510,8 +2513,10 @@ public class OverseerCollectionMessageHandler implements OverseerMessageHandler
     if(CLUSTERSTATUS.isEqual(message.getStr(Overseer.QUEUE_OPERATION)))
       return ExclusiveMarking.EXCLUSIVE;
 
-    if(collectionWip.contains(collectionName))
-      return ExclusiveMarking.NONEXCLUSIVE;
+    synchronized (collectionWip) {
+      if(collectionWip.contains(collectionName))
+        return ExclusiveMarking.NONEXCLUSIVE;
+    }
 
     return ExclusiveMarking.NOTDETERMINED;
   }
diff --git a/solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor.java b/solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor.java
deleted file mode 100644
index d1c6043..0000000
--- a/solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor.java
+++ /dev/null
@@ -1,92 +0,0 @@
-package org.apache.solr.cloud;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.solr.common.cloud.ZkNodeProps;
-import org.apache.solr.common.cloud.ZkStateReader;
-import org.apache.solr.handler.component.ShardHandler;
-import org.apache.solr.handler.component.ShardHandlerFactory;
-
-/**
- * An {@link OverseerProcessor} that handles collection-related Overseer
- * messages only.
- */
-public class OverseerCollectionProcessor extends OverseerProcessor {
-
-   public OverseerCollectionProcessor(ZkStateReader zkStateReader, String myId,
-                                     final ShardHandler shardHandler,
-                                     String adminPath, Overseer.Stats stats, Overseer overseer,
-                                     OverseerNodePrioritizer overseerNodePrioritizer) {
-    this(
-        zkStateReader,
-        myId,
-        shardHandler.getShardHandlerFactory(),
-        adminPath,
-        stats,
-        overseer,
-        overseerNodePrioritizer,
-        Overseer.getCollectionQueue(zkStateReader.getZkClient(), stats),
-        Overseer.getRunningMap(zkStateReader.getZkClient()),
-        Overseer.getCompletedMap(zkStateReader.getZkClient()),
-        Overseer.getFailureMap(zkStateReader.getZkClient())
-    );
-  }
-
-  protected OverseerCollectionProcessor(ZkStateReader zkStateReader, String myId,
-                                        final ShardHandlerFactory shardHandlerFactory,
-                                        String adminPath,
-                                        Overseer.Stats stats,
-                                        Overseer overseer,
-                                        OverseerNodePrioritizer overseerNodePrioritizer,
-                                        OverseerCollectionQueue workQueue,
-                                        DistributedMap runningMap,
-                                        DistributedMap completedMap,
-                                        DistributedMap failureMap) {
-    super(
-        zkStateReader,
-        myId,
-        shardHandlerFactory,
-        adminPath,
-        stats,
-        getOverseerMessageHandlerSelector(zkStateReader, myId, shardHandlerFactory,
-            adminPath, stats, overseer, overseerNodePrioritizer),
-        overseerNodePrioritizer,
-        workQueue,
-        runningMap,
-        completedMap,
-        failureMap);
-  }
-
-  private static OverseerMessageHandlerSelector getOverseerMessageHandlerSelector(
-      ZkStateReader zkStateReader,
-      String myId,
-      final ShardHandlerFactory shardHandlerFactory,
-      String adminPath,
-      Overseer.Stats stats,
-      Overseer overseer,
-      OverseerNodePrioritizer overseerNodePrioritizer) {
-    final OverseerCollectionMessageHandler messageHandler = new OverseerCollectionMessageHandler(
-        zkStateReader, myId, shardHandlerFactory, adminPath, stats, overseer, overseerNodePrioritizer);
-    return new OverseerMessageHandlerSelector() {
-      @Override
-      public OverseerMessageHandler selectOverseerMessageHandler(ZkNodeProps message) {
-        return messageHandler;
-      }
-    };
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/cloud/OverseerCollectionQueue.java b/solr/core/src/java/org/apache/solr/cloud/OverseerCollectionQueue.java
deleted file mode 100644
index 7ab6ba8..0000000
--- a/solr/core/src/java/org/apache/solr/cloud/OverseerCollectionQueue.java
+++ /dev/null
@@ -1,324 +0,0 @@
-package org.apache.solr.cloud;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.util.ArrayList;
-import java.util.List;
-import java.util.Set;
-import java.util.TreeSet;
-
-import org.apache.solr.common.cloud.SolrZkClient;
-import org.apache.solr.common.cloud.ZkNodeProps;
-import org.apache.solr.util.stats.TimerContext;
-import org.apache.zookeeper.CreateMode;
-import org.apache.zookeeper.KeeperException;
-import org.apache.zookeeper.WatchedEvent;
-import org.apache.zookeeper.Watcher;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-/**
- * A {@link DistributedQueue} augmented with helper methods specific to the collection queue.
- * Methods specific to this subclass ignore superclass internal state and hit ZK directly.
- * This is inefficient!  But the API on this class is kind of muddy..
- */
-public class OverseerCollectionQueue extends DistributedQueue {
-  private static final Logger LOG = LoggerFactory.getLogger(OverseerCollectionQueue.class);
-  
-  private final String response_prefix = "qnr-" ;
-
-  public OverseerCollectionQueue(SolrZkClient zookeeper, String dir) {
-    this(zookeeper, dir, new Overseer.Stats());
-  }
-
-  public OverseerCollectionQueue(SolrZkClient zookeeper, String dir, Overseer.Stats stats) {
-    super(zookeeper, dir, stats);
-  }
-  
-  /**
-   * Returns true if the queue contains a task with the specified async id.
-   */
-  public boolean containsTaskWithRequestId(String requestIdKey, String requestId)
-      throws KeeperException, InterruptedException {
-
-    List<String> childNames = zookeeper.getChildren(dir, null, true);
-    stats.setQueueLength(childNames.size());
-    for (String childName : childNames) {
-      if (childName != null) {
-        try {
-          byte[] data = zookeeper.getData(dir + "/" + childName, null, null, true);
-          if (data != null) {
-            ZkNodeProps message = ZkNodeProps.load(data);
-            if (message.containsKey(requestIdKey)) {
-              LOG.debug(">>>> {}", message.get(requestIdKey));
-              if(message.get(requestIdKey).equals(requestId)) return true;
-            }
-          }
-        } catch (KeeperException.NoNodeException e) {
-          // Another client removed the node first, try next
-        }
-      }
-    }
-
-    return false;
-  }
-
-  /**
-   * Remove the event and save the response into the other path.
-   * 
-   */
-  public byte[] remove(QueueEvent event) throws KeeperException,
-      InterruptedException {
-    TimerContext time = stats.time(dir + "_remove_event");
-    try {
-      String path = event.getId();
-      String responsePath = dir + "/" + response_prefix
-          + path.substring(path.lastIndexOf("-") + 1);
-      if (zookeeper.exists(responsePath, true)) {
-        zookeeper.setData(responsePath, event.getBytes(), true);
-      }
-      byte[] data = zookeeper.getData(path, null, null, true);
-      zookeeper.delete(path, -1, true);
-      return data;
-    } finally {
-      time.stop();
-    }
-  }
-
-  /**
-   * Watcher that blocks until a WatchedEvent occurs for a znode.
-   */
-  private final class LatchWatcher implements Watcher {
-
-    private final Object lock;
-    private WatchedEvent event;
-    private Event.EventType latchEventType;
-
-    LatchWatcher(Object lock) {
-      this(lock, null);
-    }
-
-    LatchWatcher(Event.EventType eventType) {
-      this(new Object(), eventType);
-    }
-
-    LatchWatcher(Object lock, Event.EventType eventType) {
-      this.lock = lock;
-      this.latchEventType = eventType;
-    }
-
-    @Override
-    public void process(WatchedEvent event) {
-      Event.EventType eventType = event.getType();
-      // None events are ignored
-      // If latchEventType is not null, only fire if the type matches
-      if (eventType != Event.EventType.None && (latchEventType == null || eventType == latchEventType)) {
-        LOG.info("{} fired on path {} state {}", eventType, event.getPath(), event.getState());
-        synchronized (lock) {
-          this.event = event;
-          lock.notifyAll();
-        }
-      }
-    }
-
-    public void await(long timeout) throws InterruptedException {
-      synchronized (lock) {
-        if (this.event != null) return;
-        lock.wait(timeout);
-      }
-    }
-
-    public WatchedEvent getWatchedEvent() {
-      return event;
-    }
-  }
-
-  /**
-   * Inserts data into zookeeper.
-   * 
-   * @return true if data was successfully added
-   */
-  private String createData(String path, byte[] data, CreateMode mode)
-      throws KeeperException, InterruptedException {
-    for (;;) {
-      try {
-        return zookeeper.create(path, data, mode, true);
-      } catch (KeeperException.NoNodeException e) {
-        try {
-          zookeeper.create(dir, new byte[0], CreateMode.PERSISTENT, true);
-        } catch (KeeperException.NodeExistsException ne) {
-          // someone created it
-        }
-      }
-    }
-  }
-  
-  /**
-   * Offer the data and wait for the response
-   * 
-   */
-  public QueueEvent offer(byte[] data, long timeout) throws KeeperException,
-      InterruptedException {
-    TimerContext time = stats.time(dir + "_offer");
-    try {
-      String path = createData(dir + "/" + PREFIX, data,
-          CreateMode.PERSISTENT_SEQUENTIAL);
-      String watchID = createData(
-          dir + "/" + response_prefix + path.substring(path.lastIndexOf("-") + 1),
-          null, CreateMode.EPHEMERAL);
-
-      Object lock = new Object();
-      LatchWatcher watcher = new LatchWatcher(lock);
-      synchronized (lock) {
-        if (zookeeper.exists(watchID, watcher, true) != null) {
-          watcher.await(timeout);
-        }
-      }
-      byte[] bytes = zookeeper.getData(watchID, null, null, true);
-      zookeeper.delete(watchID, -1, true);
-      return new QueueEvent(watchID, bytes, watcher.getWatchedEvent());
-    } finally {
-      time.stop();
-    }
-  }
-
-  public List<QueueEvent> peekTopN(int n, Set<String> excludeSet, long waitMillis)
-      throws KeeperException, InterruptedException {
-    ArrayList<QueueEvent> topN = new ArrayList<>();
-
-    LOG.debug("Peeking for top {} elements. ExcludeSet: {}", n, excludeSet);
-    TimerContext time = null;
-    if (waitMillis == Long.MAX_VALUE) time = stats.time(dir + "_peekTopN_wait_forever");
-    else time = stats.time(dir + "_peekTopN_wait" + waitMillis);
-
-    try {
-      for (String headNode : getChildren(waitMillis)) {
-        if (topN.size() < n) {
-          try {
-            String id = dir + "/" + headNode;
-            if (excludeSet.contains(id)) continue;
-            QueueEvent queueEvent = new QueueEvent(id,
-                zookeeper.getData(dir + "/" + headNode, null, null, true), null);
-            topN.add(queueEvent);
-          } catch (KeeperException.NoNodeException e) {
-            // Another client removed the node first, try next
-          }
-        } else {
-          if (topN.size() >= 1) {
-            printQueueEventsListElementIds(topN);
-            return topN;
-          }
-        }
-      }
-
-      if (topN.size() > 0 ) {
-        printQueueEventsListElementIds(topN);
-        return topN;
-      }
-      return null;
-    } finally {
-      time.stop();
-    }
-  }
-
-  private static void printQueueEventsListElementIds(ArrayList<QueueEvent> topN) {
-    if(LOG.isDebugEnabled()) {
-      StringBuffer sb = new StringBuffer("[");
-      for(QueueEvent queueEvent: topN) {
-        sb.append(queueEvent.getId()).append(", ");
-      }
-      sb.append("]");
-      LOG.debug("Returning topN elements: {}", sb.toString());
-    }
-  }
-
-
-  /**
-   *
-   * Gets last element of the Queue without removing it.
-   */
-  public String getTailId() throws KeeperException, InterruptedException {
-    // TODO: could we use getChildren here?  Unsure what freshness guarantee the caller needs.
-    TreeSet<String> orderedChildren = fetchZkChildren(null);
-
-    for (String headNode : orderedChildren.descendingSet())
-      if (headNode != null) {
-        try {
-          QueueEvent queueEvent = new QueueEvent(dir + "/" + headNode, zookeeper.getData(dir + "/" + headNode,
-              null, null, true), null);
-          return queueEvent.getId();
-        } catch (KeeperException.NoNodeException e) {
-          // Another client removed the node first, try next
-        }
-      }
-    return null;
-  }
-  
-  public static class QueueEvent {
-    @Override
-    public int hashCode() {
-      final int prime = 31;
-      int result = 1;
-      result = prime * result + ((id == null) ? 0 : id.hashCode());
-      return result;
-    }
-    
-    @Override
-    public boolean equals(Object obj) {
-      if (this == obj) return true;
-      if (obj == null) return false;
-      if (getClass() != obj.getClass()) return false;
-      QueueEvent other = (QueueEvent) obj;
-      if (id == null) {
-        if (other.id != null) return false;
-      } else if (!id.equals(other.id)) return false;
-      return true;
-    }
-    
-    private WatchedEvent event = null;
-    private String id;
-    private byte[] bytes;
-    
-    QueueEvent(String id, byte[] bytes, WatchedEvent event) {
-      this.id = id;
-      this.bytes = bytes;
-      this.event = event;
-    }
-    
-    public void setId(String id) {
-      this.id = id;
-    }
-    
-    public String getId() {
-      return id;
-    }
-    
-    public void setBytes(byte[] bytes) {
-      this.bytes = bytes;
-    }
-    
-    public byte[] getBytes() {
-      return bytes;
-    }
-    
-    public WatchedEvent getWatchedEvent() {
-      return event;
-    }
-    
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/cloud/OverseerConfigSetMessageHandler.java b/solr/core/src/java/org/apache/solr/cloud/OverseerConfigSetMessageHandler.java
new file mode 100644
index 0000000..f618fa0
--- /dev/null
+++ b/solr/core/src/java/org/apache/solr/cloud/OverseerConfigSetMessageHandler.java
@@ -0,0 +1,365 @@
+package org.apache.solr.cloud;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.ByteArrayInputStream;
+import java.io.IOException;
+import java.io.InputStreamReader;
+import java.nio.charset.StandardCharsets;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.Map;
+import java.util.Set;
+
+import org.apache.solr.client.solrj.SolrResponse;
+import org.apache.solr.common.SolrException;
+import org.apache.solr.common.SolrException.ErrorCode;
+import org.apache.solr.common.cloud.SolrZkClient;
+import org.apache.solr.common.cloud.ZkConfigManager;
+import org.apache.solr.common.cloud.ZkNodeProps;
+import org.apache.solr.common.cloud.ZkStateReader;
+import org.apache.solr.common.params.ConfigSetParams;
+import org.apache.solr.common.util.NamedList;
+import org.apache.solr.common.util.SimpleOrderedMap;
+import org.apache.solr.core.ConfigSetProperties;
+import org.apache.zookeeper.CreateMode;
+import org.apache.zookeeper.KeeperException;
+import org.noggit.JSONUtil;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import static org.apache.solr.cloud.OverseerMessageHandler.ExclusiveMarking.NONEXCLUSIVE;
+import static org.apache.solr.cloud.OverseerMessageHandler.ExclusiveMarking.NOTDETERMINED;
+import static org.apache.solr.common.params.ConfigSetParams.ConfigSetAction.CREATE;
+import static org.apache.solr.common.params.ConfigSetParams.ConfigSetAction.DELETE;
+import static org.apache.solr.common.params.CommonParams.NAME;
+
+/**
+ * A {@link OverseerMessageHandler} that handles ConfigSets API related
+ * overseer messages.
+ */
+public class OverseerConfigSetMessageHandler implements OverseerMessageHandler {
+
+  /**
+   * Prefix to specify an action should be handled by this handler.
+   */
+  public static final String CONFIGSETS_ACTION_PREFIX = "configsets:";
+
+  /**
+   * Name of the ConfigSet to copy from for CREATE
+   */
+  public static final String BASE_CONFIGSET = "baseConfigSet";
+
+  /**
+   * Prefix for properties that should be applied to the ConfigSet for CREATE
+   */
+  public static final String PROPERTY_PREFIX = "configSetProp";
+
+  private ZkStateReader zkStateReader;
+
+  // we essentially implement a read/write lock for the ConfigSet exclusivity as follows:
+  // WRITE: CREATE/DELETE on the ConfigSet under operation
+  // READ: for the Base ConfigSet being copied in CREATE.
+  // in this way, we prevent a Base ConfigSet from being deleted while it is being copied
+  // but don't prevent different ConfigSets from being created with the same Base ConfigSet
+  // at the same time.
+  final private Set configSetWriteWip;
+  final private Set configSetReadWip;
+
+  private static Logger log = LoggerFactory
+      .getLogger(OverseerConfigSetMessageHandler.class);
+
+  public OverseerConfigSetMessageHandler(ZkStateReader zkStateReader) {
+    this.zkStateReader = zkStateReader;
+    this.configSetWriteWip = new HashSet();
+    this.configSetReadWip = new HashSet();
+  }
+
+  @Override
+  public SolrResponse processMessage(ZkNodeProps message, String operation) {
+    NamedList results = new NamedList();
+    try {
+      if (!operation.startsWith(CONFIGSETS_ACTION_PREFIX)) {
+        throw new SolrException(ErrorCode.BAD_REQUEST,
+            "Operation does not contain proper prefix: " + operation
+            + " expected: " + CONFIGSETS_ACTION_PREFIX);
+      }
+      operation = operation.substring(CONFIGSETS_ACTION_PREFIX.length());
+      log.info("OverseerConfigSetMessageHandler.processMessage : "+ operation + " , "+ message.toString());
+
+      ConfigSetParams.ConfigSetAction action = ConfigSetParams.ConfigSetAction.get(operation);
+      if (action == null) {
+        throw new SolrException(ErrorCode.BAD_REQUEST, "Unknown operation:" + operation);
+      }
+      switch (action) {
+        case CREATE:
+          createConfigSet(message);
+          break;
+        case DELETE:
+          deleteConfigSet(message);
+          break;
+        default:
+          throw new SolrException(ErrorCode.BAD_REQUEST, "Unknown operation:"
+              + operation);
+      }
+    } catch (Exception e) {
+      String configSetName = message.getStr(NAME);
+
+      if (configSetName == null) {
+        SolrException.log(log, "Operation " + operation + " failed", e);
+      } else  {
+        SolrException.log(log, "ConfigSet: " + configSetName + " operation: " + operation
+            + " failed", e);
+      }
+
+      results.add("Operation " + operation + " caused exception:", e);
+      SimpleOrderedMap nl = new SimpleOrderedMap();
+      nl.add("msg", e.getMessage());
+      nl.add("rspCode", e instanceof SolrException ? ((SolrException)e).code() : -1);
+      results.add("exception", nl);
+    }
+    return new OverseerSolrResponse(results);
+  }
+
+  @Override
+  public String getName() {
+    return "Overseer ConfigSet Message Handler";
+  }
+
+  @Override
+  public String getTimerName(String operation) {
+    return "configset_" + operation;
+  }
+
+  @Override
+  public String getTaskKey(ZkNodeProps message) {
+    return message.getStr(NAME);
+  }
+
+  @Override
+  public void markExclusiveTask(String configSetName, ZkNodeProps message) {
+    String baseConfigSet = getBaseConfigSetIfCreate(message);
+    markExclusive(configSetName, baseConfigSet);
+  }
+
+  private void markExclusive(String configSetName, String baseConfigSetName) {
+    synchronized (configSetWriteWip) {
+      configSetWriteWip.add(configSetName);
+      if (baseConfigSetName != null) configSetReadWip.add(baseConfigSetName);
+    }
+  }
+
+  @Override
+  public void unmarkExclusiveTask(String configSetName, String operation, ZkNodeProps message) {
+    String baseConfigSet = getBaseConfigSetIfCreate(message);
+    unmarkExclusiveConfigSet(configSetName, baseConfigSet);
+  }
+
+  private void unmarkExclusiveConfigSet(String configSetName, String baseConfigSetName) {
+    synchronized (configSetWriteWip) {
+      configSetWriteWip.remove(configSetName);
+      if (baseConfigSetName != null) configSetReadWip.remove(baseConfigSetName);
+    }
+  }
+
+  @Override
+  public ExclusiveMarking checkExclusiveMarking(String configSetName, ZkNodeProps message) {
+    String baseConfigSet = getBaseConfigSetIfCreate(message);
+    return checkExclusiveMarking(configSetName, baseConfigSet);
+  }
+
+  private ExclusiveMarking checkExclusiveMarking(String configSetName, String baseConfigSetName) {
+    synchronized (configSetWriteWip) {
+      // need to acquire:
+      // 1) write lock on ConfigSet
+      // 2) read lock on Base ConfigSet
+      if (configSetWriteWip.contains(configSetName) || configSetReadWip.contains(configSetName)) {
+        return NONEXCLUSIVE;
+      }
+      if (baseConfigSetName != null && configSetWriteWip.contains(baseConfigSetName)) {
+        return NONEXCLUSIVE;
+      }
+    }
+
+    return NOTDETERMINED;
+  }
+
+  private String getBaseConfigSetIfCreate(ZkNodeProps message) {
+    String operation = message.getStr(Overseer.QUEUE_OPERATION);
+    if (operation != null) {
+      operation = operation.substring(CONFIGSETS_ACTION_PREFIX.length());
+      ConfigSetParams.ConfigSetAction action = ConfigSetParams.ConfigSetAction.get(operation);
+      if (action == CREATE) {
+        return message.getStr(BASE_CONFIGSET);
+      }
+    }
+    return null;
+  }
+
+  private NamedList getConfigSetProperties(String path) throws IOException {
+    byte [] oldPropsData = null;
+    try {
+     oldPropsData = zkStateReader.getZkClient().getData(path, null, null, true);
+    } catch (KeeperException.NoNodeException e) {
+      log.info("no existing ConfigSet properties found");
+    } catch (KeeperException | InterruptedException e) {
+      throw new IOException("Error reading old properties",
+          SolrZkClient.checkInterrupted(e));
+    }
+
+    if (oldPropsData != null) {
+      InputStreamReader reader = new InputStreamReader(new ByteArrayInputStream(oldPropsData), StandardCharsets.UTF_8);
+      try {
+        return ConfigSetProperties.readFromInputStream(reader);
+      } finally {
+        reader.close();
+      }
+    }
+    return null;
+  }
+
+  private Map<String, Object> getNewProperties(ZkNodeProps message) {
+    Map<String, Object> properties = null;
+    for (Map.Entry<String, Object> entry : message.getProperties().entrySet()) {
+      if (entry.getKey().startsWith(PROPERTY_PREFIX + ".")) {
+        if (properties == null) {
+          properties = new HashMap<String, Object>();
+        }
+        properties.put(entry.getKey().substring((PROPERTY_PREFIX + ".").length()),
+            entry.getValue());
+      }
+    }
+    return properties;
+  }
+
+  private void mergeOldProperties(Map<String, Object> newProps, NamedList oldProps) {
+    Iterator<Map.Entry<String, Object>> it = oldProps.iterator();
+    while (it.hasNext()) {
+      Map.Entry<String, Object> oldEntry = it.next();
+      if (!newProps.containsKey(oldEntry.getKey())) {
+        newProps.put(oldEntry.getKey(), oldEntry.getValue());
+      }
+    }
+  }
+
+  private byte[] getPropertyData(Map<String, Object> newProps) {
+    if (newProps != null) {
+      String propertyDataStr = JSONUtil.toJSON(newProps);
+      if (propertyDataStr == null) {
+        throw new SolrException(ErrorCode.BAD_REQUEST, "Invalid property specification");
+      }
+      return propertyDataStr.getBytes(StandardCharsets.UTF_8);
+    }
+    return null;
+  }
+
+  private String getPropertyPath(String configName, String propertyPath) {
+    return ZkConfigManager.CONFIGS_ZKNODE + "/" + configName + "/" + propertyPath;
+  }
+
+  private void createConfigSet(ZkNodeProps message) throws IOException {
+    String configSetName = getTaskKey(message);
+    if (configSetName == null || configSetName.length() == 0) {
+      throw new SolrException(ErrorCode.BAD_REQUEST, "ConfigSet name not specified");
+    }
+
+    String baseConfigSetName = message.getStr(BASE_CONFIGSET);
+    if (baseConfigSetName == null || baseConfigSetName.length() == 0) {
+      throw new SolrException(ErrorCode.BAD_REQUEST, "Base ConfigSet name not specified");
+    }
+
+    ZkConfigManager configManager = new ZkConfigManager(zkStateReader.getZkClient());
+    if (configManager.configExists(configSetName)) {
+      throw new SolrException(ErrorCode.BAD_REQUEST, "ConfigSet already exists: " + configSetName);
+    }
+
+    // is there a base config that already exists
+    if (!configManager.configExists(baseConfigSetName)) {
+      throw new SolrException(ErrorCode.BAD_REQUEST,
+          "Base ConfigSet does not exist: " + baseConfigSetName);
+    }
+
+    String propertyPath = ConfigSetProperties.DEFAULT_FILENAME;
+    Map<String, Object> props = getNewProperties(message);
+    if (props != null) {
+      // read the old config properties and do a merge, if necessary
+      NamedList oldProps = getConfigSetProperties(getPropertyPath(baseConfigSetName,propertyPath));
+      if (oldProps != null) {
+        mergeOldProperties(props, oldProps);
+      }
+    }
+    byte[] propertyData = getPropertyData(props);
+
+    Set<String> copiedToZkPaths = new HashSet<String>();
+    try {
+      configManager.copyConfigDir(baseConfigSetName, configSetName, copiedToZkPaths);
+      if (propertyData != null) {
+        try {
+          zkStateReader.getZkClient().makePath(
+              getPropertyPath(configSetName, propertyPath),
+                  propertyData, CreateMode.PERSISTENT, null, false, true);
+        } catch (KeeperException | InterruptedException e) {
+          throw new IOException("Error writing new properties",
+              SolrZkClient.checkInterrupted(e));
+        }
+      }
+    } catch (Exception e) {
+      // copying the config dir or writing the properties file may have failed.
+      // we should delete the ConfigSet because it may be invalid,
+      // assuming we actually wrote something.  E.g. could be
+      // the entire baseConfig set with the old properties, including immutable,
+      // that would make it impossible for the user to delete.
+      try {
+        if (configManager.configExists(configSetName) && copiedToZkPaths.size() > 0) {
+          deleteConfigSet(configSetName, true);
+        }
+      } catch (IOException ioe) {
+        log.error("Error while trying to delete partially created ConfigSet", ioe);
+      }
+      throw e;
+    }
+  }
+
+  private void deleteConfigSet(ZkNodeProps message) throws IOException {
+    String configSetName = getTaskKey(message);
+    if (configSetName == null || configSetName.length() == 0) {
+      throw new SolrException(ErrorCode.BAD_REQUEST, "ConfigSet name not specified");
+    }
+
+    deleteConfigSet(configSetName, false);
+  }
+
+  private void deleteConfigSet(String configSetName, boolean force) throws IOException {
+    ZkConfigManager configManager = new ZkConfigManager(zkStateReader.getZkClient());
+    if (!configManager.configExists(configSetName)) {
+      throw new SolrException(ErrorCode.BAD_REQUEST, "ConfigSet does not exist to delete: " + configSetName);
+    }
+
+    String propertyPath = ConfigSetProperties.DEFAULT_FILENAME;
+    NamedList properties = getConfigSetProperties(getPropertyPath(configSetName, propertyPath));
+    if (properties != null) {
+      Object immutable = properties.get(ConfigSetProperties.IMMUTABLE_CONFIGSET_ARG);
+      boolean isImmutableConfigSet = immutable  != null ? Boolean.parseBoolean(immutable.toString()) : false;
+      if (!force && isImmutableConfigSet) {
+        throw new SolrException(ErrorCode.BAD_REQUEST, "Requested delete of immutable ConfigSet: " + configSetName);
+      }
+    }
+    configManager.deleteConfigDir(configSetName);
+  }
+}
diff --git a/solr/core/src/java/org/apache/solr/cloud/OverseerMessageHandler.java b/solr/core/src/java/org/apache/solr/cloud/OverseerMessageHandler.java
index c066b24..e374b47 100644
--- a/solr/core/src/java/org/apache/solr/cloud/OverseerMessageHandler.java
+++ b/solr/core/src/java/org/apache/solr/cloud/OverseerMessageHandler.java
@@ -21,7 +21,7 @@ import org.apache.solr.client.solrj.SolrResponse;
 import org.apache.solr.common.cloud.ZkNodeProps;
 
 /**
- * Interface for processing messages received by an {@link OverseerProcessor}
+ * Interface for processing messages received by an {@link OverseerTaskProcessor}
  */
 public interface OverseerMessageHandler {
 
@@ -61,8 +61,9 @@ public interface OverseerMessageHandler {
   /**
    * @param taskKey the key associated with the task
    * @param operation the operation being processed
+   * @param message the message being processed
    */
-  void unmarkExclusiveTask(String taskKey, String operation);
+  void unmarkExclusiveTask(String taskKey, String operation, ZkNodeProps message);
 
   /**
    * @param taskKey the key associated with the task
diff --git a/solr/core/src/java/org/apache/solr/cloud/OverseerNodePrioritizer.java b/solr/core/src/java/org/apache/solr/cloud/OverseerNodePrioritizer.java
index aea9251..7cd7129 100644
--- a/solr/core/src/java/org/apache/solr/cloud/OverseerNodePrioritizer.java
+++ b/solr/core/src/java/org/apache/solr/cloud/OverseerNodePrioritizer.java
@@ -61,10 +61,10 @@ public class OverseerNodePrioritizer {
 
     List overseerDesignates = (List) m.get("overseer");
     if(overseerDesignates==null || overseerDesignates.isEmpty()) return;
-    String ldr = OverseerProcessor.getLeaderNode(zk);
+    String ldr = OverseerTaskProcessor.getLeaderNode(zk);
     if(overseerDesignates.contains(ldr)) return;
     log.info("prioritizing overseer nodes at {} overseer designates are {}", overseerId, overseerDesignates);
-    List<String> electionNodes = OverseerProcessor.getSortedElectionNodes(zk, OverseerElectionContext.PATH + LeaderElector.ELECTION_NODE);
+    List<String> electionNodes = OverseerTaskProcessor.getSortedElectionNodes(zk, OverseerElectionContext.PATH + LeaderElector.ELECTION_NODE);
     if(electionNodes.size()<2) return;
     log.info("sorted nodes {}", electionNodes);
 
@@ -89,7 +89,7 @@ public class OverseerNodePrioritizer {
     //now ask the current leader to QUIT , so that the designate can takeover
     Overseer.getInQueue(zkStateReader.getZkClient()).offer(
         Utils.toJSON(new ZkNodeProps(Overseer.QUEUE_OPERATION, OverseerAction.QUIT.toLower(),
-            "id", OverseerProcessor.getLeaderId(zkStateReader.getZkClient()))));
+            "id", OverseerTaskProcessor.getLeaderId(zkStateReader.getZkClient()))));
 
   }
 
diff --git a/solr/core/src/java/org/apache/solr/cloud/OverseerProcessor.java b/solr/core/src/java/org/apache/solr/cloud/OverseerProcessor.java
deleted file mode 100644
index 18cd335..0000000
--- a/solr/core/src/java/org/apache/solr/cloud/OverseerProcessor.java
+++ /dev/null
@@ -1,561 +0,0 @@
-package org.apache.solr.cloud;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Closeable;
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
-import java.util.concurrent.ExecutorService;
-import java.util.concurrent.SynchronousQueue;
-import java.util.concurrent.TimeUnit;
-
-import org.apache.solr.client.solrj.SolrResponse;
-import org.apache.solr.cloud.OverseerCollectionQueue.QueueEvent;
-import org.apache.solr.cloud.Overseer.LeaderStatus;
-import org.apache.solr.common.SolrException;
-import org.apache.solr.common.cloud.SolrZkClient;
-import org.apache.solr.common.cloud.ZkNodeProps;
-import org.apache.solr.common.cloud.ZkStateReader;
-import org.apache.solr.common.util.ExecutorUtil;
-import org.apache.solr.common.util.Utils;
-import org.apache.solr.handler.component.ShardHandlerFactory;
-import org.apache.solr.util.DefaultSolrThreadFactory;
-import org.apache.solr.util.stats.TimerContext;
-import org.apache.zookeeper.KeeperException;
-import org.apache.zookeeper.data.Stat;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import static org.apache.solr.common.params.CommonAdminParams.ASYNC;
-
-/**
- * A generic processor run in the Overseer, used for handling items added
- * to a distributed work queue.  Has support for handling exclusive tasks
- * (i.e. tasks that should not run in parallel with each other).
- *
- * An {@link OverseerMessageHandlerSelector} determines which
- * {@link OverseerMessageHandler} handles specific messages in the
- * queue.
- */
-public class OverseerProcessor implements Runnable, Closeable {
-
-  public int maxParallelThreads = 10;
-
-  public ExecutorService tpe ;
-
-  private static Logger log = LoggerFactory
-      .getLogger(OverseerProcessor.class);
-
-  private OverseerCollectionQueue workQueue;
-  private DistributedMap runningMap;
-  private DistributedMap completedMap;
-  private DistributedMap failureMap;
-
-  // Set that maintains a list of all the tasks that are running. This is keyed on zk id of the task.
-  final private Set runningTasks;
-
-  // List of completed tasks. This is used to clean up workQueue in zk.
-  final private HashMap<String, QueueEvent> completedTasks;
-
-  private String myId;
-
-  private final ShardHandlerFactory shardHandlerFactory;
-
-  private String adminPath;
-
-  private ZkStateReader zkStateReader;
-
-  private boolean isClosed;
-
-  private Overseer.Stats stats;
-
-  // Set of tasks that have been picked up for processing but not cleaned up from zk work-queue.
-  // It may contain tasks that have completed execution, have been entered into the completed/failed map in zk but not
-  // deleted from the work-queue as that is a batched operation.
-  final private Set<String> runningZKTasks;
-  private final Object waitLock = new Object();
-
-  private OverseerMessageHandlerSelector selector;
-
-  private OverseerNodePrioritizer prioritizer;
-
-  public OverseerProcessor(ZkStateReader zkStateReader, String myId,
-                                        final ShardHandlerFactory shardHandlerFactory,
-                                        String adminPath,
-                                        Overseer.Stats stats,
-                                        OverseerMessageHandlerSelector selector,
-                                        OverseerNodePrioritizer prioritizer,
-                                        OverseerCollectionQueue workQueue,
-                                        DistributedMap runningMap,
-                                        DistributedMap completedMap,
-                                        DistributedMap failureMap) {
-    this.zkStateReader = zkStateReader;
-    this.myId = myId;
-    this.shardHandlerFactory = shardHandlerFactory;
-    this.adminPath = adminPath;
-    this.stats = stats;
-    this.selector = selector;
-    this.prioritizer = prioritizer;
-    this.workQueue = workQueue;
-    this.runningMap = runningMap;
-    this.completedMap = completedMap;
-    this.failureMap = failureMap;
-    this.runningZKTasks = new HashSet<>();
-    this.runningTasks = new HashSet();
-    this.completedTasks = new HashMap<>();
-  }
-
-  @Override
-  public void run() {
-    log.info("Process current queue of overseer operations");
-    LeaderStatus isLeader = amILeader();
-    while (isLeader == LeaderStatus.DONT_KNOW) {
-      log.debug("am_i_leader unclear {}", isLeader);
-      isLeader = amILeader();  // not a no, not a yes, try ask again
-    }
-
-    String oldestItemInWorkQueue = null;
-    // hasLeftOverItems - used for avoiding re-execution of async tasks that were processed by a previous Overseer.
-    // This variable is set in case there's any task found on the workQueue when the OCP starts up and
-    // the id for the queue tail is used as a marker to check for the task in completed/failed map in zk.
-    // Beyond the marker, all tasks can safely be assumed to have never been executed.
-    boolean hasLeftOverItems = true;
-
-    try {
-      oldestItemInWorkQueue = workQueue.getTailId();
-    } catch (KeeperException e) {
-      // We don't need to handle this. This is just a fail-safe which comes in handy in skipping already processed
-      // async calls.
-      SolrException.log(log, "", e);
-    } catch (InterruptedException e) {
-      Thread.currentThread().interrupt();
-    }
-
-    if (oldestItemInWorkQueue == null)
-      hasLeftOverItems = false;
-    else
-      log.debug("Found already existing elements in the work-queue. Last element: {}", oldestItemInWorkQueue);
-
-    try {
-      prioritizer.prioritizeOverseerNodes(myId);
-    } catch (Exception e) {
-      log.error("Unable to prioritize overseer ", e);
-    }
-
-    // TODO: Make maxThreads configurable.
-
-    this.tpe = new ExecutorUtil.MDCAwareThreadPoolExecutor(5, 100, 0L, TimeUnit.MILLISECONDS,
-        new SynchronousQueue<Runnable>(),
-        new DefaultSolrThreadFactory("OverseerThreadFactory"));
-    try {
-      while (!this.isClosed) {
-        try {
-          isLeader = amILeader();
-          if (LeaderStatus.NO == isLeader) {
-            break;
-          } else if (LeaderStatus.YES != isLeader) {
-            log.debug("am_i_leader unclear {}", isLeader);
-            continue; // not a no, not a yes, try asking again
-          }
-
-          log.debug("Cleaning up work-queue. #Running tasks: {}", runningTasks.size());
-          cleanUpWorkQueue();
-
-          printTrackingMaps();
-
-          boolean waited = false;
-
-          while (runningTasks.size() > maxParallelThreads) {
-            synchronized (waitLock) {
-              waitLock.wait(100);//wait for 100 ms or till a task is complete
-            }
-            waited = true;
-          }
-
-          if (waited)
-            cleanUpWorkQueue();
-
-          List<QueueEvent> heads = workQueue.peekTopN(maxParallelThreads, runningZKTasks, 2000L);
-
-          if (heads == null)
-            continue;
-
-          log.debug("Got {} tasks from work-queue : [{}]", heads.size(), heads.toString());
-
-          if (isClosed) break;
-
-          for (QueueEvent head : heads) {
-            final ZkNodeProps message = ZkNodeProps.load(head.getBytes());
-            OverseerMessageHandler messageHandler = selector.selectOverseerMessageHandler(message);
-            String taskKey = messageHandler.getTaskKey(message);
-            final String asyncId = message.getStr(ASYNC);
-            if (hasLeftOverItems) {
-              if (head.getId().equals(oldestItemInWorkQueue))
-                hasLeftOverItems = false;
-              if (asyncId != null && (completedMap.contains(asyncId) || failureMap.contains(asyncId))) {
-                log.debug("Found already processed task in workQueue, cleaning up. AsyncId [{}]",asyncId );
-                workQueue.remove(head);
-                continue;
-              }
-            }
-
-            if (!checkExclusivity(messageHandler, message, head.getId())) {
-              log.debug("Exclusivity check failed for [{}]", message.toString());
-              continue;
-            }
-
-            try {
-              markTaskAsRunning(messageHandler, head, taskKey, asyncId, message);
-              log.debug("Marked task [{}] as running", head.getId());
-            } catch (KeeperException.NodeExistsException e) {
-              // This should never happen
-              log.error("Tried to pick up task [{}] when it was already running!", head.getId());
-            } catch (InterruptedException e) {
-              log.error("Thread interrupted while trying to pick task for execution.", head.getId());
-              Thread.currentThread().interrupt();
-            }
-
-            log.info(messageHandler.getName() + ": Get the message id:" + head.getId() + " message:" + message.toString());
-            String operation = message.getStr(Overseer.QUEUE_OPERATION);
-            Runner runner = new Runner(messageHandler, message,
-                operation, head);
-            tpe.execute(runner);
-          }
-
-        } catch (KeeperException e) {
-          if (e.code() == KeeperException.Code.SESSIONEXPIRED) {
-            log.warn("Overseer cannot talk to ZK");
-            return;
-          }
-          SolrException.log(log, "", e);
-        } catch (InterruptedException e) {
-          Thread.currentThread().interrupt();
-          return;
-        } catch (Exception e) {
-          SolrException.log(log, "", e);
-        }
-      }
-    } finally {
-      this.close();
-    }
-  }
-
-  protected boolean checkExclusivity(OverseerMessageHandler messageHandler, ZkNodeProps message, String id)
-      throws KeeperException, InterruptedException {
-    String taskKey = messageHandler.getTaskKey(message);
-
-    if(taskKey == null)
-      return true;
-
-    OverseerMessageHandler.ExclusiveMarking marking = messageHandler.checkExclusiveMarking(taskKey, message);
-    switch (marking) {
-      case NOTDETERMINED:
-        break;
-      case EXCLUSIVE:
-        return true;
-      case NONEXCLUSIVE:
-        return false;
-      default:
-        throw new IllegalArgumentException("Undefined marking: " + marking);
-    }
-
-    if(runningZKTasks.contains(id))
-      return false;
-
-    return true;
-  }
-
-  private void cleanUpWorkQueue() throws KeeperException, InterruptedException {
-    synchronized (completedTasks) {
-      for (String id : completedTasks.keySet()) {
-        workQueue.remove(completedTasks.get(id));
-        runningZKTasks.remove(id);
-      }
-      completedTasks.clear();
-    }
-  }
-
-  public void close() {
-    isClosed = true;
-    if(tpe != null) {
-      if (!tpe.isShutdown()) {
-        ExecutorUtil.shutdownAndAwaitTermination(tpe);
-      }
-    }
-  }
-
-  public static List<String> getSortedOverseerNodeNames(SolrZkClient zk) throws KeeperException, InterruptedException {
-    List<String> children = null;
-    try {
-      children = zk.getChildren(OverseerElectionContext.PATH + LeaderElector.ELECTION_NODE, null, true);
-    } catch (Exception e) {
-      log.warn("error ", e);
-      return new ArrayList<>();
-    }
-    LeaderElector.sortSeqs(children);
-    ArrayList<String> nodeNames = new ArrayList<>(children.size());
-    for (String c : children) nodeNames.add(LeaderElector.getNodeName(c));
-    return nodeNames;
-  }
-
-  public static List<String> getSortedElectionNodes(SolrZkClient zk, String path) throws KeeperException, InterruptedException {
-    List<String> children = null;
-    try {
-      children = zk.getChildren(path, null, true);
-      LeaderElector.sortSeqs(children);
-      return children;
-    } catch (Exception e) {
-      throw e;
-    }
-
-  }
-
-  public static String getLeaderNode(SolrZkClient zkClient) throws KeeperException, InterruptedException {
-    String id = getLeaderId(zkClient);
-    return id==null ?
-        null:
-        LeaderElector.getNodeName( id);
-  }
-
-  public static String getLeaderId(SolrZkClient zkClient) throws KeeperException,InterruptedException{
-    byte[] data = null;
-    try {
-      data = zkClient.getData("/overseer_elect/leader", null, new Stat(), true);
-    } catch (KeeperException.NoNodeException e) {
-      return null;
-    }
-    Map m = (Map) Utils.fromJSON(data);
-    return  (String) m.get("id");
-  }
-
-  protected LeaderStatus amILeader() {
-    String statsName = "collection_am_i_leader";
-    TimerContext timerContext = stats.time(statsName);
-    boolean success = true;
-    try {
-      ZkNodeProps props = ZkNodeProps.load(zkStateReader.getZkClient().getData(
-          "/overseer_elect/leader", null, null, true));
-      if (myId.equals(props.getStr("id"))) {
-        return LeaderStatus.YES;
-      }
-    } catch (KeeperException e) {
-      success = false;
-      if (e.code() == KeeperException.Code.CONNECTIONLOSS) {
-        log.error("", e);
-        return LeaderStatus.DONT_KNOW;
-      } else if (e.code() == KeeperException.Code.SESSIONEXPIRED) {
-        log.info("", e);
-      } else {
-        log.warn("", e);
-      }
-    } catch (InterruptedException e) {
-      success = false;
-      Thread.currentThread().interrupt();
-    } finally {
-      timerContext.stop();
-      if (success)  {
-        stats.success(statsName);
-      } else  {
-        stats.error(statsName);
-      }
-    }
-    log.info("According to ZK I (id=" + myId + ") am no longer a leader.");
-    return LeaderStatus.NO;
-  }
-
-  public boolean isClosed() {
-    return isClosed;
-  }
-
-  @SuppressWarnings("unchecked")
-  private void markTaskAsRunning(OverseerMessageHandler messageHandler, QueueEvent head, String taskKey,
-                                 String asyncId, ZkNodeProps message)
-      throws KeeperException, InterruptedException {
-    synchronized (runningZKTasks) {
-      runningZKTasks.add(head.getId());
-    }
-
-    synchronized (runningTasks) {
-      runningTasks.add(head.getId());
-    }
-
-    messageHandler.markExclusiveTask(taskKey, message);
-
-    if(asyncId != null)
-      runningMap.put(asyncId, null);
-  }
-  
-  protected class Runner implements Runnable {
-    ZkNodeProps message;
-    String operation;
-    SolrResponse response;
-    QueueEvent head;
-    OverseerMessageHandler messageHandler;
-  
-    public Runner(OverseerMessageHandler messageHandler, ZkNodeProps message, String operation, QueueEvent head) {
-      this.message = message;
-      this.operation = operation;
-      this.head = head;
-      this.messageHandler = messageHandler;
-      response = null;
-    }
-
-
-    public void run() {
-      String statsName = messageHandler.getTimerName(operation);
-      final TimerContext timerContext = stats.time(statsName);
-
-      boolean success = false;
-      final String asyncId = message.getStr(ASYNC);
-      String taskKey = messageHandler.getTaskKey(message);
-
-      try {
-        try {
-          log.debug("Runner processing {}", head.getId());
-          response = messageHandler.processMessage(message, operation);
-        } finally {
-          timerContext.stop();
-          updateStats(statsName);
-        }
-
-        if(asyncId != null) {
-          if (response != null && (response.getResponse().get("failure") != null 
-              || response.getResponse().get("exception") != null)) {
-            failureMap.put(asyncId, SolrResponse.serializable(response));
-            log.debug("Updated failed map for task with zkid:[{}]", head.getId());
-          } else {
-            completedMap.put(asyncId, SolrResponse.serializable(response));
-            log.debug("Updated completed map for task with zkid:[{}]", head.getId());
-          }
-        } else {
-          head.setBytes(SolrResponse.serializable(response));
-          log.debug("Completed task:[{}]", head.getId());
-        }
-
-        markTaskComplete(messageHandler, head.getId(), asyncId, taskKey);
-        log.debug("Marked task [{}] as completed.", head.getId());
-        printTrackingMaps();
-
-        log.info(messageHandler.getName() + ": Message id:" + head.getId() +
-            " complete, response:" + response.getResponse().toString());
-        success = true;
-      } catch (KeeperException e) {
-        SolrException.log(log, "", e);
-      } catch (InterruptedException e) {
-        // Reset task from tracking data structures so that it can be retried.
-        resetTaskWithException(messageHandler, head.getId(), asyncId, taskKey);
-        log.warn("Resetting task {} as the thread was interrupted.", head.getId());
-        Thread.currentThread().interrupt();
-      } finally {
-        if(!success) {
-          // Reset task from tracking data structures so that it can be retried.
-          resetTaskWithException(messageHandler, head.getId(), asyncId, taskKey);
-        }
-        synchronized (waitLock){
-          waitLock.notifyAll();
-        }
-      }
-    }
-
-    private void markTaskComplete(OverseerMessageHandler messageHandler, String id, String asyncId, String taskKey)
-        throws KeeperException, InterruptedException {
-      synchronized (completedTasks) {
-        completedTasks.put(id, head);
-      }
-
-      synchronized (runningTasks) {
-        runningTasks.remove(id);
-      }
-
-      if(asyncId != null)
-        runningMap.remove(asyncId);
-
-      messageHandler.unmarkExclusiveTask(taskKey, operation);
-    }
-
-    private void resetTaskWithException(OverseerMessageHandler messageHandler, String id, String asyncId, String taskKey) {
-      log.warn("Resetting task: {}, requestid: {}, taskKey: {}", id, asyncId, taskKey);
-      try {
-        if (asyncId != null)
-          runningMap.remove(asyncId);
-
-        synchronized (runningTasks) {
-          runningTasks.remove(id);
-        }
-
-        messageHandler.unmarkExclusiveTask(taskKey, operation);
-      } catch (KeeperException e) {
-        SolrException.log(log, "", e);
-      } catch (InterruptedException e) {
-        Thread.currentThread().interrupt();
-      }
-
-    }
-
-    private void updateStats(String statsName) {
-      if (isSuccessful()) {
-        stats.success(statsName);
-      } else {
-        stats.error(statsName);
-        stats.storeFailureDetails(statsName, message, response);
-      }
-    }
-
-    private boolean isSuccessful() {
-      if(response == null)
-        return false;
-      return !(response.getResponse().get("failure") != null || response.getResponse().get("exception") != null);
-    }
-  }
-
-  private void printTrackingMaps() {
-    if(log.isDebugEnabled()) {
-      synchronized (runningTasks) {
-        log.debug("RunningTasks: {}", runningTasks.toString());
-      }
-      synchronized (completedTasks) {
-        log.debug("CompletedTasks: {}", completedTasks.keySet().toString());
-      }
-      synchronized (runningZKTasks) {
-        log.debug("RunningZKTasks: {}", runningZKTasks.toString());
-      }
-    }
-  }
-
-
-
-  String getId(){
-    return myId;
-  }
-
-  /**
-   * An interface to determine which {@link OverseerMessageHandler}
-   * handles a given message.  This could be a single OverseerMessageHandler
-   * for the case where a single type of message is handled (e.g. collection
-   * messages only) , or a different handler could be selected based on the
-   * contents of the message.
-   */
-  public interface OverseerMessageHandlerSelector {
-    OverseerMessageHandler selectOverseerMessageHandler(ZkNodeProps message);
-  }
-
-}
diff --git a/solr/core/src/java/org/apache/solr/cloud/OverseerTaskProcessor.java b/solr/core/src/java/org/apache/solr/cloud/OverseerTaskProcessor.java
new file mode 100644
index 0000000..138d696
--- /dev/null
+++ b/solr/core/src/java/org/apache/solr/cloud/OverseerTaskProcessor.java
@@ -0,0 +1,561 @@
+package org.apache.solr.cloud;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Closeable;
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.SynchronousQueue;
+import java.util.concurrent.TimeUnit;
+
+import org.apache.solr.client.solrj.SolrResponse;
+import org.apache.solr.cloud.OverseerTaskQueue.QueueEvent;
+import org.apache.solr.cloud.Overseer.LeaderStatus;
+import org.apache.solr.common.SolrException;
+import org.apache.solr.common.cloud.SolrZkClient;
+import org.apache.solr.common.cloud.ZkNodeProps;
+import org.apache.solr.common.cloud.ZkStateReader;
+import org.apache.solr.common.util.ExecutorUtil;
+import org.apache.solr.common.util.Utils;
+import org.apache.solr.handler.component.ShardHandlerFactory;
+import org.apache.solr.util.DefaultSolrThreadFactory;
+import org.apache.solr.util.stats.TimerContext;
+import org.apache.zookeeper.KeeperException;
+import org.apache.zookeeper.data.Stat;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import static org.apache.solr.common.params.CommonAdminParams.ASYNC;
+
+/**
+ * A generic processor run in the Overseer, used for handling items added
+ * to a distributed work queue.  Has support for handling exclusive tasks
+ * (i.e. tasks that should not run in parallel with each other).
+ *
+ * An {@link OverseerMessageHandlerSelector} determines which
+ * {@link OverseerMessageHandler} handles specific messages in the
+ * queue.
+ */
+public class OverseerTaskProcessor implements Runnable, Closeable {
+
+  public int maxParallelThreads = 10;
+
+  public ExecutorService tpe ;
+
+  private static Logger log = LoggerFactory
+      .getLogger(OverseerTaskProcessor.class);
+
+  private OverseerTaskQueue workQueue;
+  private DistributedMap runningMap;
+  private DistributedMap completedMap;
+  private DistributedMap failureMap;
+
+  // Set that maintains a list of all the tasks that are running. This is keyed on zk id of the task.
+  final private Set runningTasks;
+
+  // List of completed tasks. This is used to clean up workQueue in zk.
+  final private HashMap<String, QueueEvent> completedTasks;
+
+  private String myId;
+
+  private final ShardHandlerFactory shardHandlerFactory;
+
+  private String adminPath;
+
+  private ZkStateReader zkStateReader;
+
+  private boolean isClosed;
+
+  private Overseer.Stats stats;
+
+  // Set of tasks that have been picked up for processing but not cleaned up from zk work-queue.
+  // It may contain tasks that have completed execution, have been entered into the completed/failed map in zk but not
+  // deleted from the work-queue as that is a batched operation.
+  final private Set<String> runningZKTasks;
+  private final Object waitLock = new Object();
+
+  private OverseerMessageHandlerSelector selector;
+
+  private OverseerNodePrioritizer prioritizer;
+
+  public OverseerTaskProcessor(ZkStateReader zkStateReader, String myId,
+                                        final ShardHandlerFactory shardHandlerFactory,
+                                        String adminPath,
+                                        Overseer.Stats stats,
+                                        OverseerMessageHandlerSelector selector,
+                                        OverseerNodePrioritizer prioritizer,
+                                        OverseerTaskQueue workQueue,
+                                        DistributedMap runningMap,
+                                        DistributedMap completedMap,
+                                        DistributedMap failureMap) {
+    this.zkStateReader = zkStateReader;
+    this.myId = myId;
+    this.shardHandlerFactory = shardHandlerFactory;
+    this.adminPath = adminPath;
+    this.stats = stats;
+    this.selector = selector;
+    this.prioritizer = prioritizer;
+    this.workQueue = workQueue;
+    this.runningMap = runningMap;
+    this.completedMap = completedMap;
+    this.failureMap = failureMap;
+    this.runningZKTasks = new HashSet<>();
+    this.runningTasks = new HashSet();
+    this.completedTasks = new HashMap<>();
+  }
+
+  @Override
+  public void run() {
+    log.info("Process current queue of overseer operations");
+    LeaderStatus isLeader = amILeader();
+    while (isLeader == LeaderStatus.DONT_KNOW) {
+      log.debug("am_i_leader unclear {}", isLeader);
+      isLeader = amILeader();  // not a no, not a yes, try ask again
+    }
+
+    String oldestItemInWorkQueue = null;
+    // hasLeftOverItems - used for avoiding re-execution of async tasks that were processed by a previous Overseer.
+    // This variable is set in case there's any task found on the workQueue when the OCP starts up and
+    // the id for the queue tail is used as a marker to check for the task in completed/failed map in zk.
+    // Beyond the marker, all tasks can safely be assumed to have never been executed.
+    boolean hasLeftOverItems = true;
+
+    try {
+      oldestItemInWorkQueue = workQueue.getTailId();
+    } catch (KeeperException e) {
+      // We don't need to handle this. This is just a fail-safe which comes in handy in skipping already processed
+      // async calls.
+      SolrException.log(log, "", e);
+    } catch (InterruptedException e) {
+      Thread.currentThread().interrupt();
+    }
+
+    if (oldestItemInWorkQueue == null)
+      hasLeftOverItems = false;
+    else
+      log.debug("Found already existing elements in the work-queue. Last element: {}", oldestItemInWorkQueue);
+
+    try {
+      prioritizer.prioritizeOverseerNodes(myId);
+    } catch (Exception e) {
+      log.error("Unable to prioritize overseer ", e);
+    }
+
+    // TODO: Make maxThreads configurable.
+
+    this.tpe = new ExecutorUtil.MDCAwareThreadPoolExecutor(5, 100, 0L, TimeUnit.MILLISECONDS,
+        new SynchronousQueue<Runnable>(),
+        new DefaultSolrThreadFactory("OverseerThreadFactory"));
+    try {
+      while (!this.isClosed) {
+        try {
+          isLeader = amILeader();
+          if (LeaderStatus.NO == isLeader) {
+            break;
+          } else if (LeaderStatus.YES != isLeader) {
+            log.debug("am_i_leader unclear {}", isLeader);
+            continue; // not a no, not a yes, try asking again
+          }
+
+          log.debug("Cleaning up work-queue. #Running tasks: {}", runningTasks.size());
+          cleanUpWorkQueue();
+
+          printTrackingMaps();
+
+          boolean waited = false;
+
+          while (runningTasks.size() > maxParallelThreads) {
+            synchronized (waitLock) {
+              waitLock.wait(100);//wait for 100 ms or till a task is complete
+            }
+            waited = true;
+          }
+
+          if (waited)
+            cleanUpWorkQueue();
+
+          List<QueueEvent> heads = workQueue.peekTopN(maxParallelThreads, runningZKTasks, 2000L);
+
+          if (heads == null)
+            continue;
+
+          log.debug("Got {} tasks from work-queue : [{}]", heads.size(), heads.toString());
+
+          if (isClosed) break;
+
+          for (QueueEvent head : heads) {
+            final ZkNodeProps message = ZkNodeProps.load(head.getBytes());
+            OverseerMessageHandler messageHandler = selector.selectOverseerMessageHandler(message);
+            String taskKey = messageHandler.getTaskKey(message);
+            final String asyncId = message.getStr(ASYNC);
+            if (hasLeftOverItems) {
+              if (head.getId().equals(oldestItemInWorkQueue))
+                hasLeftOverItems = false;
+              if (asyncId != null && (completedMap.contains(asyncId) || failureMap.contains(asyncId))) {
+                log.debug("Found already processed task in workQueue, cleaning up. AsyncId [{}]",asyncId );
+                workQueue.remove(head);
+                continue;
+              }
+            }
+
+            if (!checkExclusivity(messageHandler, message, head.getId())) {
+              log.debug("Exclusivity check failed for [{}]", message.toString());
+              continue;
+            }
+
+            try {
+              markTaskAsRunning(messageHandler, head, taskKey, asyncId, message);
+              log.debug("Marked task [{}] as running", head.getId());
+            } catch (KeeperException.NodeExistsException e) {
+              // This should never happen
+              log.error("Tried to pick up task [{}] when it was already running!", head.getId());
+            } catch (InterruptedException e) {
+              log.error("Thread interrupted while trying to pick task for execution.", head.getId());
+              Thread.currentThread().interrupt();
+            }
+
+            log.info(messageHandler.getName() + ": Get the message id:" + head.getId() + " message:" + message.toString());
+            String operation = message.getStr(Overseer.QUEUE_OPERATION);
+            Runner runner = new Runner(messageHandler, message,
+                operation, head);
+            tpe.execute(runner);
+          }
+
+        } catch (KeeperException e) {
+          if (e.code() == KeeperException.Code.SESSIONEXPIRED) {
+            log.warn("Overseer cannot talk to ZK");
+            return;
+          }
+          SolrException.log(log, "", e);
+        } catch (InterruptedException e) {
+          Thread.currentThread().interrupt();
+          return;
+        } catch (Exception e) {
+          SolrException.log(log, "", e);
+        }
+      }
+    } finally {
+      this.close();
+    }
+  }
+
+  protected boolean checkExclusivity(OverseerMessageHandler messageHandler, ZkNodeProps message, String id)
+      throws KeeperException, InterruptedException {
+    String taskKey = messageHandler.getTaskKey(message);
+
+    if(taskKey == null)
+      return true;
+
+    OverseerMessageHandler.ExclusiveMarking marking = messageHandler.checkExclusiveMarking(taskKey, message);
+    switch (marking) {
+      case NOTDETERMINED:
+        break;
+      case EXCLUSIVE:
+        return true;
+      case NONEXCLUSIVE:
+        return false;
+      default:
+        throw new IllegalArgumentException("Undefined marking: " + marking);
+    }
+
+    if(runningZKTasks.contains(id))
+      return false;
+
+    return true;
+  }
+
+  private void cleanUpWorkQueue() throws KeeperException, InterruptedException {
+    synchronized (completedTasks) {
+      for (String id : completedTasks.keySet()) {
+        workQueue.remove(completedTasks.get(id));
+        runningZKTasks.remove(id);
+      }
+      completedTasks.clear();
+    }
+  }
+
+  public void close() {
+    isClosed = true;
+    if(tpe != null) {
+      if (!tpe.isShutdown()) {
+        ExecutorUtil.shutdownAndAwaitTermination(tpe);
+      }
+    }
+  }
+
+  public static List<String> getSortedOverseerNodeNames(SolrZkClient zk) throws KeeperException, InterruptedException {
+    List<String> children = null;
+    try {
+      children = zk.getChildren(OverseerElectionContext.PATH + LeaderElector.ELECTION_NODE, null, true);
+    } catch (Exception e) {
+      log.warn("error ", e);
+      return new ArrayList<>();
+    }
+    LeaderElector.sortSeqs(children);
+    ArrayList<String> nodeNames = new ArrayList<>(children.size());
+    for (String c : children) nodeNames.add(LeaderElector.getNodeName(c));
+    return nodeNames;
+  }
+
+  public static List<String> getSortedElectionNodes(SolrZkClient zk, String path) throws KeeperException, InterruptedException {
+    List<String> children = null;
+    try {
+      children = zk.getChildren(path, null, true);
+      LeaderElector.sortSeqs(children);
+      return children;
+    } catch (Exception e) {
+      throw e;
+    }
+
+  }
+
+  public static String getLeaderNode(SolrZkClient zkClient) throws KeeperException, InterruptedException {
+    String id = getLeaderId(zkClient);
+    return id==null ?
+        null:
+        LeaderElector.getNodeName( id);
+  }
+
+  public static String getLeaderId(SolrZkClient zkClient) throws KeeperException,InterruptedException{
+    byte[] data = null;
+    try {
+      data = zkClient.getData("/overseer_elect/leader", null, new Stat(), true);
+    } catch (KeeperException.NoNodeException e) {
+      return null;
+    }
+    Map m = (Map) Utils.fromJSON(data);
+    return  (String) m.get("id");
+  }
+
+  protected LeaderStatus amILeader() {
+    String statsName = "collection_am_i_leader";
+    TimerContext timerContext = stats.time(statsName);
+    boolean success = true;
+    try {
+      ZkNodeProps props = ZkNodeProps.load(zkStateReader.getZkClient().getData(
+          "/overseer_elect/leader", null, null, true));
+      if (myId.equals(props.getStr("id"))) {
+        return LeaderStatus.YES;
+      }
+    } catch (KeeperException e) {
+      success = false;
+      if (e.code() == KeeperException.Code.CONNECTIONLOSS) {
+        log.error("", e);
+        return LeaderStatus.DONT_KNOW;
+      } else if (e.code() == KeeperException.Code.SESSIONEXPIRED) {
+        log.info("", e);
+      } else {
+        log.warn("", e);
+      }
+    } catch (InterruptedException e) {
+      success = false;
+      Thread.currentThread().interrupt();
+    } finally {
+      timerContext.stop();
+      if (success)  {
+        stats.success(statsName);
+      } else  {
+        stats.error(statsName);
+      }
+    }
+    log.info("According to ZK I (id=" + myId + ") am no longer a leader.");
+    return LeaderStatus.NO;
+  }
+
+  public boolean isClosed() {
+    return isClosed;
+  }
+
+  @SuppressWarnings("unchecked")
+  private void markTaskAsRunning(OverseerMessageHandler messageHandler, QueueEvent head, String taskKey,
+                                 String asyncId, ZkNodeProps message)
+      throws KeeperException, InterruptedException {
+    synchronized (runningZKTasks) {
+      runningZKTasks.add(head.getId());
+    }
+
+    synchronized (runningTasks) {
+      runningTasks.add(head.getId());
+    }
+
+    messageHandler.markExclusiveTask(taskKey, message);
+
+    if(asyncId != null)
+      runningMap.put(asyncId, null);
+  }
+  
+  protected class Runner implements Runnable {
+    ZkNodeProps message;
+    String operation;
+    SolrResponse response;
+    QueueEvent head;
+    OverseerMessageHandler messageHandler;
+  
+    public Runner(OverseerMessageHandler messageHandler, ZkNodeProps message, String operation, QueueEvent head) {
+      this.message = message;
+      this.operation = operation;
+      this.head = head;
+      this.messageHandler = messageHandler;
+      response = null;
+    }
+
+
+    public void run() {
+      String statsName = messageHandler.getTimerName(operation);
+      final TimerContext timerContext = stats.time(statsName);
+
+      boolean success = false;
+      final String asyncId = message.getStr(ASYNC);
+      String taskKey = messageHandler.getTaskKey(message);
+
+      try {
+        try {
+          log.debug("Runner processing {}", head.getId());
+          response = messageHandler.processMessage(message, operation);
+        } finally {
+          timerContext.stop();
+          updateStats(statsName);
+        }
+
+        if(asyncId != null) {
+          if (response != null && (response.getResponse().get("failure") != null 
+              || response.getResponse().get("exception") != null)) {
+            failureMap.put(asyncId, SolrResponse.serializable(response));
+            log.debug("Updated failed map for task with zkid:[{}]", head.getId());
+          } else {
+            completedMap.put(asyncId, SolrResponse.serializable(response));
+            log.debug("Updated completed map for task with zkid:[{}]", head.getId());
+          }
+        } else {
+          head.setBytes(SolrResponse.serializable(response));
+          log.debug("Completed task:[{}]", head.getId());
+        }
+
+        markTaskComplete(messageHandler, head.getId(), asyncId, taskKey, message);
+        log.debug("Marked task [{}] as completed.", head.getId());
+        printTrackingMaps();
+
+        log.info(messageHandler.getName() + ": Message id:" + head.getId() +
+            " complete, response:" + response.getResponse().toString());
+        success = true;
+      } catch (KeeperException e) {
+        SolrException.log(log, "", e);
+      } catch (InterruptedException e) {
+        // Reset task from tracking data structures so that it can be retried.
+        resetTaskWithException(messageHandler, head.getId(), asyncId, taskKey, message);
+        log.warn("Resetting task {} as the thread was interrupted.", head.getId());
+        Thread.currentThread().interrupt();
+      } finally {
+        if(!success) {
+          // Reset task from tracking data structures so that it can be retried.
+          resetTaskWithException(messageHandler, head.getId(), asyncId, taskKey, message);
+        }
+        synchronized (waitLock){
+          waitLock.notifyAll();
+        }
+      }
+    }
+
+    private void markTaskComplete(OverseerMessageHandler messageHandler, String id, String asyncId, String taskKey, ZkNodeProps message)
+        throws KeeperException, InterruptedException {
+      synchronized (completedTasks) {
+        completedTasks.put(id, head);
+      }
+
+      synchronized (runningTasks) {
+        runningTasks.remove(id);
+      }
+
+      if(asyncId != null)
+        runningMap.remove(asyncId);
+
+      messageHandler.unmarkExclusiveTask(taskKey, operation, message);
+    }
+
+    private void resetTaskWithException(OverseerMessageHandler messageHandler, String id, String asyncId, String taskKey, ZkNodeProps message) {
+      log.warn("Resetting task: {}, requestid: {}, taskKey: {}", id, asyncId, taskKey);
+      try {
+        if (asyncId != null)
+          runningMap.remove(asyncId);
+
+        synchronized (runningTasks) {
+          runningTasks.remove(id);
+        }
+
+        messageHandler.unmarkExclusiveTask(taskKey, operation, message);
+      } catch (KeeperException e) {
+        SolrException.log(log, "", e);
+      } catch (InterruptedException e) {
+        Thread.currentThread().interrupt();
+      }
+
+    }
+
+    private void updateStats(String statsName) {
+      if (isSuccessful()) {
+        stats.success(statsName);
+      } else {
+        stats.error(statsName);
+        stats.storeFailureDetails(statsName, message, response);
+      }
+    }
+
+    private boolean isSuccessful() {
+      if(response == null)
+        return false;
+      return !(response.getResponse().get("failure") != null || response.getResponse().get("exception") != null);
+    }
+  }
+
+  private void printTrackingMaps() {
+    if(log.isDebugEnabled()) {
+      synchronized (runningTasks) {
+        log.debug("RunningTasks: {}", runningTasks.toString());
+      }
+      synchronized (completedTasks) {
+        log.debug("CompletedTasks: {}", completedTasks.keySet().toString());
+      }
+      synchronized (runningZKTasks) {
+        log.debug("RunningZKTasks: {}", runningZKTasks.toString());
+      }
+    }
+  }
+
+
+
+  String getId(){
+    return myId;
+  }
+
+  /**
+   * An interface to determine which {@link OverseerMessageHandler}
+   * handles a given message.  This could be a single OverseerMessageHandler
+   * for the case where a single type of message is handled (e.g. collection
+   * messages only) , or a different handler could be selected based on the
+   * contents of the message.
+   */
+  public interface OverseerMessageHandlerSelector {
+    OverseerMessageHandler selectOverseerMessageHandler(ZkNodeProps message);
+  }
+
+}
diff --git a/solr/core/src/java/org/apache/solr/cloud/OverseerTaskQueue.java b/solr/core/src/java/org/apache/solr/cloud/OverseerTaskQueue.java
new file mode 100644
index 0000000..096d947
--- /dev/null
+++ b/solr/core/src/java/org/apache/solr/cloud/OverseerTaskQueue.java
@@ -0,0 +1,324 @@
+package org.apache.solr.cloud;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.util.ArrayList;
+import java.util.List;
+import java.util.Set;
+import java.util.TreeSet;
+
+import org.apache.solr.common.cloud.SolrZkClient;
+import org.apache.solr.common.cloud.ZkNodeProps;
+import org.apache.solr.util.stats.TimerContext;
+import org.apache.zookeeper.CreateMode;
+import org.apache.zookeeper.KeeperException;
+import org.apache.zookeeper.WatchedEvent;
+import org.apache.zookeeper.Watcher;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * A {@link DistributedQueue} augmented with helper methods specific to the overseer task queues.
+ * Methods specific to this subclass ignore superclass internal state and hit ZK directly.
+ * This is inefficient!  But the API on this class is kind of muddy..
+ */
+public class OverseerTaskQueue extends DistributedQueue {
+  private static final Logger LOG = LoggerFactory.getLogger(OverseerTaskQueue.class);
+  
+  private final String response_prefix = "qnr-" ;
+
+  public OverseerTaskQueue(SolrZkClient zookeeper, String dir) {
+    this(zookeeper, dir, new Overseer.Stats());
+  }
+
+  public OverseerTaskQueue(SolrZkClient zookeeper, String dir, Overseer.Stats stats) {
+    super(zookeeper, dir, stats);
+  }
+  
+  /**
+   * Returns true if the queue contains a task with the specified async id.
+   */
+  public boolean containsTaskWithRequestId(String requestIdKey, String requestId)
+      throws KeeperException, InterruptedException {
+
+    List<String> childNames = zookeeper.getChildren(dir, null, true);
+    stats.setQueueLength(childNames.size());
+    for (String childName : childNames) {
+      if (childName != null) {
+        try {
+          byte[] data = zookeeper.getData(dir + "/" + childName, null, null, true);
+          if (data != null) {
+            ZkNodeProps message = ZkNodeProps.load(data);
+            if (message.containsKey(requestIdKey)) {
+              LOG.debug(">>>> {}", message.get(requestIdKey));
+              if(message.get(requestIdKey).equals(requestId)) return true;
+            }
+          }
+        } catch (KeeperException.NoNodeException e) {
+          // Another client removed the node first, try next
+        }
+      }
+    }
+
+    return false;
+  }
+
+  /**
+   * Remove the event and save the response into the other path.
+   * 
+   */
+  public byte[] remove(QueueEvent event) throws KeeperException,
+      InterruptedException {
+    TimerContext time = stats.time(dir + "_remove_event");
+    try {
+      String path = event.getId();
+      String responsePath = dir + "/" + response_prefix
+          + path.substring(path.lastIndexOf("-") + 1);
+      if (zookeeper.exists(responsePath, true)) {
+        zookeeper.setData(responsePath, event.getBytes(), true);
+      }
+      byte[] data = zookeeper.getData(path, null, null, true);
+      zookeeper.delete(path, -1, true);
+      return data;
+    } finally {
+      time.stop();
+    }
+  }
+
+  /**
+   * Watcher that blocks until a WatchedEvent occurs for a znode.
+   */
+  private final class LatchWatcher implements Watcher {
+
+    private final Object lock;
+    private WatchedEvent event;
+    private Event.EventType latchEventType;
+
+    LatchWatcher(Object lock) {
+      this(lock, null);
+    }
+
+    LatchWatcher(Event.EventType eventType) {
+      this(new Object(), eventType);
+    }
+
+    LatchWatcher(Object lock, Event.EventType eventType) {
+      this.lock = lock;
+      this.latchEventType = eventType;
+    }
+
+    @Override
+    public void process(WatchedEvent event) {
+      Event.EventType eventType = event.getType();
+      // None events are ignored
+      // If latchEventType is not null, only fire if the type matches
+      if (eventType != Event.EventType.None && (latchEventType == null || eventType == latchEventType)) {
+        LOG.info("{} fired on path {} state {}", eventType, event.getPath(), event.getState());
+        synchronized (lock) {
+          this.event = event;
+          lock.notifyAll();
+        }
+      }
+    }
+
+    public void await(long timeout) throws InterruptedException {
+      synchronized (lock) {
+        if (this.event != null) return;
+        lock.wait(timeout);
+      }
+    }
+
+    public WatchedEvent getWatchedEvent() {
+      return event;
+    }
+  }
+
+  /**
+   * Inserts data into zookeeper.
+   * 
+   * @return true if data was successfully added
+   */
+  private String createData(String path, byte[] data, CreateMode mode)
+      throws KeeperException, InterruptedException {
+    for (;;) {
+      try {
+        return zookeeper.create(path, data, mode, true);
+      } catch (KeeperException.NoNodeException e) {
+        try {
+          zookeeper.create(dir, new byte[0], CreateMode.PERSISTENT, true);
+        } catch (KeeperException.NodeExistsException ne) {
+          // someone created it
+        }
+      }
+    }
+  }
+  
+  /**
+   * Offer the data and wait for the response
+   * 
+   */
+  public QueueEvent offer(byte[] data, long timeout) throws KeeperException,
+      InterruptedException {
+    TimerContext time = stats.time(dir + "_offer");
+    try {
+      String path = createData(dir + "/" + PREFIX, data,
+          CreateMode.PERSISTENT_SEQUENTIAL);
+      String watchID = createData(
+          dir + "/" + response_prefix + path.substring(path.lastIndexOf("-") + 1),
+          null, CreateMode.EPHEMERAL);
+
+      Object lock = new Object();
+      LatchWatcher watcher = new LatchWatcher(lock);
+      synchronized (lock) {
+        if (zookeeper.exists(watchID, watcher, true) != null) {
+          watcher.await(timeout);
+        }
+      }
+      byte[] bytes = zookeeper.getData(watchID, null, null, true);
+      zookeeper.delete(watchID, -1, true);
+      return new QueueEvent(watchID, bytes, watcher.getWatchedEvent());
+    } finally {
+      time.stop();
+    }
+  }
+
+  public List<QueueEvent> peekTopN(int n, Set<String> excludeSet, long waitMillis)
+      throws KeeperException, InterruptedException {
+    ArrayList<QueueEvent> topN = new ArrayList<>();
+
+    LOG.debug("Peeking for top {} elements. ExcludeSet: {}", n, excludeSet);
+    TimerContext time = null;
+    if (waitMillis == Long.MAX_VALUE) time = stats.time(dir + "_peekTopN_wait_forever");
+    else time = stats.time(dir + "_peekTopN_wait" + waitMillis);
+
+    try {
+      for (String headNode : getChildren(waitMillis)) {
+        if (topN.size() < n) {
+          try {
+            String id = dir + "/" + headNode;
+            if (excludeSet.contains(id)) continue;
+            QueueEvent queueEvent = new QueueEvent(id,
+                zookeeper.getData(dir + "/" + headNode, null, null, true), null);
+            topN.add(queueEvent);
+          } catch (KeeperException.NoNodeException e) {
+            // Another client removed the node first, try next
+          }
+        } else {
+          if (topN.size() >= 1) {
+            printQueueEventsListElementIds(topN);
+            return topN;
+          }
+        }
+      }
+
+      if (topN.size() > 0 ) {
+        printQueueEventsListElementIds(topN);
+        return topN;
+      }
+      return null;
+    } finally {
+      time.stop();
+    }
+  }
+
+  private static void printQueueEventsListElementIds(ArrayList<QueueEvent> topN) {
+    if(LOG.isDebugEnabled()) {
+      StringBuffer sb = new StringBuffer("[");
+      for(QueueEvent queueEvent: topN) {
+        sb.append(queueEvent.getId()).append(", ");
+      }
+      sb.append("]");
+      LOG.debug("Returning topN elements: {}", sb.toString());
+    }
+  }
+
+
+  /**
+   *
+   * Gets last element of the Queue without removing it.
+   */
+  public String getTailId() throws KeeperException, InterruptedException {
+    // TODO: could we use getChildren here?  Unsure what freshness guarantee the caller needs.
+    TreeSet<String> orderedChildren = fetchZkChildren(null);
+
+    for (String headNode : orderedChildren.descendingSet())
+      if (headNode != null) {
+        try {
+          QueueEvent queueEvent = new QueueEvent(dir + "/" + headNode, zookeeper.getData(dir + "/" + headNode,
+              null, null, true), null);
+          return queueEvent.getId();
+        } catch (KeeperException.NoNodeException e) {
+          // Another client removed the node first, try next
+        }
+      }
+    return null;
+  }
+  
+  public static class QueueEvent {
+    @Override
+    public int hashCode() {
+      final int prime = 31;
+      int result = 1;
+      result = prime * result + ((id == null) ? 0 : id.hashCode());
+      return result;
+    }
+    
+    @Override
+    public boolean equals(Object obj) {
+      if (this == obj) return true;
+      if (obj == null) return false;
+      if (getClass() != obj.getClass()) return false;
+      QueueEvent other = (QueueEvent) obj;
+      if (id == null) {
+        if (other.id != null) return false;
+      } else if (!id.equals(other.id)) return false;
+      return true;
+    }
+    
+    private WatchedEvent event = null;
+    private String id;
+    private byte[] bytes;
+    
+    QueueEvent(String id, byte[] bytes, WatchedEvent event) {
+      this.id = id;
+      this.bytes = bytes;
+      this.event = event;
+    }
+    
+    public void setId(String id) {
+      this.id = id;
+    }
+    
+    public String getId() {
+      return id;
+    }
+    
+    public void setBytes(byte[] bytes) {
+      this.bytes = bytes;
+    }
+    
+    public byte[] getBytes() {
+      return bytes;
+    }
+    
+    public WatchedEvent getWatchedEvent() {
+      return event;
+    }
+    
+  }
+}
diff --git a/solr/core/src/java/org/apache/solr/cloud/ZkController.java b/solr/core/src/java/org/apache/solr/cloud/ZkController.java
index a5569f9..469d647 100644
--- a/solr/core/src/java/org/apache/solr/cloud/ZkController.java
+++ b/solr/core/src/java/org/apache/solr/cloud/ZkController.java
@@ -116,7 +116,8 @@ public final class ZkController {
   private final boolean SKIP_AUTO_RECOVERY = Boolean.getBoolean("solrcloud.skip.autorecovery");
 
   private final DistributedQueue overseerJobQueue;
-  private final OverseerCollectionQueue overseerCollectionQueue;
+  private final OverseerTaskQueue overseerCollectionQueue;
+  private final OverseerTaskQueue overseerConfigSetQueue;
 
   private final DistributedMap overseerRunningMap;
   private final DistributedMap overseerCompletedMap;
@@ -376,6 +377,7 @@ public final class ZkController {
 
     this.overseerJobQueue = Overseer.getInQueue(zkClient);
     this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);
+    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);
     this.overseerRunningMap = Overseer.getRunningMap(zkClient);
     this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);
     this.overseerFailureMap = Overseer.getFailureMap(zkClient);
@@ -1768,10 +1770,14 @@ public final class ZkController {
     return overseerJobQueue;
   }
 
-  public OverseerCollectionQueue getOverseerCollectionQueue() {
+  public OverseerTaskQueue getOverseerCollectionQueue() {
     return overseerCollectionQueue;
   }
 
+  public OverseerTaskQueue getOverseerConfigSetQueue() {
+    return overseerConfigSetQueue;
+  }
+
   public DistributedMap getOverseerRunningMap() {
     return overseerRunningMap;
   }
diff --git a/solr/core/src/java/org/apache/solr/core/ConfigSetProperties.java b/solr/core/src/java/org/apache/solr/core/ConfigSetProperties.java
index 8b01fa8..dcb1736 100644
--- a/solr/core/src/java/org/apache/solr/core/ConfigSetProperties.java
+++ b/solr/core/src/java/org/apache/solr/core/ConfigSetProperties.java
@@ -36,6 +36,9 @@ public class ConfigSetProperties {
 
   private static final Logger log = LoggerFactory.getLogger(ConfigSetProperties.class);
 
+  public static final String DEFAULT_FILENAME = "configsetprops.json";
+  public static final String IMMUTABLE_CONFIGSET_ARG = "immutable";
+
   /**
    * Return the properties associated with the ConfigSet (e.g. immutable)
    *
@@ -55,9 +58,18 @@ public class ConfigSetProperties {
     }
 
     try {
+      return readFromInputStream(reader);
+    } finally {
+      IOUtils.closeQuietly(reader);
+    }
+  }
+
+  public static NamedList readFromInputStream(InputStreamReader reader) {
+    try {
       JSONParser jsonParser = new JSONParser(reader);
       Object object = ObjectBuilder.getVal(jsonParser);
       if (!(object instanceof Map)) {
+        final String objectClass = object == null ? "null" : object.getClass().getName();
         throw new SolrException(ErrorCode.SERVER_ERROR, "Invalid JSON type " + object.getClass().getName() + ", expected Map");
       }
       return new NamedList((Map)object);
diff --git a/solr/core/src/java/org/apache/solr/core/CoreContainer.java b/solr/core/src/java/org/apache/solr/core/CoreContainer.java
index 78b2748..22600c1 100644
--- a/solr/core/src/java/org/apache/solr/core/CoreContainer.java
+++ b/solr/core/src/java/org/apache/solr/core/CoreContainer.java
@@ -46,6 +46,7 @@ import org.apache.solr.common.util.IOUtils;
 import org.apache.solr.common.util.Utils;
 import org.apache.solr.handler.RequestHandlerBase;
 import org.apache.solr.handler.admin.CollectionsHandler;
+import org.apache.solr.handler.admin.ConfigSetsHandler;
 import org.apache.solr.handler.admin.CoreAdminHandler;
 import org.apache.solr.handler.admin.InfoHandler;
 import org.apache.solr.handler.admin.SecurityConfHandler;
@@ -97,6 +98,7 @@ public class CoreContainer {
   protected CoreAdminHandler coreAdminHandler = null;
   protected CollectionsHandler collectionsHandler = null;
   private InfoHandler infoHandler;
+  protected ConfigSetsHandler configSetsHandler = null;
 
   private PKIAuthenticationPlugin pkiAuthenticationPlugin;
 
@@ -129,6 +131,7 @@ public class CoreContainer {
   public static final String CORES_HANDLER_PATH = "/admin/cores";
   public static final String COLLECTIONS_HANDLER_PATH = "/admin/collections";
   public static final String INFO_HANDLER_PATH = "/admin/info";
+  public static final String CONFIGSETS_HANDLER_PATH = "/admin/configs";
 
   private PluginBag<SolrRequestHandler> containerHandlers = new PluginBag<>(SolrRequestHandler.class, null);
 
@@ -407,6 +410,8 @@ public class CoreContainer {
     containerHandlers.put(INFO_HANDLER_PATH, infoHandler);
     coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);
     containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);
+    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);
+    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);
     containerHandlers.put("/admin/authorization", securityConfHandler);
     containerHandlers.put("/admin/authentication", securityConfHandler);
     if(pkiAuthenticationPlugin != null)
@@ -1040,6 +1045,10 @@ public class CoreContainer {
     return infoHandler;
   }
 
+  public ConfigSetsHandler getConfigSetsHandler() {
+    return configSetsHandler;
+  }
+
   public String getHostName() {
     return this.hostName;
   }
diff --git a/solr/core/src/java/org/apache/solr/core/CoreDescriptor.java b/solr/core/src/java/org/apache/solr/core/CoreDescriptor.java
index 837b823..c2e70a1 100644
--- a/solr/core/src/java/org/apache/solr/core/CoreDescriptor.java
+++ b/solr/core/src/java/org/apache/solr/core/CoreDescriptor.java
@@ -84,7 +84,7 @@ public class CoreDescriptor {
   private static ImmutableMap<String, String> defaultProperties = new ImmutableMap.Builder<String, String>()
       .put(CORE_CONFIG, "solrconfig.xml")
       .put(CORE_SCHEMA, "schema.xml")
-      .put(CORE_CONFIGSET_PROPERTIES, "configsetprops.json")
+      .put(CORE_CONFIGSET_PROPERTIES, ConfigSetProperties.DEFAULT_FILENAME)
       .put(CORE_DATADIR, "data" + File.separator)
       .put(CORE_TRANSIENT, "false")
       .put(CORE_LOADONSTARTUP, "true")
diff --git a/solr/core/src/java/org/apache/solr/core/NodeConfig.java b/solr/core/src/java/org/apache/solr/core/NodeConfig.java
index e0e8661..b5f114e 100644
--- a/solr/core/src/java/org/apache/solr/core/NodeConfig.java
+++ b/solr/core/src/java/org/apache/solr/core/NodeConfig.java
@@ -44,6 +44,8 @@ public class NodeConfig {
 
   private final String infoHandlerClass;
 
+  private final String configSetsHandlerClass;
+
   private final LogWatcherConfig logWatcherConfig;
 
   private final CloudConfig cloudConfig;
@@ -58,7 +60,8 @@ public class NodeConfig {
 
   private NodeConfig(String nodeName, String coreRootDirectory, String configSetBaseDirectory, String sharedLibDirectory,
                      PluginInfo shardHandlerFactoryConfig, UpdateShardHandlerConfig updateShardHandlerConfig,
-                     String coreAdminHandlerClass, String collectionsAdminHandlerClass, String infoHandlerClass,
+                     String coreAdminHandlerClass, String collectionsAdminHandlerClass,
+                     String infoHandlerClass, String configSetsHandlerClass,
                      LogWatcherConfig logWatcherConfig, CloudConfig cloudConfig, int coreLoadThreads,
                      int transientCacheSize, boolean useSchemaCache, String managementPath,
                      SolrResourceLoader loader, Properties solrProperties) {
@@ -71,6 +74,7 @@ public class NodeConfig {
     this.coreAdminHandlerClass = coreAdminHandlerClass;
     this.collectionsAdminHandlerClass = collectionsAdminHandlerClass;
     this.infoHandlerClass = infoHandlerClass;
+    this.configSetsHandlerClass = configSetsHandlerClass;
     this.logWatcherConfig = logWatcherConfig;
     this.cloudConfig = cloudConfig;
     this.coreLoadThreads = coreLoadThreads;
@@ -142,6 +146,10 @@ public class NodeConfig {
     return infoHandlerClass;
   }
 
+  public String getConfigSetsHandlerClass() {
+    return configSetsHandlerClass;
+  }
+
   public boolean hasSchemaCache() {
     return useSchemaCache;
   }
@@ -187,6 +195,7 @@ public class NodeConfig {
     private String coreAdminHandlerClass = DEFAULT_ADMINHANDLERCLASS;
     private String collectionsAdminHandlerClass = DEFAULT_COLLECTIONSHANDLERCLASS;
     private String infoHandlerClass = DEFAULT_INFOHANDLERCLASS;
+    private String configSetsHandlerClass = DEFAULT_CONFIGSETSHANDLERCLASS;
     private LogWatcherConfig logWatcherConfig = new LogWatcherConfig(true, null, null, 50);
     private CloudConfig cloudConfig;
     private int coreLoadThreads = DEFAULT_CORE_LOAD_THREADS;
@@ -205,6 +214,7 @@ public class NodeConfig {
     private static final String DEFAULT_ADMINHANDLERCLASS = "org.apache.solr.handler.admin.CoreAdminHandler";
     private static final String DEFAULT_INFOHANDLERCLASS = "org.apache.solr.handler.admin.InfoHandler";
     private static final String DEFAULT_COLLECTIONSHANDLERCLASS = "org.apache.solr.handler.admin.CollectionsHandler";
+    private static final String DEFAULT_CONFIGSETSHANDLERCLASS = "org.apache.solr.handler.admin.ConfigSetsHandler";
 
     public NodeConfigBuilder(String nodeName, SolrResourceLoader loader) {
       this.nodeName = nodeName;
@@ -252,6 +262,11 @@ public class NodeConfig {
       return this;
     }
 
+    public NodeConfigBuilder setConfigSetsHandlerClass(String configSetsHandlerClass) {
+      this.configSetsHandlerClass = configSetsHandlerClass;
+      return this;
+    }
+
     public NodeConfigBuilder setLogWatcherConfig(LogWatcherConfig logWatcherConfig) {
       this.logWatcherConfig = logWatcherConfig;
       return this;
@@ -289,7 +304,7 @@ public class NodeConfig {
 
     public NodeConfig build() {
       return new NodeConfig(nodeName, coreRootDirectory, configSetBaseDirectory, sharedLibDirectory, shardHandlerFactoryConfig,
-                            updateShardHandlerConfig, coreAdminHandlerClass, collectionsAdminHandlerClass, infoHandlerClass,
+                            updateShardHandlerConfig, coreAdminHandlerClass, collectionsAdminHandlerClass, infoHandlerClass, configSetsHandlerClass,
                             logWatcherConfig, cloudConfig, coreLoadThreads, transientCacheSize, useSchemaCache, managementPath, loader, solrProperties);
     }
   }
diff --git a/solr/core/src/java/org/apache/solr/core/SolrXmlConfig.java b/solr/core/src/java/org/apache/solr/core/SolrXmlConfig.java
index 15f85bf..6565a06 100644
--- a/solr/core/src/java/org/apache/solr/core/SolrXmlConfig.java
+++ b/solr/core/src/java/org/apache/solr/core/SolrXmlConfig.java
@@ -234,6 +234,9 @@ public class SolrXmlConfig {
         case "infoHandler":
           builder.setInfoHandlerClass(value);
           break;
+        case "configSetsHandler":
+          builder.setConfigSetsHandlerClass(value);
+          break;
         case "coreRootDirectory":
           builder.setCoreRootDirectory(value);
           break;
diff --git a/solr/core/src/java/org/apache/solr/handler/SchemaHandler.java b/solr/core/src/java/org/apache/solr/handler/SchemaHandler.java
index 87d249a..61f18ff 100644
--- a/solr/core/src/java/org/apache/solr/handler/SchemaHandler.java
+++ b/solr/core/src/java/org/apache/solr/handler/SchemaHandler.java
@@ -41,11 +41,10 @@ import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 import static org.apache.solr.common.params.CommonParams.JSON;
+import static org.apache.solr.core.ConfigSetProperties.IMMUTABLE_CONFIGSET_ARG;
 
 public class SchemaHandler extends RequestHandlerBase {
   private static final Logger log = LoggerFactory.getLogger(SchemaHandler.class);
-
-  public static final String IMMUTABLE_CONFIGSET_ARG = "immutable";
   private boolean isImmutableConfigSet = false;
 
   @Override
diff --git a/solr/core/src/java/org/apache/solr/handler/SolrConfigHandler.java b/solr/core/src/java/org/apache/solr/handler/SolrConfigHandler.java
index 3187402..562eef0 100644
--- a/solr/core/src/java/org/apache/solr/handler/SolrConfigHandler.java
+++ b/solr/core/src/java/org/apache/solr/handler/SolrConfigHandler.java
@@ -82,6 +82,7 @@ import static org.apache.solr.common.params.CoreAdminParams.NAME;
 import static org.apache.solr.common.util.StrUtils.formatString;
 import static org.apache.solr.core.ConfigOverlay.NOT_EDITABLE;
 import static org.apache.solr.core.ConfigOverlay.ZNODEVER;
+import static org.apache.solr.core.ConfigSetProperties.IMMUTABLE_CONFIGSET_ARG;
 import static org.apache.solr.core.SolrConfig.PluginOpts.REQUIRE_CLASS;
 import static org.apache.solr.core.SolrConfig.PluginOpts.REQUIRE_NAME;
 import static org.apache.solr.core.SolrConfig.PluginOpts.REQUIRE_NAME_IN_OVERLAY;
@@ -91,7 +92,6 @@ public class SolrConfigHandler extends RequestHandlerBase {
   public static final Logger log = LoggerFactory.getLogger(SolrConfigHandler.class);
   public static final String CONFIGSET_EDITING_DISABLED_ARG = "disable.configEdit";
   public static final boolean configEditing_disabled = Boolean.getBoolean(CONFIGSET_EDITING_DISABLED_ARG);
-  public static final String IMMUTABLE_CONFIGSET_ARG = "immutable";
   private static final Map<String, SolrConfig.SolrPluginInfo> namedPlugins;
   private Lock reloadLock = new ReentrantLock(true);
   private boolean isImmutableConfigSet = false;
diff --git a/solr/core/src/java/org/apache/solr/handler/admin/CollectionsHandler.java b/solr/core/src/java/org/apache/solr/handler/admin/CollectionsHandler.java
index 77d3695..266dfba 100644
--- a/solr/core/src/java/org/apache/solr/handler/admin/CollectionsHandler.java
+++ b/solr/core/src/java/org/apache/solr/handler/admin/CollectionsHandler.java
@@ -36,8 +36,8 @@ import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.CoreAdminRequest;
 import org.apache.solr.client.solrj.request.CoreAdminRequest.RequestSyncShard;
 import org.apache.solr.cloud.DistributedMap;
-import org.apache.solr.cloud.OverseerCollectionQueue;
-import org.apache.solr.cloud.OverseerCollectionQueue.QueueEvent;
+import org.apache.solr.cloud.OverseerTaskQueue;
+import org.apache.solr.cloud.OverseerTaskQueue.QueueEvent;
 import org.apache.solr.cloud.Overseer;
 import org.apache.solr.cloud.OverseerSolrResponse;
 import org.apache.solr.cloud.overseer.SliceMutator;
@@ -246,13 +246,13 @@ public class CollectionsHandler extends RequestHandlerBase {
             + event.getWatchedEvent().getType() + "]");
       } else {
         throw new SolrException(ErrorCode.SERVER_ERROR, operation
-            + " the collection unkown case");
+            + " the collection unknown case");
       }
     }
   }
 
   private boolean overseerCollectionQueueContains(String asyncId) throws KeeperException, InterruptedException {
-    OverseerCollectionQueue collectionQueue = coreContainer.getZkController().getOverseerCollectionQueue();
+    OverseerTaskQueue collectionQueue = coreContainer.getZkController().getOverseerCollectionQueue();
     return collectionQueue.containsTaskWithRequestId(ASYNC, asyncId);
   }
 
diff --git a/solr/core/src/java/org/apache/solr/handler/admin/ConfigSetsHandler.java b/solr/core/src/java/org/apache/solr/handler/admin/ConfigSetsHandler.java
new file mode 100644
index 0000000..5074835
--- /dev/null
+++ b/solr/core/src/java/org/apache/solr/handler/admin/ConfigSetsHandler.java
@@ -0,0 +1,190 @@
+package org.apache.solr.handler.admin;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.util.Iterator;
+import java.util.Map;
+import java.util.concurrent.TimeUnit;
+
+import org.apache.solr.client.solrj.SolrResponse;
+import org.apache.solr.cloud.Overseer;
+import org.apache.solr.cloud.OverseerTaskQueue.QueueEvent;
+import org.apache.solr.common.SolrException;
+import org.apache.solr.common.SolrException.ErrorCode;
+import org.apache.solr.common.cloud.ZkNodeProps;
+import org.apache.solr.common.params.ConfigSetParams;
+import org.apache.solr.common.params.ConfigSetParams.ConfigSetAction;
+import org.apache.solr.common.params.SolrParams;
+import org.apache.solr.common.util.NamedList;
+import org.apache.solr.common.util.SimpleOrderedMap;
+import org.apache.solr.common.util.Utils;
+import org.apache.solr.core.CoreContainer;
+import org.apache.solr.handler.RequestHandlerBase;
+import org.apache.solr.request.SolrQueryRequest;
+import org.apache.solr.response.SolrQueryResponse;
+import org.apache.zookeeper.KeeperException;
+import static org.apache.solr.cloud.OverseerConfigSetMessageHandler.BASE_CONFIGSET;
+import static org.apache.solr.cloud.OverseerConfigSetMessageHandler.CONFIGSETS_ACTION_PREFIX;
+import static org.apache.solr.cloud.OverseerConfigSetMessageHandler.PROPERTY_PREFIX;
+import static org.apache.solr.common.params.CommonParams.NAME;
+import static org.apache.solr.common.params.ConfigSetParams.ConfigSetAction.*;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+
+import static org.apache.solr.cloud.Overseer.QUEUE_OPERATION;
+
+/**
+ * A {@link org.apache.solr.request.SolrRequestHandler} for ConfigSets API requests.
+ */
+public class ConfigSetsHandler extends RequestHandlerBase {
+  protected static Logger log = LoggerFactory.getLogger(ConfigSetsHandler.class);
+  protected final CoreContainer coreContainer;
+  public static long DEFAULT_ZK_TIMEOUT = 180*1000;
+
+  /**
+   * Overloaded ctor to inject CoreContainer into the handler.
+   *
+   * @param coreContainer Core Container of the solr webapp installed.
+   */
+  public ConfigSetsHandler(final CoreContainer coreContainer) {
+    this.coreContainer = coreContainer;
+  }
+
+  @Override
+  final public void init(NamedList args) {
+
+  }
+
+  @Override
+  public void handleRequestBody(SolrQueryRequest req, SolrQueryResponse rsp) throws Exception {
+    if (coreContainer == null) {
+      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,
+              "Core container instance missing");
+    }
+
+    // Make sure that the core is ZKAware
+    if(!coreContainer.isZooKeeperAware()) {
+      throw new SolrException(ErrorCode.BAD_REQUEST,
+          "Solr instance is not running in SolrCloud mode.");
+    }
+
+    // Pick the action
+    SolrParams params = req.getParams();
+    String a = params.get(ConfigSetParams.ACTION);
+    if (a != null) {
+      ConfigSetAction action = ConfigSetAction.get(a);
+      if (action == null)
+        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, "Unknown action: " + a);
+      ConfigSetOperation operation = ConfigSetOperation.get(action);
+      log.info("Invoked ConfigSet Action :{} with params {} ", action.toLower(), req.getParamString());
+      Map<String, Object> result = operation.call(req, rsp, this);
+      if (result != null) {
+        // We need to differentiate between collection and configsets actions since they currently
+        // use the same underlying queue.
+        result.put(QUEUE_OPERATION, CONFIGSETS_ACTION_PREFIX + operation.action.toLower());
+        ZkNodeProps props = new ZkNodeProps(result);
+        handleResponse(operation.action.toLower(), props, rsp, DEFAULT_ZK_TIMEOUT);
+      }
+    } else {
+      throw new SolrException(ErrorCode.BAD_REQUEST, "action is a required param");
+    }
+
+    rsp.setHttpCaching(false);
+  }
+
+  private void handleResponse(String operation, ZkNodeProps m,
+      SolrQueryResponse rsp, long timeout) throws KeeperException, InterruptedException {
+    long time = System.nanoTime();
+
+    QueueEvent event = coreContainer.getZkController()
+        .getOverseerConfigSetQueue()
+        .offer(Utils.toJSON(m), timeout);
+    if (event.getBytes() != null) {
+      SolrResponse response = SolrResponse.deserialize(event.getBytes());
+      rsp.getValues().addAll(response.getResponse());
+      SimpleOrderedMap exp = (SimpleOrderedMap) response.getResponse().get("exception");
+      if (exp != null) {
+        Integer code = (Integer) exp.get("rspCode");
+        rsp.setException(new SolrException(code != null && code != -1 ? ErrorCode.getErrorCode(code) : ErrorCode.SERVER_ERROR, (String)exp.get("msg")));
+      }
+    } else {
+      if (System.nanoTime() - time >= TimeUnit.NANOSECONDS.convert(timeout, TimeUnit.MILLISECONDS)) {
+        throw new SolrException(ErrorCode.SERVER_ERROR, operation
+            + " the configset time out:" + timeout / 1000 + "s");
+      } else if (event.getWatchedEvent() != null) {
+        throw new SolrException(ErrorCode.SERVER_ERROR, operation
+            + " the configset error [Watcher fired on path: "
+            + event.getWatchedEvent().getPath() + " state: "
+            + event.getWatchedEvent().getState() + " type "
+            + event.getWatchedEvent().getType() + "]");
+      } else {
+        throw new SolrException(ErrorCode.SERVER_ERROR, operation
+            + " the configset unknown case");
+      }
+    }
+  }
+
+  private static Map<String, Object> copyPropertiesWithPrefix(SolrParams params, Map<String, Object> props, String prefix) {
+    Iterator<String> iter =  params.getParameterNamesIterator();
+    while (iter.hasNext()) {
+      String param = iter.next();
+      if (param.startsWith(prefix)) {
+        props.put(param, params.get(param));
+      }
+    }
+    return props;
+  }
+
+  @Override
+  public String getDescription() {
+    return "Manage SolrCloud ConfigSets";
+  }
+
+  enum ConfigSetOperation {
+    CREATE_OP(CREATE) {
+      @Override
+      Map<String, Object> call(SolrQueryRequest req, SolrQueryResponse rsp, ConfigSetsHandler h) throws Exception {
+        Map<String, Object> props = req.getParams().required().getAll(null, NAME, BASE_CONFIGSET);
+        return copyPropertiesWithPrefix(req.getParams(), props, PROPERTY_PREFIX + ".");
+      }
+    },
+    DELETE_OP(DELETE) {
+      @Override
+      Map<String, Object> call(SolrQueryRequest req, SolrQueryResponse rsp, ConfigSetsHandler h) throws Exception {
+        return req.getParams().required().getAll(null, NAME);
+      }
+    };
+
+    ConfigSetAction action;
+
+    ConfigSetOperation(ConfigSetAction action) {
+      this.action = action;
+    }
+
+    abstract Map<String, Object> call(SolrQueryRequest req, SolrQueryResponse rsp, ConfigSetsHandler h) throws Exception;
+
+    public static ConfigSetOperation get(ConfigSetAction action) {
+      for (ConfigSetOperation op : values()) {
+        if (op.action == action) return op;
+      }
+      throw new SolrException(ErrorCode.SERVER_ERROR, "No such action" + action);
+    }
+  }
+}
diff --git a/solr/core/src/java/org/apache/solr/handler/admin/RebalanceLeaders.java b/solr/core/src/java/org/apache/solr/handler/admin/RebalanceLeaders.java
index 9f45fac..e7bce61 100644
--- a/solr/core/src/java/org/apache/solr/handler/admin/RebalanceLeaders.java
+++ b/solr/core/src/java/org/apache/solr/handler/admin/RebalanceLeaders.java
@@ -25,7 +25,7 @@ import java.util.Map;
 
 import org.apache.commons.lang.StringUtils;
 import org.apache.solr.cloud.LeaderElector;
-import org.apache.solr.cloud.OverseerProcessor;
+import org.apache.solr.cloud.OverseerTaskProcessor;
 import org.apache.solr.cloud.overseer.SliceMutator;
 import org.apache.solr.common.SolrException;
 import org.apache.solr.common.cloud.ClusterState;
@@ -160,7 +160,7 @@ class RebalanceLeaders {
 
       ZkStateReader zkStateReader = coreContainer.getZkController().getZkStateReader();
 
-      List<String> electionNodes = OverseerProcessor.getSortedElectionNodes(zkStateReader.getZkClient(),
+      List<String> electionNodes = OverseerTaskProcessor.getSortedElectionNodes(zkStateReader.getZkClient(),
           ZkStateReader.getShardLeadersElectPath(collectionName, slice.getName()));
 
       if (electionNodes.size() < 2) { // if there's only one node in the queue, should already be leader and we shouldn't be here anyway.
@@ -193,7 +193,7 @@ class RebalanceLeaders {
       throws KeeperException, InterruptedException {
 
     ZkStateReader zkStateReader = coreContainer.getZkController().getZkStateReader();
-    List<String> electionNodes = OverseerProcessor.getSortedElectionNodes(zkStateReader.getZkClient(),
+    List<String> electionNodes = OverseerTaskProcessor.getSortedElectionNodes(zkStateReader.getZkClient(),
         ZkStateReader.getShardLeadersElectPath(collectionName, slice.getName()));
 
     // First, queue up the preferred leader at the head of the queue.
@@ -210,12 +210,12 @@ class RebalanceLeaders {
       return; // let's not continue if we didn't get what we expect. Possibly we're offline etc..
     }
 
-    List<String> electionNodesTmp = OverseerProcessor.getSortedElectionNodes(zkStateReader.getZkClient(),
+    List<String> electionNodesTmp = OverseerTaskProcessor.getSortedElectionNodes(zkStateReader.getZkClient(),
         ZkStateReader.getShardLeadersElectPath(collectionName, slice.getName()));
 
 
     // Now find other nodes that have the same sequence number as this node and re-queue them at the end of the queue.
-    electionNodes = OverseerProcessor.getSortedElectionNodes(zkStateReader.getZkClient(),
+    electionNodes = OverseerTaskProcessor.getSortedElectionNodes(zkStateReader.getZkClient(),
         ZkStateReader.getShardLeadersElectPath(collectionName, slice.getName()));
 
     for (String thisNode : electionNodes) {
@@ -238,7 +238,7 @@ class RebalanceLeaders {
     int oldSeq = LeaderElector.getSeq(electionNode);
     for (int idx = 0; idx < 600; ++idx) {
       ZkStateReader zkStateReader = coreContainer.getZkController().getZkStateReader();
-      List<String> electionNodes = OverseerProcessor.getSortedElectionNodes(zkStateReader.getZkClient(),
+      List<String> electionNodes = OverseerTaskProcessor.getSortedElectionNodes(zkStateReader.getZkClient(),
           ZkStateReader.getShardLeadersElectPath(collectionName, slice.getName()));
       for (String testNode : electionNodes) {
         if (LeaderElector.getNodeName(testNode).equals(nodeName) && oldSeq != LeaderElector.getSeq(testNode)) {
diff --git a/solr/core/src/test-files/solr/solr-50-all.xml b/solr/core/src/test-files/solr/solr-50-all.xml
index 28b445c..a0f3165 100644
--- a/solr/core/src/test-files/solr/solr-50-all.xml
+++ b/solr/core/src/test-files/solr/solr-50-all.xml
@@ -21,6 +21,7 @@
   <int name="coreLoadThreads">11</int>
   <str name="coreRootDirectory">${coreRootDirectory:testCoreRootDirectory}</str>
   <str name="infoHandler">testInfoHandler</str>
+  <str name="configSetsHandler">testConfigSetsHandler</str>
   <str name="managementPath">testManagementPath</str>
   <str name="sharedLib">testSharedLib</str>
   <str name="shareSchema">${shareSchema:true}</str>
diff --git a/solr/core/src/test/org/apache/solr/cloud/OverseerCollectionConfigSetProcessorTest.java b/solr/core/src/test/org/apache/solr/cloud/OverseerCollectionConfigSetProcessorTest.java
new file mode 100644
index 0000000..952522a
--- /dev/null
+++ b/solr/core/src/test/org/apache/solr/cloud/OverseerCollectionConfigSetProcessorTest.java
@@ -0,0 +1,806 @@
+package org.apache.solr.cloud;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.solr.SolrTestCaseJ4;
+import org.apache.solr.client.solrj.SolrResponse;
+import org.apache.solr.client.solrj.response.QueryResponse;
+import org.apache.solr.cloud.OverseerTaskQueue.QueueEvent;
+import org.apache.solr.cloud.Overseer.LeaderStatus;
+import org.apache.solr.common.cloud.ClusterState;
+import org.apache.solr.common.cloud.SolrZkClient;
+import org.apache.solr.common.cloud.ZkNodeProps;
+import org.apache.solr.common.cloud.ZkStateReader;
+import org.apache.solr.common.params.CollectionParams;
+import org.apache.solr.common.params.CoreAdminParams;
+import org.apache.solr.common.params.CoreAdminParams.CoreAdminAction;
+import org.apache.solr.common.params.ModifiableSolrParams;
+import org.apache.solr.common.util.StrUtils;
+import org.apache.solr.common.util.Utils;
+import org.apache.solr.handler.component.ShardHandler;
+import org.apache.solr.handler.component.ShardHandlerFactory;
+import org.apache.solr.handler.component.ShardRequest;
+import org.apache.solr.handler.component.ShardResponse;
+import org.apache.solr.util.TimeOut;
+import org.apache.zookeeper.CreateMode;
+import org.easymock.Capture;
+import org.easymock.EasyMock;
+import org.easymock.IAnswer;
+import org.junit.After;
+import org.junit.AfterClass;
+import org.junit.Before;
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+import java.util.Map.Entry;
+import java.util.Queue;
+import java.util.Set;
+import java.util.concurrent.ArrayBlockingQueue;
+import java.util.concurrent.TimeUnit;
+
+import static org.easymock.EasyMock.anyBoolean;
+import static org.easymock.EasyMock.anyObject;
+import static org.easymock.EasyMock.capture;
+import static org.easymock.EasyMock.createMock;
+import static org.easymock.EasyMock.expect;
+import static org.easymock.EasyMock.expectLastCall;
+import static org.easymock.EasyMock.getCurrentArguments;
+import static org.easymock.EasyMock.replay;
+import static org.easymock.EasyMock.reset;
+import static org.easymock.EasyMock.verify;
+
+public class OverseerCollectionConfigSetProcessorTest extends SolrTestCaseJ4 {
+  
+  private static final String ADMIN_PATH = "/admin/cores";
+  private static final String COLLECTION_NAME = "mycollection";
+  private static final String CONFIG_NAME = "myconfig";
+  
+  private static OverseerTaskQueue workQueueMock;
+  private static DistributedMap runningMapMock;
+  private static DistributedMap completedMapMock;
+  private static DistributedMap failureMapMock;
+  private static ShardHandlerFactory shardHandlerFactoryMock;
+  private static ShardHandler shardHandlerMock;
+  private static ZkStateReader zkStateReaderMock;
+  private static ClusterState clusterStateMock;
+  private static SolrZkClient solrZkClientMock;
+  private final Map zkMap = new HashMap();
+  private final Set collectionsSet = new HashSet();
+  private SolrResponse lastProcessMessageResult;
+
+
+  private OverseerCollectionConfigSetProcessorToBeTested underTest;
+  
+  private Thread thread;
+  private Queue<QueueEvent> queue = new ArrayBlockingQueue<>(10);
+
+  private class OverseerCollectionConfigSetProcessorToBeTested extends
+      OverseerCollectionConfigSetProcessor {
+    
+
+    public OverseerCollectionConfigSetProcessorToBeTested(ZkStateReader zkStateReader,
+        String myId, ShardHandlerFactory shardHandlerFactory,
+        String adminPath,
+        OverseerTaskQueue workQueue, DistributedMap runningMap,
+        DistributedMap completedMap,
+        DistributedMap failureMap) {
+      super(zkStateReader, myId, shardHandlerFactory, adminPath, new Overseer.Stats(), null, new OverseerNodePrioritizer(zkStateReader, adminPath, shardHandlerFactory), workQueue, runningMap, completedMap, failureMap);
+    }
+    
+    @Override
+    protected LeaderStatus amILeader() {
+      return LeaderStatus.YES;
+    }
+    
+  }
+  
+  @BeforeClass
+  public static void setUpOnce() throws Exception {
+    workQueueMock = createMock(OverseerTaskQueue.class);
+    runningMapMock = createMock(DistributedMap.class);
+    completedMapMock = createMock(DistributedMap.class);
+    failureMapMock = createMock(DistributedMap.class);
+    shardHandlerFactoryMock = createMock(ShardHandlerFactory.class);
+    shardHandlerMock = createMock(ShardHandler.class);
+    zkStateReaderMock = createMock(ZkStateReader.class);
+    clusterStateMock = createMock(ClusterState.class);
+    solrZkClientMock = createMock(SolrZkClient.class);
+
+  }
+  
+  @AfterClass
+  public static void tearDownOnce() {
+    workQueueMock = null;
+    runningMapMock = null;
+    completedMapMock = null;
+    failureMapMock = null;
+    shardHandlerFactoryMock = null;
+    shardHandlerMock = null;
+    zkStateReaderMock = null;
+    clusterStateMock = null;
+    solrZkClientMock = null;
+  }
+  
+  @Before
+  public void setUp() throws Exception {
+    super.setUp();
+    queue.clear();
+    reset(workQueueMock);
+    reset(runningMapMock);
+    reset(completedMapMock);
+    reset(failureMapMock);
+    reset(shardHandlerFactoryMock);
+    reset(shardHandlerMock);
+    reset(zkStateReaderMock);
+    reset(clusterStateMock);
+    reset(solrZkClientMock);
+    underTest = new OverseerCollectionConfigSetProcessorToBeTested(zkStateReaderMock,
+        "1234", shardHandlerFactoryMock, ADMIN_PATH, workQueueMock, runningMapMock,
+        completedMapMock, failureMapMock);
+    zkMap.clear();
+    collectionsSet.clear();
+  }
+  
+  @After
+  public void tearDown() throws Exception {
+    stopComponentUnderTest();
+    super.tearDown();
+  }
+  
+  protected Set<String> commonMocks(int liveNodesCount) throws Exception {
+
+    shardHandlerFactoryMock.getShardHandler();
+    expectLastCall().andAnswer(new IAnswer<ShardHandler>() {
+      @Override
+      public ShardHandler answer() throws Throwable {
+        log.info("SHARDHANDLER");
+        return shardHandlerMock;
+      }
+    }).anyTimes();
+    workQueueMock.peekTopN(EasyMock.anyInt(), anyObject(Set.class), EasyMock.anyLong());
+    expectLastCall().andAnswer(new IAnswer<List>() {
+      @Override
+      public List answer() throws Throwable {
+        Object result;
+        int count = 0;
+        while ((result = queue.peek()) == null) {
+          Thread.sleep(1000);
+          count++;
+          if (count > 1) return null;
+        }
+
+        return Arrays.asList(result);
+      }
+    }).anyTimes();
+
+    workQueueMock.getTailId();
+    expectLastCall().andAnswer(new IAnswer<Object>() {
+      @Override
+      public Object answer() throws Throwable {
+        Object result = null;
+        Iterator iter = queue.iterator();
+        while(iter.hasNext()) {
+          result = iter.next();
+        }
+        return result==null ? null : ((QueueEvent)result).getId();
+      }
+    }).anyTimes();
+
+    workQueueMock.peek(true);
+    expectLastCall().andAnswer(new IAnswer<Object>() {
+      @Override
+      public Object answer() throws Throwable {
+        Object result;
+        while ((result = queue.peek()) == null) {
+          Thread.sleep(1000);
+        }
+        return result;
+      }
+    }).anyTimes();
+    
+    workQueueMock.remove(anyObject(QueueEvent.class));
+    expectLastCall().andAnswer(new IAnswer<Object>() {
+      @Override
+      public Object answer() throws Throwable {
+        queue.remove((QueueEvent) getCurrentArguments()[0]);
+        return null;
+      }
+    }).anyTimes();
+    
+    workQueueMock.poll();
+    expectLastCall().andAnswer(new IAnswer<Object>() {
+      @Override
+      public Object answer() throws Throwable {
+        return queue.poll();
+      }
+    }).anyTimes();
+
+    zkStateReaderMock.getClusterState();
+    expectLastCall().andAnswer(new IAnswer<Object>() {
+      @Override
+      public Object answer() throws Throwable {
+        return clusterStateMock;
+      }
+    }).anyTimes();
+    
+    zkStateReaderMock.getZkClient();
+    expectLastCall().andAnswer(new IAnswer<Object>() {
+      @Override
+      public Object answer() throws Throwable {
+        return solrZkClientMock;
+      }
+    }).anyTimes();
+
+    zkStateReaderMock.updateClusterState();
+
+    clusterStateMock.getCollections();
+    expectLastCall().andAnswer(new IAnswer<Object>() {
+      @Override
+      public Object answer() throws Throwable {
+        return collectionsSet;
+      }
+    }).anyTimes();
+    final Set<String> liveNodes = new HashSet<>();
+    for (int i = 0; i < liveNodesCount; i++) {
+      final String address = "localhost:" + (8963 + i) + "_solr";
+      liveNodes.add(address);
+      
+      zkStateReaderMock.getBaseUrlForNodeName(address);
+      expectLastCall().andAnswer(new IAnswer<Object>() {
+        @Override
+        public Object answer() throws Throwable {
+          // This works as long as this test does not use a 
+          // webapp context with an underscore in it
+          return address.replaceAll("_", "/");
+        }
+      }).anyTimes();
+      
+    }
+    zkStateReaderMock.getClusterProps();
+    expectLastCall().andAnswer(new IAnswer<Map>() {
+      @Override
+      public Map answer() throws Throwable {
+        return new HashMap();
+      }
+    });
+
+    solrZkClientMock.getZkClientTimeout();
+    expectLastCall().andAnswer(new IAnswer<Object>() {
+      @Override
+      public Object answer() throws Throwable {
+        return 30000;
+      }
+    }).anyTimes();
+    
+    clusterStateMock.hasCollection(anyObject(String.class));
+    expectLastCall().andAnswer(new IAnswer<Boolean>() {
+      @Override
+      public Boolean answer() throws Throwable {
+        String key = (String) getCurrentArguments()[0];
+        return collectionsSet.contains(key);
+      }
+    } ).anyTimes();
+
+
+    clusterStateMock.getLiveNodes();
+    expectLastCall().andAnswer(new IAnswer<Object>() {
+      @Override
+      public Object answer() throws Throwable {
+        return liveNodes;
+      }
+    }).anyTimes();
+    solrZkClientMock.create(anyObject(String.class), anyObject(byte[].class), anyObject(CreateMode.class), anyBoolean());
+    expectLastCall().andAnswer(new IAnswer<String>() {
+      @Override
+      public String answer() throws Throwable {
+        String key = (String) getCurrentArguments()[0];
+        zkMap.put(key, null);
+        handleCreateCollMessage((byte[]) getCurrentArguments()[1]);
+        return key;
+      }
+    }).anyTimes();
+
+    solrZkClientMock.makePath(anyObject(String.class), anyObject(byte[].class), anyBoolean());
+    expectLastCall().andAnswer(new IAnswer<String>() {
+      @Override
+      public String answer() throws Throwable {
+        String key = (String) getCurrentArguments()[0];
+        return key;
+      }
+    }).anyTimes();
+
+    solrZkClientMock.makePath(anyObject(String.class), anyObject(byte[].class), anyObject(CreateMode.class), anyBoolean());
+    expectLastCall().andAnswer(new IAnswer<String>() {
+      @Override
+      public String answer() throws Throwable {
+        String key = (String) getCurrentArguments()[0];
+        return key;
+      }
+    }).anyTimes();
+
+    solrZkClientMock.exists(anyObject(String.class),anyBoolean());
+    expectLastCall().andAnswer(new IAnswer<Boolean>() {
+      @Override
+      public Boolean answer() throws Throwable {
+        String key = (String) getCurrentArguments()[0];
+        return zkMap.containsKey(key);
+      }
+    }).anyTimes();
+    
+    zkMap.put("/configs/myconfig", null);
+    
+    return liveNodes;
+  }
+
+  private void handleCreateCollMessage(byte[] bytes) {
+    try {
+      ZkNodeProps props = ZkNodeProps.load(bytes);
+      if(CollectionParams.CollectionAction.CREATE.isEqual(props.getStr("operation"))){
+        String collName = props.getStr("name") ;
+        if(collName != null) collectionsSet.add(collName);
+      }
+    } catch (Exception e) { }
+  }
+
+  protected void startComponentUnderTest() {
+    thread = new Thread(underTest);
+    thread.start();
+  }
+  
+  protected void stopComponentUnderTest() throws Exception {
+    underTest.close();
+    thread.interrupt();
+    thread.join();
+  }
+  
+  private class SubmitCapture {
+    public Capture<ShardRequest> shardRequestCapture = new Capture<>();
+    public Capture<String> nodeUrlsWithoutProtocolPartCapture = new Capture<>();
+    public Capture<ModifiableSolrParams> params = new Capture<>();
+  }
+  
+  protected List<SubmitCapture> mockShardHandlerForCreateJob(
+      Integer numberOfSlices, Integer numberOfReplica) {
+    List<SubmitCapture> submitCaptures = new ArrayList<>();
+    for (int i = 0; i < (numberOfSlices * numberOfReplica); i++) {
+      SubmitCapture submitCapture = new SubmitCapture();
+      shardHandlerMock.submit(capture(submitCapture.shardRequestCapture),
+          capture(submitCapture.nodeUrlsWithoutProtocolPartCapture),
+          capture(submitCapture.params));
+      expectLastCall();
+      submitCaptures.add(submitCapture);
+      ShardResponse shardResponseWithoutException = new ShardResponse();
+      shardResponseWithoutException.setSolrResponse(new QueryResponse());
+      expect(shardHandlerMock.takeCompletedOrError()).andReturn(
+          shardResponseWithoutException);
+    }
+    expect(shardHandlerMock.takeCompletedOrError()).andReturn(null);
+    return submitCaptures;
+  }
+  
+  protected void issueCreateJob(Integer numberOfSlices,
+      Integer replicationFactor, Integer maxShardsPerNode, List<String> createNodeList, boolean sendCreateNodeList, boolean createNodeSetShuffle) {
+    Map<String,Object> propMap = Utils.makeMap(
+        Overseer.QUEUE_OPERATION, CollectionParams.CollectionAction.CREATE.toLower(),
+        ZkStateReader.REPLICATION_FACTOR, replicationFactor.toString(),
+        "name", COLLECTION_NAME,
+        "collection.configName", CONFIG_NAME,
+        OverseerCollectionMessageHandler.NUM_SLICES, numberOfSlices.toString(),
+        ZkStateReader.MAX_SHARDS_PER_NODE, maxShardsPerNode.toString()
+    );
+    if (sendCreateNodeList) {
+      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET,
+          (createNodeList != null)?StrUtils.join(createNodeList, ','):null);
+      if (OverseerCollectionMessageHandler.CREATE_NODE_SET_SHUFFLE_DEFAULT != createNodeSetShuffle || random().nextBoolean()) {
+        propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET_SHUFFLE, createNodeSetShuffle);
+      }
+    }
+
+    ZkNodeProps props = new ZkNodeProps(propMap);
+    QueueEvent qe = new QueueEvent("id", Utils.toJSON(props), null){
+      @Override
+      public void setBytes(byte[] bytes) {
+        lastProcessMessageResult = SolrResponse.deserialize( bytes);
+      }
+    };
+    queue.add(qe);
+  }
+  
+  protected void verifySubmitCaptures(List<SubmitCapture> submitCaptures,
+      Integer numberOfSlices, Integer numberOfReplica, Collection<String> createNodes, boolean dontShuffleCreateNodeSet) {
+    List<String> coreNames = new ArrayList<>();
+    Map<String,Map<String,Integer>> sliceToNodeUrlsWithoutProtocolPartToNumberOfShardsRunningMapMap = new HashMap<>();
+    List<String> nodeUrlWithoutProtocolPartForLiveNodes = new ArrayList<>(
+        createNodes.size());
+    for (String nodeName : createNodes) {
+      String nodeUrlWithoutProtocolPart = nodeName.replaceAll("_", "/");
+      if (nodeUrlWithoutProtocolPart.startsWith("http://")) nodeUrlWithoutProtocolPart = nodeUrlWithoutProtocolPart
+          .substring(7);
+      nodeUrlWithoutProtocolPartForLiveNodes.add(nodeUrlWithoutProtocolPart);
+    }
+    final Map<String,String> coreName_TO_nodeUrlWithoutProtocolPartForLiveNodes_map = new HashMap<>();
+    
+    for (SubmitCapture submitCapture : submitCaptures) {
+      ShardRequest shardRequest = submitCapture.shardRequestCapture.getValue();
+      assertEquals(CoreAdminAction.CREATE.toString(),
+          shardRequest.params.get(CoreAdminParams.ACTION));
+      // assertEquals(shardRequest.params, submitCapture.params);
+      String coreName = shardRequest.params.get(CoreAdminParams.NAME);
+      assertFalse("Core with name " + coreName + " created twice",
+          coreNames.contains(coreName));
+      coreNames.add(coreName);
+      assertEquals(CONFIG_NAME,
+          shardRequest.params.get("collection.configName"));
+      assertEquals(COLLECTION_NAME,
+          shardRequest.params.get(CoreAdminParams.COLLECTION));
+      assertEquals(numberOfSlices.toString(),
+          shardRequest.params.get(ZkStateReader.NUM_SHARDS_PROP));
+      assertEquals(ADMIN_PATH, shardRequest.params.get("qt"));
+      assertEquals(1, shardRequest.purpose);
+      assertEquals(1, shardRequest.shards.length);
+      assertEquals(submitCapture.nodeUrlsWithoutProtocolPartCapture.getValue(),
+          shardRequest.shards[0]);
+      assertTrue("Shard " + coreName + " created on wrong node "
+          + shardRequest.shards[0],
+          nodeUrlWithoutProtocolPartForLiveNodes
+              .contains(shardRequest.shards[0]));
+      coreName_TO_nodeUrlWithoutProtocolPartForLiveNodes_map.put(coreName, shardRequest.shards[0]);
+      assertEquals(shardRequest.shards, shardRequest.actualShards);
+      
+      String sliceName = shardRequest.params.get(CoreAdminParams.SHARD);
+      if (!sliceToNodeUrlsWithoutProtocolPartToNumberOfShardsRunningMapMap
+          .containsKey(sliceName)) {
+        sliceToNodeUrlsWithoutProtocolPartToNumberOfShardsRunningMapMap.put(
+            sliceName, new HashMap<String,Integer>());
+      }
+      Map<String,Integer> nodeUrlsWithoutProtocolPartToNumberOfShardsRunningMap = sliceToNodeUrlsWithoutProtocolPartToNumberOfShardsRunningMapMap
+          .get(sliceName);
+      Integer existingCount;
+      nodeUrlsWithoutProtocolPartToNumberOfShardsRunningMap
+          .put(
+              shardRequest.shards[0],
+              ((existingCount = nodeUrlsWithoutProtocolPartToNumberOfShardsRunningMap
+                  .get(shardRequest.shards[0])) == null) ? 1
+                  : (existingCount + 1));
+    }
+    
+    assertEquals(numberOfSlices * numberOfReplica, coreNames.size());
+    for (int i = 1; i <= numberOfSlices; i++) {
+      for (int j = 1; j <= numberOfReplica; j++) {
+        String coreName = COLLECTION_NAME + "_shard" + i + "_replica" + j;
+        assertTrue("Shard " + coreName + " was not created",
+            coreNames.contains(coreName));
+        
+        if (dontShuffleCreateNodeSet) {
+          final String expectedNodeName = nodeUrlWithoutProtocolPartForLiveNodes.get((numberOfReplica * (i - 1) + (j - 1)) % nodeUrlWithoutProtocolPartForLiveNodes.size());
+          assertFalse("expectedNodeName is null for coreName="+coreName, null == expectedNodeName);
+          
+          final String actualNodeName = coreName_TO_nodeUrlWithoutProtocolPartForLiveNodes_map.get(coreName);
+          assertFalse("actualNodeName is null for coreName="+coreName, null == actualNodeName);
+
+          assertTrue("node name mismatch for coreName="+coreName+" ( actual="+actualNodeName+" versus expected="+expectedNodeName+" )", actualNodeName.equals(expectedNodeName));
+        }
+      }
+    }
+    
+    assertEquals(numberOfSlices.intValue(),
+        sliceToNodeUrlsWithoutProtocolPartToNumberOfShardsRunningMapMap.size());
+    for (int i = 1; i <= numberOfSlices; i++) {
+      sliceToNodeUrlsWithoutProtocolPartToNumberOfShardsRunningMapMap.keySet()
+          .contains("shard" + i);
+    }
+    int minShardsPerSlicePerNode = numberOfReplica / createNodes.size();
+    int numberOfNodesSupposedToRunMaxShards = numberOfReplica
+        % createNodes.size();
+    int numberOfNodesSupposedToRunMinShards = createNodes.size()
+        - numberOfNodesSupposedToRunMaxShards;
+    int maxShardsPerSlicePerNode = (minShardsPerSlicePerNode + 1);
+    if (numberOfNodesSupposedToRunMaxShards == 0) {
+      numberOfNodesSupposedToRunMaxShards = numberOfNodesSupposedToRunMinShards;
+      maxShardsPerSlicePerNode = minShardsPerSlicePerNode;
+    }
+    boolean diffBetweenMinAndMaxShardsPerSlicePerNode = (maxShardsPerSlicePerNode != minShardsPerSlicePerNode);
+    
+    for (Entry<String,Map<String,Integer>> sliceToNodeUrlsWithoutProtocolPartToNumberOfShardsRunningMapMapEntry : sliceToNodeUrlsWithoutProtocolPartToNumberOfShardsRunningMapMap
+        .entrySet()) {
+      int numberOfShardsRunning = 0;
+      int numberOfNodesRunningMinShards = 0;
+      int numberOfNodesRunningMaxShards = 0;
+      int numberOfNodesRunningAtLeastOneShard = 0;
+      for (String nodeUrlsWithoutProtocolPart : sliceToNodeUrlsWithoutProtocolPartToNumberOfShardsRunningMapMapEntry
+          .getValue().keySet()) {
+        int numberOfShardsRunningOnThisNode = sliceToNodeUrlsWithoutProtocolPartToNumberOfShardsRunningMapMapEntry
+            .getValue().get(nodeUrlsWithoutProtocolPart);
+        numberOfShardsRunning += numberOfShardsRunningOnThisNode;
+        numberOfNodesRunningAtLeastOneShard++;
+        assertTrue(
+            "Node "
+                + nodeUrlsWithoutProtocolPart
+                + " is running wrong number of shards. Supposed to run "
+                + minShardsPerSlicePerNode
+                + (diffBetweenMinAndMaxShardsPerSlicePerNode ? (" or " + maxShardsPerSlicePerNode)
+                    : ""),
+            (numberOfShardsRunningOnThisNode == minShardsPerSlicePerNode)
+                || (numberOfShardsRunningOnThisNode == maxShardsPerSlicePerNode));
+        if (numberOfShardsRunningOnThisNode == minShardsPerSlicePerNode) numberOfNodesRunningMinShards++;
+        if (numberOfShardsRunningOnThisNode == maxShardsPerSlicePerNode) numberOfNodesRunningMaxShards++;
+      }
+      if (minShardsPerSlicePerNode == 0) numberOfNodesRunningMinShards = (createNodes
+          .size() - numberOfNodesRunningAtLeastOneShard);
+      assertEquals(
+          "Too many shards are running under slice "
+              + sliceToNodeUrlsWithoutProtocolPartToNumberOfShardsRunningMapMapEntry
+                  .getKey(),
+          numberOfReplica.intValue(), numberOfShardsRunning);
+      assertEquals(numberOfNodesSupposedToRunMinShards,
+          numberOfNodesRunningMinShards);
+      assertEquals(numberOfNodesSupposedToRunMaxShards,
+          numberOfNodesRunningMaxShards);
+    }
+  }
+  
+  protected void waitForEmptyQueue(long maxWait) throws Exception {
+    final TimeOut timeout = new TimeOut(maxWait, TimeUnit.MILLISECONDS);
+    while (queue.peek() != null) {
+      if (timeout.hasTimedOut())
+        fail("Queue not empty within " + maxWait + " ms");
+      Thread.sleep(100);
+    }
+  }
+  
+  protected enum CreateNodeListOptions {
+    SEND,
+    DONT_SEND,
+    SEND_NULL
+  }
+  protected void testTemplate(Integer numberOfNodes, Integer numberOfNodesToCreateOn, CreateNodeListOptions createNodeListOption, Integer replicationFactor,
+      Integer numberOfSlices, Integer maxShardsPerNode,
+      boolean collectionExceptedToBeCreated) throws Exception {
+    assertTrue("Wrong usage of testTemplate. numberOfNodesToCreateOn " + numberOfNodesToCreateOn + " is not allowed to be higher than numberOfNodes " + numberOfNodes, numberOfNodes.intValue() >= numberOfNodesToCreateOn.intValue());
+    assertTrue("Wrong usage of testTemplage. createNodeListOption has to be " + CreateNodeListOptions.SEND + " when numberOfNodes and numberOfNodesToCreateOn are unequal", ((createNodeListOption == CreateNodeListOptions.SEND) || (numberOfNodes.intValue() == numberOfNodesToCreateOn.intValue())));
+    
+    Set<String> liveNodes = commonMocks(numberOfNodes);
+    List<String> createNodeList = new ArrayList<>();
+    int i = 0;
+    for (String node : liveNodes) {
+      if (i++ < numberOfNodesToCreateOn) {
+        createNodeList.add(node);
+      }
+    }
+    
+    if (random().nextBoolean()) Collections.shuffle(createNodeList, OverseerCollectionMessageHandler.RANDOM);
+    
+    List<SubmitCapture> submitCaptures = null;
+    if (collectionExceptedToBeCreated) {
+      submitCaptures = mockShardHandlerForCreateJob(numberOfSlices,
+          replicationFactor);
+    }
+    
+    replay(workQueueMock);
+    replay(solrZkClientMock);
+    replay(zkStateReaderMock);
+    replay(clusterStateMock);
+    replay(shardHandlerFactoryMock);
+    replay(shardHandlerMock);
+
+
+    log.info("clusterstate " + clusterStateMock.hashCode());
+
+    startComponentUnderTest();
+    
+    final List<String> createNodeListToSend = ((createNodeListOption != CreateNodeListOptions.SEND_NULL) ? createNodeList : null);
+    final boolean sendCreateNodeList = (createNodeListOption != CreateNodeListOptions.DONT_SEND);
+    final boolean dontShuffleCreateNodeSet = (createNodeListToSend != null) && sendCreateNodeList && random().nextBoolean();
+    issueCreateJob(numberOfSlices, replicationFactor, maxShardsPerNode, createNodeListToSend, sendCreateNodeList, !dontShuffleCreateNodeSet);
+    waitForEmptyQueue(10000);
+    
+    if (collectionExceptedToBeCreated) {
+      assertNotNull(lastProcessMessageResult.getResponse().toString(), lastProcessMessageResult);
+    }
+    verify(shardHandlerFactoryMock);
+    verify(shardHandlerMock);
+
+    if (collectionExceptedToBeCreated) {
+      verifySubmitCaptures(submitCaptures, numberOfSlices, replicationFactor,
+          createNodeList, dontShuffleCreateNodeSet);
+    }
+  }
+    @Test
+  public void testNoReplicationEqualNumberOfSlicesPerNode() throws Exception {
+    Integer numberOfNodes = 4;
+    Integer numberOfNodesToCreateOn = 4;
+    CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.DONT_SEND;
+    Integer replicationFactor = 1;
+    Integer numberOfSlices = 8;
+    Integer maxShardsPerNode = 2;
+    testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
+        maxShardsPerNode, true);
+  }
+  
+  @Test
+  public void testReplicationEqualNumberOfSlicesPerNode() throws Exception {
+    Integer numberOfNodes = 4;
+    Integer numberOfNodesToCreateOn = 4;
+    CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.DONT_SEND;
+    Integer replicationFactor = 2;
+    Integer numberOfSlices = 4;
+    Integer maxShardsPerNode = 2;
+    testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
+        maxShardsPerNode, true);
+  }
+  
+  @Test
+  public void testNoReplicationEqualNumberOfSlicesPerNodeSendCreateNodesEqualToLiveNodes() throws Exception {
+    Integer numberOfNodes = 4;
+    Integer numberOfNodesToCreateOn = 4;
+    CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.SEND;
+    Integer replicationFactor = 1;
+    Integer numberOfSlices = 8;
+    Integer maxShardsPerNode = 2;
+    testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
+        maxShardsPerNode, true);
+  }
+  
+  @Test
+  public void testReplicationEqualNumberOfSlicesPerNodeSendCreateNodesEqualToLiveNodes() throws Exception {
+    Integer numberOfNodes = 4;
+    Integer numberOfNodesToCreateOn = 4;
+    CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.SEND;
+    Integer replicationFactor = 2;
+    Integer numberOfSlices = 4;
+    Integer maxShardsPerNode = 2;
+    testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
+        maxShardsPerNode, true);
+  }
+  
+  @Test
+  public void testNoReplicationEqualNumberOfSlicesPerNodeSendNullCreateNodes() throws Exception {
+    Integer numberOfNodes = 4;
+    Integer numberOfNodesToCreateOn = 4;
+    CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.SEND_NULL;
+    Integer replicationFactor = 1;
+    Integer numberOfSlices = 8;
+    Integer maxShardsPerNode = 2;
+    testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
+        maxShardsPerNode, true);
+  }
+  
+  @Test
+  public void testReplicationEqualNumberOfSlicesPerNodeSendNullCreateNodes() throws Exception {
+    Integer numberOfNodes = 4;
+    Integer numberOfNodesToCreateOn = 4;
+    CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.SEND_NULL;
+    Integer replicationFactor = 2;
+    Integer numberOfSlices = 4;
+    Integer maxShardsPerNode = 2;
+    testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
+        maxShardsPerNode, true);
+  }  
+  
+  @Test
+  public void testNoReplicationUnequalNumberOfSlicesPerNode() throws Exception {
+    Integer numberOfNodes = 4;
+    Integer numberOfNodesToCreateOn = 4;
+    CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.DONT_SEND;
+    Integer replicationFactor = 1;
+    Integer numberOfSlices = 6;
+    Integer maxShardsPerNode = 2;
+    testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
+        maxShardsPerNode, true);
+  }
+  
+  @Test
+  public void testReplicationUnequalNumberOfSlicesPerNode() throws Exception {
+    Integer numberOfNodes = 4;
+    Integer numberOfNodesToCreateOn = 4;
+    CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.DONT_SEND;
+    Integer replicationFactor = 2;
+    Integer numberOfSlices = 3;
+    Integer maxShardsPerNode = 2;
+    testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
+        maxShardsPerNode, true);
+  }
+  
+  @Test
+  public void testNoReplicationCollectionNotCreatedDueToMaxShardsPerNodeLimit()
+      throws Exception {
+    Integer numberOfNodes = 4;
+    Integer numberOfNodesToCreateOn = 4;
+    CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.DONT_SEND;
+    Integer replicationFactor = 1;
+    Integer numberOfSlices = 6;
+    Integer maxShardsPerNode = 1;
+    testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
+        maxShardsPerNode, false);
+  }
+  
+  @Test
+  public void testReplicationCollectionNotCreatedDueToMaxShardsPerNodeLimit()
+      throws Exception {
+    Integer numberOfNodes = 4;
+    Integer numberOfNodesToCreateOn = 4;
+    CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.DONT_SEND;
+    Integer replicationFactor = 2;
+    Integer numberOfSlices = 3;
+    Integer maxShardsPerNode = 1;
+    testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
+        maxShardsPerNode, false);
+  }
+
+  @Test
+  public void testNoReplicationLimitedNodesToCreateOn()
+      throws Exception {
+    Integer numberOfNodes = 4;
+    Integer numberOfNodesToCreateOn = 2;
+    CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.SEND;
+    Integer replicationFactor = 1;
+    Integer numberOfSlices = 6;
+    Integer maxShardsPerNode = 3;
+    testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
+        maxShardsPerNode, true);
+  }
+  
+  @Test
+  public void testReplicationLimitedNodesToCreateOn()
+      throws Exception {
+    Integer numberOfNodes = 4;
+    Integer numberOfNodesToCreateOn = 2;
+    CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.SEND;
+    Integer replicationFactor = 2;
+    Integer numberOfSlices = 3;
+    Integer maxShardsPerNode = 3;
+    testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
+        maxShardsPerNode, true);
+  }
+
+  @Test
+  public void testNoReplicationCollectionNotCreatedDueToMaxShardsPerNodeAndNodesToCreateOnLimits()
+      throws Exception {
+    Integer numberOfNodes = 4;
+    Integer numberOfNodesToCreateOn = 3;
+    CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.SEND;
+    Integer replicationFactor = 1;
+    Integer numberOfSlices = 8;
+    Integer maxShardsPerNode = 2;
+    testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
+        maxShardsPerNode, false);
+  }
+  
+  @Test
+  public void testReplicationCollectionNotCreatedDueToMaxShardsPerNodeAndNodesToCreateOnLimits()
+      throws Exception {
+    Integer numberOfNodes = 4;
+    Integer numberOfNodesToCreateOn = 3;
+    CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.SEND;
+    Integer replicationFactor = 2;
+    Integer numberOfSlices = 4;
+    Integer maxShardsPerNode = 2;
+    testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
+        maxShardsPerNode, false);
+  }
+
+}
diff --git a/solr/core/src/test/org/apache/solr/cloud/OverseerCollectionProcessorTest.java b/solr/core/src/test/org/apache/solr/cloud/OverseerCollectionProcessorTest.java
deleted file mode 100644
index 1c10f7e..0000000
--- a/solr/core/src/test/org/apache/solr/cloud/OverseerCollectionProcessorTest.java
+++ /dev/null
@@ -1,806 +0,0 @@
-package org.apache.solr.cloud;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.solr.SolrTestCaseJ4;
-import org.apache.solr.client.solrj.SolrResponse;
-import org.apache.solr.client.solrj.response.QueryResponse;
-import org.apache.solr.cloud.OverseerCollectionQueue.QueueEvent;
-import org.apache.solr.cloud.Overseer.LeaderStatus;
-import org.apache.solr.common.cloud.ClusterState;
-import org.apache.solr.common.cloud.SolrZkClient;
-import org.apache.solr.common.cloud.ZkNodeProps;
-import org.apache.solr.common.cloud.ZkStateReader;
-import org.apache.solr.common.params.CollectionParams;
-import org.apache.solr.common.params.CoreAdminParams;
-import org.apache.solr.common.params.CoreAdminParams.CoreAdminAction;
-import org.apache.solr.common.params.ModifiableSolrParams;
-import org.apache.solr.common.util.StrUtils;
-import org.apache.solr.common.util.Utils;
-import org.apache.solr.handler.component.ShardHandler;
-import org.apache.solr.handler.component.ShardHandlerFactory;
-import org.apache.solr.handler.component.ShardRequest;
-import org.apache.solr.handler.component.ShardResponse;
-import org.apache.solr.util.TimeOut;
-import org.apache.zookeeper.CreateMode;
-import org.easymock.Capture;
-import org.easymock.EasyMock;
-import org.easymock.IAnswer;
-import org.junit.After;
-import org.junit.AfterClass;
-import org.junit.Before;
-import org.junit.BeforeClass;
-import org.junit.Test;
-
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Map;
-import java.util.Map.Entry;
-import java.util.Queue;
-import java.util.Set;
-import java.util.concurrent.ArrayBlockingQueue;
-import java.util.concurrent.TimeUnit;
-
-import static org.easymock.EasyMock.anyBoolean;
-import static org.easymock.EasyMock.anyObject;
-import static org.easymock.EasyMock.capture;
-import static org.easymock.EasyMock.createMock;
-import static org.easymock.EasyMock.expect;
-import static org.easymock.EasyMock.expectLastCall;
-import static org.easymock.EasyMock.getCurrentArguments;
-import static org.easymock.EasyMock.replay;
-import static org.easymock.EasyMock.reset;
-import static org.easymock.EasyMock.verify;
-
-public class OverseerCollectionProcessorTest extends SolrTestCaseJ4 {
-  
-  private static final String ADMIN_PATH = "/admin/cores";
-  private static final String COLLECTION_NAME = "mycollection";
-  private static final String CONFIG_NAME = "myconfig";
-  
-  private static OverseerCollectionQueue workQueueMock;
-  private static DistributedMap runningMapMock;
-  private static DistributedMap completedMapMock;
-  private static DistributedMap failureMapMock;
-  private static ShardHandlerFactory shardHandlerFactoryMock;
-  private static ShardHandler shardHandlerMock;
-  private static ZkStateReader zkStateReaderMock;
-  private static ClusterState clusterStateMock;
-  private static SolrZkClient solrZkClientMock;
-  private final Map zkMap = new HashMap();
-  private final Set collectionsSet = new HashSet();
-  private SolrResponse lastProcessMessageResult;
-
-
-  private OverseerCollectionProcessorToBeTested underTest;
-  
-  private Thread thread;
-  private Queue<QueueEvent> queue = new ArrayBlockingQueue<>(10);
-
-  private class OverseerCollectionProcessorToBeTested extends
-      OverseerCollectionProcessor {
-    
-
-    public OverseerCollectionProcessorToBeTested(ZkStateReader zkStateReader,
-        String myId, ShardHandlerFactory shardHandlerFactory,
-        String adminPath,
-        OverseerCollectionQueue workQueue, DistributedMap runningMap,
-        DistributedMap completedMap,
-        DistributedMap failureMap) {
-      super(zkStateReader, myId, shardHandlerFactory, adminPath, new Overseer.Stats(), null, new OverseerNodePrioritizer(zkStateReader, adminPath, shardHandlerFactory), workQueue, runningMap, completedMap, failureMap);
-    }
-    
-    @Override
-    protected LeaderStatus amILeader() {
-      return LeaderStatus.YES;
-    }
-    
-  }
-  
-  @BeforeClass
-  public static void setUpOnce() throws Exception {
-    workQueueMock = createMock(OverseerCollectionQueue.class);
-    runningMapMock = createMock(DistributedMap.class);
-    completedMapMock = createMock(DistributedMap.class);
-    failureMapMock = createMock(DistributedMap.class);
-    shardHandlerFactoryMock = createMock(ShardHandlerFactory.class);
-    shardHandlerMock = createMock(ShardHandler.class);
-    zkStateReaderMock = createMock(ZkStateReader.class);
-    clusterStateMock = createMock(ClusterState.class);
-    solrZkClientMock = createMock(SolrZkClient.class);
-
-  }
-  
-  @AfterClass
-  public static void tearDownOnce() {
-    workQueueMock = null;
-    runningMapMock = null;
-    completedMapMock = null;
-    failureMapMock = null;
-    shardHandlerFactoryMock = null;
-    shardHandlerMock = null;
-    zkStateReaderMock = null;
-    clusterStateMock = null;
-    solrZkClientMock = null;
-  }
-  
-  @Before
-  public void setUp() throws Exception {
-    super.setUp();
-    queue.clear();
-    reset(workQueueMock);
-    reset(runningMapMock);
-    reset(completedMapMock);
-    reset(failureMapMock);
-    reset(shardHandlerFactoryMock);
-    reset(shardHandlerMock);
-    reset(zkStateReaderMock);
-    reset(clusterStateMock);
-    reset(solrZkClientMock);
-    underTest = new OverseerCollectionProcessorToBeTested(zkStateReaderMock,
-        "1234", shardHandlerFactoryMock, ADMIN_PATH, workQueueMock, runningMapMock,
-        completedMapMock, failureMapMock);
-    zkMap.clear();
-    collectionsSet.clear();
-  }
-  
-  @After
-  public void tearDown() throws Exception {
-    stopComponentUnderTest();
-    super.tearDown();
-  }
-  
-  protected Set<String> commonMocks(int liveNodesCount) throws Exception {
-
-    shardHandlerFactoryMock.getShardHandler();
-    expectLastCall().andAnswer(new IAnswer<ShardHandler>() {
-      @Override
-      public ShardHandler answer() throws Throwable {
-        log.info("SHARDHANDLER");
-        return shardHandlerMock;
-      }
-    }).anyTimes();
-    workQueueMock.peekTopN(EasyMock.anyInt(), anyObject(Set.class), EasyMock.anyLong());
-    expectLastCall().andAnswer(new IAnswer<List>() {
-      @Override
-      public List answer() throws Throwable {
-        Object result;
-        int count = 0;
-        while ((result = queue.peek()) == null) {
-          Thread.sleep(1000);
-          count++;
-          if (count > 1) return null;
-        }
-
-        return Arrays.asList(result);
-      }
-    }).anyTimes();
-
-    workQueueMock.getTailId();
-    expectLastCall().andAnswer(new IAnswer<Object>() {
-      @Override
-      public Object answer() throws Throwable {
-        Object result = null;
-        Iterator iter = queue.iterator();
-        while(iter.hasNext()) {
-          result = iter.next();
-        }
-        return result==null ? null : ((QueueEvent)result).getId();
-      }
-    }).anyTimes();
-
-    workQueueMock.peek(true);
-    expectLastCall().andAnswer(new IAnswer<Object>() {
-      @Override
-      public Object answer() throws Throwable {
-        Object result;
-        while ((result = queue.peek()) == null) {
-          Thread.sleep(1000);
-        }
-        return result;
-      }
-    }).anyTimes();
-    
-    workQueueMock.remove(anyObject(QueueEvent.class));
-    expectLastCall().andAnswer(new IAnswer<Object>() {
-      @Override
-      public Object answer() throws Throwable {
-        queue.remove((QueueEvent) getCurrentArguments()[0]);
-        return null;
-      }
-    }).anyTimes();
-    
-    workQueueMock.poll();
-    expectLastCall().andAnswer(new IAnswer<Object>() {
-      @Override
-      public Object answer() throws Throwable {
-        return queue.poll();
-      }
-    }).anyTimes();
-
-    zkStateReaderMock.getClusterState();
-    expectLastCall().andAnswer(new IAnswer<Object>() {
-      @Override
-      public Object answer() throws Throwable {
-        return clusterStateMock;
-      }
-    }).anyTimes();
-    
-    zkStateReaderMock.getZkClient();
-    expectLastCall().andAnswer(new IAnswer<Object>() {
-      @Override
-      public Object answer() throws Throwable {
-        return solrZkClientMock;
-      }
-    }).anyTimes();
-
-    zkStateReaderMock.updateClusterState();
-
-    clusterStateMock.getCollections();
-    expectLastCall().andAnswer(new IAnswer<Object>() {
-      @Override
-      public Object answer() throws Throwable {
-        return collectionsSet;
-      }
-    }).anyTimes();
-    final Set<String> liveNodes = new HashSet<>();
-    for (int i = 0; i < liveNodesCount; i++) {
-      final String address = "localhost:" + (8963 + i) + "_solr";
-      liveNodes.add(address);
-      
-      zkStateReaderMock.getBaseUrlForNodeName(address);
-      expectLastCall().andAnswer(new IAnswer<Object>() {
-        @Override
-        public Object answer() throws Throwable {
-          // This works as long as this test does not use a 
-          // webapp context with an underscore in it
-          return address.replaceAll("_", "/");
-        }
-      }).anyTimes();
-      
-    }
-    zkStateReaderMock.getClusterProps();
-    expectLastCall().andAnswer(new IAnswer<Map>() {
-      @Override
-      public Map answer() throws Throwable {
-        return new HashMap();
-      }
-    });
-
-    solrZkClientMock.getZkClientTimeout();
-    expectLastCall().andAnswer(new IAnswer<Object>() {
-      @Override
-      public Object answer() throws Throwable {
-        return 30000;
-      }
-    }).anyTimes();
-    
-    clusterStateMock.hasCollection(anyObject(String.class));
-    expectLastCall().andAnswer(new IAnswer<Boolean>() {
-      @Override
-      public Boolean answer() throws Throwable {
-        String key = (String) getCurrentArguments()[0];
-        return collectionsSet.contains(key);
-      }
-    } ).anyTimes();
-
-
-    clusterStateMock.getLiveNodes();
-    expectLastCall().andAnswer(new IAnswer<Object>() {
-      @Override
-      public Object answer() throws Throwable {
-        return liveNodes;
-      }
-    }).anyTimes();
-    solrZkClientMock.create(anyObject(String.class), anyObject(byte[].class), anyObject(CreateMode.class), anyBoolean());
-    expectLastCall().andAnswer(new IAnswer<String>() {
-      @Override
-      public String answer() throws Throwable {
-        String key = (String) getCurrentArguments()[0];
-        zkMap.put(key, null);
-        handleCreateCollMessage((byte[]) getCurrentArguments()[1]);
-        return key;
-      }
-    }).anyTimes();
-
-    solrZkClientMock.makePath(anyObject(String.class), anyObject(byte[].class), anyBoolean());
-    expectLastCall().andAnswer(new IAnswer<String>() {
-      @Override
-      public String answer() throws Throwable {
-        String key = (String) getCurrentArguments()[0];
-        return key;
-      }
-    }).anyTimes();
-
-    solrZkClientMock.makePath(anyObject(String.class), anyObject(byte[].class), anyObject(CreateMode.class), anyBoolean());
-    expectLastCall().andAnswer(new IAnswer<String>() {
-      @Override
-      public String answer() throws Throwable {
-        String key = (String) getCurrentArguments()[0];
-        return key;
-      }
-    }).anyTimes();
-
-    solrZkClientMock.exists(anyObject(String.class),anyBoolean());
-    expectLastCall().andAnswer(new IAnswer<Boolean>() {
-      @Override
-      public Boolean answer() throws Throwable {
-        String key = (String) getCurrentArguments()[0];
-        return zkMap.containsKey(key);
-      }
-    }).anyTimes();
-    
-    zkMap.put("/configs/myconfig", null);
-    
-    return liveNodes;
-  }
-
-  private void handleCreateCollMessage(byte[] bytes) {
-    try {
-      ZkNodeProps props = ZkNodeProps.load(bytes);
-      if(CollectionParams.CollectionAction.CREATE.isEqual(props.getStr("operation"))){
-        String collName = props.getStr("name") ;
-        if(collName != null) collectionsSet.add(collName);
-      }
-    } catch (Exception e) { }
-  }
-
-  protected void startComponentUnderTest() {
-    thread = new Thread(underTest);
-    thread.start();
-  }
-  
-  protected void stopComponentUnderTest() throws Exception {
-    underTest.close();
-    thread.interrupt();
-    thread.join();
-  }
-  
-  private class SubmitCapture {
-    public Capture<ShardRequest> shardRequestCapture = new Capture<>();
-    public Capture<String> nodeUrlsWithoutProtocolPartCapture = new Capture<>();
-    public Capture<ModifiableSolrParams> params = new Capture<>();
-  }
-  
-  protected List<SubmitCapture> mockShardHandlerForCreateJob(
-      Integer numberOfSlices, Integer numberOfReplica) {
-    List<SubmitCapture> submitCaptures = new ArrayList<>();
-    for (int i = 0; i < (numberOfSlices * numberOfReplica); i++) {
-      SubmitCapture submitCapture = new SubmitCapture();
-      shardHandlerMock.submit(capture(submitCapture.shardRequestCapture),
-          capture(submitCapture.nodeUrlsWithoutProtocolPartCapture),
-          capture(submitCapture.params));
-      expectLastCall();
-      submitCaptures.add(submitCapture);
-      ShardResponse shardResponseWithoutException = new ShardResponse();
-      shardResponseWithoutException.setSolrResponse(new QueryResponse());
-      expect(shardHandlerMock.takeCompletedOrError()).andReturn(
-          shardResponseWithoutException);
-    }
-    expect(shardHandlerMock.takeCompletedOrError()).andReturn(null);
-    return submitCaptures;
-  }
-  
-  protected void issueCreateJob(Integer numberOfSlices,
-      Integer replicationFactor, Integer maxShardsPerNode, List<String> createNodeList, boolean sendCreateNodeList, boolean createNodeSetShuffle) {
-    Map<String,Object> propMap = Utils.makeMap(
-        Overseer.QUEUE_OPERATION, CollectionParams.CollectionAction.CREATE.toLower(),
-        ZkStateReader.REPLICATION_FACTOR, replicationFactor.toString(),
-        "name", COLLECTION_NAME,
-        "collection.configName", CONFIG_NAME,
-        OverseerCollectionMessageHandler.NUM_SLICES, numberOfSlices.toString(),
-        ZkStateReader.MAX_SHARDS_PER_NODE, maxShardsPerNode.toString()
-    );
-    if (sendCreateNodeList) {
-      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET,
-          (createNodeList != null)?StrUtils.join(createNodeList, ','):null);
-      if (OverseerCollectionMessageHandler.CREATE_NODE_SET_SHUFFLE_DEFAULT != createNodeSetShuffle || random().nextBoolean()) {
-        propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET_SHUFFLE, createNodeSetShuffle);
-      }
-    }
-
-    ZkNodeProps props = new ZkNodeProps(propMap);
-    QueueEvent qe = new QueueEvent("id", Utils.toJSON(props), null){
-      @Override
-      public void setBytes(byte[] bytes) {
-        lastProcessMessageResult = SolrResponse.deserialize( bytes);
-      }
-    };
-    queue.add(qe);
-  }
-  
-  protected void verifySubmitCaptures(List<SubmitCapture> submitCaptures,
-      Integer numberOfSlices, Integer numberOfReplica, Collection<String> createNodes, boolean dontShuffleCreateNodeSet) {
-    List<String> coreNames = new ArrayList<>();
-    Map<String,Map<String,Integer>> sliceToNodeUrlsWithoutProtocolPartToNumberOfShardsRunningMapMap = new HashMap<>();
-    List<String> nodeUrlWithoutProtocolPartForLiveNodes = new ArrayList<>(
-        createNodes.size());
-    for (String nodeName : createNodes) {
-      String nodeUrlWithoutProtocolPart = nodeName.replaceAll("_", "/");
-      if (nodeUrlWithoutProtocolPart.startsWith("http://")) nodeUrlWithoutProtocolPart = nodeUrlWithoutProtocolPart
-          .substring(7);
-      nodeUrlWithoutProtocolPartForLiveNodes.add(nodeUrlWithoutProtocolPart);
-    }
-    final Map<String,String> coreName_TO_nodeUrlWithoutProtocolPartForLiveNodes_map = new HashMap<>();
-    
-    for (SubmitCapture submitCapture : submitCaptures) {
-      ShardRequest shardRequest = submitCapture.shardRequestCapture.getValue();
-      assertEquals(CoreAdminAction.CREATE.toString(),
-          shardRequest.params.get(CoreAdminParams.ACTION));
-      // assertEquals(shardRequest.params, submitCapture.params);
-      String coreName = shardRequest.params.get(CoreAdminParams.NAME);
-      assertFalse("Core with name " + coreName + " created twice",
-          coreNames.contains(coreName));
-      coreNames.add(coreName);
-      assertEquals(CONFIG_NAME,
-          shardRequest.params.get("collection.configName"));
-      assertEquals(COLLECTION_NAME,
-          shardRequest.params.get(CoreAdminParams.COLLECTION));
-      assertEquals(numberOfSlices.toString(),
-          shardRequest.params.get(ZkStateReader.NUM_SHARDS_PROP));
-      assertEquals(ADMIN_PATH, shardRequest.params.get("qt"));
-      assertEquals(1, shardRequest.purpose);
-      assertEquals(1, shardRequest.shards.length);
-      assertEquals(submitCapture.nodeUrlsWithoutProtocolPartCapture.getValue(),
-          shardRequest.shards[0]);
-      assertTrue("Shard " + coreName + " created on wrong node "
-          + shardRequest.shards[0],
-          nodeUrlWithoutProtocolPartForLiveNodes
-              .contains(shardRequest.shards[0]));
-      coreName_TO_nodeUrlWithoutProtocolPartForLiveNodes_map.put(coreName, shardRequest.shards[0]);
-      assertEquals(shardRequest.shards, shardRequest.actualShards);
-      
-      String sliceName = shardRequest.params.get(CoreAdminParams.SHARD);
-      if (!sliceToNodeUrlsWithoutProtocolPartToNumberOfShardsRunningMapMap
-          .containsKey(sliceName)) {
-        sliceToNodeUrlsWithoutProtocolPartToNumberOfShardsRunningMapMap.put(
-            sliceName, new HashMap<String,Integer>());
-      }
-      Map<String,Integer> nodeUrlsWithoutProtocolPartToNumberOfShardsRunningMap = sliceToNodeUrlsWithoutProtocolPartToNumberOfShardsRunningMapMap
-          .get(sliceName);
-      Integer existingCount;
-      nodeUrlsWithoutProtocolPartToNumberOfShardsRunningMap
-          .put(
-              shardRequest.shards[0],
-              ((existingCount = nodeUrlsWithoutProtocolPartToNumberOfShardsRunningMap
-                  .get(shardRequest.shards[0])) == null) ? 1
-                  : (existingCount + 1));
-    }
-    
-    assertEquals(numberOfSlices * numberOfReplica, coreNames.size());
-    for (int i = 1; i <= numberOfSlices; i++) {
-      for (int j = 1; j <= numberOfReplica; j++) {
-        String coreName = COLLECTION_NAME + "_shard" + i + "_replica" + j;
-        assertTrue("Shard " + coreName + " was not created",
-            coreNames.contains(coreName));
-        
-        if (dontShuffleCreateNodeSet) {
-          final String expectedNodeName = nodeUrlWithoutProtocolPartForLiveNodes.get((numberOfReplica * (i - 1) + (j - 1)) % nodeUrlWithoutProtocolPartForLiveNodes.size());
-          assertFalse("expectedNodeName is null for coreName="+coreName, null == expectedNodeName);
-          
-          final String actualNodeName = coreName_TO_nodeUrlWithoutProtocolPartForLiveNodes_map.get(coreName);
-          assertFalse("actualNodeName is null for coreName="+coreName, null == actualNodeName);
-
-          assertTrue("node name mismatch for coreName="+coreName+" ( actual="+actualNodeName+" versus expected="+expectedNodeName+" )", actualNodeName.equals(expectedNodeName));
-        }
-      }
-    }
-    
-    assertEquals(numberOfSlices.intValue(),
-        sliceToNodeUrlsWithoutProtocolPartToNumberOfShardsRunningMapMap.size());
-    for (int i = 1; i <= numberOfSlices; i++) {
-      sliceToNodeUrlsWithoutProtocolPartToNumberOfShardsRunningMapMap.keySet()
-          .contains("shard" + i);
-    }
-    int minShardsPerSlicePerNode = numberOfReplica / createNodes.size();
-    int numberOfNodesSupposedToRunMaxShards = numberOfReplica
-        % createNodes.size();
-    int numberOfNodesSupposedToRunMinShards = createNodes.size()
-        - numberOfNodesSupposedToRunMaxShards;
-    int maxShardsPerSlicePerNode = (minShardsPerSlicePerNode + 1);
-    if (numberOfNodesSupposedToRunMaxShards == 0) {
-      numberOfNodesSupposedToRunMaxShards = numberOfNodesSupposedToRunMinShards;
-      maxShardsPerSlicePerNode = minShardsPerSlicePerNode;
-    }
-    boolean diffBetweenMinAndMaxShardsPerSlicePerNode = (maxShardsPerSlicePerNode != minShardsPerSlicePerNode);
-    
-    for (Entry<String,Map<String,Integer>> sliceToNodeUrlsWithoutProtocolPartToNumberOfShardsRunningMapMapEntry : sliceToNodeUrlsWithoutProtocolPartToNumberOfShardsRunningMapMap
-        .entrySet()) {
-      int numberOfShardsRunning = 0;
-      int numberOfNodesRunningMinShards = 0;
-      int numberOfNodesRunningMaxShards = 0;
-      int numberOfNodesRunningAtLeastOneShard = 0;
-      for (String nodeUrlsWithoutProtocolPart : sliceToNodeUrlsWithoutProtocolPartToNumberOfShardsRunningMapMapEntry
-          .getValue().keySet()) {
-        int numberOfShardsRunningOnThisNode = sliceToNodeUrlsWithoutProtocolPartToNumberOfShardsRunningMapMapEntry
-            .getValue().get(nodeUrlsWithoutProtocolPart);
-        numberOfShardsRunning += numberOfShardsRunningOnThisNode;
-        numberOfNodesRunningAtLeastOneShard++;
-        assertTrue(
-            "Node "
-                + nodeUrlsWithoutProtocolPart
-                + " is running wrong number of shards. Supposed to run "
-                + minShardsPerSlicePerNode
-                + (diffBetweenMinAndMaxShardsPerSlicePerNode ? (" or " + maxShardsPerSlicePerNode)
-                    : ""),
-            (numberOfShardsRunningOnThisNode == minShardsPerSlicePerNode)
-                || (numberOfShardsRunningOnThisNode == maxShardsPerSlicePerNode));
-        if (numberOfShardsRunningOnThisNode == minShardsPerSlicePerNode) numberOfNodesRunningMinShards++;
-        if (numberOfShardsRunningOnThisNode == maxShardsPerSlicePerNode) numberOfNodesRunningMaxShards++;
-      }
-      if (minShardsPerSlicePerNode == 0) numberOfNodesRunningMinShards = (createNodes
-          .size() - numberOfNodesRunningAtLeastOneShard);
-      assertEquals(
-          "Too many shards are running under slice "
-              + sliceToNodeUrlsWithoutProtocolPartToNumberOfShardsRunningMapMapEntry
-                  .getKey(),
-          numberOfReplica.intValue(), numberOfShardsRunning);
-      assertEquals(numberOfNodesSupposedToRunMinShards,
-          numberOfNodesRunningMinShards);
-      assertEquals(numberOfNodesSupposedToRunMaxShards,
-          numberOfNodesRunningMaxShards);
-    }
-  }
-  
-  protected void waitForEmptyQueue(long maxWait) throws Exception {
-    final TimeOut timeout = new TimeOut(maxWait, TimeUnit.MILLISECONDS);
-    while (queue.peek() != null) {
-      if (timeout.hasTimedOut())
-        fail("Queue not empty within " + maxWait + " ms");
-      Thread.sleep(100);
-    }
-  }
-  
-  protected enum CreateNodeListOptions {
-    SEND,
-    DONT_SEND,
-    SEND_NULL
-  }
-  protected void testTemplate(Integer numberOfNodes, Integer numberOfNodesToCreateOn, CreateNodeListOptions createNodeListOption, Integer replicationFactor,
-      Integer numberOfSlices, Integer maxShardsPerNode,
-      boolean collectionExceptedToBeCreated) throws Exception {
-    assertTrue("Wrong usage of testTemplate. numberOfNodesToCreateOn " + numberOfNodesToCreateOn + " is not allowed to be higher than numberOfNodes " + numberOfNodes, numberOfNodes.intValue() >= numberOfNodesToCreateOn.intValue());
-    assertTrue("Wrong usage of testTemplage. createNodeListOption has to be " + CreateNodeListOptions.SEND + " when numberOfNodes and numberOfNodesToCreateOn are unequal", ((createNodeListOption == CreateNodeListOptions.SEND) || (numberOfNodes.intValue() == numberOfNodesToCreateOn.intValue())));
-    
-    Set<String> liveNodes = commonMocks(numberOfNodes);
-    List<String> createNodeList = new ArrayList<>();
-    int i = 0;
-    for (String node : liveNodes) {
-      if (i++ < numberOfNodesToCreateOn) {
-        createNodeList.add(node);
-      }
-    }
-    
-    if (random().nextBoolean()) Collections.shuffle(createNodeList, OverseerCollectionMessageHandler.RANDOM);
-    
-    List<SubmitCapture> submitCaptures = null;
-    if (collectionExceptedToBeCreated) {
-      submitCaptures = mockShardHandlerForCreateJob(numberOfSlices,
-          replicationFactor);
-    }
-    
-    replay(workQueueMock);
-    replay(solrZkClientMock);
-    replay(zkStateReaderMock);
-    replay(clusterStateMock);
-    replay(shardHandlerFactoryMock);
-    replay(shardHandlerMock);
-
-
-    log.info("clusterstate " + clusterStateMock.hashCode());
-
-    startComponentUnderTest();
-    
-    final List<String> createNodeListToSend = ((createNodeListOption != CreateNodeListOptions.SEND_NULL) ? createNodeList : null);
-    final boolean sendCreateNodeList = (createNodeListOption != CreateNodeListOptions.DONT_SEND);
-    final boolean dontShuffleCreateNodeSet = (createNodeListToSend != null) && sendCreateNodeList && random().nextBoolean();
-    issueCreateJob(numberOfSlices, replicationFactor, maxShardsPerNode, createNodeListToSend, sendCreateNodeList, !dontShuffleCreateNodeSet);
-    waitForEmptyQueue(10000);
-    
-    if (collectionExceptedToBeCreated) {
-      assertNotNull(lastProcessMessageResult.getResponse().toString(), lastProcessMessageResult);
-    }
-    verify(shardHandlerFactoryMock);
-    verify(shardHandlerMock);
-
-    if (collectionExceptedToBeCreated) {
-      verifySubmitCaptures(submitCaptures, numberOfSlices, replicationFactor,
-          createNodeList, dontShuffleCreateNodeSet);
-    }
-  }
-    @Test
-  public void testNoReplicationEqualNumberOfSlicesPerNode() throws Exception {
-    Integer numberOfNodes = 4;
-    Integer numberOfNodesToCreateOn = 4;
-    CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.DONT_SEND;
-    Integer replicationFactor = 1;
-    Integer numberOfSlices = 8;
-    Integer maxShardsPerNode = 2;
-    testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
-        maxShardsPerNode, true);
-  }
-  
-  @Test
-  public void testReplicationEqualNumberOfSlicesPerNode() throws Exception {
-    Integer numberOfNodes = 4;
-    Integer numberOfNodesToCreateOn = 4;
-    CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.DONT_SEND;
-    Integer replicationFactor = 2;
-    Integer numberOfSlices = 4;
-    Integer maxShardsPerNode = 2;
-    testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
-        maxShardsPerNode, true);
-  }
-  
-  @Test
-  public void testNoReplicationEqualNumberOfSlicesPerNodeSendCreateNodesEqualToLiveNodes() throws Exception {
-    Integer numberOfNodes = 4;
-    Integer numberOfNodesToCreateOn = 4;
-    CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.SEND;
-    Integer replicationFactor = 1;
-    Integer numberOfSlices = 8;
-    Integer maxShardsPerNode = 2;
-    testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
-        maxShardsPerNode, true);
-  }
-  
-  @Test
-  public void testReplicationEqualNumberOfSlicesPerNodeSendCreateNodesEqualToLiveNodes() throws Exception {
-    Integer numberOfNodes = 4;
-    Integer numberOfNodesToCreateOn = 4;
-    CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.SEND;
-    Integer replicationFactor = 2;
-    Integer numberOfSlices = 4;
-    Integer maxShardsPerNode = 2;
-    testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
-        maxShardsPerNode, true);
-  }
-  
-  @Test
-  public void testNoReplicationEqualNumberOfSlicesPerNodeSendNullCreateNodes() throws Exception {
-    Integer numberOfNodes = 4;
-    Integer numberOfNodesToCreateOn = 4;
-    CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.SEND_NULL;
-    Integer replicationFactor = 1;
-    Integer numberOfSlices = 8;
-    Integer maxShardsPerNode = 2;
-    testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
-        maxShardsPerNode, true);
-  }
-  
-  @Test
-  public void testReplicationEqualNumberOfSlicesPerNodeSendNullCreateNodes() throws Exception {
-    Integer numberOfNodes = 4;
-    Integer numberOfNodesToCreateOn = 4;
-    CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.SEND_NULL;
-    Integer replicationFactor = 2;
-    Integer numberOfSlices = 4;
-    Integer maxShardsPerNode = 2;
-    testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
-        maxShardsPerNode, true);
-  }  
-  
-  @Test
-  public void testNoReplicationUnequalNumberOfSlicesPerNode() throws Exception {
-    Integer numberOfNodes = 4;
-    Integer numberOfNodesToCreateOn = 4;
-    CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.DONT_SEND;
-    Integer replicationFactor = 1;
-    Integer numberOfSlices = 6;
-    Integer maxShardsPerNode = 2;
-    testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
-        maxShardsPerNode, true);
-  }
-  
-  @Test
-  public void testReplicationUnequalNumberOfSlicesPerNode() throws Exception {
-    Integer numberOfNodes = 4;
-    Integer numberOfNodesToCreateOn = 4;
-    CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.DONT_SEND;
-    Integer replicationFactor = 2;
-    Integer numberOfSlices = 3;
-    Integer maxShardsPerNode = 2;
-    testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
-        maxShardsPerNode, true);
-  }
-  
-  @Test
-  public void testNoReplicationCollectionNotCreatedDueToMaxShardsPerNodeLimit()
-      throws Exception {
-    Integer numberOfNodes = 4;
-    Integer numberOfNodesToCreateOn = 4;
-    CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.DONT_SEND;
-    Integer replicationFactor = 1;
-    Integer numberOfSlices = 6;
-    Integer maxShardsPerNode = 1;
-    testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
-        maxShardsPerNode, false);
-  }
-  
-  @Test
-  public void testReplicationCollectionNotCreatedDueToMaxShardsPerNodeLimit()
-      throws Exception {
-    Integer numberOfNodes = 4;
-    Integer numberOfNodesToCreateOn = 4;
-    CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.DONT_SEND;
-    Integer replicationFactor = 2;
-    Integer numberOfSlices = 3;
-    Integer maxShardsPerNode = 1;
-    testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
-        maxShardsPerNode, false);
-  }
-
-  @Test
-  public void testNoReplicationLimitedNodesToCreateOn()
-      throws Exception {
-    Integer numberOfNodes = 4;
-    Integer numberOfNodesToCreateOn = 2;
-    CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.SEND;
-    Integer replicationFactor = 1;
-    Integer numberOfSlices = 6;
-    Integer maxShardsPerNode = 3;
-    testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
-        maxShardsPerNode, true);
-  }
-  
-  @Test
-  public void testReplicationLimitedNodesToCreateOn()
-      throws Exception {
-    Integer numberOfNodes = 4;
-    Integer numberOfNodesToCreateOn = 2;
-    CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.SEND;
-    Integer replicationFactor = 2;
-    Integer numberOfSlices = 3;
-    Integer maxShardsPerNode = 3;
-    testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
-        maxShardsPerNode, true);
-  }
-
-  @Test
-  public void testNoReplicationCollectionNotCreatedDueToMaxShardsPerNodeAndNodesToCreateOnLimits()
-      throws Exception {
-    Integer numberOfNodes = 4;
-    Integer numberOfNodesToCreateOn = 3;
-    CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.SEND;
-    Integer replicationFactor = 1;
-    Integer numberOfSlices = 8;
-    Integer maxShardsPerNode = 2;
-    testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
-        maxShardsPerNode, false);
-  }
-  
-  @Test
-  public void testReplicationCollectionNotCreatedDueToMaxShardsPerNodeAndNodesToCreateOnLimits()
-      throws Exception {
-    Integer numberOfNodes = 4;
-    Integer numberOfNodesToCreateOn = 3;
-    CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.SEND;
-    Integer replicationFactor = 2;
-    Integer numberOfSlices = 4;
-    Integer maxShardsPerNode = 2;
-    testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
-        maxShardsPerNode, false);
-  }
-
-}
diff --git a/solr/core/src/test/org/apache/solr/cloud/OverseerCollectionQueueTest.java b/solr/core/src/test/org/apache/solr/cloud/OverseerCollectionQueueTest.java
deleted file mode 100644
index f25d75e..0000000
--- a/solr/core/src/test/org/apache/solr/cloud/OverseerCollectionQueueTest.java
+++ /dev/null
@@ -1,28 +0,0 @@
-package org.apache.solr.cloud;
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements. See the NOTICE file distributed with this
- * work for additional information regarding copyright ownership. The ASF
- * licenses this file to You under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- * http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
- * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
- * License for the specific language governing permissions and limitations under
- * the License.
- */
-
-public class OverseerCollectionQueueTest extends DistributedQueueTest {
-
-
-  // TODO: OverseerCollectionQueue specific tests.
-
-  @Override
-  protected OverseerCollectionQueue makeDistributedQueue(String dqZNode) throws Exception {
-    return new OverseerCollectionQueue(zkClient, setupNewDistributedQueueZNode(dqZNode));
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/cloud/OverseerRolesTest.java b/solr/core/src/test/org/apache/solr/cloud/OverseerRolesTest.java
index 34d62fb..43531bd 100644
--- a/solr/core/src/test/org/apache/solr/cloud/OverseerRolesTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/OverseerRolesTest.java
@@ -43,8 +43,8 @@ import java.util.Locale;
 import java.util.Map;
 import java.util.concurrent.TimeUnit;
 
-import static org.apache.solr.cloud.OverseerCollectionProcessor.getLeaderNode;
-import static org.apache.solr.cloud.OverseerCollectionProcessor.getSortedOverseerNodeNames;
+import static org.apache.solr.cloud.OverseerCollectionConfigSetProcessor.getLeaderNode;
+import static org.apache.solr.cloud.OverseerCollectionConfigSetProcessor.getSortedOverseerNodeNames;
 import static org.apache.solr.cloud.OverseerCollectionMessageHandler.NUM_SLICES;
 import static org.apache.solr.common.util.Utils.makeMap;
 import static org.apache.solr.common.cloud.ZkStateReader.MAX_SHARDS_PER_NODE;
@@ -88,7 +88,7 @@ public class OverseerRolesTest  extends AbstractFullDistribZkTestBase{
     final TimeOut timeout = new TimeOut(10, TimeUnit.SECONDS);
     String newLeader=null;
     for(;! timeout.hasTimedOut();){
-      newLeader = OverseerCollectionProcessor.getLeaderNode(zk);
+      newLeader = OverseerCollectionConfigSetProcessor.getLeaderNode(zk);
       if(newLeader!=null && !newLeader.equals(leader)) break;
       Thread.sleep(100);
     }
@@ -96,7 +96,7 @@ public class OverseerRolesTest  extends AbstractFullDistribZkTestBase{
 
 
 
-    assertTrue("The old leader should have rejoined election ", OverseerCollectionProcessor.getSortedOverseerNodeNames(zk).contains(leader));
+    assertTrue("The old leader should have rejoined election ", OverseerCollectionConfigSetProcessor.getSortedOverseerNodeNames(zk).contains(leader));
   }
 
 
@@ -108,10 +108,10 @@ public class OverseerRolesTest  extends AbstractFullDistribZkTestBase{
     createCollection(collectionName, client);
 
     waitForRecoveriesToFinish(collectionName, false);
-    List<String> l = OverseerCollectionProcessor.getSortedOverseerNodeNames(client.getZkStateReader().getZkClient()) ;
+    List<String> l = OverseerCollectionConfigSetProcessor.getSortedOverseerNodeNames(client.getZkStateReader().getZkClient()) ;
 
     log.info("All nodes {}", l);
-    String currentLeader = OverseerCollectionProcessor.getLeaderNode(client.getZkStateReader().getZkClient());
+    String currentLeader = OverseerCollectionConfigSetProcessor.getLeaderNode(client.getZkStateReader().getZkClient());
     log.info("Current leader {} ", currentLeader);
     l.remove(currentLeader);
 
@@ -124,7 +124,7 @@ public class OverseerRolesTest  extends AbstractFullDistribZkTestBase{
 
     boolean leaderchanged = false;
     for(;!timeout.hasTimedOut();){
-      if(overseerDesignate.equals(OverseerCollectionProcessor.getLeaderNode(client.getZkStateReader().getZkClient()))){
+      if(overseerDesignate.equals(OverseerCollectionConfigSetProcessor.getLeaderNode(client.getZkStateReader().getZkClient()))){
         log.info("overseer designate is the new overseer");
         leaderchanged =true;
         break;
@@ -134,7 +134,7 @@ public class OverseerRolesTest  extends AbstractFullDistribZkTestBase{
     assertTrue("could not set the new overseer . expected "+
         overseerDesignate + " current order : " +
         getSortedOverseerNodeNames(client.getZkStateReader().getZkClient()) +
-        " ldr :"+ OverseerCollectionProcessor.getLeaderNode(client.getZkStateReader().getZkClient()) ,leaderchanged);
+        " ldr :"+ OverseerCollectionConfigSetProcessor.getLeaderNode(client.getZkStateReader().getZkClient()) ,leaderchanged);
 
 
 
@@ -176,7 +176,7 @@ public class OverseerRolesTest  extends AbstractFullDistribZkTestBase{
 
     log.info("leader node {}", leaderJetty.getBaseUrl());
     log.info ("current election Queue",
-        OverseerCollectionProcessor.getSortedElectionNodes(client.getZkStateReader().getZkClient(),
+        OverseerCollectionConfigSetProcessor.getSortedElectionNodes(client.getZkStateReader().getZkClient(),
             OverseerElectionContext.PATH + LeaderElector.ELECTION_NODE));
     ChaosMonkey.stop(leaderJetty);
     timeout = new TimeOut(10, TimeUnit.SECONDS);
diff --git a/solr/core/src/test/org/apache/solr/cloud/OverseerTaskQueueTest.java b/solr/core/src/test/org/apache/solr/cloud/OverseerTaskQueueTest.java
new file mode 100644
index 0000000..72a046f
--- /dev/null
+++ b/solr/core/src/test/org/apache/solr/cloud/OverseerTaskQueueTest.java
@@ -0,0 +1,28 @@
+package org.apache.solr.cloud;
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements. See the NOTICE file distributed with this
+ * work for additional information regarding copyright ownership. The ASF
+ * licenses this file to You under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
+ * License for the specific language governing permissions and limitations under
+ * the License.
+ */
+
+public class OverseerTaskQueueTest extends DistributedQueueTest {
+
+
+  // TODO: OverseerTaskQueue specific tests.
+
+  @Override
+  protected OverseerTaskQueue makeDistributedQueue(String dqZNode) throws Exception {
+    return new OverseerTaskQueue(zkClient, setupNewDistributedQueueZNode(dqZNode));
+  }
+}
diff --git a/solr/core/src/test/org/apache/solr/cloud/RollingRestartTest.java b/solr/core/src/test/org/apache/solr/cloud/RollingRestartTest.java
index f9897a6..dbdf0f3 100644
--- a/solr/core/src/test/org/apache/solr/cloud/RollingRestartTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/RollingRestartTest.java
@@ -57,7 +57,7 @@ public class RollingRestartTest extends AbstractFullDistribZkTestBase {
 
 
   public void restartWithRolesTest() throws Exception {
-    String leader = OverseerCollectionProcessor.getLeaderNode(cloudClient.getZkStateReader().getZkClient());
+    String leader = OverseerCollectionConfigSetProcessor.getLeaderNode(cloudClient.getZkStateReader().getZkClient());
     assertNotNull(leader);
     log.info("Current overseer leader = {}", leader);
 
@@ -93,10 +93,10 @@ public class RollingRestartTest extends AbstractFullDistribZkTestBase {
           sawLiveDesignate = true;
           boolean success = waitUntilOverseerDesignateIsLeader(cloudClient.getZkStateReader().getZkClient(), designates, MAX_WAIT_TIME);
           if (!success) {
-            leader = OverseerCollectionProcessor.getLeaderNode(cloudClient.getZkStateReader().getZkClient());
+            leader = OverseerCollectionConfigSetProcessor.getLeaderNode(cloudClient.getZkStateReader().getZkClient());
             if (leader == null)
               log.error("NOOVERSEER election queue is :" +
-                  OverseerCollectionProcessor.getSortedElectionNodes(cloudClient.getZkStateReader().getZkClient(),
+                  OverseerCollectionConfigSetProcessor.getSortedElectionNodes(cloudClient.getZkStateReader().getZkClient(),
                       OverseerElectionContext.PATH + LeaderElector.ELECTION_NODE));
             fail("No overseer designate as leader found after restart #" + (i + 1) + ": " + leader);
           }
@@ -104,10 +104,10 @@ public class RollingRestartTest extends AbstractFullDistribZkTestBase {
         assertTrue("Unable to restart (#" + i + "): " + cloudJetty, ChaosMonkey.start(cloudJetty.jetty));
         boolean success = waitUntilOverseerDesignateIsLeader(cloudClient.getZkStateReader().getZkClient(), designates, MAX_WAIT_TIME);
         if (!success) {
-          leader = OverseerCollectionProcessor.getLeaderNode(cloudClient.getZkStateReader().getZkClient());
+          leader = OverseerCollectionConfigSetProcessor.getLeaderNode(cloudClient.getZkStateReader().getZkClient());
           if (leader == null)
             log.error("NOOVERSEER election queue is :" +
-                OverseerCollectionProcessor.getSortedElectionNodes(cloudClient.getZkStateReader().getZkClient(),
+                OverseerCollectionConfigSetProcessor.getSortedElectionNodes(cloudClient.getZkStateReader().getZkClient(),
                     OverseerElectionContext.PATH + LeaderElector.ELECTION_NODE));
           fail("No overseer leader found after restart #" + (i + 1) + ": " + leader);
         }
@@ -120,7 +120,7 @@ public class RollingRestartTest extends AbstractFullDistribZkTestBase {
     
     assertTrue("Test may not be working if we never saw a live designate", sawLiveDesignate);
 
-    leader = OverseerCollectionProcessor.getLeaderNode(cloudClient.getZkStateReader().getZkClient());
+    leader = OverseerCollectionConfigSetProcessor.getLeaderNode(cloudClient.getZkStateReader().getZkClient());
     assertNotNull(leader);
     log.info("Current overseer leader (after restart) = {}", leader);
 
@@ -135,7 +135,7 @@ public class RollingRestartTest extends AbstractFullDistribZkTestBase {
     int stableCheckTimeout = 2000;
     String oldleader = null;
     while (System.nanoTime() < timeout && System.nanoTime() < maxTimeout) {
-      String newLeader = OverseerCollectionProcessor.getLeaderNode(testZkClient);
+      String newLeader = OverseerCollectionConfigSetProcessor.getLeaderNode(testZkClient);
       if (newLeader != null && !newLeader.equals(oldleader)) {
         // the leaders have changed, let's move the timeout further
         timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);
diff --git a/solr/core/src/test/org/apache/solr/cloud/SimpleCollectionCreateDeleteTest.java b/solr/core/src/test/org/apache/solr/cloud/SimpleCollectionCreateDeleteTest.java
index bbe893d..1481323 100644
--- a/solr/core/src/test/org/apache/solr/cloud/SimpleCollectionCreateDeleteTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/SimpleCollectionCreateDeleteTest.java
@@ -33,7 +33,7 @@ public class SimpleCollectionCreateDeleteTest extends AbstractFullDistribZkTestB
   @Test
   @ShardsFixed(num = 1)
   public void test() throws Exception {
-    String overseerNode = OverseerCollectionProcessor.getLeaderNode(cloudClient.getZkStateReader().getZkClient());
+    String overseerNode = OverseerCollectionConfigSetProcessor.getLeaderNode(cloudClient.getZkStateReader().getZkClient());
     String notOverseerNode = null;
     for (CloudJettyRunner cloudJetty : cloudJettys) {
       if (!overseerNode.equals(cloudJetty.nodeName)) {
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestConfigSetsAPI.java b/solr/core/src/test/org/apache/solr/cloud/TestConfigSetsAPI.java
new file mode 100644
index 0000000..245d6ef
--- /dev/null
+++ b/solr/core/src/test/org/apache/solr/cloud/TestConfigSetsAPI.java
@@ -0,0 +1,331 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.cloud;
+
+import com.google.common.collect.ImmutableMap;
+import java.io.ByteArrayInputStream;
+import java.io.File;
+import java.io.InputStreamReader;
+import java.nio.charset.StandardCharsets;
+import java.util.Iterator;
+import java.util.Map;
+import java.util.Properties;
+
+import org.apache.commons.io.FileUtils;
+import org.apache.solr.SolrTestCaseJ4;
+import org.apache.solr.client.solrj.SolrClient;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
+import org.apache.solr.client.solrj.request.ConfigSetAdminRequest;
+import org.apache.solr.client.solrj.request.ConfigSetAdminRequest.Create;
+import org.apache.solr.client.solrj.request.ConfigSetAdminRequest.Delete;
+import org.apache.solr.client.solrj.response.ConfigSetAdminResponse;
+import org.apache.solr.common.cloud.SolrZkClient;
+import org.apache.solr.common.cloud.ZkConfigManager;
+import org.apache.solr.common.params.ConfigSetParams;
+import org.apache.solr.common.params.ConfigSetParams.ConfigSetAction;
+import org.apache.solr.common.params.ModifiableSolrParams;
+import org.apache.solr.common.params.SolrParams;
+import org.apache.solr.common.util.NamedList;
+import org.apache.solr.common.util.Utils;
+import org.apache.solr.core.ConfigSetProperties;
+import org.apache.zookeeper.KeeperException;
+
+import org.junit.After;
+import org.junit.Assert;
+import org.junit.Before;
+import org.junit.Test;
+import static org.apache.solr.cloud.OverseerConfigSetMessageHandler.BASE_CONFIGSET;
+import static org.apache.solr.common.params.CommonParams.NAME;
+import static org.apache.solr.core.ConfigSetProperties.DEFAULT_FILENAME;
+
+/**
+ * Simple ConfigSets API tests on user errors and simple success cases.
+ */
+public class TestConfigSetsAPI extends SolrTestCaseJ4 {
+
+  private MiniSolrCloudCluster solrCluster;
+
+  @Override
+  @Before
+  public void setUp() throws Exception {
+    super.setUp();
+    final File solrXml = getFile("solr").toPath().resolve("solr.xml").toFile();
+    solrCluster = new MiniSolrCloudCluster(1, createTempDir().toFile(), solrXml, buildJettyConfig("/solr"));
+  }
+
+  @Override
+  @After
+  public void tearDown() throws Exception {
+    solrCluster.shutdown();
+    super.tearDown();
+  }
+
+  @Test
+  public void testCreateErrors() throws Exception {
+    final SolrClient solrClient =
+        new HttpSolrClient(solrCluster.getJettySolrRunners().get(0).getBaseUrl().toString());
+    final File configDir = getFile("solr").toPath().resolve("configsets/configset-2/conf").toFile();
+    solrCluster.uploadConfigDir(configDir, "configSet");
+
+    // no action
+    CreateNoErrorChecking createNoAction = new CreateNoErrorChecking();
+    createNoAction.setAction(null);
+    verifyException(solrClient, createNoAction, "action");
+
+    // no ConfigSet name
+    CreateNoErrorChecking create = new CreateNoErrorChecking();
+    verifyException(solrClient, create, NAME);
+
+    // no base ConfigSet name
+    create.setConfigSetName("configSetName");
+    verifyException(solrClient, create, BASE_CONFIGSET);
+
+    // ConfigSet already exists
+    Create alreadyExists = new Create();
+    alreadyExists.setConfigSetName("configSet").setBaseConfigSetName("baseConfigSet");
+    verifyException(solrClient, alreadyExists, "ConfigSet already exists");
+
+    // Base ConfigSet does not exist
+    Create baseConfigNoExists = new Create();
+    baseConfigNoExists.setConfigSetName("newConfigSet").setBaseConfigSetName("baseConfigSet");
+    verifyException(solrClient, baseConfigNoExists, "Base ConfigSet does not exist");
+
+    solrClient.close();
+  }
+
+  @Test
+  public void testCreate() throws Exception {
+    // no old, no new
+    verifyCreate("baseConfigSet1", "configSet1", null, null);
+
+    // no old, new
+    verifyCreate("baseConfigSet2", "configSet2",
+        null, ImmutableMap.<String, String>of("immutable", "true", "key1", "value1"));
+
+    // old, no new
+    verifyCreate("baseConfigSet3", "configSet3",
+        ImmutableMap.<String, String>of("immutable", "false", "key2", "value2"), null);
+
+    // old, new
+    verifyCreate("baseConfigSet4", "configSet4",
+        ImmutableMap.<String, String>of("immutable", "true", "onlyOld", "onlyOldValue"),
+        ImmutableMap.<String, String>of("immutable", "false", "onlyNew", "onlyNewValue"));
+  }
+
+  private void setupBaseConfigSet(String baseConfigSetName, Map<String, String> oldProps) throws Exception {
+    final File configDir = getFile("solr").toPath().resolve("configsets/configset-2/conf").toFile();
+    final File tmpConfigDir = createTempDir().toFile();
+    tmpConfigDir.deleteOnExit();
+    FileUtils.copyDirectory(configDir, tmpConfigDir);
+    if (oldProps != null) {
+      FileUtils.write(new File(tmpConfigDir, ConfigSetProperties.DEFAULT_FILENAME),
+          getConfigSetProps(oldProps));
+    }
+    solrCluster.uploadConfigDir(tmpConfigDir, baseConfigSetName);
+  }
+
+  private void verifyCreate(String baseConfigSetName, String configSetName,
+      Map<String, String> oldProps, Map<String, String> newProps) throws Exception {
+    final SolrClient solrClient =
+        new HttpSolrClient(solrCluster.getJettySolrRunners().get(0).getBaseUrl().toString());
+    setupBaseConfigSet(baseConfigSetName, oldProps);
+
+    SolrZkClient zkClient = new SolrZkClient(solrCluster.getZkServer().getZkAddress(),
+        AbstractZkTestCase.TIMEOUT, 45000, null);
+    try {
+      ZkConfigManager configManager = new ZkConfigManager(zkClient);
+      assertFalse(configManager.configExists(configSetName));
+
+      Create create = new Create();
+      create.setBaseConfigSetName(baseConfigSetName).setConfigSetName(configSetName);
+      if (newProps != null) {
+        Properties p = new Properties();
+        p.putAll(newProps);
+        create.setNewConfigSetProperties(p);
+      }
+      ConfigSetAdminResponse response = create.process(solrClient);
+      assertNotNull(response.getResponse());
+      assertTrue(configManager.configExists(configSetName));
+
+      verifyProperties(configSetName, oldProps, newProps, zkClient);
+    } finally {
+      zkClient.close();
+    }
+    solrClient.close();
+  }
+
+  private NamedList getConfigSetPropertiesFromZk(
+      SolrZkClient zkClient, String path) throws Exception {
+    byte [] oldPropsData = null;
+    try {
+      oldPropsData = zkClient.getData(path, null, null, true);
+    } catch (KeeperException.NoNodeException e) {
+      // okay, properties just don't exist
+    }
+
+    if (oldPropsData != null) {
+      InputStreamReader reader = new InputStreamReader(new ByteArrayInputStream(oldPropsData), StandardCharsets.UTF_8);
+      try {
+        return ConfigSetProperties.readFromInputStream(reader);
+      } finally {
+        reader.close();
+      }
+    }
+    return null;
+  }
+
+  private void verifyProperties(String configSetName, Map<String, String> oldProps,
+       Map<String, String> newProps, SolrZkClient zkClient) throws Exception {
+    NamedList properties = getConfigSetPropertiesFromZk(zkClient,
+        ZkConfigManager.CONFIGS_ZKNODE + "/" + configSetName + "/" + DEFAULT_FILENAME);
+    // let's check without merging the maps, since that's what the MessageHandler does
+    // (since we'd probably repeat any bug in the MessageHandler here)
+    if (oldProps == null && newProps == null) {
+      assertNull(properties);
+      return;
+    }
+    assertNotNull(properties);
+
+    // check all oldProps are in props
+    if (oldProps != null) {
+      for (Map.Entry<String, String> entry : oldProps.entrySet()) {
+        assertNotNull(properties.get(entry.getKey()));
+      }
+    }
+    // check all newProps are in props
+    if (newProps != null) {
+      for (Map.Entry<String, String> entry : newProps.entrySet()) {
+        assertNotNull(properties.get(entry.getKey()));
+      }
+    }
+
+    // check the value in properties are correct
+    Iterator<Map.Entry<String, Object>> it = properties.iterator();
+    while (it.hasNext()) {
+      Map.Entry<String, Object> entry = it.next();
+      String newValue = newProps != null ? newProps.get(entry.getKey()) : null;
+      String oldValue = oldProps != null ? oldProps.get(entry.getKey()) : null;
+      if (newValue != null) {
+        assertTrue(newValue.equals(entry.getValue()));
+      } else if (oldValue != null) {
+        assertTrue(oldValue.equals(entry.getValue()));
+      } else {
+        // not in either
+        assert(false);
+      }
+    }
+  }
+
+  @Test
+  public void testDeleteErrors() throws Exception {
+    final SolrClient solrClient =
+        new HttpSolrClient(solrCluster.getJettySolrRunners().get(0).getBaseUrl().toString());
+    final File configDir = getFile("solr").toPath().resolve("configsets/configset-2/conf").toFile();
+    final File tmpConfigDir = createTempDir().toFile();
+    tmpConfigDir.deleteOnExit();
+    // Ensure ConfigSet is immutable
+    FileUtils.copyDirectory(configDir, tmpConfigDir);
+    FileUtils.write(new File(tmpConfigDir, "configsetprops.json"),
+        getConfigSetProps(ImmutableMap.<String, String>of("immutable", "true")));
+    solrCluster.uploadConfigDir(tmpConfigDir, "configSet");
+
+    // no ConfigSet name
+    DeleteNoErrorChecking delete = new DeleteNoErrorChecking();
+    verifyException(solrClient, delete, NAME);
+
+    // ConfigSet doesn't exist
+    delete.setConfigSetName("configSetBogus");
+    verifyException(solrClient, delete, "ConfigSet does not exist");
+
+    // ConfigSet is immutable
+    delete.setConfigSetName("configSet");
+    verifyException(solrClient, delete, "Requested delete of immutable ConfigSet");
+
+    solrClient.close();
+  }
+
+  private void verifyException(SolrClient solrClient, ConfigSetAdminRequest request,
+      String errorContains) throws Exception {
+    try {
+      solrClient.request(request);
+      Assert.fail("Expected exception");
+    } catch (Exception e) {
+      assertTrue("Expected exception message to contain: " + errorContains
+          + " got: " + e.getMessage(), e.getMessage().contains(errorContains));
+    }
+  }
+
+  @Test
+  public void testDelete() throws Exception {
+    final SolrClient solrClient =
+        new HttpSolrClient(solrCluster.getJettySolrRunners().get(0).getBaseUrl().toString());
+    final File configDir = getFile("solr").toPath().resolve("configsets/configset-2/conf").toFile();
+    final String configSet = "configSet";
+    solrCluster.uploadConfigDir(configDir, configSet);
+
+    SolrZkClient zkClient = new SolrZkClient(solrCluster.getZkServer().getZkAddress(),
+        AbstractZkTestCase.TIMEOUT, 45000, null);
+    try {
+      ZkConfigManager configManager = new ZkConfigManager(zkClient);
+      assertTrue(configManager.configExists(configSet));
+
+      Delete delete = new Delete();
+      delete.setConfigSetName(configSet);
+      ConfigSetAdminResponse response = delete.process(solrClient);
+      assertNotNull(response.getResponse());
+      assertFalse(configManager.configExists(configSet));
+    } finally {
+      zkClient.close();
+    }
+
+    solrClient.close();
+  }
+
+  private StringBuilder getConfigSetProps(Map<String, String> map) {
+    return new StringBuilder(new String(Utils.toJSON(map), StandardCharsets.UTF_8));
+  }
+
+  public static class CreateNoErrorChecking extends ConfigSetAdminRequest.Create {
+    public ConfigSetAdminRequest setAction(ConfigSetAction action) {
+       return super.setAction(action);
+    }
+
+    @Override
+    public SolrParams getParams() {
+      ModifiableSolrParams params = new ModifiableSolrParams();
+      if (action != null) params.set(ConfigSetParams.ACTION, action.toString());
+      if (configSetName != null) params.set(NAME, configSetName);
+      if (baseConfigSetName != null) params.set("baseConfigSet", baseConfigSetName);
+      return params;
+    }
+  }
+
+  public static class DeleteNoErrorChecking extends ConfigSetAdminRequest.Delete {
+    public ConfigSetAdminRequest setAction(ConfigSetAction action) {
+       return super.setAction(action);
+    }
+
+    @Override
+    public SolrParams getParams() {
+      ModifiableSolrParams params = new ModifiableSolrParams();
+      if (action != null) params.set(ConfigSetParams.ACTION, action.toString());
+      if (configSetName != null) params.set(NAME, configSetName);
+      return params;
+    }
+  }
+}
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestConfigSetsAPIExclusivity.java b/solr/core/src/test/org/apache/solr/cloud/TestConfigSetsAPIExclusivity.java
new file mode 100644
index 0000000..7ce4e52
--- /dev/null
+++ b/solr/core/src/test/org/apache/solr/cloud/TestConfigSetsAPIExclusivity.java
@@ -0,0 +1,194 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.cloud;
+
+import java.io.File;
+import java.util.Arrays;
+import java.util.LinkedList;
+import java.util.List;
+
+import org.apache.commons.io.FileUtils;
+import org.apache.solr.SolrTestCaseJ4;
+import org.apache.solr.client.solrj.SolrClient;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
+import org.apache.solr.client.solrj.request.ConfigSetAdminRequest;
+import org.apache.solr.client.solrj.request.ConfigSetAdminRequest.Create;
+import org.apache.solr.client.solrj.request.ConfigSetAdminRequest.Delete;
+
+import org.junit.After;
+import org.junit.Before;
+import org.junit.Test;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * Tests the exclusivity of the ConfigSets API.
+ * Submits a number of API requests concurrently and checks that
+ * the responses indicate the requests are handled sequentially for
+ * the same ConfigSet and base ConfigSet.
+ */
+public class TestConfigSetsAPIExclusivity extends SolrTestCaseJ4 {
+  private static Logger log = LoggerFactory
+      .getLogger(TestConfigSetsAPIExclusivity.class);
+
+  private MiniSolrCloudCluster solrCluster;
+  private static final String GRANDBASE_CONFIGSET_NAME = "grandBaseConfigSet1";
+  private static final String BASE_CONFIGSET_NAME = "baseConfigSet1";
+  private static final String CONFIGSET_NAME = "configSet1";
+
+  @Override
+  @Before
+  public void setUp() throws Exception {
+    super.setUp();
+    final File solrXml = getFile("solr").toPath().resolve("solr.xml").toFile();
+    final File testDir = createTempDir().toFile();
+    solrCluster = new MiniSolrCloudCluster(1, testDir,
+        solrXml, buildJettyConfig("/solr"));
+  }
+
+  @Override
+  @After
+  public void tearDown() throws Exception {
+    solrCluster.shutdown();
+    super.tearDown();
+  }
+
+  @Test
+  public void testAPIExclusivity() throws Exception {
+    int trials = 30;
+    setupBaseConfigSet(GRANDBASE_CONFIGSET_NAME);
+    CreateThread createBaseThread =
+        new CreateThread(solrCluster, BASE_CONFIGSET_NAME, GRANDBASE_CONFIGSET_NAME, trials);
+    CreateThread createThread =
+        new CreateThread(solrCluster, CONFIGSET_NAME, BASE_CONFIGSET_NAME, trials);
+    DeleteThread deleteBaseThread = new DeleteThread(solrCluster, BASE_CONFIGSET_NAME, trials);
+    DeleteThread deleteThread = new DeleteThread(solrCluster, CONFIGSET_NAME, trials);
+    List<ConfigSetsAPIThread> threads = Arrays.asList(
+        createBaseThread, createThread, deleteBaseThread, deleteThread);
+
+    for (ConfigSetsAPIThread thread : threads) {
+      thread.start();
+    }
+    for (ConfigSetsAPIThread thread : threads) {
+      thread.join();
+    }
+    List<Exception> exceptions = new LinkedList<Exception>();
+    for (ConfigSetsAPIThread thread : threads) {
+      exceptions.addAll(thread.getUnexpectedExceptions());
+    }
+    assertEquals("Unexpected exception: " + getFirstExceptionOrNull(exceptions),
+        0, exceptions.size());
+  }
+
+  private void setupBaseConfigSet(String baseConfigSetName) throws Exception {
+    final File configDir = getFile("solr").toPath().resolve("configsets/configset-2/conf").toFile();
+    final File tmpConfigDir = createTempDir().toFile();
+    tmpConfigDir.deleteOnExit();
+    FileUtils.copyDirectory(configDir, tmpConfigDir);
+    solrCluster.uploadConfigDir(tmpConfigDir, baseConfigSetName);
+  }
+
+  private Exception getFirstExceptionOrNull(List<Exception> list) {
+    return list.size() == 0 ? null : list.get(0);
+  }
+
+  private static abstract class ConfigSetsAPIThread extends Thread {
+    private MiniSolrCloudCluster solrCluster;
+    private int trials;
+    private List<Exception> unexpectedExceptions = new LinkedList<Exception>();
+    private List<String> allowedExceptions = Arrays.asList(new String[] {
+        "ConfigSet already exists",
+        "ConfigSet does not exist to delete",
+        "Base ConfigSet does not exist"});
+
+    public ConfigSetsAPIThread(MiniSolrCloudCluster solrCluster, int trials) {
+      this.solrCluster = solrCluster;
+      this.trials = trials;
+    }
+
+    public abstract ConfigSetAdminRequest createRequest();
+
+    public void run() {
+      final SolrClient solrClient =
+          new HttpSolrClient(solrCluster.getJettySolrRunners().get(0).getBaseUrl().toString());
+      ConfigSetAdminRequest request = createRequest();
+
+      for (int i = 0; i < trials; ++i) {
+        try {
+          request.process(solrClient);
+        } catch (Exception e) {
+          verifyException(e);
+        }
+      }
+      try {
+        solrClient.close();
+      } catch (Exception e) {
+        log.error("Error closing client", e);
+      }
+    }
+
+    private void verifyException(Exception e) {
+      for (String ex : allowedExceptions) {
+        if (e.getMessage().contains(ex)) {
+          return;
+        }
+      }
+      unexpectedExceptions.add(e);
+    }
+
+    public List<Exception> getUnexpectedExceptions() {
+      return unexpectedExceptions;
+    }
+  }
+
+  private static class CreateThread extends ConfigSetsAPIThread {
+    private String configSet;
+    private String baseConfigSet;
+
+    public CreateThread(MiniSolrCloudCluster solrCluster, String configSet,
+        String baseConfigSet, int trials) {
+      super(solrCluster, trials);
+      this.configSet = configSet;
+      this.baseConfigSet = baseConfigSet;
+    }
+
+    @Override
+    public ConfigSetAdminRequest createRequest() {
+      Create create = new Create();
+      create.setBaseConfigSetName(baseConfigSet).setConfigSetName(configSet);
+      return create;
+    }
+  }
+
+  private static class DeleteThread extends ConfigSetsAPIThread {
+    private String configSet;
+
+    public DeleteThread(MiniSolrCloudCluster solrCluster, String configSet, int trials) {
+      super(solrCluster, trials);
+      this.configSet = configSet;
+    }
+
+    @Override
+    public ConfigSetAdminRequest createRequest() {
+      Delete delete = new Delete();
+      delete.setConfigSetName(configSet);
+      return delete;
+    }
+  }
+}
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestConfigSetsAPIZkFailure.java b/solr/core/src/test/org/apache/solr/cloud/TestConfigSetsAPIZkFailure.java
new file mode 100644
index 0000000..2247843
--- /dev/null
+++ b/solr/core/src/test/org/apache/solr/cloud/TestConfigSetsAPIZkFailure.java
@@ -0,0 +1,372 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.cloud;
+
+import com.google.common.collect.ImmutableMap;
+import java.io.File;
+import java.io.IOException;
+import java.io.PrintWriter;
+import java.nio.charset.StandardCharsets;
+import java.util.Collection;
+import java.util.HashSet;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Map;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.locks.ReentrantReadWriteLock;
+
+import org.apache.commons.io.FileUtils;
+import org.apache.jute.InputArchive;
+import org.apache.jute.OutputArchive;
+import org.apache.jute.Record;
+import org.apache.solr.SolrTestCaseJ4;
+import org.apache.solr.client.solrj.SolrClient;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
+import org.apache.solr.client.solrj.impl.HttpSolrClient.RemoteSolrException;
+import org.apache.solr.client.solrj.request.ConfigSetAdminRequest.Create;
+import org.apache.solr.client.solrj.response.ConfigSetAdminResponse;
+import org.apache.solr.cloud.ZkTestServer;
+import org.apache.solr.common.SolrException;
+import org.apache.solr.common.cloud.SolrZkClient;
+import org.apache.solr.common.cloud.ZkConfigManager;
+import org.apache.solr.common.util.Utils;
+import org.apache.solr.core.ConfigSetProperties;
+import org.apache.zookeeper.KeeperException;
+import org.apache.zookeeper.KeeperException.NoNodeException;
+import org.apache.zookeeper.Watcher;
+import org.apache.zookeeper.data.ACL;
+import org.apache.zookeeper.data.Stat;
+import org.apache.zookeeper.server.quorum.Leader.Proposal;
+import org.apache.zookeeper.server.DataNode;
+import org.apache.zookeeper.server.DataTree;
+import org.apache.zookeeper.server.DataTree.ProcessTxnResult;
+import org.apache.zookeeper.server.Request;
+import org.apache.zookeeper.server.ServerCnxn;
+import org.apache.zookeeper.server.ZKDatabase;
+import org.apache.zookeeper.txn.TxnHeader;
+
+import org.junit.After;
+import org.junit.Assert;
+import org.junit.Before;
+import org.junit.Test;
+
+import static org.apache.solr.common.cloud.ZkConfigManager.CONFIGS_ZKNODE;
+
+/**
+ * Test the ConfigSets API under ZK failure.  In particular,
+ * if create fails, ensure proper cleanup occurs so we aren't
+ * left with a partially created ConfigSet.
+ */
+public class TestConfigSetsAPIZkFailure extends SolrTestCaseJ4 {
+  private MiniSolrCloudCluster solrCluster;
+  private ZkTestServer zkTestServer;
+  private static final String BASE_CONFIGSET_NAME = "baseConfigSet1";
+  private static final String CONFIGSET_NAME = "configSet1";
+
+  @Override
+  @Before
+  public void setUp() throws Exception {
+    super.setUp();
+    final File solrXml = getFile("solr").toPath().resolve("solr.xml").toFile();
+    final File testDir = createTempDir().toFile();
+    String zkDir = testDir.getAbsolutePath() + File.separator
+      + "zookeeper/server1/data";
+    zkTestServer = new ZkTestServer(zkDir);
+    zkTestServer.run();
+    zkTestServer.setZKDatabase(
+        new FailureDuringCopyZKDatabase(zkTestServer.getZKDatabase(), zkTestServer));
+    solrCluster = new MiniSolrCloudCluster(1, testDir,
+        solrXml, buildJettyConfig("/solr"), zkTestServer);
+  }
+
+  @Override
+  @After
+  public void tearDown() throws Exception {
+    solrCluster.shutdown();
+    zkTestServer.shutdown();
+    super.tearDown();
+  }
+
+  @Test
+  public void testCreateZkFailure() throws Exception {
+    final SolrClient solrClient =
+        new HttpSolrClient(solrCluster.getJettySolrRunners().get(0).getBaseUrl().toString());
+
+    final Map<String, String> oldProps = ImmutableMap.of("immutable", "true");
+    setupBaseConfigSet(BASE_CONFIGSET_NAME, oldProps);
+
+    SolrZkClient zkClient = new SolrZkClient(solrCluster.getZkServer().getZkAddress(),
+        AbstractZkTestCase.TIMEOUT, 45000, null);
+    try {
+      ZkConfigManager configManager = new ZkConfigManager(zkClient);
+      assertFalse(configManager.configExists(CONFIGSET_NAME));
+
+      Create create = new Create();
+      create.setBaseConfigSetName(BASE_CONFIGSET_NAME).setConfigSetName(CONFIGSET_NAME);
+      try {
+        ConfigSetAdminResponse response = create.process(solrClient);
+        Assert.fail("Expected solr exception");
+      } catch (RemoteSolrException se) {
+        // partial creation should have been cleaned up
+        assertFalse(configManager.configExists(CONFIGSET_NAME));
+        assertEquals(SolrException.ErrorCode.SERVER_ERROR.code, se.code());
+      }
+    } finally {
+      zkClient.close();
+    }
+
+    solrClient.close();
+  }
+
+  private void setupBaseConfigSet(String baseConfigSetName, Map<String, String> oldProps) throws Exception {
+    final File configDir = getFile("solr").toPath().resolve("configsets/configset-2/conf").toFile();
+    final File tmpConfigDir = createTempDir().toFile();
+    tmpConfigDir.deleteOnExit();
+    FileUtils.copyDirectory(configDir, tmpConfigDir);
+    if (oldProps != null) {
+      FileUtils.write(new File(tmpConfigDir, ConfigSetProperties.DEFAULT_FILENAME),
+          getConfigSetProps(oldProps));
+    }
+    solrCluster.uploadConfigDir(tmpConfigDir, baseConfigSetName);
+  }
+
+  private StringBuilder getConfigSetProps(Map<String, String> map) {
+    return new StringBuilder(new String(Utils.toJSON(map), StandardCharsets.UTF_8));
+  }
+
+  private static class FailureDuringCopyZKDatabase extends ForwardingZKDatabase {
+    private final ZkTestServer zkTestServer;
+
+    public FailureDuringCopyZKDatabase(ZKDatabase zkdb, ZkTestServer zkTestServer) {
+      super(zkdb);
+      this.zkTestServer = zkTestServer;
+    }
+
+    @Override
+    public byte[] getData(String path, Stat stat, Watcher watcher) throws KeeperException.NoNodeException {
+      // we know we are doing a copy when we are getting data from the base config set and
+      // the new config set (partially) exists
+      String zkAddress = zkTestServer.getZkAddress();
+      String chroot = zkAddress.substring(zkAddress.lastIndexOf("/"));
+      if (path.startsWith(chroot + CONFIGS_ZKNODE + "/" + BASE_CONFIGSET_NAME)
+          && !path.contains(ConfigSetProperties.DEFAULT_FILENAME)) {
+        List<String> children = null;
+        try {
+          children = getChildren(chroot + CONFIGS_ZKNODE + "/" + CONFIGSET_NAME, null, null);
+        } catch (KeeperException.NoNodeException e) {}
+        if (children != null && children.size() > 0) {
+          throw new RuntimeException("sample zookeeper error");
+        }
+      }
+      return super.getData(path, stat, watcher);
+    }
+  }
+
+  private static class ForwardingZKDatabase extends ZKDatabase {
+    private ZKDatabase zkdb;
+
+    public ForwardingZKDatabase(ZKDatabase zkdb) {
+      super(null);
+      this.zkdb = zkdb;
+    }
+
+    @Override
+    public boolean isInitialized() {
+      return zkdb.isInitialized();
+    }
+
+    @Override
+    public void clear() {
+      zkdb.clear();
+    }
+
+    @Override
+    public DataTree getDataTree() {
+      return zkdb.getDataTree();
+    }
+
+    @Override
+    public long getmaxCommittedLog() {
+      return zkdb.getmaxCommittedLog();
+    }
+
+    @Override
+    public long getminCommittedLog() {
+      return zkdb.getminCommittedLog();
+    }
+
+    @Override
+    public ReentrantReadWriteLock getLogLock() {
+      return zkdb.getLogLock();
+    }
+
+    @Override
+    public synchronized LinkedList<Proposal> getCommittedLog() {
+      return zkdb.getCommittedLog();
+    }
+
+    @Override
+    public long getDataTreeLastProcessedZxid() {
+      return zkdb.getDataTreeLastProcessedZxid();
+    }
+
+    @Override
+    public void setDataTreeInit(boolean b) {
+      zkdb.setDataTreeInit(b);
+    }
+
+    @Override
+    public Collection<Long> getSessions() {
+      return zkdb.getSessions();
+    }
+
+    @Override
+    public ConcurrentHashMap<Long, Integer> getSessionWithTimeOuts() {
+      return zkdb.getSessionWithTimeOuts();
+    }
+
+    @Override
+    public long loadDataBase() throws IOException {
+      return zkdb.loadDataBase();
+    }
+
+    @Override
+    public void addCommittedProposal(Request request) {
+      zkdb.addCommittedProposal(request);
+    }
+
+    @Override
+    public void removeCnxn(ServerCnxn cnxn) {
+      zkdb.removeCnxn(cnxn);
+    }
+
+    @Override
+    public void killSession(long sessionId, long zxid) {
+      zkdb.killSession(sessionId, zxid);
+    }
+
+    @Override
+    public void dumpEphemerals(PrintWriter pwriter) {
+      zkdb.dumpEphemerals(pwriter);
+    }
+
+    @Override
+    public int getNodeCount() {
+      return zkdb.getNodeCount();
+    }
+
+    @Override
+    public HashSet<String> getEphemerals(long sessionId) {
+      return zkdb.getEphemerals(sessionId);
+    }
+
+    @Override
+    public void setlastProcessedZxid(long zxid) {
+      zkdb.setlastProcessedZxid(zxid);
+    }
+
+    @Override
+    public ProcessTxnResult processTxn(TxnHeader hdr, Record txn) {
+      return zkdb.processTxn(hdr, txn);
+    }
+
+    @Override
+    public Stat statNode(String path, ServerCnxn serverCnxn) throws KeeperException.NoNodeException {
+      return zkdb.statNode(path, serverCnxn);
+    }
+
+    @Override
+    public DataNode getNode(String path) {
+      return zkdb.getNode(path);
+    }
+
+    @Override
+    public List<ACL> convertLong(Long aclL) {
+      return zkdb.convertLong(aclL);
+    }
+
+    @Override
+    public byte[] getData(String path, Stat stat, Watcher watcher)
+    throws KeeperException.NoNodeException {
+      return zkdb.getData(path, stat, watcher);
+    }
+
+    @Override
+    public void setWatches(long relativeZxid, List<String> dataWatches,
+            List<String> existWatches, List<String> childWatches, Watcher watcher) {
+      zkdb.setWatches(relativeZxid, dataWatches, existWatches, childWatches, watcher);
+    }
+
+    @Override
+    public List<ACL> getACL(String path, Stat stat) throws NoNodeException {
+      return zkdb.getACL(path, stat);
+    }
+
+    @Override
+    public List<String> getChildren(String path, Stat stat, Watcher watcher)
+    throws KeeperException.NoNodeException {
+      return zkdb.getChildren(path, stat, watcher);
+    }
+
+    @Override
+    public boolean isSpecialPath(String path) {
+      return zkdb.isSpecialPath(path);
+    }
+
+    @Override
+    public int getAclSize() {
+      return zkdb.getAclSize();
+    }
+
+    @Override
+    public boolean truncateLog(long zxid) throws IOException {
+      return zkdb.truncateLog(zxid);
+    }
+
+    @Override
+    public void deserializeSnapshot(InputArchive ia) throws IOException {
+      zkdb.deserializeSnapshot(ia);
+    }
+
+    @Override
+    public void serializeSnapshot(OutputArchive oa) throws IOException,
+    InterruptedException {
+      zkdb.serializeSnapshot(oa);
+    }
+
+    @Override
+    public boolean append(Request si) throws IOException {
+      return zkdb.append(si);
+    }
+
+    @Override
+    public void rollLog() throws IOException {
+      zkdb.rollLog();
+    }
+
+    @Override
+    public void commit() throws IOException {
+      zkdb.commit();
+    }
+
+    @Override
+    public void close() throws IOException {
+      zkdb.close();
+    }
+  }
+}
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestLeaderElectionZkExpiry.java b/solr/core/src/test/org/apache/solr/cloud/TestLeaderElectionZkExpiry.java
index c4dc888..66f8b90 100644
--- a/solr/core/src/test/org/apache/solr/cloud/TestLeaderElectionZkExpiry.java
+++ b/solr/core/src/test/org/apache/solr/cloud/TestLeaderElectionZkExpiry.java
@@ -78,7 +78,7 @@ public class TestLeaderElectionZkExpiry extends SolrTestCaseJ4 {
         boolean found = false;
         while (System.nanoTime() < timeout) {
           try {
-            String leaderNode = OverseerCollectionProcessor.getLeaderNode(zc);
+            String leaderNode = OverseerCollectionConfigSetProcessor.getLeaderNode(zc);
             if (leaderNode != null && !leaderNode.trim().isEmpty()) {
               log.info("Time={} Overseer leader is = {}", System.nanoTime(), leaderNode);
               found = true;
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestRebalanceLeaders.java b/solr/core/src/test/org/apache/solr/cloud/TestRebalanceLeaders.java
index 9cbc95c..71b156b 100644
--- a/solr/core/src/test/org/apache/solr/cloud/TestRebalanceLeaders.java
+++ b/solr/core/src/test/org/apache/solr/cloud/TestRebalanceLeaders.java
@@ -182,7 +182,7 @@ public class TestRebalanceLeaders extends AbstractFullDistribZkTestBase {
   List<String> getOverseerSort(String key) {
     List<String> ret = null;
     try {
-      ret = OverseerCollectionProcessor.getSortedElectionNodes(cloudClient.getZkStateReader().getZkClient(),
+      ret = OverseerCollectionConfigSetProcessor.getSortedElectionNodes(cloudClient.getZkStateReader().getZkClient(),
           "/collections/" + COLLECTION_NAME + "/leader_elect/" + key + "/election");
       return ret;
     } catch (KeeperException e) {
diff --git a/solr/core/src/test/org/apache/solr/core/TestCoreContainer.java b/solr/core/src/test/org/apache/solr/core/TestCoreContainer.java
index de1f74a..3216edf 100644
--- a/solr/core/src/test/org/apache/solr/core/TestCoreContainer.java
+++ b/solr/core/src/test/org/apache/solr/core/TestCoreContainer.java
@@ -24,6 +24,7 @@ import org.apache.solr.common.SolrException;
 import org.apache.solr.handler.admin.CollectionsHandler;
 import org.apache.solr.handler.admin.CoreAdminHandler;
 import org.apache.solr.handler.admin.InfoHandler;
+import org.apache.solr.handler.admin.ConfigSetsHandler;
 import org.junit.AfterClass;
 import org.junit.BeforeClass;
 import org.junit.Test;
@@ -308,6 +309,7 @@ public class TestCoreContainer extends SolrTestCaseJ4 {
       " <str name=\"collectionsHandler\">" + CustomCollectionsHandler.class.getName() + "</str>" +
       " <str name=\"infoHandler\">" + CustomInfoHandler.class.getName() + "</str>" +
       " <str name=\"adminHandler\">" + CustomCoreAdminHandler.class.getName() + "</str>" +
+      " <str name=\"configSetsHandler\">" + CustomConfigSetsHandler.class.getName() + "</str>" +
       "</solr>";
 
   public static class CustomCollectionsHandler extends CollectionsHandler {
@@ -328,6 +330,12 @@ public class TestCoreContainer extends SolrTestCaseJ4 {
     }
   }
 
+  public static class CustomConfigSetsHandler extends ConfigSetsHandler {
+    public CustomConfigSetsHandler(CoreContainer cc) {
+      super(cc);
+    }
+  }
+
   @Test
   public void testCustomHandlers() throws Exception {
 
diff --git a/solr/core/src/test/org/apache/solr/core/TestSolrXml.java b/solr/core/src/test/org/apache/solr/core/TestSolrXml.java
index beea8da..f23b13b 100644
--- a/solr/core/src/test/org/apache/solr/core/TestSolrXml.java
+++ b/solr/core/src/test/org/apache/solr/core/TestSolrXml.java
@@ -72,6 +72,7 @@ public class TestSolrXml extends SolrTestCaseJ4 {
     assertEquals("core admin handler class", "testAdminHandler", cfg.getCoreAdminHandlerClass());
     assertEquals("collection handler class", "testCollectionsHandler", cfg.getCollectionsHandlerClass());
     assertEquals("info handler class", "testInfoHandler", cfg.getInfoHandlerClass());
+    assertEquals("config set handler class", "testConfigSetsHandler", cfg.getConfigSetsHandlerClass());
     assertEquals("core load threads", 11, cfg.getCoreLoadThreadCount());
     assertThat("core root dir", cfg.getCoreRootDirectory(), containsString("testCoreRootDirectory"));
     assertEquals("distrib conn timeout", 22, cfg.getDistributedConnectionTimeout());
diff --git a/solr/solrj/src/java/org/apache/solr/client/solrj/request/ConfigSetAdminRequest.java b/solr/solrj/src/java/org/apache/solr/client/solrj/request/ConfigSetAdminRequest.java
new file mode 100644
index 0000000..eab6112
--- /dev/null
+++ b/solr/solrj/src/java/org/apache/solr/client/solrj/request/ConfigSetAdminRequest.java
@@ -0,0 +1,155 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.client.solrj.request;
+
+import java.io.IOException;
+import java.util.Collection;
+import java.util.Map;
+import java.util.Properties;
+
+
+import org.apache.solr.client.solrj.SolrClient;
+import org.apache.solr.client.solrj.SolrRequest;
+import org.apache.solr.client.solrj.response.ConfigSetAdminResponse;
+import org.apache.solr.common.params.ConfigSetParams;
+import org.apache.solr.common.params.ConfigSetParams.ConfigSetAction;
+import org.apache.solr.common.params.ModifiableSolrParams;
+import org.apache.solr.common.params.SolrParams;
+import org.apache.solr.common.util.ContentStream;
+import static org.apache.solr.common.params.CommonParams.NAME;
+
+/**
+ * This class is experimental and subject to change.
+ *
+ * @since solr 5.4
+ */
+public abstract class ConfigSetAdminRequest <Q extends ConfigSetAdminRequest<Q>> extends SolrRequest<ConfigSetAdminResponse> {
+
+  protected ConfigSetAction action = null;
+  protected String configSetName = null;
+
+  protected ConfigSetAdminRequest setAction(ConfigSetAction action) {
+    this.action = action;
+    return this;
+  }
+
+  public ConfigSetAdminRequest() {
+    super(METHOD.GET, "/admin/configs");
+  }
+
+  public ConfigSetAdminRequest(String path) {
+    super (METHOD.GET, path);
+  }
+
+  protected abstract Q getThis();
+
+  @Override
+  public SolrParams getParams() {
+    if (action == null) {
+      throw new RuntimeException( "no action specified!" );
+    }
+    if (configSetName == null) {
+      throw new RuntimeException( "no ConfigSet specified!" );
+    }
+    ModifiableSolrParams params = new ModifiableSolrParams();
+    params.set(ConfigSetParams.ACTION, action.toString());
+    params.set(NAME, configSetName);
+    return params;
+  }
+
+  @Override
+  public Collection<ContentStream> getContentStreams() throws IOException {
+    return null;
+  }
+
+  @Override
+  protected ConfigSetAdminResponse createResponse(SolrClient client) {
+    return new ConfigSetAdminResponse();
+  }
+
+  public final Q setConfigSetName(String configSetName) {
+    this.configSetName = configSetName;
+    return getThis();
+  }
+
+  public final String getConfigSetName() {
+    return configSetName;
+  }
+
+  // CREATE request
+  public static class Create extends ConfigSetAdminRequest<Create> {
+    protected static String PROPERTY_PREFIX = "configSetProp";
+    protected String baseConfigSetName;
+    protected Properties properties;
+
+    public Create() {
+      action = ConfigSetAction.CREATE;
+    }
+
+    @Override
+    protected Create getThis() {
+      return this;
+    }
+
+    public final Create setBaseConfigSetName(String baseConfigSetName) {
+      this.baseConfigSetName = baseConfigSetName;
+      return getThis();
+    }
+
+    public final String getBaseConfigSetName() {
+      return baseConfigSetName;
+    }
+
+    public final Create setNewConfigSetProperties(Properties properties) {
+      this.properties = properties;
+      return getThis();
+    }
+
+    public final Properties getNewConfigSetProperties() {
+      return properties;
+    }
+
+    @Override
+    public SolrParams getParams() {
+      ModifiableSolrParams params = new ModifiableSolrParams(super.getParams());
+      if (baseConfigSetName == null) {
+        throw new RuntimeException( "no Base ConfigSet specified!" );
+      }
+      params.set("baseConfigSet", baseConfigSetName);
+      if (properties != null) {
+        for (Map.Entry entry : properties.entrySet()) {
+          params.set(PROPERTY_PREFIX + "." + entry.getKey().toString(),
+              entry.getValue().toString());
+        }
+      }
+      return params;
+    }
+  }
+
+  // DELETE request
+  public static class Delete extends ConfigSetAdminRequest<Delete> {
+    public Delete() {
+      action = ConfigSetAction.DELETE;
+    }
+
+    @Override
+    protected Delete getThis() {
+      return this;
+    }
+  }
+}
diff --git a/solr/solrj/src/java/org/apache/solr/client/solrj/response/ConfigSetAdminResponse.java b/solr/solrj/src/java/org/apache/solr/client/solrj/response/ConfigSetAdminResponse.java
new file mode 100644
index 0000000..52dae45
--- /dev/null
+++ b/solr/solrj/src/java/org/apache/solr/client/solrj/response/ConfigSetAdminResponse.java
@@ -0,0 +1,33 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.client.solrj.response;
+
+import org.apache.solr.common.util.NamedList;
+
+/**
+ * No special handling at this time.
+ */
+public class ConfigSetAdminResponse extends SolrResponseBase
+{
+  @SuppressWarnings("unchecked")
+  public NamedList<String> getErrorMessages()
+  {
+     return (NamedList<String>) getResponse().get( "exceptions" );
+  }
+
+}
diff --git a/solr/solrj/src/java/org/apache/solr/common/cloud/ZkConfigManager.java b/solr/solrj/src/java/org/apache/solr/common/cloud/ZkConfigManager.java
index a3a8060..1871df9 100644
--- a/solr/solrj/src/java/org/apache/solr/common/cloud/ZkConfigManager.java
+++ b/solr/solrj/src/java/org/apache/solr/common/cloud/ZkConfigManager.java
@@ -29,6 +29,7 @@ import java.nio.file.SimpleFileVisitor;
 import java.nio.file.attribute.BasicFileAttributes;
 import java.util.Collections;
 import java.util.List;
+import java.util.Set;
 
 /**
  * Class that manages named configs in Zookeeper
@@ -142,4 +143,81 @@ public class ZkConfigManager {
       throw new IOException("Error listing configs", SolrZkClient.checkInterrupted(e));
     }
   }
+
+  /**
+   * Check whether a config exists in Zookeeper
+   *
+   * @param configName the config to check existance on
+   * @return whether the config exists or not
+   * @throws IOException if an I/O error occurs
+   */
+  public Boolean configExists(String configName) throws IOException {
+    try {
+      return zkClient.exists(ZkConfigManager.CONFIGS_ZKNODE + "/" + configName, true);
+    } catch (KeeperException | InterruptedException e) {
+      throw new IOException("Error checking whether config exists",
+          SolrZkClient.checkInterrupted(e));
+    }
+  }
+
+  /**
+   * Delete a config in ZooKeeper
+   *
+   * @param configName the config to delete
+   * @throws IOException if an I/O error occurs
+   */
+  public void deleteConfigDir(String configName) throws IOException {
+    try {
+      zkClient.clean(ZkConfigManager.CONFIGS_ZKNODE + "/" + configName);
+    } catch (KeeperException | InterruptedException e) {
+      throw new IOException("Error checking whether config exists",
+          SolrZkClient.checkInterrupted(e));
+    }
+  }
+
+  private void copyConfigDirFromZk(String fromZkPath, String toZkPath, Set<String> copiedToZkPaths) throws IOException {
+    try {
+      List<String> files = zkClient.getChildren(fromZkPath, null, true);
+      for (String file : files) {
+        List<String> children = zkClient.getChildren(fromZkPath + "/" + file, null, true);
+        if (children.size() == 0) {
+          final String toZkFilePath = toZkPath + "/" + file;
+          logger.info("Copying zk node {} to {}",
+              fromZkPath + "/" + file, toZkFilePath);
+          byte[] data = zkClient.getData(fromZkPath + "/" + file, null, null, true);
+          zkClient.makePath(toZkFilePath, data, true);
+          if (copiedToZkPaths != null) copiedToZkPaths.add(toZkFilePath);
+        } else {
+          copyConfigDirFromZk(fromZkPath + "/" + file, toZkPath + "/" + file, copiedToZkPaths);
+        }
+      }
+    } catch (KeeperException | InterruptedException e) {
+      throw new IOException("Error copying nodes from zookeeper path " + fromZkPath + " to " + toZkPath,
+          SolrZkClient.checkInterrupted(e));
+    }
+  }
+
+  /**
+   * Copy a config in ZooKeeper
+   *
+   * @param fromConfig the config to copy from
+   * @param toConfig the config to copy to
+   * @throws IOException if an I/O error occurs
+   */
+  public void copyConfigDir(String fromConfig, String toConfig) throws IOException {
+    copyConfigDir(CONFIGS_ZKNODE + "/" + fromConfig, CONFIGS_ZKNODE + "/" + toConfig, null);
+  }
+
+  /**
+   * Copy a config in ZooKeeper
+   *
+   * @param fromConfig the config to copy from
+   * @param toConfig the config to copy to
+   * @param copiedToZkPaths should be an empty Set, will be filled in by function
+                            with the paths that were actually copied to.
+   * @throws IOException if an I/O error occurs
+   */
+  public void copyConfigDir(String fromConfig, String toConfig, Set<String> copiedToZkPaths) throws IOException {
+    copyConfigDirFromZk(CONFIGS_ZKNODE + "/" + fromConfig, CONFIGS_ZKNODE + "/" + toConfig, copiedToZkPaths);
+  }
 }
diff --git a/solr/solrj/src/java/org/apache/solr/common/params/ConfigSetParams.java b/solr/solrj/src/java/org/apache/solr/common/params/ConfigSetParams.java
new file mode 100644
index 0000000..fda708f
--- /dev/null
+++ b/solr/solrj/src/java/org/apache/solr/common/params/ConfigSetParams.java
@@ -0,0 +1,51 @@
+package org.apache.solr.common.params;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.util.Locale;
+
+/**
+ * ConfigSets API related parameters and actions.
+ */
+public interface ConfigSetParams
+{
+  public final static String ACTION = "action";
+
+  public enum ConfigSetAction {
+    CREATE,
+    DELETE;
+
+    public static ConfigSetAction get(String p) {
+      if (p != null) {
+        try {
+          return ConfigSetAction.valueOf( p.toUpperCase(Locale.ROOT) );
+        } catch (Exception ex) {}
+      }
+      return null;
+    }
+
+    public boolean isEqual(String s) {
+      if (s == null) return false;
+      return toString().equals(s.toUpperCase(Locale.ROOT));
+    }
+
+    public String toLower() {
+      return toString().toLowerCase(Locale.ROOT);
+    }
+  }
+}
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/request/TestConfigSetAdminRequest.java b/solr/solrj/src/test/org/apache/solr/client/solrj/request/TestConfigSetAdminRequest.java
new file mode 100644
index 0000000..8ecdb5e
--- /dev/null
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/request/TestConfigSetAdminRequest.java
@@ -0,0 +1,70 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.client.solrj.request;
+
+import org.apache.solr.SolrTestCaseJ4;
+import org.junit.Assert;
+import org.junit.Test;
+
+/**
+ * Basic error checking of ConfigSetAdminRequests.
+ */
+public class TestConfigSetAdminRequest extends SolrTestCaseJ4 {
+
+  @Test
+  public void testNoAction() {
+    ConfigSetAdminRequest request = new MyConfigSetAdminRequest();
+    request.setConfigSetName("name");
+    verifyException(request, "action");
+  }
+
+  @Test
+  public void testCreate() {
+    ConfigSetAdminRequest.Create create = new ConfigSetAdminRequest.Create();
+    verifyException(create, "ConfigSet");
+    create.setConfigSetName("name");
+    verifyException(create, "Base ConfigSet");
+    create.setBaseConfigSetName("baseConfigSet");
+    create.getParams();
+  }
+
+  @Test
+  public void testDelete() {
+    ConfigSetAdminRequest.Delete delete = new ConfigSetAdminRequest.Delete();
+    verifyException(delete, "ConfigSet");
+  }
+
+  private void verifyException(ConfigSetAdminRequest request, String errorContains) {
+    try {
+      request.getParams();
+      Assert.fail("Expected exception");
+    } catch (Exception e) {
+      assertTrue("Expected exception message to contain: " + errorContains,
+          e.getMessage().contains(errorContains));
+    }
+  }
+
+  private static class MyConfigSetAdminRequest extends ConfigSetAdminRequest<MyConfigSetAdminRequest> {
+      public MyConfigSetAdminRequest() {}
+
+      @Override
+      public MyConfigSetAdminRequest getThis() {
+        return this;
+      }
+    };
+}
diff --git a/solr/test-framework/src/java/org/apache/solr/cloud/MiniSolrCloudCluster.java b/solr/test-framework/src/java/org/apache/solr/cloud/MiniSolrCloudCluster.java
index 9be1f14..0638d8c 100644
--- a/solr/test-framework/src/java/org/apache/solr/cloud/MiniSolrCloudCluster.java
+++ b/solr/test-framework/src/java/org/apache/solr/cloud/MiniSolrCloudCluster.java
@@ -64,6 +64,7 @@ public class MiniSolrCloudCluster {
   private static Logger log = LoggerFactory.getLogger(MiniSolrCloudCluster.class);
 
   private final ZkTestServer zkServer;
+  private final boolean externalZkServer;
   private final List<JettySolrRunner> jettys = new LinkedList<>();
   private final File testDir;
   private final CloudSolrClient solrClient;
@@ -125,15 +126,34 @@ public class MiniSolrCloudCluster {
    * @throws Exception if there was an error starting the cluster
    */
   public MiniSolrCloudCluster(int numServers, File baseDir, File solrXml, JettyConfig jettyConfig) throws Exception {
+    this(numServers, baseDir, solrXml, jettyConfig, null);
+  }
+
+  /**
+   * Create a MiniSolrCloudCluster
+   *
+   * @param numServers number of Solr servers to start
+   * @param baseDir base directory that the mini cluster should be run from
+   * @param solrXml solr.xml file to be uploaded to ZooKeeper
+   * @param jettyConfig Jetty configuration
+   * @param zkTestServer ZkTestServer to use.  If null, one will be created
+   *
+   * @throws Exception if there was an error starting the cluster
+   */
+  public MiniSolrCloudCluster(int numServers, File baseDir, File solrXml, JettyConfig jettyConfig, ZkTestServer zkTestServer) throws Exception {
 
     this.testDir = baseDir;
     this.jettyConfig = jettyConfig;
 
-    String zkDir = testDir.getAbsolutePath() + File.separator
-      + "zookeeper/server1/data";
-    zkServer = new ZkTestServer(zkDir);
-    zkServer.run();
-    
+    this.externalZkServer = zkTestServer != null;
+    if (!externalZkServer) {
+      String zkDir = testDir.getAbsolutePath() + File.separator
+        + "zookeeper/server1/data";
+      zkTestServer = new ZkTestServer(zkDir);
+      zkTestServer.run();
+    }
+    this.zkServer = zkTestServer;
+
     try(SolrZkClient zkClient = new SolrZkClient(zkServer.getZkHost(),
         AbstractZkTestCase.TIMEOUT, 45000, null)) {
       zkClient.makePath("/solr/solr.xml", solrXml, false, true);
@@ -375,7 +395,9 @@ public class MiniSolrCloudCluster {
       executor.shutdown();
       executor.awaitTermination(2, TimeUnit.SECONDS);
       try {
-        zkServer.shutdown();
+        if (!externalZkServer) {
+          zkServer.shutdown();
+        }
       } finally {
         System.clearProperty("zkHost");
       }
diff --git a/solr/test-framework/src/java/org/apache/solr/cloud/ZkTestServer.java b/solr/test-framework/src/java/org/apache/solr/cloud/ZkTestServer.java
index b36bec3..b23f273 100644
--- a/solr/test-framework/src/java/org/apache/solr/cloud/ZkTestServer.java
+++ b/solr/test-framework/src/java/org/apache/solr/cloud/ZkTestServer.java
@@ -448,6 +448,14 @@ public class ZkTestServer {
     });
   }
 
+  public ZKDatabase getZKDatabase() {
+    return zkServer.zooKeeperServer.getZKDatabase();
+  }
+
+  public void setZKDatabase(ZKDatabase zkDb) {
+    zkServer.zooKeeperServer.setZKDatabase(zkDb);
+  }
+
   public void run() throws InterruptedException {
     log.info("STARTING ZK TEST SERVER");
     // we don't call super.distribSetUp

