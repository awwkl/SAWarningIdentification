GitDiffStart: 48a5004fe62bca387dc9c476033724e7ef1905a9 | Wed Jan 16 09:43:51 2013 +0000
diff --git a/lucene/CHANGES.txt b/lucene/CHANGES.txt
index 2080d4d..db5f556 100644
--- a/lucene/CHANGES.txt
+++ b/lucene/CHANGES.txt
@@ -32,8 +32,13 @@ Changes in backwards compatibility policy
 
 ======================= Lucene 4.2.0 =======================
 
-(No changes yet)
+Changes in backwards compatibility policy
 
+* LUCENE-4602: FacetFields now stores facet ordinals in a DocValues field, 
+  rather than a payload. This forces rebuilding existing indexes, or do a
+  one time migration using FacetsPayloadMigratingReader. Since DocValues 
+  support in-memory caching, CategoryListCache was removed too.
+  (Shai Erera, Michael McCandless)
 
 ======================= Lucene 4.1.0 =======================
 
diff --git a/lucene/facet/src/examples/org/apache/lucene/facet/example/merge/TaxonomyMergeUtils.java b/lucene/facet/src/examples/org/apache/lucene/facet/example/merge/TaxonomyMergeUtils.java
index 55d1e67..b5c53a1 100644
--- a/lucene/facet/src/examples/org/apache/lucene/facet/example/merge/TaxonomyMergeUtils.java
+++ b/lucene/facet/src/examples/org/apache/lucene/facet/example/merge/TaxonomyMergeUtils.java
@@ -90,8 +90,9 @@ public class TaxonomyMergeUtils {
 
     DirectoryReader reader = DirectoryReader.open(srcIndexDir, -1);
     List<AtomicReaderContext> leaves = reader.leaves();
-    AtomicReader wrappedLeaves[] = new AtomicReader[leaves.size()];
-    for (int i = 0; i < leaves.size(); i++) {
+    int numReaders = leaves.size();
+    AtomicReader wrappedLeaves[] = new AtomicReader[numReaders];
+    for (int i = 0; i < numReaders; i++) {
       wrappedLeaves[i] = new OrdinalMappingAtomicReader(leaves.get(i).reader(), ordinalMap, params);
     }
     try {
diff --git a/lucene/facet/src/examples/org/apache/lucene/facet/example/multiCL/MultiCLIndexer.java b/lucene/facet/src/examples/org/apache/lucene/facet/example/multiCL/MultiCLIndexer.java
index 96d273a..5925e23 100644
--- a/lucene/facet/src/examples/org/apache/lucene/facet/example/multiCL/MultiCLIndexer.java
+++ b/lucene/facet/src/examples/org/apache/lucene/facet/example/multiCL/MultiCLIndexer.java
@@ -20,7 +20,6 @@ import org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyWriter;
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.IndexWriterConfig;
 import org.apache.lucene.index.IndexWriterConfig.OpenMode;
-import org.apache.lucene.index.Term;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.RAMDirectory;
 
@@ -80,12 +79,12 @@ public class MultiCLIndexer {
   // Initialize PerDimensionIndexingParams
   static {
     Map<CategoryPath, CategoryListParams> paramsMap = new HashMap<CategoryPath,CategoryListParams>();
-    paramsMap.put(new CategoryPath("0"), new CategoryListParams(new Term("$Digits", "Zero")));
-    paramsMap.put(new CategoryPath("1"), new CategoryListParams(new Term("$Digits", "One")));
-    paramsMap.put(new CategoryPath("2"), new CategoryListParams(new Term("$Digits", "Two")));
-    paramsMap.put(new CategoryPath("3"), new CategoryListParams(new Term("$Digits", "Three")));
-    paramsMap.put(new CategoryPath("4"), new CategoryListParams(new Term("$Digits", "Four")));
-    paramsMap.put(new CategoryPath("5"), new CategoryListParams(new Term("$Digits", "Five")));
+    paramsMap.put(new CategoryPath("0"), new CategoryListParams("$Digits$Zero"));
+    paramsMap.put(new CategoryPath("1"), new CategoryListParams("$Digits$One"));
+    paramsMap.put(new CategoryPath("2"), new CategoryListParams("$Digits$Two"));
+    paramsMap.put(new CategoryPath("3"), new CategoryListParams("$Digits$Three"));
+    paramsMap.put(new CategoryPath("4"), new CategoryListParams("$Digits$Four"));
+    paramsMap.put(new CategoryPath("5"), new CategoryListParams("$Digits$Five"));
     MULTI_IPARAMS = new PerDimensionIndexingParams(paramsMap);
   }
   
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/associations/AssociationsFacetFields.java b/lucene/facet/src/java/org/apache/lucene/facet/associations/AssociationsFacetFields.java
index 1ed3985..0e61117 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/associations/AssociationsFacetFields.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/associations/AssociationsFacetFields.java
@@ -114,7 +114,7 @@ public class AssociationsFacetFields extends FacetFields {
   }
   
   @Override
-  protected FieldType fieldType() {
+  protected FieldType drillDownFieldType() {
     return DRILL_DOWN_TYPE;
   }
 
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/associations/AssociationsIterator.java b/lucene/facet/src/java/org/apache/lucene/facet/associations/AssociationsIterator.java
new file mode 100644
index 0000000..7f81461
--- /dev/null
+++ b/lucene/facet/src/java/org/apache/lucene/facet/associations/AssociationsIterator.java
@@ -0,0 +1,98 @@
+package org.apache.lucene.facet.associations;
+
+import java.io.IOException;
+
+import org.apache.lucene.index.AtomicReaderContext;
+import org.apache.lucene.index.DocValues;
+import org.apache.lucene.index.DocValues.Source;
+import org.apache.lucene.store.ByteArrayDataInput;
+import org.apache.lucene.util.BytesRef;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/**
+ * An iterator over a document's category associations.
+ * 
+ * @lucene.experimental
+ */
+public abstract class AssociationsIterator<T extends CategoryAssociation> {
+
+  private final T association;
+  private final String dvField;
+  private final boolean useDirectSource;
+  private final BytesRef bytes = new BytesRef(32);
+  
+  private DocValues.Source current;
+  
+  /**
+   * Construct a new associations iterator. The given
+   * {@link CategoryAssociation} is used to deserialize the association values.
+   * It is assumed that all association values can be deserialized with the
+   * given {@link CategoryAssociation}.
+   * 
+   * <p>
+   * <b>NOTE:</b> if {@code useDirectSource} is {@code false}, then a
+   * {@link DocValues#getSource()} is used, which is an in-memory {@link Source}.
+   */
+  public AssociationsIterator(String field, T association, boolean useDirectSource) throws IOException {
+    this.association = association;
+    this.dvField = field + association.getCategoryListID();
+    this.useDirectSource = useDirectSource;
+  }
+
+  /**
+   * Sets the {@link AtomicReaderContext} for which {@link #setNextDoc(int)}
+   * calls will be made. Returns true iff this reader has associations for any
+   * of the documents belonging to the association given to the constructor.
+   */
+  public final boolean setNextReader(AtomicReaderContext context) throws IOException {
+    DocValues dv = context.reader().docValues(dvField);
+    if (dv == null) {
+      current = null;
+      return false;
+    }
+    
+    current = useDirectSource ? dv.getDirectSource() : dv.getSource();
+    return true;
+  }
+  
+  /**
+   * Skip to the requested document. Returns true iff the document has category
+   * association values and they were read successfully. Associations are
+   * handled through {@link #handleAssociation(int, CategoryAssociation)} by
+   * extending classes.
+   */
+  protected final boolean setNextDoc(int docID) throws IOException {
+    current.getBytes(docID, bytes);
+    if (bytes.length == 0) {
+      return false; // no associations for the requested document
+    }
+
+    ByteArrayDataInput in = new ByteArrayDataInput(bytes.bytes, bytes.offset, bytes.length);
+    while (!in.eof()) {
+      int ordinal = in.readInt();
+      association.deserialize(in);
+      handleAssociation(ordinal, association);
+    }
+    return true;
+  }
+
+  /** A hook for extending classes to handle the given association value for the ordinal. */
+  protected abstract void handleAssociation(int ordinal, T association);
+
+}
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/associations/AssociationsPayloadIterator.java b/lucene/facet/src/java/org/apache/lucene/facet/associations/AssociationsPayloadIterator.java
deleted file mode 100644
index ff26633..0000000
--- a/lucene/facet/src/java/org/apache/lucene/facet/associations/AssociationsPayloadIterator.java
+++ /dev/null
@@ -1,92 +0,0 @@
-package org.apache.lucene.facet.associations;
-
-import java.io.IOException;
-
-import org.apache.lucene.facet.search.PayloadIterator;
-import org.apache.lucene.index.AtomicReaderContext;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.store.ByteArrayDataInput;
-import org.apache.lucene.util.BytesRef;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-/**
- * An iterator over a document's category associations.
- * 
- * @lucene.experimental
- */
-public abstract class AssociationsPayloadIterator<T extends CategoryAssociation> {
-
-  private final PayloadIterator pi;
-  private final T association;
-  
-  /**
-   * Marking whether there are associations (at all) in the given index
-   */
-  private boolean hasAssociations = false;
-
-  /**
-   * Construct a new associations iterator. The given
-   * {@link CategoryAssociation} is used to deserialize the association values.
-   * It is assumed that all association values can be deserialized with the
-   * given {@link CategoryAssociation}.
-   */
-  public AssociationsPayloadIterator(String field, T association) throws IOException {
-    pi = new PayloadIterator(new Term(field, association.getCategoryListID()));
-    this.association = association;
-  }
-
-  /**
-   * Sets the {@link AtomicReaderContext} for which {@link #setNextDoc(int)}
-   * calls will be made. Returns true iff this reader has associations for any
-   * of the documents belonging to the association given to the constructor.
-   */
-  public final boolean setNextReader(AtomicReaderContext context) throws IOException {
-    hasAssociations = pi.setNextReader(context);
-    return hasAssociations;
-  }
-  
-  /**
-   * Skip to the requested document. Returns true iff the document has category
-   * association values and they were read successfully. Associations are
-   * handled through {@link #handleAssociation(int, CategoryAssociation)} by
-   * extending classes.
-   */
-  protected final boolean setNextDoc(int docID) throws IOException {
-    if (!hasAssociations) { // there are no associations at all
-      return false;
-    }
-
-    BytesRef bytes = pi.getPayload(docID);
-    if (bytes == null) { // no associations for the requested document
-      return false;
-    }
-    
-    ByteArrayDataInput in = new ByteArrayDataInput(bytes.bytes, bytes.offset, bytes.length);
-    while (!in.eof()) {
-      int ordinal = in.readInt();
-      association.deserialize(in);
-      handleAssociation(ordinal, association);
-    }
-    return true;
-  }
-
-  /** A hook for extending classes to handle the given association value for the ordinal. */
-  protected abstract void handleAssociation(int ordinal, T association);
-
-}
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/associations/FloatAssociationsIterator.java b/lucene/facet/src/java/org/apache/lucene/facet/associations/FloatAssociationsIterator.java
new file mode 100644
index 0000000..d07b7cf
--- /dev/null
+++ b/lucene/facet/src/java/org/apache/lucene/facet/associations/FloatAssociationsIterator.java
@@ -0,0 +1,69 @@
+package org.apache.lucene.facet.associations;
+
+import java.io.IOException;
+
+import org.apache.lucene.index.DocValues;
+import org.apache.lucene.index.DocValues.Source;
+import org.apache.lucene.util.collections.IntToFloatMap;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/**
+ * An {@link AssociationsIterator} over integer association values.
+ * 
+ * @lucene.experimental
+ */
+public class FloatAssociationsIterator extends AssociationsIterator<CategoryFloatAssociation> {
+
+  private final IntToFloatMap ordinalAssociations = new IntToFloatMap();
+
+  /**
+   * Constructs a new {@link FloatAssociationsIterator} which uses an
+   * in-memory {@link DocValues#getSource() DocValues source}.
+   */
+  public FloatAssociationsIterator(String field, CategoryFloatAssociation association) throws IOException {
+    this(field, association, false);
+  }
+  
+  /**
+   * Constructs a new {@link FloatAssociationsIterator} which uses a
+   * {@link DocValues} {@link Source} per {@code useDirectSource}.
+   */
+  public FloatAssociationsIterator(String field, CategoryFloatAssociation association, boolean useDirectSource) 
+      throws IOException {
+    super(field, association, useDirectSource);
+  }
+
+  @Override
+  protected void handleAssociation(int ordinal, CategoryFloatAssociation association) {
+    ordinalAssociations.put(ordinal, association.getValue());
+  }
+
+  /**
+   * Returns the float association values of the categories that are associated
+   * with the given document, or {@code null} if the document has no
+   * associations.
+   * <p>
+   * <b>NOTE:</b> you are not expected to modify the returned map.
+   */
+  public IntToFloatMap getAssociations(int docID) throws IOException {
+    ordinalAssociations.clear();
+    return setNextDoc(docID) ? ordinalAssociations : null;
+  }
+  
+}
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/associations/FloatAssociationsPayloadIterator.java b/lucene/facet/src/java/org/apache/lucene/facet/associations/FloatAssociationsPayloadIterator.java
deleted file mode 100644
index 4ddb077..0000000
--- a/lucene/facet/src/java/org/apache/lucene/facet/associations/FloatAssociationsPayloadIterator.java
+++ /dev/null
@@ -1,54 +0,0 @@
-package org.apache.lucene.facet.associations;
-
-import java.io.IOException;
-
-import org.apache.lucene.util.collections.IntToFloatMap;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-/**
- * An {@link AssociationsPayloadIterator} over integer association values.
- * 
- * @lucene.experimental
- */
-public class FloatAssociationsPayloadIterator extends AssociationsPayloadIterator<CategoryFloatAssociation> {
-
-  private final IntToFloatMap ordinalAssociations = new IntToFloatMap();
-
-  public FloatAssociationsPayloadIterator(String field, CategoryFloatAssociation association) throws IOException {
-    super(field, association);
-  }
-
-  @Override
-  protected void handleAssociation(int ordinal, CategoryFloatAssociation association) {
-    ordinalAssociations.put(ordinal, association.getValue());
-  }
-
-  /**
-   * Returns the float association values of the categories that are associated
-   * with the given document, or {@code null} if the document has no
-   * associations.
-   * <p>
-   * <b>NOTE:</b> you are not expected to modify the returned map.
-   */
-  public IntToFloatMap getAssociations(int docID) throws IOException {
-    ordinalAssociations.clear();
-    return setNextDoc(docID) ? ordinalAssociations : null;
-  }
-  
-}
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/associations/IntAssociationsIterator.java b/lucene/facet/src/java/org/apache/lucene/facet/associations/IntAssociationsIterator.java
new file mode 100644
index 0000000..65178c0
--- /dev/null
+++ b/lucene/facet/src/java/org/apache/lucene/facet/associations/IntAssociationsIterator.java
@@ -0,0 +1,69 @@
+package org.apache.lucene.facet.associations;
+
+import java.io.IOException;
+
+import org.apache.lucene.index.DocValues;
+import org.apache.lucene.index.DocValues.Source;
+import org.apache.lucene.util.collections.IntToIntMap;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/**
+ * An {@link AssociationsIterator} over integer association values.
+ * 
+ * @lucene.experimental
+ */
+public class IntAssociationsIterator extends AssociationsIterator<CategoryIntAssociation> {
+
+  private final IntToIntMap ordinalAssociations = new IntToIntMap();
+
+  /**
+   * Constructs a new {@link IntAssociationsIterator} which uses an
+   * in-memory {@link DocValues#getSource() DocValues source}.
+   */
+  public IntAssociationsIterator(String field, CategoryIntAssociation association) throws IOException {
+    this(field, association, false);
+  }
+
+  /**
+   * Constructs a new {@link IntAssociationsIterator} which uses a
+   * {@link DocValues} {@link Source} per {@code useDirectSource}.
+   */
+  public IntAssociationsIterator(String field, CategoryIntAssociation association, boolean useDirectSource)
+      throws IOException {
+    super(field, association, useDirectSource);
+  }
+
+  @Override
+  protected void handleAssociation(int ordinal, CategoryIntAssociation association) {
+    ordinalAssociations.put(ordinal, association.getValue());
+  }
+  
+  /**
+   * Returns the integer association values of the categories that are
+   * associated with the given document, or {@code null} if the document has no
+   * associations.
+   * <p>
+   * <b>NOTE:</b> you are not expected to modify the returned map.
+   */
+  public IntToIntMap getAssociations(int docID) throws IOException {
+    ordinalAssociations.clear();
+    return setNextDoc(docID) ? ordinalAssociations : null;
+  }
+
+}
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/associations/IntAssociationsPayloadIterator.java b/lucene/facet/src/java/org/apache/lucene/facet/associations/IntAssociationsPayloadIterator.java
deleted file mode 100644
index c400c6d..0000000
--- a/lucene/facet/src/java/org/apache/lucene/facet/associations/IntAssociationsPayloadIterator.java
+++ /dev/null
@@ -1,54 +0,0 @@
-package org.apache.lucene.facet.associations;
-
-import java.io.IOException;
-
-import org.apache.lucene.util.collections.IntToIntMap;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-/**
- * An {@link AssociationsPayloadIterator} over integer association values.
- * 
- * @lucene.experimental
- */
-public class IntAssociationsPayloadIterator extends AssociationsPayloadIterator<CategoryIntAssociation> {
-
-  private final IntToIntMap ordinalAssociations = new IntToIntMap();
-
-  public IntAssociationsPayloadIterator(String field, CategoryIntAssociation association) throws IOException {
-    super(field, association);
-  }
-
-  @Override
-  protected void handleAssociation(int ordinal, CategoryIntAssociation association) {
-    ordinalAssociations.put(ordinal, association.getValue());
-  }
-  
-  /**
-   * Returns the integer association values of the categories that are
-   * associated with the given document, or {@code null} if the document has no
-   * associations.
-   * <p>
-   * <b>NOTE:</b> you are not expected to modify the returned map.
-   */
-  public IntToIntMap getAssociations(int docID) throws IOException {
-    ordinalAssociations.clear();
-    return setNextDoc(docID) ? ordinalAssociations : null;
-  }
-
-}
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/index/CountingListBuilder.java b/lucene/facet/src/java/org/apache/lucene/facet/index/CountingListBuilder.java
index 29b87b3..9077698 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/index/CountingListBuilder.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/index/CountingListBuilder.java
@@ -56,10 +56,9 @@ public class CountingListBuilder implements CategoryListBuilder {
   private static final class NoPartitionsOrdinalsEncoder extends OrdinalsEncoder {
     
     private final IntEncoder encoder;
-    private final String name;
+    private final String name = "";
     
     NoPartitionsOrdinalsEncoder(CategoryListParams categoryListParams) {
-      name = categoryListParams.getTerm().text();
       encoder = categoryListParams.createEncoder();
     }
     
@@ -91,7 +90,7 @@ public class CountingListBuilder implements CategoryListBuilder {
       final HashMap<String,IntsRef> partitionOrdinals = new HashMap<String,IntsRef>();
       for (int i = 0; i < ordinals.length; i++) {
         int ordinal = ordinals.ints[i];
-        final String name = PartitionsUtils.partitionNameByOrdinal(indexingParams, categoryListParams, ordinal);
+        final String name = PartitionsUtils.partitionNameByOrdinal(indexingParams, ordinal);
         IntsRef partitionOrds = partitionOrdinals.get(name);
         if (partitionOrds == null) {
           partitionOrds = new IntsRef(32);
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/index/FacetFields.java b/lucene/facet/src/java/org/apache/lucene/facet/index/FacetFields.java
index 9fda239..db6c595 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/index/FacetFields.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/index/FacetFields.java
@@ -4,17 +4,14 @@ import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.HashMap;
-import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Map.Entry;
 
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.FieldType;
+import org.apache.lucene.document.StraightBytesDocValuesField;
 import org.apache.lucene.document.TextField;
 import org.apache.lucene.facet.index.params.CategoryListParams;
 import org.apache.lucene.facet.index.params.FacetIndexingParams;
@@ -51,32 +48,6 @@ import org.apache.lucene.util.IntsRef;
  */
 public class FacetFields {
 
-  // a TokenStream for writing the counting list payload
-  private static final class CountingListStream extends TokenStream {
-    private final PayloadAttribute payloadAtt = addAttribute(PayloadAttribute.class);
-    private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
-    private Iterator<Entry<String,BytesRef>> categoriesData;
-    
-    CountingListStream() {}
-    
-    @Override
-    public boolean incrementToken() throws IOException {
-      if (!categoriesData.hasNext()) {
-        return false;
-      }
-      
-      Entry<String,BytesRef> entry = categoriesData.next();
-      termAtt.setEmpty().append(entry.getKey());
-      payloadAtt.setPayload(entry.getValue());
-      return true;
-    }
-    
-    void setCategoriesData(Map<String,BytesRef> categoriesData) {
-      this.categoriesData = categoriesData.entrySet().iterator();
-    }
-    
-  }
-
   // The counting list is written in a payload, but we don't store it
   // nor need norms.
   private static final FieldType COUNTING_LIST_PAYLOAD_TYPE = new FieldType();
@@ -94,9 +65,7 @@ public class FacetFields {
   // Therefore we set its IndexOptions to DOCS_ONLY.
   private static final FieldType DRILL_DOWN_TYPE = new FieldType(TextField.TYPE_NOT_STORED);
   static {
-    // TODO: once we cutover to DocValues, we can set it to DOCS_ONLY for this 
-    // FacetFields (not associations)
-    DRILL_DOWN_TYPE.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);
+    DRILL_DOWN_TYPE.setIndexOptions(IndexOptions.DOCS_ONLY);
     DRILL_DOWN_TYPE.freeze();
   }
   
@@ -175,10 +144,20 @@ public class FacetFields {
    * Returns the {@link FieldType} with which the drill-down terms should be
    * indexed. The default is {@link IndexOptions#DOCS_ONLY}.
    */
-  protected FieldType fieldType() {
+  protected FieldType drillDownFieldType() {
     return DRILL_DOWN_TYPE;
   }
 
+  /**
+   * Add the counting list data to the document under the given field. Note that
+   * the field is determined by the {@link CategoryListParams}.
+   */
+  protected void addCountingListData(Document doc, Map<String,BytesRef> categoriesData, String field) {
+    for (Entry<String,BytesRef> entry : categoriesData.entrySet()) {
+      doc.add(new StraightBytesDocValuesField(field + entry.getKey(), entry.getValue()));
+    }
+  }
+  
   /** Adds the needed facet fields to the document. */
   public void addFields(Document doc, Iterable<CategoryPath> categories) throws IOException {
     if (categories == null) {
@@ -198,7 +177,7 @@ public class FacetFields {
     IntsRef ordinals = new IntsRef(32); // should be enough for most common applications
     for (Entry<CategoryListParams, Iterable<CategoryPath>> e : categoryLists.entrySet()) {
       final CategoryListParams clp = e.getKey();
-      final String field = clp.getTerm().field();
+      final String field = clp.field;
 
       // build category list data
       ordinals.length = 0; // reset
@@ -214,13 +193,11 @@ public class FacetFields {
       Map<String,BytesRef> categoriesData = getCategoryListData(clp, ordinals, e.getValue());
       
       // add the counting list data
-      CountingListStream ts = new CountingListStream();
-      ts.setCategoriesData(categoriesData);
-      doc.add(new Field(field, ts, COUNTING_LIST_PAYLOAD_TYPE));
+      addCountingListData(doc, categoriesData, field);
       
       // add the drill-down field
       DrillDownStream drillDownStream = getDrillDownStream(e.getValue());
-      Field drillDown = new Field(field, drillDownStream, fieldType());
+      Field drillDown = new Field(field, drillDownStream, drillDownFieldType());
       doc.add(drillDown);
     }
   }
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/index/FacetsPayloadMigrationReader.java b/lucene/facet/src/java/org/apache/lucene/facet/index/FacetsPayloadMigrationReader.java
new file mode 100644
index 0000000..c634762
--- /dev/null
+++ b/lucene/facet/src/java/org/apache/lucene/facet/index/FacetsPayloadMigrationReader.java
@@ -0,0 +1,258 @@
+package org.apache.lucene.facet.index;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Map;
+
+import org.apache.lucene.facet.index.params.CategoryListParams;
+import org.apache.lucene.facet.index.params.FacetIndexingParams;
+import org.apache.lucene.index.AtomicReader;
+import org.apache.lucene.index.AtomicReaderContext;
+import org.apache.lucene.index.DirectoryReader;
+import org.apache.lucene.index.DocValues;
+import org.apache.lucene.index.DocValues.Source;
+import org.apache.lucene.index.DocValues.Type;
+import org.apache.lucene.index.DocsAndPositionsEnum;
+import org.apache.lucene.index.FieldInfo;
+import org.apache.lucene.index.FieldInfos;
+import org.apache.lucene.index.Fields;
+import org.apache.lucene.index.FilterAtomicReader;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.index.Terms;
+import org.apache.lucene.index.TermsEnum;
+import org.apache.lucene.search.DocIdSetIterator;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.BytesRef;
+
+/**
+ * A {@link FilterAtomicReader} for migrating a facets index which encodes
+ * category ordinals in a payload to {@link DocValues}. To migrate the index,
+ * you should build a mapping from a field (String) to term ({@link Term}),
+ * which denotes under which DocValues field to put the data encoded in the
+ * matching term's payload. You can follow the code example below to migrate an
+ * existing index:
+ * 
+ * <pre class="prettyprint">
+ * // Add the index and migrate payload to DocValues on the go
+ * DirectoryReader reader = DirectoryReader.open(oldDir);
+ * IndexWriterConfig conf = new IndexWriterConfig(VER, ANALYZER);
+ * IndexWriter writer = new IndexWriter(newDir, conf);
+ * List&lt;AtomicReaderContext&gt; leaves = reader.leaves();
+ * AtomicReader wrappedLeaves[] = new AtomicReader[leaves.size()];
+ * for (int i = 0; i &lt; leaves.size(); i++) {
+ *   wrappedLeaves[i] = new FacetPayloadMigrationReader(leaves.get(i).reader(),
+ *       fieldTerms);
+ * }
+ * writer.addIndexes(new MultiReader(wrappedLeaves));
+ * writer.commit();
+ * </pre>
+ * 
+ * <p>
+ * <b>NOTE:</b> to build the field-to-term map you can use
+ * {@link #buildFieldTermsMap(Directory, FacetIndexingParams)}, as long as the
+ * index to migrate contains the ordinals payload under
+ * {@link #PAYLOAD_TERM_TEXT}.
+ * 
+ * @lucene.experimental
+ */
+public class FacetsPayloadMigrationReader extends FilterAtomicReader {  
+
+  private class PayloadMigratingDocValues extends DocValues {
+
+    private final DocsAndPositionsEnum dpe;
+    
+    public PayloadMigratingDocValues(DocsAndPositionsEnum dpe) {
+      this.dpe = dpe;
+    }
+
+    @Override
+    protected Source loadDirectSource() throws IOException {
+      return new PayloadMigratingSource(getType(), dpe);
+    }
+
+    @Override
+    protected Source loadSource() throws IOException {
+      throw new UnsupportedOperationException("in-memory Source is not supported by this reader");
+    }
+
+    @Override
+    public Type getType() {
+      return Type.BYTES_VAR_STRAIGHT;
+    }
+    
+  }
+  
+  private class PayloadMigratingSource extends Source {
+
+    private final DocsAndPositionsEnum dpe;
+    private int curDocID;
+    
+    protected PayloadMigratingSource(Type type, DocsAndPositionsEnum dpe) {
+      super(type);
+      this.dpe = dpe;
+      if (dpe == null) {
+        curDocID = DocIdSetIterator.NO_MORE_DOCS;
+      } else {
+        try {
+          curDocID = dpe.nextDoc();
+        } catch (IOException e) {
+          throw new RuntimeException(e);
+        }
+      }
+    }
+    
+    @Override
+    public BytesRef getBytes(int docID, BytesRef ref) {
+      if (curDocID > docID) {
+        // document does not exist
+        ref.length = 0;
+        return ref;
+      }
+      
+      try {
+        if (curDocID < docID) {
+          curDocID = dpe.advance(docID);
+          if (curDocID != docID) { // requested document does not have a payload
+            ref.length = 0;
+            return ref;
+          }
+        }
+        
+        // we're on the document
+        dpe.nextPosition();
+        ref.copyBytes(dpe.getPayload());
+        return ref;
+      } catch (IOException e) {
+        throw new RuntimeException(e);
+      }
+    }
+    
+  }
+  
+  /** The {@link Term} text of the ordinals payload. */
+  public static final String PAYLOAD_TERM_TEXT = "$fulltree$";
+
+  /**
+   * A utility method for building the field-to-Term map, given the
+   * {@link FacetIndexingParams} and the directory of the index to migrate. The
+   * map that will be built will correspond to partitions as well as multiple
+   * {@link CategoryListParams}.
+   * <p>
+   * <b>NOTE:</b> since {@link CategoryListParams} no longer define a
+   * {@link Term}, this method assumes that the term used by the different
+   * {@link CategoryListParams} is {@link #PAYLOAD_TERM_TEXT}. If this is not
+   * the case, then you should build the map yourself, using the terms in your
+   * index.
+   */
+  public static Map<String,Term> buildFieldTermsMap(Directory dir, FacetIndexingParams fip) throws IOException {
+    // only add field-Term mapping that will actually have DocValues in the end.
+    // therefore traverse the index terms and add what exists. this pertains to
+    // multiple CLPs, as well as partitions
+    DirectoryReader reader = DirectoryReader.open(dir);
+    final Map<String,Term> fieldTerms = new HashMap<String,Term>();
+    for (AtomicReaderContext context : reader.leaves()) {
+      for (CategoryListParams clp : fip.getAllCategoryListParams()) {
+        Terms terms = context.reader().terms(clp.field);
+        if (terms != null) {
+          TermsEnum te = terms.iterator(null);
+          BytesRef termBytes = null;
+          while ((termBytes = te.next()) != null) {
+            String term = termBytes.utf8ToString();
+            if (term.startsWith(PAYLOAD_TERM_TEXT )) {
+              if (term.equals(PAYLOAD_TERM_TEXT)) {
+                fieldTerms.put(clp.field, new Term(clp.field, term));
+              } else {
+                fieldTerms.put(clp.field + term.substring(PAYLOAD_TERM_TEXT.length()), new Term(clp.field, term));
+              }
+            }
+          }
+        }        
+      }
+    }
+    reader.close();
+    return fieldTerms;
+  }
+  
+  private final Map<String,Term> fieldTerms;
+  
+  /**
+   * Wraps an {@link AtomicReader} and migrates the payload to {@link DocValues}
+   * fields by using the given mapping.
+   */
+  public FacetsPayloadMigrationReader(AtomicReader in, Map<String,Term> fieldTerms) {
+    super(in);
+    this.fieldTerms = fieldTerms;
+  }
+  
+  @Override
+  public DocValues docValues(String field) throws IOException {
+    Term term = fieldTerms.get(field);
+    if (term == null) {
+      return super.docValues(field);
+    } else {
+      DocsAndPositionsEnum dpe = null;
+      Fields fields = fields();
+      if (fields != null) {
+        Terms terms = fields.terms(term.field());
+        if (terms != null) {
+          TermsEnum te = terms.iterator(null); // no use for reusing
+          if (te.seekExact(term.bytes(), true)) {
+            // we're not expected to be called for deleted documents
+            dpe = te.docsAndPositions(null, null, DocsAndPositionsEnum.FLAG_PAYLOADS);
+          }
+        }
+      }
+      // we shouldn't return null, even if the term does not exist or has no
+      // payloads, since we already marked the field as having DocValues.
+      return new PayloadMigratingDocValues(dpe);
+    }
+  }
+
+  @Override
+  public FieldInfos getFieldInfos() {
+    FieldInfos innerInfos = super.getFieldInfos();
+    ArrayList<FieldInfo> infos = new ArrayList<FieldInfo>(innerInfos.size());
+    // if there are partitions, then the source index contains one field for all their terms
+    // while with DocValues, we simulate that by multiple fields.
+    HashSet<String> leftoverFields = new HashSet<String>(fieldTerms.keySet());
+    int number = -1;
+    for (FieldInfo info : innerInfos) {
+      if (fieldTerms.containsKey(info.name)) {
+        // mark this field as having a DocValues
+        infos.add(new FieldInfo(info.name, true, info.number,
+            info.hasVectors(), info.omitsNorms(), info.hasPayloads(),
+            info.getIndexOptions(), Type.BYTES_VAR_STRAIGHT,
+            info.getNormType(), info.attributes()));
+        leftoverFields.remove(info.name);
+      } else {
+        infos.add(info);
+      }
+      number = Math.max(number, info.number);
+    }
+    for (String field : leftoverFields) {
+      infos.add(new FieldInfo(field, false, ++number, false, false, false,
+          null, Type.BYTES_VAR_STRAIGHT, null, null));
+    }
+    return new FieldInfos(infos.toArray(new FieldInfo[infos.size()]));
+  }
+  
+}
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/index/OrdinalMappingAtomicReader.java b/lucene/facet/src/java/org/apache/lucene/facet/index/OrdinalMappingAtomicReader.java
index 522f383..d892ab0 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/index/OrdinalMappingAtomicReader.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/index/OrdinalMappingAtomicReader.java
@@ -25,13 +25,10 @@ import org.apache.lucene.facet.index.params.CategoryListParams;
 import org.apache.lucene.facet.index.params.FacetIndexingParams;
 import org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyWriter.OrdinalMap;
 import org.apache.lucene.index.AtomicReader;
-import org.apache.lucene.index.DocsAndPositionsEnum;
-import org.apache.lucene.index.Fields;
+import org.apache.lucene.index.DocValues;
+import org.apache.lucene.index.DocValues.Source;
+import org.apache.lucene.index.DocValues.Type;
 import org.apache.lucene.index.FilterAtomicReader;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.index.Terms;
-import org.apache.lucene.index.TermsEnum;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IntsRef;
 import org.apache.lucene.util.encoding.IntDecoder;
@@ -41,8 +38,8 @@ import org.apache.lucene.util.encoding.IntEncoder;
  * A {@link FilterAtomicReader} for updating facets ordinal references,
  * based on an ordinal map. You should use this code in conjunction with merging
  * taxonomies - after you merge taxonomies, you receive an {@link OrdinalMap}
- * which maps the 'old' payloads to the 'new' ones. You can use that map to
- * re-map the payloads which contain the facets information (ordinals) either
+ * which maps the 'old' ordinals to the 'new' ones. You can use that map to
+ * re-map the doc values which contain the facets information (ordinals) either
  * before or while merging the indexes.
  * <p>
  * For re-mapping the ordinals during index merge, do the following:
@@ -70,9 +67,8 @@ import org.apache.lucene.util.encoding.IntEncoder;
 public class OrdinalMappingAtomicReader extends FilterAtomicReader {
   
   private final int[] ordinalMap;
-  // a little obtuse: but we dont need to create Term objects this way
-  private final Map<String,Map<BytesRef,CategoryListParams>> termMap = 
-      new HashMap<String,Map<BytesRef,CategoryListParams>>(1);
+  
+  private final Map<String,CategoryListParams> dvFieldMap = new HashMap<String,CategoryListParams>();
   
   /**
    * Wraps an AtomicReader, mapping ordinals according to the ordinalMap.
@@ -91,125 +87,85 @@ public class OrdinalMappingAtomicReader extends FilterAtomicReader {
     super(in);
     this.ordinalMap = ordinalMap;
     for (CategoryListParams params: indexingParams.getAllCategoryListParams()) {
-      Term term = params.getTerm();
-      Map<BytesRef,CategoryListParams> fieldMap = termMap.get(term.field());
-      if (fieldMap == null) {
-        fieldMap = new HashMap<BytesRef,CategoryListParams>(1);
-        termMap.put(term.field(), fieldMap);
-      }
-      fieldMap.put(term.bytes(), params);
+      dvFieldMap.put(params.field, params);
     }
   }
 
   @Override
-  public Fields getTermVectors(int docID) throws IOException {
-    Fields fields = super.getTermVectors(docID);
-    if (fields == null) {
-      return null;
-    } else {
-      return new OrdinalMappingFields(fields);
+  public DocValues docValues(String field) throws IOException {
+    DocValues inner = super.docValues(field);
+    if (inner == null) {
+      return inner;
     }
-  }
-
-  @Override
-  public Fields fields() throws IOException {
-    Fields fields = super.fields();
-    if (fields == null) {
-      return null;
+    
+    CategoryListParams clp = dvFieldMap.get(field);
+    if (clp == null) {
+      return inner;
     } else {
-      return new OrdinalMappingFields(fields);
+      return new OrdinalMappingDocValues(inner, clp);
     }
   }
   
-  private class OrdinalMappingFields extends FilterFields {
+  private class OrdinalMappingDocValues extends DocValues {
 
-    public OrdinalMappingFields(Fields in) {
-      super(in);
+    private final CategoryListParams clp;
+    private final DocValues delegate;
+    
+    public OrdinalMappingDocValues(DocValues delegate, CategoryListParams clp) {
+      this.delegate = delegate;
+      this.clp = clp;
     }
 
     @Override
-    public Terms terms(String field) throws IOException {
-      Terms terms = super.terms(field);
-      if (terms == null) {
-        return terms;
-      }
-      Map<BytesRef,CategoryListParams> termsMap = termMap.get(field);
-      if (termsMap == null) {
-        return terms;
-      } else {
-        return new OrdinalMappingTerms(terms, termsMap);
-      }
-    }
-  }
-  
-  private class OrdinalMappingTerms extends FilterTerms {
-    private final Map<BytesRef,CategoryListParams> termsMap;
-    
-    public OrdinalMappingTerms(Terms in, Map<BytesRef,CategoryListParams> termsMap) {
-      super(in);
-      this.termsMap = termsMap;
+    protected Source loadSource() throws IOException {
+      return new OrdinalMappingSource(getType(), clp, delegate.getSource());
     }
 
     @Override
-    public TermsEnum iterator(TermsEnum reuse) throws IOException {
-      // TODO: should we reuse the inner termsenum?
-      return new OrdinalMappingTermsEnum(super.iterator(reuse), termsMap);
-    }
-  }
-  
-  private class OrdinalMappingTermsEnum extends FilterTermsEnum {
-    private final Map<BytesRef,CategoryListParams> termsMap;
-    
-    public OrdinalMappingTermsEnum(TermsEnum in, Map<BytesRef,CategoryListParams> termsMap) {
-      super(in);
-      this.termsMap = termsMap;
+    protected Source loadDirectSource() throws IOException {
+      return new OrdinalMappingSource(getType(), clp, delegate.getDirectSource());
     }
 
     @Override
-    public DocsAndPositionsEnum docsAndPositions(Bits liveDocs, DocsAndPositionsEnum reuse, int flags) throws IOException {
-      // TODO: we could reuse our D&P enum if we need
-      DocsAndPositionsEnum inner = super.docsAndPositions(liveDocs, reuse, flags);
-      if (inner == null) {
-        return inner;
-      }
-      
-      CategoryListParams params = termsMap.get(term());
-      if (params == null) {
-        return inner;
-      }
-      
-      return new OrdinalMappingDocsAndPositionsEnum(inner, params);
+    public Type getType() {
+      return Type.BYTES_VAR_STRAIGHT;
     }
+    
   }
   
-  private class OrdinalMappingDocsAndPositionsEnum extends FilterDocsAndPositionsEnum {
+  private class OrdinalMappingSource extends Source {
+
     private final IntEncoder encoder;
     private final IntDecoder decoder;
     private final IntsRef ordinals = new IntsRef(32);
-    private final BytesRef payloadOut = new BytesRef();
-
-    public OrdinalMappingDocsAndPositionsEnum(DocsAndPositionsEnum in, CategoryListParams params) {
-      super(in);
-      encoder = params.createEncoder();
+    private final Source delegate;
+    
+    protected OrdinalMappingSource(Type type, CategoryListParams clp, Source delegate) {
+      super(type);
+      this.delegate = delegate;
+      encoder = clp.createEncoder();
       decoder = encoder.createMatchingDecoder();
     }
-
+    
+    @SuppressWarnings("synthetic-access")
     @Override
-    public BytesRef getPayload() throws IOException {
-      BytesRef payload = super.getPayload();
-      if (payload == null) {
-        return payload;
+    public BytesRef getBytes(int docID, BytesRef ref) {
+      ref = delegate.getBytes(docID, ref);
+      if (ref == null || ref.length == 0) {
+        return ref;
       } else {
-        decoder.decode(payload, ordinals);
+        decoder.decode(ref, ordinals);
         
         // map the ordinals
         for (int i = 0; i < ordinals.length; i++) {
           ordinals.ints[i] = ordinalMap[ordinals.ints[i]];
         }
         
-        encoder.encode(ordinals, payloadOut);
-        return payloadOut;
+        encoder.encode(ordinals, ref);
+        return ref;
       }
     }
+    
   }
+  
 }
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/index/params/CategoryListParams.java b/lucene/facet/src/java/org/apache/lucene/facet/index/params/CategoryListParams.java
index 847da00..39a5d12 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/index/params/CategoryListParams.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/index/params/CategoryListParams.java
@@ -4,9 +4,8 @@ import java.io.IOException;
 import java.io.Serializable;
 
 import org.apache.lucene.facet.search.CategoryListIterator;
-import org.apache.lucene.facet.search.PayloadCategoryListIteraor;
+import org.apache.lucene.facet.search.DocValuesCategoryListIterator;
 import org.apache.lucene.facet.util.PartitionsUtils;
-import org.apache.lucene.index.Term;
 import org.apache.lucene.util.encoding.DGapIntEncoder;
 import org.apache.lucene.util.encoding.IntDecoder;
 import org.apache.lucene.util.encoding.IntEncoder;
@@ -38,39 +37,26 @@ import org.apache.lucene.util.encoding.VInt8IntEncoder;
  */
 public class CategoryListParams implements Serializable {
 
-  /** The default term used to store the facets information. */
-  public static final Term DEFAULT_TERM = new Term("$facets", "$fulltree$");
+  /** The default field used to store the facets information. */
+  public static final String DEFAULT_FIELD = "$facets";
 
-  private final Term term;
+  public final String field;
 
   private final int hashCode;
 
-  /**
-   * Constructs a default category list parameters object, using
-   * {@link #DEFAULT_TERM}.
-   */
+  /** Constructs a default category list parameters object, using {@link #DEFAULT_FIELD}. */
   public CategoryListParams() {
-    this(DEFAULT_TERM);
+    this(DEFAULT_FIELD);
   }
 
-  /**
-   * Constructs a category list parameters object, using the given {@link Term}.
-   * @param term who's payload hold the category-list.
-   */
-  public CategoryListParams(Term term) {
-    this.term = term;
+  /** Constructs a category list parameters object, using the given field. */
+  public CategoryListParams(String field) {
+    this.field = field;
     // Pre-compute the hashCode because these objects are immutable.  Saves
     // some time on the comparisons later.
-    this.hashCode = term.hashCode();
+    this.hashCode = field.hashCode();
   }
   
-  /** 
-   * A {@link Term} who's payload holds the category-list. 
-   */
-  public final Term getTerm() {
-    return term;
-  }
-
   /**
    * Allows to override how categories are encoded and decoded. A matching
    * {@link IntDecoder} is provided by the {@link IntEncoder}.
@@ -110,7 +96,7 @@ public class CategoryListParams implements Serializable {
     // The above hashcodes might equal each other in the case of a collision,
     // so at this point only directly term equality testing will settle
     // the equality test.
-    return this.term.equals(other.term);
+    return field.equals(other.field);
   }
 
   @Override
@@ -120,9 +106,9 @@ public class CategoryListParams implements Serializable {
 
   /** Create the {@link CategoryListIterator} for the specified partition. */
   public CategoryListIterator createCategoryListIterator(int partition) throws IOException {
-    String categoryListTermStr = PartitionsUtils.partitionName(this, partition);
-    Term payloadTerm = new Term(term.field(), categoryListTermStr);
-    return new PayloadCategoryListIteraor(payloadTerm, createEncoder().createMatchingDecoder());
+    String categoryListTermStr = PartitionsUtils.partitionName(partition);
+    String docValuesField = field + categoryListTermStr;
+    return new DocValuesCategoryListIterator(docValuesField, createEncoder().createMatchingDecoder());
   }
   
 }
\ No newline at end of file
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/search/DocValuesCategoryListIterator.java b/lucene/facet/src/java/org/apache/lucene/facet/search/DocValuesCategoryListIterator.java
new file mode 100644
index 0000000..bdef15c
--- /dev/null
+++ b/lucene/facet/src/java/org/apache/lucene/facet/search/DocValuesCategoryListIterator.java
@@ -0,0 +1,105 @@
+package org.apache.lucene.facet.search;
+
+import java.io.IOException;
+
+import org.apache.lucene.index.AtomicReaderContext;
+import org.apache.lucene.index.DocValues;
+import org.apache.lucene.index.DocValues.Source;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.IntsRef;
+import org.apache.lucene.util.encoding.IntDecoder;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/** A {@link CategoryListIterator} which reads the ordinals from a {@link DocValues}. */
+public class DocValuesCategoryListIterator implements CategoryListIterator {
+  
+  private final IntDecoder decoder;
+  private final String field;
+  private final int hashCode;
+  private final boolean useDirectSource;
+  private final BytesRef bytes = new BytesRef(32);
+  
+  private DocValues.Source current;
+  
+  /**
+   * Constructs a new {@link DocValuesCategoryListIterator} which uses an
+   * in-memory {@link Source}.
+   */
+  public DocValuesCategoryListIterator(String field, IntDecoder decoder) {
+    this(field, decoder, false);
+  }
+  
+  /**
+   * Constructs a new {@link DocValuesCategoryListIterator} which uses either a
+   * {@link DocValues#getDirectSource() direct source} or
+   * {@link DocValues#getSource() in-memory} one.
+   */
+  public DocValuesCategoryListIterator(String field, IntDecoder decoder, boolean useDirectSource) {
+    this.field = field;
+    this.decoder = decoder;
+    this.hashCode = field.hashCode();
+    this.useDirectSource = useDirectSource;
+  }
+  
+  @Override
+  public int hashCode() {
+    return hashCode;
+  }
+  
+  @Override
+  public boolean equals(Object o) {
+    if (!(o instanceof DocValuesCategoryListIterator)) {
+      return false;
+    }
+    DocValuesCategoryListIterator other = (DocValuesCategoryListIterator) o;
+    if (hashCode != other.hashCode) {
+      return false;
+    }
+    
+    // Hash codes are the same, check equals() to avoid cases of hash-collisions.
+    return field.equals(other.field);
+  }
+  
+  @Override
+  public boolean setNextReader(AtomicReaderContext context) throws IOException {
+    DocValues dv = context.reader().docValues(field);
+    if (dv == null) {
+      current = null;
+      return false;
+    }
+    
+    current = useDirectSource ? dv.getDirectSource() : dv.getSource();
+    return true;
+  }
+  
+  @Override
+  public void getOrdinals(int docID, IntsRef ints) throws IOException {
+    current.getBytes(docID, bytes);
+    ints.length = 0;
+    if (bytes.length > 0) {
+      decoder.decode(bytes, ints);
+    }
+  }
+  
+  @Override
+  public String toString() {
+    return field;
+  }
+  
+}
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/search/DrillDown.java b/lucene/facet/src/java/org/apache/lucene/facet/search/DrillDown.java
index b6cdf73..38dc02a 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/search/DrillDown.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/search/DrillDown.java
@@ -55,7 +55,7 @@ public final class DrillDown {
     CategoryListParams clp = iParams.getCategoryListParams(path);
     char[] buffer = new char[path.fullPathLength()];
     iParams.drillDownTermText(path, buffer);
-    return new Term(clp.getTerm().field(), String.valueOf(buffer));
+    return new Term(clp.field, String.valueOf(buffer));
   }
   
   /**
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/search/PayloadCategoryListIteraor.java b/lucene/facet/src/java/org/apache/lucene/facet/search/PayloadCategoryListIteraor.java
deleted file mode 100644
index b8639c3..0000000
--- a/lucene/facet/src/java/org/apache/lucene/facet/search/PayloadCategoryListIteraor.java
+++ /dev/null
@@ -1,81 +0,0 @@
-package org.apache.lucene.facet.search;
-
-import java.io.IOException;
-
-import org.apache.lucene.index.AtomicReaderContext;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.IntsRef;
-import org.apache.lucene.util.encoding.IntDecoder;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-/**
- * A {@link CategoryListIterator} which reads the category ordinals from a
- * payload.
- * 
- * @lucene.experimental
- */
-public class PayloadCategoryListIteraor implements CategoryListIterator {
-
-  private final IntDecoder decoder;
-  private final Term term;
-  private final PayloadIterator pi;
-  private final int hashCode;
-  
-  public PayloadCategoryListIteraor(Term term, IntDecoder decoder) throws IOException {
-    pi = new PayloadIterator(term);
-    this.decoder = decoder;
-    hashCode = term.hashCode();
-    this.term = term;
-  }
-
-  @Override
-  public boolean equals(Object other) {
-    if (!(other instanceof PayloadCategoryListIteraor)) {
-      return false;
-    }
-    PayloadCategoryListIteraor that = (PayloadCategoryListIteraor) other;
-    if (hashCode != that.hashCode) {
-      return false;
-    }
-    
-    // Hash codes are the same, check equals() to avoid cases of hash-collisions.
-    return term.equals(that.term);
-  }
-
-  @Override
-  public int hashCode() {
-    return hashCode;
-  }
-
-  @Override
-  public boolean setNextReader(AtomicReaderContext context) throws IOException {
-    return pi.setNextReader(context);
-  }
-  
-  @Override
-  public void getOrdinals(int docID, IntsRef ints) throws IOException {
-    ints.length = 0;
-    BytesRef payload = pi.getPayload(docID);
-    if (payload != null) {
-      decoder.decode(payload, ints);
-    }
-  }
-
-}
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/search/PayloadIterator.java b/lucene/facet/src/java/org/apache/lucene/facet/search/PayloadIterator.java
deleted file mode 100644
index 7d956ac..0000000
--- a/lucene/facet/src/java/org/apache/lucene/facet/search/PayloadIterator.java
+++ /dev/null
@@ -1,114 +0,0 @@
-package org.apache.lucene.facet.search;
-
-import java.io.IOException;
-
-import org.apache.lucene.index.AtomicReaderContext;
-import org.apache.lucene.index.DocsAndPositionsEnum;
-import org.apache.lucene.index.Fields;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.index.Terms;
-import org.apache.lucene.index.TermsEnum;
-import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.util.BytesRef;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-/**
- * A utility class for iterating through a posting list of a given term and
- * retrieving the payload of the first position in every document. For
- * efficiency, this class does not check if documents passed to
- * {@link #getPayload(int)} are deleted, since it is usually used to iterate on
- * payloads of documents that matched a query. If you need to skip over deleted
- * documents, you should do so before calling {@link #getPayload(int)}.
- * 
- * @lucene.experimental
- */
-public class PayloadIterator {
-
-  private TermsEnum reuseTE;
-  private DocsAndPositionsEnum dpe;
-  private boolean hasMore;
-  private int curDocID;
-  
-  private final Term term;
-
-  public PayloadIterator(Term term) throws IOException {
-    this.term = term;
-  }
-
-  /**
-   * Sets the {@link AtomicReaderContext} for which {@link #getPayload(int)}
-   * calls will be made. Returns true iff this reader has payload for any of the
-   * documents belonging to the {@link Term} given to the constructor.
-   */
-  public boolean setNextReader(AtomicReaderContext context) throws IOException {
-    hasMore = false;
-    Fields fields = context.reader().fields();
-    if (fields != null) {
-      Terms terms = fields.terms(term.field());
-      if (terms != null) {
-        reuseTE = terms.iterator(reuseTE);
-        if (reuseTE.seekExact(term.bytes(), true)) {
-          // this class is usually used to iterate on whatever a Query matched
-          // if it didn't match deleted documents, we won't receive them. if it
-          // did, we should iterate on them too, therefore we pass liveDocs=null
-          dpe = reuseTE.docsAndPositions(null, dpe, DocsAndPositionsEnum.FLAG_PAYLOADS);
-          if (dpe != null && (curDocID = dpe.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
-            hasMore = true;
-          }
-        }
-      }
-    }
-    return hasMore;
-  }
-  
-  /**
-   * Returns the {@link BytesRef payload} of the given document, or {@code null}
-   * if the document does not exist, there are no more documents in the posting
-   * list, or the document exists but has not payload. The given document IDs
-   * are treated as local to the reader given to
-   * {@link #setNextReader(AtomicReaderContext)}.
-   */
-  public BytesRef getPayload(int docID) throws IOException {
-    if (!hasMore) {
-      return null;
-    }
-
-    if (curDocID > docID) {
-      // document does not exist
-      return null;
-    }
-    
-    if (curDocID < docID) {
-      curDocID = dpe.advance(docID);
-      if (curDocID != docID) { // requested document does not have a payload
-        if (curDocID == DocIdSetIterator.NO_MORE_DOCS) { // no more docs in this reader
-          hasMore = false;
-        }
-        return null;
-      }
-    }
-
-    // we're on the document
-    assert dpe.freq() == 1 : "expecting freq=1 (got " + dpe.freq() + ") term=" + term + " doc=" + curDocID;
-    int pos = dpe.nextPosition();
-    assert pos != -1 : "no positions for term=" + term + " doc=" + curDocID;
-    return dpe.getPayload();
-  }
-  
-}
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/search/StandardFacetsAccumulator.java b/lucene/facet/src/java/org/apache/lucene/facet/search/StandardFacetsAccumulator.java
index 7373e4d..15e195f 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/search/StandardFacetsAccumulator.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/search/StandardFacetsAccumulator.java
@@ -10,6 +10,7 @@ import java.util.Map.Entry;
 import java.util.logging.Level;
 import java.util.logging.Logger;
 
+import org.apache.lucene.facet.index.params.FacetIndexingParams;
 import org.apache.lucene.facet.search.aggregator.Aggregator;
 import org.apache.lucene.facet.search.params.FacetRequest;
 import org.apache.lucene.facet.search.params.FacetSearchParams;
@@ -110,9 +111,8 @@ public class StandardFacetsAccumulator extends FacetsAccumulator {
 
       if (isUsingComplements) {
         try {
-          totalFacetCounts = TotalFacetCountsCache.getSingleton()
-            .getTotalCounts(indexReader, taxonomyReader,
-                searchParams.getFacetIndexingParams(), searchParams.getCategoryListCache());
+          totalFacetCounts = TotalFacetCountsCache.getSingleton().getTotalCounts(indexReader, taxonomyReader, 
+              searchParams.getFacetIndexingParams());
           if (totalFacetCounts != null) {
             docids = ScoredDocIdsUtils.getComplementSet(docids, indexReader);
           } else {
@@ -242,20 +242,29 @@ public class StandardFacetsAccumulator extends FacetsAccumulator {
       int maxDoc = -1;
       while (iterator.next()) {
         int docID = iterator.getDocID();
-        while (docID >= maxDoc) { // find the segment which contains this document
-          if (!contexts.hasNext()) {
-            throw new RuntimeException("ScoredDocIDs contains documents outside this reader's segments !?");
-          }
-          current = contexts.next();
-          maxDoc = current.docBase + current.reader().maxDoc();
-          if (docID < maxDoc) { // segment has docs, check if it has categories
-            boolean validSegment = categoryListIter.setNextReader(current);
-            validSegment &= aggregator.setNextReader(current);
-            if (!validSegment) { // if categoryList or aggregtor say it's an invalid segment, skip all docs
-              while (docID < maxDoc && iterator.next()) {
-                docID = iterator.getDocID();
+        if (docID >= maxDoc) {
+          boolean iteratorDone = false;
+          do { // find the segment which contains this document
+            if (!contexts.hasNext()) {
+              throw new RuntimeException("ScoredDocIDs contains documents outside this reader's segments !?");
+            }
+            current = contexts.next();
+            maxDoc = current.docBase + current.reader().maxDoc();
+            if (docID < maxDoc) { // segment has docs, check if it has categories
+              boolean validSegment = categoryListIter.setNextReader(current);
+              validSegment &= aggregator.setNextReader(current);
+              if (!validSegment) { // if categoryList or aggregtor say it's an invalid segment, skip all docs
+                while (docID < maxDoc && iterator.next()) {
+                  docID = iterator.getDocID();
+                }
+                if (docID < maxDoc) {
+                  iteratorDone = true;
+                }
               }
             }
+          } while (docID >= maxDoc);
+          if (iteratorDone) { // iterator finished, terminate the loop
+            break;
           }
         }
         docID -= current.docBase;
@@ -312,19 +321,17 @@ public class StandardFacetsAccumulator extends FacetsAccumulator {
     
     HashMap<CategoryListIterator, Aggregator> categoryLists = new HashMap<CategoryListIterator, Aggregator>();
 
+    FacetIndexingParams indexingParams = searchParams.getFacetIndexingParams();
     for (FacetRequest facetRequest : searchParams.getFacetRequests()) {
-      Aggregator categoryAggregator = facetRequest.createAggregator(
-          isUsingComplements, facetArrays, taxonomyReader);
+      Aggregator categoryAggregator = facetRequest.createAggregator(isUsingComplements, facetArrays, taxonomyReader);
 
-      CategoryListIterator cli = facetRequest.createCategoryListIterator(taxonomyReader, searchParams, partition);
+      CategoryListIterator cli = indexingParams.getCategoryListParams(facetRequest.categoryPath).createCategoryListIterator(partition);
       
       // get the aggregator
       Aggregator old = categoryLists.put(cli, categoryAggregator);
 
       if (old != null && !old.equals(categoryAggregator)) {
-        // TODO (Facet): create a more meaningful RE class, and throw it.
-        throw new RuntimeException(
-        "Overriding existing category list with different aggregator. THAT'S A NO NO!");
+        throw new RuntimeException("Overriding existing category list with different aggregator");
       }
       // if the aggregator is the same we're covered
     }
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler.java b/lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler.java
index 20feeb0..b868951 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler.java
@@ -55,7 +55,7 @@ public class TopKFacetResultsHandler extends FacetResultsHandler {
   public IntermediateFacetResult fetchPartitionResult(FacetArrays facetArrays, int offset)
   throws IOException {
     TopKFacetResult res = null;
-    int ordinal = taxonomyReader.getOrdinal(facetRequest.getCategoryPath());
+    int ordinal = taxonomyReader.getOrdinal(facetRequest.categoryPath);
     if (ordinal != TaxonomyReader.INVALID_ORDINAL) {
       double value = 0;  
       if (isSelfPartition(ordinal, facetArrays, offset)) {
@@ -79,7 +79,7 @@ public class TopKFacetResultsHandler extends FacetResultsHandler {
   @Override
   public IntermediateFacetResult mergeResults(IntermediateFacetResult... tmpResults) throws IOException {
     
-    int ordinal = taxonomyReader.getOrdinal(facetRequest.getCategoryPath());
+    int ordinal = taxonomyReader.getOrdinal(facetRequest.categoryPath);
     MutableFacetResultNode resNode = new MutableFacetResultNode(ordinal, 0);
     
     int totalFacets = 0;
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/search/TopKInEachNodeHandler.java b/lucene/facet/src/java/org/apache/lucene/facet/search/TopKInEachNodeHandler.java
index dff7fee..7aee99d 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/search/TopKInEachNodeHandler.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/search/TopKInEachNodeHandler.java
@@ -34,35 +34,37 @@ import org.apache.lucene.util.collections.IntToObjectMap;
  */
 
 /**
- * Generates {@link FacetResult} from the count arrays aggregated for a particular 
- * {@link FacetRequest}.
- * The generated {@link FacetResult} is a subtree of the taxonomy tree.
- * Its root node, {@link FacetResult#getFacetResultNode()}, 
- * is the facet specified by {@link FacetRequest#getCategoryPath()},
- * and the enumerated children, {@link FacetResultNode#getSubResults()}, of each node in that 
- * {@link FacetResult} are the top K ( = {@link FacetRequest#getNumResults()}) among its children
- * in the taxonomy.
- * Top in the sense {@link FacetRequest#getSortBy()},
- * which can be by the values aggregated in the count arrays, or by ordinal numbers;
- * also specified is the sort order, {@link FacetRequest#getSortOrder()}, 
- * ascending or descending, of these values or ordinals before their top K are selected. 
- * The depth (number of levels excluding the root) of the 
- * {@link FacetResult} tree is specified by {@link FacetRequest#getDepth()}.  
+ * Generates {@link FacetResult} from the count arrays aggregated for a
+ * particular {@link FacetRequest}. The generated {@link FacetResult} is a
+ * subtree of the taxonomy tree. Its root node,
+ * {@link FacetResult#getFacetResultNode()}, is the facet specified by
+ * {@link FacetRequest#categoryPath}, and the enumerated children,
+ * {@link FacetResultNode#getSubResults()}, of each node in that
+ * {@link FacetResult} are the top K ( = {@link FacetRequest#getNumResults()})
+ * among its children in the taxonomy. Top in the sense
+ * {@link FacetRequest#getSortBy()}, which can be by the values aggregated in
+ * the count arrays, or by ordinal numbers; also specified is the sort order,
+ * {@link FacetRequest#getSortOrder()}, ascending or descending, of these values
+ * or ordinals before their top K are selected. The depth (number of levels
+ * excluding the root) of the {@link FacetResult} tree is specified by
+ * {@link FacetRequest#getDepth()}.
  * <p>
- * Because the number of selected children of each node is restricted,
- * and not the overall number of nodes in the {@link FacetResult}, facets not selected 
+ * Because the number of selected children of each node is restricted, and not
+ * the overall number of nodes in the {@link FacetResult}, facets not selected
  * into {@link FacetResult} might have better values, or ordinals, (typically,
  * higher counts), than facets that are selected into the {@link FacetResult}.
  * <p>
- * The generated {@link FacetResult} also provides with 
- * {@link FacetResult#getNumValidDescendants()}, which returns the total number of facets 
- * that are descendants of the root node, no deeper than {@link FacetRequest#getDepth()}, and
- * which have valid value. The rootnode itself is not counted here. 
- * Valid value is determined by the {@link FacetResultsHandler}. 
- * {@link TopKInEachNodeHandler} defines valid as != 0. 
+ * The generated {@link FacetResult} also provides with
+ * {@link FacetResult#getNumValidDescendants()}, which returns the total number
+ * of facets that are descendants of the root node, no deeper than
+ * {@link FacetRequest#getDepth()}, and which have valid value. The rootnode
+ * itself is not counted here. Valid value is determined by the
+ * {@link FacetResultsHandler}. {@link TopKInEachNodeHandler} defines valid as
+ * != 0.
  * <p>
- * <b>NOTE:</b> this code relies on the assumption that {@link TaxonomyReader#INVALID_ORDINAL} == -1, a smaller
- * value than any valid ordinal.
+ * <b>NOTE:</b> this code relies on the assumption that
+ * {@link TaxonomyReader#INVALID_ORDINAL} == -1, a smaller value than any valid
+ * ordinal.
  * 
  * @lucene.experimental
  */
@@ -109,7 +111,7 @@ public class TopKInEachNodeHandler extends FacetResultsHandler {
 
     // get the root of the result tree to be returned, and the depth of that result tree
     // (depth means number of node levels excluding the root). 
-    int rootNode = this.taxonomyReader.getOrdinal(this.facetRequest.getCategoryPath());
+    int rootNode = this.taxonomyReader.getOrdinal(facetRequest.categoryPath);
     if (rootNode == TaxonomyReader.INVALID_ORDINAL) {
       return null;
     }
@@ -767,7 +769,7 @@ public class TopKInEachNodeHandler extends FacetResultsHandler {
   @Override
   public FacetResult renderFacetResult(IntermediateFacetResult tmpResult) throws IOException {
     IntermediateFacetResultWithHash tmp = (IntermediateFacetResultWithHash) tmpResult;
-    int ordinal = this.taxonomyReader.getOrdinal(this.facetRequest.getCategoryPath());
+    int ordinal = this.taxonomyReader.getOrdinal(this.facetRequest.categoryPath);
     if ((tmp == null) || (ordinal == TaxonomyReader.INVALID_ORDINAL)) {
       return null;
     }
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/search/TotalFacetCounts.java b/lucene/facet/src/java/org/apache/lucene/facet/search/TotalFacetCounts.java
index 84c3b2f..1ab291d 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/search/TotalFacetCounts.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/search/TotalFacetCounts.java
@@ -17,8 +17,6 @@ import org.apache.lucene.facet.index.params.CategoryListParams;
 import org.apache.lucene.facet.index.params.FacetIndexingParams;
 import org.apache.lucene.facet.search.aggregator.Aggregator;
 import org.apache.lucene.facet.search.aggregator.CountingAggregator;
-import org.apache.lucene.facet.search.cache.CategoryListCache;
-import org.apache.lucene.facet.search.cache.CategoryListData;
 import org.apache.lucene.facet.search.params.CountFacetRequest;
 import org.apache.lucene.facet.search.params.FacetRequest;
 import org.apache.lucene.facet.search.params.FacetSearchParams;
@@ -155,9 +153,8 @@ public class TotalFacetCounts {
   private static final List<FacetRequest> DUMMY_REQ = Arrays.asList(
       new FacetRequest[] { new CountFacetRequest(CategoryPath.EMPTY, 1) });
 
-  static TotalFacetCounts compute(final IndexReader indexReader,
-      final TaxonomyReader taxonomy, final FacetIndexingParams facetIndexingParams,
-      final CategoryListCache clCache) throws IOException {
+  static TotalFacetCounts compute(final IndexReader indexReader, final TaxonomyReader taxonomy, 
+      final FacetIndexingParams facetIndexingParams) throws IOException {
     int partitionSize = PartitionsUtils.partitionSize(facetIndexingParams, taxonomy);
     final int[][] counts = new int[(int) Math.ceil(taxonomy.getSize()  /(float) partitionSize)][partitionSize];
     FacetSearchParams newSearchParams = new FacetSearchParams(DUMMY_REQ, facetIndexingParams); 
@@ -170,8 +167,7 @@ public class TotalFacetCounts {
         Aggregator aggregator = new CountingAggregator(counts[partition]);
         HashMap<CategoryListIterator, Aggregator> map = new HashMap<CategoryListIterator, Aggregator>();
         for (CategoryListParams clp: facetIndexingParams.getAllCategoryListParams()) {
-          final CategoryListIterator cli = clIteraor(clCache, clp, partition);
-          map.put(cli, aggregator);
+          map.put(clp.createCategoryListIterator(partition), aggregator);
         }
         return map;
       }
@@ -181,14 +177,4 @@ public class TotalFacetCounts {
     return new TotalFacetCounts(taxonomy, facetIndexingParams, counts, CreationType.Computed);
   }
   
-  static CategoryListIterator clIteraor(CategoryListCache clCache, CategoryListParams clp, int partition) 
-      throws IOException {
-    if (clCache != null) {
-      CategoryListData cld = clCache.get(clp);
-      if (cld != null) {
-        return cld.iterator(partition);
-      }
-    }
-    return clp.createCategoryListIterator(partition);
-  }
 }
\ No newline at end of file
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/search/TotalFacetCountsCache.java b/lucene/facet/src/java/org/apache/lucene/facet/search/TotalFacetCountsCache.java
index edb4b50..95ba960 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/search/TotalFacetCountsCache.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/search/TotalFacetCountsCache.java
@@ -7,12 +7,10 @@ import java.util.LinkedHashMap;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.ConcurrentLinkedQueue;
 
-import org.apache.lucene.index.IndexReader;
-
 import org.apache.lucene.facet.index.params.CategoryListParams;
 import org.apache.lucene.facet.index.params.FacetIndexingParams;
-import org.apache.lucene.facet.search.cache.CategoryListCache;
 import org.apache.lucene.facet.taxonomy.TaxonomyReader;
+import org.apache.lucene.index.IndexReader;
 
 /*
  * Licensed to the Apache Software Foundation (ASF) under one or more
@@ -80,16 +78,20 @@ public final class TotalFacetCountsCache {
   }
   
   /**
-   * Get the total facet counts for a reader/taxonomy pair and facet indexing parameters.
-   * If not in cache, computed here and added to the cache for later use.
-   * @param indexReader the documents index
-   * @param taxonomy the taxonomy index
-   * @param facetIndexingParams facet indexing parameters
-   * @param clCache category list cache for faster computation, can be null 
+   * Get the total facet counts for a reader/taxonomy pair and facet indexing
+   * parameters. If not in cache, computed here and added to the cache for later
+   * use.
+   * 
+   * @param indexReader
+   *          the documents index
+   * @param taxonomy
+   *          the taxonomy index
+   * @param facetIndexingParams
+   *          facet indexing parameters
    * @return the total facet counts.
    */
   public TotalFacetCounts getTotalCounts(IndexReader indexReader, TaxonomyReader taxonomy,
-      FacetIndexingParams facetIndexingParams, CategoryListCache clCache) throws IOException {
+      FacetIndexingParams facetIndexingParams) throws IOException {
     // create the key
     TFCKey key = new TFCKey(indexReader, taxonomy, facetIndexingParams);
     // it is important that this call is not synchronized, so that available TFC 
@@ -99,7 +101,7 @@ public final class TotalFacetCountsCache {
       markRecentlyUsed(key); 
       return tfc;
     }
-    return computeAndCache(key, clCache);
+    return computeAndCache(key);
   }
 
   /**
@@ -149,10 +151,10 @@ public final class TotalFacetCountsCache {
    * matter this method is synchronized, which is not too bad, because there is
    * lots of work done in the computations.
    */
-  private synchronized TotalFacetCounts computeAndCache(TFCKey key, CategoryListCache clCache) throws IOException {
+  private synchronized TotalFacetCounts computeAndCache(TFCKey key) throws IOException {
     TotalFacetCounts tfc = cache.get(key); 
     if (tfc == null) {
-      tfc = TotalFacetCounts.compute(key.indexReader, key.taxonomy, key.facetIndexingParams, clCache);
+      tfc = TotalFacetCounts.compute(key.indexReader, key.taxonomy, key.facetIndexingParams);
       lruKeys.add(key);
       cache.put(key,tfc);
       trimCache();
@@ -161,16 +163,22 @@ public final class TotalFacetCountsCache {
   }
 
   /**
-   * Load {@link TotalFacetCounts} matching input parameters from the provided outputFile 
-   * and add them into the cache for the provided indexReader, taxonomy, and facetIndexingParams.
-   * If a {@link TotalFacetCounts} for these parameters already exists in the cache, it will be
-   * replaced by the loaded one.
-   * @param inputFile file from which to read the data 
-   * @param indexReader the documents index
-   * @param taxonomy the taxonomy index
-   * @param facetIndexingParams the facet indexing parameters
-   * @throws IOException on error
-   * @see #store(File, IndexReader, TaxonomyReader, FacetIndexingParams, CategoryListCache)
+   * Load {@link TotalFacetCounts} matching input parameters from the provided
+   * outputFile and add them into the cache for the provided indexReader,
+   * taxonomy, and facetIndexingParams. If a {@link TotalFacetCounts} for these
+   * parameters already exists in the cache, it will be replaced by the loaded
+   * one.
+   * 
+   * @param inputFile
+   *          file from which to read the data
+   * @param indexReader
+   *          the documents index
+   * @param taxonomy
+   *          the taxonomy index
+   * @param facetIndexingParams
+   *          the facet indexing parameters
+   * @throws IOException
+   *           on error
    */
   public synchronized void load(File inputFile, IndexReader indexReader, TaxonomyReader taxonomy,
       FacetIndexingParams facetIndexingParams) throws IOException {
@@ -185,21 +193,27 @@ public final class TotalFacetCountsCache {
   }
   
   /**
-   * Store the {@link TotalFacetCounts} matching input parameters into the provided outputFile,
-   * making them available for a later call to {@link #load(File, IndexReader, TaxonomyReader, FacetIndexingParams)}.
-   * If these {@link TotalFacetCounts} are available in the cache, they are used. But if they are
-   * not in the cache, this call will first compute them (which will also add them to the cache). 
-   * @param outputFile file to store in.
-   * @param indexReader the documents index
-   * @param taxonomy the taxonomy index
-   * @param facetIndexingParams the facet indexing parameters
-   * @param clCache category list cache for faster computation, can be null
-   * @throws IOException on error
+   * Store the {@link TotalFacetCounts} matching input parameters into the
+   * provided outputFile, making them available for a later call to
+   * {@link #load(File, IndexReader, TaxonomyReader, FacetIndexingParams)}. If
+   * these {@link TotalFacetCounts} are available in the cache, they are used.
+   * But if they are not in the cache, this call will first compute them (which
+   * will also add them to the cache).
+   * 
+   * @param outputFile
+   *          file to store in.
+   * @param indexReader
+   *          the documents index
+   * @param taxonomy
+   *          the taxonomy index
+   * @param facetIndexingParams
+   *          the facet indexing parameters
+   * @throws IOException
+   *           on error
    * @see #load(File, IndexReader, TaxonomyReader, FacetIndexingParams)
-   * @see #getTotalCounts(IndexReader, TaxonomyReader, FacetIndexingParams, CategoryListCache)
    */
   public void store(File outputFile, IndexReader indexReader, TaxonomyReader taxonomy,
-      FacetIndexingParams facetIndexingParams, CategoryListCache clCache) throws IOException {
+      FacetIndexingParams facetIndexingParams) throws IOException {
     File parentFile = outputFile.getParentFile();
     if (
         ( outputFile.exists() && (!outputFile.isFile()      || !outputFile.canWrite())) ||
@@ -207,7 +221,7 @@ public final class TotalFacetCountsCache {
       ) {
       throw new IllegalArgumentException("Exepecting a writable file: "+outputFile);
     }
-    TotalFacetCounts tfc = getTotalCounts(indexReader, taxonomy, facetIndexingParams, clCache);
+    TotalFacetCounts tfc = getTotalCounts(indexReader, taxonomy, facetIndexingParams);
     TotalFacetCounts.storeToFile(outputFile, tfc);  
   }
   
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/search/aggregator/associations/AssociationFloatSumAggregator.java b/lucene/facet/src/java/org/apache/lucene/facet/search/aggregator/associations/AssociationFloatSumAggregator.java
index 5aa38af..d35428f 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/search/aggregator/associations/AssociationFloatSumAggregator.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/search/aggregator/associations/AssociationFloatSumAggregator.java
@@ -3,7 +3,7 @@ package org.apache.lucene.facet.search.aggregator.associations;
 import java.io.IOException;
 
 import org.apache.lucene.facet.associations.CategoryFloatAssociation;
-import org.apache.lucene.facet.associations.FloatAssociationsPayloadIterator;
+import org.apache.lucene.facet.associations.FloatAssociationsIterator;
 import org.apache.lucene.facet.index.params.CategoryListParams;
 import org.apache.lucene.facet.search.aggregator.Aggregator;
 import org.apache.lucene.index.AtomicReaderContext;
@@ -37,15 +37,15 @@ public class AssociationFloatSumAggregator implements Aggregator {
 
   protected final String field;
   protected final float[] sumArray;
-  protected final FloatAssociationsPayloadIterator associations;
+  protected final FloatAssociationsIterator associations;
 
   public AssociationFloatSumAggregator(float[] sumArray) throws IOException {
-    this(CategoryListParams.DEFAULT_TERM.field(), sumArray);
+    this(CategoryListParams.DEFAULT_FIELD, sumArray);
   }
   
   public AssociationFloatSumAggregator(String field, float[] sumArray) throws IOException {
     this.field = field;
-    associations = new FloatAssociationsPayloadIterator(field, new CategoryFloatAssociation());
+    associations = new FloatAssociationsIterator(field, new CategoryFloatAssociation());
     this.sumArray = sumArray;
   }
 
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/search/aggregator/associations/AssociationIntSumAggregator.java b/lucene/facet/src/java/org/apache/lucene/facet/search/aggregator/associations/AssociationIntSumAggregator.java
index 52baf36..ec20dc3 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/search/aggregator/associations/AssociationIntSumAggregator.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/search/aggregator/associations/AssociationIntSumAggregator.java
@@ -3,7 +3,7 @@ package org.apache.lucene.facet.search.aggregator.associations;
 import java.io.IOException;
 
 import org.apache.lucene.facet.associations.CategoryIntAssociation;
-import org.apache.lucene.facet.associations.IntAssociationsPayloadIterator;
+import org.apache.lucene.facet.associations.IntAssociationsIterator;
 import org.apache.lucene.facet.index.params.CategoryListParams;
 import org.apache.lucene.facet.search.aggregator.Aggregator;
 import org.apache.lucene.index.AtomicReaderContext;
@@ -37,15 +37,15 @@ public class AssociationIntSumAggregator implements Aggregator {
 
   protected final String field;
   protected final int[] sumArray;
-  protected final IntAssociationsPayloadIterator associations;
+  protected final IntAssociationsIterator associations;
 
   public AssociationIntSumAggregator(int[] sumArray) throws IOException {
-    this(CategoryListParams.DEFAULT_TERM.field(), sumArray);
+    this(CategoryListParams.DEFAULT_FIELD, sumArray);
   }
   
   public AssociationIntSumAggregator(String field, int[] sumArray) throws IOException {
     this.field = field;
-    associations = new IntAssociationsPayloadIterator(field, new CategoryIntAssociation());
+    associations = new IntAssociationsIterator(field, new CategoryIntAssociation());
     this.sumArray = sumArray;
   }
 
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/search/cache/CategoryListCache.java b/lucene/facet/src/java/org/apache/lucene/facet/search/cache/CategoryListCache.java
deleted file mode 100644
index d87356f..0000000
--- a/lucene/facet/src/java/org/apache/lucene/facet/search/cache/CategoryListCache.java
+++ /dev/null
@@ -1,61 +0,0 @@
-package org.apache.lucene.facet.search.cache;
-
-import java.io.IOException;
-import java.util.HashMap;
-
-import org.apache.lucene.index.IndexReader;
-
-import org.apache.lucene.facet.index.params.CategoryListParams;
-import org.apache.lucene.facet.index.params.FacetIndexingParams;
-import org.apache.lucene.facet.taxonomy.TaxonomyReader;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-/**
- * Cache for {@link CategoryListData}, per {@link CategoryListParams}. 
- * 
- * @lucene.experimental
- */
-public class CategoryListCache {
-
-  private HashMap<CategoryListParams, CategoryListData> 
-    cldMap = new HashMap<CategoryListParams,CategoryListData>();
-
-  /**
-   * Fetch the cached {@link CategoryListData} for a given {@link CategoryListParams}.
-   */
-  public CategoryListData get(CategoryListParams clp) {
-    return cldMap.get(clp);
-  }
-  
-  /**
-   * Register a pre-computed {@link CategoryListData}.
-   */
-  public void register(CategoryListParams clp, CategoryListData clData) {
-    cldMap.put(clp,clData);
-  }
-  
-  /**
-   * Load and register {@link CategoryListData}.
-   */
-  public void loadAndRegister(CategoryListParams clp, 
-      IndexReader reader, TaxonomyReader taxo, FacetIndexingParams iparams) throws IOException {
-    CategoryListData clData = new CategoryListData(reader, taxo, iparams, clp);
-    register(clp,clData);
-  }
-}
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/search/cache/CategoryListData.java b/lucene/facet/src/java/org/apache/lucene/facet/search/cache/CategoryListData.java
deleted file mode 100644
index db4769c..0000000
--- a/lucene/facet/src/java/org/apache/lucene/facet/search/cache/CategoryListData.java
+++ /dev/null
@@ -1,133 +0,0 @@
-package org.apache.lucene.facet.search.cache;
-
-import java.io.IOException;
-
-import org.apache.lucene.facet.index.params.CategoryListParams;
-import org.apache.lucene.facet.index.params.FacetIndexingParams;
-import org.apache.lucene.facet.search.CategoryListIterator;
-import org.apache.lucene.facet.taxonomy.TaxonomyReader;
-import org.apache.lucene.index.AtomicReaderContext;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.util.IntsRef;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-/**
- * Category list data maintained in RAM.
- * <p>
- * Speeds up facets accumulation when more RAM is available.
- * <p>
- * Note that this will consume more memory: one int (4 bytes) for each category
- * of each document.
- * <p>
- * Note: at the moment this class is insensitive to updates of the index, and,
- * in particular, does not make use of Lucene's ability to refresh a single
- * segment.
- * <p>
- * See {@link CategoryListCache#register(CategoryListParams, CategoryListData)}
- * and
- * {@link CategoryListCache#loadAndRegister(CategoryListParams, IndexReader, TaxonomyReader, FacetIndexingParams)}.
- * 
- * @lucene.experimental
- */
-public class CategoryListData {
-  
-  // TODO (Facet): experiment with different orders - p-d-c vs. current d-p-c.
-  private transient volatile int[][][] docPartitionCategories;  
-  
-  /**
-   * Empty constructor for extensions with modified computation of the data.
-   */
-  protected CategoryListData() {
-  }
-  
-  /** Compute category list data for caching for faster iteration. */
-  CategoryListData(IndexReader reader, TaxonomyReader taxo, FacetIndexingParams iparams, CategoryListParams clp) 
-      throws IOException {
-  
-    int[][][]dpf  = new int[reader.maxDoc()][][];
-    int numPartitions = (int)Math.ceil(taxo.getSize()/(double)iparams.getPartitionSize());
-    IntsRef ordinals = new IntsRef(32);
-    for (int part = 0; part < numPartitions; part++) {
-      for (AtomicReaderContext context : reader.leaves()) {
-        CategoryListIterator cli = clp.createCategoryListIterator(part);
-        if (cli.setNextReader(context)) {
-          final int maxDoc = context.reader().maxDoc();
-          for (int i = 0; i < maxDoc; i++) {
-            cli.getOrdinals(i, ordinals);
-            if (ordinals.length > 0) {
-              int doc = i + context.docBase;
-              if (dpf[doc] == null) {
-                dpf[doc] = new int[numPartitions][];
-              }
-              if (dpf[doc][part] == null) {
-                dpf[doc][part] = new int[ordinals.length];
-              }
-              for (int j = 0; j < ordinals.length; j++) {
-                dpf[doc][part][j] = ordinals.ints[j];
-              }
-            }
-          }
-        }
-      }
-    }
-    docPartitionCategories = dpf;
-  }
-  
-  /**
-   * Iterate on the category list data for the specified partition.
-   */
-  public CategoryListIterator iterator(int partition) throws IOException {
-    return new RAMCategoryListIterator(partition, docPartitionCategories);
-  }
-
-  /** Internal: category list iterator over uncompressed category info in RAM */
-  private static class RAMCategoryListIterator implements CategoryListIterator {
-    
-    private int docBase;
-    private final int part;
-    private final int[][][] dpc;
-    
-    RAMCategoryListIterator(int part, int[][][] docPartitionCategories) {
-      this.part = part;
-      dpc = docPartitionCategories;
-    }
-
-    @Override
-    public boolean setNextReader(AtomicReaderContext context) throws IOException {
-      docBase = context.docBase;
-      return dpc != null && dpc.length > part;
-    }
-    
-    @Override
-    public void getOrdinals(int docID, IntsRef ints) throws IOException {
-      ints.length = 0;
-      docID += docBase;
-      if (dpc.length > docID && dpc[docID] != null && dpc[docID][part] != null) {
-        if (ints.ints.length < dpc[docID][part].length) {
-          ints.grow(dpc[docID][part].length);
-        }
-        ints.length = 0;
-        for (int i = 0; i < dpc[docID][part].length; i++) {
-          ints.ints[ints.length++] = dpc[docID][part][i];
-        }
-      }
-    }
-  }
-  
-}
\ No newline at end of file
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/search/cache/package.html b/lucene/facet/src/java/org/apache/lucene/facet/search/cache/package.html
deleted file mode 100644
index 1fc371e..0000000
--- a/lucene/facet/src/java/org/apache/lucene/facet/search/cache/package.html
+++ /dev/null
@@ -1,22 +0,0 @@
-<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-<html><head></head>
-<body>
-Caching to speed up facets accumulation.
-</body>
-</html>
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/search/params/FacetRequest.java b/lucene/facet/src/java/org/apache/lucene/facet/search/params/FacetRequest.java
index 851f3a3..8387253 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/search/params/FacetRequest.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/search/params/FacetRequest.java
@@ -2,15 +2,11 @@ package org.apache.lucene.facet.search.params;
 
 import java.io.IOException;
 
-import org.apache.lucene.facet.index.params.CategoryListParams;
-import org.apache.lucene.facet.search.CategoryListIterator;
 import org.apache.lucene.facet.search.FacetArrays;
 import org.apache.lucene.facet.search.FacetResultsHandler;
 import org.apache.lucene.facet.search.TopKFacetResultsHandler;
 import org.apache.lucene.facet.search.TopKInEachNodeHandler;
 import org.apache.lucene.facet.search.aggregator.Aggregator;
-import org.apache.lucene.facet.search.cache.CategoryListCache;
-import org.apache.lucene.facet.search.cache.CategoryListData;
 import org.apache.lucene.facet.taxonomy.CategoryPath;
 import org.apache.lucene.facet.taxonomy.TaxonomyReader;
 
@@ -64,7 +60,7 @@ public abstract class FacetRequest implements Cloneable {
    */
   public static final ResultMode DEFAULT_RESULT_MODE = ResultMode.PER_NODE_IN_TREE;
 
-  private final CategoryPath categoryPath;
+  public final CategoryPath categoryPath;
   private final int numResults;
   private int numLabel;
   private int depth;
@@ -134,17 +130,6 @@ public abstract class FacetRequest implements Cloneable {
   }
 
   /**
-   * The root category of this facet request. The categories that are returned
-   * as a result of this request will all be descendants of this root.
-   * <p>
-   * <b>NOTE:</b> you should not modify the returned {@link CategoryPath}, or
-   * otherwise some methonds may not work properly, e.g. {@link #hashCode()}.
-   */
-  public final CategoryPath getCategoryPath() {
-    return categoryPath;
-  }
-
-  /**
    * How deeply to look under the given category. If the depth is 0,
    * only the category itself is counted. If the depth is 1, its immediate
    * children are also counted, and so on. If the depth is Integer.MAX_VALUE,
@@ -160,24 +145,22 @@ public abstract class FacetRequest implements Cloneable {
    * will have their category paths calculated, and the rest will only be
    * available as ordinals (category numbers) and will have null paths.
    * <P>
-   * If Integer.MAX_VALUE is specified, all 
-   * results are labled.
+   * If Integer.MAX_VALUE is specified, all results are labled.
    * <P>
-   * The purpose of this parameter is to avoid having to run the whole
-   * faceted search again when the user asks for more values for the facet;
-   * The application can ask (getNumResults()) for more values than it needs
-   * to show, but keep getNumLabel() only the number it wants to immediately
-   * show. The slow-down caused by finding more values is negligible, because
-   * the slowest part - finding the categories' paths, is avoided.
+   * The purpose of this parameter is to avoid having to run the whole faceted
+   * search again when the user asks for more values for the facet; The
+   * application can ask (getNumResults()) for more values than it needs to
+   * show, but keep getNumLabel() only the number it wants to immediately show.
+   * The slow-down caused by finding more values is negligible, because the
+   * slowest part - finding the categories' paths, is avoided.
    * <p>
-   * Depending on the {@link #getResultMode() LimitsMode},
-   * this limit is applied globally or per results node.
-   * In the global mode, if this limit is 3, 
-   * only 3 top results would be labeled.
-   * In the per-node mode, if this limit is 3,
-   * 3 top children of {@link #getCategoryPath() the target category} would be labeled,
-   * as well as 3 top children of each of them, and so forth, until the depth defined 
-   * by {@link #getDepth()}.
+   * Depending on the {@link #getResultMode() LimitsMode}, this limit is applied
+   * globally or per results node. In the global mode, if this limit is 3, only
+   * 3 top results would be labeled. In the per-node mode, if this limit is 3, 3
+   * top children of {@link #categoryPath the target category} would be labeled,
+   * as well as 3 top children of each of them, and so forth, until the depth
+   * defined by {@link #getDepth()}.
+   * 
    * @see #getResultMode()
    */
   public final int getNumLabel() {
@@ -185,20 +168,18 @@ public abstract class FacetRequest implements Cloneable {
   }
 
   /**
-   * The number of sub-categories to return (at most).
-   * If the sub-categories are returned.
+   * The number of sub-categories to return (at most). If the sub-categories are
+   * returned.
    * <p>
-   * If Integer.MAX_VALUE is specified, all 
-   * sub-categories are returned.
+   * If Integer.MAX_VALUE is specified, all sub-categories are returned.
    * <p>
-   * Depending on the {@link #getResultMode() LimitsMode},
-   * this limit is applied globally or per results node.
-   * In the global mode, if this limit is 3, 
-   * only 3 top results would be computed.
-   * In the per-node mode, if this limit is 3,
-   * 3 top children of {@link #getCategoryPath() the target category} would be returned,
-   * as well as 3 top children of each of them, and so forth, until the depth defined 
-   * by {@link #getDepth()}.
+   * Depending on the {@link #getResultMode() LimitsMode}, this limit is applied
+   * globally or per results node. In the global mode, if this limit is 3, only
+   * 3 top results would be computed. In the per-node mode, if this limit is 3,
+   * 3 top children of {@link #categoryPath the target category} would be
+   * returned, as well as 3 top children of each of them, and so forth, until
+   * the depth defined by {@link #getDepth()}.
+   * 
    * @see #getResultMode()
    */
   public final int getNumResults() {
@@ -320,24 +301,6 @@ public abstract class FacetRequest implements Cloneable {
       throws IOException;
 
   /**
-   * Create the category list iterator for the specified partition. If a non
-   * null cache is provided which contains the required data, use it for the
-   * iteration.
-   */
-  public CategoryListIterator createCategoryListIterator(TaxonomyReader taxo, FacetSearchParams sParams, int partition)
-      throws IOException {
-    CategoryListCache clCache = sParams.getCategoryListCache();
-    CategoryListParams clParams = sParams.getFacetIndexingParams().getCategoryListParams(categoryPath);
-    if (clCache != null) {
-      CategoryListData clData = clCache.get(clParams);
-      if (clData != null) {
-        return clData.iterator(partition);
-      }
-    }
-    return clParams.createCategoryListIterator(partition);
-  }
-
-  /**
    * Return the value of a category used for facets computations for this
    * request. For a count request this would be the count for that facet, i.e.
    * an integer number. but for other requests this can be the result of a more
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/search/params/FacetSearchParams.java b/lucene/facet/src/java/org/apache/lucene/facet/search/params/FacetSearchParams.java
index 7866243..711406a 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/search/params/FacetSearchParams.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/search/params/FacetSearchParams.java
@@ -4,7 +4,6 @@ import java.util.Arrays;
 import java.util.List;
 
 import org.apache.lucene.facet.index.params.FacetIndexingParams;
-import org.apache.lucene.facet.search.cache.CategoryListCache;
 
 /*
  * Licensed to the Apache Software Foundation (ASF) under one or more
@@ -72,14 +71,6 @@ public class FacetSearchParams {
   }
 
   /**
-   * Returns the {@link CategoryListCache}. By default returns {@code null}, you
-   * should override if you want to use a cache.
-   */
-  public CategoryListCache getCategoryListCache() {
-    return null;
-  }
-
-  /**
    * Returns the {@link FacetIndexingParams} that were passed to the
    * constructor.
    */
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/search/params/associations/AssociationFloatSumFacetRequest.java b/lucene/facet/src/java/org/apache/lucene/facet/search/params/associations/AssociationFloatSumFacetRequest.java
index 5e5a258..80dedb7 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/search/params/associations/AssociationFloatSumFacetRequest.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/search/params/associations/AssociationFloatSumFacetRequest.java
@@ -28,7 +28,10 @@ import org.apache.lucene.facet.taxonomy.TaxonomyReader;
 
 /**
  * A {@link FacetRequest} for weighting facets according to their float
- * association by summing the association values.
+ * association by summing the association values. Note that this class caches
+ * the associations data in-memory by default. You can override
+ * {@link #createAggregator(boolean, FacetArrays, TaxonomyReader)} to return an
+ * {@link AssociationFloatSumAggregator} which does otherwise.
  * 
  * @lucene.experimental
  */
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/search/params/associations/AssociationIntSumFacetRequest.java b/lucene/facet/src/java/org/apache/lucene/facet/search/params/associations/AssociationIntSumFacetRequest.java
index 0d29111..bbf1b69 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/search/params/associations/AssociationIntSumFacetRequest.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/search/params/associations/AssociationIntSumFacetRequest.java
@@ -4,6 +4,7 @@ import java.io.IOException;
 
 import org.apache.lucene.facet.search.FacetArrays;
 import org.apache.lucene.facet.search.aggregator.Aggregator;
+import org.apache.lucene.facet.search.aggregator.associations.AssociationFloatSumAggregator;
 import org.apache.lucene.facet.search.aggregator.associations.AssociationIntSumAggregator;
 import org.apache.lucene.facet.search.params.FacetRequest;
 import org.apache.lucene.facet.taxonomy.CategoryPath;
@@ -28,7 +29,10 @@ import org.apache.lucene.facet.taxonomy.TaxonomyReader;
 
 /**
  * A {@link FacetRequest} for weighting facets according to their integer
- * association by summing the association values.
+ * association by summing the association values. Note that this class caches
+ * the associations data in-memory by default. You can override
+ * {@link #createAggregator(boolean, FacetArrays, TaxonomyReader)} to return an
+ * {@link AssociationFloatSumAggregator} which does otherwise.
  * 
  * @lucene.experimental
  */
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/search/results/FacetResult.java b/lucene/facet/src/java/org/apache/lucene/facet/search/results/FacetResult.java
index 14078f9..85c053c 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/search/results/FacetResult.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/search/results/FacetResult.java
@@ -39,7 +39,7 @@ public class FacetResult {
   /**
    * Facet result node matching the root of the {@link #getFacetRequest() facet request}.
    * @see #getFacetRequest()
-   * @see FacetRequest#getCategoryPath()
+   * @see FacetRequest#categoryPath
    */
   public final FacetResultNode getFacetResultNode() {
     return this.rootNode;
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/search/sampling/Sampler.java b/lucene/facet/src/java/org/apache/lucene/facet/search/sampling/Sampler.java
index 294e602..17760a0 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/search/sampling/Sampler.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/search/sampling/Sampler.java
@@ -4,9 +4,6 @@ import java.io.IOException;
 import java.util.ArrayList;
 import java.util.List;
 
-import org.apache.lucene.index.IndexReader;
-
-import org.apache.lucene.facet.search.CategoryListIterator;
 import org.apache.lucene.facet.search.FacetArrays;
 import org.apache.lucene.facet.search.ScoredDocIDs;
 import org.apache.lucene.facet.search.aggregator.Aggregator;
@@ -16,6 +13,7 @@ import org.apache.lucene.facet.search.results.FacetResult;
 import org.apache.lucene.facet.search.results.FacetResultNode;
 import org.apache.lucene.facet.search.results.MutableFacetResultNode;
 import org.apache.lucene.facet.taxonomy.TaxonomyReader;
+import org.apache.lucene.index.IndexReader;
 
 /*
  * Licensed to the Apache Software Foundation (ASF) under one or more
@@ -205,7 +203,7 @@ public abstract class Sampler {
   private static class OverSampledFacetRequest extends FacetRequest {
     final FacetRequest orig;
     public OverSampledFacetRequest(FacetRequest orig, int num) {
-      super(orig.getCategoryPath(), num);
+      super(orig.categoryPath, num);
       this.orig = orig;
       setDepth(orig.getDepth());
       setNumLabel(orig.getNumLabel());
@@ -215,12 +213,6 @@ public abstract class Sampler {
     }
     
     @Override
-    public CategoryListIterator createCategoryListIterator(TaxonomyReader taxo, FacetSearchParams sParams, 
-        int partition) throws IOException {
-      return orig.createCategoryListIterator(taxo, sParams, partition);
-    }
-    
-    @Override
     public Aggregator createAggregator(boolean useComplements, FacetArrays arrays, TaxonomyReader taxonomy) 
         throws IOException {
       return orig.createAggregator(useComplements, arrays, taxonomy);
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/util/PartitionsUtils.java b/lucene/facet/src/java/org/apache/lucene/facet/util/PartitionsUtils.java
index 7e583e1..a16a472 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/util/PartitionsUtils.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/util/PartitionsUtils.java
@@ -1,6 +1,5 @@
 package org.apache.lucene.facet.util;
 
-import org.apache.lucene.facet.index.params.CategoryListParams;
 import org.apache.lucene.facet.index.params.FacetIndexingParams;
 import org.apache.lucene.facet.taxonomy.TaxonomyReader;
 
@@ -28,15 +27,9 @@ import org.apache.lucene.facet.taxonomy.TaxonomyReader;
  */
 public final class PartitionsUtils {
 
-  /**
-   * Get the offset for a given partition.  That is, what is the minimum number an
-   * ordinal could be for a particular partition. 
-   */
-  public final static int partitionOffset(FacetIndexingParams iParams,
-      int partitionNumber, final TaxonomyReader taxonomyReader) {
-    return partitionNumber * partitionSize(iParams, taxonomyReader);
-  }
-
+  /** The prefix that is added to the name of the partition. */
+  public static final String PART_NAME_PREFIX = "$part";
+  
   /**
    * Get the partition size in this parameter, or return the size of the taxonomy, which
    * is smaller.  (Guarantees usage of as little memory as possible at search time).
@@ -58,21 +51,21 @@ public final class PartitionsUtils {
   /**
    * Partition name by category ordinal
    */
-  public final static String partitionNameByOrdinal(
-      FacetIndexingParams iParams, CategoryListParams clParams, int ordinal) {
+  public final static String partitionNameByOrdinal(FacetIndexingParams iParams, int ordinal) {
     int partition = partitionNumber(iParams, ordinal);
-    return partitionName(clParams, partition);
+    return partitionName(partition);
   }
 
-  /** 
-   * Partition name by its number
-   */
-  public final static String partitionName(CategoryListParams clParams, int partition) {
-    String term = clParams.getTerm().text();
+  /** Partition name by its number */
+  public final static String partitionName(int partition) {
+    // TODO would be good if this method isn't called when partitions are not enabled.
+    // perhaps through some specialization code.
     if (partition == 0) {
-      return term; // for backwards compatibility we do not add a partition number in this case
+      // since regular faceted search code goes through this method too,
+      // return the same value for partition 0 and when there are no partitions
+      return "";
     }
-    return term + partition;
+    return PART_NAME_PREFIX + Integer.toString(partition);
   }
 
 }
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/FacetTestBase.java b/lucene/facet/src/test/org/apache/lucene/facet/FacetTestBase.java
index 709bb3c..3491835 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/FacetTestBase.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/FacetTestBase.java
@@ -266,13 +266,12 @@ public abstract class FacetTestBase extends LuceneTestCase {
     FacetIndexingParams iParams = getFacetIndexingParams(Integer.MAX_VALUE);
     String delim = String.valueOf(iParams.getFacetDelimChar());
     Map<CategoryPath, Integer> res = new HashMap<CategoryPath, Integer>();
-    HashSet<Term> handledTerms = new HashSet<Term>();
+    HashSet<String> handledTerms = new HashSet<String>();
     for (CategoryListParams clp : iParams.getAllCategoryListParams()) {
-      Term baseTerm = new Term(clp.getTerm().field());
-      if (!handledTerms.add(baseTerm)) {
+      if (!handledTerms.add(clp.field)) {
         continue; // already handled this term (for another list) 
       }
-      Terms terms = MultiFields.getTerms(indexReader, baseTerm.field());
+      Terms terms = MultiFields.getTerms(indexReader, clp.field);
       if (terms == null) {
         continue;
       }
@@ -297,7 +296,7 @@ public abstract class FacetTestBase extends LuceneTestCase {
       FacetResultNode topResNode = fr.getFacetResultNode();
       FacetRequest freq = fr.getFacetRequest();
       if (VERBOSE) {
-        System.out.println(freq.getCategoryPath().toString()+ "\t\t" + topResNode);
+        System.out.println(freq.categoryPath.toString()+ "\t\t" + topResNode);
       }
       assertCountsAndCardinality(facetCountsTruth, topResNode, freq.getNumResults());
     }
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/FacetTestUtils.java b/lucene/facet/src/test/org/apache/lucene/facet/FacetTestUtils.java
index d2ac98a..708e744 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/FacetTestUtils.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/FacetTestUtils.java
@@ -2,14 +2,9 @@ package org.apache.lucene.facet;
 
 import java.io.IOException;
 import java.util.ArrayList;
-import java.util.Collections;
 import java.util.List;
 
 import org.apache.lucene.analysis.standard.StandardAnalyzer;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.document.TextField;
-import org.apache.lucene.facet.index.FacetFields;
 import org.apache.lucene.facet.index.params.FacetIndexingParams;
 import org.apache.lucene.facet.search.FacetsCollector;
 import org.apache.lucene.facet.search.params.CountFacetRequest;
@@ -23,7 +18,6 @@ import org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyWriter;
 import org.apache.lucene.index.DirectoryReader;
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.IndexWriterConfig;
-import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.search.Collector;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.MatchAllDocsQuery;
@@ -116,15 +110,6 @@ public class FacetTestUtils {
     return collectors;
   }
   
-  public static void add(FacetIndexingParams iParams, RandomIndexWriter iw,
-      TaxonomyWriter tw, String... strings) throws IOException {
-    Document d = new Document();
-    FacetFields facetFields = new FacetFields(tw, iParams);
-    facetFields.addFields(d, Collections.singletonList(new CategoryPath(strings)));
-    d.add(new TextField("content", "alpha", Field.Store.YES));
-    iw.addDocument(d);
-  }
-
   public static class IndexTaxonomyReaderPair {
     public DirectoryReader indexReader;
     public DirectoryTaxonomyReader taxReader;
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/index/TestFacetsPayloadMigrationReader.java b/lucene/facet/src/test/org/apache/lucene/facet/index/TestFacetsPayloadMigrationReader.java
new file mode 100644
index 0000000..c7ed773
--- /dev/null
+++ b/lucene/facet/src/test/org/apache/lucene/facet/index/TestFacetsPayloadMigrationReader.java
@@ -0,0 +1,398 @@
+package org.apache.lucene.facet.index;
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+import java.util.Map.Entry;
+import java.util.Random;
+
+import org.apache.lucene.analysis.MockAnalyzer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.document.Field.Store;
+import org.apache.lucene.document.FieldType;
+import org.apache.lucene.document.StringField;
+import org.apache.lucene.document.TextField;
+import org.apache.lucene.facet.index.params.CategoryListParams;
+import org.apache.lucene.facet.index.params.FacetIndexingParams;
+import org.apache.lucene.facet.index.params.PerDimensionIndexingParams;
+import org.apache.lucene.facet.search.CategoryListIterator;
+import org.apache.lucene.facet.search.DrillDown;
+import org.apache.lucene.facet.search.FacetsCollector;
+import org.apache.lucene.facet.search.params.CountFacetRequest;
+import org.apache.lucene.facet.search.params.FacetRequest;
+import org.apache.lucene.facet.search.params.FacetSearchParams;
+import org.apache.lucene.facet.search.results.FacetResult;
+import org.apache.lucene.facet.search.results.FacetResultNode;
+import org.apache.lucene.facet.taxonomy.CategoryPath;
+import org.apache.lucene.facet.taxonomy.TaxonomyReader;
+import org.apache.lucene.facet.taxonomy.TaxonomyWriter;
+import org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyReader;
+import org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyWriter;
+import org.apache.lucene.facet.util.PartitionsUtils;
+import org.apache.lucene.index.AtomicReader;
+import org.apache.lucene.index.AtomicReaderContext;
+import org.apache.lucene.index.DirectoryReader;
+import org.apache.lucene.index.FieldInfo;
+import org.apache.lucene.index.FieldInfo.IndexOptions;
+import org.apache.lucene.index.FieldInfos;
+import org.apache.lucene.index.IndexWriter;
+import org.apache.lucene.index.IndexWriterConfig;
+import org.apache.lucene.index.MultiReader;
+import org.apache.lucene.index.NoMergePolicy;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.index.Terms;
+import org.apache.lucene.index.TermsEnum;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.MatchAllDocsQuery;
+import org.apache.lucene.search.MultiCollector;
+import org.apache.lucene.search.PrefixQuery;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.TotalHitCountCollector;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.IntsRef;
+import org.apache.lucene.util.LuceneTestCase;
+import org.junit.Test;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/** Tests facets index migration from payload to DocValues.*/
+public class TestFacetsPayloadMigrationReader extends LuceneTestCase {
+  
+  private static class PayloadFacetFields extends FacetFields {
+
+    private static final class CountingListStream extends TokenStream {
+      private final PayloadAttribute payloadAtt = addAttribute(PayloadAttribute.class);
+      private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
+      private final Iterator<Entry<String,BytesRef>> categoriesData;
+      
+      CountingListStream(Map<String,BytesRef> categoriesData) {
+        this.categoriesData = categoriesData.entrySet().iterator();
+      }
+      
+      @Override
+      public boolean incrementToken() throws IOException {
+        if (!categoriesData.hasNext()) {
+          return false;
+        }
+        
+        Entry<String,BytesRef> entry = categoriesData.next();
+        termAtt.setEmpty().append(FacetsPayloadMigrationReader.PAYLOAD_TERM_TEXT + entry.getKey());
+        payloadAtt.setPayload(entry.getValue());
+        return true;
+      }
+      
+    }
+
+    private static final FieldType COUNTING_LIST_PAYLOAD_TYPE = new FieldType();
+    static {
+      COUNTING_LIST_PAYLOAD_TYPE.setIndexed(true);
+      COUNTING_LIST_PAYLOAD_TYPE.setTokenized(true);
+      COUNTING_LIST_PAYLOAD_TYPE.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);
+      COUNTING_LIST_PAYLOAD_TYPE.setStored(false);
+      COUNTING_LIST_PAYLOAD_TYPE.setOmitNorms(true);
+      COUNTING_LIST_PAYLOAD_TYPE.freeze();
+    }
+    
+    public PayloadFacetFields(TaxonomyWriter taxonomyWriter, FacetIndexingParams params) {
+      super(taxonomyWriter, params);
+    }
+
+    @Override
+    protected FieldType drillDownFieldType() {
+      // Since the payload is indexed in the same field as the drill-down terms,
+      // we must set IndexOptions to DOCS_AND_FREQS_AND_POSITIONS
+      final FieldType type = new FieldType(TextField.TYPE_NOT_STORED);
+      type.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);
+      type.freeze();
+      return type;
+    }
+
+    @Override
+    protected void addCountingListData(Document doc, Map<String,BytesRef> categoriesData, String field) {
+      CountingListStream ts = new CountingListStream(categoriesData);
+      doc.add(new Field(field, ts, COUNTING_LIST_PAYLOAD_TYPE));
+    }
+  }
+
+  private static final String[] DIMENSIONS = new String[] { "dim1", "dim2", "dim3.1", "dim3.2" };
+  
+  private HashMap<String,Integer> createIndex(Directory indexDir, Directory taxoDir, FacetIndexingParams fip) 
+      throws Exception {
+    Random random = random();
+    IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));
+    conf.setMaxBufferedDocs(2); // force few segments
+    conf.setMergePolicy(NoMergePolicy.COMPOUND_FILES); // avoid merges so that we're left with few segments
+    IndexWriter indexWriter = new IndexWriter(indexDir, conf);
+    TaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir);
+    
+    FacetFields facetFields = new PayloadFacetFields(taxoWriter, fip);
+    
+    HashMap<String,Integer> expectedCounts = new HashMap<String,Integer>(DIMENSIONS.length);
+    int numDocs = atLeast(10);
+    for (int i = 0; i < numDocs; i++) {
+      Document doc = new Document();
+      int numCategories = random.nextInt(3) + 1;
+      ArrayList<CategoryPath> categories = new ArrayList<CategoryPath>(numCategories);
+      HashSet<String> docDimensions = new HashSet<String>();
+      while (numCategories-- > 0) {
+        String dim = DIMENSIONS[random.nextInt(DIMENSIONS.length)];
+        // we should only increment the expected count by 1 per document
+        docDimensions.add(dim);
+        categories.add(new CategoryPath(dim, Integer.toString(i), Integer.toString(numCategories)));
+      }
+      facetFields.addFields(doc, categories);
+      doc.add(new StringField("docid", Integer.toString(i), Store.YES));
+      doc.add(new TextField("foo", "content" + i, Store.YES));
+      indexWriter.addDocument(doc);
+
+      // update expected count per dimension
+      for (String dim : docDimensions) {
+        Integer val = expectedCounts.get(dim);
+        if (val == null) {
+          expectedCounts.put(dim, Integer.valueOf(1));
+        } else {
+          expectedCounts.put(dim, Integer.valueOf(val.intValue() + 1));
+        }
+      }
+      
+      if (random.nextDouble() < 0.2) { // add some documents that will be deleted
+        doc = new Document();
+        doc.add(new StringField("del", "key", Store.NO));
+        facetFields.addFields(doc, Collections.singletonList(new CategoryPath("dummy")));
+        indexWriter.addDocument(doc);
+      }
+    }
+    
+    indexWriter.commit();
+    taxoWriter.commit();
+
+    // delete the docs that were marked for deletion. note that the 'dummy'
+    // category is not removed from the taxonomy, so must account for it when we
+    // verify the migrated index.
+    indexWriter.deleteDocuments(new Term("del", "key"));
+    indexWriter.commit();
+    
+    IOUtils.close(indexWriter, taxoWriter);
+    
+    return expectedCounts;
+  }
+  
+  private void migrateIndex(Directory indexDir, FacetIndexingParams fip) throws Exception {
+    final Map<String,Term> fieldTerms = FacetsPayloadMigrationReader.buildFieldTermsMap(indexDir, fip);
+    DirectoryReader reader = DirectoryReader.open(indexDir);
+    List<AtomicReaderContext> leaves = reader.leaves();
+    int numReaders = leaves.size();
+    AtomicReader wrappedLeaves[] = new AtomicReader[numReaders];
+    for (int i = 0; i < numReaders; i++) {
+      wrappedLeaves[i] = new FacetsPayloadMigrationReader(leaves.get(i).reader(), fieldTerms);
+    }
+    
+    IndexWriter writer = new IndexWriter(indexDir, newIndexWriterConfig(TEST_VERSION_CURRENT, null));
+    writer.deleteAll();
+    try {
+      writer.addIndexes(new MultiReader(wrappedLeaves));
+      writer.commit();
+    } finally {
+      reader.close();
+      writer.close();
+    }
+  }
+  
+  private void verifyMigratedIndex(Directory indexDir, Directory taxoDir, HashMap<String,Integer> expectedCounts, 
+      FacetIndexingParams fip) throws Exception {
+    DirectoryReader indexReader = DirectoryReader.open(indexDir);
+    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoDir);
+    IndexSearcher searcher = new IndexSearcher(indexReader);
+
+    assertFalse("index should not have deletions", indexReader.hasDeletions());
+    
+    verifyNotFacetsData(indexReader, searcher);
+    verifyFacetedSearch(expectedCounts, fip, indexReader, taxoReader, searcher);
+    verifyDrillDown(expectedCounts, fip, indexReader, taxoReader, searcher);
+    verifyIndexOrdinals(indexReader, taxoReader, fip);
+    
+    IOUtils.close(indexReader, taxoReader);
+  }
+  
+  private void verifyNotFacetsData(DirectoryReader indexReader, IndexSearcher searcher) throws IOException {
+    // verify that non facets data was not damaged
+    TotalHitCountCollector total = new TotalHitCountCollector();
+    searcher.search(new PrefixQuery(new Term("foo", "content")), total);
+    assertEquals("invalid number of results for content query", total.getTotalHits(), indexReader.maxDoc());
+    
+    int numDocIDs = 0;
+    for (AtomicReaderContext context : indexReader.leaves()) {
+      Terms docIDs = context.reader().terms("docid");
+      assertNotNull(docIDs);
+      TermsEnum te = docIDs.iterator(null);
+      while (te.next() != null) {
+        ++numDocIDs;
+      }
+    }
+    assertEquals("invalid number of docid terms", indexReader.maxDoc(), numDocIDs);
+  }
+  
+  private void verifyFacetedSearch(Map<String,Integer> expectedCounts, FacetIndexingParams fip, 
+      DirectoryReader indexReader, TaxonomyReader taxoReader, IndexSearcher searcher) throws IOException {
+    // run faceted search and assert expected counts
+    ArrayList<FacetRequest> requests = new ArrayList<FacetRequest>(expectedCounts.size());
+    for (String dim : expectedCounts.keySet()) {
+      requests.add(new CountFacetRequest(new CategoryPath(dim), 5));
+    }
+    FacetSearchParams fsp = new FacetSearchParams(requests, fip);
+    FacetsCollector fc = new FacetsCollector(fsp, indexReader, taxoReader);
+    MatchAllDocsQuery base = new MatchAllDocsQuery();
+    searcher.search(base, fc);
+    List<FacetResult> facetResults = fc.getFacetResults();
+    assertEquals(requests.size(), facetResults.size());
+    for (FacetResult res : facetResults) {
+      FacetResultNode node = res.getFacetResultNode();
+      String dim = node.getLabel().components[0];
+      assertEquals("wrong count for " + dim, expectedCounts.get(dim).intValue(), (int) node.getValue());
+    }
+  }
+  
+  private void verifyDrillDown(Map<String,Integer> expectedCounts, FacetIndexingParams fip, DirectoryReader indexReader, 
+      TaxonomyReader taxoReader, IndexSearcher searcher) throws IOException {
+    // verify drill-down
+    for (String dim : expectedCounts.keySet()) {
+      CategoryPath drillDownCP = new CategoryPath(dim);
+      ArrayList<FacetRequest> request = new ArrayList<FacetRequest>(1);
+      request.add(new CountFacetRequest(drillDownCP, 10));
+      FacetSearchParams fsp = new FacetSearchParams(request, fip);
+      Query drillDown = DrillDown.query(fsp, new MatchAllDocsQuery(), drillDownCP);
+      TotalHitCountCollector total = new TotalHitCountCollector();
+      FacetsCollector fc = new FacetsCollector(fsp, indexReader, taxoReader);
+      searcher.search(drillDown, MultiCollector.wrap(fc, total));
+      assertTrue("no results for drill-down query " + drillDown, total.getTotalHits() > 0);
+      List<FacetResult> facetResults = fc.getFacetResults();
+      assertEquals(1, facetResults.size());
+      FacetResultNode rootNode = facetResults.get(0).getFacetResultNode();
+      assertEquals("wrong count for " + dim, expectedCounts.get(dim).intValue(), (int) rootNode.getValue());
+    }
+  }
+  
+  private void verifyIndexOrdinals(DirectoryReader indexReader, TaxonomyReader taxoReader, FacetIndexingParams fip) 
+      throws IOException {
+    // verify that the ordinals in the index match the ones in the taxonomy, and vice versa
+    
+    // collect all fields which have DocValues, to assert later that all were
+    // visited i.e. that during migration we didn't add FieldInfos with no
+    // DocValues
+    HashSet<String> docValuesFields = new HashSet<String>();
+    for (AtomicReaderContext context : indexReader.leaves()) {
+      FieldInfos infos = context.reader().getFieldInfos();
+      for (FieldInfo info : infos) {
+        if (info.hasDocValues()) {
+          docValuesFields.add(info.name);
+        }
+      }
+    }
+    
+    // check that all visited ordinals are found in the taxonomy and vice versa
+    boolean[] foundOrdinals = new boolean[taxoReader.getSize()];
+    for (int i = 0; i < foundOrdinals.length; i++) {
+      foundOrdinals[i] = false; // init to be on the safe side
+    }
+    foundOrdinals[0] = true; // ROOT ordinals isn't indexed
+    // mark 'dummy' category ordinal as seen
+    int dummyOrdinal = taxoReader.getOrdinal(new CategoryPath("dummy"));
+    if (dummyOrdinal > 0) {
+      foundOrdinals[dummyOrdinal] = true;
+    }
+    
+    int partitionSize = fip.getPartitionSize();
+    int numPartitions = (int) Math.ceil(taxoReader.getSize() / (double) partitionSize);
+    final IntsRef ordinals = new IntsRef(32);
+    for (String dim : DIMENSIONS) {
+      CategoryListParams clp = fip.getCategoryListParams(new CategoryPath(dim));
+      int partitionOffset = 0;
+      for (int partition = 0; partition < numPartitions; partition++, partitionOffset += partitionSize) {
+        final CategoryListIterator cli = clp.createCategoryListIterator(partition);
+        for (AtomicReaderContext context : indexReader.leaves()) {
+          if (cli.setNextReader(context)) { // not all fields may exist in all segments
+            // remove that field from the list of DocValues fields
+            docValuesFields.remove(clp.field + PartitionsUtils.partitionName(partition));
+            int maxDoc = context.reader().maxDoc();
+            for (int doc = 0; doc < maxDoc; doc++) {
+              cli.getOrdinals(doc, ordinals);
+              for (int j = 0; j < ordinals.length; j++) {
+                // verify that the ordinal is recognized by the taxonomy
+                int ordinal = ordinals.ints[j] + partitionOffset;
+                assertTrue("should not have received dummy ordinal (" + dummyOrdinal + ")", dummyOrdinal != ordinal);
+                assertNotNull("missing category for ordinal " + ordinal, taxoReader.getPath(ordinal));
+                foundOrdinals[ordinal] = true;
+              }
+            }
+          }
+        }
+      }
+    }
+    
+    assertTrue("some fields which have docValues were not visited: " + docValuesFields, docValuesFields.isEmpty());
+    
+    for (int i = 0; i < foundOrdinals.length; i++) {
+      assertTrue("ordinal " + i + " not visited", foundOrdinals[i]);
+    }
+  }
+  
+  private void doTestMigration(final int partitionSize) throws Exception {
+    // create a facets index with PayloadFacetFields and check it after migration
+    Directory indexDir = newDirectory();
+    Directory taxoDir = newDirectory();
+    
+    // set custom CLP fields for two dimensions and use the default ($facets) for the other two
+    HashMap<CategoryPath,CategoryListParams> params = new HashMap<CategoryPath,CategoryListParams>();
+    params.put(new CategoryPath(DIMENSIONS[0]), new CategoryListParams(DIMENSIONS[0]));
+    params.put(new CategoryPath(DIMENSIONS[1]), new CategoryListParams(DIMENSIONS[1]));
+    FacetIndexingParams fip = new PerDimensionIndexingParams(params) {
+      @Override
+      public int getPartitionSize() {
+        return partitionSize;
+      }
+    };
+    
+    HashMap<String,Integer> expectedCounts = createIndex(indexDir, taxoDir, fip);
+    migrateIndex(indexDir, fip);
+    verifyMigratedIndex(indexDir, taxoDir, expectedCounts, fip);
+    
+    IOUtils.close(indexDir, taxoDir);
+  }
+  
+  @Test
+  public void testMigration() throws Exception {
+    doTestMigration(Integer.MAX_VALUE);
+  }
+  
+  @Test
+  public void testMigrationWithPartitions() throws Exception {
+    doTestMigration(2);
+  }
+  
+}
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/index/params/CategoryListParamsTest.java b/lucene/facet/src/test/org/apache/lucene/facet/index/params/CategoryListParamsTest.java
index 4ea2aea..49ca1b7 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/index/params/CategoryListParamsTest.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/index/params/CategoryListParamsTest.java
@@ -1,10 +1,7 @@
 package org.apache.lucene.facet.index.params;
 
-import org.apache.lucene.index.Term;
-import org.junit.Test;
-
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.facet.index.params.CategoryListParams;
+import org.junit.Test;
 
 /*
  * Licensed to the Apache Software Foundation (ASF) under one or more
@@ -28,7 +25,7 @@ public class CategoryListParamsTest extends LuceneTestCase {
   @Test
   public void testDefaultSettings() {
     CategoryListParams clp = new CategoryListParams();
-    assertEquals("wrong default term", new Term("$facets", "$fulltree$"), clp.getTerm());
+    assertEquals("wrong default field", "$facets", clp.field);
     assertEquals("unexpected default encoder", "Sorting (Unique (DGap (VInt8)))", clp.createEncoder().toString());
     assertEquals("unexpected default decoder", "DGap (VInt8)", clp.createEncoder().createMatchingDecoder().toString());
   }
@@ -64,8 +61,8 @@ public class CategoryListParamsTest extends LuceneTestCase {
         clParams1.hashCode(), clParams2.hashCode());
 
     // Test 2 CategoryListParams with the same specified Term
-    clParams1 = new CategoryListParams(new Term("test"));
-    clParams2 = new CategoryListParams(new Term("test"));
+    clParams1 = new CategoryListParams("test");
+    clParams2 = new CategoryListParams("test");
     assertEquals(
         "2 CategoryListParams with the same term should equal each other.",
         clParams1, clParams2);
@@ -73,8 +70,8 @@ public class CategoryListParamsTest extends LuceneTestCase {
         clParams1.hashCode(), clParams2.hashCode());
     
     // Test 2 CategoryListParams with DIFFERENT terms
-    clParams1 = new CategoryListParams(new Term("test1"));
-    clParams2 = new CategoryListParams(new Term("test2"));
+    clParams1 = new CategoryListParams("test1");
+    clParams2 = new CategoryListParams("test2");
     assertFalse(
         "2 CategoryListParams with the different terms should NOT equal each other.",
         clParams1.equals(clParams2));
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/index/params/FacetIndexingParamsTest.java b/lucene/facet/src/test/org/apache/lucene/facet/index/params/FacetIndexingParamsTest.java
index c04d68d..de5f233 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/index/params/FacetIndexingParamsTest.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/index/params/FacetIndexingParamsTest.java
@@ -35,8 +35,7 @@ public class FacetIndexingParamsTest extends LuceneTestCase {
     assertNotNull("Missing default category list", dfip.getAllCategoryListParams());
     assertEquals("all categories have the same CategoryListParams by default",
         dfip.getCategoryListParams(null), dfip.getCategoryListParams(new CategoryPath("a")));
-    assertEquals("Expected default category list term is $facets:$fulltree$",
-        new Term("$facets", "$fulltree$"), dfip.getCategoryListParams(null).getTerm());
+    assertEquals("Expected default category list field is $facets", "$facets", dfip.getCategoryListParams(null).field);
     String expectedDDText = "a"
         + dfip.getFacetDelimChar() + "b";
     CategoryPath cp = new CategoryPath("a", "b");
@@ -48,13 +47,13 @@ public class FacetIndexingParamsTest extends LuceneTestCase {
     assertEquals("wrong drill-down term text", expectedDDText, new String(
         buf, 0, numchars));
     CategoryListParams clParams = dfip.getCategoryListParams(null);
-    assertEquals("partition for all ordinals is the first", "$fulltree$", 
-        PartitionsUtils.partitionNameByOrdinal(dfip, clParams , 250));
+    assertEquals("partition for all ordinals is the first", "", 
+        PartitionsUtils.partitionNameByOrdinal(dfip, 250));
     assertEquals("for partition 0, the same name should be returned",
-        "$fulltree$", PartitionsUtils.partitionName(clParams, 0));
+        "", PartitionsUtils.partitionName(0));
     assertEquals(
         "for any other, it's the concatenation of name + partition",
-        "$fulltree$1", PartitionsUtils.partitionName(clParams, 1));
+        PartitionsUtils.PART_NAME_PREFIX + "1", PartitionsUtils.partitionName(1));
     assertEquals("default partition number is always 0", 0, 
         PartitionsUtils.partitionNumber(dfip,100));
     assertEquals("default partition size is unbounded", Integer.MAX_VALUE,
@@ -63,11 +62,9 @@ public class FacetIndexingParamsTest extends LuceneTestCase {
 
   @Test
   public void testCategoryListParamsWithDefaultIndexingParams() {
-    CategoryListParams clp = new CategoryListParams(
-        new Term("clp", "value"));
+    CategoryListParams clp = new CategoryListParams("clp");
     FacetIndexingParams dfip = new FacetIndexingParams(clp);
-    assertEquals("Expected default category list term is " + clp.getTerm(),
-        clp.getTerm(), dfip.getCategoryListParams(null).getTerm());
+    assertEquals("Expected default category list field is " + clp.field, clp.field, dfip.getCategoryListParams(null).field);
   }
 
   @Test
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/index/params/PerDimensionIndexingParamsTest.java b/lucene/facet/src/test/org/apache/lucene/facet/index/params/PerDimensionIndexingParamsTest.java
index c73cf8d..6db5e22 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/index/params/PerDimensionIndexingParamsTest.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/index/params/PerDimensionIndexingParamsTest.java
@@ -32,44 +32,31 @@ public class PerDimensionIndexingParamsTest extends LuceneTestCase {
   public void testTopLevelSettings() {
     FacetIndexingParams ifip = new PerDimensionIndexingParams(Collections.<CategoryPath, CategoryListParams>emptyMap());
     assertNotNull("Missing default category list", ifip.getAllCategoryListParams());
-    assertEquals(
-        "Expected default category list term is $facets:$fulltree$",
-        new Term("$facets", "$fulltree$"), ifip.getCategoryListParams(
-            null).getTerm());
-    String expectedDDText = "a"
-        + ifip.getFacetDelimChar() + "b";
+    assertEquals("Expected default category list field is $facets", "$facets", ifip.getCategoryListParams(null).field);
+    String expectedDDText = "a" + ifip.getFacetDelimChar() + "b";
     CategoryPath cp = new CategoryPath("a", "b");
-    assertEquals("wrong drill-down term", new Term("$facets",
-        expectedDDText), DrillDown.term(ifip,cp));
+    assertEquals("wrong drill-down term", new Term("$facets", expectedDDText), DrillDown.term(ifip,cp));
     char[] buf = new char[20];
     int numchars = ifip.drillDownTermText(cp, buf);
     assertEquals("3 characters should be written", 3, numchars);
-    assertEquals("wrong drill-down term text", expectedDDText, new String(
-        buf, 0, numchars));
+    assertEquals("wrong drill-down term text", expectedDDText, new String(buf, 0, numchars));
     
     CategoryListParams clParams = ifip.getCategoryListParams(null);
-    assertEquals("partition for all ordinals is the first", "$fulltree$", 
-        PartitionsUtils.partitionNameByOrdinal(ifip, clParams , 250));
-    assertEquals("for partition 0, the same name should be returned",
-        "$fulltree$", PartitionsUtils.partitionName(clParams, 0));
-    assertEquals(
-        "for any other, it's the concatenation of name + partition",
-        "$fulltree$1", PartitionsUtils.partitionName(clParams, 1));
-    assertEquals("default partition number is always 0", 0, 
-        PartitionsUtils.partitionNumber(ifip,100));
-    
-    assertEquals("default partition size is unbounded", Integer.MAX_VALUE,
-        ifip.getPartitionSize());
+    assertEquals("partition for all ordinals is the first", "", PartitionsUtils.partitionNameByOrdinal(ifip, 250));
+    assertEquals("for partition 0, the same name should be returned", "", PartitionsUtils.partitionName(0));
+    assertEquals("for any other, it's the concatenation of name + partition", PartitionsUtils.PART_NAME_PREFIX + "1", PartitionsUtils.partitionName(1));
+    assertEquals("default partition number is always 0", 0, PartitionsUtils.partitionNumber(ifip,100));
+    assertEquals("default partition size is unbounded", Integer.MAX_VALUE, ifip.getPartitionSize());
   }
 
   @Test
   public void testCategoryListParamsAddition() {
-    CategoryListParams clp = new CategoryListParams(new Term("clp", "value"));
+    CategoryListParams clp = new CategoryListParams("clp");
     PerDimensionIndexingParams tlfip = new PerDimensionIndexingParams(
         Collections.<CategoryPath,CategoryListParams> singletonMap(new CategoryPath("a"), clp));
-    assertEquals("Expected category list term is " + clp.getTerm(), 
-        clp.getTerm(), tlfip.getCategoryListParams(new CategoryPath("a")).getTerm());
-    assertNotSame("Unexpected default category list " + clp.getTerm(), clp, tlfip.getCategoryListParams(null));
+    assertEquals("Expected category list field is " + clp.field, 
+        clp.field, tlfip.getCategoryListParams(new CategoryPath("a")).field);
+    assertNotSame("Unexpected default category list " + clp.field, clp, tlfip.getCategoryListParams(null));
   }
 
 }
\ No newline at end of file
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest.java b/lucene/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest.java
index c326bbb..9f3c977 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest.java
@@ -1,23 +1,15 @@
 package org.apache.lucene.facet.search;
 
-import java.io.IOException;
-import java.io.Reader;
 import java.util.HashSet;
 import java.util.Set;
 
-import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;
 import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.document.TextField;
+import org.apache.lucene.document.StraightBytesDocValuesField;
 import org.apache.lucene.index.AtomicReaderContext;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.Term;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IntsRef;
@@ -48,42 +40,6 @@ import org.junit.Test;
 
 public class CategoryListIteratorTest extends LuceneTestCase {
 
-  private static final class DataTokenStream extends TokenStream {
-
-    private final PayloadAttribute payload = addAttribute(PayloadAttribute.class);
-    private final BytesRef buf;
-    private final IntEncoder encoder;
-    private final CharTermAttribute term = addAttribute(CharTermAttribute.class);
-    
-    private int idx;
-    private boolean exhausted = false;
-
-    public DataTokenStream(String text, IntEncoder encoder) {
-      this.encoder = encoder;
-      term.setEmpty().append(text);
-      buf = new BytesRef();
-      payload.setPayload(buf);
-    }
-
-    public void setIdx(int idx) {
-      this.idx = idx;
-      exhausted = false;
-    }
-
-    @Override
-    public boolean incrementToken() throws IOException {
-      if (exhausted) {
-        return false;
-      }
-
-      // must copy because encoders may change the buffer
-      encoder.encode(IntsRef.deepCopyOf(data[idx]), buf);
-      exhausted = true;
-      return true;
-    }
-
-  }
-
   static final IntsRef[] data = new IntsRef[] {
     new IntsRef(new int[] { 1, 2 }, 0, 2), 
     new IntsRef(new int[] { 3, 4 }, 0, 2),
@@ -95,13 +51,13 @@ public class CategoryListIteratorTest extends LuceneTestCase {
   public void testPayloadCategoryListIteraor() throws Exception {
     Directory dir = newDirectory();
     final IntEncoder encoder = new SortingIntEncoder(new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder())));
-    DataTokenStream dts = new DataTokenStream("1",encoder);
     RandomIndexWriter writer = new RandomIndexWriter(random(), dir, newIndexWriterConfig(TEST_VERSION_CURRENT, 
         new MockAnalyzer(random(), MockTokenizer.KEYWORD, false)).setMergePolicy(newLogMergePolicy()));
+    BytesRef buf = new BytesRef();
     for (int i = 0; i < data.length; i++) {
-      dts.setIdx(i);
       Document doc = new Document();
-      doc.add(new TextField("f", dts));
+      encoder.encode(IntsRef.deepCopyOf(data[i]), buf);
+      doc.add(new StraightBytesDocValuesField("f", buf));
       writer.addDocument(doc);
     }
     IndexReader reader = writer.getReader();
@@ -109,9 +65,9 @@ public class CategoryListIteratorTest extends LuceneTestCase {
 
     int totalCategories = 0;
     IntsRef ordinals = new IntsRef();
-    CategoryListIterator cli = new PayloadCategoryListIteraor(new Term("f","1"), encoder.createMatchingDecoder());
+    CategoryListIterator cli = new DocValuesCategoryListIterator("f", encoder.createMatchingDecoder());
     for (AtomicReaderContext context : reader.leaves()) {
-      cli.setNextReader(context);
+      assertTrue("failed to initalize iterator", cli.setNextReader(context));
       int maxDoc = context.reader().maxDoc();
       int dataIdx = context.docBase;
       for (int doc = 0; doc < maxDoc; doc++, dataIdx++) {
@@ -136,24 +92,17 @@ public class CategoryListIteratorTest extends LuceneTestCase {
   public void testPayloadIteratorWithInvalidDoc() throws Exception {
     Directory dir = newDirectory();
     final IntEncoder encoder = new SortingIntEncoder(new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder())));
-    DataTokenStream dts = new DataTokenStream("1", encoder);
-    // this test requires that no payloads ever be randomly present!
-    final Analyzer noPayloadsAnalyzer = new Analyzer() {
-      @Override
-      public TokenStreamComponents createComponents(String fieldName, Reader reader) {
-        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.KEYWORD, false));
-      }
-    };
     // NOTE: test is wired to LogMP... because test relies on certain docids having payloads
     RandomIndexWriter writer = new RandomIndexWriter(random(), dir, 
-        newIndexWriterConfig(TEST_VERSION_CURRENT, noPayloadsAnalyzer).setMergePolicy(newLogMergePolicy()));
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));
     for (int i = 0; i < data.length; i++) {
       Document doc = new Document();
       if (i == 0) {
-        dts.setIdx(i);
-        doc.add(new TextField("f", dts)); // only doc 0 has payloads!
+        BytesRef buf = new BytesRef();
+        encoder.encode(IntsRef.deepCopyOf(data[i]), buf );
+        doc.add(new StraightBytesDocValuesField("f", buf));
       } else {
-        doc.add(new TextField("f", "1", Field.Store.NO));
+        doc.add(new StraightBytesDocValuesField("f", new BytesRef()));
       }
       writer.addDocument(doc);
       writer.commit();
@@ -164,9 +113,9 @@ public class CategoryListIteratorTest extends LuceneTestCase {
 
     int totalCategories = 0;
     IntsRef ordinals = new IntsRef();
-    CategoryListIterator cli = new PayloadCategoryListIteraor(new Term("f","1"), encoder.createMatchingDecoder());
+    CategoryListIterator cli = new DocValuesCategoryListIterator("f", encoder.createMatchingDecoder());
     for (AtomicReaderContext context : reader.leaves()) {
-      cli.setNextReader(context);
+      assertTrue("failed to initalize iterator", cli.setNextReader(context));
       int maxDoc = context.reader().maxDoc();
       int dataIdx = context.docBase;
       for (int doc = 0; doc < maxDoc; doc++, dataIdx++) {
@@ -176,13 +125,13 @@ public class CategoryListIteratorTest extends LuceneTestCase {
         }
         cli.getOrdinals(doc, ordinals);
         if (dataIdx == 0) {
-          assertTrue("document 0 must have a payload", ordinals.length > 0);
+          assertTrue("document 0 must have ordinals", ordinals.length > 0);
           for (int j = 0; j < ordinals.length; j++) {
             assertTrue("expected category not found: " + ordinals.ints[j], values.contains(ordinals.ints[j]));
           }
           totalCategories += ordinals.length;
         } else {
-          assertTrue("only document 0 should have a payload", ordinals.length == 0);
+          assertTrue("only document 0 should have ordinals", ordinals.length == 0);
         }
       }
     }
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/search/DrillDownTest.java b/lucene/facet/src/test/org/apache/lucene/facet/search/DrillDownTest.java
index c20a98c..9a881cb 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/search/DrillDownTest.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/search/DrillDownTest.java
@@ -60,8 +60,8 @@ public class DrillDownTest extends LuceneTestCase {
   
   public DrillDownTest() {
     Map<CategoryPath,CategoryListParams> paramsMap = new HashMap<CategoryPath,CategoryListParams>();
-    paramsMap.put(new CategoryPath("a"), new CategoryListParams(new Term("testing_facets_a", "a")));
-    paramsMap.put(new CategoryPath("b"), new CategoryListParams(new Term("testing_facets_b", "b")));
+    paramsMap.put(new CategoryPath("a"), new CategoryListParams("testing_facets_a"));
+    paramsMap.put(new CategoryPath("b"), new CategoryListParams("testing_facets_b"));
     nonDefaultParams = new PerDimensionIndexingParams(paramsMap);
   }
 
@@ -113,8 +113,8 @@ public class DrillDownTest extends LuceneTestCase {
   }
   
   @Test
-  public void testTermDefault() {
-    String defaultField = CategoryListParams.DEFAULT_TERM.field();
+  public void testDefaultField() {
+    String defaultField = CategoryListParams.DEFAULT_FIELD;
     
     Term termA = DrillDown.term(defaultParams, new CategoryPath("a"));
     assertEquals(new Term(defaultField, "a"), termA);
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/search/TestCategoryListCache.java b/lucene/facet/src/test/org/apache/lucene/facet/search/TestCategoryListCache.java
deleted file mode 100644
index 0d7d317..0000000
--- a/lucene/facet/src/test/org/apache/lucene/facet/search/TestCategoryListCache.java
+++ /dev/null
@@ -1,145 +0,0 @@
-package org.apache.lucene.facet.search;
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.List;
-import java.util.Map;
-
-import org.apache.lucene.search.MatchAllDocsQuery;
-import org.apache.lucene.util.IntsRef;
-
-import org.junit.After;
-import org.junit.Before;
-import org.junit.Test;
-
-import org.apache.lucene.facet.FacetTestBase;
-import org.apache.lucene.facet.index.params.CategoryListParams;
-import org.apache.lucene.facet.index.params.FacetIndexingParams;
-import org.apache.lucene.facet.search.cache.CategoryListCache;
-import org.apache.lucene.facet.search.cache.CategoryListData;
-import org.apache.lucene.facet.search.params.CountFacetRequest;
-import org.apache.lucene.facet.search.params.FacetRequest;
-import org.apache.lucene.facet.search.params.FacetSearchParams;
-import org.apache.lucene.facet.search.results.FacetResult;
-import org.apache.lucene.facet.taxonomy.CategoryPath;
-import org.apache.lucene.index.AtomicReaderContext;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-public class TestCategoryListCache extends FacetTestBase {
-
-  public TestCategoryListCache() {
-    super();
-  }
-  
-  @Before
-  @Override
-  public void setUp() throws Exception {
-    super.setUp();
-    initIndex();
-  }
-  
-  @After
-  @Override
-  public void tearDown() throws Exception {
-    closeAll();
-    super.tearDown();
-  }
-  
-  @Test
-  public void testNoClCache() throws Exception {
-    doTest(false,false);
-  }
-
-  @Test
-  public void testCorrectClCache() throws Exception {
-    doTest(true,false);
-  }
-  
-  @Test
-  public void testWrongClCache() throws Exception {
-    doTest(true,true);
-  }
-  
-  private void doTest(boolean withCache, boolean plantWrongData) throws Exception {
-    Map<CategoryPath,Integer> truth = facetCountsTruth();
-    CategoryPath cp = (CategoryPath) truth.keySet().toArray()[0]; // any category path will do for this test
-    FacetIndexingParams iParams = FacetIndexingParams.ALL_PARENTS;
-    final CategoryListCache clCache;
-    if (withCache) {
-      //let's use a cached cl data
-      CategoryListParams clp = new CategoryListParams(); // default term ok as only single list
-      clCache = new CategoryListCache();
-      clCache.loadAndRegister(clp, indexReader, taxoReader, iParams);
-      if (plantWrongData) {
-        // let's mess up the cached data and then expect a wrong result...
-        messCachedData(clCache, clp);
-      }
-    } else {
-      clCache = null;
-    }
-    List<FacetRequest> req = new ArrayList<FacetRequest>();
-    req.add(new CountFacetRequest(cp, 10));
-    final FacetSearchParams sParams = new FacetSearchParams(req, iParams) {
-      @Override
-      public CategoryListCache getCategoryListCache() {
-        return clCache;
-      }
-    };
-    FacetsCollector fc = new FacetsCollector(sParams, indexReader, taxoReader);
-    searcher.search(new MatchAllDocsQuery(), fc);
-    List<FacetResult> res = fc.getFacetResults();
-    try {
-      assertCountsAndCardinality(truth, res);
-      assertFalse("Correct results not expected when wrong data was cached", plantWrongData);
-    } catch (Throwable e) {
-      assertTrue("Wrong results not expected unless wrong data was cached", withCache);
-      assertTrue("Wrong results not expected unless wrong data was cached", plantWrongData);
-    }
-  }
-
-  /** Mess the cached data for this {@link CategoryListParams} */
-  private void messCachedData(CategoryListCache clCache, CategoryListParams clp) {
-    final CategoryListData cld = clCache.get(clp);
-    CategoryListData badCld = new CategoryListData() {
-      @Override
-      public CategoryListIterator iterator(int partition)  throws IOException {
-        final CategoryListIterator it = cld.iterator(partition);
-        return new CategoryListIterator() {
-          @Override
-          public void getOrdinals(int docID, IntsRef ints) throws IOException {
-            it.getOrdinals(docID, ints);
-            for (int i = 0; i < ints.length; i++) {
-              if (ints.ints[i] > 1) {
-                ints.ints[i]--;
-              } else {
-                ints.ints[i]++;
-              }
-            }
-          }
-          @Override
-          public boolean setNextReader(AtomicReaderContext context) throws IOException {
-            return it.setNextReader(context);
-          }
-        };
-      }
-    };
-    clCache.register(clp, badCld);
-  }
-  
-}
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/search/TestMultipleCategoryLists.java b/lucene/facet/src/test/org/apache/lucene/facet/search/TestMultipleCategoryLists.java
index 12a054c..51967c5 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/search/TestMultipleCategoryLists.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/search/TestMultipleCategoryLists.java
@@ -10,14 +10,18 @@ import java.util.Map;
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.document.TextField;
 import org.apache.lucene.facet.FacetTestUtils;
+import org.apache.lucene.facet.index.FacetFields;
 import org.apache.lucene.facet.index.params.CategoryListParams;
 import org.apache.lucene.facet.index.params.FacetIndexingParams;
 import org.apache.lucene.facet.index.params.PerDimensionIndexingParams;
 import org.apache.lucene.facet.search.params.CountFacetRequest;
 import org.apache.lucene.facet.search.params.FacetRequest;
-import org.apache.lucene.facet.search.params.FacetSearchParams;
 import org.apache.lucene.facet.search.params.FacetRequest.ResultMode;
+import org.apache.lucene.facet.search.params.FacetSearchParams;
 import org.apache.lucene.facet.search.results.FacetResult;
 import org.apache.lucene.facet.search.results.FacetResultNode;
 import org.apache.lucene.facet.taxonomy.CategoryPath;
@@ -25,23 +29,19 @@ import org.apache.lucene.facet.taxonomy.TaxonomyReader;
 import org.apache.lucene.facet.taxonomy.TaxonomyWriter;
 import org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyReader;
 import org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyWriter;
-import org.apache.lucene.index.DocsEnum;
+import org.apache.lucene.index.AtomicReader;
+import org.apache.lucene.index.AtomicReaderContext;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexWriterConfig.OpenMode;
-import org.apache.lucene.index.MultiFields;
 import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.MatchAllDocsQuery;
 import org.apache.lucene.search.MultiCollector;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.TopScoreDocCollector;
 import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
 import org.junit.Test;
 
 /*
@@ -63,6 +63,18 @@ import org.junit.Test;
 
 public class TestMultipleCategoryLists extends LuceneTestCase {
 
+  private static final CategoryPath[] CATEGORIES = new CategoryPath[] {
+    new CategoryPath("Author", "Mark Twain"),
+    new CategoryPath("Author", "Stephen King"),
+    new CategoryPath("Author", "Kurt Vonnegut"),
+    new CategoryPath("Band", "Rock & Pop", "The Beatles"),
+    new CategoryPath("Band", "Punk", "The Ramones"),
+    new CategoryPath("Band", "Rock & Pop", "U2"),
+    new CategoryPath("Band", "Rock & Pop", "REM"),
+    new CategoryPath("Band", "Rock & Pop", "Dave Matthews Band"),
+    new CategoryPath("Composer", "Bach"),
+  };
+  
   @Test
   public void testDefault() throws Exception {
     Directory[][] dirs = getDirs();
@@ -72,9 +84,6 @@ public class TestMultipleCategoryLists extends LuceneTestCase {
     // create and open a taxonomy writer
     TaxonomyWriter tw = new DirectoryTaxonomyWriter(dirs[0][1], OpenMode.CREATE);
 
-    /**
-     * Configure with no custom counting lists
-     */
     PerDimensionIndexingParams iParams = new PerDimensionIndexingParams(Collections.<CategoryPath, CategoryListParams>emptyMap());
 
     seedIndex(iw, tw, iParams);
@@ -88,19 +97,14 @@ public class TestMultipleCategoryLists extends LuceneTestCase {
     // prepare searcher to search against
     IndexSearcher searcher = newSearcher(ir);
 
-    FacetsCollector facetsCollector = performSearch(iParams, tr, ir,
-        searcher);
+    FacetsCollector facetsCollector = performSearch(iParams, tr, ir, searcher);
 
     // Obtain facets results and hand-test them
     assertCorrectResults(facetsCollector);
 
-    DocsEnum td = _TestUtil.docs(random(), ir, "$facets", new BytesRef("$fulltree$"), MultiFields.getLiveDocs(ir), null, DocsEnum.FLAG_NONE);
-    assertTrue(td.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
+    assertOrdinalsExist("$facets", ir);
 
-    tr.close();
-    ir.close();
-    iw.close();
-    tw.close();
+    IOUtils.close(tr, ir, iw, tw);
     IOUtils.close(dirs[0]);
   }
 
@@ -111,12 +115,10 @@ public class TestMultipleCategoryLists extends LuceneTestCase {
     RandomIndexWriter iw = new RandomIndexWriter(random(), dirs[0][0], newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));
     // create and open a taxonomy writer
-    TaxonomyWriter tw = new DirectoryTaxonomyWriter(dirs[0][1],
-        OpenMode.CREATE);
+    TaxonomyWriter tw = new DirectoryTaxonomyWriter(dirs[0][1], OpenMode.CREATE);
 
     PerDimensionIndexingParams iParams = new PerDimensionIndexingParams(
-        Collections.singletonMap(new CategoryPath("Author"),
-            new CategoryListParams(new Term("$author", "Authors"))));
+        Collections.singletonMap(new CategoryPath("Author"), new CategoryListParams("$author")));
     seedIndex(iw, tw, iParams);
 
     IndexReader ir = iw.getReader();
@@ -133,13 +135,10 @@ public class TestMultipleCategoryLists extends LuceneTestCase {
     // Obtain facets results and hand-test them
     assertCorrectResults(facetsCollector);
 
-    assertPostingListExists("$facets", "$fulltree$", ir);
-    assertPostingListExists("$author", "Authors", ir);
+    assertOrdinalsExist("$facets", ir);
+    assertOrdinalsExist("$author", ir);
 
-    tr.close();
-    ir.close();
-    iw.close();
-    tw.close();
+    IOUtils.close(tr, ir, iw, tw);
     IOUtils.close(dirs[0]);
   }
 
@@ -150,12 +149,11 @@ public class TestMultipleCategoryLists extends LuceneTestCase {
     RandomIndexWriter iw = new RandomIndexWriter(random(), dirs[0][0], newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));
     // create and open a taxonomy writer
-    TaxonomyWriter tw = new DirectoryTaxonomyWriter(dirs[0][1],
-        OpenMode.CREATE);
+    TaxonomyWriter tw = new DirectoryTaxonomyWriter(dirs[0][1], OpenMode.CREATE);
 
     Map<CategoryPath,CategoryListParams> paramsMap = new HashMap<CategoryPath,CategoryListParams>();
-    paramsMap.put(new CategoryPath("Band"), new CategoryListParams(new Term("$music", "Bands")));
-    paramsMap.put(new CategoryPath("Composer"), new CategoryListParams(new Term("$music", "Composers")));
+    paramsMap.put(new CategoryPath("Band"), new CategoryListParams("$music"));
+    paramsMap.put(new CategoryPath("Composer"), new CategoryListParams("$music"));
     PerDimensionIndexingParams iParams = new PerDimensionIndexingParams(paramsMap);
     seedIndex(iw, tw, iParams);
 
@@ -168,26 +166,27 @@ public class TestMultipleCategoryLists extends LuceneTestCase {
     // prepare searcher to search against
     IndexSearcher searcher = newSearcher(ir);
 
-    FacetsCollector facetsCollector = performSearch(iParams, tr, ir,
-        searcher);
+    FacetsCollector facetsCollector = performSearch(iParams, tr, ir, searcher);
 
     // Obtain facets results and hand-test them
     assertCorrectResults(facetsCollector);
 
-    assertPostingListExists("$facets", "$fulltree$", ir);
-    assertPostingListExists("$music", "Bands", ir);
-    assertPostingListExists("$music", "Composers", ir);
+    assertOrdinalsExist("$facets", ir);
+    assertOrdinalsExist("$music", ir);
+    assertOrdinalsExist("$music", ir);
 
-    tr.close();
-    ir.close();
-    iw.close();
-    tw.close();
+    IOUtils.close(tr, ir, iw, tw);
     IOUtils.close(dirs[0]);
   }
 
-  private void assertPostingListExists(String field, String text, IndexReader ir) throws IOException {
-    DocsEnum de = _TestUtil.docs(random(), ir, field, new BytesRef(text), null, null, DocsEnum.FLAG_NONE);
-    assertTrue(de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
+  private void assertOrdinalsExist(String field, IndexReader ir) throws IOException {
+    for (AtomicReaderContext context : ir.leaves()) {
+      AtomicReader r = context.reader();
+      if (r.docValues(field) != null) {
+        return; // not all segments must have this DocValues
+      }
+    }
+    fail("no ordinals found for " + field);
   }
 
   @Test
@@ -200,8 +199,8 @@ public class TestMultipleCategoryLists extends LuceneTestCase {
     TaxonomyWriter tw = new DirectoryTaxonomyWriter(dirs[0][1], OpenMode.CREATE);
 
     Map<CategoryPath,CategoryListParams> paramsMap = new HashMap<CategoryPath,CategoryListParams>();
-    paramsMap.put(new CategoryPath("Band"), new CategoryListParams(new Term("$bands", "Bands")));
-    paramsMap.put(new CategoryPath("Composer"), new CategoryListParams(new Term("$composers", "Composers")));
+    paramsMap.put(new CategoryPath("Band"), new CategoryListParams("$bands"));
+    paramsMap.put(new CategoryPath("Composer"), new CategoryListParams("$composers"));
     PerDimensionIndexingParams iParams = new PerDimensionIndexingParams(paramsMap);
     seedIndex(iw, tw, iParams);
 
@@ -214,18 +213,15 @@ public class TestMultipleCategoryLists extends LuceneTestCase {
     // prepare searcher to search against
     IndexSearcher searcher = newSearcher(ir);
 
-    FacetsCollector facetsCollector = performSearch(iParams, tr, ir,
-        searcher);
+    FacetsCollector facetsCollector = performSearch(iParams, tr, ir, searcher);
 
     // Obtain facets results and hand-test them
     assertCorrectResults(facetsCollector);
-    assertPostingListExists("$facets", "$fulltree$", ir);
-    assertPostingListExists("$bands", "Bands", ir);
-    assertPostingListExists("$composers", "Composers", ir);
-    tr.close();
-    ir.close();
-    iw.close();
-    tw.close();
+    assertOrdinalsExist("$facets", ir);
+    assertOrdinalsExist("$bands", ir);
+    assertOrdinalsExist("$composers", ir);
+
+    IOUtils.close(tr, ir, iw, tw);
     IOUtils.close(dirs[0]);
   }
 
@@ -236,13 +232,12 @@ public class TestMultipleCategoryLists extends LuceneTestCase {
     RandomIndexWriter iw = new RandomIndexWriter(random(), dirs[0][0], newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));
     // create and open a taxonomy writer
-    TaxonomyWriter tw = new DirectoryTaxonomyWriter(dirs[0][1],
-        OpenMode.CREATE);
+    TaxonomyWriter tw = new DirectoryTaxonomyWriter(dirs[0][1], OpenMode.CREATE);
 
     Map<CategoryPath,CategoryListParams> paramsMap = new HashMap<CategoryPath,CategoryListParams>();
-    paramsMap.put(new CategoryPath("Band"), new CategoryListParams(new Term("$music", "music")));
-    paramsMap.put(new CategoryPath("Composer"), new CategoryListParams(new Term("$music", "music")));
-    paramsMap.put(new CategoryPath("Author"), new CategoryListParams(new Term("$literature", "Authors")));
+    paramsMap.put(new CategoryPath("Band"), new CategoryListParams("$music"));
+    paramsMap.put(new CategoryPath("Composer"), new CategoryListParams("$music"));
+    paramsMap.put(new CategoryPath("Author"), new CategoryListParams("$literature"));
     PerDimensionIndexingParams iParams = new PerDimensionIndexingParams(paramsMap);
 
     seedIndex(iw, tw, iParams);
@@ -256,18 +251,14 @@ public class TestMultipleCategoryLists extends LuceneTestCase {
     // prepare searcher to search against
     IndexSearcher searcher = newSearcher(ir);
 
-    FacetsCollector facetsCollector = performSearch(iParams, tr, ir,
-        searcher);
+    FacetsCollector facetsCollector = performSearch(iParams, tr, ir, searcher);
 
     // Obtain facets results and hand-test them
     assertCorrectResults(facetsCollector);
-    assertPostingListExists("$music", "music", ir);
-    assertPostingListExists("$literature", "Authors", ir);
+    assertOrdinalsExist("$music", ir);
+    assertOrdinalsExist("$literature", ir);
 
-    tr.close();
-    ir.close();
-    iw.close();
-    tw.close();
+    IOUtils.close(tr, ir, iw, tw);
     IOUtils.close(dirs[0]);
   }
 
@@ -275,14 +266,12 @@ public class TestMultipleCategoryLists extends LuceneTestCase {
     return FacetTestUtils.createIndexTaxonomyDirs(1);
   }
 
-  private void assertCorrectResults(FacetsCollector facetsCollector)
-  throws IOException {
+  private void assertCorrectResults(FacetsCollector facetsCollector) throws IOException {
     List<FacetResult> res = facetsCollector.getFacetResults();
 
     FacetResult results = res.get(0);
     FacetResultNode resNode = results.getFacetResultNode();
-    Iterable<? extends FacetResultNode> subResults = resNode
-    .getSubResults();
+    Iterable<? extends FacetResultNode> subResults = resNode.getSubResults();
     Iterator<? extends FacetResultNode> subIter = subResults.iterator();
 
     checkResult(resNode, "Band", 5.0);
@@ -325,9 +314,8 @@ public class TestMultipleCategoryLists extends LuceneTestCase {
     checkResult(subIter.next(), "Band/Rock & Pop/The Beatles", 1.0);
   }
 
-  private FacetsCollector performSearch(FacetIndexingParams iParams,
-                                        TaxonomyReader tr, IndexReader ir,
-                                        IndexSearcher searcher) throws IOException {
+  private FacetsCollector performSearch(FacetIndexingParams iParams, TaxonomyReader tr, IndexReader ir, 
+      IndexSearcher searcher) throws IOException {
     // step 1: collect matching documents into a collector
     Query q = new MatchAllDocsQuery();
     TopScoreDocCollector topDocsCollector = TopScoreDocCollector.create(10, true);
@@ -344,7 +332,6 @@ public class TestMultipleCategoryLists extends LuceneTestCase {
 
     // Faceted search parameters indicate which facets are we interested in
     FacetSearchParams facetSearchParams = new FacetSearchParams(facetRequests, iParams);
-    
 
     // perform documents search and facets accumulation
     FacetsCollector facetsCollector = new FacetsCollector(facetSearchParams, ir, tr);
@@ -352,27 +339,19 @@ public class TestMultipleCategoryLists extends LuceneTestCase {
     return facetsCollector;
   }
 
-  private void seedIndex(RandomIndexWriter iw, TaxonomyWriter tw,
-                          FacetIndexingParams iParams) throws IOException {
-    FacetTestUtils.add(iParams, iw, tw, "Author", "Mark Twain");
-    FacetTestUtils.add(iParams, iw, tw, "Author", "Stephen King");
-    FacetTestUtils.add(iParams, iw, tw, "Author", "Kurt Vonnegut");
-    FacetTestUtils.add(iParams, iw, tw, "Band", "Rock & Pop",
-    "The Beatles");
-    FacetTestUtils.add(iParams, iw, tw, "Band", "Punk", "The Ramones");
-    FacetTestUtils.add(iParams, iw, tw, "Band", "Rock & Pop", "U2");
-    FacetTestUtils.add(iParams, iw, tw, "Band", "Rock & Pop", "REM");
-    FacetTestUtils.add(iParams, iw, tw, "Band", "Rock & Pop",
-    "Dave Matthews Band");
-    FacetTestUtils.add(iParams, iw, tw, "Composer", "Bach");
+  private void seedIndex(RandomIndexWriter iw, TaxonomyWriter tw, FacetIndexingParams iParams) throws IOException {
+    FacetFields facetFields = new FacetFields(tw, iParams);
+    for (CategoryPath cp : CATEGORIES) {
+      Document doc = new Document();
+      facetFields.addFields(doc, Collections.singletonList(cp));
+      doc.add(new TextField("content", "alpha", Field.Store.YES));
+      iw.addDocument(doc);
+    }
   }
 
   private static void checkResult(FacetResultNode sub, String label, double value) {
-    assertEquals("Label of subresult " + sub.getLabel() + " was incorrect",
-        label, sub.getLabel().toString());
-    assertEquals(
-        "Value for " + sub.getLabel() + " subresult was incorrect",
-        value, sub.getValue(), 0.0);
+    assertEquals("Label of subresult " + sub.getLabel() + " was incorrect", label, sub.getLabel().toString());
+    assertEquals("Value for " + sub.getLabel() + " subresult was incorrect", value, sub.getValue(), 0.0);
   }
 
 }
\ No newline at end of file
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/search/TestStandardFacetsAccumulator.java b/lucene/facet/src/test/org/apache/lucene/facet/search/TestStandardFacetsAccumulator.java
index db88c73..71769e9 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/search/TestStandardFacetsAccumulator.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/search/TestStandardFacetsAccumulator.java
@@ -93,6 +93,7 @@ public class TestStandardFacetsAccumulator extends LuceneTestCase {
     indexTwoDocs(indexWriter, null, false);        // 4th segment, no content, or categories
     indexTwoDocs(indexWriter, null, true);         // 5th segment, with content, no categories
     indexTwoDocs(indexWriter, facetFields, true);  // 6th segment, with content, with categories
+    indexTwoDocs(indexWriter, null, true);         // 7th segment, with content, no categories
     IOUtils.close(indexWriter, taxoWriter);
 
     DirectoryReader indexReader = DirectoryReader.open(indexDir);
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/search/TestTopKInEachNodeResultHandler.java b/lucene/facet/src/test/org/apache/lucene/facet/search/TestTopKInEachNodeResultHandler.java
index 6f9ccab..c164245 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/search/TestTopKInEachNodeResultHandler.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/search/TestTopKInEachNodeResultHandler.java
@@ -178,7 +178,7 @@ public class TestTopKInEachNodeResultHandler extends LuceneTestCase {
       }
       
       FacetResult fr = facetResults.get(0); // a, depth=3, K=2
-      boolean hasDoctor = "Doctor".equals(fr.getFacetRequest().getCategoryPath().components[0]);
+      boolean hasDoctor = "Doctor".equals(fr.getFacetRequest().categoryPath.components[0]);
       assertEquals(9, fr.getNumValidDescendants());
       FacetResultNode parentRes = fr.getFacetResultNode();
       assertEquals(16.0, parentRes.getValue(), Double.MIN_VALUE);
@@ -219,7 +219,7 @@ public class TestTopKInEachNodeResultHandler extends LuceneTestCase {
       }
 
       fr = facetResults.get(1); // a, depth=2, K=2. same result as before
-      hasDoctor |= "Doctor".equals(fr.getFacetRequest().getCategoryPath().components[0]);
+      hasDoctor |= "Doctor".equals(fr.getFacetRequest().categoryPath.components[0]);
       assertEquals(9, fr.getNumValidDescendants());
       parentRes = fr.getFacetResultNode();
       assertEquals(16.0, parentRes.getValue(), Double.MIN_VALUE);
@@ -239,7 +239,7 @@ public class TestTopKInEachNodeResultHandler extends LuceneTestCase {
       }
 
       fr = facetResults.get(2); // a, depth=1, K=2
-      hasDoctor |= "Doctor".equals(fr.getFacetRequest().getCategoryPath().components[0]);
+      hasDoctor |= "Doctor".equals(fr.getFacetRequest().categoryPath.components[0]);
       assertEquals(4, fr.getNumValidDescendants(), 4);
       parentRes = fr.getFacetResultNode();
       assertEquals(16.0, parentRes.getValue(), Double.MIN_VALUE);
@@ -257,7 +257,7 @@ public class TestTopKInEachNodeResultHandler extends LuceneTestCase {
       }
       
       fr = facetResults.get(3); // a/b, depth=3, K=2
-      hasDoctor |= "Doctor".equals(fr.getFacetRequest().getCategoryPath().components[0]);
+      hasDoctor |= "Doctor".equals(fr.getFacetRequest().categoryPath.components[0]);
       assertEquals(4, fr.getNumValidDescendants());
       parentRes = fr.getFacetResultNode();
       assertEquals(8.0, parentRes.getValue(), Double.MIN_VALUE);
@@ -272,7 +272,7 @@ public class TestTopKInEachNodeResultHandler extends LuceneTestCase {
       }
 
       fr = facetResults.get(4); // a/b, depth=2, K=2
-      hasDoctor |= "Doctor".equals(fr.getFacetRequest().getCategoryPath().components[0]);
+      hasDoctor |= "Doctor".equals(fr.getFacetRequest().categoryPath.components[0]);
       assertEquals(4, fr.getNumValidDescendants());
       parentRes = fr.getFacetResultNode();
       assertEquals(8.0, parentRes.getValue(), Double.MIN_VALUE);
@@ -286,7 +286,7 @@ public class TestTopKInEachNodeResultHandler extends LuceneTestCase {
       }
 
       fr = facetResults.get(5); // a/b, depth=1, K=2
-      hasDoctor |= "Doctor".equals(fr.getFacetRequest().getCategoryPath().components[0]);
+      hasDoctor |= "Doctor".equals(fr.getFacetRequest().categoryPath.components[0]);
       assertEquals(4, fr.getNumValidDescendants());
       parentRes = fr.getFacetResultNode();
       assertEquals(8.0, parentRes.getValue(), Double.MIN_VALUE);
@@ -300,13 +300,13 @@ public class TestTopKInEachNodeResultHandler extends LuceneTestCase {
       }
       
       fr = facetResults.get(6); // a/b, depth=0, K=2
-      hasDoctor |= "Doctor".equals(fr.getFacetRequest().getCategoryPath().components[0]);
+      hasDoctor |= "Doctor".equals(fr.getFacetRequest().categoryPath.components[0]);
       assertEquals(0, fr.getNumValidDescendants()); // 0 descendants but rootnode
       parentRes = fr.getFacetResultNode();
       assertEquals(8.0, parentRes.getValue(), Double.MIN_VALUE);
       assertEquals(0.0, parentRes.getResidue(), Double.MIN_VALUE);
       assertEquals(0, parentRes.getNumSubResults());
-      hasDoctor |= "Doctor".equals(fr.getFacetRequest().getCategoryPath().components[0]);
+      hasDoctor |= "Doctor".equals(fr.getFacetRequest().categoryPath.components[0]);
 
       // doctor, depth=1, K=2
       assertFalse("Shouldn't have found anything for a FacetRequest " +
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/search/TestTotalFacetCounts.java b/lucene/facet/src/test/org/apache/lucene/facet/search/TestTotalFacetCounts.java
index bc4922f..7dfd8c6 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/search/TestTotalFacetCounts.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/search/TestTotalFacetCounts.java
@@ -85,12 +85,12 @@ public class TestTotalFacetCounts extends LuceneTestCase {
 
     TotalFacetCountsCache tfcc = TotalFacetCountsCache.getSingleton();
     File tmpFile = _TestUtil.createTempFile("test", "tmp", TEMP_DIR);
-    tfcc.store(tmpFile, readers[0].indexReader, readers[0].taxReader, iParams, null);
+    tfcc.store(tmpFile, readers[0].indexReader, readers[0].taxReader, iParams);
     tfcc.clear(); // not really required because TFCC overrides on load(), but in the test we need not rely on this.
     tfcc.load(tmpFile, readers[0].indexReader, readers[0].taxReader, iParams);
     
     // now retrieve the one just loaded
-    TotalFacetCounts totalCounts = tfcc.getTotalCounts(readers[0].indexReader, readers[0].taxReader, iParams, null);
+    TotalFacetCounts totalCounts = tfcc.getTotalCounts(readers[0].indexReader, readers[0].taxReader, iParams);
 
     int partition = 0;
     for (int i=0; i<expectedCounts.length; i+=partitionSize) {
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/search/TestTotalFacetCountsCache.java b/lucene/facet/src/test/org/apache/lucene/facet/search/TestTotalFacetCountsCache.java
index 0217471..55816c1 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/search/TestTotalFacetCountsCache.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/search/TestTotalFacetCountsCache.java
@@ -78,7 +78,7 @@ public class TestTotalFacetCountsCache extends LuceneTestCase {
     @Override
     public void run() {
       try {
-        tfc = TFC.getTotalCounts(r, tr, iParams, null);
+        tfc = TFC.getTotalCounts(r, tr, iParams);
       } catch (Exception e) {
         throw new RuntimeException(e);
       }
@@ -264,29 +264,29 @@ public class TestTotalFacetCountsCache extends LuceneTestCase {
     // As this is the first time we have invoked the TotalFacetCountsManager, 
     // we should expect to compute and not read from disk.
     TotalFacetCounts totalCounts = 
-      TFC.getTotalCounts(readers[0].indexReader, readers[0].taxReader, iParams, null);
+      TFC.getTotalCounts(readers[0].indexReader, readers[0].taxReader, iParams);
     int prevGen = assertRecomputed(totalCounts, 0, "after first attempt to get it!");
 
     // Repeating same operation should pull from the cache - not recomputed. 
     assertTrue("Should be obtained from cache at 2nd attempt",totalCounts == 
-      TFC.getTotalCounts(readers[0].indexReader, readers[0].taxReader, iParams, null));
+      TFC.getTotalCounts(readers[0].indexReader, readers[0].taxReader, iParams));
 
     // Repeat the same operation as above. but clear first - now should recompute again
     initCache();
-    totalCounts = TFC.getTotalCounts(readers[0].indexReader, readers[0].taxReader, iParams, null);
+    totalCounts = TFC.getTotalCounts(readers[0].indexReader, readers[0].taxReader, iParams);
     prevGen = assertRecomputed(totalCounts, prevGen, "after cache clear, 3rd attempt to get it!");
     
     //store to file
     File outputFile = _TestUtil.createTempFile("test", "tmp", TEMP_DIR);
     initCache();
-    TFC.store(outputFile, readers[0].indexReader, readers[0].taxReader, iParams, null);
-    totalCounts = TFC.getTotalCounts(readers[0].indexReader, readers[0].taxReader, iParams, null);
+    TFC.store(outputFile, readers[0].indexReader, readers[0].taxReader, iParams);
+    totalCounts = TFC.getTotalCounts(readers[0].indexReader, readers[0].taxReader, iParams);
     prevGen = assertRecomputed(totalCounts, prevGen, "after cache clear, 4th attempt to get it!");
 
     //clear and load
     initCache();
     TFC.load(outputFile, readers[0].indexReader, readers[0].taxReader, iParams);
-    totalCounts = TFC.getTotalCounts(readers[0].indexReader, readers[0].taxReader, iParams, null);
+    totalCounts = TFC.getTotalCounts(readers[0].indexReader, readers[0].taxReader, iParams);
     prevGen = assertReadFromDisc(totalCounts, prevGen, "after 5th attempt to get it!");
 
     // Add a new facet to the index, commit and refresh readers
@@ -306,12 +306,12 @@ public class TestTotalFacetCountsCache extends LuceneTestCase {
     readers[0].indexReader = r2;
 
     // now use the new reader - should recompute
-    totalCounts = TFC.getTotalCounts(readers[0].indexReader, readers[0].taxReader, iParams, null);
+    totalCounts = TFC.getTotalCounts(readers[0].indexReader, readers[0].taxReader, iParams);
     prevGen = assertRecomputed(totalCounts, prevGen, "after updating the index - 7th attempt!");
 
     // try again - should not recompute
     assertTrue("Should be obtained from cache at 8th attempt",totalCounts == 
-      TFC.getTotalCounts(readers[0].indexReader, readers[0].taxReader, iParams, null));
+      TFC.getTotalCounts(readers[0].indexReader, readers[0].taxReader, iParams));
     
     readers[0].close();
     outputFile.delete();
@@ -361,7 +361,7 @@ public class TestTotalFacetCountsCache extends LuceneTestCase {
 
     // Create TFC and write cache to disk
     File outputFile = _TestUtil.createTempFile("test", "tmp", TEMP_DIR);
-    TFC.store(outputFile, readers[0].indexReader, readers[0].taxReader, iParams, null);
+    TFC.store(outputFile, readers[0].indexReader, readers[0].taxReader, iParams);
     
     // Make the taxonomy grow without touching the index
     for (int i = 0; i < 10; i++) {
@@ -377,8 +377,7 @@ public class TestTotalFacetCountsCache extends LuceneTestCase {
 
     // With the bug, this next call should result in an exception
     TFC.load(outputFile, readers[0].indexReader, readers[0].taxReader, iParams);
-    TotalFacetCounts totalCounts = TFC.getTotalCounts(
-        readers[0].indexReader, readers[0].taxReader, iParams, null);
+    TotalFacetCounts totalCounts = TFC.getTotalCounts(readers[0].indexReader, readers[0].taxReader, iParams);
     assertReadFromDisc(totalCounts, 0, "after reading from disk.");
     outputFile.delete();
     writers[0].close();
@@ -467,28 +466,25 @@ public class TestTotalFacetCountsCache extends LuceneTestCase {
     // As this is the first time we have invoked the TotalFacetCountsManager, we
     // should expect to compute.
     TotalFacetCounts totalCounts0 = 
-      TFC.getTotalCounts(readers[0].indexReader, readers[0].taxReader, iParams, null);
+      TFC.getTotalCounts(readers[0].indexReader, readers[0].taxReader, iParams);
     int prevGen = -1;
     prevGen = assertRecomputed(totalCounts0, prevGen, "after attempt 1");
     assertTrue("attempt 1b for same input [0] shout find it in cache",
-        totalCounts0 == TFC.getTotalCounts(readers[0].indexReader, readers[0].taxReader, iParams, null));
+        totalCounts0 == TFC.getTotalCounts(readers[0].indexReader, readers[0].taxReader, iParams));
     
     // 2nd Reader - As this is the first time we have invoked the
     // TotalFacetCountsManager, we should expect a state of NEW to be returned.
-    TotalFacetCounts totalCounts1 = 
-      TFC.getTotalCounts(readers[1].indexReader, readers[1].taxReader, iParams, null);
+    TotalFacetCounts totalCounts1 = TFC.getTotalCounts(readers[1].indexReader, readers[1].taxReader, iParams);
     prevGen = assertRecomputed(totalCounts1, prevGen, "after attempt 2");
     assertTrue("attempt 2b for same input [1] shout find it in cache",
-        totalCounts1 == TFC.getTotalCounts(readers[1].indexReader, readers[1].taxReader, iParams, null));
+        totalCounts1 == TFC.getTotalCounts(readers[1].indexReader, readers[1].taxReader, iParams));
 
     // Right now cache size is one, so first TFC is gone and should be recomputed  
-    totalCounts0 = 
-      TFC.getTotalCounts(readers[0].indexReader, readers[0].taxReader, iParams, null);
+    totalCounts0 = TFC.getTotalCounts(readers[0].indexReader, readers[0].taxReader, iParams);
     prevGen = assertRecomputed(totalCounts0, prevGen, "after attempt 3");
     
     // Similarly will recompute the second result  
-    totalCounts1 = 
-      TFC.getTotalCounts(readers[1].indexReader, readers[1].taxReader, iParams, null);
+    totalCounts1 = TFC.getTotalCounts(readers[1].indexReader, readers[1].taxReader, iParams);
     prevGen = assertRecomputed(totalCounts1, prevGen, "after attempt 4");
 
     // Now we set the cache size to two, meaning both should exist in the
@@ -496,17 +492,15 @@ public class TestTotalFacetCountsCache extends LuceneTestCase {
     TFC.setCacheSize(2);
 
     // Re-compute totalCounts0 (was evicted from the cache when the cache was smaller)
-    totalCounts0 = 
-      TFC.getTotalCounts(readers[0].indexReader, readers[0].taxReader, iParams, null);
+    totalCounts0 = TFC.getTotalCounts(readers[0].indexReader, readers[0].taxReader, iParams);
     prevGen = assertRecomputed(totalCounts0, prevGen, "after attempt 5");
 
     // now both are in the larger cache and should not be recomputed 
-    totalCounts1 = TFC.getTotalCounts(readers[1].indexReader,
-        readers[1].taxReader, iParams, null);
+    totalCounts1 = TFC.getTotalCounts(readers[1].indexReader, readers[1].taxReader, iParams);
     assertTrue("with cache of size 2 res no. 0 should come from cache",
-        totalCounts0 == TFC.getTotalCounts(readers[0].indexReader, readers[0].taxReader, iParams, null));
+        totalCounts0 == TFC.getTotalCounts(readers[0].indexReader, readers[0].taxReader, iParams));
     assertTrue("with cache of size 2 res no. 1 should come from cache",
-        totalCounts1 == TFC.getTotalCounts(readers[1].indexReader, readers[1].taxReader, iParams, null));
+        totalCounts1 == TFC.getTotalCounts(readers[1].indexReader, readers[1].taxReader, iParams));
     
     writers[0].close();
     writers[1].close();
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/search/params/FacetRequestTest.java b/lucene/facet/src/test/org/apache/lucene/facet/search/params/FacetRequestTest.java
index 6d22d8b..e9db167 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/search/params/FacetRequestTest.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/search/params/FacetRequestTest.java
@@ -32,12 +32,12 @@ public class FacetRequestTest extends LuceneTestCase {
 
   @Test(expected=IllegalArgumentException.class)
   public void testIllegalNumResults() throws Exception {
-    new CountFacetRequest(new CategoryPath("a", "b"), 0);
+    assertNotNull(new CountFacetRequest(new CategoryPath("a", "b"), 0));
   }
   
   @Test(expected=IllegalArgumentException.class)
   public void testIllegalCategoryPath() throws Exception {
-    new CountFacetRequest(null, 1);
+    assertNotNull(new CountFacetRequest(null, 1));
   }
 
   @Test
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/search/params/FacetSearchParamsTest.java b/lucene/facet/src/test/org/apache/lucene/facet/search/params/FacetSearchParamsTest.java
index 33bc116..7d6253f 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/search/params/FacetSearchParamsTest.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/search/params/FacetSearchParamsTest.java
@@ -1,13 +1,5 @@
 package org.apache.lucene.facet.search.params;
 
-import org.apache.lucene.facet.index.params.FacetIndexingParams;
-import org.apache.lucene.facet.taxonomy.CategoryPath;
-import org.apache.lucene.facet.taxonomy.TaxonomyReader;
-import org.apache.lucene.facet.taxonomy.TaxonomyWriter;
-import org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyReader;
-import org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyWriter;
-import org.apache.lucene.facet.util.PartitionsUtils;
-import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
 import org.junit.Test;
 
@@ -31,28 +23,6 @@ import org.junit.Test;
 public class FacetSearchParamsTest extends LuceneTestCase {
 
   @Test
-  public void testAddFacetRequest() throws Exception {
-    FacetSearchParams fsp = new FacetSearchParams(new CountFacetRequest(new CategoryPath("a", "b"), 1));
-    assertEquals("expected 1 facet request", 1, fsp.getFacetRequests().size());
-  }
-  
-  @Test
-  public void testPartitionSizeWithCategories() throws Exception {
-    Directory dir = newDirectory();
-    TaxonomyWriter tw = new DirectoryTaxonomyWriter(dir);
-    tw.addCategory(new CategoryPath("a"));
-    tw.commit();
-    tw.close();
-    TaxonomyReader tr = new DirectoryTaxonomyReader(dir);
-    assertEquals("unexpected partition offset for 1 categories", 2,
-        PartitionsUtils.partitionOffset(FacetIndexingParams.ALL_PARENTS, 1, tr));
-    assertEquals("unexpected partition size for 1 categories", 2,
-        PartitionsUtils.partitionSize(FacetIndexingParams.ALL_PARENTS,tr));
-    tr.close();
-    dir.close();
-  }
-  
-  @Test
   public void testSearchParamsWithNullRequest() throws Exception {
     try {
       assertNull(new FacetSearchParams());
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/search/params/MultiCategoryListIteratorTest.java b/lucene/facet/src/test/org/apache/lucene/facet/search/params/MultiCategoryListIteratorTest.java
index 5265051..88a1d90 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/search/params/MultiCategoryListIteratorTest.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/search/params/MultiCategoryListIteratorTest.java
@@ -9,8 +9,7 @@ import org.apache.lucene.facet.index.FacetFields;
 import org.apache.lucene.facet.index.params.CategoryListParams;
 import org.apache.lucene.facet.index.params.PerDimensionIndexingParams;
 import org.apache.lucene.facet.search.CategoryListIterator;
-import org.apache.lucene.facet.search.PayloadCategoryListIteraor;
-import org.apache.lucene.facet.search.cache.CategoryListCache;
+import org.apache.lucene.facet.search.DocValuesCategoryListIterator;
 import org.apache.lucene.facet.taxonomy.CategoryPath;
 import org.apache.lucene.facet.taxonomy.TaxonomyReader;
 import org.apache.lucene.facet.taxonomy.TaxonomyWriter;
@@ -20,7 +19,6 @@ import org.apache.lucene.facet.util.MultiCategoryListIterator;
 import org.apache.lucene.index.AtomicReaderContext;
 import org.apache.lucene.index.DirectoryReader;
 import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.Term;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.IntsRef;
@@ -60,7 +58,7 @@ public class MultiCategoryListIteratorTest extends LuceneTestCase {
     HashMap<CategoryPath,CategoryListParams> clps = new HashMap<CategoryPath,CategoryListParams>();
     for (String dim : dimensions) {
       CategoryPath cp = new CategoryPath(dim);
-      CategoryListParams clp = new CategoryListParams(new Term("$" + dim, CategoryListParams.DEFAULT_TERM.bytes()));
+      CategoryListParams clp = new CategoryListParams("$" + dim);
       clps.put(cp, clp);
     }
     PerDimensionIndexingParams indexingParams = new PerDimensionIndexingParams(clps);
@@ -86,23 +84,13 @@ public class MultiCategoryListIteratorTest extends LuceneTestCase {
     IOUtils.close(indexWriter, taxoWriter);
     
     // test the multi iterator
-    CategoryListCache clCache = null;
-    if (random.nextBoolean()) {
-      clCache = new CategoryListCache();
-    }
-    
     DirectoryReader indexReader = DirectoryReader.open(indexDir);
     TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoDir);
     CategoryListIterator[] iterators = new CategoryListIterator[numDimensions];
     for (int i = 0; i < iterators.length; i++) {
       CategoryListParams clp = indexingParams.getCategoryListParams(new CategoryPath(dimensions[i]));
       IntDecoder decoder = clp.createEncoder().createMatchingDecoder();
-      if (clCache != null && random.nextBoolean()) {
-        clCache.loadAndRegister(clp, indexReader, taxoReader, indexingParams);
-        iterators[i] = clCache.get(clp).iterator(0); // no partitions
-      } else {
-        iterators[i] = new PayloadCategoryListIteraor(clp.getTerm(), decoder);
-      }
+      iterators[i] = new DocValuesCategoryListIterator(clp.field, decoder);
     }
     MultiCategoryListIterator cli = new MultiCategoryListIterator(iterators);
     for (AtomicReaderContext context : indexReader.leaves()) {

