GitDiffStart: 5a661500c161d92bb0249c5253d425bafbfce24f | Wed Jun 16 11:33:29 2010 +0000
diff --git a/lucene/contrib/benchmark/conf/collector-small.alg b/lucene/contrib/benchmark/conf/collector-small.alg
index f647054..c67cab9 100644
--- a/lucene/contrib/benchmark/conf/collector-small.alg
+++ b/lucene/contrib/benchmark/conf/collector-small.alg
@@ -23,7 +23,7 @@
 #    topScoreDocUnordered - Like above, but allows out of order
 collector.class=coll:topScoreDocOrdered:topScoreDocUnordered:topScoreDocOrdered:topScoreDocUnordered
 
-analyzer=org.apache.lucene.analysis.WhitespaceAnalyzer
+analyzer=org.apache.lucene.analysis.core.WhitespaceAnalyzer
 directory=FSDirectory
 #directory=RamDirectory
 
diff --git a/lucene/contrib/benchmark/conf/collector.alg b/lucene/contrib/benchmark/conf/collector.alg
index a105ad8..a80d564 100644
--- a/lucene/contrib/benchmark/conf/collector.alg
+++ b/lucene/contrib/benchmark/conf/collector.alg
@@ -23,7 +23,7 @@
 #    topScoreDocUnordered - Like above, but allows out of order
 collector.class=coll:topScoreDocOrdered:topScoreDocUnordered:topScoreDocOrdered:topScoreDocUnordered
 
-analyzer=org.apache.lucene.analysis.WhitespaceAnalyzer
+analyzer=org.apache.lucene.analysis.core.WhitespaceAnalyzer
 directory=FSDirectory
 #directory=RamDirectory
 
diff --git a/lucene/contrib/benchmark/conf/indexLineFile.alg b/lucene/contrib/benchmark/conf/indexLineFile.alg
index 2624ea3..bcb9922 100644
--- a/lucene/contrib/benchmark/conf/indexLineFile.alg
+++ b/lucene/contrib/benchmark/conf/indexLineFile.alg
@@ -29,7 +29,7 @@
 #   ant run-task -Dtask.alg=conf/indexLineFile.alg
 #
 
-analyzer=org.apache.lucene.analysis.SimpleAnalyzer
+analyzer=org.apache.lucene.analysis.core.SimpleAnalyzer
 
 # Feed that knows how to process the line file format:
 content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource
diff --git a/lucene/docs/demo2.html b/lucene/docs/demo2.html
index ebd1076..9d3f8f9 100644
--- a/lucene/docs/demo2.html
+++ b/lucene/docs/demo2.html
@@ -316,7 +316,7 @@ stop words and characters from the index.  By stop words and characters I mean c
 words such as articles (a, an, the, etc.) and other strings that may have less value for searching
 (e.g. <b>'s</b>) .  It should be noted that there are different rules for every language, and you
 should use the proper analyzer for each.  Lucene currently provides Analyzers for a number of
-different languages (see the <span class="codefrag">*Analyzer.java</span> sources under <a href="http://svn.apache.org/repos/asf/lucene/dev/trunk/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/">contrib/analyzers/src/java/org/apache/lucene/analysis</a>).
+different languages (see the <span class="codefrag">*Analyzer.java</span> sources under <a href="http://svn.apache.org/repos/asf/lucene/dev/trunk/modules/analysis/common/src/java/org/apache/lucene/analysis/">modules/analysis/common/src/java/org/apache/lucene/analysis</a>).
 </p>
 <p>
 Looking further down in the file, you should see the <span class="codefrag">indexDocs()</span> code.  This recursive
diff --git a/lucene/src/java/org/apache/lucene/analysis/package.html b/lucene/src/java/org/apache/lucene/analysis/package.html
index dd944ad..eb23fc7 100644
--- a/lucene/src/java/org/apache/lucene/analysis/package.html
+++ b/lucene/src/java/org/apache/lucene/analysis/package.html
@@ -105,7 +105,7 @@ There are many post tokenization steps that can be done, including (but not limi
     <li>{@link org.apache.lucene.analysis.PerFieldAnalyzerWrapper} &ndash; Most Analyzers perform the same operation on all
       {@link org.apache.lucene.document.Field}s.  The PerFieldAnalyzerWrapper can be used to associate a different Analyzer with different
       {@link org.apache.lucene.document.Field}s.</li>
-    <li>The contrib/analyzers library located at the root of the Lucene distribution has a number of different Analyzer implementations to solve a variety
+    <li>The modules/analysis library located at the root of the Lucene distribution has a number of different Analyzer implementations to solve a variety
     of different problems related to searching.  Many of the Analyzers are designed to analyze non-English languages.</li>
     <li>The contrib/snowball library 
         located at the root of the Lucene distribution has Analyzer and TokenFilter 
@@ -168,7 +168,7 @@ There are many post tokenization steps that can be done, including (but not limi
 <h2>Implementing your own Analyzer</h2>
 <p>Creating your own Analyzer is straightforward. It usually involves either wrapping an existing Tokenizer and  set of TokenFilters to create a new Analyzer
 or creating both the Analyzer and a Tokenizer or TokenFilter.  Before pursuing this approach, you may find it worthwhile
-to explore the contrib/analyzers library and/or ask on the java-user@lucene.apache.org mailing list first to see if what you need already exists.
+to explore the modules/analysis library and/or ask on the java-user@lucene.apache.org mailing list first to see if what you need already exists.
 If you are still committed to creating your own Analyzer or TokenStream derivation (Tokenizer or TokenFilter) have a look at
 the source code of any one of the many samples located in this package.
 </p>
diff --git a/lucene/src/site/src/documentation/content/xdocs/demo2.xml b/lucene/src/site/src/documentation/content/xdocs/demo2.xml
index 44cd327..0509b2f 100644
--- a/lucene/src/site/src/documentation/content/xdocs/demo2.xml
+++ b/lucene/src/site/src/documentation/content/xdocs/demo2.xml
@@ -74,7 +74,7 @@ words such as articles (a, an, the, etc.) and other strings that may have less v
 (e.g. <b>'s</b>) .  It should be noted that there are different rules for every language, and you
 should use the proper analyzer for each.  Lucene currently provides Analyzers for a number of
 different languages (see the <code>*Analyzer.java</code> sources under <a
-href="http://svn.apache.org/repos/asf/lucene/dev/trunk/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/">contrib/analyzers/src/java/org/apache/lucene/analysis</a>).
+href="http://svn.apache.org/repos/asf/lucene/dev/trunk/modules/analysis/common/src/java/org/apache/lucene/analysis/">modules/analysis/common/src/java/org/apache/lucene/analysis</a>).
 </p>
 
 <p>
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/snowball/SnowballAnalyzer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/snowball/SnowballAnalyzer.java
index 666d012..3766f63 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/snowball/SnowballAnalyzer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/snowball/SnowballAnalyzer.java
@@ -42,7 +42,7 @@ import java.util.Set;
  *   <li> As of 3.1, uses {@link TurkishLowerCaseFilter} for Turkish language.
  * </ul>
  * </p>
- * @deprecated Use the language-specific analyzer in contrib/analyzers instead. 
+ * @deprecated Use the language-specific analyzer in modules/analysis instead. 
  * This analyzer will be removed in Lucene 4.0
  */
 @Deprecated

