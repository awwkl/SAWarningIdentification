GitDiffStart: 88fc2e2f56a654546860b0d90f0473216e2ded8e | Fri Apr 2 04:36:13 2010 +0000
diff --git a/solr/client/javascript/README.txt b/solr/client/javascript/README.txt
index 34188b0..30de6ae 100644
--- a/solr/client/javascript/README.txt
+++ b/solr/client/javascript/README.txt
@@ -1,5 +1,5 @@
-For a Solr JavaScript Client, see:
-http://evolvingweb.github.com/ajax-solr/
-
-For information on (now deprecated) SorlJS, see:
+For a Solr JavaScript Client, see:
+http://evolvingweb.github.com/ajax-solr/
+
+For information on (now deprecated) SorlJS, see:
 http://wiki.apache.org/solr/SolrJS
\ No newline at end of file
diff --git a/solr/client/ruby/flare/vendor/plugins/engines/lib/engines/deprecated_config_support.rb b/solr/client/ruby/flare/vendor/plugins/engines/lib/engines/deprecated_config_support.rb
index 54e504c..62c43d3 100644
--- a/solr/client/ruby/flare/vendor/plugins/engines/lib/engines/deprecated_config_support.rb
+++ b/solr/client/ruby/flare/vendor/plugins/engines/lib/engines/deprecated_config_support.rb
@@ -1,135 +1,135 @@
-# This file contains support for the now-deprecated +config+ method that the engines
-# plugin provided before version 1.2. Instead of using this, plugin authors are
-# now encouraged to create their own Module configuration mechanisms; the 
-# +mattr_accessor+ mechanism provided by ActiveSupport is ideal for this:
-#
-#  module MyPlugin
-#    mattr_accessor :config_value
-#    self.config_value = "default"
-#  end
-#
-# == Using the deprecated config method
-#
-# If you require the config method to be present, change your <tt>environment.rb</tt>
-# file such that the very top of the file looks like this:
-#
-#   require File.join(File.dirname(__FILE__), 'boot')
-#   require File.join(RAILS_ROOT, "vendor", "plugins", "engines",
-#                     "lib", "engines", "deprecated_config_support")
-#
-
-
-# Adds the +config+ and +default_constant+ methods to Module.
-#
-# *IMPORTANT NOTE* - these methods are deprecated. Only use them when you have no
-# other choice. See link:files/lib/engines/deprecated_config_support_rb.html for more
-# information.
-class Module
-  # Defines a constant within a module/class ONLY if that constant does
-  # not already exist.
-  #
-  # This can be used to implement defaults in plugins/engines/libraries, e.g.
-  # if a plugin module exists:
-  #   module MyPlugin
-  #     default_constant :MyDefault, "the_default_value"
-  #   end
-  #
-  # then developers can override this default by defining that constant at
-  # some point *before* the module/plugin gets loaded (such as environment.rb)
-  def default_constant(name, value)
-    if !(name.is_a?(String) or name.is_a?(Symbol))
-      raise "Cannot use a #{name.class.name} ['#{name}'] object as a constant name"
-    end
-    if !self.const_defined?(name)
-      self.class_eval("#{name} = #{value.inspect}")
-    end
-  end
-  
-  # A mechanism for defining configuration of Modules. With this
-  # mechanism, default values for configuration can be provided within shareable
-  # code, and the end user can customise the configuration without having to
-  # provide all values.
-  #
-  # Example:
-  #
-  #  module MyModule
-  #    config :param_one, "some value"
-  #    config :param_two, 12345
-  #  end
-  #
-  # Those values can now be accessed by the following method
-  #
-  #   MyModule.config :param_one  
-  #     => "some value"
-  #   MyModule.config :param_two  
-  #     => 12345
-  #
-  # ... or, if you have overrriden the method 'config'
-  #
-  #   MyModule::CONFIG[:param_one]  
-  #     => "some value"
-  #   MyModule::CONFIG[:param_two]  
-  #     => 12345
-  #
-  # Once a value is stored in the configuration, it will not be altered
-  # by subsequent assignments, unless a special flag is given:
-  #
-  #   (later on in your code, most likely in another file)
-  #   module MyModule
-  #     config :param_one, "another value"
-  #     config :param_two, 98765, :force
-  #   end
-  #
-  # The configuration is now:
-  #
-  #   MyModule.config :param_one  
-  #     => "some value" # not changed
-  #   MyModule.config :param_two  
-  #     => 98765
-  #
-  # Configuration values can also be given as a Hash:
-  #
-  #   MyModule.config :param1 => 'value1', :param2 => 'value2'
-  #
-  # Setting of these values can also be forced:
-  #
-  #   MyModule.config :param1 => 'value3', :param2 => 'value4', :force => true
-  #
-  # A value of anything other than false or nil given for the :force key will
-  # result in the new values *always* being set.
-  def config(*args)
-    
-    raise "config expects at least one argument" if args.empty?
-    
-    # extract the arguments
-    if args[0].is_a?(Hash)
-      override = args[0][:force]
-      args[0].delete(:force)
-      args[0].each { |key, value| _handle_config(key, value, override)}
-    else
-      _handle_config(*args)
-    end
-  end
-  
-  private
-    # Actually set the config values
-    def _handle_config(name, value=nil, override=false)
-      if !self.const_defined?("CONFIG")
-        self.class_eval("CONFIG = {}")
-      end
-    
-      if value != nil
-        if override or self::CONFIG[name] == nil
-          self::CONFIG[name] = value 
-        end
-      else
-        # if we pass an array of config keys to config(),
-        # get the array of values back
-        if name.is_a? Array
-          name.map { |c| self::CONFIG[c] }
-        else
-          self::CONFIG[name]
-        end
-      end      
-    end
+# This file contains support for the now-deprecated +config+ method that the engines
+# plugin provided before version 1.2. Instead of using this, plugin authors are
+# now encouraged to create their own Module configuration mechanisms; the 
+# +mattr_accessor+ mechanism provided by ActiveSupport is ideal for this:
+#
+#  module MyPlugin
+#    mattr_accessor :config_value
+#    self.config_value = "default"
+#  end
+#
+# == Using the deprecated config method
+#
+# If you require the config method to be present, change your <tt>environment.rb</tt>
+# file such that the very top of the file looks like this:
+#
+#   require File.join(File.dirname(__FILE__), 'boot')
+#   require File.join(RAILS_ROOT, "vendor", "plugins", "engines",
+#                     "lib", "engines", "deprecated_config_support")
+#
+
+
+# Adds the +config+ and +default_constant+ methods to Module.
+#
+# *IMPORTANT NOTE* - these methods are deprecated. Only use them when you have no
+# other choice. See link:files/lib/engines/deprecated_config_support_rb.html for more
+# information.
+class Module
+  # Defines a constant within a module/class ONLY if that constant does
+  # not already exist.
+  #
+  # This can be used to implement defaults in plugins/engines/libraries, e.g.
+  # if a plugin module exists:
+  #   module MyPlugin
+  #     default_constant :MyDefault, "the_default_value"
+  #   end
+  #
+  # then developers can override this default by defining that constant at
+  # some point *before* the module/plugin gets loaded (such as environment.rb)
+  def default_constant(name, value)
+    if !(name.is_a?(String) or name.is_a?(Symbol))
+      raise "Cannot use a #{name.class.name} ['#{name}'] object as a constant name"
+    end
+    if !self.const_defined?(name)
+      self.class_eval("#{name} = #{value.inspect}")
+    end
+  end
+  
+  # A mechanism for defining configuration of Modules. With this
+  # mechanism, default values for configuration can be provided within shareable
+  # code, and the end user can customise the configuration without having to
+  # provide all values.
+  #
+  # Example:
+  #
+  #  module MyModule
+  #    config :param_one, "some value"
+  #    config :param_two, 12345
+  #  end
+  #
+  # Those values can now be accessed by the following method
+  #
+  #   MyModule.config :param_one  
+  #     => "some value"
+  #   MyModule.config :param_two  
+  #     => 12345
+  #
+  # ... or, if you have overrriden the method 'config'
+  #
+  #   MyModule::CONFIG[:param_one]  
+  #     => "some value"
+  #   MyModule::CONFIG[:param_two]  
+  #     => 12345
+  #
+  # Once a value is stored in the configuration, it will not be altered
+  # by subsequent assignments, unless a special flag is given:
+  #
+  #   (later on in your code, most likely in another file)
+  #   module MyModule
+  #     config :param_one, "another value"
+  #     config :param_two, 98765, :force
+  #   end
+  #
+  # The configuration is now:
+  #
+  #   MyModule.config :param_one  
+  #     => "some value" # not changed
+  #   MyModule.config :param_two  
+  #     => 98765
+  #
+  # Configuration values can also be given as a Hash:
+  #
+  #   MyModule.config :param1 => 'value1', :param2 => 'value2'
+  #
+  # Setting of these values can also be forced:
+  #
+  #   MyModule.config :param1 => 'value3', :param2 => 'value4', :force => true
+  #
+  # A value of anything other than false or nil given for the :force key will
+  # result in the new values *always* being set.
+  def config(*args)
+    
+    raise "config expects at least one argument" if args.empty?
+    
+    # extract the arguments
+    if args[0].is_a?(Hash)
+      override = args[0][:force]
+      args[0].delete(:force)
+      args[0].each { |key, value| _handle_config(key, value, override)}
+    else
+      _handle_config(*args)
+    end
+  end
+  
+  private
+    # Actually set the config values
+    def _handle_config(name, value=nil, override=false)
+      if !self.const_defined?("CONFIG")
+        self.class_eval("CONFIG = {}")
+      end
+    
+      if value != nil
+        if override or self::CONFIG[name] == nil
+          self::CONFIG[name] = value 
+        end
+      else
+        # if we pass an array of config keys to config(),
+        # get the array of values back
+        if name.is_a? Array
+          name.map { |c| self::CONFIG[c] }
+        else
+          self::CONFIG[name]
+        end
+      end      
+    end
 end
\ No newline at end of file
diff --git a/solr/client/ruby/solr-ruby/solr/conf/scripts.conf b/solr/client/ruby/solr-ruby/solr/conf/scripts.conf
index e993bbf..f58b262 100644
--- a/solr/client/ruby/solr-ruby/solr/conf/scripts.conf
+++ b/solr/client/ruby/solr-ruby/solr/conf/scripts.conf
@@ -1,24 +1,24 @@
-# Licensed to the Apache Software Foundation (ASF) under one or more
-# contributor license agreements.  See the NOTICE file distributed with
-# this work for additional information regarding copyright ownership.
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-user=
-solr_hostname=localhost
-solr_port=8983
-rsyncd_port=18983
-data_dir=
-webapp_name=solr
-master_host=
-master_data_dir=
-master_status_dir=
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+user=
+solr_hostname=localhost
+solr_port=8983
+rsyncd_port=18983
+data_dir=
+webapp_name=solr
+master_host=
+master_data_dir=
+master_status_dir=
diff --git a/solr/client/ruby/solr-ruby/test/conf/scripts.conf b/solr/client/ruby/solr-ruby/test/conf/scripts.conf
index e993bbf..f58b262 100644
--- a/solr/client/ruby/solr-ruby/test/conf/scripts.conf
+++ b/solr/client/ruby/solr-ruby/test/conf/scripts.conf
@@ -1,24 +1,24 @@
-# Licensed to the Apache Software Foundation (ASF) under one or more
-# contributor license agreements.  See the NOTICE file distributed with
-# this work for additional information regarding copyright ownership.
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-user=
-solr_hostname=localhost
-solr_port=8983
-rsyncd_port=18983
-data_dir=
-webapp_name=solr
-master_host=
-master_data_dir=
-master_status_dir=
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+user=
+solr_hostname=localhost
+solr_port=8983
+rsyncd_port=18983
+data_dir=
+webapp_name=solr
+master_host=
+master_data_dir=
+master_status_dir=
diff --git a/solr/contrib/dataimporthandler/src/extras/main/java/org/apache/solr/handler/dataimport/TikaEntityProcessor.java b/solr/contrib/dataimporthandler/src/extras/main/java/org/apache/solr/handler/dataimport/TikaEntityProcessor.java
index aeb64c3..ea183ae 100644
--- a/solr/contrib/dataimporthandler/src/extras/main/java/org/apache/solr/handler/dataimport/TikaEntityProcessor.java
+++ b/solr/contrib/dataimporthandler/src/extras/main/java/org/apache/solr/handler/dataimport/TikaEntityProcessor.java
@@ -1,193 +1,193 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.solr.handler.dataimport;
-
-import org.apache.commons.io.IOUtils;
-import static org.apache.solr.handler.dataimport.DataImportHandlerException.SEVERE;
-import static org.apache.solr.handler.dataimport.DataImportHandlerException.wrapAndThrow;
-import static org.apache.solr.handler.dataimport.DataImporter.COLUMN;
-import static org.apache.solr.handler.dataimport.XPathEntityProcessor.URL;
-import org.apache.tika.config.TikaConfig;
-import org.apache.tika.metadata.Metadata;
-import org.apache.tika.parser.AutoDetectParser;
-import org.apache.tika.parser.Parser;
-import org.apache.tika.parser.ParseContext;
-import org.apache.tika.sax.BodyContentHandler;
-import org.apache.tika.sax.ContentHandlerDecorator;
-import org.apache.tika.sax.XHTMLContentHandler;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-import org.xml.sax.Attributes;
-import org.xml.sax.ContentHandler;
-import org.xml.sax.SAXException;
-import org.xml.sax.helpers.DefaultHandler;
-
-import javax.xml.transform.OutputKeys;
-import javax.xml.transform.TransformerConfigurationException;
-import javax.xml.transform.sax.SAXTransformerFactory;
-import javax.xml.transform.sax.TransformerHandler;
-import javax.xml.transform.stream.StreamResult;
-import java.io.File;
-import java.io.InputStream;
-import java.io.StringWriter;
-import java.io.Writer;
-import java.util.HashMap;
-import java.util.Map;
-/**
- * <p>An implementation of EntityProcessor which reads data from rich docs using Tika
- *
- * @version $Id$
- * @since solr 1.5
- */
-public class TikaEntityProcessor extends EntityProcessorBase {
-  private TikaConfig tikaConfig;
-  private static final Logger LOG = LoggerFactory.getLogger(TikaEntityProcessor.class);
-  private String format = "text";
-  private boolean done = false;
-  private String parser;
-  static final String AUTO_PARSER = "org.apache.tika.parser.AutoDetectParser";
-
-
-  @Override
-  protected void firstInit(Context context) {
-    String tikaConfigFile = context.getResolvedEntityAttribute("tikaConfig");
-    if (tikaConfigFile == null) {
-      tikaConfig = TikaConfig.getDefaultConfig();
-    } else {
-      File configFile = new File(tikaConfigFile);
-      if (!configFile.isAbsolute()) {
-        configFile = new File(context.getSolrCore().getResourceLoader().getConfigDir(), tikaConfigFile);
-      }
-      try {
-        tikaConfig = new TikaConfig(configFile);
-      } catch (Exception e) {
-        wrapAndThrow (SEVERE, e,"Unable to load Tika Config");
-      }
-    }
-
-    format = context.getResolvedEntityAttribute("format");
-    if(format == null)
-      format = "text";
-    if (!"html".equals(format) && !"xml".equals(format) && !"text".equals(format)&& !"none".equals(format) )
-      throw new DataImportHandlerException(SEVERE, "'format' can be one of text|html|xml|none");
-    parser = context.getResolvedEntityAttribute("parser");
-    if(parser == null) {
-      parser = AUTO_PARSER;
-    }
-    done = false;
-  }
-
-  public Map<String, Object> nextRow() {
-    if(done) return null;
-    Map<String, Object> row = new HashMap<String, Object>();
-    DataSource<InputStream> dataSource = context.getDataSource();
-    InputStream is = dataSource.getData(context.getResolvedEntityAttribute(URL));
-    ContentHandler contentHandler = null;
-    Metadata metadata = new Metadata();
-    StringWriter sw = new StringWriter();
-    try {
-      if ("html".equals(format)) {
-        contentHandler = getHtmlHandler(sw);
-      } else if ("xml".equals(format)) {
-        contentHandler = getXmlContentHandler(sw);
-      } else if ("text".equals(format)) {
-        contentHandler = getTextContentHandler(sw);
-      } else if("none".equals(format)){
-        contentHandler = new DefaultHandler();        
-      }
-    } catch (TransformerConfigurationException e) {
-      wrapAndThrow(SEVERE, e, "Unable to create content handler");
-    }
-    Parser tikaParser = null;
-    if(parser.equals(AUTO_PARSER)){
-      AutoDetectParser parser = new AutoDetectParser();
-      parser.setConfig(tikaConfig);
-      tikaParser = parser;
-    } else {
-      tikaParser = (Parser) context.getSolrCore().getResourceLoader().newInstance(parser);
-    }
-    try {
-      tikaParser.parse(is, contentHandler, metadata , new ParseContext());
-    } catch (Exception e) {
-      wrapAndThrow(SEVERE, e, "Unable to read content");
-    }
-    IOUtils.closeQuietly(is);
-    for (Map<String, String> field : context.getAllEntityFields()) {
-      if (!"true".equals(field.get("meta"))) continue;
-      String col = field.get(COLUMN);
-      String s = metadata.get(col);
-      if (s != null) row.put(col, s);
-    }
-    if(!"none".equals(format) ) row.put("text", sw.toString());
-    done = true;
-    return row;
-  }
-
-  private static ContentHandler getHtmlHandler(Writer writer)
-          throws TransformerConfigurationException {
-    SAXTransformerFactory factory = (SAXTransformerFactory)
-            SAXTransformerFactory.newInstance();
-    TransformerHandler handler = factory.newTransformerHandler();
-    handler.getTransformer().setOutputProperty(OutputKeys.METHOD, "html");
-    handler.setResult(new StreamResult(writer));
-    return new ContentHandlerDecorator(handler) {
-      @Override
-      public void startElement(
-              String uri, String localName, String name, Attributes atts)
-              throws SAXException {
-        if (XHTMLContentHandler.XHTML.equals(uri)) {
-          uri = null;
-        }
-        if (!"head".equals(localName)) {
-          super.startElement(uri, localName, name, atts);
-        }
-      }
-
-      @Override
-      public void endElement(String uri, String localName, String name)
-              throws SAXException {
-        if (XHTMLContentHandler.XHTML.equals(uri)) {
-          uri = null;
-        }
-        if (!"head".equals(localName)) {
-          super.endElement(uri, localName, name);
-        }
-      }
-
-      @Override
-      public void startPrefixMapping(String prefix, String uri) {/*no op*/ }
-
-      @Override
-      public void endPrefixMapping(String prefix) {/*no op*/ }
-    };
-  }
-
-  private static ContentHandler getTextContentHandler(Writer writer) {
-    return new BodyContentHandler(writer);
-  }
-
-  private static ContentHandler getXmlContentHandler(Writer writer)
-          throws TransformerConfigurationException {
-    SAXTransformerFactory factory = (SAXTransformerFactory)
-            SAXTransformerFactory.newInstance();
-    TransformerHandler handler = factory.newTransformerHandler();
-    handler.getTransformer().setOutputProperty(OutputKeys.METHOD, "xml");
-    handler.setResult(new StreamResult(writer));
-    return handler;
-  }
-
-}
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.solr.handler.dataimport;
+
+import org.apache.commons.io.IOUtils;
+import static org.apache.solr.handler.dataimport.DataImportHandlerException.SEVERE;
+import static org.apache.solr.handler.dataimport.DataImportHandlerException.wrapAndThrow;
+import static org.apache.solr.handler.dataimport.DataImporter.COLUMN;
+import static org.apache.solr.handler.dataimport.XPathEntityProcessor.URL;
+import org.apache.tika.config.TikaConfig;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.parser.AutoDetectParser;
+import org.apache.tika.parser.Parser;
+import org.apache.tika.parser.ParseContext;
+import org.apache.tika.sax.BodyContentHandler;
+import org.apache.tika.sax.ContentHandlerDecorator;
+import org.apache.tika.sax.XHTMLContentHandler;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.xml.sax.Attributes;
+import org.xml.sax.ContentHandler;
+import org.xml.sax.SAXException;
+import org.xml.sax.helpers.DefaultHandler;
+
+import javax.xml.transform.OutputKeys;
+import javax.xml.transform.TransformerConfigurationException;
+import javax.xml.transform.sax.SAXTransformerFactory;
+import javax.xml.transform.sax.TransformerHandler;
+import javax.xml.transform.stream.StreamResult;
+import java.io.File;
+import java.io.InputStream;
+import java.io.StringWriter;
+import java.io.Writer;
+import java.util.HashMap;
+import java.util.Map;
+/**
+ * <p>An implementation of EntityProcessor which reads data from rich docs using Tika
+ *
+ * @version $Id$
+ * @since solr 1.5
+ */
+public class TikaEntityProcessor extends EntityProcessorBase {
+  private TikaConfig tikaConfig;
+  private static final Logger LOG = LoggerFactory.getLogger(TikaEntityProcessor.class);
+  private String format = "text";
+  private boolean done = false;
+  private String parser;
+  static final String AUTO_PARSER = "org.apache.tika.parser.AutoDetectParser";
+
+
+  @Override
+  protected void firstInit(Context context) {
+    String tikaConfigFile = context.getResolvedEntityAttribute("tikaConfig");
+    if (tikaConfigFile == null) {
+      tikaConfig = TikaConfig.getDefaultConfig();
+    } else {
+      File configFile = new File(tikaConfigFile);
+      if (!configFile.isAbsolute()) {
+        configFile = new File(context.getSolrCore().getResourceLoader().getConfigDir(), tikaConfigFile);
+      }
+      try {
+        tikaConfig = new TikaConfig(configFile);
+      } catch (Exception e) {
+        wrapAndThrow (SEVERE, e,"Unable to load Tika Config");
+      }
+    }
+
+    format = context.getResolvedEntityAttribute("format");
+    if(format == null)
+      format = "text";
+    if (!"html".equals(format) && !"xml".equals(format) && !"text".equals(format)&& !"none".equals(format) )
+      throw new DataImportHandlerException(SEVERE, "'format' can be one of text|html|xml|none");
+    parser = context.getResolvedEntityAttribute("parser");
+    if(parser == null) {
+      parser = AUTO_PARSER;
+    }
+    done = false;
+  }
+
+  public Map<String, Object> nextRow() {
+    if(done) return null;
+    Map<String, Object> row = new HashMap<String, Object>();
+    DataSource<InputStream> dataSource = context.getDataSource();
+    InputStream is = dataSource.getData(context.getResolvedEntityAttribute(URL));
+    ContentHandler contentHandler = null;
+    Metadata metadata = new Metadata();
+    StringWriter sw = new StringWriter();
+    try {
+      if ("html".equals(format)) {
+        contentHandler = getHtmlHandler(sw);
+      } else if ("xml".equals(format)) {
+        contentHandler = getXmlContentHandler(sw);
+      } else if ("text".equals(format)) {
+        contentHandler = getTextContentHandler(sw);
+      } else if("none".equals(format)){
+        contentHandler = new DefaultHandler();        
+      }
+    } catch (TransformerConfigurationException e) {
+      wrapAndThrow(SEVERE, e, "Unable to create content handler");
+    }
+    Parser tikaParser = null;
+    if(parser.equals(AUTO_PARSER)){
+      AutoDetectParser parser = new AutoDetectParser();
+      parser.setConfig(tikaConfig);
+      tikaParser = parser;
+    } else {
+      tikaParser = (Parser) context.getSolrCore().getResourceLoader().newInstance(parser);
+    }
+    try {
+      tikaParser.parse(is, contentHandler, metadata , new ParseContext());
+    } catch (Exception e) {
+      wrapAndThrow(SEVERE, e, "Unable to read content");
+    }
+    IOUtils.closeQuietly(is);
+    for (Map<String, String> field : context.getAllEntityFields()) {
+      if (!"true".equals(field.get("meta"))) continue;
+      String col = field.get(COLUMN);
+      String s = metadata.get(col);
+      if (s != null) row.put(col, s);
+    }
+    if(!"none".equals(format) ) row.put("text", sw.toString());
+    done = true;
+    return row;
+  }
+
+  private static ContentHandler getHtmlHandler(Writer writer)
+          throws TransformerConfigurationException {
+    SAXTransformerFactory factory = (SAXTransformerFactory)
+            SAXTransformerFactory.newInstance();
+    TransformerHandler handler = factory.newTransformerHandler();
+    handler.getTransformer().setOutputProperty(OutputKeys.METHOD, "html");
+    handler.setResult(new StreamResult(writer));
+    return new ContentHandlerDecorator(handler) {
+      @Override
+      public void startElement(
+              String uri, String localName, String name, Attributes atts)
+              throws SAXException {
+        if (XHTMLContentHandler.XHTML.equals(uri)) {
+          uri = null;
+        }
+        if (!"head".equals(localName)) {
+          super.startElement(uri, localName, name, atts);
+        }
+      }
+
+      @Override
+      public void endElement(String uri, String localName, String name)
+              throws SAXException {
+        if (XHTMLContentHandler.XHTML.equals(uri)) {
+          uri = null;
+        }
+        if (!"head".equals(localName)) {
+          super.endElement(uri, localName, name);
+        }
+      }
+
+      @Override
+      public void startPrefixMapping(String prefix, String uri) {/*no op*/ }
+
+      @Override
+      public void endPrefixMapping(String prefix) {/*no op*/ }
+    };
+  }
+
+  private static ContentHandler getTextContentHandler(Writer writer) {
+    return new BodyContentHandler(writer);
+  }
+
+  private static ContentHandler getXmlContentHandler(Writer writer)
+          throws TransformerConfigurationException {
+    SAXTransformerFactory factory = (SAXTransformerFactory)
+            SAXTransformerFactory.newInstance();
+    TransformerHandler handler = factory.newTransformerHandler();
+    handler.getTransformer().setOutputProperty(OutputKeys.METHOD, "xml");
+    handler.setResult(new StreamResult(writer));
+    return handler;
+  }
+
+}
diff --git a/solr/contrib/dataimporthandler/src/extras/test/java/org/apache/solr/handler/dataimport/TestTikaEntityProcessor.java b/solr/contrib/dataimporthandler/src/extras/test/java/org/apache/solr/handler/dataimport/TestTikaEntityProcessor.java
index 35059e7..d2adc5a 100644
--- a/solr/contrib/dataimporthandler/src/extras/test/java/org/apache/solr/handler/dataimport/TestTikaEntityProcessor.java
+++ b/solr/contrib/dataimporthandler/src/extras/test/java/org/apache/solr/handler/dataimport/TestTikaEntityProcessor.java
@@ -1,61 +1,61 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.solr.handler.dataimport;
-
-import org.junit.After;
-import org.junit.Before;
-
-/**Testcase for TikaEntityProcessor
- * @version $Id$
- * @since solr 1.5 
- */
-public class TestTikaEntityProcessor extends AbstractDataImportHandlerTest {
-
-  @Before
-  public void setUp() throws Exception {
-    super.setUp();
-  }
-
-  @After
-  public void tearDown() throws Exception {
-    super.tearDown();
-  }
-
-  public String getSchemaFile() {
-    return "dataimport-schema-no-unique-key.xml";
-  }
-
-  public String getSolrConfigFile() {
-    return "dataimport-solrconfig.xml";
-  }
-
-  public void testIndexingWithTikaEntityProcessor() throws Exception {
-    String conf =
-            "<dataConfig>" +
-                    "  <dataSource type=\"BinFileDataSource\"/>" +
-                    "  <document>" +
-                    "    <entity processor=\"TikaEntityProcessor\" url=\"../../../../../extraction/src/test/resources/solr-word.pdf\" >" +
-                    "      <field column=\"Author\" meta=\"true\" name=\"author\"/>" +
-                    "      <field column=\"title\" meta=\"true\" name=\"docTitle\"/>" +
-                    "      <field column=\"text\"/>" +
-                    "     </entity>" +
-                    "  </document>" +
-                    "</dataConfig>";
-    super.runFullImport(conf);
-    assertQ(req("*:*"), "//*[@numFound='1']");
-  }
-}
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.solr.handler.dataimport;
+
+import org.junit.After;
+import org.junit.Before;
+
+/**Testcase for TikaEntityProcessor
+ * @version $Id$
+ * @since solr 1.5 
+ */
+public class TestTikaEntityProcessor extends AbstractDataImportHandlerTest {
+
+  @Before
+  public void setUp() throws Exception {
+    super.setUp();
+  }
+
+  @After
+  public void tearDown() throws Exception {
+    super.tearDown();
+  }
+
+  public String getSchemaFile() {
+    return "dataimport-schema-no-unique-key.xml";
+  }
+
+  public String getSolrConfigFile() {
+    return "dataimport-solrconfig.xml";
+  }
+
+  public void testIndexingWithTikaEntityProcessor() throws Exception {
+    String conf =
+            "<dataConfig>" +
+                    "  <dataSource type=\"BinFileDataSource\"/>" +
+                    "  <document>" +
+                    "    <entity processor=\"TikaEntityProcessor\" url=\"../../../../../extraction/src/test/resources/solr-word.pdf\" >" +
+                    "      <field column=\"Author\" meta=\"true\" name=\"author\"/>" +
+                    "      <field column=\"title\" meta=\"true\" name=\"docTitle\"/>" +
+                    "      <field column=\"text\"/>" +
+                    "     </entity>" +
+                    "  </document>" +
+                    "</dataConfig>";
+    super.runFullImport(conf);
+    assertQ(req("*:*"), "//*[@numFound='1']");
+  }
+}
diff --git a/solr/contrib/dataimporthandler/src/extras/test/resources/solr/conf/dataimport-schema-no-unique-key.xml b/solr/contrib/dataimporthandler/src/extras/test/resources/solr/conf/dataimport-schema-no-unique-key.xml
index 4d023e7..b1ec8be 100644
--- a/solr/contrib/dataimporthandler/src/extras/test/resources/solr/conf/dataimport-schema-no-unique-key.xml
+++ b/solr/contrib/dataimporthandler/src/extras/test/resources/solr/conf/dataimport-schema-no-unique-key.xml
@@ -1,205 +1,205 @@
-<?xml version="1.0" encoding="UTF-8" ?>
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-
-<!--  
- This is the Solr schema file. This file should be named "schema.xml" and
- should be in the conf directory under the solr home
- (i.e. ./solr/conf/schema.xml by default) 
- or located where the classloader for the Solr webapp can find it.
-
- This example schema is the recommended starting point for users.
- It should be kept correct and concise, usable out-of-the-box.
-
- For more information, on how to customize this file, please see
- http://wiki.apache.org/solr/SchemaXml
--->
-
-<schema name="test" version="1.2">
-  <!-- attribute "name" is the name of this schema and is only used for display purposes.
-       Applications should change this to reflect the nature of the search collection.
-       version="1.1" is Solr's version number for the schema syntax and semantics.  It should
-       not normally be changed by applications.
-       1.0: multiValued attribute did not exist, all fields are multiValued by nature
-       1.1: multiValued attribute introduced, false by default -->
-
-  <types>
-    <!-- field type definitions. The "name" attribute is
-       just a label to be used by field definitions.  The "class"
-       attribute and any other attributes determine the real
-       behavior of the fieldType.
-         Class names starting with "solr" refer to java classes in the
-       org.apache.solr.analysis package.
-    -->
-
-    <!-- The StrField type is not analyzed, but indexed/stored verbatim.  
-       - StrField and TextField support an optional compressThreshold which
-       limits compression (if enabled in the derived fields) to values which
-       exceed a certain size (in characters).
-    -->
-    <fieldType name="string" class="solr.StrField" sortMissingLast="true" omitNorms="true"/>
-
-    <!-- boolean type: "true" or "false" -->
-    <fieldType name="boolean" class="solr.BoolField" sortMissingLast="true" omitNorms="true"/>
-
-    <!-- The optional sortMissingLast and sortMissingFirst attributes are
-         currently supported on types that are sorted internally as strings.
-       - If sortMissingLast="true", then a sort on this field will cause documents
-         without the field to come after documents with the field,
-         regardless of the requested sort order (asc or desc).
-       - If sortMissingFirst="true", then a sort on this field will cause documents
-         without the field to come before documents with the field,
-         regardless of the requested sort order.
-       - If sortMissingLast="false" and sortMissingFirst="false" (the default),
-         then default lucene sorting will be used which places docs without the
-         field first in an ascending sort and last in a descending sort.
-    -->    
-
-
-    <!-- numeric field types that store and index the text
-         value verbatim (and hence don't support range queries, since the
-         lexicographic ordering isn't equal to the numeric ordering) -->
-    <fieldType name="integer" class="solr.IntField" omitNorms="true"/>
-    <fieldType name="long" class="solr.LongField" omitNorms="true"/>
-    <fieldType name="float" class="solr.FloatField" omitNorms="true"/>
-    <fieldType name="double" class="solr.DoubleField" omitNorms="true"/>
-
-
-    <!-- Numeric field types that manipulate the value into
-         a string value that isn't human-readable in its internal form,
-         but with a lexicographic ordering the same as the numeric ordering,
-         so that range queries work correctly. -->
-    <fieldType name="sint" class="solr.SortableIntField" sortMissingLast="true" omitNorms="true"/>
-    <fieldType name="slong" class="solr.SortableLongField" sortMissingLast="true" omitNorms="true"/>
-    <fieldType name="sfloat" class="solr.SortableFloatField" sortMissingLast="true" omitNorms="true"/>
-    <fieldType name="sdouble" class="solr.SortableDoubleField" sortMissingLast="true" omitNorms="true"/>
-
-
-    <!-- The format for this date field is of the form 1995-12-31T23:59:59Z, and
-         is a more restricted form of the canonical representation of dateTime
-         http://www.w3.org/TR/xmlschema-2/#dateTime    
-         The trailing "Z" designates UTC time and is mandatory.
-         Optional fractional seconds are allowed: 1995-12-31T23:59:59.999Z
-         All other components are mandatory.
-
-         Expressions can also be used to denote calculations that should be
-         performed relative to "NOW" to determine the value, ie...
-
-               NOW/HOUR
-                  ... Round to the start of the current hour
-               NOW-1DAY
-                  ... Exactly 1 day prior to now
-               NOW/DAY+6MONTHS+3DAYS
-                  ... 6 months and 3 days in the future from the start of
-                      the current day
-                      
-         Consult the DateField javadocs for more information.
-      -->
-    <fieldType name="date" class="solr.DateField" sortMissingLast="true" omitNorms="true"/>
-
-
-    <!-- The "RandomSortField" is not used to store or search any
-         data.  You can declare fields of this type it in your schema
-         to generate psuedo-random orderings of your docs for sorting 
-         purposes.  The ordering is generated based on the field name 
-         and the version of the index, As long as the index version
-         remains unchanged, and the same field name is reused,
-         the ordering of the docs will be consistent.  
-         If you want differend psuedo-random orderings of documents,
-         for the same version of the index, use a dynamicField and
-         change the name
-     -->
-    <fieldType name="random" class="solr.RandomSortField" indexed="true" />
-
-    <!-- solr.TextField allows the specification of custom text analyzers
-         specified as a tokenizer and a list of token filters. Different
-         analyzers may be specified for indexing and querying.
-
-         The optional positionIncrementGap puts space between multiple fields of
-         this type on the same document, with the purpose of preventing false phrase
-         matching across fields.
-
-         For more info on customizing your analyzer chain, please see
-         http://wiki.apache.org/solr/AnalyzersTokenizersTokenFilters
-     -->
-
-    <!-- One can also specify an existing Analyzer class that has a
-         default constructor via the class attribute on the analyzer element
-    <fieldType name="text_greek" class="solr.TextField">
-      <analyzer class="org.apache.lucene.analysis.el.GreekAnalyzer"/>
-    </fieldType>
-    -->
-
-    <!-- A text field that only splits on whitespace for exact matching of words -->
-    <fieldType name="text_ws" class="solr.TextField" positionIncrementGap="100">
-      <analyzer>
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-      </analyzer>
-    </fieldType>
-
-    <!-- A text field that uses WordDelimiterFilter to enable splitting and matching of
-        words on case-change, alpha numeric boundaries, and non-alphanumeric chars,
-        so that a query of "wifi" or "wi fi" could match a document containing "Wi-Fi".
-        Synonyms and stopwords are customized by external files, and stemming is enabled.
-        Duplicate tokens at the same position (which may result from Stemmed Synonyms or
-        WordDelim parts) are removed.
-        -->
-    <fieldType name="text" class="solr.TextField" positionIncrementGap="100">
-      <analyzer type="index">
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-        <!-- in this example, we will only use synonyms at query time
-        <filter class="solr.SynonymFilterFactory" synonyms="index_synonyms.txt" ignoreCase="true" expand="false"/>
-        -->
-        <!--<filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt"/>-->
-        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="1" catenateNumbers="1" catenateAll="0" splitOnCaseChange="1"/>
-        <filter class="solr.LowerCaseFilterFactory"/>
-        <!--<filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
-        <filter class="solr.PorterStemFilterFactory"/>-->
-        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
-      </analyzer>
-      <analyzer type="query">
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-        <!--<filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt" ignoreCase="true" expand="true"/>-->
-        <!--<filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt"/>-->
-        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="0" catenateNumbers="0" catenateAll="0" splitOnCaseChange="1"/>
-        <filter class="solr.LowerCaseFilterFactory"/>
-        <!--<filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
-        <filter class="solr.PorterStemFilterFactory"/>-->
-        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
-      </analyzer>
-    </fieldType>
-    <!-- since fields of this type are by default not stored or indexed, any data added to 
-         them will be ignored outright 
-     --> 
-    <fieldtype name="ignored" stored="false" indexed="false" class="solr.StrField" /> 
-
- </types>
-
-
- <fields>
-   <field name="title" type="string" indexed="true" stored="true"/>
-   <field name="author" type="string" indexed="true" stored="true" />
-   <field name="text" type="text" indexed="true" stored="true" />
-   
- </fields>
- <!-- field for the QueryParser to use when an explicit fieldname is absent -->
- <defaultSearchField>text</defaultSearchField>
-
- <!-- SolrQueryParser configuration: defaultOperator="AND|OR" -->
- <solrQueryParser defaultOperator="OR"/>
-
-</schema>
+<?xml version="1.0" encoding="UTF-8" ?>
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+
+<!--  
+ This is the Solr schema file. This file should be named "schema.xml" and
+ should be in the conf directory under the solr home
+ (i.e. ./solr/conf/schema.xml by default) 
+ or located where the classloader for the Solr webapp can find it.
+
+ This example schema is the recommended starting point for users.
+ It should be kept correct and concise, usable out-of-the-box.
+
+ For more information, on how to customize this file, please see
+ http://wiki.apache.org/solr/SchemaXml
+-->
+
+<schema name="test" version="1.2">
+  <!-- attribute "name" is the name of this schema and is only used for display purposes.
+       Applications should change this to reflect the nature of the search collection.
+       version="1.1" is Solr's version number for the schema syntax and semantics.  It should
+       not normally be changed by applications.
+       1.0: multiValued attribute did not exist, all fields are multiValued by nature
+       1.1: multiValued attribute introduced, false by default -->
+
+  <types>
+    <!-- field type definitions. The "name" attribute is
+       just a label to be used by field definitions.  The "class"
+       attribute and any other attributes determine the real
+       behavior of the fieldType.
+         Class names starting with "solr" refer to java classes in the
+       org.apache.solr.analysis package.
+    -->
+
+    <!-- The StrField type is not analyzed, but indexed/stored verbatim.  
+       - StrField and TextField support an optional compressThreshold which
+       limits compression (if enabled in the derived fields) to values which
+       exceed a certain size (in characters).
+    -->
+    <fieldType name="string" class="solr.StrField" sortMissingLast="true" omitNorms="true"/>
+
+    <!-- boolean type: "true" or "false" -->
+    <fieldType name="boolean" class="solr.BoolField" sortMissingLast="true" omitNorms="true"/>
+
+    <!-- The optional sortMissingLast and sortMissingFirst attributes are
+         currently supported on types that are sorted internally as strings.
+       - If sortMissingLast="true", then a sort on this field will cause documents
+         without the field to come after documents with the field,
+         regardless of the requested sort order (asc or desc).
+       - If sortMissingFirst="true", then a sort on this field will cause documents
+         without the field to come before documents with the field,
+         regardless of the requested sort order.
+       - If sortMissingLast="false" and sortMissingFirst="false" (the default),
+         then default lucene sorting will be used which places docs without the
+         field first in an ascending sort and last in a descending sort.
+    -->    
+
+
+    <!-- numeric field types that store and index the text
+         value verbatim (and hence don't support range queries, since the
+         lexicographic ordering isn't equal to the numeric ordering) -->
+    <fieldType name="integer" class="solr.IntField" omitNorms="true"/>
+    <fieldType name="long" class="solr.LongField" omitNorms="true"/>
+    <fieldType name="float" class="solr.FloatField" omitNorms="true"/>
+    <fieldType name="double" class="solr.DoubleField" omitNorms="true"/>
+
+
+    <!-- Numeric field types that manipulate the value into
+         a string value that isn't human-readable in its internal form,
+         but with a lexicographic ordering the same as the numeric ordering,
+         so that range queries work correctly. -->
+    <fieldType name="sint" class="solr.SortableIntField" sortMissingLast="true" omitNorms="true"/>
+    <fieldType name="slong" class="solr.SortableLongField" sortMissingLast="true" omitNorms="true"/>
+    <fieldType name="sfloat" class="solr.SortableFloatField" sortMissingLast="true" omitNorms="true"/>
+    <fieldType name="sdouble" class="solr.SortableDoubleField" sortMissingLast="true" omitNorms="true"/>
+
+
+    <!-- The format for this date field is of the form 1995-12-31T23:59:59Z, and
+         is a more restricted form of the canonical representation of dateTime
+         http://www.w3.org/TR/xmlschema-2/#dateTime    
+         The trailing "Z" designates UTC time and is mandatory.
+         Optional fractional seconds are allowed: 1995-12-31T23:59:59.999Z
+         All other components are mandatory.
+
+         Expressions can also be used to denote calculations that should be
+         performed relative to "NOW" to determine the value, ie...
+
+               NOW/HOUR
+                  ... Round to the start of the current hour
+               NOW-1DAY
+                  ... Exactly 1 day prior to now
+               NOW/DAY+6MONTHS+3DAYS
+                  ... 6 months and 3 days in the future from the start of
+                      the current day
+                      
+         Consult the DateField javadocs for more information.
+      -->
+    <fieldType name="date" class="solr.DateField" sortMissingLast="true" omitNorms="true"/>
+
+
+    <!-- The "RandomSortField" is not used to store or search any
+         data.  You can declare fields of this type it in your schema
+         to generate psuedo-random orderings of your docs for sorting 
+         purposes.  The ordering is generated based on the field name 
+         and the version of the index, As long as the index version
+         remains unchanged, and the same field name is reused,
+         the ordering of the docs will be consistent.  
+         If you want differend psuedo-random orderings of documents,
+         for the same version of the index, use a dynamicField and
+         change the name
+     -->
+    <fieldType name="random" class="solr.RandomSortField" indexed="true" />
+
+    <!-- solr.TextField allows the specification of custom text analyzers
+         specified as a tokenizer and a list of token filters. Different
+         analyzers may be specified for indexing and querying.
+
+         The optional positionIncrementGap puts space between multiple fields of
+         this type on the same document, with the purpose of preventing false phrase
+         matching across fields.
+
+         For more info on customizing your analyzer chain, please see
+         http://wiki.apache.org/solr/AnalyzersTokenizersTokenFilters
+     -->
+
+    <!-- One can also specify an existing Analyzer class that has a
+         default constructor via the class attribute on the analyzer element
+    <fieldType name="text_greek" class="solr.TextField">
+      <analyzer class="org.apache.lucene.analysis.el.GreekAnalyzer"/>
+    </fieldType>
+    -->
+
+    <!-- A text field that only splits on whitespace for exact matching of words -->
+    <fieldType name="text_ws" class="solr.TextField" positionIncrementGap="100">
+      <analyzer>
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+      </analyzer>
+    </fieldType>
+
+    <!-- A text field that uses WordDelimiterFilter to enable splitting and matching of
+        words on case-change, alpha numeric boundaries, and non-alphanumeric chars,
+        so that a query of "wifi" or "wi fi" could match a document containing "Wi-Fi".
+        Synonyms and stopwords are customized by external files, and stemming is enabled.
+        Duplicate tokens at the same position (which may result from Stemmed Synonyms or
+        WordDelim parts) are removed.
+        -->
+    <fieldType name="text" class="solr.TextField" positionIncrementGap="100">
+      <analyzer type="index">
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+        <!-- in this example, we will only use synonyms at query time
+        <filter class="solr.SynonymFilterFactory" synonyms="index_synonyms.txt" ignoreCase="true" expand="false"/>
+        -->
+        <!--<filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt"/>-->
+        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="1" catenateNumbers="1" catenateAll="0" splitOnCaseChange="1"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <!--<filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
+        <filter class="solr.PorterStemFilterFactory"/>-->
+        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
+      </analyzer>
+      <analyzer type="query">
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+        <!--<filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt" ignoreCase="true" expand="true"/>-->
+        <!--<filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt"/>-->
+        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="0" catenateNumbers="0" catenateAll="0" splitOnCaseChange="1"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <!--<filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
+        <filter class="solr.PorterStemFilterFactory"/>-->
+        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
+      </analyzer>
+    </fieldType>
+    <!-- since fields of this type are by default not stored or indexed, any data added to 
+         them will be ignored outright 
+     --> 
+    <fieldtype name="ignored" stored="false" indexed="false" class="solr.StrField" /> 
+
+ </types>
+
+
+ <fields>
+   <field name="title" type="string" indexed="true" stored="true"/>
+   <field name="author" type="string" indexed="true" stored="true" />
+   <field name="text" type="text" indexed="true" stored="true" />
+   
+ </fields>
+ <!-- field for the QueryParser to use when an explicit fieldname is absent -->
+ <defaultSearchField>text</defaultSearchField>
+
+ <!-- SolrQueryParser configuration: defaultOperator="AND|OR" -->
+ <solrQueryParser defaultOperator="OR"/>
+
+</schema>
diff --git a/solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/BinContentStreamDataSource.java b/solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/BinContentStreamDataSource.java
index cf37ec6..221d8ea 100644
--- a/solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/BinContentStreamDataSource.java
+++ b/solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/BinContentStreamDataSource.java
@@ -1,68 +1,68 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.solr.handler.dataimport;
-
-import org.apache.solr.common.util.ContentStream;
-import static org.apache.solr.handler.dataimport.DataImportHandlerException.SEVERE;
-
-import java.io.InputStream;
-import java.io.IOException;
-import java.util.Properties;
-/**
- * <p> A data source implementation which can be used to read binary stream from content streams. </p> <p/> <p> Refer to <a
- * href="http://wiki.apache.org/solr/DataImportHandler">http://wiki.apache.org/solr/DataImportHandler</a> for more
- * details. </p>
- * <p/>
- * <b>This API is experimental and may change in the future.</b>
- *
- * @version $Id$
- * @since solr 1.5
- */
-
-public class BinContentStreamDataSource extends DataSource<InputStream> {
-  private ContextImpl context;
-  private ContentStream contentStream;
-  private InputStream in;
-
-
-  public void init(Context context, Properties initProps) {
-    this.context = (ContextImpl) context;
-  }
-
-  public InputStream getData(String query) {
-     contentStream = context.getDocBuilder().requestParameters.contentStream;
-    if (contentStream == null)
-      throw new DataImportHandlerException(SEVERE, "No stream available. The request has no body");
-    try {
-      return in = contentStream.getStream();
-    } catch (IOException e) {
-      DataImportHandlerException.wrapAndThrow(SEVERE, e);
-      return null;
-    }
-  }
-
-  public void close() {
-     if (contentStream != null) {
-      try {
-        if (in == null) in = contentStream.getStream();
-        in.close();
-      } catch (IOException e) {
-        /*no op*/
-      }
-    } 
-  }
-}
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.solr.handler.dataimport;
+
+import org.apache.solr.common.util.ContentStream;
+import static org.apache.solr.handler.dataimport.DataImportHandlerException.SEVERE;
+
+import java.io.InputStream;
+import java.io.IOException;
+import java.util.Properties;
+/**
+ * <p> A data source implementation which can be used to read binary stream from content streams. </p> <p/> <p> Refer to <a
+ * href="http://wiki.apache.org/solr/DataImportHandler">http://wiki.apache.org/solr/DataImportHandler</a> for more
+ * details. </p>
+ * <p/>
+ * <b>This API is experimental and may change in the future.</b>
+ *
+ * @version $Id$
+ * @since solr 1.5
+ */
+
+public class BinContentStreamDataSource extends DataSource<InputStream> {
+  private ContextImpl context;
+  private ContentStream contentStream;
+  private InputStream in;
+
+
+  public void init(Context context, Properties initProps) {
+    this.context = (ContextImpl) context;
+  }
+
+  public InputStream getData(String query) {
+     contentStream = context.getDocBuilder().requestParameters.contentStream;
+    if (contentStream == null)
+      throw new DataImportHandlerException(SEVERE, "No stream available. The request has no body");
+    try {
+      return in = contentStream.getStream();
+    } catch (IOException e) {
+      DataImportHandlerException.wrapAndThrow(SEVERE, e);
+      return null;
+    }
+  }
+
+  public void close() {
+     if (contentStream != null) {
+      try {
+        if (in == null) in = contentStream.getStream();
+        in.close();
+      } catch (IOException e) {
+        /*no op*/
+      }
+    } 
+  }
+}
diff --git a/solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/BinFileDataSource.java b/solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/BinFileDataSource.java
index 769ab63..4d4cdeb 100644
--- a/solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/BinFileDataSource.java
+++ b/solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/BinFileDataSource.java
@@ -1,63 +1,63 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.solr.handler.dataimport;
-
-import static org.apache.solr.handler.dataimport.DataImportHandlerException.wrapAndThrow;
-import static org.apache.solr.handler.dataimport.DataImportHandlerException.SEVERE;
-
-import java.io.InputStream;
-import java.io.File;
-import java.io.FileInputStream;
-import java.io.FileNotFoundException;
-import java.util.Properties;
-/**
- * <p>
- * A DataSource which reads from local files
- * </p>
- * <p/>
- * <p>
- * Refer to <a
- * href="http://wiki.apache.org/solr/DataImportHandler">http://wiki.apache.org/solr/DataImportHandler</a>
- * for more details.
- * </p>
- * <p/>
- * <b>This API is experimental and may change in the future.</b>
- *
- * @version $Id$
- * @since solr 1.5
- */
-
-public class BinFileDataSource extends DataSource<InputStream>{
-   protected String basePath;
-  public void init(Context context, Properties initProps) {
-     basePath = initProps.getProperty(FileDataSource.BASE_PATH);
-  }
-
-  public InputStream getData(String query) {
-    File f = FileDataSource.getFile(basePath,query);
-    try {
-      return new FileInputStream(f);
-    } catch (FileNotFoundException e) {
-      wrapAndThrow(SEVERE,e,"Unable to open file "+f.getAbsolutePath());
-      return null;
-    }
-  }
-
-  public void close() {
-
-  }
-}
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.solr.handler.dataimport;
+
+import static org.apache.solr.handler.dataimport.DataImportHandlerException.wrapAndThrow;
+import static org.apache.solr.handler.dataimport.DataImportHandlerException.SEVERE;
+
+import java.io.InputStream;
+import java.io.File;
+import java.io.FileInputStream;
+import java.io.FileNotFoundException;
+import java.util.Properties;
+/**
+ * <p>
+ * A DataSource which reads from local files
+ * </p>
+ * <p/>
+ * <p>
+ * Refer to <a
+ * href="http://wiki.apache.org/solr/DataImportHandler">http://wiki.apache.org/solr/DataImportHandler</a>
+ * for more details.
+ * </p>
+ * <p/>
+ * <b>This API is experimental and may change in the future.</b>
+ *
+ * @version $Id$
+ * @since solr 1.5
+ */
+
+public class BinFileDataSource extends DataSource<InputStream>{
+   protected String basePath;
+  public void init(Context context, Properties initProps) {
+     basePath = initProps.getProperty(FileDataSource.BASE_PATH);
+  }
+
+  public InputStream getData(String query) {
+    File f = FileDataSource.getFile(basePath,query);
+    try {
+      return new FileInputStream(f);
+    } catch (FileNotFoundException e) {
+      wrapAndThrow(SEVERE,e,"Unable to open file "+f.getAbsolutePath());
+      return null;
+    }
+  }
+
+  public void close() {
+
+  }
+}
diff --git a/solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/BinURLDataSource.java b/solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/BinURLDataSource.java
index be78fb6..9d4d879 100644
--- a/solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/BinURLDataSource.java
+++ b/solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/BinURLDataSource.java
@@ -1,101 +1,101 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.solr.handler.dataimport;
-
-import static org.apache.solr.handler.dataimport.DataImportHandlerException.*;
-import static org.apache.solr.handler.dataimport.URLDataSource.*;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.InputStream;
-import java.net.URL;
-import java.net.URLConnection;
-import java.util.Properties;
-/**
- * <p> A data source implementation which can be used to read binary streams using HTTP. </p> <p/> <p> Refer to <a
- * href="http://wiki.apache.org/solr/DataImportHandler">http://wiki.apache.org/solr/DataImportHandler</a> for more
- * details. </p>
- * <p/>
- * <b>This API is experimental and may change in the future.</b>
- *
- * @version $Id$
- * @since solr 1.5
- */
-public class BinURLDataSource extends DataSource<InputStream>{
-  private static final Logger LOG = LoggerFactory.getLogger(BinURLDataSource.class);
-
-  private String baseUrl;
-  private int connectionTimeout = CONNECTION_TIMEOUT;
-
-  private int readTimeout = READ_TIMEOUT;
-
-  private Context context;
-
-  private Properties initProps;
-
-  public BinURLDataSource() { }
-
-  public void init(Context context, Properties initProps) {
-      this.context = context;
-    this.initProps = initProps;
-
-    baseUrl = getInitPropWithReplacements(BASE_URL);
-    String cTimeout = getInitPropWithReplacements(CONNECTION_TIMEOUT_FIELD_NAME);
-    String rTimeout = getInitPropWithReplacements(READ_TIMEOUT_FIELD_NAME);
-    if (cTimeout != null) {
-      try {
-        connectionTimeout = Integer.parseInt(cTimeout);
-      } catch (NumberFormatException e) {
-        LOG.warn("Invalid connection timeout: " + cTimeout);
-      }
-    }
-    if (rTimeout != null) {
-      try {
-        readTimeout = Integer.parseInt(rTimeout);
-      } catch (NumberFormatException e) {
-        LOG.warn("Invalid read timeout: " + rTimeout);
-      }
-    }
-  }
-
-  public InputStream getData(String query) {
-    URL url = null;
-    try {
-      if (URIMETHOD.matcher(query).find()) url = new URL(query);
-      else url = new URL(baseUrl + query);
-      LOG.debug("Accessing URL: " + url.toString());
-      URLConnection conn = url.openConnection();
-      conn.setConnectTimeout(connectionTimeout);
-      conn.setReadTimeout(readTimeout);
-      return conn.getInputStream();
-    } catch (Exception e) {
-      LOG.error("Exception thrown while getting data", e);
-      wrapAndThrow (SEVERE, e, "Exception in invoking url " + url);
-      return null;//unreachable
-    }
-  }
-
-  public void close() { }
-
-  private String getInitPropWithReplacements(String propertyName) {
-    final String expr = initProps.getProperty(propertyName);
-    if (expr == null) {
-      return null;
-    }
-    return context.replaceTokens(expr);
-  }
-}
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.solr.handler.dataimport;
+
+import static org.apache.solr.handler.dataimport.DataImportHandlerException.*;
+import static org.apache.solr.handler.dataimport.URLDataSource.*;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.io.InputStream;
+import java.net.URL;
+import java.net.URLConnection;
+import java.util.Properties;
+/**
+ * <p> A data source implementation which can be used to read binary streams using HTTP. </p> <p/> <p> Refer to <a
+ * href="http://wiki.apache.org/solr/DataImportHandler">http://wiki.apache.org/solr/DataImportHandler</a> for more
+ * details. </p>
+ * <p/>
+ * <b>This API is experimental and may change in the future.</b>
+ *
+ * @version $Id$
+ * @since solr 1.5
+ */
+public class BinURLDataSource extends DataSource<InputStream>{
+  private static final Logger LOG = LoggerFactory.getLogger(BinURLDataSource.class);
+
+  private String baseUrl;
+  private int connectionTimeout = CONNECTION_TIMEOUT;
+
+  private int readTimeout = READ_TIMEOUT;
+
+  private Context context;
+
+  private Properties initProps;
+
+  public BinURLDataSource() { }
+
+  public void init(Context context, Properties initProps) {
+      this.context = context;
+    this.initProps = initProps;
+
+    baseUrl = getInitPropWithReplacements(BASE_URL);
+    String cTimeout = getInitPropWithReplacements(CONNECTION_TIMEOUT_FIELD_NAME);
+    String rTimeout = getInitPropWithReplacements(READ_TIMEOUT_FIELD_NAME);
+    if (cTimeout != null) {
+      try {
+        connectionTimeout = Integer.parseInt(cTimeout);
+      } catch (NumberFormatException e) {
+        LOG.warn("Invalid connection timeout: " + cTimeout);
+      }
+    }
+    if (rTimeout != null) {
+      try {
+        readTimeout = Integer.parseInt(rTimeout);
+      } catch (NumberFormatException e) {
+        LOG.warn("Invalid read timeout: " + rTimeout);
+      }
+    }
+  }
+
+  public InputStream getData(String query) {
+    URL url = null;
+    try {
+      if (URIMETHOD.matcher(query).find()) url = new URL(query);
+      else url = new URL(baseUrl + query);
+      LOG.debug("Accessing URL: " + url.toString());
+      URLConnection conn = url.openConnection();
+      conn.setConnectTimeout(connectionTimeout);
+      conn.setReadTimeout(readTimeout);
+      return conn.getInputStream();
+    } catch (Exception e) {
+      LOG.error("Exception thrown while getting data", e);
+      wrapAndThrow (SEVERE, e, "Exception in invoking url " + url);
+      return null;//unreachable
+    }
+  }
+
+  public void close() { }
+
+  private String getInitPropWithReplacements(String propertyName) {
+    final String expr = initProps.getProperty(propertyName);
+    if (expr == null) {
+      return null;
+    }
+    return context.replaceTokens(expr);
+  }
+}
diff --git a/solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/FieldStreamDataSource.java b/solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/FieldStreamDataSource.java
index f476adf..e7ae120 100644
--- a/solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/FieldStreamDataSource.java
+++ b/solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/FieldStreamDataSource.java
@@ -1,95 +1,95 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.solr.handler.dataimport;
-
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.ByteArrayInputStream;
-import java.io.InputStream;
-import java.lang.reflect.Method;
-import java.lang.reflect.Modifier;
-import java.sql.Blob;
-import java.util.Properties;
-
-import static org.apache.solr.handler.dataimport.DataImportHandlerException.SEVERE;
-
-
-/**
- * This can be useful for users who have a DB field containing BLOBs which may be Rich documents
- * <p/>
- * The datasouce may be configured as follows
- * <p/>
- * <datasource name="f1" type="FieldStreamDataSource" />
- * <p/>
- * The enity which uses this datasource must keep and attribute dataField
- * <p/>
- * The fieldname must be resolvable from VariableResolver
- * <p/>
- * This may be used with any EntityProcessor which uses a DataSource<InputStream> eg:TikaEntityProcessor
- * <p/>
- *
- * @version $Id$
- * @since 1.5
- */
-public class FieldStreamDataSource extends DataSource<InputStream> {
-  private static final Logger LOG = LoggerFactory.getLogger(FieldReaderDataSource.class);
-  protected VariableResolver vr;
-  protected String dataField;
-  private EntityProcessorWrapper wrapper;
-
-  public void init(Context context, Properties initProps) {
-    dataField = context.getEntityAttribute("dataField");
-    wrapper = (EntityProcessorWrapper) context.getEntityProcessor();
-    /*no op*/
-  }
-
-  public InputStream getData(String query) {
-    Object o = wrapper.getVariableResolver().resolve(dataField);
-    if (o == null) {
-      throw new DataImportHandlerException(SEVERE, "No field available for name : " + dataField);
-    }
-    if (o instanceof Blob) {
-      Blob blob = (Blob) o;
-      try {
-        //Most of the JDBC drivers have getBinaryStream defined as public
-        // so let us just check it
-        Method m = blob.getClass().getDeclaredMethod("getBinaryStream");
-        if (Modifier.isPublic(m.getModifiers())) {
-          return (InputStream) m.invoke(blob);
-        } else {
-          // force invoke
-          m.setAccessible(true);
-          return (InputStream) m.invoke(blob);
-        }
-      } catch (Exception e) {
-        LOG.info("Unable to get data from BLOB");
-        return null;
-
-      }
-    } else if (o instanceof byte[]) {
-      byte[] bytes = (byte[]) o;
-      return new ByteArrayInputStream(bytes);
-    } else {
-      throw new RuntimeException("unsupported type : " + o.getClass());
-    } 
-
-  }
-
-  public void close() {
-  }
-}
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.solr.handler.dataimport;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.io.ByteArrayInputStream;
+import java.io.InputStream;
+import java.lang.reflect.Method;
+import java.lang.reflect.Modifier;
+import java.sql.Blob;
+import java.util.Properties;
+
+import static org.apache.solr.handler.dataimport.DataImportHandlerException.SEVERE;
+
+
+/**
+ * This can be useful for users who have a DB field containing BLOBs which may be Rich documents
+ * <p/>
+ * The datasouce may be configured as follows
+ * <p/>
+ * <datasource name="f1" type="FieldStreamDataSource" />
+ * <p/>
+ * The enity which uses this datasource must keep and attribute dataField
+ * <p/>
+ * The fieldname must be resolvable from VariableResolver
+ * <p/>
+ * This may be used with any EntityProcessor which uses a DataSource<InputStream> eg:TikaEntityProcessor
+ * <p/>
+ *
+ * @version $Id$
+ * @since 1.5
+ */
+public class FieldStreamDataSource extends DataSource<InputStream> {
+  private static final Logger LOG = LoggerFactory.getLogger(FieldReaderDataSource.class);
+  protected VariableResolver vr;
+  protected String dataField;
+  private EntityProcessorWrapper wrapper;
+
+  public void init(Context context, Properties initProps) {
+    dataField = context.getEntityAttribute("dataField");
+    wrapper = (EntityProcessorWrapper) context.getEntityProcessor();
+    /*no op*/
+  }
+
+  public InputStream getData(String query) {
+    Object o = wrapper.getVariableResolver().resolve(dataField);
+    if (o == null) {
+      throw new DataImportHandlerException(SEVERE, "No field available for name : " + dataField);
+    }
+    if (o instanceof Blob) {
+      Blob blob = (Blob) o;
+      try {
+        //Most of the JDBC drivers have getBinaryStream defined as public
+        // so let us just check it
+        Method m = blob.getClass().getDeclaredMethod("getBinaryStream");
+        if (Modifier.isPublic(m.getModifiers())) {
+          return (InputStream) m.invoke(blob);
+        } else {
+          // force invoke
+          m.setAccessible(true);
+          return (InputStream) m.invoke(blob);
+        }
+      } catch (Exception e) {
+        LOG.info("Unable to get data from BLOB");
+        return null;
+
+      }
+    } else if (o instanceof byte[]) {
+      byte[] bytes = (byte[]) o;
+      return new ByteArrayInputStream(bytes);
+    } else {
+      throw new RuntimeException("unsupported type : " + o.getClass());
+    } 
+
+  }
+
+  public void close() {
+  }
+}
diff --git a/solr/example/example-DIH/solr/tika/conf/schema.xml b/solr/example/example-DIH/solr/tika/conf/schema.xml
index 4d023e7..b1ec8be 100644
--- a/solr/example/example-DIH/solr/tika/conf/schema.xml
+++ b/solr/example/example-DIH/solr/tika/conf/schema.xml
@@ -1,205 +1,205 @@
-<?xml version="1.0" encoding="UTF-8" ?>
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-
-<!--  
- This is the Solr schema file. This file should be named "schema.xml" and
- should be in the conf directory under the solr home
- (i.e. ./solr/conf/schema.xml by default) 
- or located where the classloader for the Solr webapp can find it.
-
- This example schema is the recommended starting point for users.
- It should be kept correct and concise, usable out-of-the-box.
-
- For more information, on how to customize this file, please see
- http://wiki.apache.org/solr/SchemaXml
--->
-
-<schema name="test" version="1.2">
-  <!-- attribute "name" is the name of this schema and is only used for display purposes.
-       Applications should change this to reflect the nature of the search collection.
-       version="1.1" is Solr's version number for the schema syntax and semantics.  It should
-       not normally be changed by applications.
-       1.0: multiValued attribute did not exist, all fields are multiValued by nature
-       1.1: multiValued attribute introduced, false by default -->
-
-  <types>
-    <!-- field type definitions. The "name" attribute is
-       just a label to be used by field definitions.  The "class"
-       attribute and any other attributes determine the real
-       behavior of the fieldType.
-         Class names starting with "solr" refer to java classes in the
-       org.apache.solr.analysis package.
-    -->
-
-    <!-- The StrField type is not analyzed, but indexed/stored verbatim.  
-       - StrField and TextField support an optional compressThreshold which
-       limits compression (if enabled in the derived fields) to values which
-       exceed a certain size (in characters).
-    -->
-    <fieldType name="string" class="solr.StrField" sortMissingLast="true" omitNorms="true"/>
-
-    <!-- boolean type: "true" or "false" -->
-    <fieldType name="boolean" class="solr.BoolField" sortMissingLast="true" omitNorms="true"/>
-
-    <!-- The optional sortMissingLast and sortMissingFirst attributes are
-         currently supported on types that are sorted internally as strings.
-       - If sortMissingLast="true", then a sort on this field will cause documents
-         without the field to come after documents with the field,
-         regardless of the requested sort order (asc or desc).
-       - If sortMissingFirst="true", then a sort on this field will cause documents
-         without the field to come before documents with the field,
-         regardless of the requested sort order.
-       - If sortMissingLast="false" and sortMissingFirst="false" (the default),
-         then default lucene sorting will be used which places docs without the
-         field first in an ascending sort and last in a descending sort.
-    -->    
-
-
-    <!-- numeric field types that store and index the text
-         value verbatim (and hence don't support range queries, since the
-         lexicographic ordering isn't equal to the numeric ordering) -->
-    <fieldType name="integer" class="solr.IntField" omitNorms="true"/>
-    <fieldType name="long" class="solr.LongField" omitNorms="true"/>
-    <fieldType name="float" class="solr.FloatField" omitNorms="true"/>
-    <fieldType name="double" class="solr.DoubleField" omitNorms="true"/>
-
-
-    <!-- Numeric field types that manipulate the value into
-         a string value that isn't human-readable in its internal form,
-         but with a lexicographic ordering the same as the numeric ordering,
-         so that range queries work correctly. -->
-    <fieldType name="sint" class="solr.SortableIntField" sortMissingLast="true" omitNorms="true"/>
-    <fieldType name="slong" class="solr.SortableLongField" sortMissingLast="true" omitNorms="true"/>
-    <fieldType name="sfloat" class="solr.SortableFloatField" sortMissingLast="true" omitNorms="true"/>
-    <fieldType name="sdouble" class="solr.SortableDoubleField" sortMissingLast="true" omitNorms="true"/>
-
-
-    <!-- The format for this date field is of the form 1995-12-31T23:59:59Z, and
-         is a more restricted form of the canonical representation of dateTime
-         http://www.w3.org/TR/xmlschema-2/#dateTime    
-         The trailing "Z" designates UTC time and is mandatory.
-         Optional fractional seconds are allowed: 1995-12-31T23:59:59.999Z
-         All other components are mandatory.
-
-         Expressions can also be used to denote calculations that should be
-         performed relative to "NOW" to determine the value, ie...
-
-               NOW/HOUR
-                  ... Round to the start of the current hour
-               NOW-1DAY
-                  ... Exactly 1 day prior to now
-               NOW/DAY+6MONTHS+3DAYS
-                  ... 6 months and 3 days in the future from the start of
-                      the current day
-                      
-         Consult the DateField javadocs for more information.
-      -->
-    <fieldType name="date" class="solr.DateField" sortMissingLast="true" omitNorms="true"/>
-
-
-    <!-- The "RandomSortField" is not used to store or search any
-         data.  You can declare fields of this type it in your schema
-         to generate psuedo-random orderings of your docs for sorting 
-         purposes.  The ordering is generated based on the field name 
-         and the version of the index, As long as the index version
-         remains unchanged, and the same field name is reused,
-         the ordering of the docs will be consistent.  
-         If you want differend psuedo-random orderings of documents,
-         for the same version of the index, use a dynamicField and
-         change the name
-     -->
-    <fieldType name="random" class="solr.RandomSortField" indexed="true" />
-
-    <!-- solr.TextField allows the specification of custom text analyzers
-         specified as a tokenizer and a list of token filters. Different
-         analyzers may be specified for indexing and querying.
-
-         The optional positionIncrementGap puts space between multiple fields of
-         this type on the same document, with the purpose of preventing false phrase
-         matching across fields.
-
-         For more info on customizing your analyzer chain, please see
-         http://wiki.apache.org/solr/AnalyzersTokenizersTokenFilters
-     -->
-
-    <!-- One can also specify an existing Analyzer class that has a
-         default constructor via the class attribute on the analyzer element
-    <fieldType name="text_greek" class="solr.TextField">
-      <analyzer class="org.apache.lucene.analysis.el.GreekAnalyzer"/>
-    </fieldType>
-    -->
-
-    <!-- A text field that only splits on whitespace for exact matching of words -->
-    <fieldType name="text_ws" class="solr.TextField" positionIncrementGap="100">
-      <analyzer>
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-      </analyzer>
-    </fieldType>
-
-    <!-- A text field that uses WordDelimiterFilter to enable splitting and matching of
-        words on case-change, alpha numeric boundaries, and non-alphanumeric chars,
-        so that a query of "wifi" or "wi fi" could match a document containing "Wi-Fi".
-        Synonyms and stopwords are customized by external files, and stemming is enabled.
-        Duplicate tokens at the same position (which may result from Stemmed Synonyms or
-        WordDelim parts) are removed.
-        -->
-    <fieldType name="text" class="solr.TextField" positionIncrementGap="100">
-      <analyzer type="index">
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-        <!-- in this example, we will only use synonyms at query time
-        <filter class="solr.SynonymFilterFactory" synonyms="index_synonyms.txt" ignoreCase="true" expand="false"/>
-        -->
-        <!--<filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt"/>-->
-        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="1" catenateNumbers="1" catenateAll="0" splitOnCaseChange="1"/>
-        <filter class="solr.LowerCaseFilterFactory"/>
-        <!--<filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
-        <filter class="solr.PorterStemFilterFactory"/>-->
-        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
-      </analyzer>
-      <analyzer type="query">
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-        <!--<filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt" ignoreCase="true" expand="true"/>-->
-        <!--<filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt"/>-->
-        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="0" catenateNumbers="0" catenateAll="0" splitOnCaseChange="1"/>
-        <filter class="solr.LowerCaseFilterFactory"/>
-        <!--<filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
-        <filter class="solr.PorterStemFilterFactory"/>-->
-        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
-      </analyzer>
-    </fieldType>
-    <!-- since fields of this type are by default not stored or indexed, any data added to 
-         them will be ignored outright 
-     --> 
-    <fieldtype name="ignored" stored="false" indexed="false" class="solr.StrField" /> 
-
- </types>
-
-
- <fields>
-   <field name="title" type="string" indexed="true" stored="true"/>
-   <field name="author" type="string" indexed="true" stored="true" />
-   <field name="text" type="text" indexed="true" stored="true" />
-   
- </fields>
- <!-- field for the QueryParser to use when an explicit fieldname is absent -->
- <defaultSearchField>text</defaultSearchField>
-
- <!-- SolrQueryParser configuration: defaultOperator="AND|OR" -->
- <solrQueryParser defaultOperator="OR"/>
-
-</schema>
+<?xml version="1.0" encoding="UTF-8" ?>
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+
+<!--  
+ This is the Solr schema file. This file should be named "schema.xml" and
+ should be in the conf directory under the solr home
+ (i.e. ./solr/conf/schema.xml by default) 
+ or located where the classloader for the Solr webapp can find it.
+
+ This example schema is the recommended starting point for users.
+ It should be kept correct and concise, usable out-of-the-box.
+
+ For more information, on how to customize this file, please see
+ http://wiki.apache.org/solr/SchemaXml
+-->
+
+<schema name="test" version="1.2">
+  <!-- attribute "name" is the name of this schema and is only used for display purposes.
+       Applications should change this to reflect the nature of the search collection.
+       version="1.1" is Solr's version number for the schema syntax and semantics.  It should
+       not normally be changed by applications.
+       1.0: multiValued attribute did not exist, all fields are multiValued by nature
+       1.1: multiValued attribute introduced, false by default -->
+
+  <types>
+    <!-- field type definitions. The "name" attribute is
+       just a label to be used by field definitions.  The "class"
+       attribute and any other attributes determine the real
+       behavior of the fieldType.
+         Class names starting with "solr" refer to java classes in the
+       org.apache.solr.analysis package.
+    -->
+
+    <!-- The StrField type is not analyzed, but indexed/stored verbatim.  
+       - StrField and TextField support an optional compressThreshold which
+       limits compression (if enabled in the derived fields) to values which
+       exceed a certain size (in characters).
+    -->
+    <fieldType name="string" class="solr.StrField" sortMissingLast="true" omitNorms="true"/>
+
+    <!-- boolean type: "true" or "false" -->
+    <fieldType name="boolean" class="solr.BoolField" sortMissingLast="true" omitNorms="true"/>
+
+    <!-- The optional sortMissingLast and sortMissingFirst attributes are
+         currently supported on types that are sorted internally as strings.
+       - If sortMissingLast="true", then a sort on this field will cause documents
+         without the field to come after documents with the field,
+         regardless of the requested sort order (asc or desc).
+       - If sortMissingFirst="true", then a sort on this field will cause documents
+         without the field to come before documents with the field,
+         regardless of the requested sort order.
+       - If sortMissingLast="false" and sortMissingFirst="false" (the default),
+         then default lucene sorting will be used which places docs without the
+         field first in an ascending sort and last in a descending sort.
+    -->    
+
+
+    <!-- numeric field types that store and index the text
+         value verbatim (and hence don't support range queries, since the
+         lexicographic ordering isn't equal to the numeric ordering) -->
+    <fieldType name="integer" class="solr.IntField" omitNorms="true"/>
+    <fieldType name="long" class="solr.LongField" omitNorms="true"/>
+    <fieldType name="float" class="solr.FloatField" omitNorms="true"/>
+    <fieldType name="double" class="solr.DoubleField" omitNorms="true"/>
+
+
+    <!-- Numeric field types that manipulate the value into
+         a string value that isn't human-readable in its internal form,
+         but with a lexicographic ordering the same as the numeric ordering,
+         so that range queries work correctly. -->
+    <fieldType name="sint" class="solr.SortableIntField" sortMissingLast="true" omitNorms="true"/>
+    <fieldType name="slong" class="solr.SortableLongField" sortMissingLast="true" omitNorms="true"/>
+    <fieldType name="sfloat" class="solr.SortableFloatField" sortMissingLast="true" omitNorms="true"/>
+    <fieldType name="sdouble" class="solr.SortableDoubleField" sortMissingLast="true" omitNorms="true"/>
+
+
+    <!-- The format for this date field is of the form 1995-12-31T23:59:59Z, and
+         is a more restricted form of the canonical representation of dateTime
+         http://www.w3.org/TR/xmlschema-2/#dateTime    
+         The trailing "Z" designates UTC time and is mandatory.
+         Optional fractional seconds are allowed: 1995-12-31T23:59:59.999Z
+         All other components are mandatory.
+
+         Expressions can also be used to denote calculations that should be
+         performed relative to "NOW" to determine the value, ie...
+
+               NOW/HOUR
+                  ... Round to the start of the current hour
+               NOW-1DAY
+                  ... Exactly 1 day prior to now
+               NOW/DAY+6MONTHS+3DAYS
+                  ... 6 months and 3 days in the future from the start of
+                      the current day
+                      
+         Consult the DateField javadocs for more information.
+      -->
+    <fieldType name="date" class="solr.DateField" sortMissingLast="true" omitNorms="true"/>
+
+
+    <!-- The "RandomSortField" is not used to store or search any
+         data.  You can declare fields of this type it in your schema
+         to generate psuedo-random orderings of your docs for sorting 
+         purposes.  The ordering is generated based on the field name 
+         and the version of the index, As long as the index version
+         remains unchanged, and the same field name is reused,
+         the ordering of the docs will be consistent.  
+         If you want differend psuedo-random orderings of documents,
+         for the same version of the index, use a dynamicField and
+         change the name
+     -->
+    <fieldType name="random" class="solr.RandomSortField" indexed="true" />
+
+    <!-- solr.TextField allows the specification of custom text analyzers
+         specified as a tokenizer and a list of token filters. Different
+         analyzers may be specified for indexing and querying.
+
+         The optional positionIncrementGap puts space between multiple fields of
+         this type on the same document, with the purpose of preventing false phrase
+         matching across fields.
+
+         For more info on customizing your analyzer chain, please see
+         http://wiki.apache.org/solr/AnalyzersTokenizersTokenFilters
+     -->
+
+    <!-- One can also specify an existing Analyzer class that has a
+         default constructor via the class attribute on the analyzer element
+    <fieldType name="text_greek" class="solr.TextField">
+      <analyzer class="org.apache.lucene.analysis.el.GreekAnalyzer"/>
+    </fieldType>
+    -->
+
+    <!-- A text field that only splits on whitespace for exact matching of words -->
+    <fieldType name="text_ws" class="solr.TextField" positionIncrementGap="100">
+      <analyzer>
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+      </analyzer>
+    </fieldType>
+
+    <!-- A text field that uses WordDelimiterFilter to enable splitting and matching of
+        words on case-change, alpha numeric boundaries, and non-alphanumeric chars,
+        so that a query of "wifi" or "wi fi" could match a document containing "Wi-Fi".
+        Synonyms and stopwords are customized by external files, and stemming is enabled.
+        Duplicate tokens at the same position (which may result from Stemmed Synonyms or
+        WordDelim parts) are removed.
+        -->
+    <fieldType name="text" class="solr.TextField" positionIncrementGap="100">
+      <analyzer type="index">
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+        <!-- in this example, we will only use synonyms at query time
+        <filter class="solr.SynonymFilterFactory" synonyms="index_synonyms.txt" ignoreCase="true" expand="false"/>
+        -->
+        <!--<filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt"/>-->
+        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="1" catenateNumbers="1" catenateAll="0" splitOnCaseChange="1"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <!--<filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
+        <filter class="solr.PorterStemFilterFactory"/>-->
+        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
+      </analyzer>
+      <analyzer type="query">
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+        <!--<filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt" ignoreCase="true" expand="true"/>-->
+        <!--<filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt"/>-->
+        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="0" catenateNumbers="0" catenateAll="0" splitOnCaseChange="1"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <!--<filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
+        <filter class="solr.PorterStemFilterFactory"/>-->
+        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
+      </analyzer>
+    </fieldType>
+    <!-- since fields of this type are by default not stored or indexed, any data added to 
+         them will be ignored outright 
+     --> 
+    <fieldtype name="ignored" stored="false" indexed="false" class="solr.StrField" /> 
+
+ </types>
+
+
+ <fields>
+   <field name="title" type="string" indexed="true" stored="true"/>
+   <field name="author" type="string" indexed="true" stored="true" />
+   <field name="text" type="text" indexed="true" stored="true" />
+   
+ </fields>
+ <!-- field for the QueryParser to use when an explicit fieldname is absent -->
+ <defaultSearchField>text</defaultSearchField>
+
+ <!-- SolrQueryParser configuration: defaultOperator="AND|OR" -->
+ <solrQueryParser defaultOperator="OR"/>
+
+</schema>
diff --git a/solr/example/example-DIH/solr/tika/conf/solrconfig.xml b/solr/example/example-DIH/solr/tika/conf/solrconfig.xml
index 990c802..ff423d5 100644
--- a/solr/example/example-DIH/solr/tika/conf/solrconfig.xml
+++ b/solr/example/example-DIH/solr/tika/conf/solrconfig.xml
@@ -1,410 +1,410 @@
-<?xml version="1.0" encoding="UTF-8" ?>
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-
-<config>
-  <!-- Set this to 'false' if you want solr to continue working after it has 
-       encountered an severe configuration error.  In a production environment, 
-       you may want solr to keep working even if one handler is mis-configured.
-
-       You may also set this to false using by setting the system property:
-         -Dsolr.abortOnConfigurationError=false
-     -->
-  <abortOnConfigurationError>${solr.abortOnConfigurationError:true}</abortOnConfigurationError>
-
-  <lib dir="../../../../contrib/extraction/lib" />
-  <lib dir="../../../../dist/" regex="apache-solr-dataimporthandler-extras-\d.*\.jar" />
-
-  <!-- Used to specify an alternate directory to hold all index data
-       other than the default ./data under the Solr home.
-       If replication is in use, this should match the replication configuration. -->
-       <dataDir>${solr.data.dir:./solr/data}</dataDir>
-
-
-  <indexDefaults>
-   <!-- Values here affect all index writers and act as a default unless overridden. -->
-    <useCompoundFile>false</useCompoundFile>
-
-    <mergeFactor>10</mergeFactor>
-    <!--
-     If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
-
-     -->
-    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
-    <!-- Tell Lucene when to flush documents to disk.
-    Giving Lucene more memory for indexing means faster indexing at the cost of more RAM
-
-    If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
-
-    -->
-    <ramBufferSizeMB>32</ramBufferSizeMB>
-    <maxMergeDocs>2147483647</maxMergeDocs>
-    <maxFieldLength>10000</maxFieldLength>
-    <writeLockTimeout>1000</writeLockTimeout>
-    <commitLockTimeout>10000</commitLockTimeout>
-
-    <!--
-     Expert: Turn on Lucene's auto commit capability.
-
-     TODO: Add recommendations on why you would want to do this.
-
-     NOTE: Despite the name, this value does not have any relation to Solr's autoCommit functionality
-
-     -->
-    <!--<luceneAutoCommit>false</luceneAutoCommit>-->
-    <!--
-     Expert:
-     The Merge Policy in Lucene controls how merging is handled by Lucene.  The default in 2.3 is the LogByteSizeMergePolicy, previous
-     versions used LogDocMergePolicy.
-
-     LogByteSizeMergePolicy chooses segments to merge based on their size.  The Lucene 2.2 default, LogDocMergePolicy chose when
-     to merge based on number of documents
-
-     Other implementations of MergePolicy must have a no-argument constructor
-     -->
-    <!--<mergePolicy>org.apache.lucene.index.LogByteSizeMergePolicy</mergePolicy>-->
-
-    <!--
-     Expert:
-     The Merge Scheduler in Lucene controls how merges are performed.  The ConcurrentMergeScheduler (Lucene 2.3 default)
-      can perform merges in the background using separate threads.  The SerialMergeScheduler (Lucene 2.2 default) does not.
-     -->
-    <!--<mergeScheduler>org.apache.lucene.index.ConcurrentMergeScheduler</mergeScheduler>-->
-
-    <!--
-      As long as Solr is the only process modifying your index, it is
-      safe to use Lucene's in process locking mechanism.  But you may
-      specify one of the other Lucene LockFactory implementations in
-      the event that you have a custom situation.
-      
-      none = NoLockFactory (typically only used with read only indexes)
-      single = SingleInstanceLockFactory (suggested)
-      native = NativeFSLockFactory
-      simple = SimpleFSLockFactory
-
-      ('simple' is the default for backwards compatibility with Solr 1.2)
-    -->
-    <lockType>single</lockType>
-  </indexDefaults>
-
-  <mainIndex>
-    <!-- options specific to the main on-disk lucene index -->
-    <useCompoundFile>false</useCompoundFile>
-    <ramBufferSizeMB>32</ramBufferSizeMB>
-    <mergeFactor>10</mergeFactor>
-    <!-- Deprecated -->
-    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
-    <maxMergeDocs>2147483647</maxMergeDocs>
-    <maxFieldLength>10000</maxFieldLength>
-
-    <!-- If true, unlock any held write or commit locks on startup. 
-         This defeats the locking mechanism that allows multiple
-         processes to safely access a lucene index, and should be
-         used with care.
-         This is not needed if lock type is 'none' or 'single'
-     -->
-    <unlockOnStartup>false</unlockOnStartup>
-  </mainIndex>
-
-  <!-- the default high-performance update handler -->
-  <updateHandler class="solr.DirectUpdateHandler2">
-
-    <!-- A prefix of "solr." for class names is an alias that
-         causes solr to search appropriate packages, including
-         org.apache.solr.(search|update|request|core|analysis)
-     -->
-
-    <!-- Limit the number of deletions Solr will buffer during doc updating.
-        
-        Setting this lower can help bound memory use during indexing.
-    -->
-    <maxPendingDeletes>100000</maxPendingDeletes>
-
-  </updateHandler>
-
-
-  <query>
-    <!-- Maximum number of clauses in a boolean query... can affect
-        range or prefix queries that expand to big boolean
-        queries.  An exception is thrown if exceeded.  -->
-    <maxBooleanClauses>1024</maxBooleanClauses>
-
-    
-    <!-- Cache used by SolrIndexSearcher for filters (DocSets),
-         unordered sets of *all* documents that match a query.
-         When a new searcher is opened, its caches may be prepopulated
-         or "autowarmed" using data from caches in the old searcher.
-         autowarmCount is the number of items to prepopulate.  For LRUCache,
-         the autowarmed items will be the most recently accessed items.
-       Parameters:
-         class - the SolrCache implementation (currently only LRUCache)
-         size - the maximum number of entries in the cache
-         initialSize - the initial capacity (number of entries) of
-           the cache.  (seel java.util.HashMap)
-         autowarmCount - the number of entries to prepopulate from
-           and old cache.
-         -->
-    <filterCache
-      class="solr.LRUCache"
-      size="512"
-      initialSize="512"
-      autowarmCount="256"/>
-
-   <!-- queryResultCache caches results of searches - ordered lists of
-         document ids (DocList) based on a query, a sort, and the range
-         of documents requested.  -->
-    <queryResultCache
-      class="solr.LRUCache"
-      size="512"
-      initialSize="512"
-      autowarmCount="256"/>
-
-  <!-- documentCache caches Lucene Document objects (the stored fields for each document).
-       Since Lucene internal document ids are transient, this cache will not be autowarmed.  -->
-    <documentCache
-      class="solr.LRUCache"
-      size="512"
-      initialSize="512"
-      autowarmCount="0"/>
-
-    <!-- If true, stored fields that are not requested will be loaded lazily.
-
-    This can result in a significant speed improvement if the usual case is to
-    not load all stored fields, especially if the skipped fields are large compressed
-    text fields.
-    -->
-    <enableLazyFieldLoading>true</enableLazyFieldLoading>
-
-    <!-- Example of a generic cache.  These caches may be accessed by name
-         through SolrIndexSearcher.getCache(),cacheLookup(), and cacheInsert().
-         The purpose is to enable easy caching of user/application level data.
-         The regenerator argument should be specified as an implementation
-         of solr.search.CacheRegenerator if autowarming is desired.  -->
-    <!--
-    <cache name="myUserCache"
-      class="solr.LRUCache"
-      size="4096"
-      initialSize="1024"
-      autowarmCount="1024"
-      regenerator="org.mycompany.mypackage.MyRegenerator"
-      />
-    -->
-
-   <!-- An optimization that attempts to use a filter to satisfy a search.
-         If the requested sort does not include score, then the filterCache
-         will be checked for a filter matching the query. If found, the filter
-         will be used as the source of document ids, and then the sort will be
-         applied to that.
-    <useFilterForSortedQuery>true</useFilterForSortedQuery>
-   -->
-
-   <!-- An optimization for use with the queryResultCache.  When a search
-         is requested, a superset of the requested number of document ids
-         are collected.  For example, if a search for a particular query
-         requests matching documents 10 through 19, and queryWindowSize is 50,
-         then documents 0 through 49 will be collected and cached.  Any further
-         requests in that range can be satisfied via the cache.  -->
-    <queryResultWindowSize>50</queryResultWindowSize>
-    
-    <!-- Maximum number of documents to cache for any entry in the
-         queryResultCache. -->
-    <queryResultMaxDocsCached>200</queryResultMaxDocsCached>
-
-    <!-- This entry enables an int hash representation for filters (DocSets)
-         when the number of items in the set is less than maxSize.  For smaller
-         sets, this representation is more memory efficient, more efficient to
-         iterate over, and faster to take intersections.  -->
-    <HashDocSet maxSize="3000" loadFactor="0.75"/>
-
-    <!-- a newSearcher event is fired whenever a new searcher is being prepared
-         and there is a current searcher handling requests (aka registered). -->
-    <!-- QuerySenderListener takes an array of NamedList and executes a
-         local query request for each NamedList in sequence. -->
-    <listener event="newSearcher" class="solr.QuerySenderListener">
-      <arr name="queries">
-        <lst> <str name="q">solr</str> <str name="start">0</str> <str name="rows">10</str> </lst>
-        <lst> <str name="q">rocks</str> <str name="start">0</str> <str name="rows">10</str> </lst>
-        <lst><str name="q">static newSearcher warming query from solrconfig.xml</str></lst>
-      </arr>
-    </listener>
-
-    <!-- a firstSearcher event is fired whenever a new searcher is being
-         prepared but there is no current registered searcher to handle
-         requests or to gain autowarming data from. -->
-    <listener event="firstSearcher" class="solr.QuerySenderListener">
-      <arr name="queries">
-      </arr>
-    </listener>
-
-    <!-- If a search request comes in and there is no current registered searcher,
-         then immediately register the still warming searcher and use it.  If
-         "false" then all requests will block until the first searcher is done
-         warming. -->
-    <useColdSearcher>false</useColdSearcher>
-
-    <!-- Maximum number of searchers that may be warming in the background
-      concurrently.  An error is returned if this limit is exceeded. Recommend
-      1-2 for read-only slaves, higher for masters w/o cache warming. -->
-    <maxWarmingSearchers>4</maxWarmingSearchers>
-
-  </query>
-
-  <!-- 
-    Let the dispatch filter handler /select?qt=XXX
-    handleSelect=true will use consistent error handling for /select and /update
-    handleSelect=false will use solr1.1 style error formatting
-    -->
-  <requestDispatcher handleSelect="true" >
-    <!--Make sure your system has some authentication before enabling remote streaming!  -->
-    <requestParsers enableRemoteStreaming="false" multipartUploadLimitInKB="2048" />
-        
-    <!-- Set HTTP caching related parameters (for proxy caches and clients).
-          
-         To get the behaviour of Solr 1.2 (ie: no caching related headers)
-         use the never304="true" option and do not specify a value for
-         <cacheControl>
-    -->
-    <httpCaching never304="true">
-    <!--httpCaching lastModifiedFrom="openTime"
-                 etagSeed="Solr"-->
-       <!-- lastModFrom="openTime" is the default, the Last-Modified value
-            (and validation against If-Modified-Since requests) will all be
-            relative to when the current Searcher was opened.
-            You can change it to lastModFrom="dirLastMod" if you want the
-            value to exactly corrispond to when the physical index was last
-            modified.
-               
-            etagSeed="..." is an option you can change to force the ETag
-            header (and validation against If-None-Match requests) to be
-            differnet even if the index has not changed (ie: when making
-            significant changes to your config file)
-
-            lastModifiedFrom and etagSeed are both ignored if you use the
-            never304="true" option.
-       -->
-       <!-- If you include a <cacheControl> directive, it will be used to
-            generate a Cache-Control header, as well as an Expires header
-            if the value contains "max-age="
-               
-            By default, no Cache-Control header is generated.
-
-            You can use the <cacheControl> option even if you have set
-            never304="true"
-       -->
-       <!-- <cacheControl>max-age=30, public</cacheControl> -->
-    </httpCaching>
-  </requestDispatcher>
-  
-      
-  <!-- requestHandler plugins... incoming queries will be dispatched to the
-     correct handler based on the path or the qt (query type) param.
-     Names starting with a '/' are accessed with the a path equal to the 
-     registered name.  Names without a leading '/' are accessed with:
-      http://host/app/select?qt=name
-     If no qt is defined, the requestHandler that declares default="true"
-     will be used.
-  -->
-  <requestHandler name="standard" class="solr.StandardRequestHandler" default="true">
-    <!-- default values for query parameters -->
-     <lst name="defaults">
-       <str name="echoParams">explicit</str>
-       <!-- 
-       <int name="rows">10</int>
-       <str name="fl">*</str>
-       <str name="version">2.1</str>
-        -->
-     </lst>
-  </requestHandler>
-  
-  <requestHandler name="/dataimport" class="org.apache.solr.handler.dataimport.DataImportHandler">
-    <lst name="defaults">
-		<str name="config">tika-data-config.xml</str>
-	</lst>
-  </requestHandler>
-    
-  <!--
-   
-   Search components are registered to SolrCore and used by Search Handlers
-   
-   By default, the following components are avaliable:
-    
-   <searchComponent name="query"     class="org.apache.solr.handler.component.QueryComponent" />
-   <searchComponent name="facet"     class="org.apache.solr.handler.component.FacetComponent" />
-   <searchComponent name="mlt"       class="org.apache.solr.handler.component.MoreLikeThisComponent" />
-   <searchComponent name="highlight" class="org.apache.solr.handler.component.HighlightComponent" />
-   <searchComponent name="debug"     class="org.apache.solr.handler.component.DebugComponent" />
-  
-   If you register a searchComponent to one of the standard names, that will be used instead.
-  
-   -->
- 
-  <requestHandler name="/search" class="org.apache.solr.handler.component.SearchHandler">
-    <lst name="defaults">
-      <str name="echoParams">explicit</str>
-    </lst>
-    <!--
-    By default, this will register the following components:
-    
-    <arr name="components">
-      <str>query</str>
-      <str>facet</str>
-      <str>mlt</str>
-      <str>highlight</str>
-      <str>debug</str>
-    </arr>
-    
-    To insert handlers before or after the 'standard' components, use:
-    
-    <arr name="first-components">
-      <str>first</str>
-    </arr>
-    
-    <arr name="last-components">
-      <str>last</str>
-    </arr>
-    
-    -->
-  </requestHandler>
-  
-  <!-- Update request handler.  
-  
-       Note: Since solr1.1 requestHandlers requires a valid content type header if posted in 
-       the body. For example, curl now requires: -H 'Content-type:text/xml; charset=utf-8'
-       The response format differs from solr1.1 formatting and returns a standard error code.
-       
-       To enable solr1.1 behavior, remove the /update handler or change its path
-       
-       "update.processor.class" is the class name for the UpdateRequestProcessor.  It is initalized
-       only once.  This can not be changed for each request.
-    -->
-  <requestHandler name="/update" class="solr.XmlUpdateRequestHandler" >
-    <!--
-    <str name="update.processor.class">org.apache.solr.handler.UpdateRequestProcessor</str>
-    -->
-  </requestHandler>
-  
-  <!-- config for the admin interface --> 
-  <admin>
-    <defaultQuery>*:*</defaultQuery>
-    
-    <!-- configure a healthcheck file for servers behind a loadbalancer
-    <healthcheck type="file">server-enabled</healthcheck>
-    -->
-  </admin>
-
-</config>
-
+<?xml version="1.0" encoding="UTF-8" ?>
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+
+<config>
+  <!-- Set this to 'false' if you want solr to continue working after it has 
+       encountered an severe configuration error.  In a production environment, 
+       you may want solr to keep working even if one handler is mis-configured.
+
+       You may also set this to false using by setting the system property:
+         -Dsolr.abortOnConfigurationError=false
+     -->
+  <abortOnConfigurationError>${solr.abortOnConfigurationError:true}</abortOnConfigurationError>
+
+  <lib dir="../../../../contrib/extraction/lib" />
+  <lib dir="../../../../dist/" regex="apache-solr-dataimporthandler-extras-\d.*\.jar" />
+
+  <!-- Used to specify an alternate directory to hold all index data
+       other than the default ./data under the Solr home.
+       If replication is in use, this should match the replication configuration. -->
+       <dataDir>${solr.data.dir:./solr/data}</dataDir>
+
+
+  <indexDefaults>
+   <!-- Values here affect all index writers and act as a default unless overridden. -->
+    <useCompoundFile>false</useCompoundFile>
+
+    <mergeFactor>10</mergeFactor>
+    <!--
+     If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
+
+     -->
+    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
+    <!-- Tell Lucene when to flush documents to disk.
+    Giving Lucene more memory for indexing means faster indexing at the cost of more RAM
+
+    If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
+
+    -->
+    <ramBufferSizeMB>32</ramBufferSizeMB>
+    <maxMergeDocs>2147483647</maxMergeDocs>
+    <maxFieldLength>10000</maxFieldLength>
+    <writeLockTimeout>1000</writeLockTimeout>
+    <commitLockTimeout>10000</commitLockTimeout>
+
+    <!--
+     Expert: Turn on Lucene's auto commit capability.
+
+     TODO: Add recommendations on why you would want to do this.
+
+     NOTE: Despite the name, this value does not have any relation to Solr's autoCommit functionality
+
+     -->
+    <!--<luceneAutoCommit>false</luceneAutoCommit>-->
+    <!--
+     Expert:
+     The Merge Policy in Lucene controls how merging is handled by Lucene.  The default in 2.3 is the LogByteSizeMergePolicy, previous
+     versions used LogDocMergePolicy.
+
+     LogByteSizeMergePolicy chooses segments to merge based on their size.  The Lucene 2.2 default, LogDocMergePolicy chose when
+     to merge based on number of documents
+
+     Other implementations of MergePolicy must have a no-argument constructor
+     -->
+    <!--<mergePolicy>org.apache.lucene.index.LogByteSizeMergePolicy</mergePolicy>-->
+
+    <!--
+     Expert:
+     The Merge Scheduler in Lucene controls how merges are performed.  The ConcurrentMergeScheduler (Lucene 2.3 default)
+      can perform merges in the background using separate threads.  The SerialMergeScheduler (Lucene 2.2 default) does not.
+     -->
+    <!--<mergeScheduler>org.apache.lucene.index.ConcurrentMergeScheduler</mergeScheduler>-->
+
+    <!--
+      As long as Solr is the only process modifying your index, it is
+      safe to use Lucene's in process locking mechanism.  But you may
+      specify one of the other Lucene LockFactory implementations in
+      the event that you have a custom situation.
+      
+      none = NoLockFactory (typically only used with read only indexes)
+      single = SingleInstanceLockFactory (suggested)
+      native = NativeFSLockFactory
+      simple = SimpleFSLockFactory
+
+      ('simple' is the default for backwards compatibility with Solr 1.2)
+    -->
+    <lockType>single</lockType>
+  </indexDefaults>
+
+  <mainIndex>
+    <!-- options specific to the main on-disk lucene index -->
+    <useCompoundFile>false</useCompoundFile>
+    <ramBufferSizeMB>32</ramBufferSizeMB>
+    <mergeFactor>10</mergeFactor>
+    <!-- Deprecated -->
+    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
+    <maxMergeDocs>2147483647</maxMergeDocs>
+    <maxFieldLength>10000</maxFieldLength>
+
+    <!-- If true, unlock any held write or commit locks on startup. 
+         This defeats the locking mechanism that allows multiple
+         processes to safely access a lucene index, and should be
+         used with care.
+         This is not needed if lock type is 'none' or 'single'
+     -->
+    <unlockOnStartup>false</unlockOnStartup>
+  </mainIndex>
+
+  <!-- the default high-performance update handler -->
+  <updateHandler class="solr.DirectUpdateHandler2">
+
+    <!-- A prefix of "solr." for class names is an alias that
+         causes solr to search appropriate packages, including
+         org.apache.solr.(search|update|request|core|analysis)
+     -->
+
+    <!-- Limit the number of deletions Solr will buffer during doc updating.
+        
+        Setting this lower can help bound memory use during indexing.
+    -->
+    <maxPendingDeletes>100000</maxPendingDeletes>
+
+  </updateHandler>
+
+
+  <query>
+    <!-- Maximum number of clauses in a boolean query... can affect
+        range or prefix queries that expand to big boolean
+        queries.  An exception is thrown if exceeded.  -->
+    <maxBooleanClauses>1024</maxBooleanClauses>
+
+    
+    <!-- Cache used by SolrIndexSearcher for filters (DocSets),
+         unordered sets of *all* documents that match a query.
+         When a new searcher is opened, its caches may be prepopulated
+         or "autowarmed" using data from caches in the old searcher.
+         autowarmCount is the number of items to prepopulate.  For LRUCache,
+         the autowarmed items will be the most recently accessed items.
+       Parameters:
+         class - the SolrCache implementation (currently only LRUCache)
+         size - the maximum number of entries in the cache
+         initialSize - the initial capacity (number of entries) of
+           the cache.  (seel java.util.HashMap)
+         autowarmCount - the number of entries to prepopulate from
+           and old cache.
+         -->
+    <filterCache
+      class="solr.LRUCache"
+      size="512"
+      initialSize="512"
+      autowarmCount="256"/>
+
+   <!-- queryResultCache caches results of searches - ordered lists of
+         document ids (DocList) based on a query, a sort, and the range
+         of documents requested.  -->
+    <queryResultCache
+      class="solr.LRUCache"
+      size="512"
+      initialSize="512"
+      autowarmCount="256"/>
+
+  <!-- documentCache caches Lucene Document objects (the stored fields for each document).
+       Since Lucene internal document ids are transient, this cache will not be autowarmed.  -->
+    <documentCache
+      class="solr.LRUCache"
+      size="512"
+      initialSize="512"
+      autowarmCount="0"/>
+
+    <!-- If true, stored fields that are not requested will be loaded lazily.
+
+    This can result in a significant speed improvement if the usual case is to
+    not load all stored fields, especially if the skipped fields are large compressed
+    text fields.
+    -->
+    <enableLazyFieldLoading>true</enableLazyFieldLoading>
+
+    <!-- Example of a generic cache.  These caches may be accessed by name
+         through SolrIndexSearcher.getCache(),cacheLookup(), and cacheInsert().
+         The purpose is to enable easy caching of user/application level data.
+         The regenerator argument should be specified as an implementation
+         of solr.search.CacheRegenerator if autowarming is desired.  -->
+    <!--
+    <cache name="myUserCache"
+      class="solr.LRUCache"
+      size="4096"
+      initialSize="1024"
+      autowarmCount="1024"
+      regenerator="org.mycompany.mypackage.MyRegenerator"
+      />
+    -->
+
+   <!-- An optimization that attempts to use a filter to satisfy a search.
+         If the requested sort does not include score, then the filterCache
+         will be checked for a filter matching the query. If found, the filter
+         will be used as the source of document ids, and then the sort will be
+         applied to that.
+    <useFilterForSortedQuery>true</useFilterForSortedQuery>
+   -->
+
+   <!-- An optimization for use with the queryResultCache.  When a search
+         is requested, a superset of the requested number of document ids
+         are collected.  For example, if a search for a particular query
+         requests matching documents 10 through 19, and queryWindowSize is 50,
+         then documents 0 through 49 will be collected and cached.  Any further
+         requests in that range can be satisfied via the cache.  -->
+    <queryResultWindowSize>50</queryResultWindowSize>
+    
+    <!-- Maximum number of documents to cache for any entry in the
+         queryResultCache. -->
+    <queryResultMaxDocsCached>200</queryResultMaxDocsCached>
+
+    <!-- This entry enables an int hash representation for filters (DocSets)
+         when the number of items in the set is less than maxSize.  For smaller
+         sets, this representation is more memory efficient, more efficient to
+         iterate over, and faster to take intersections.  -->
+    <HashDocSet maxSize="3000" loadFactor="0.75"/>
+
+    <!-- a newSearcher event is fired whenever a new searcher is being prepared
+         and there is a current searcher handling requests (aka registered). -->
+    <!-- QuerySenderListener takes an array of NamedList and executes a
+         local query request for each NamedList in sequence. -->
+    <listener event="newSearcher" class="solr.QuerySenderListener">
+      <arr name="queries">
+        <lst> <str name="q">solr</str> <str name="start">0</str> <str name="rows">10</str> </lst>
+        <lst> <str name="q">rocks</str> <str name="start">0</str> <str name="rows">10</str> </lst>
+        <lst><str name="q">static newSearcher warming query from solrconfig.xml</str></lst>
+      </arr>
+    </listener>
+
+    <!-- a firstSearcher event is fired whenever a new searcher is being
+         prepared but there is no current registered searcher to handle
+         requests or to gain autowarming data from. -->
+    <listener event="firstSearcher" class="solr.QuerySenderListener">
+      <arr name="queries">
+      </arr>
+    </listener>
+
+    <!-- If a search request comes in and there is no current registered searcher,
+         then immediately register the still warming searcher and use it.  If
+         "false" then all requests will block until the first searcher is done
+         warming. -->
+    <useColdSearcher>false</useColdSearcher>
+
+    <!-- Maximum number of searchers that may be warming in the background
+      concurrently.  An error is returned if this limit is exceeded. Recommend
+      1-2 for read-only slaves, higher for masters w/o cache warming. -->
+    <maxWarmingSearchers>4</maxWarmingSearchers>
+
+  </query>
+
+  <!-- 
+    Let the dispatch filter handler /select?qt=XXX
+    handleSelect=true will use consistent error handling for /select and /update
+    handleSelect=false will use solr1.1 style error formatting
+    -->
+  <requestDispatcher handleSelect="true" >
+    <!--Make sure your system has some authentication before enabling remote streaming!  -->
+    <requestParsers enableRemoteStreaming="false" multipartUploadLimitInKB="2048" />
+        
+    <!-- Set HTTP caching related parameters (for proxy caches and clients).
+          
+         To get the behaviour of Solr 1.2 (ie: no caching related headers)
+         use the never304="true" option and do not specify a value for
+         <cacheControl>
+    -->
+    <httpCaching never304="true">
+    <!--httpCaching lastModifiedFrom="openTime"
+                 etagSeed="Solr"-->
+       <!-- lastModFrom="openTime" is the default, the Last-Modified value
+            (and validation against If-Modified-Since requests) will all be
+            relative to when the current Searcher was opened.
+            You can change it to lastModFrom="dirLastMod" if you want the
+            value to exactly corrispond to when the physical index was last
+            modified.
+               
+            etagSeed="..." is an option you can change to force the ETag
+            header (and validation against If-None-Match requests) to be
+            differnet even if the index has not changed (ie: when making
+            significant changes to your config file)
+
+            lastModifiedFrom and etagSeed are both ignored if you use the
+            never304="true" option.
+       -->
+       <!-- If you include a <cacheControl> directive, it will be used to
+            generate a Cache-Control header, as well as an Expires header
+            if the value contains "max-age="
+               
+            By default, no Cache-Control header is generated.
+
+            You can use the <cacheControl> option even if you have set
+            never304="true"
+       -->
+       <!-- <cacheControl>max-age=30, public</cacheControl> -->
+    </httpCaching>
+  </requestDispatcher>
+  
+      
+  <!-- requestHandler plugins... incoming queries will be dispatched to the
+     correct handler based on the path or the qt (query type) param.
+     Names starting with a '/' are accessed with the a path equal to the 
+     registered name.  Names without a leading '/' are accessed with:
+      http://host/app/select?qt=name
+     If no qt is defined, the requestHandler that declares default="true"
+     will be used.
+  -->
+  <requestHandler name="standard" class="solr.StandardRequestHandler" default="true">
+    <!-- default values for query parameters -->
+     <lst name="defaults">
+       <str name="echoParams">explicit</str>
+       <!-- 
+       <int name="rows">10</int>
+       <str name="fl">*</str>
+       <str name="version">2.1</str>
+        -->
+     </lst>
+  </requestHandler>
+  
+  <requestHandler name="/dataimport" class="org.apache.solr.handler.dataimport.DataImportHandler">
+    <lst name="defaults">
+		<str name="config">tika-data-config.xml</str>
+	</lst>
+  </requestHandler>
+    
+  <!--
+   
+   Search components are registered to SolrCore and used by Search Handlers
+   
+   By default, the following components are avaliable:
+    
+   <searchComponent name="query"     class="org.apache.solr.handler.component.QueryComponent" />
+   <searchComponent name="facet"     class="org.apache.solr.handler.component.FacetComponent" />
+   <searchComponent name="mlt"       class="org.apache.solr.handler.component.MoreLikeThisComponent" />
+   <searchComponent name="highlight" class="org.apache.solr.handler.component.HighlightComponent" />
+   <searchComponent name="debug"     class="org.apache.solr.handler.component.DebugComponent" />
+  
+   If you register a searchComponent to one of the standard names, that will be used instead.
+  
+   -->
+ 
+  <requestHandler name="/search" class="org.apache.solr.handler.component.SearchHandler">
+    <lst name="defaults">
+      <str name="echoParams">explicit</str>
+    </lst>
+    <!--
+    By default, this will register the following components:
+    
+    <arr name="components">
+      <str>query</str>
+      <str>facet</str>
+      <str>mlt</str>
+      <str>highlight</str>
+      <str>debug</str>
+    </arr>
+    
+    To insert handlers before or after the 'standard' components, use:
+    
+    <arr name="first-components">
+      <str>first</str>
+    </arr>
+    
+    <arr name="last-components">
+      <str>last</str>
+    </arr>
+    
+    -->
+  </requestHandler>
+  
+  <!-- Update request handler.  
+  
+       Note: Since solr1.1 requestHandlers requires a valid content type header if posted in 
+       the body. For example, curl now requires: -H 'Content-type:text/xml; charset=utf-8'
+       The response format differs from solr1.1 formatting and returns a standard error code.
+       
+       To enable solr1.1 behavior, remove the /update handler or change its path
+       
+       "update.processor.class" is the class name for the UpdateRequestProcessor.  It is initalized
+       only once.  This can not be changed for each request.
+    -->
+  <requestHandler name="/update" class="solr.XmlUpdateRequestHandler" >
+    <!--
+    <str name="update.processor.class">org.apache.solr.handler.UpdateRequestProcessor</str>
+    -->
+  </requestHandler>
+  
+  <!-- config for the admin interface --> 
+  <admin>
+    <defaultQuery>*:*</defaultQuery>
+    
+    <!-- configure a healthcheck file for servers behind a loadbalancer
+    <healthcheck type="file">server-enabled</healthcheck>
+    -->
+  </admin>
+
+</config>
+
diff --git a/solr/example/example-DIH/solr/tika/conf/tika-data-config.xml b/solr/example/example-DIH/solr/tika/conf/tika-data-config.xml
index a7fa4e0..d2a0ec9 100644
--- a/solr/example/example-DIH/solr/tika/conf/tika-data-config.xml
+++ b/solr/example/example-DIH/solr/tika/conf/tika-data-config.xml
@@ -1,10 +1,10 @@
-<dataConfig>
-        <dataSource type="BinFileDataSource" />
-        <document>
-        <entity name="tika-test" processor="TikaEntityProcessor" url="../contrib/extraction/src/test/resources/solr-word.pdf" format="text">
-                <field column="Author" name="author" meta="true"/>
-                <field column="title" name="title" meta="true"/>
-                <field column="text" name="text"/>
-        </entity>
-        </document>
-</dataConfig>
+<dataConfig>
+        <dataSource type="BinFileDataSource" />
+        <document>
+        <entity name="tika-test" processor="TikaEntityProcessor" url="../contrib/extraction/src/test/resources/solr-word.pdf" format="text">
+                <field column="Author" name="author" meta="true"/>
+                <field column="title" name="title" meta="true"/>
+                <field column="text" name="text"/>
+        </entity>
+        </document>
+</dataConfig>
diff --git a/solr/example/solr/solr.xml b/solr/example/solr/solr.xml
index 6f0d0fd..4d1a84e 100644
--- a/solr/example/solr/solr.xml
+++ b/solr/example/solr/solr.xml
@@ -1,34 +1,34 @@
-<?xml version="1.0" encoding="UTF-8" ?>
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-
-<!--
- All (relative) paths are relative to the installation path
-  
-  persistent: Save changes made via the API to this file
-  sharedLib: path to a lib directory that will be shared across all cores
--->
-<solr persistent="false">
-
-  <!--
-  adminPath: RequestHandler path to manage cores.  
-    If 'null' (or absent), cores will not be manageable via request handler
-  -->
-  <cores adminPath="/admin/cores" defaultCoreName="collection1">
-    <core name="collection1" instanceDir="." />
-  </cores>
-</solr>
+<?xml version="1.0" encoding="UTF-8" ?>
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+
+<!--
+ All (relative) paths are relative to the installation path
+  
+  persistent: Save changes made via the API to this file
+  sharedLib: path to a lib directory that will be shared across all cores
+-->
+<solr persistent="false">
+
+  <!--
+  adminPath: RequestHandler path to manage cores.  
+    If 'null' (or absent), cores will not be manageable via request handler
+  -->
+  <cores adminPath="/admin/cores" defaultCoreName="collection1">
+    <core name="collection1" instanceDir="." />
+  </cores>
+</solr>
diff --git a/solr/src/java/org/apache/solr/analysis/EdgeNGramFilterFactory.java b/solr/src/java/org/apache/solr/analysis/EdgeNGramFilterFactory.java
index 5783ee0..a05b625 100644
--- a/solr/src/java/org/apache/solr/analysis/EdgeNGramFilterFactory.java
+++ b/solr/src/java/org/apache/solr/analysis/EdgeNGramFilterFactory.java
@@ -1,54 +1,54 @@
-package org.apache.solr.analysis;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.util.Map;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.ngram.EdgeNGramTokenFilter;
-
-/**
- * Creates new instances of {@link EdgeNGramTokenFilter}.
- */
-public class EdgeNGramFilterFactory extends BaseTokenFilterFactory {
-  private int maxGramSize = 0;
-
-  private int minGramSize = 0;
-
-  private String side;
-
-  @Override
-  public void init(Map<String, String> args) {
-    super.init(args);
-    String maxArg = args.get("maxGramSize");
-    maxGramSize = (maxArg != null ? Integer.parseInt(maxArg)
-        : EdgeNGramTokenFilter.DEFAULT_MAX_GRAM_SIZE);
-
-    String minArg = args.get("minGramSize");
-    minGramSize = (minArg != null ? Integer.parseInt(minArg)
-        : EdgeNGramTokenFilter.DEFAULT_MIN_GRAM_SIZE);
-
-    side = args.get("side");
-    if (side == null) {
-      side = EdgeNGramTokenFilter.Side.FRONT.getLabel();
-    }
-  }
-
-  public EdgeNGramTokenFilter create(TokenStream input) {
-    return new EdgeNGramTokenFilter(input, side, minGramSize, maxGramSize);
-  }
-}
+package org.apache.solr.analysis;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.util.Map;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.ngram.EdgeNGramTokenFilter;
+
+/**
+ * Creates new instances of {@link EdgeNGramTokenFilter}.
+ */
+public class EdgeNGramFilterFactory extends BaseTokenFilterFactory {
+  private int maxGramSize = 0;
+
+  private int minGramSize = 0;
+
+  private String side;
+
+  @Override
+  public void init(Map<String, String> args) {
+    super.init(args);
+    String maxArg = args.get("maxGramSize");
+    maxGramSize = (maxArg != null ? Integer.parseInt(maxArg)
+        : EdgeNGramTokenFilter.DEFAULT_MAX_GRAM_SIZE);
+
+    String minArg = args.get("minGramSize");
+    minGramSize = (minArg != null ? Integer.parseInt(minArg)
+        : EdgeNGramTokenFilter.DEFAULT_MIN_GRAM_SIZE);
+
+    side = args.get("side");
+    if (side == null) {
+      side = EdgeNGramTokenFilter.Side.FRONT.getLabel();
+    }
+  }
+
+  public EdgeNGramTokenFilter create(TokenStream input) {
+    return new EdgeNGramTokenFilter(input, side, minGramSize, maxGramSize);
+  }
+}
diff --git a/solr/src/java/org/apache/solr/analysis/NGramFilterFactory.java b/solr/src/java/org/apache/solr/analysis/NGramFilterFactory.java
index c8eb023..0cb850b 100644
--- a/solr/src/java/org/apache/solr/analysis/NGramFilterFactory.java
+++ b/solr/src/java/org/apache/solr/analysis/NGramFilterFactory.java
@@ -1,48 +1,48 @@
-package org.apache.solr.analysis;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.util.Map;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.ngram.NGramTokenFilter;
-
-/**
- * Creates new instances of {@link NGramTokenFilter}.
- */
-public class NGramFilterFactory extends BaseTokenFilterFactory {
-  private int maxGramSize = 0;
-
-  private int minGramSize = 0;
-
-  /** Initialize the n-gram min and max sizes and the side from which one should start tokenizing. */
-  @Override
-  public void init(Map<String, String> args) {
-    super.init(args);
-    String maxArg = args.get("maxGramSize");
-    maxGramSize = (maxArg != null ? Integer.parseInt(maxArg)
-        : NGramTokenFilter.DEFAULT_MAX_NGRAM_SIZE);
-
-    String minArg = args.get("minGramSize");
-    minGramSize = (minArg != null ? Integer.parseInt(minArg)
-        : NGramTokenFilter.DEFAULT_MIN_NGRAM_SIZE);
-  }
-
-  public NGramTokenFilter create(TokenStream input) {
-    return new NGramTokenFilter(input, minGramSize, maxGramSize);
-  }
-}
+package org.apache.solr.analysis;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.util.Map;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.ngram.NGramTokenFilter;
+
+/**
+ * Creates new instances of {@link NGramTokenFilter}.
+ */
+public class NGramFilterFactory extends BaseTokenFilterFactory {
+  private int maxGramSize = 0;
+
+  private int minGramSize = 0;
+
+  /** Initialize the n-gram min and max sizes and the side from which one should start tokenizing. */
+  @Override
+  public void init(Map<String, String> args) {
+    super.init(args);
+    String maxArg = args.get("maxGramSize");
+    maxGramSize = (maxArg != null ? Integer.parseInt(maxArg)
+        : NGramTokenFilter.DEFAULT_MAX_NGRAM_SIZE);
+
+    String minArg = args.get("minGramSize");
+    minGramSize = (minArg != null ? Integer.parseInt(minArg)
+        : NGramTokenFilter.DEFAULT_MIN_NGRAM_SIZE);
+  }
+
+  public NGramTokenFilter create(TokenStream input) {
+    return new NGramTokenFilter(input, minGramSize, maxGramSize);
+  }
+}
diff --git a/solr/src/java/org/apache/solr/request/BinaryQueryResponseWriter.java b/solr/src/java/org/apache/solr/request/BinaryQueryResponseWriter.java
index 0af1e2f..5cbdbfe 100644
--- a/solr/src/java/org/apache/solr/request/BinaryQueryResponseWriter.java
+++ b/solr/src/java/org/apache/solr/request/BinaryQueryResponseWriter.java
@@ -1,26 +1,26 @@
-package org.apache.solr.request;
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-
-/**
- * @deprecated use org.apache.solr.response.BinaryQueryResponseWriter
- */
-public interface BinaryQueryResponseWriter extends org.apache.solr.response.BinaryQueryResponseWriter 
-{
-  
-}
+package org.apache.solr.request;
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+
+/**
+ * @deprecated use org.apache.solr.response.BinaryQueryResponseWriter
+ */
+public interface BinaryQueryResponseWriter extends org.apache.solr.response.BinaryQueryResponseWriter 
+{
+  
+}
diff --git a/solr/src/java/org/apache/solr/request/BinaryResponseWriter.java b/solr/src/java/org/apache/solr/request/BinaryResponseWriter.java
index f78634e..897abac 100644
--- a/solr/src/java/org/apache/solr/request/BinaryResponseWriter.java
+++ b/solr/src/java/org/apache/solr/request/BinaryResponseWriter.java
@@ -1,26 +1,26 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.solr.request;
-
-
-/**
- * @deprecated use org.apache.solr.response.BinaryResponseWriter
- */
-public class BinaryResponseWriter extends org.apache.solr.response.BinaryResponseWriter 
-{
-	
-}
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.solr.request;
+
+
+/**
+ * @deprecated use org.apache.solr.response.BinaryResponseWriter
+ */
+public class BinaryResponseWriter extends org.apache.solr.response.BinaryResponseWriter 
+{
+	
+}
diff --git a/solr/src/java/org/apache/solr/request/JSONResponseWriter.java b/solr/src/java/org/apache/solr/request/JSONResponseWriter.java
index 0d90f45..39e2e69 100644
--- a/solr/src/java/org/apache/solr/request/JSONResponseWriter.java
+++ b/solr/src/java/org/apache/solr/request/JSONResponseWriter.java
@@ -1,26 +1,26 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.solr.request;
-
-
-/**
- * @deprecated use org.apache.solr.response.JSONResponseWriter
- */
-public class JSONResponseWriter extends org.apache.solr.response.JSONResponseWriter 
-{
-	
-}
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.solr.request;
+
+
+/**
+ * @deprecated use org.apache.solr.response.JSONResponseWriter
+ */
+public class JSONResponseWriter extends org.apache.solr.response.JSONResponseWriter 
+{
+	
+}
diff --git a/solr/src/java/org/apache/solr/request/PHPResponseWriter.java b/solr/src/java/org/apache/solr/request/PHPResponseWriter.java
index decc504..19eb749 100644
--- a/solr/src/java/org/apache/solr/request/PHPResponseWriter.java
+++ b/solr/src/java/org/apache/solr/request/PHPResponseWriter.java
@@ -1,26 +1,26 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.solr.request;
-
-
-/**
- * @deprecated use org.apache.solr.response.PHPResponseWriter
- */
-public class PHPResponseWriter extends org.apache.solr.response.PHPResponseWriter 
-{
-	
-}
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.solr.request;
+
+
+/**
+ * @deprecated use org.apache.solr.response.PHPResponseWriter
+ */
+public class PHPResponseWriter extends org.apache.solr.response.PHPResponseWriter 
+{
+	
+}
diff --git a/solr/src/java/org/apache/solr/request/PHPSerializedResponseWriter.java b/solr/src/java/org/apache/solr/request/PHPSerializedResponseWriter.java
index a5903c3..a2103cc 100644
--- a/solr/src/java/org/apache/solr/request/PHPSerializedResponseWriter.java
+++ b/solr/src/java/org/apache/solr/request/PHPSerializedResponseWriter.java
@@ -1,26 +1,26 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.solr.request;
-
-
-/**
- * @deprecated use org.apache.solr.response.PHPSerializedResponseWriter
- */
-public class PHPSerializedResponseWriter extends org.apache.solr.response.PHPSerializedResponseWriter 
-{
-	
-}
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.solr.request;
+
+
+/**
+ * @deprecated use org.apache.solr.response.PHPSerializedResponseWriter
+ */
+public class PHPSerializedResponseWriter extends org.apache.solr.response.PHPSerializedResponseWriter 
+{
+	
+}
diff --git a/solr/src/java/org/apache/solr/request/PythonResponseWriter.java b/solr/src/java/org/apache/solr/request/PythonResponseWriter.java
index 29d2353..b736eba 100644
--- a/solr/src/java/org/apache/solr/request/PythonResponseWriter.java
+++ b/solr/src/java/org/apache/solr/request/PythonResponseWriter.java
@@ -1,26 +1,26 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.solr.request;
-
-
-/**
- * @deprecated use org.apache.solr.response.PythonResponseWriter
- */
-public class PythonResponseWriter extends org.apache.solr.response.PythonResponseWriter 
-{
-	
-}
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.solr.request;
+
+
+/**
+ * @deprecated use org.apache.solr.response.PythonResponseWriter
+ */
+public class PythonResponseWriter extends org.apache.solr.response.PythonResponseWriter 
+{
+	
+}
diff --git a/solr/src/java/org/apache/solr/request/QueryResponseWriter.java b/solr/src/java/org/apache/solr/request/QueryResponseWriter.java
index c6a17f1..750f480 100644
--- a/solr/src/java/org/apache/solr/request/QueryResponseWriter.java
+++ b/solr/src/java/org/apache/solr/request/QueryResponseWriter.java
@@ -1,26 +1,26 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.solr.request;
-
-
-/**
- * @deprecated use org.apache.solr.response.QueryResponseWriter
- */
-public interface QueryResponseWriter extends org.apache.solr.response.QueryResponseWriter 
-{
-	
-}
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.solr.request;
+
+
+/**
+ * @deprecated use org.apache.solr.response.QueryResponseWriter
+ */
+public interface QueryResponseWriter extends org.apache.solr.response.QueryResponseWriter 
+{
+	
+}
diff --git a/solr/src/java/org/apache/solr/request/RawResponseWriter.java b/solr/src/java/org/apache/solr/request/RawResponseWriter.java
index 1e6ff56..c425aaf 100644
--- a/solr/src/java/org/apache/solr/request/RawResponseWriter.java
+++ b/solr/src/java/org/apache/solr/request/RawResponseWriter.java
@@ -1,26 +1,26 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.solr.request;
-
-
-/**
- * @deprecated use org.apache.solr.response.RawResponseWriter
- */
-public class RawResponseWriter extends org.apache.solr.response.RawResponseWriter 
-{
-	
-}
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.solr.request;
+
+
+/**
+ * @deprecated use org.apache.solr.response.RawResponseWriter
+ */
+public class RawResponseWriter extends org.apache.solr.response.RawResponseWriter 
+{
+	
+}
diff --git a/solr/src/java/org/apache/solr/request/RubyResponseWriter.java b/solr/src/java/org/apache/solr/request/RubyResponseWriter.java
index a596bff..eff59fc 100644
--- a/solr/src/java/org/apache/solr/request/RubyResponseWriter.java
+++ b/solr/src/java/org/apache/solr/request/RubyResponseWriter.java
@@ -1,26 +1,26 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.solr.request;
-
-
-/**
- * @deprecated use org.apache.solr.response.RubyResponseWriter
- */
-public class RubyResponseWriter extends org.apache.solr.response.RubyResponseWriter 
-{
-	
-}
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.solr.request;
+
+
+/**
+ * @deprecated use org.apache.solr.response.RubyResponseWriter
+ */
+public class RubyResponseWriter extends org.apache.solr.response.RubyResponseWriter 
+{
+	
+}
diff --git a/solr/src/java/org/apache/solr/request/SolrQueryResponse.java b/solr/src/java/org/apache/solr/request/SolrQueryResponse.java
index 679ba47..a71bb88 100644
--- a/solr/src/java/org/apache/solr/request/SolrQueryResponse.java
+++ b/solr/src/java/org/apache/solr/request/SolrQueryResponse.java
@@ -1,26 +1,26 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.solr.request;
-
-
-/**
- * @deprecated use org.apache.solr.response.SolrQueryResponse
- */
-public class SolrQueryResponse extends org.apache.solr.response.SolrQueryResponse 
-{
-	
-}
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.solr.request;
+
+
+/**
+ * @deprecated use org.apache.solr.response.SolrQueryResponse
+ */
+public class SolrQueryResponse extends org.apache.solr.response.SolrQueryResponse 
+{
+	
+}
diff --git a/solr/src/java/org/apache/solr/request/TextResponseWriter.java b/solr/src/java/org/apache/solr/request/TextResponseWriter.java
index a9758a3..a205d2e 100644
--- a/solr/src/java/org/apache/solr/request/TextResponseWriter.java
+++ b/solr/src/java/org/apache/solr/request/TextResponseWriter.java
@@ -1,32 +1,32 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.solr.request;
-
-import java.io.Writer;
-
-import org.apache.solr.response.SolrQueryResponse;
-
-
-/**
- * @deprecated use org.apache.solr.response.TextResponseWriter
- */
-public abstract class TextResponseWriter extends org.apache.solr.response.TextResponseWriter 
-{
-  public TextResponseWriter(Writer writer, SolrQueryRequest req, SolrQueryResponse rsp) {
-    super(writer, req, rsp);
-  }
-}
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.solr.request;
+
+import java.io.Writer;
+
+import org.apache.solr.response.SolrQueryResponse;
+
+
+/**
+ * @deprecated use org.apache.solr.response.TextResponseWriter
+ */
+public abstract class TextResponseWriter extends org.apache.solr.response.TextResponseWriter 
+{
+  public TextResponseWriter(Writer writer, SolrQueryRequest req, SolrQueryResponse rsp) {
+    super(writer, req, rsp);
+  }
+}
diff --git a/solr/src/java/org/apache/solr/request/XMLResponseWriter.java b/solr/src/java/org/apache/solr/request/XMLResponseWriter.java
index 6c0ec4c..c1ece98 100644
--- a/solr/src/java/org/apache/solr/request/XMLResponseWriter.java
+++ b/solr/src/java/org/apache/solr/request/XMLResponseWriter.java
@@ -1,26 +1,26 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.solr.request;
-
-
-/**
- * @deprecated use org.apache.solr.response.XMLResponseWriter
- */
-public class XMLResponseWriter extends org.apache.solr.response.XMLResponseWriter 
-{
-	
-}
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.solr.request;
+
+
+/**
+ * @deprecated use org.apache.solr.response.XMLResponseWriter
+ */
+public class XMLResponseWriter extends org.apache.solr.response.XMLResponseWriter 
+{
+	
+}
diff --git a/solr/src/java/org/apache/solr/request/XSLTResponseWriter.java b/solr/src/java/org/apache/solr/request/XSLTResponseWriter.java
index c59f35c..bfa039f 100644
--- a/solr/src/java/org/apache/solr/request/XSLTResponseWriter.java
+++ b/solr/src/java/org/apache/solr/request/XSLTResponseWriter.java
@@ -1,26 +1,26 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.solr.request;
-
-
-/**
- * @deprecated use org.apache.solr.response.XSLTResponseWriter
- */
-public class XSLTResponseWriter extends org.apache.solr.response.XSLTResponseWriter 
-{
-	
-}
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.solr.request;
+
+
+/**
+ * @deprecated use org.apache.solr.response.XSLTResponseWriter
+ */
+public class XSLTResponseWriter extends org.apache.solr.response.XSLTResponseWriter 
+{
+	
+}
diff --git a/solr/src/java/org/apache/solr/response/BaseResponseWriter.java b/solr/src/java/org/apache/solr/response/BaseResponseWriter.java
index 32e8bba..d677e34 100644
--- a/solr/src/java/org/apache/solr/response/BaseResponseWriter.java
+++ b/solr/src/java/org/apache/solr/response/BaseResponseWriter.java
@@ -1,330 +1,330 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.response;
-
-import org.apache.solr.common.util.NamedList;
-import org.apache.solr.common.SolrDocumentList;
-import org.apache.solr.common.SolrDocument;
-import org.apache.solr.common.SolrInputDocument;
-import org.apache.solr.common.params.CommonParams;
-import org.apache.solr.request.SolrQueryRequest;
-import org.apache.solr.search.DocList;
-import org.apache.solr.search.SolrIndexSearcher;
-import org.apache.solr.search.DocIterator;
-import org.apache.solr.schema.FieldType;
-import org.apache.solr.schema.IndexSchema;
-import org.apache.solr.schema.SchemaField;
-
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Fieldable;
-
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.IOException;
-import java.util.List;
-import java.util.Set;
-import java.util.ArrayList;
-
-/**
- * 
- * 
- * This class serves as a basis from which {@link QueryResponseWriter}s can be
- * developed. The class provides a single method
- * {@link #write(SingleResponseWriter, SolrQueryRequest, SolrQueryResponse)}
- * that allows users to implement a {@link SingleResponseWriter} sub-class which
- * defines how to output {@link SolrInputDocument}s or a
- * {@link SolrDocumentList}.
- * 
- * @version $Id$
- * @since 1.5
- * 
- */
-public abstract class BaseResponseWriter {
-
-  private static final Logger LOG = LoggerFactory
-      .getLogger(BaseResponseWriter.class);
-
-  private static final String SCORE_FIELD = "score";
-
-  /**
-   * 
-   * The main method that allows users to write {@link SingleResponseWriter}s
-   * and provide them as the initial parameter <code>responseWriter</code> to
-   * this method which defines how output should be generated.
-   * 
-   * @param responseWriter
-   *          The user-provided {@link SingleResponseWriter} implementation.
-   * @param request
-   *          The provided {@link SolrQueryRequest}.
-   * @param response
-   *          The provided {@link SolrQueryResponse}.
-   * @throws IOException
-   *           If any error occurs.
-   */
-  public void write(SingleResponseWriter responseWriter,
-      SolrQueryRequest request, SolrQueryResponse response) throws IOException {
-    responseWriter.start();
-    NamedList nl = response.getValues();
-    for (int i = 0; i < nl.size(); i++) {
-      String name = nl.getName(i);
-      Object val = nl.getVal(i);
-      if ("responseHeader".equals(name)) {
-        Boolean omitHeader = request.getParams().getBool(CommonParams.OMIT_HEADER);
-        if (omitHeader == null || !omitHeader) responseWriter.writeResponseHeader((NamedList) val);
-      } else if (val instanceof SolrDocumentList) {
-        SolrDocumentList list = (SolrDocumentList) val;
-        DocListInfo info = new DocListInfo((int)list.getNumFound(), list.size(), (int)list.getStart(), list.getMaxScore());
-        if (responseWriter.isStreamingDocs()) {
-          responseWriter.startDocumentList(name,info);
-          for (SolrDocument solrDocument : list)
-            responseWriter.writeDoc(solrDocument);
-          responseWriter.endDocumentList();
-        } else {
-          responseWriter.writeAllDocs(info, list);
-        }
-      } else if (val instanceof DocList) {
-        DocList docList = (DocList) val;
-        int sz = docList.size();
-        IdxInfo idxInfo = new IdxInfo(request.getSchema(), request
-            .getSearcher(), response.getReturnFields());
-        DocListInfo info = new DocListInfo(docList.matches(), docList.size(),docList.offset(),
-            docList.maxScore());
-        DocIterator iterator = docList.iterator();
-        if (responseWriter.isStreamingDocs()) {
-          responseWriter.startDocumentList(name,info);
-          for (int j = 0; j < sz; j++) {
-            SolrDocument sdoc = getDoc(iterator.nextDoc(), idxInfo);
-            if (idxInfo.includeScore && docList.hasScores()) {
-              sdoc.addField(SCORE_FIELD, iterator.score());
-            }
-            responseWriter.writeDoc(sdoc);
-          }
-          responseWriter.end();
-        } else {
-          ArrayList<SolrDocument> list = new ArrayList<SolrDocument>(docList
-              .size());
-          for (int j = 0; j < sz; j++) {
-            SolrDocument sdoc = getDoc(iterator.nextDoc(), idxInfo);
-            if (idxInfo.includeScore && docList.hasScores()) {
-              sdoc.addField(SCORE_FIELD, iterator.score());
-            }
-          }
-          responseWriter.writeAllDocs(info, list);
-        }
-
-      } else {
-        responseWriter.writeOther(name, val);
-
-      }
-    }
-    responseWriter.end();
-
-  }
-
-  /**No ops implementation so that the implementing classes do not have to do it
-   */
-  public void init(NamedList args){}
-
-  private static class IdxInfo {
-    IndexSchema schema;
-    SolrIndexSearcher searcher;
-    Set<String> returnFields;
-    boolean includeScore;
-
-    private IdxInfo(IndexSchema schema, SolrIndexSearcher searcher,
-        Set<String> returnFields) {
-      this.schema = schema;
-      this.searcher = searcher;
-      this.includeScore = returnFields != null
-              && returnFields.contains(SCORE_FIELD);
-      if (returnFields != null) {
-        if (returnFields.size() == 0 || (returnFields.size() == 1 && includeScore) || returnFields.contains("*")) {
-          returnFields = null;  // null means return all stored fields
-        }
-      }
-      this.returnFields = returnFields;
-
-    }
-  }
-
-  private static SolrDocument getDoc(int id, IdxInfo info) throws IOException {
-    Document doc = info.searcher.doc(id);
-    SolrDocument solrDoc = new SolrDocument();
-    for (Fieldable f : (List<Fieldable>) doc.getFields()) {
-      String fieldName = f.name();
-      if (info.returnFields != null && !info.returnFields.contains(fieldName))
-        continue;
-      SchemaField sf = info.schema.getFieldOrNull(fieldName);
-      FieldType ft = null;
-      if (sf != null) ft = sf.getType();
-      Object val = null;
-      if (ft == null) { // handle fields not in the schema
-        if (f.isBinary())
-          val = f.getBinaryValue();
-        else
-          val = f.stringValue();
-      } else {
-        try {
-          if (BinaryResponseWriter.KNOWN_TYPES.contains(ft.getClass())) {
-            val = ft.toObject(f);
-          } else {
-            val = ft.toExternal(f);
-          }
-        } catch (Exception e) {
-          // There is a chance of the underlying field not really matching the
-          // actual field type . So ,it can throw exception
-          LOG.warn("Error reading a field from document : " + solrDoc, e);
-          // if it happens log it and continue
-          continue;
-        }
-      }
-      if (sf != null && sf.multiValued() && !solrDoc.containsKey(fieldName)) {
-        ArrayList l = new ArrayList();
-        l.add(val);
-        solrDoc.addField(fieldName, l);
-      } else {
-        solrDoc.addField(fieldName, val);
-      }
-    }
-
-    return solrDoc;
-  }
-
-  public static class DocListInfo {
-    public final int numFound;
-    public final int start ;
-    public Float maxScore = null;
-    public final int size;
-
-    public DocListInfo(int numFound, int sz,int start, Float maxScore) {
-      this.numFound = numFound;
-      size = sz;
-      this.start = start;
-      this.maxScore = maxScore;
-    }
-  }
-
-  /**
-   * 
-   * Users wanting to define custom {@link QueryResponseWriter}s that deal with
-   * {@link SolrInputDocument}s and {@link SolrDocumentList} should override the
-   * methods for this class. All the methods are w/o body because the user is left
-   * to choose which all methods are required for his purpose
-   */
-  public static abstract class SingleResponseWriter {
-
-    /**
-     * This method is called at the start of the {@link QueryResponseWriter}
-     * output. Override this method if you want to provide a header for your
-     * output, e.g., XML headers, etc.
-     * 
-     * @throws IOException
-     *           if any error occurs.
-     */
-    public void start() throws IOException { }
-
-    /**
-     * This method is called at the start of processing a
-     * {@link SolrDocumentList}. Those that override this method are provided
-     * with {@link DocListInfo} object to use to inspect the output
-     * {@link SolrDocumentList}.
-     * 
-     * @param info Information about the {@link SolrDocumentList} to output.
-     */
-    public void startDocumentList(String name, DocListInfo info) throws IOException { }
-
-    /**
-     * This method writes out a {@link SolrDocument}, on a doc-by-doc basis.
-     * This method is only called when {@link #isStreamingDocs()} returns true.
-     * 
-     * @param solrDocument
-     *          The doc-by-doc {@link SolrDocument} to transform into output as
-     *          part of this {@link QueryResponseWriter}.
-     */
-    public void writeDoc(SolrDocument solrDocument) throws IOException { }
-
-    /**
-     * This method is called at the end of outputting a {@link SolrDocumentList}
-     * or on a doc-by-doc {@link SolrDocument} basis.
-     */
-    public void endDocumentList() throws IOException { } 
-    /**
-     * This method defines how to output the {@link SolrQueryResponse} header
-     * which is provided as a {@link NamedList} parameter.
-     * 
-     * @param responseHeader
-     *          The response header to output.
-     */
-    public void writeResponseHeader(NamedList responseHeader) throws IOException { }
-
-    /**
-     * This method is called at the end of the {@link QueryResponseWriter}
-     * lifecycle. Implement this method to add a footer to your output, e.g., in
-     * the case of XML, the outer tag for your tag set, etc.
-     * 
-     * @throws IOException
-     *           If any error occurs.
-     */
-    public void end() throws IOException { }
-
-    /**
-     * Define this method to control how output is written by this
-     * {@link QueryResponseWriter} if the output is not a
-     * {@link SolrInputDocument} or a {@link SolrDocumentList}.
-     * 
-     * @param name
-     *          The name of the object to output.
-     * @param other
-     *          The object to output.
-     * @throws IOException
-     *           If any error occurs.
-     */
-    public void writeOther(String name, Object other) throws IOException { }
-
-    /**
-     * Overriding this method to return false forces all
-     * {@link SolrInputDocument}s to be spit out as a {@link SolrDocumentList}
-     * so they can be processed as a whole, rather than on a doc-by-doc basis.
-     * If set to false, this method calls
-     * {@link #writeAllDocs(DocListInfo, List)}, else if set to true, then this
-     * method forces calling {@link #writeDoc(SolrDocument)} on a doc-by-doc
-     * basis. one
-     * 
-     * @return True to force {@link #writeDoc(SolrDocument)} to be called, False
-     *         to force {@link #writeAllDocs(DocListInfo, List)} to be called.
-     */
-    public boolean isStreamingDocs() { return true; }
-
-    /**
-     * Writes out all {@link SolrInputDocument}s . This is invoked only if
-     * {@link #isStreamingDocs()} returns false.
-     * 
-     * @param info
-     *          Information about the {@link List} of {@link SolrDocument}s to
-     *          output.
-     * @param allDocs
-     *          A {@link List} of {@link SolrDocument}s to output.
-     * @throws IOException
-     *           If any error occurs.
-     */
-    public void writeAllDocs(DocListInfo info, List<SolrDocument> allDocs) throws IOException { }
-
-  }
-
-}
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.response;
+
+import org.apache.solr.common.util.NamedList;
+import org.apache.solr.common.SolrDocumentList;
+import org.apache.solr.common.SolrDocument;
+import org.apache.solr.common.SolrInputDocument;
+import org.apache.solr.common.params.CommonParams;
+import org.apache.solr.request.SolrQueryRequest;
+import org.apache.solr.search.DocList;
+import org.apache.solr.search.SolrIndexSearcher;
+import org.apache.solr.search.DocIterator;
+import org.apache.solr.schema.FieldType;
+import org.apache.solr.schema.IndexSchema;
+import org.apache.solr.schema.SchemaField;
+
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Fieldable;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.io.IOException;
+import java.util.List;
+import java.util.Set;
+import java.util.ArrayList;
+
+/**
+ * 
+ * 
+ * This class serves as a basis from which {@link QueryResponseWriter}s can be
+ * developed. The class provides a single method
+ * {@link #write(SingleResponseWriter, SolrQueryRequest, SolrQueryResponse)}
+ * that allows users to implement a {@link SingleResponseWriter} sub-class which
+ * defines how to output {@link SolrInputDocument}s or a
+ * {@link SolrDocumentList}.
+ * 
+ * @version $Id$
+ * @since 1.5
+ * 
+ */
+public abstract class BaseResponseWriter {
+
+  private static final Logger LOG = LoggerFactory
+      .getLogger(BaseResponseWriter.class);
+
+  private static final String SCORE_FIELD = "score";
+
+  /**
+   * 
+   * The main method that allows users to write {@link SingleResponseWriter}s
+   * and provide them as the initial parameter <code>responseWriter</code> to
+   * this method which defines how output should be generated.
+   * 
+   * @param responseWriter
+   *          The user-provided {@link SingleResponseWriter} implementation.
+   * @param request
+   *          The provided {@link SolrQueryRequest}.
+   * @param response
+   *          The provided {@link SolrQueryResponse}.
+   * @throws IOException
+   *           If any error occurs.
+   */
+  public void write(SingleResponseWriter responseWriter,
+      SolrQueryRequest request, SolrQueryResponse response) throws IOException {
+    responseWriter.start();
+    NamedList nl = response.getValues();
+    for (int i = 0; i < nl.size(); i++) {
+      String name = nl.getName(i);
+      Object val = nl.getVal(i);
+      if ("responseHeader".equals(name)) {
+        Boolean omitHeader = request.getParams().getBool(CommonParams.OMIT_HEADER);
+        if (omitHeader == null || !omitHeader) responseWriter.writeResponseHeader((NamedList) val);
+      } else if (val instanceof SolrDocumentList) {
+        SolrDocumentList list = (SolrDocumentList) val;
+        DocListInfo info = new DocListInfo((int)list.getNumFound(), list.size(), (int)list.getStart(), list.getMaxScore());
+        if (responseWriter.isStreamingDocs()) {
+          responseWriter.startDocumentList(name,info);
+          for (SolrDocument solrDocument : list)
+            responseWriter.writeDoc(solrDocument);
+          responseWriter.endDocumentList();
+        } else {
+          responseWriter.writeAllDocs(info, list);
+        }
+      } else if (val instanceof DocList) {
+        DocList docList = (DocList) val;
+        int sz = docList.size();
+        IdxInfo idxInfo = new IdxInfo(request.getSchema(), request
+            .getSearcher(), response.getReturnFields());
+        DocListInfo info = new DocListInfo(docList.matches(), docList.size(),docList.offset(),
+            docList.maxScore());
+        DocIterator iterator = docList.iterator();
+        if (responseWriter.isStreamingDocs()) {
+          responseWriter.startDocumentList(name,info);
+          for (int j = 0; j < sz; j++) {
+            SolrDocument sdoc = getDoc(iterator.nextDoc(), idxInfo);
+            if (idxInfo.includeScore && docList.hasScores()) {
+              sdoc.addField(SCORE_FIELD, iterator.score());
+            }
+            responseWriter.writeDoc(sdoc);
+          }
+          responseWriter.end();
+        } else {
+          ArrayList<SolrDocument> list = new ArrayList<SolrDocument>(docList
+              .size());
+          for (int j = 0; j < sz; j++) {
+            SolrDocument sdoc = getDoc(iterator.nextDoc(), idxInfo);
+            if (idxInfo.includeScore && docList.hasScores()) {
+              sdoc.addField(SCORE_FIELD, iterator.score());
+            }
+          }
+          responseWriter.writeAllDocs(info, list);
+        }
+
+      } else {
+        responseWriter.writeOther(name, val);
+
+      }
+    }
+    responseWriter.end();
+
+  }
+
+  /**No ops implementation so that the implementing classes do not have to do it
+   */
+  public void init(NamedList args){}
+
+  private static class IdxInfo {
+    IndexSchema schema;
+    SolrIndexSearcher searcher;
+    Set<String> returnFields;
+    boolean includeScore;
+
+    private IdxInfo(IndexSchema schema, SolrIndexSearcher searcher,
+        Set<String> returnFields) {
+      this.schema = schema;
+      this.searcher = searcher;
+      this.includeScore = returnFields != null
+              && returnFields.contains(SCORE_FIELD);
+      if (returnFields != null) {
+        if (returnFields.size() == 0 || (returnFields.size() == 1 && includeScore) || returnFields.contains("*")) {
+          returnFields = null;  // null means return all stored fields
+        }
+      }
+      this.returnFields = returnFields;
+
+    }
+  }
+
+  private static SolrDocument getDoc(int id, IdxInfo info) throws IOException {
+    Document doc = info.searcher.doc(id);
+    SolrDocument solrDoc = new SolrDocument();
+    for (Fieldable f : (List<Fieldable>) doc.getFields()) {
+      String fieldName = f.name();
+      if (info.returnFields != null && !info.returnFields.contains(fieldName))
+        continue;
+      SchemaField sf = info.schema.getFieldOrNull(fieldName);
+      FieldType ft = null;
+      if (sf != null) ft = sf.getType();
+      Object val = null;
+      if (ft == null) { // handle fields not in the schema
+        if (f.isBinary())
+          val = f.getBinaryValue();
+        else
+          val = f.stringValue();
+      } else {
+        try {
+          if (BinaryResponseWriter.KNOWN_TYPES.contains(ft.getClass())) {
+            val = ft.toObject(f);
+          } else {
+            val = ft.toExternal(f);
+          }
+        } catch (Exception e) {
+          // There is a chance of the underlying field not really matching the
+          // actual field type . So ,it can throw exception
+          LOG.warn("Error reading a field from document : " + solrDoc, e);
+          // if it happens log it and continue
+          continue;
+        }
+      }
+      if (sf != null && sf.multiValued() && !solrDoc.containsKey(fieldName)) {
+        ArrayList l = new ArrayList();
+        l.add(val);
+        solrDoc.addField(fieldName, l);
+      } else {
+        solrDoc.addField(fieldName, val);
+      }
+    }
+
+    return solrDoc;
+  }
+
+  public static class DocListInfo {
+    public final int numFound;
+    public final int start ;
+    public Float maxScore = null;
+    public final int size;
+
+    public DocListInfo(int numFound, int sz,int start, Float maxScore) {
+      this.numFound = numFound;
+      size = sz;
+      this.start = start;
+      this.maxScore = maxScore;
+    }
+  }
+
+  /**
+   * 
+   * Users wanting to define custom {@link QueryResponseWriter}s that deal with
+   * {@link SolrInputDocument}s and {@link SolrDocumentList} should override the
+   * methods for this class. All the methods are w/o body because the user is left
+   * to choose which all methods are required for his purpose
+   */
+  public static abstract class SingleResponseWriter {
+
+    /**
+     * This method is called at the start of the {@link QueryResponseWriter}
+     * output. Override this method if you want to provide a header for your
+     * output, e.g., XML headers, etc.
+     * 
+     * @throws IOException
+     *           if any error occurs.
+     */
+    public void start() throws IOException { }
+
+    /**
+     * This method is called at the start of processing a
+     * {@link SolrDocumentList}. Those that override this method are provided
+     * with {@link DocListInfo} object to use to inspect the output
+     * {@link SolrDocumentList}.
+     * 
+     * @param info Information about the {@link SolrDocumentList} to output.
+     */
+    public void startDocumentList(String name, DocListInfo info) throws IOException { }
+
+    /**
+     * This method writes out a {@link SolrDocument}, on a doc-by-doc basis.
+     * This method is only called when {@link #isStreamingDocs()} returns true.
+     * 
+     * @param solrDocument
+     *          The doc-by-doc {@link SolrDocument} to transform into output as
+     *          part of this {@link QueryResponseWriter}.
+     */
+    public void writeDoc(SolrDocument solrDocument) throws IOException { }
+
+    /**
+     * This method is called at the end of outputting a {@link SolrDocumentList}
+     * or on a doc-by-doc {@link SolrDocument} basis.
+     */
+    public void endDocumentList() throws IOException { } 
+    /**
+     * This method defines how to output the {@link SolrQueryResponse} header
+     * which is provided as a {@link NamedList} parameter.
+     * 
+     * @param responseHeader
+     *          The response header to output.
+     */
+    public void writeResponseHeader(NamedList responseHeader) throws IOException { }
+
+    /**
+     * This method is called at the end of the {@link QueryResponseWriter}
+     * lifecycle. Implement this method to add a footer to your output, e.g., in
+     * the case of XML, the outer tag for your tag set, etc.
+     * 
+     * @throws IOException
+     *           If any error occurs.
+     */
+    public void end() throws IOException { }
+
+    /**
+     * Define this method to control how output is written by this
+     * {@link QueryResponseWriter} if the output is not a
+     * {@link SolrInputDocument} or a {@link SolrDocumentList}.
+     * 
+     * @param name
+     *          The name of the object to output.
+     * @param other
+     *          The object to output.
+     * @throws IOException
+     *           If any error occurs.
+     */
+    public void writeOther(String name, Object other) throws IOException { }
+
+    /**
+     * Overriding this method to return false forces all
+     * {@link SolrInputDocument}s to be spit out as a {@link SolrDocumentList}
+     * so they can be processed as a whole, rather than on a doc-by-doc basis.
+     * If set to false, this method calls
+     * {@link #writeAllDocs(DocListInfo, List)}, else if set to true, then this
+     * method forces calling {@link #writeDoc(SolrDocument)} on a doc-by-doc
+     * basis. one
+     * 
+     * @return True to force {@link #writeDoc(SolrDocument)} to be called, False
+     *         to force {@link #writeAllDocs(DocListInfo, List)} to be called.
+     */
+    public boolean isStreamingDocs() { return true; }
+
+    /**
+     * Writes out all {@link SolrInputDocument}s . This is invoked only if
+     * {@link #isStreamingDocs()} returns false.
+     * 
+     * @param info
+     *          Information about the {@link List} of {@link SolrDocument}s to
+     *          output.
+     * @param allDocs
+     *          A {@link List} of {@link SolrDocument}s to output.
+     * @throws IOException
+     *           If any error occurs.
+     */
+    public void writeAllDocs(DocListInfo info, List<SolrDocument> allDocs) throws IOException { }
+
+  }
+
+}
diff --git a/solr/src/java/org/apache/solr/response/GenericBinaryResponseWriter.java b/solr/src/java/org/apache/solr/response/GenericBinaryResponseWriter.java
index 489ad31..47dbb5c 100644
--- a/solr/src/java/org/apache/solr/response/GenericBinaryResponseWriter.java
+++ b/solr/src/java/org/apache/solr/response/GenericBinaryResponseWriter.java
@@ -1,86 +1,86 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.response;
-
-import java.io.OutputStream;
-import java.io.IOException;
-import java.io.Writer;
-
-import org.apache.solr.common.SolrDocumentList;
-import org.apache.solr.common.SolrInputDocument;
-import org.apache.solr.request.SolrQueryRequest;
-
-/**
- * 
- * 
- * A generic {@link QueryResponseWriter} implementation that requires a user to
- * implement the
- * {@link #getSingleResponseWriter(OutputStream, SolrQueryRequest, SolrQueryResponse)}
- * that defines a {@link SingleResponseWriter} to handle the binary output.
- * 
- * @since 1.5
- * @version $Id$
- * 
- */
-public abstract class GenericBinaryResponseWriter extends BaseResponseWriter
-    implements BinaryQueryResponseWriter {
-
-  /**
-   * 
-   * Writes the binary output data using the {@link SingleResponseWriter}
-   * provided by a call to
-   * {@link #getSingleResponseWriter(OutputStream, SolrQueryRequest, SolrQueryResponse)}
-   * .
-   * 
-   * @param out
-   *          The {@link OutputStream} to write the binary data to.
-   * @param request
-   *          The provided {@link SolrQueryRequest}.
-   * @param response
-   *          The provided {@link SolrQueryResponse}.
-   */
-  public void write(OutputStream out, SolrQueryRequest request,
-      SolrQueryResponse response) throws IOException {
-    super.write(getSingleResponseWriter(out, request, response), request,
-        response);
-  }
-
-  /**
-   * Users of this class should implement this method to define a
-   * {@link SingleResponseWriter} responsible for writing the binary output
-   * given a {@link SolrDocumentList} or doc-by-doc, given a
-   * {@link SolrInputDocument}.
-   * 
-   * @param out
-   *          The {@link OutputStream} to write the binary data response to.
-   * @param request
-   *          The provided {@link SolrQueryRequest}.
-   * @param response
-   *          The provided {@link SolrQueryResponse}.
-   * @return A {@link SingleResponseWriter} that will be used to generate the
-   *         response output from this {@link QueryResponseWriter}.
-   */
-  public abstract SingleResponseWriter getSingleResponseWriter(
-      OutputStream out, SolrQueryRequest request, SolrQueryResponse response);
-
-  /**Just to throw Exception So that the eimplementing classes do not have to do the  same
-   */
-  public void write(Writer writer, SolrQueryRequest request, SolrQueryResponse response) throws IOException {
-    throw new RuntimeException("This is a binary writer , Cannot write to a characterstream");
-  }
-}
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.response;
+
+import java.io.OutputStream;
+import java.io.IOException;
+import java.io.Writer;
+
+import org.apache.solr.common.SolrDocumentList;
+import org.apache.solr.common.SolrInputDocument;
+import org.apache.solr.request.SolrQueryRequest;
+
+/**
+ * 
+ * 
+ * A generic {@link QueryResponseWriter} implementation that requires a user to
+ * implement the
+ * {@link #getSingleResponseWriter(OutputStream, SolrQueryRequest, SolrQueryResponse)}
+ * that defines a {@link SingleResponseWriter} to handle the binary output.
+ * 
+ * @since 1.5
+ * @version $Id$
+ * 
+ */
+public abstract class GenericBinaryResponseWriter extends BaseResponseWriter
+    implements BinaryQueryResponseWriter {
+
+  /**
+   * 
+   * Writes the binary output data using the {@link SingleResponseWriter}
+   * provided by a call to
+   * {@link #getSingleResponseWriter(OutputStream, SolrQueryRequest, SolrQueryResponse)}
+   * .
+   * 
+   * @param out
+   *          The {@link OutputStream} to write the binary data to.
+   * @param request
+   *          The provided {@link SolrQueryRequest}.
+   * @param response
+   *          The provided {@link SolrQueryResponse}.
+   */
+  public void write(OutputStream out, SolrQueryRequest request,
+      SolrQueryResponse response) throws IOException {
+    super.write(getSingleResponseWriter(out, request, response), request,
+        response);
+  }
+
+  /**
+   * Users of this class should implement this method to define a
+   * {@link SingleResponseWriter} responsible for writing the binary output
+   * given a {@link SolrDocumentList} or doc-by-doc, given a
+   * {@link SolrInputDocument}.
+   * 
+   * @param out
+   *          The {@link OutputStream} to write the binary data response to.
+   * @param request
+   *          The provided {@link SolrQueryRequest}.
+   * @param response
+   *          The provided {@link SolrQueryResponse}.
+   * @return A {@link SingleResponseWriter} that will be used to generate the
+   *         response output from this {@link QueryResponseWriter}.
+   */
+  public abstract SingleResponseWriter getSingleResponseWriter(
+      OutputStream out, SolrQueryRequest request, SolrQueryResponse response);
+
+  /**Just to throw Exception So that the eimplementing classes do not have to do the  same
+   */
+  public void write(Writer writer, SolrQueryRequest request, SolrQueryResponse response) throws IOException {
+    throw new RuntimeException("This is a binary writer , Cannot write to a characterstream");
+  }
+}
diff --git a/solr/src/java/org/apache/solr/response/GenericTextResponseWriter.java b/solr/src/java/org/apache/solr/response/GenericTextResponseWriter.java
index e998a32..35ee473 100644
--- a/solr/src/java/org/apache/solr/response/GenericTextResponseWriter.java
+++ b/solr/src/java/org/apache/solr/response/GenericTextResponseWriter.java
@@ -1,78 +1,78 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.response;
-
-import java.io.Writer;
-import java.io.IOException;
-
-import org.apache.solr.common.SolrDocumentList;
-import org.apache.solr.common.SolrInputDocument;
-import org.apache.solr.request.SolrQueryRequest;
-
-/**
- * 
- * 
- * A generic {@link QueryResponseWriter} implementation that requires a user to
- * implement the
- * {@link #getSingleResponseWriter(Writer, SolrQueryRequest, SolrQueryResponse)}
- * that defines a {@link SingleResponseWriter} to handle plain ol' text output.
- * 
- * @since 1.5
- * @version $Id$
- * 
- */
-public abstract class GenericTextResponseWriter extends BaseResponseWriter
-    implements QueryResponseWriter {
-
-  /**
-   * 
-   * Writes text output using the {@link SingleResponseWriter} provided by a
-   * call to
-   * {@link #getSingleResponseWriter(Writer, SolrQueryRequest, SolrQueryResponse)}
-   * .
-   * 
-   * @param out
-   *          The {@link Writer} to write the text output to.
-   * @param request
-   *          The provided {@link SolrQueryRequest}.
-   * @param response
-   *          The provided {@link SolrQueryResponse}.
-   */
-  public void write(Writer writer, SolrQueryRequest request,
-      SolrQueryResponse response) throws IOException {
-    super.write(getSingleResponseWriter(writer, request, response), request,
-        response);
-  }
-
-  /**
-   * Users of this class should implement this method to define a
-   * {@link SingleResponseWriter} responsible for writing text output given a
-   * {@link SolrDocumentList} or doc-by-doc, given a {@link SolrInputDocument}.
-   * 
-   * @param writer
-   *          The {@link Writer} to write the text data response to.
-   * @param request
-   *          The provided {@link SolrQueryRequest}.
-   * @param response
-   *          The provided {@link SolrQueryResponse}.
-   * @return A {@link SingleResponseWriter} that will be used to generate the
-   *         response output from this {@link QueryResponseWriter}.
-   */
-  protected abstract SingleResponseWriter getSingleResponseWriter(
-      Writer writer, SolrQueryRequest request, SolrQueryResponse response);
-}
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.response;
+
+import java.io.Writer;
+import java.io.IOException;
+
+import org.apache.solr.common.SolrDocumentList;
+import org.apache.solr.common.SolrInputDocument;
+import org.apache.solr.request.SolrQueryRequest;
+
+/**
+ * 
+ * 
+ * A generic {@link QueryResponseWriter} implementation that requires a user to
+ * implement the
+ * {@link #getSingleResponseWriter(Writer, SolrQueryRequest, SolrQueryResponse)}
+ * that defines a {@link SingleResponseWriter} to handle plain ol' text output.
+ * 
+ * @since 1.5
+ * @version $Id$
+ * 
+ */
+public abstract class GenericTextResponseWriter extends BaseResponseWriter
+    implements QueryResponseWriter {
+
+  /**
+   * 
+   * Writes text output using the {@link SingleResponseWriter} provided by a
+   * call to
+   * {@link #getSingleResponseWriter(Writer, SolrQueryRequest, SolrQueryResponse)}
+   * .
+   * 
+   * @param out
+   *          The {@link Writer} to write the text output to.
+   * @param request
+   *          The provided {@link SolrQueryRequest}.
+   * @param response
+   *          The provided {@link SolrQueryResponse}.
+   */
+  public void write(Writer writer, SolrQueryRequest request,
+      SolrQueryResponse response) throws IOException {
+    super.write(getSingleResponseWriter(writer, request, response), request,
+        response);
+  }
+
+  /**
+   * Users of this class should implement this method to define a
+   * {@link SingleResponseWriter} responsible for writing text output given a
+   * {@link SolrDocumentList} or doc-by-doc, given a {@link SolrInputDocument}.
+   * 
+   * @param writer
+   *          The {@link Writer} to write the text data response to.
+   * @param request
+   *          The provided {@link SolrQueryRequest}.
+   * @param response
+   *          The provided {@link SolrQueryResponse}.
+   * @return A {@link SingleResponseWriter} that will be used to generate the
+   *         response output from this {@link QueryResponseWriter}.
+   */
+  protected abstract SingleResponseWriter getSingleResponseWriter(
+      Writer writer, SolrQueryRequest request, SolrQueryResponse response);
+}
diff --git a/solr/src/java/org/apache/solr/search/FieldQParserPlugin.java b/solr/src/java/org/apache/solr/search/FieldQParserPlugin.java
index ef399ae..d1d9a31 100644
--- a/solr/src/java/org/apache/solr/search/FieldQParserPlugin.java
+++ b/solr/src/java/org/apache/solr/search/FieldQParserPlugin.java
@@ -1,62 +1,62 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.solr.search;
-
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.Token;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.queryParser.ParseException;
-import org.apache.lucene.search.*;
-import org.apache.solr.common.params.SolrParams;
-import org.apache.solr.common.util.NamedList;
-import org.apache.solr.common.SolrException;
-import org.apache.solr.request.SolrQueryRequest;
-import org.apache.solr.schema.FieldType;
-import org.apache.solr.schema.TextField;
-import org.apache.solr.schema.SchemaField;
-
-import java.io.IOException;
-import java.io.StringReader;
-import java.util.ArrayList;
-
-
-/**
- * Create a field query from the input value, applying text analysis and constructing a phrase query if appropriate.
- * <br>Other parameters: <code>f</code>, the field
- * <br>Example: <code>{!field f=myfield}Foo Bar</code> creates a phrase query with "foo" followed by "bar"
- * if the analyzer for myfield is a text field with an analyzer that splits on whitespace and lowercases terms.
- * This is generally equivalent to the Lucene query parser expression <code>myfield:"Foo Bar"</code>
- */
-public class FieldQParserPlugin extends QParserPlugin {
-  public static String NAME = "field";
-
-  public void init(NamedList args) {
-  }
-
-  public QParser createParser(String qstr, SolrParams localParams, SolrParams params, SolrQueryRequest req) {
-    return new QParser(qstr, localParams, params, req) {
-      public Query parse() throws ParseException {
-        String field = localParams.get(QueryParsing.F);
-        String queryText = localParams.get(QueryParsing.V);
-        SchemaField sf = req.getSchema().getField(field);
-        FieldType ft = sf.getType();
-        return ft.getFieldQuery(this, sf, queryText);
-      }
-    };
-  }
-}
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.solr.search;
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.Token;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.queryParser.ParseException;
+import org.apache.lucene.search.*;
+import org.apache.solr.common.params.SolrParams;
+import org.apache.solr.common.util.NamedList;
+import org.apache.solr.common.SolrException;
+import org.apache.solr.request.SolrQueryRequest;
+import org.apache.solr.schema.FieldType;
+import org.apache.solr.schema.TextField;
+import org.apache.solr.schema.SchemaField;
+
+import java.io.IOException;
+import java.io.StringReader;
+import java.util.ArrayList;
+
+
+/**
+ * Create a field query from the input value, applying text analysis and constructing a phrase query if appropriate.
+ * <br>Other parameters: <code>f</code>, the field
+ * <br>Example: <code>{!field f=myfield}Foo Bar</code> creates a phrase query with "foo" followed by "bar"
+ * if the analyzer for myfield is a text field with an analyzer that splits on whitespace and lowercases terms.
+ * This is generally equivalent to the Lucene query parser expression <code>myfield:"Foo Bar"</code>
+ */
+public class FieldQParserPlugin extends QParserPlugin {
+  public static String NAME = "field";
+
+  public void init(NamedList args) {
+  }
+
+  public QParser createParser(String qstr, SolrParams localParams, SolrParams params, SolrQueryRequest req) {
+    return new QParser(qstr, localParams, params, req) {
+      public Query parse() throws ParseException {
+        String field = localParams.get(QueryParsing.F);
+        String queryText = localParams.get(QueryParsing.V);
+        SchemaField sf = req.getSchema().getField(field);
+        FieldType ft = sf.getType();
+        return ft.getFieldQuery(this, sf, queryText);
+      }
+    };
+  }
+}
diff --git a/solr/src/java/org/apache/solr/search/FunctionQParserPlugin.java b/solr/src/java/org/apache/solr/search/FunctionQParserPlugin.java
index 0f66ec2..164e1cc 100644
--- a/solr/src/java/org/apache/solr/search/FunctionQParserPlugin.java
+++ b/solr/src/java/org/apache/solr/search/FunctionQParserPlugin.java
@@ -1,37 +1,37 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.solr.search;
-
-import org.apache.solr.common.params.SolrParams;
-import org.apache.solr.common.util.NamedList;
-import org.apache.solr.request.SolrQueryRequest;
-
-/**
- * Create a function query from the input value.
- * <br>Other parameters: none
- * <br>Example: <code>{!func}log(foo)</code>
- */
-public class FunctionQParserPlugin extends QParserPlugin {
-  public static String NAME = "func";
-
-  public void init(NamedList args) {
-  }
-
-  public QParser createParser(String qstr, SolrParams localParams, SolrParams params, SolrQueryRequest req) {
-    return new FunctionQParser(qstr, localParams, params, req);
-  }
-}
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.solr.search;
+
+import org.apache.solr.common.params.SolrParams;
+import org.apache.solr.common.util.NamedList;
+import org.apache.solr.request.SolrQueryRequest;
+
+/**
+ * Create a function query from the input value.
+ * <br>Other parameters: none
+ * <br>Example: <code>{!func}log(foo)</code>
+ */
+public class FunctionQParserPlugin extends QParserPlugin {
+  public static String NAME = "func";
+
+  public void init(NamedList args) {
+  }
+
+  public QParser createParser(String qstr, SolrParams localParams, SolrParams params, SolrQueryRequest req) {
+    return new FunctionQParser(qstr, localParams, params, req);
+  }
+}
diff --git a/solr/src/java/org/apache/solr/search/RawQParserPlugin.java b/solr/src/java/org/apache/solr/search/RawQParserPlugin.java
index a56b0e6..dae4a13 100644
--- a/solr/src/java/org/apache/solr/search/RawQParserPlugin.java
+++ b/solr/src/java/org/apache/solr/search/RawQParserPlugin.java
@@ -1,45 +1,45 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.solr.search;
-
-import org.apache.lucene.index.Term;
-import org.apache.lucene.queryParser.ParseException;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.TermQuery;
-import org.apache.solr.common.params.SolrParams;
-import org.apache.solr.common.util.NamedList;
-import org.apache.solr.request.SolrQueryRequest;
-
-/**
- * Create a term query from the input value without any text analysis or transformation whatsoever.
- * <br>Other parameters: <code>f</code>, the field
- * <br>Example: <code>{!raw f=myfield}Foo Bar</code> creates <code>TermQuery(Term("myfield","Foo Bar"))</code>
- */
-public class RawQParserPlugin extends QParserPlugin {
-  public static String NAME = "raw";
-
-  public void init(NamedList args) {
-  }
-
-  public QParser createParser(String qstr, SolrParams localParams, SolrParams params, SolrQueryRequest req) {
-    return new QParser(qstr, localParams, params, req) {
-      public Query parse() throws ParseException {
-        return new TermQuery(new Term(localParams.get(QueryParsing.F), localParams.get(QueryParsing.V)));
-      }
-    };
-  }
-}
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.solr.search;
+
+import org.apache.lucene.index.Term;
+import org.apache.lucene.queryParser.ParseException;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.TermQuery;
+import org.apache.solr.common.params.SolrParams;
+import org.apache.solr.common.util.NamedList;
+import org.apache.solr.request.SolrQueryRequest;
+
+/**
+ * Create a term query from the input value without any text analysis or transformation whatsoever.
+ * <br>Other parameters: <code>f</code>, the field
+ * <br>Example: <code>{!raw f=myfield}Foo Bar</code> creates <code>TermQuery(Term("myfield","Foo Bar"))</code>
+ */
+public class RawQParserPlugin extends QParserPlugin {
+  public static String NAME = "raw";
+
+  public void init(NamedList args) {
+  }
+
+  public QParser createParser(String qstr, SolrParams localParams, SolrParams params, SolrQueryRequest req) {
+    return new QParser(qstr, localParams, params, req) {
+      public Query parse() throws ParseException {
+        return new TermQuery(new Term(localParams.get(QueryParsing.F), localParams.get(QueryParsing.V)));
+      }
+    };
+  }
+}
diff --git a/solr/src/java/org/apache/solr/search/SolrFilter.java b/solr/src/java/org/apache/solr/search/SolrFilter.java
index 6d7e94f..c09d569 100644
--- a/solr/src/java/org/apache/solr/search/SolrFilter.java
+++ b/solr/src/java/org/apache/solr/search/SolrFilter.java
@@ -1,46 +1,46 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.search;
-
-import org.apache.lucene.search.Filter;
-import org.apache.lucene.search.Searcher;
-import org.apache.lucene.search.DocIdSet;
-import org.apache.lucene.index.IndexReader;
-
-import java.util.Map;
-import java.io.IOException;
-
-
-/** A SolrFilter extends the Lucene Filter and adds extra semantics such as passing on
- * weight context info for function queries.
- *
- * Experimental and subject to change.
- */
-public abstract class SolrFilter extends Filter {
-
-  /** Implementations should propagate createWeight to sub-ValueSources which can store weight info in the context.
-   * The context object will be passed to getDocIdSet() where this info can be retrieved. */
-  public abstract void createWeight(Map context, Searcher searcher) throws IOException;
-  
-  public abstract DocIdSet getDocIdSet(Map context, IndexReader reader) throws IOException;
-
-  @Override
-  public DocIdSet getDocIdSet(IndexReader reader) throws IOException {
-    return getDocIdSet(null, reader);
-  }
-}
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.search;
+
+import org.apache.lucene.search.Filter;
+import org.apache.lucene.search.Searcher;
+import org.apache.lucene.search.DocIdSet;
+import org.apache.lucene.index.IndexReader;
+
+import java.util.Map;
+import java.io.IOException;
+
+
+/** A SolrFilter extends the Lucene Filter and adds extra semantics such as passing on
+ * weight context info for function queries.
+ *
+ * Experimental and subject to change.
+ */
+public abstract class SolrFilter extends Filter {
+
+  /** Implementations should propagate createWeight to sub-ValueSources which can store weight info in the context.
+   * The context object will be passed to getDocIdSet() where this info can be retrieved. */
+  public abstract void createWeight(Map context, Searcher searcher) throws IOException;
+  
+  public abstract DocIdSet getDocIdSet(Map context, IndexReader reader) throws IOException;
+
+  @Override
+  public DocIdSet getDocIdSet(IndexReader reader) throws IOException {
+    return getDocIdSet(null, reader);
+  }
+}
diff --git a/solr/src/java/org/apache/solr/util/plugin/PluginInfoInitialized.java b/solr/src/java/org/apache/solr/util/plugin/PluginInfoInitialized.java
index b7ab00f..36e6e75 100644
--- a/solr/src/java/org/apache/solr/util/plugin/PluginInfoInitialized.java
+++ b/solr/src/java/org/apache/solr/util/plugin/PluginInfoInitialized.java
@@ -1,31 +1,31 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.solr.util.plugin;
-
-import org.apache.solr.core.PluginInfo;
-
-/**
- * A plugin that can be initialized with a PluginInfo
- *
- * @version $Id$
- * @since solr 1.4
- */
-public interface PluginInfoInitialized {
-  
-  public void init(PluginInfo info);
-
-}
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.solr.util.plugin;
+
+import org.apache.solr.core.PluginInfo;
+
+/**
+ * A plugin that can be initialized with a PluginInfo
+ *
+ * @version $Id$
+ * @since solr 1.4
+ */
+public interface PluginInfoInitialized {
+  
+  public void init(PluginInfo info);
+
+}
diff --git a/solr/src/test/org/apache/solr/core/TestBadConfig.java b/solr/src/test/org/apache/solr/core/TestBadConfig.java
index 4b8a3f3..e0e8f24 100644
--- a/solr/src/test/org/apache/solr/core/TestBadConfig.java
+++ b/solr/src/test/org/apache/solr/core/TestBadConfig.java
@@ -1,57 +1,57 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.core;
-
-import org.apache.solr.SolrTestCaseJ4;
-import org.apache.solr.util.AbstractSolrTestCase;
-import org.apache.solr.util.TestHarness;
-import org.junit.BeforeClass;
-
-import java.io.File;
-
-public class TestBadConfig extends AbstractSolrTestCase {
-
-  public String getSchemaFile() { return "schema.xml"; }
-  public String getSolrConfigFile() { return "bad_solrconfig.xml"; }
-
-  public void setUp() throws Exception {
-
-    dataDir = new File(System.getProperty("java.io.tmpdir")
-                       + System.getProperty("file.separator")
-                       + getClass().getName());
-    dataDir.mkdirs();
-    try {
-     SolrTestCaseJ4.ignoreException("unset.sys.property");
-
-      solrConfig = new SolrConfig(getSolrConfigFile());
-      h = new TestHarness( dataDir.getAbsolutePath(),
-                           solrConfig,
-                           getSchemaFile());
-      fail("Exception should have been thrown");
-    } catch (Exception e) {
-      assertTrue(e.getMessage().contains("unset.sys.property"));
-      SolrTestCaseJ4.resetExceptionIgnores();
-    }
-  }
-    
-
-  public void testNothing() {
-    // Empty test case as the real test is that the initialization of the TestHarness fails
-    assertTrue(true);
-  }
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.core;
+
+import org.apache.solr.SolrTestCaseJ4;
+import org.apache.solr.util.AbstractSolrTestCase;
+import org.apache.solr.util.TestHarness;
+import org.junit.BeforeClass;
+
+import java.io.File;
+
+public class TestBadConfig extends AbstractSolrTestCase {
+
+  public String getSchemaFile() { return "schema.xml"; }
+  public String getSolrConfigFile() { return "bad_solrconfig.xml"; }
+
+  public void setUp() throws Exception {
+
+    dataDir = new File(System.getProperty("java.io.tmpdir")
+                       + System.getProperty("file.separator")
+                       + getClass().getName());
+    dataDir.mkdirs();
+    try {
+     SolrTestCaseJ4.ignoreException("unset.sys.property");
+
+      solrConfig = new SolrConfig(getSolrConfigFile());
+      h = new TestHarness( dataDir.getAbsolutePath(),
+                           solrConfig,
+                           getSchemaFile());
+      fail("Exception should have been thrown");
+    } catch (Exception e) {
+      assertTrue(e.getMessage().contains("unset.sys.property"));
+      SolrTestCaseJ4.resetExceptionIgnores();
+    }
+  }
+    
+
+  public void testNothing() {
+    // Empty test case as the real test is that the initialization of the TestHarness fails
+    assertTrue(true);
+  }
 }
\ No newline at end of file
diff --git a/solr/src/test/org/apache/solr/core/TestLegacyMergeSchedulerPolicyConfig.java b/solr/src/test/org/apache/solr/core/TestLegacyMergeSchedulerPolicyConfig.java
index 771d257..712dc15 100644
--- a/solr/src/test/org/apache/solr/core/TestLegacyMergeSchedulerPolicyConfig.java
+++ b/solr/src/test/org/apache/solr/core/TestLegacyMergeSchedulerPolicyConfig.java
@@ -1,36 +1,36 @@
-package org.apache.solr.core;
-
-import java.io.IOException;
-
-import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.LogDocMergePolicy;
-import org.apache.lucene.index.SerialMergeScheduler;
-import org.apache.solr.update.DirectUpdateHandler2;
-import org.apache.solr.util.AbstractSolrTestCase;
-
-public class TestLegacyMergeSchedulerPolicyConfig extends AbstractSolrTestCase {
-  public String getSchemaFile() {
-    return "schema.xml";
-  }
-
-  public String getSolrConfigFile() {
-    return "solrconfig-legacy.xml";
-  }
-  
-  public void testLegacy() throws Exception {
-    IndexWriter writer = new ExposeWriterHandler().getWriter();
-    assertTrue(writer.getMergePolicy().getClass().getName().equals(LogDocMergePolicy.class.getName()));
-    assertTrue(writer.getMergeScheduler().getClass().getName().equals(SerialMergeScheduler.class.getName()));
-  }
-  
-  class ExposeWriterHandler extends DirectUpdateHandler2 {
-    public ExposeWriterHandler() throws IOException {
-      super(h.getCore());
-    }
-
-    public IndexWriter getWriter() throws IOException {
-      forceOpenWriter();
-      return writer;
-    }
-  }
-}
+package org.apache.solr.core;
+
+import java.io.IOException;
+
+import org.apache.lucene.index.IndexWriter;
+import org.apache.lucene.index.LogDocMergePolicy;
+import org.apache.lucene.index.SerialMergeScheduler;
+import org.apache.solr.update.DirectUpdateHandler2;
+import org.apache.solr.util.AbstractSolrTestCase;
+
+public class TestLegacyMergeSchedulerPolicyConfig extends AbstractSolrTestCase {
+  public String getSchemaFile() {
+    return "schema.xml";
+  }
+
+  public String getSolrConfigFile() {
+    return "solrconfig-legacy.xml";
+  }
+  
+  public void testLegacy() throws Exception {
+    IndexWriter writer = new ExposeWriterHandler().getWriter();
+    assertTrue(writer.getMergePolicy().getClass().getName().equals(LogDocMergePolicy.class.getName()));
+    assertTrue(writer.getMergeScheduler().getClass().getName().equals(SerialMergeScheduler.class.getName()));
+  }
+  
+  class ExposeWriterHandler extends DirectUpdateHandler2 {
+    public ExposeWriterHandler() throws IOException {
+      super(h.getCore());
+    }
+
+    public IndexWriter getWriter() throws IOException {
+      forceOpenWriter();
+      return writer;
+    }
+  }
+}
diff --git a/solr/src/test/org/apache/solr/core/TestPropInject.java b/solr/src/test/org/apache/solr/core/TestPropInject.java
index d0fa763..1db6d0e 100644
--- a/solr/src/test/org/apache/solr/core/TestPropInject.java
+++ b/solr/src/test/org/apache/solr/core/TestPropInject.java
@@ -1,65 +1,65 @@
-package org.apache.solr.core;
-
-import java.io.IOException;
-
-import org.apache.lucene.index.ConcurrentMergeScheduler;
-import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.LogByteSizeMergePolicy;
-import org.apache.solr.update.DirectUpdateHandler2;
-import org.apache.solr.util.AbstractSolrTestCase;
-
-public class TestPropInject extends AbstractSolrTestCase {
-  public String getSchemaFile() {
-    return "schema.xml";
-  }
-
-  public String getSolrConfigFile() {
-    if ("testMergePolicyDefaults".equals(getName()) || "testPropsDefaults".equals(getName()))
-      return "solrconfig-propinject-indexdefault.xml";
-    else
-      return "solrconfig-propinject.xml";
-  }
-  
-  class ExposeWriterHandler extends DirectUpdateHandler2 {
-    public ExposeWriterHandler() throws IOException {
-      super(h.getCore());
-    }
-
-    public IndexWriter getWriter() throws IOException {
-      forceOpenWriter();
-      return writer;
-    }
-  }
-
-  public void testMergePolicy() throws Exception {
-    ExposeWriterHandler uh = new ExposeWriterHandler();
-    IndexWriter writer = uh.getWriter();
-    LogByteSizeMergePolicy mp = (LogByteSizeMergePolicy)writer.getMergePolicy();
-    assertEquals(64.0, mp.getMaxMergeMB());
-    uh.close();
-  }
-
-  public void testMergePolicyDefaults() throws Exception {
-    ExposeWriterHandler uh = new ExposeWriterHandler();
-    IndexWriter writer = uh.getWriter();
-    LogByteSizeMergePolicy mp = (LogByteSizeMergePolicy)writer.getMergePolicy();
-    assertEquals(32.0, mp.getMaxMergeMB());
-    uh.close();
-  }
-  
-  public void testProps() throws Exception {
-    ExposeWriterHandler uh = new ExposeWriterHandler();
-    IndexWriter writer = uh.getWriter();
-    ConcurrentMergeScheduler cms = (ConcurrentMergeScheduler)writer.getMergeScheduler();
-    assertEquals(2, cms.getMaxThreadCount());
-    uh.close();
-  }
-
-  public void testPropsDefaults() throws Exception {
-    ExposeWriterHandler uh = new ExposeWriterHandler();
-    IndexWriter writer = uh.getWriter();
-    ConcurrentMergeScheduler cms = (ConcurrentMergeScheduler)writer.getMergeScheduler();
-    assertEquals(4, cms.getMaxThreadCount());
-    uh.close();
-  }
-}
+package org.apache.solr.core;
+
+import java.io.IOException;
+
+import org.apache.lucene.index.ConcurrentMergeScheduler;
+import org.apache.lucene.index.IndexWriter;
+import org.apache.lucene.index.LogByteSizeMergePolicy;
+import org.apache.solr.update.DirectUpdateHandler2;
+import org.apache.solr.util.AbstractSolrTestCase;
+
+public class TestPropInject extends AbstractSolrTestCase {
+  public String getSchemaFile() {
+    return "schema.xml";
+  }
+
+  public String getSolrConfigFile() {
+    if ("testMergePolicyDefaults".equals(getName()) || "testPropsDefaults".equals(getName()))
+      return "solrconfig-propinject-indexdefault.xml";
+    else
+      return "solrconfig-propinject.xml";
+  }
+  
+  class ExposeWriterHandler extends DirectUpdateHandler2 {
+    public ExposeWriterHandler() throws IOException {
+      super(h.getCore());
+    }
+
+    public IndexWriter getWriter() throws IOException {
+      forceOpenWriter();
+      return writer;
+    }
+  }
+
+  public void testMergePolicy() throws Exception {
+    ExposeWriterHandler uh = new ExposeWriterHandler();
+    IndexWriter writer = uh.getWriter();
+    LogByteSizeMergePolicy mp = (LogByteSizeMergePolicy)writer.getMergePolicy();
+    assertEquals(64.0, mp.getMaxMergeMB());
+    uh.close();
+  }
+
+  public void testMergePolicyDefaults() throws Exception {
+    ExposeWriterHandler uh = new ExposeWriterHandler();
+    IndexWriter writer = uh.getWriter();
+    LogByteSizeMergePolicy mp = (LogByteSizeMergePolicy)writer.getMergePolicy();
+    assertEquals(32.0, mp.getMaxMergeMB());
+    uh.close();
+  }
+  
+  public void testProps() throws Exception {
+    ExposeWriterHandler uh = new ExposeWriterHandler();
+    IndexWriter writer = uh.getWriter();
+    ConcurrentMergeScheduler cms = (ConcurrentMergeScheduler)writer.getMergeScheduler();
+    assertEquals(2, cms.getMaxThreadCount());
+    uh.close();
+  }
+
+  public void testPropsDefaults() throws Exception {
+    ExposeWriterHandler uh = new ExposeWriterHandler();
+    IndexWriter writer = uh.getWriter();
+    ConcurrentMergeScheduler cms = (ConcurrentMergeScheduler)writer.getMergeScheduler();
+    assertEquals(4, cms.getMaxThreadCount());
+    uh.close();
+  }
+}
diff --git a/solr/src/test/test-files/solr/conf/protwords.txt b/solr/src/test/test-files/solr/conf/protwords.txt
index f896cfa..ab7e3e2 100644
--- a/solr/src/test/test-files/solr/conf/protwords.txt
+++ b/solr/src/test/test-files/solr/conf/protwords.txt
@@ -1,23 +1,23 @@
-# Licensed to the Apache Software Foundation (ASF) under one or more
-# contributor license agreements.  See the NOTICE file distributed with
-# this work for additional information regarding copyright ownership.
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-#use a protected word file to avoid stemming two
-#unrelated words to the same base word.
-#to test, we will use words that would normally obviously be stemmed.
-cats
-ridding
-c#
-c++
-.net
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+#use a protected word file to avoid stemming two
+#unrelated words to the same base word.
+#to test, we will use words that would normally obviously be stemmed.
+cats
+ridding
+c#
+c++
+.net
diff --git a/solr/src/test/test-files/solr/conf/solrconfig-legacy.xml b/solr/src/test/test-files/solr/conf/solrconfig-legacy.xml
index 15b7abc..645eab8 100644
--- a/solr/src/test/test-files/solr/conf/solrconfig-legacy.xml
+++ b/solr/src/test/test-files/solr/conf/solrconfig-legacy.xml
@@ -1,461 +1,461 @@
-<?xml version="1.0" ?>
-
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-
-<!-- $Id: solrconfig.xml 382610 2006-03-03 01:43:03Z yonik $
-     $Source$
-     $Name$
-
-
-
-     This is a "kitchen sink" config file that tests can use.
-     When writting a new test, feel free to add *new* items (plugins,
-     config options, etc...) as long as they don't break any existing
-     tests.  if you need to test something esoteric please add a new
-     "solrconfig-your-esoteric-purpose.xml" config file.
-
-     Note in particular that this test is used by MinimalSchemaTest so 
-     Anything added to this file needs to work correctly even if there
-     is now uniqueKey or defaultSearch Field.
-
-
-  -->
-
-<config>
-
-  <jmx />
-
-  <!-- Used to specify an alternate directory to hold all index data.
-       It defaults to "index" if not present, and should probably
-       not be changed if replication is in use. -->
-  <dataDir>${solr.data.dir:./solr/data}</dataDir>
-
-  <!--  The DirectoryFactory to use for indexes.
-        solr.StandardDirectoryFactory, the default, is filesystem based.
-        solr.RAMDirectoryFactory is memory based and not persistent. -->
-  <directoryFactory name="DirectoryFactory" class="${solr.directoryFactory:solr.RAMDirectoryFactory}"/>
-
-
-  <indexDefaults>
-   <!-- Values here affect all index writers and act as a default
-   unless overridden. -->
-    <!-- Values here affect all index writers and act as a default unless overridden. -->
-    <useCompoundFile>false</useCompoundFile>
-    <mergeFactor>10</mergeFactor>
-    <!-- If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
-     -->
-    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
-    <!-- Tell Lucene when to flush documents to disk.
-    Giving Lucene more memory for indexing means faster indexing at the cost of more RAM
-
-    If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
-
-    -->
-    <ramBufferSizeMB>32</ramBufferSizeMB>
-    <maxMergeDocs>2147483647</maxMergeDocs>
-    <maxFieldLength>10000</maxFieldLength>
-    <writeLockTimeout>1000</writeLockTimeout>
-    <commitLockTimeout>10000</commitLockTimeout>
-
-    <!-- 
-     Expert: Turn on Lucene's auto commit capability.
-
-     NOTE: Despite the name, this value does not have any relation to Solr's autoCommit functionality
-
-     -->
-    <luceneAutoCommit>false</luceneAutoCommit>
-
-    <!--
-     Expert:
-     The Merge Policy in Lucene controls how merging is handled by Lucene.  The default in 2.3 is the LogByteSizeMergePolicy, previous
-     versions used LogDocMergePolicy.
-
-     LogByteSizeMergePolicy chooses segments to merge based on their size.  The Lucene 2.2 default, LogDocMergePolicy chose when
-     to merge based on number of documents
-
-     Other implementations of MergePolicy must have a no-argument constructor
-     -->
-    <mergePolicy>org.apache.lucene.index.LogDocMergePolicy</mergePolicy>
-
-    <!--
-     Expert:
-     The Merge Scheduler in Lucene controls how merges are performed.  The ConcurrentMergeScheduler (Lucene 2.3 default)
-      can perform merges in the background using separate threads.  The SerialMergeScheduler (Lucene 2.2 default) does not.
-     -->
-    <mergeScheduler>org.apache.lucene.index.SerialMergeScheduler</mergeScheduler>
-    <!-- these are global... can't currently override per index -->
-    <writeLockTimeout>1000</writeLockTimeout>
-    <commitLockTimeout>10000</commitLockTimeout>
-
-    <lockType>single</lockType>
-  </indexDefaults>
-
-  <mainIndex>
-    <!-- lucene options specific to the main on-disk lucene index -->
-    <useCompoundFile>false</useCompoundFile>
-    <mergeFactor>10</mergeFactor>
-    <!-- for better multi-segment testing, we are using slower
-    indexing properties of maxBufferedDocs=10 and LogDocMergePolicy.
-    -->
-    <maxBufferedDocs>10</maxBufferedDocs>
-    <maxMergeDocs>2147483647</maxMergeDocs>
-    <maxFieldLength>10000</maxFieldLength>
-    <mergePolicy>org.apache.lucene.index.LogDocMergePolicy</mergePolicy>
-    <mergeScheduler>org.apache.lucene.index.SerialMergeScheduler</mergeScheduler>
-    <unlockOnStartup>true</unlockOnStartup>
-  </mainIndex>
-
-  <updateHandler class="solr.DirectUpdateHandler2">
-
-    <!-- autocommit pending docs if certain criteria are met 
-    <autoCommit> 
-      <maxDocs>10000</maxDocs>
-      <maxTime>3600000</maxTime> 
-    </autoCommit>
-    -->
-    <!-- represents a lower bound on the frequency that commits may
-    occur (in seconds). NOTE: not yet implemented
-    
-    <commitIntervalLowerBound>0</commitIntervalLowerBound>
-    -->
-
-    <!-- The RunExecutableListener executes an external command.
-         exe - the name of the executable to run
-         dir - dir to use as the current working directory. default="."
-         wait - the calling thread waits until the executable returns. default="true"
-         args - the arguments to pass to the program.  default=nothing
-         env - environment variables to set.  default=nothing
-      -->
-    <!-- A postCommit event is fired after every commit
-    <listener event="postCommit" class="solr.RunExecutableListener">
-      <str name="exe">/var/opt/resin3/__PORT__/scripts/solr/snapshooter</str>
-      <str name="dir">/var/opt/resin3/__PORT__</str>
-      <bool name="wait">true</bool>
-      <arr name="args"> <str>arg1</str> <str>arg2</str> </arr>
-      <arr name="env"> <str>MYVAR=val1</str> </arr>
-    </listener>
-    -->
-
-
-  </updateHandler>
-
-
-  <query>
-    <!-- Maximum number of clauses in a boolean query... can affect
-        range or wildcard queries that expand to big boolean
-        queries.  An exception is thrown if exceeded.
-    -->
-    <maxBooleanClauses>1024</maxBooleanClauses>
-
-
-    <!-- Cache specification for Filters or DocSets - unordered set of *all* documents
-         that match a particular query.
-      -->
-    <filterCache
-      class="solr.search.FastLRUCache"
-      size="512"
-      initialSize="512"
-      autowarmCount="256"/>
-
-    <queryResultCache
-      class="solr.search.LRUCache"
-      size="512"
-      initialSize="512"
-      autowarmCount="1024"/>
-
-    <documentCache
-      class="solr.search.LRUCache"
-      size="512"
-      initialSize="512"
-      autowarmCount="0"/>
-
-    <!-- If true, stored fields that are not requested will be loaded lazily.
-    -->
-    <enableLazyFieldLoading>true</enableLazyFieldLoading>
-
-    <!--
-
-    <cache name="myUserCache"
-      class="solr.search.LRUCache"
-      size="4096"
-      initialSize="1024"
-      autowarmCount="1024"
-      regenerator="MyRegenerator"
-      />
-    -->
-
-
-    <!--
-    <useFilterForSortedQuery>true</useFilterForSortedQuery>
-    -->
-
-    <queryResultWindowSize>10</queryResultWindowSize>
-
-    <!-- set maxSize artificially low to exercise both types of sets -->
-    <HashDocSet maxSize="3" loadFactor="0.75"/>
-
-
-    <!-- boolToFilterOptimizer converts boolean clauses with zero boost
-         into cached filters if the number of docs selected by the clause exceeds
-         the threshold (represented as a fraction of the total index)
-    -->
-    <boolTofilterOptimizer enabled="false" cacheSize="32" threshold=".05"/>
-
-
-    <!-- a newSearcher event is fired whenever a new searcher is being prepared
-         and there is a current searcher handling requests (aka registered). -->
-    <!-- QuerySenderListener takes an array of NamedList and executes a
-         local query request for each NamedList in sequence. -->
-    <!--
-    <listener event="newSearcher" class="solr.QuerySenderListener">
-      <arr name="queries">
-        <lst> <str name="q">solr</str> <str name="start">0</str> <str name="rows">10</str> </lst>
-        <lst> <str name="q">rocks</str> <str name="start">0</str> <str name="rows">10</str> </lst>
-      </arr>
-    </listener>
-    -->
-
-    <!-- a firstSearcher event is fired whenever a new searcher is being
-         prepared but there is no current registered searcher to handle
-         requests or to gain prewarming data from. -->
-    <!--
-    <listener event="firstSearcher" class="solr.QuerySenderListener">
-      <arr name="queries">
-        <lst> <str name="q">fast_warm</str> <str name="start">0</str> <str name="rows">10</str> </lst>
-      </arr>
-    </listener>
-    -->
-
-
-  </query>
-
-
-  <!-- An alternate set representation that uses an integer hash to store filters (sets of docids).
-       If the set cardinality <= maxSize elements, then HashDocSet will be used instead of the bitset
-       based HashBitset. -->
-
-  <!-- requestHandler plugins... incoming queries will be dispatched to the
-     correct handler based on the qt (query type) param matching the
-     name of registered handlers.
-      The "standard" request handler is the default and will be used if qt
-     is not specified in the request.
-  -->
-  <requestHandler name="standard" class="solr.StandardRequestHandler">
-  	<bool name="httpCaching">true</bool>
-  </requestHandler>
-  <requestHandler name="dismaxOldStyleDefaults"
-                  class="solr.DisMaxRequestHandler" >
-     <!-- for historic reasons, DisMaxRequestHandler will use all of
-          it's init params as "defaults" if there is no "defaults" list
-          specified
-     -->
-     <str name="q.alt">*:*</str>
-     <float name="tie">0.01</float>
-     <str name="qf">
-        text^0.5 features_t^1.0 subject^1.4 title_stemmed^2.0
-     </str>
-     <str name="pf">
-        text^0.2 features_t^1.1 subject^1.4 title_stemmed^2.0 title^1.5
-     </str>
-     <str name="bf">
-        ord(weight)^0.5 recip(rord(iind),1,1000,1000)^0.3
-     </str>
-     <str name="mm">
-        3&lt;-1 5&lt;-2 6&lt;90%
-     </str>
-     <int name="ps">100</int>
-  </requestHandler>
-  <requestHandler name="dismax" class="solr.DisMaxRequestHandler" >
-    <lst name="defaults">
-     <str name="q.alt">*:*</str>
-     <float name="tie">0.01</float>
-     <str name="qf">
-        text^0.5 features_t^1.0 subject^1.4 title_stemmed^2.0
-     </str>
-     <str name="pf">
-        text^0.2 features_t^1.1 subject^1.4 title_stemmed^2.0 title^1.5
-     </str>
-     <str name="bf">
-        ord(weight)^0.5 recip(rord(iind),1,1000,1000)^0.3
-     </str>
-     <str name="mm">
-        3&lt;-1 5&lt;-2 6&lt;90%
-     </str>
-     <int name="ps">100</int>
-    </lst>
-  </requestHandler>
-  <requestHandler name="old" class="solr.tst.OldRequestHandler" >
-    <int name="myparam">1000</int>
-    <float name="ratio">1.4142135</float>
-    <arr name="myarr"><int>1</int><int>2</int></arr>
-    <str>foo</str>
-  </requestHandler>
-  <requestHandler name="oldagain" class="solr.tst.OldRequestHandler" >
-    <lst name="lst1"> <str name="op">sqrt</str> <int name="val">2</int> </lst>
-    <lst name="lst2"> <str name="op">log</str> <float name="val">10</float> </lst>
-  </requestHandler>
-
-  <requestHandler name="/admin/" class="org.apache.solr.handler.admin.AdminHandlers" />
-
-  <requestHandler name="test" class="solr.tst.TestRequestHandler" />
-
-  <!-- test query parameter defaults -->
-  <requestHandler name="defaults" class="solr.StandardRequestHandler">
-    <lst name="defaults">
-      <int name="rows">4</int>
-      <bool name="hl">true</bool>
-      <str name="hl.fl">text,name,subject,title,whitetok</str>
-    </lst>
-  </requestHandler>
-
-  <!-- test query parameter defaults -->
-  <requestHandler name="lazy" class="solr.StandardRequestHandler" startup="lazy">
-    <lst name="defaults">
-      <int name="rows">4</int>
-      <bool name="hl">true</bool>
-      <str name="hl.fl">text,name,subject,title,whitetok</str>
-    </lst>
-  </requestHandler>
-
-  <requestHandler name="/update"     class="solr.XmlUpdateRequestHandler"          />
-  <requestHandler name="/update/csv" class="solr.CSVRequestHandler" startup="lazy">
-  	<bool name="httpCaching">false</bool>
-  </requestHandler>
-
-  <searchComponent name="spellcheck" class="org.apache.solr.handler.component.SpellCheckComponent">
-    <str name="queryAnalyzerFieldType">lowerfilt</str>
-
-    <lst name="spellchecker">
-      <str name="name">default</str>
-      <str name="field">lowerfilt</str>
-      <str name="spellcheckIndexDir">spellchecker1</str>
-      <str name="buildOnCommit">true</str>
-    </lst>
-    <!-- Example of using different distance measure -->
-    <lst name="spellchecker">
-      <str name="name">jarowinkler</str>
-      <str name="field">lowerfilt</str>
-      <!-- Use a different Distance Measure -->
-      <str name="distanceMeasure">org.apache.lucene.search.spell.JaroWinklerDistance</str>
-      <str name="spellcheckIndexDir">spellchecker2</str>
-
-    </lst>
-    <lst name="spellchecker">
-      <str name="classname">solr.FileBasedSpellChecker</str>
-      <str name="name">external</str>
-      <str name="sourceLocation">spellings.txt</str>
-      <str name="characterEncoding">UTF-8</str>
-      <str name="spellcheckIndexDir">spellchecker3</str>
-    </lst>
-  </searchComponent>
-
-  <searchComponent name="termsComp" class="org.apache.solr.handler.component.TermsComponent"/>
-
-  <requestHandler name="/terms" class="org.apache.solr.handler.component.SearchHandler">
-    <arr name="components">
-      <str>termsComp</str>
-    </arr>
-  </requestHandler>
-  <!--
-  The SpellingQueryConverter to convert raw (CommonParams.Q) queries into tokens.  Uses a simple regular expression
-   to strip off field markup, boosts, ranges, etc. but it is not guaranteed to match an exact parse from the query parser.
-   -->
-  <queryConverter name="queryConverter" class="org.apache.solr.spelling.SpellingQueryConverter"/>
-
-  <requestHandler name="spellCheckCompRH" class="org.apache.solr.handler.component.SearchHandler">
-    <lst name="defaults">
-      <!-- omp = Only More Popular -->
-      <str name="spellcheck.onlyMorePopular">false</str>
-      <!-- exr = Extended Results -->
-      <str name="spellcheck.extendedResults">false</str>
-      <!--  The number of suggestions to return -->
-      <str name="spellcheck.count">1</str>
-    </lst>
-    <arr name="last-components">
-      <str>spellcheck</str>
-    </arr>
-  </requestHandler>
-
-  
-  <searchComponent name="tvComponent" class="org.apache.solr.handler.component.TermVectorComponent"/>
-
-  <requestHandler name="tvrh" class="org.apache.solr.handler.component.SearchHandler">
-    <lst name="defaults">
-
-    </lst>
-    <arr name="last-components">
-      <str>tvComponent</str>
-    </arr>
-  </requestHandler>
-
-  <searchComponent class="solr.HighlightComponent" name="highlight">
-  <highlighting>
-   <!-- Configure the standard fragmenter -->
-   <fragmenter name="gap" class="org.apache.solr.highlight.GapFragmenter" default="true">
-    <lst name="defaults">
-     <int name="hl.fragsize">100</int>
-    </lst>
-   </fragmenter>
-
-   <fragmenter name="regex" class="org.apache.solr.highlight.RegexFragmenter">
-    <lst name="defaults">
-     <int name="hl.fragsize">70</int>
-    </lst>
-   </fragmenter>
-
-   <!-- Configure the standard formatter -->
-   <formatter name="html" class="org.apache.solr.highlight.HtmlFormatter" default="true">
-    <lst name="defaults">
-     <str name="hl.simple.pre"><![CDATA[<em>]]></str>
-     <str name="hl.simple.post"><![CDATA[</em>]]></str>
-    </lst>
-   </formatter>
-  </highlighting>
-  </searchComponent>
-
-
-  <!-- enable streaming for testing... -->
-  <requestDispatcher handleSelect="true" >
-    <requestParsers enableRemoteStreaming="true" multipartUploadLimitInKB="2048" />
-    <httpCaching lastModifiedFrom="openTime" etagSeed="Solr" never304="false">
-      <cacheControl>max-age=30, public</cacheControl>
-    </httpCaching>
-  </requestDispatcher>
-
-  <admin>
-    <defaultQuery>solr</defaultQuery>
-    <gettableFiles>solrconfig.xml scheam.xml admin-extra.html</gettableFiles>
-  </admin>
-
-  <!-- test getting system property -->
-  <propTest attr1="${solr.test.sys.prop1}-$${literal}"
-            attr2="${non.existent.sys.prop:default-from-config}">prefix-${solr.test.sys.prop2}-suffix</propTest>
-
-  <queryParser name="foo" class="FooQParserPlugin"/>
-
-  <updateRequestProcessorChain name="dedupe">
-    <processor class="org.apache.solr.update.processor.SignatureUpdateProcessorFactory">
-      <bool name="enabled">false</bool>
-      <bool name="overwriteDupes">true</bool>
-      <str name="fields">v_t,t_field</str>
-      <str name="signatureClass">org.apache.solr.update.processor.TextProfileSignature</str>
-    </processor>
-    <processor class="solr.RunUpdateProcessorFactory" />
-  </updateRequestProcessorChain>
-
-</config>
+<?xml version="1.0" ?>
+
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+
+<!-- $Id: solrconfig.xml 382610 2006-03-03 01:43:03Z yonik $
+     $Source$
+     $Name$
+
+
+
+     This is a "kitchen sink" config file that tests can use.
+     When writting a new test, feel free to add *new* items (plugins,
+     config options, etc...) as long as they don't break any existing
+     tests.  if you need to test something esoteric please add a new
+     "solrconfig-your-esoteric-purpose.xml" config file.
+
+     Note in particular that this test is used by MinimalSchemaTest so 
+     Anything added to this file needs to work correctly even if there
+     is now uniqueKey or defaultSearch Field.
+
+
+  -->
+
+<config>
+
+  <jmx />
+
+  <!-- Used to specify an alternate directory to hold all index data.
+       It defaults to "index" if not present, and should probably
+       not be changed if replication is in use. -->
+  <dataDir>${solr.data.dir:./solr/data}</dataDir>
+
+  <!--  The DirectoryFactory to use for indexes.
+        solr.StandardDirectoryFactory, the default, is filesystem based.
+        solr.RAMDirectoryFactory is memory based and not persistent. -->
+  <directoryFactory name="DirectoryFactory" class="${solr.directoryFactory:solr.RAMDirectoryFactory}"/>
+
+
+  <indexDefaults>
+   <!-- Values here affect all index writers and act as a default
+   unless overridden. -->
+    <!-- Values here affect all index writers and act as a default unless overridden. -->
+    <useCompoundFile>false</useCompoundFile>
+    <mergeFactor>10</mergeFactor>
+    <!-- If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
+     -->
+    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
+    <!-- Tell Lucene when to flush documents to disk.
+    Giving Lucene more memory for indexing means faster indexing at the cost of more RAM
+
+    If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
+
+    -->
+    <ramBufferSizeMB>32</ramBufferSizeMB>
+    <maxMergeDocs>2147483647</maxMergeDocs>
+    <maxFieldLength>10000</maxFieldLength>
+    <writeLockTimeout>1000</writeLockTimeout>
+    <commitLockTimeout>10000</commitLockTimeout>
+
+    <!-- 
+     Expert: Turn on Lucene's auto commit capability.
+
+     NOTE: Despite the name, this value does not have any relation to Solr's autoCommit functionality
+
+     -->
+    <luceneAutoCommit>false</luceneAutoCommit>
+
+    <!--
+     Expert:
+     The Merge Policy in Lucene controls how merging is handled by Lucene.  The default in 2.3 is the LogByteSizeMergePolicy, previous
+     versions used LogDocMergePolicy.
+
+     LogByteSizeMergePolicy chooses segments to merge based on their size.  The Lucene 2.2 default, LogDocMergePolicy chose when
+     to merge based on number of documents
+
+     Other implementations of MergePolicy must have a no-argument constructor
+     -->
+    <mergePolicy>org.apache.lucene.index.LogDocMergePolicy</mergePolicy>
+
+    <!--
+     Expert:
+     The Merge Scheduler in Lucene controls how merges are performed.  The ConcurrentMergeScheduler (Lucene 2.3 default)
+      can perform merges in the background using separate threads.  The SerialMergeScheduler (Lucene 2.2 default) does not.
+     -->
+    <mergeScheduler>org.apache.lucene.index.SerialMergeScheduler</mergeScheduler>
+    <!-- these are global... can't currently override per index -->
+    <writeLockTimeout>1000</writeLockTimeout>
+    <commitLockTimeout>10000</commitLockTimeout>
+
+    <lockType>single</lockType>
+  </indexDefaults>
+
+  <mainIndex>
+    <!-- lucene options specific to the main on-disk lucene index -->
+    <useCompoundFile>false</useCompoundFile>
+    <mergeFactor>10</mergeFactor>
+    <!-- for better multi-segment testing, we are using slower
+    indexing properties of maxBufferedDocs=10 and LogDocMergePolicy.
+    -->
+    <maxBufferedDocs>10</maxBufferedDocs>
+    <maxMergeDocs>2147483647</maxMergeDocs>
+    <maxFieldLength>10000</maxFieldLength>
+    <mergePolicy>org.apache.lucene.index.LogDocMergePolicy</mergePolicy>
+    <mergeScheduler>org.apache.lucene.index.SerialMergeScheduler</mergeScheduler>
+    <unlockOnStartup>true</unlockOnStartup>
+  </mainIndex>
+
+  <updateHandler class="solr.DirectUpdateHandler2">
+
+    <!-- autocommit pending docs if certain criteria are met 
+    <autoCommit> 
+      <maxDocs>10000</maxDocs>
+      <maxTime>3600000</maxTime> 
+    </autoCommit>
+    -->
+    <!-- represents a lower bound on the frequency that commits may
+    occur (in seconds). NOTE: not yet implemented
+    
+    <commitIntervalLowerBound>0</commitIntervalLowerBound>
+    -->
+
+    <!-- The RunExecutableListener executes an external command.
+         exe - the name of the executable to run
+         dir - dir to use as the current working directory. default="."
+         wait - the calling thread waits until the executable returns. default="true"
+         args - the arguments to pass to the program.  default=nothing
+         env - environment variables to set.  default=nothing
+      -->
+    <!-- A postCommit event is fired after every commit
+    <listener event="postCommit" class="solr.RunExecutableListener">
+      <str name="exe">/var/opt/resin3/__PORT__/scripts/solr/snapshooter</str>
+      <str name="dir">/var/opt/resin3/__PORT__</str>
+      <bool name="wait">true</bool>
+      <arr name="args"> <str>arg1</str> <str>arg2</str> </arr>
+      <arr name="env"> <str>MYVAR=val1</str> </arr>
+    </listener>
+    -->
+
+
+  </updateHandler>
+
+
+  <query>
+    <!-- Maximum number of clauses in a boolean query... can affect
+        range or wildcard queries that expand to big boolean
+        queries.  An exception is thrown if exceeded.
+    -->
+    <maxBooleanClauses>1024</maxBooleanClauses>
+
+
+    <!-- Cache specification for Filters or DocSets - unordered set of *all* documents
+         that match a particular query.
+      -->
+    <filterCache
+      class="solr.search.FastLRUCache"
+      size="512"
+      initialSize="512"
+      autowarmCount="256"/>
+
+    <queryResultCache
+      class="solr.search.LRUCache"
+      size="512"
+      initialSize="512"
+      autowarmCount="1024"/>
+
+    <documentCache
+      class="solr.search.LRUCache"
+      size="512"
+      initialSize="512"
+      autowarmCount="0"/>
+
+    <!-- If true, stored fields that are not requested will be loaded lazily.
+    -->
+    <enableLazyFieldLoading>true</enableLazyFieldLoading>
+
+    <!--
+
+    <cache name="myUserCache"
+      class="solr.search.LRUCache"
+      size="4096"
+      initialSize="1024"
+      autowarmCount="1024"
+      regenerator="MyRegenerator"
+      />
+    -->
+
+
+    <!--
+    <useFilterForSortedQuery>true</useFilterForSortedQuery>
+    -->
+
+    <queryResultWindowSize>10</queryResultWindowSize>
+
+    <!-- set maxSize artificially low to exercise both types of sets -->
+    <HashDocSet maxSize="3" loadFactor="0.75"/>
+
+
+    <!-- boolToFilterOptimizer converts boolean clauses with zero boost
+         into cached filters if the number of docs selected by the clause exceeds
+         the threshold (represented as a fraction of the total index)
+    -->
+    <boolTofilterOptimizer enabled="false" cacheSize="32" threshold=".05"/>
+
+
+    <!-- a newSearcher event is fired whenever a new searcher is being prepared
+         and there is a current searcher handling requests (aka registered). -->
+    <!-- QuerySenderListener takes an array of NamedList and executes a
+         local query request for each NamedList in sequence. -->
+    <!--
+    <listener event="newSearcher" class="solr.QuerySenderListener">
+      <arr name="queries">
+        <lst> <str name="q">solr</str> <str name="start">0</str> <str name="rows">10</str> </lst>
+        <lst> <str name="q">rocks</str> <str name="start">0</str> <str name="rows">10</str> </lst>
+      </arr>
+    </listener>
+    -->
+
+    <!-- a firstSearcher event is fired whenever a new searcher is being
+         prepared but there is no current registered searcher to handle
+         requests or to gain prewarming data from. -->
+    <!--
+    <listener event="firstSearcher" class="solr.QuerySenderListener">
+      <arr name="queries">
+        <lst> <str name="q">fast_warm</str> <str name="start">0</str> <str name="rows">10</str> </lst>
+      </arr>
+    </listener>
+    -->
+
+
+  </query>
+
+
+  <!-- An alternate set representation that uses an integer hash to store filters (sets of docids).
+       If the set cardinality <= maxSize elements, then HashDocSet will be used instead of the bitset
+       based HashBitset. -->
+
+  <!-- requestHandler plugins... incoming queries will be dispatched to the
+     correct handler based on the qt (query type) param matching the
+     name of registered handlers.
+      The "standard" request handler is the default and will be used if qt
+     is not specified in the request.
+  -->
+  <requestHandler name="standard" class="solr.StandardRequestHandler">
+  	<bool name="httpCaching">true</bool>
+  </requestHandler>
+  <requestHandler name="dismaxOldStyleDefaults"
+                  class="solr.DisMaxRequestHandler" >
+     <!-- for historic reasons, DisMaxRequestHandler will use all of
+          it's init params as "defaults" if there is no "defaults" list
+          specified
+     -->
+     <str name="q.alt">*:*</str>
+     <float name="tie">0.01</float>
+     <str name="qf">
+        text^0.5 features_t^1.0 subject^1.4 title_stemmed^2.0
+     </str>
+     <str name="pf">
+        text^0.2 features_t^1.1 subject^1.4 title_stemmed^2.0 title^1.5
+     </str>
+     <str name="bf">
+        ord(weight)^0.5 recip(rord(iind),1,1000,1000)^0.3
+     </str>
+     <str name="mm">
+        3&lt;-1 5&lt;-2 6&lt;90%
+     </str>
+     <int name="ps">100</int>
+  </requestHandler>
+  <requestHandler name="dismax" class="solr.DisMaxRequestHandler" >
+    <lst name="defaults">
+     <str name="q.alt">*:*</str>
+     <float name="tie">0.01</float>
+     <str name="qf">
+        text^0.5 features_t^1.0 subject^1.4 title_stemmed^2.0
+     </str>
+     <str name="pf">
+        text^0.2 features_t^1.1 subject^1.4 title_stemmed^2.0 title^1.5
+     </str>
+     <str name="bf">
+        ord(weight)^0.5 recip(rord(iind),1,1000,1000)^0.3
+     </str>
+     <str name="mm">
+        3&lt;-1 5&lt;-2 6&lt;90%
+     </str>
+     <int name="ps">100</int>
+    </lst>
+  </requestHandler>
+  <requestHandler name="old" class="solr.tst.OldRequestHandler" >
+    <int name="myparam">1000</int>
+    <float name="ratio">1.4142135</float>
+    <arr name="myarr"><int>1</int><int>2</int></arr>
+    <str>foo</str>
+  </requestHandler>
+  <requestHandler name="oldagain" class="solr.tst.OldRequestHandler" >
+    <lst name="lst1"> <str name="op">sqrt</str> <int name="val">2</int> </lst>
+    <lst name="lst2"> <str name="op">log</str> <float name="val">10</float> </lst>
+  </requestHandler>
+
+  <requestHandler name="/admin/" class="org.apache.solr.handler.admin.AdminHandlers" />
+
+  <requestHandler name="test" class="solr.tst.TestRequestHandler" />
+
+  <!-- test query parameter defaults -->
+  <requestHandler name="defaults" class="solr.StandardRequestHandler">
+    <lst name="defaults">
+      <int name="rows">4</int>
+      <bool name="hl">true</bool>
+      <str name="hl.fl">text,name,subject,title,whitetok</str>
+    </lst>
+  </requestHandler>
+
+  <!-- test query parameter defaults -->
+  <requestHandler name="lazy" class="solr.StandardRequestHandler" startup="lazy">
+    <lst name="defaults">
+      <int name="rows">4</int>
+      <bool name="hl">true</bool>
+      <str name="hl.fl">text,name,subject,title,whitetok</str>
+    </lst>
+  </requestHandler>
+
+  <requestHandler name="/update"     class="solr.XmlUpdateRequestHandler"          />
+  <requestHandler name="/update/csv" class="solr.CSVRequestHandler" startup="lazy">
+  	<bool name="httpCaching">false</bool>
+  </requestHandler>
+
+  <searchComponent name="spellcheck" class="org.apache.solr.handler.component.SpellCheckComponent">
+    <str name="queryAnalyzerFieldType">lowerfilt</str>
+
+    <lst name="spellchecker">
+      <str name="name">default</str>
+      <str name="field">lowerfilt</str>
+      <str name="spellcheckIndexDir">spellchecker1</str>
+      <str name="buildOnCommit">true</str>
+    </lst>
+    <!-- Example of using different distance measure -->
+    <lst name="spellchecker">
+      <str name="name">jarowinkler</str>
+      <str name="field">lowerfilt</str>
+      <!-- Use a different Distance Measure -->
+      <str name="distanceMeasure">org.apache.lucene.search.spell.JaroWinklerDistance</str>
+      <str name="spellcheckIndexDir">spellchecker2</str>
+
+    </lst>
+    <lst name="spellchecker">
+      <str name="classname">solr.FileBasedSpellChecker</str>
+      <str name="name">external</str>
+      <str name="sourceLocation">spellings.txt</str>
+      <str name="characterEncoding">UTF-8</str>
+      <str name="spellcheckIndexDir">spellchecker3</str>
+    </lst>
+  </searchComponent>
+
+  <searchComponent name="termsComp" class="org.apache.solr.handler.component.TermsComponent"/>
+
+  <requestHandler name="/terms" class="org.apache.solr.handler.component.SearchHandler">
+    <arr name="components">
+      <str>termsComp</str>
+    </arr>
+  </requestHandler>
+  <!--
+  The SpellingQueryConverter to convert raw (CommonParams.Q) queries into tokens.  Uses a simple regular expression
+   to strip off field markup, boosts, ranges, etc. but it is not guaranteed to match an exact parse from the query parser.
+   -->
+  <queryConverter name="queryConverter" class="org.apache.solr.spelling.SpellingQueryConverter"/>
+
+  <requestHandler name="spellCheckCompRH" class="org.apache.solr.handler.component.SearchHandler">
+    <lst name="defaults">
+      <!-- omp = Only More Popular -->
+      <str name="spellcheck.onlyMorePopular">false</str>
+      <!-- exr = Extended Results -->
+      <str name="spellcheck.extendedResults">false</str>
+      <!--  The number of suggestions to return -->
+      <str name="spellcheck.count">1</str>
+    </lst>
+    <arr name="last-components">
+      <str>spellcheck</str>
+    </arr>
+  </requestHandler>
+
+  
+  <searchComponent name="tvComponent" class="org.apache.solr.handler.component.TermVectorComponent"/>
+
+  <requestHandler name="tvrh" class="org.apache.solr.handler.component.SearchHandler">
+    <lst name="defaults">
+
+    </lst>
+    <arr name="last-components">
+      <str>tvComponent</str>
+    </arr>
+  </requestHandler>
+
+  <searchComponent class="solr.HighlightComponent" name="highlight">
+  <highlighting>
+   <!-- Configure the standard fragmenter -->
+   <fragmenter name="gap" class="org.apache.solr.highlight.GapFragmenter" default="true">
+    <lst name="defaults">
+     <int name="hl.fragsize">100</int>
+    </lst>
+   </fragmenter>
+
+   <fragmenter name="regex" class="org.apache.solr.highlight.RegexFragmenter">
+    <lst name="defaults">
+     <int name="hl.fragsize">70</int>
+    </lst>
+   </fragmenter>
+
+   <!-- Configure the standard formatter -->
+   <formatter name="html" class="org.apache.solr.highlight.HtmlFormatter" default="true">
+    <lst name="defaults">
+     <str name="hl.simple.pre"><![CDATA[<em>]]></str>
+     <str name="hl.simple.post"><![CDATA[</em>]]></str>
+    </lst>
+   </formatter>
+  </highlighting>
+  </searchComponent>
+
+
+  <!-- enable streaming for testing... -->
+  <requestDispatcher handleSelect="true" >
+    <requestParsers enableRemoteStreaming="true" multipartUploadLimitInKB="2048" />
+    <httpCaching lastModifiedFrom="openTime" etagSeed="Solr" never304="false">
+      <cacheControl>max-age=30, public</cacheControl>
+    </httpCaching>
+  </requestDispatcher>
+
+  <admin>
+    <defaultQuery>solr</defaultQuery>
+    <gettableFiles>solrconfig.xml scheam.xml admin-extra.html</gettableFiles>
+  </admin>
+
+  <!-- test getting system property -->
+  <propTest attr1="${solr.test.sys.prop1}-$${literal}"
+            attr2="${non.existent.sys.prop:default-from-config}">prefix-${solr.test.sys.prop2}-suffix</propTest>
+
+  <queryParser name="foo" class="FooQParserPlugin"/>
+
+  <updateRequestProcessorChain name="dedupe">
+    <processor class="org.apache.solr.update.processor.SignatureUpdateProcessorFactory">
+      <bool name="enabled">false</bool>
+      <bool name="overwriteDupes">true</bool>
+      <str name="fields">v_t,t_field</str>
+      <str name="signatureClass">org.apache.solr.update.processor.TextProfileSignature</str>
+    </processor>
+    <processor class="solr.RunUpdateProcessorFactory" />
+  </updateRequestProcessorChain>
+
+</config>
diff --git a/solr/src/test/test-files/solr/conf/solrconfig-propinject.xml b/solr/src/test/test-files/solr/conf/solrconfig-propinject.xml
index 739caf0..d6d71f8 100644
--- a/solr/src/test/test-files/solr/conf/solrconfig-propinject.xml
+++ b/solr/src/test/test-files/solr/conf/solrconfig-propinject.xml
@@ -1,470 +1,470 @@
-<?xml version="1.0" ?>
-
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-
-<!-- $Id: solrconfig.xml 382610 2006-03-03 01:43:03Z yonik $
-     $Source$
-     $Name$
-
-
-
-     This is a "kitchen sink" config file that tests can use.
-     When writting a new test, feel free to add *new* items (plugins,
-     config options, etc...) as long as they don't break any existing
-     tests.  if you need to test something esoteric please add a new
-     "solrconfig-your-esoteric-purpose.xml" config file.
-
-     Note in particular that this test is used by MinimalSchemaTest so 
-     Anything added to this file needs to work correctly even if there
-     is now uniqueKey or defaultSearch Field.
-
-
-  -->
-
-<config>
-
-  <jmx />
-
-  <!-- Used to specify an alternate directory to hold all index data.
-       It defaults to "index" if not present, and should probably
-       not be changed if replication is in use. -->
-  <dataDir>${solr.data.dir:./solr/data}</dataDir>
-
-  <!--  The DirectoryFactory to use for indexes.
-        solr.StandardDirectoryFactory, the default, is filesystem based.
-        solr.RAMDirectoryFactory is memory based and not persistent. -->
-  <directoryFactory name="DirectoryFactory" class="${solr.directoryFactory:solr.RAMDirectoryFactory}"/>
-
-  <indexDefaults>
-   <!-- Values here affect all index writers and act as a default
-   unless overridden. -->
-    <!-- Values here affect all index writers and act as a default unless overridden. -->
-    <useCompoundFile>false</useCompoundFile>
-    <mergeFactor>10</mergeFactor>
-    <!-- If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
-     -->
-    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
-    <!-- Tell Lucene when to flush documents to disk.
-    Giving Lucene more memory for indexing means faster indexing at the cost of more RAM
-
-    If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
-
-    -->
-    <ramBufferSizeMB>32</ramBufferSizeMB>
-    <maxMergeDocs>2147483647</maxMergeDocs>
-    <maxFieldLength>10000</maxFieldLength>
-    <writeLockTimeout>1000</writeLockTimeout>
-    <commitLockTimeout>10000</commitLockTimeout>
-
-    <!-- 
-     Expert: Turn on Lucene's auto commit capability.
-
-     NOTE: Despite the name, this value does not have any relation to Solr's autoCommit functionality
-
-     -->
-    <luceneAutoCommit>false</luceneAutoCommit>
-
-    <!--
-     Expert:
-     The Merge Policy in Lucene controls how merging is handled by Lucene.  The default in 2.3 is the LogByteSizeMergePolicy, previous
-     versions used LogDocMergePolicy.
-
-     LogByteSizeMergePolicy chooses segments to merge based on their size.  The Lucene 2.2 default, LogDocMergePolicy chose when
-     to merge based on number of documents
-
-     Other implementations of MergePolicy must have a no-argument constructor
-     -->
-    <mergePolicy class="org.apache.lucene.index.LogByteSizeMergePolicy">
-      <double name="maxMergeMB">64.0</double>
-    </mergePolicy>
-
-    <!--
-     Expert:
-     The Merge Scheduler in Lucene controls how merges are performed.  The ConcurrentMergeScheduler (Lucene 2.3 default)
-      can perform merges in the background using separate threads.  The SerialMergeScheduler (Lucene 2.2 default) does not.
-     -->
-    <mergeScheduler class="org.apache.lucene.index.ConcurrentMergeScheduler">
-      <int name="maxThreadCount">2</int>
-    </mergeScheduler>
-    <!-- these are global... can't currently override per index -->
-    <writeLockTimeout>1000</writeLockTimeout>
-    <commitLockTimeout>10000</commitLockTimeout>
-
-    <lockType>single</lockType>
-  </indexDefaults>
-
-  <mainIndex>
-    <!-- lucene options specific to the main on-disk lucene index -->
-    <useCompoundFile>false</useCompoundFile>
-    <mergeFactor>10</mergeFactor>
-    <!-- for better multi-segment testing, we are using slower
-    indexing properties of maxBufferedDocs=10 and LogDocMergePolicy.
-    -->
-    <maxBufferedDocs>10</maxBufferedDocs>
-    <maxMergeDocs>2147483647</maxMergeDocs>
-    <maxFieldLength>10000</maxFieldLength>
-    
-    <mergePolicy class="org.apache.lucene.index.LogByteSizeMergePolicy">
-      <double name="maxMergeMB">64.0</double>
-    </mergePolicy>
-    
-    <mergeScheduler class="org.apache.lucene.index.ConcurrentMergeScheduler">
-      <int name="maxThreadCount">2</int>
-    </mergeScheduler>
-    <unlockOnStartup>true</unlockOnStartup>
-  </mainIndex>
-
-  <updateHandler class="solr.DirectUpdateHandler2">
-
-    <!-- autocommit pending docs if certain criteria are met 
-    <autoCommit> 
-      <maxDocs>10000</maxDocs>
-      <maxTime>3600000</maxTime> 
-    </autoCommit>
-    -->
-    <!-- represents a lower bound on the frequency that commits may
-    occur (in seconds). NOTE: not yet implemented
-    
-    <commitIntervalLowerBound>0</commitIntervalLowerBound>
-    -->
-
-    <!-- The RunExecutableListener executes an external command.
-         exe - the name of the executable to run
-         dir - dir to use as the current working directory. default="."
-         wait - the calling thread waits until the executable returns. default="true"
-         args - the arguments to pass to the program.  default=nothing
-         env - environment variables to set.  default=nothing
-      -->
-    <!-- A postCommit event is fired after every commit
-    <listener event="postCommit" class="solr.RunExecutableListener">
-      <str name="exe">/var/opt/resin3/__PORT__/scripts/solr/snapshooter</str>
-      <str name="dir">/var/opt/resin3/__PORT__</str>
-      <bool name="wait">true</bool>
-      <arr name="args"> <str>arg1</str> <str>arg2</str> </arr>
-      <arr name="env"> <str>MYVAR=val1</str> </arr>
-    </listener>
-    -->
-
-
-  </updateHandler>
-
-
-  <query>
-    <!-- Maximum number of clauses in a boolean query... can affect
-        range or wildcard queries that expand to big boolean
-        queries.  An exception is thrown if exceeded.
-    -->
-    <maxBooleanClauses>1024</maxBooleanClauses>
-
-
-    <!-- Cache specification for Filters or DocSets - unordered set of *all* documents
-         that match a particular query.
-      -->
-    <filterCache
-      class="solr.search.FastLRUCache"
-      size="512"
-      initialSize="512"
-      autowarmCount="256"/>
-
-    <queryResultCache
-      class="solr.search.LRUCache"
-      size="512"
-      initialSize="512"
-      autowarmCount="1024"/>
-
-    <documentCache
-      class="solr.search.LRUCache"
-      size="512"
-      initialSize="512"
-      autowarmCount="0"/>
-
-    <!-- If true, stored fields that are not requested will be loaded lazily.
-    -->
-    <enableLazyFieldLoading>true</enableLazyFieldLoading>
-
-    <!--
-
-    <cache name="myUserCache"
-      class="solr.search.LRUCache"
-      size="4096"
-      initialSize="1024"
-      autowarmCount="1024"
-      regenerator="MyRegenerator"
-      />
-    -->
-
-
-    <!--
-    <useFilterForSortedQuery>true</useFilterForSortedQuery>
-    -->
-
-    <queryResultWindowSize>10</queryResultWindowSize>
-
-    <!-- set maxSize artificially low to exercise both types of sets -->
-    <HashDocSet maxSize="3" loadFactor="0.75"/>
-
-
-    <!-- boolToFilterOptimizer converts boolean clauses with zero boost
-         into cached filters if the number of docs selected by the clause exceeds
-         the threshold (represented as a fraction of the total index)
-    -->
-    <boolTofilterOptimizer enabled="false" cacheSize="32" threshold=".05"/>
-
-
-    <!-- a newSearcher event is fired whenever a new searcher is being prepared
-         and there is a current searcher handling requests (aka registered). -->
-    <!-- QuerySenderListener takes an array of NamedList and executes a
-         local query request for each NamedList in sequence. -->
-    <!--
-    <listener event="newSearcher" class="solr.QuerySenderListener">
-      <arr name="queries">
-        <lst> <str name="q">solr</str> <str name="start">0</str> <str name="rows">10</str> </lst>
-        <lst> <str name="q">rocks</str> <str name="start">0</str> <str name="rows">10</str> </lst>
-      </arr>
-    </listener>
-    -->
-
-    <!-- a firstSearcher event is fired whenever a new searcher is being
-         prepared but there is no current registered searcher to handle
-         requests or to gain prewarming data from. -->
-    <!--
-    <listener event="firstSearcher" class="solr.QuerySenderListener">
-      <arr name="queries">
-        <lst> <str name="q">fast_warm</str> <str name="start">0</str> <str name="rows">10</str> </lst>
-      </arr>
-    </listener>
-    -->
-
-
-  </query>
-
-
-  <!-- An alternate set representation that uses an integer hash to store filters (sets of docids).
-       If the set cardinality <= maxSize elements, then HashDocSet will be used instead of the bitset
-       based HashBitset. -->
-
-  <!-- requestHandler plugins... incoming queries will be dispatched to the
-     correct handler based on the qt (query type) param matching the
-     name of registered handlers.
-      The "standard" request handler is the default and will be used if qt
-     is not specified in the request.
-  -->
-  <requestHandler name="standard" class="solr.StandardRequestHandler">
-  	<bool name="httpCaching">true</bool>
-  </requestHandler>
-  <requestHandler name="dismaxOldStyleDefaults"
-                  class="solr.DisMaxRequestHandler" >
-     <!-- for historic reasons, DisMaxRequestHandler will use all of
-          it's init params as "defaults" if there is no "defaults" list
-          specified
-     -->
-     <str name="q.alt">*:*</str>
-     <float name="tie">0.01</float>
-     <str name="qf">
-        text^0.5 features_t^1.0 subject^1.4 title_stemmed^2.0
-     </str>
-     <str name="pf">
-        text^0.2 features_t^1.1 subject^1.4 title_stemmed^2.0 title^1.5
-     </str>
-     <str name="bf">
-        ord(weight)^0.5 recip(rord(iind),1,1000,1000)^0.3
-     </str>
-     <str name="mm">
-        3&lt;-1 5&lt;-2 6&lt;90%
-     </str>
-     <int name="ps">100</int>
-  </requestHandler>
-  <requestHandler name="dismax" class="solr.DisMaxRequestHandler" >
-    <lst name="defaults">
-     <str name="q.alt">*:*</str>
-     <float name="tie">0.01</float>
-     <str name="qf">
-        text^0.5 features_t^1.0 subject^1.4 title_stemmed^2.0
-     </str>
-     <str name="pf">
-        text^0.2 features_t^1.1 subject^1.4 title_stemmed^2.0 title^1.5
-     </str>
-     <str name="bf">
-        ord(weight)^0.5 recip(rord(iind),1,1000,1000)^0.3
-     </str>
-     <str name="mm">
-        3&lt;-1 5&lt;-2 6&lt;90%
-     </str>
-     <int name="ps">100</int>
-    </lst>
-  </requestHandler>
-  <requestHandler name="old" class="solr.tst.OldRequestHandler" >
-    <int name="myparam">1000</int>
-    <float name="ratio">1.4142135</float>
-    <arr name="myarr"><int>1</int><int>2</int></arr>
-    <str>foo</str>
-  </requestHandler>
-  <requestHandler name="oldagain" class="solr.tst.OldRequestHandler" >
-    <lst name="lst1"> <str name="op">sqrt</str> <int name="val">2</int> </lst>
-    <lst name="lst2"> <str name="op">log</str> <float name="val">10</float> </lst>
-  </requestHandler>
-
-  <requestHandler name="/admin/" class="org.apache.solr.handler.admin.AdminHandlers" />
-
-  <requestHandler name="test" class="solr.tst.TestRequestHandler" />
-
-  <!-- test query parameter defaults -->
-  <requestHandler name="defaults" class="solr.StandardRequestHandler">
-    <lst name="defaults">
-      <int name="rows">4</int>
-      <bool name="hl">true</bool>
-      <str name="hl.fl">text,name,subject,title,whitetok</str>
-    </lst>
-  </requestHandler>
-
-  <!-- test query parameter defaults -->
-  <requestHandler name="lazy" class="solr.StandardRequestHandler" startup="lazy">
-    <lst name="defaults">
-      <int name="rows">4</int>
-      <bool name="hl">true</bool>
-      <str name="hl.fl">text,name,subject,title,whitetok</str>
-    </lst>
-  </requestHandler>
-
-  <requestHandler name="/update"     class="solr.XmlUpdateRequestHandler"          />
-  <requestHandler name="/update/csv" class="solr.CSVRequestHandler" startup="lazy">
-  	<bool name="httpCaching">false</bool>
-  </requestHandler>
-
-  <searchComponent name="spellcheck" class="org.apache.solr.handler.component.SpellCheckComponent">
-    <str name="queryAnalyzerFieldType">lowerfilt</str>
-
-    <lst name="spellchecker">
-      <str name="name">default</str>
-      <str name="field">lowerfilt</str>
-      <str name="spellcheckIndexDir">spellchecker1</str>
-      <str name="buildOnCommit">true</str>
-    </lst>
-    <!-- Example of using different distance measure -->
-    <lst name="spellchecker">
-      <str name="name">jarowinkler</str>
-      <str name="field">lowerfilt</str>
-      <!-- Use a different Distance Measure -->
-      <str name="distanceMeasure">org.apache.lucene.search.spell.JaroWinklerDistance</str>
-      <str name="spellcheckIndexDir">spellchecker2</str>
-
-    </lst>
-    <lst name="spellchecker">
-      <str name="classname">solr.FileBasedSpellChecker</str>
-      <str name="name">external</str>
-      <str name="sourceLocation">spellings.txt</str>
-      <str name="characterEncoding">UTF-8</str>
-      <str name="spellcheckIndexDir">spellchecker3</str>
-    </lst>
-  </searchComponent>
-
-  <searchComponent name="termsComp" class="org.apache.solr.handler.component.TermsComponent"/>
-
-  <requestHandler name="/terms" class="org.apache.solr.handler.component.SearchHandler">
-    <arr name="components">
-      <str>termsComp</str>
-    </arr>
-  </requestHandler>
-  <!--
-  The SpellingQueryConverter to convert raw (CommonParams.Q) queries into tokens.  Uses a simple regular expression
-   to strip off field markup, boosts, ranges, etc. but it is not guaranteed to match an exact parse from the query parser.
-   -->
-  <queryConverter name="queryConverter" class="org.apache.solr.spelling.SpellingQueryConverter"/>
-
-  <requestHandler name="spellCheckCompRH" class="org.apache.solr.handler.component.SearchHandler">
-    <lst name="defaults">
-      <!-- omp = Only More Popular -->
-      <str name="spellcheck.onlyMorePopular">false</str>
-      <!-- exr = Extended Results -->
-      <str name="spellcheck.extendedResults">false</str>
-      <!--  The number of suggestions to return -->
-      <str name="spellcheck.count">1</str>
-    </lst>
-    <arr name="last-components">
-      <str>spellcheck</str>
-    </arr>
-  </requestHandler>
-
-  
-  <searchComponent name="tvComponent" class="org.apache.solr.handler.component.TermVectorComponent"/>
-
-  <requestHandler name="tvrh" class="org.apache.solr.handler.component.SearchHandler">
-    <lst name="defaults">
-
-    </lst>
-    <arr name="last-components">
-      <str>tvComponent</str>
-    </arr>
-  </requestHandler>
-
-  <searchComponent class="solr.HighlightComponent" name="highlight">
-  <highlighting>
-   <!-- Configure the standard fragmenter -->
-   <fragmenter name="gap" class="org.apache.solr.highlight.GapFragmenter" default="true">
-    <lst name="defaults">
-     <int name="hl.fragsize">100</int>
-    </lst>
-   </fragmenter>
-
-   <fragmenter name="regex" class="org.apache.solr.highlight.RegexFragmenter">
-    <lst name="defaults">
-     <int name="hl.fragsize">70</int>
-    </lst>
-   </fragmenter>
-
-   <!-- Configure the standard formatter -->
-   <formatter name="html" class="org.apache.solr.highlight.HtmlFormatter" default="true">
-    <lst name="defaults">
-     <str name="hl.simple.pre"><![CDATA[<em>]]></str>
-     <str name="hl.simple.post"><![CDATA[</em>]]></str>
-    </lst>
-   </formatter>
-  </highlighting>
-  </searchComponent>
-
-
-  <!-- enable streaming for testing... -->
-  <requestDispatcher handleSelect="true" >
-    <requestParsers enableRemoteStreaming="true" multipartUploadLimitInKB="2048" />
-    <httpCaching lastModifiedFrom="openTime" etagSeed="Solr" never304="false">
-      <cacheControl>max-age=30, public</cacheControl>
-    </httpCaching>
-  </requestDispatcher>
-
-  <admin>
-    <defaultQuery>solr</defaultQuery>
-    <gettableFiles>solrconfig.xml scheam.xml admin-extra.html</gettableFiles>
-  </admin>
-
-  <!-- test getting system property -->
-  <propTest attr1="${solr.test.sys.prop1}-$${literal}"
-            attr2="${non.existent.sys.prop:default-from-config}">prefix-${solr.test.sys.prop2}-suffix</propTest>
-
-  <queryParser name="foo" class="FooQParserPlugin"/>
-
-  <updateRequestProcessorChain name="dedupe">
-    <processor class="org.apache.solr.update.processor.SignatureUpdateProcessorFactory">
-      <bool name="enabled">false</bool>
-      <bool name="overwriteDupes">true</bool>
-      <str name="fields">v_t,t_field</str>
-      <str name="signatureClass">org.apache.solr.update.processor.TextProfileSignature</str>
-    </processor>
-    <processor class="solr.RunUpdateProcessorFactory" />
-  </updateRequestProcessorChain>
-
-</config>
+<?xml version="1.0" ?>
+
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+
+<!-- $Id: solrconfig.xml 382610 2006-03-03 01:43:03Z yonik $
+     $Source$
+     $Name$
+
+
+
+     This is a "kitchen sink" config file that tests can use.
+     When writting a new test, feel free to add *new* items (plugins,
+     config options, etc...) as long as they don't break any existing
+     tests.  if you need to test something esoteric please add a new
+     "solrconfig-your-esoteric-purpose.xml" config file.
+
+     Note in particular that this test is used by MinimalSchemaTest so 
+     Anything added to this file needs to work correctly even if there
+     is now uniqueKey or defaultSearch Field.
+
+
+  -->
+
+<config>
+
+  <jmx />
+
+  <!-- Used to specify an alternate directory to hold all index data.
+       It defaults to "index" if not present, and should probably
+       not be changed if replication is in use. -->
+  <dataDir>${solr.data.dir:./solr/data}</dataDir>
+
+  <!--  The DirectoryFactory to use for indexes.
+        solr.StandardDirectoryFactory, the default, is filesystem based.
+        solr.RAMDirectoryFactory is memory based and not persistent. -->
+  <directoryFactory name="DirectoryFactory" class="${solr.directoryFactory:solr.RAMDirectoryFactory}"/>
+
+  <indexDefaults>
+   <!-- Values here affect all index writers and act as a default
+   unless overridden. -->
+    <!-- Values here affect all index writers and act as a default unless overridden. -->
+    <useCompoundFile>false</useCompoundFile>
+    <mergeFactor>10</mergeFactor>
+    <!-- If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
+     -->
+    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
+    <!-- Tell Lucene when to flush documents to disk.
+    Giving Lucene more memory for indexing means faster indexing at the cost of more RAM
+
+    If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
+
+    -->
+    <ramBufferSizeMB>32</ramBufferSizeMB>
+    <maxMergeDocs>2147483647</maxMergeDocs>
+    <maxFieldLength>10000</maxFieldLength>
+    <writeLockTimeout>1000</writeLockTimeout>
+    <commitLockTimeout>10000</commitLockTimeout>
+
+    <!-- 
+     Expert: Turn on Lucene's auto commit capability.
+
+     NOTE: Despite the name, this value does not have any relation to Solr's autoCommit functionality
+
+     -->
+    <luceneAutoCommit>false</luceneAutoCommit>
+
+    <!--
+     Expert:
+     The Merge Policy in Lucene controls how merging is handled by Lucene.  The default in 2.3 is the LogByteSizeMergePolicy, previous
+     versions used LogDocMergePolicy.
+
+     LogByteSizeMergePolicy chooses segments to merge based on their size.  The Lucene 2.2 default, LogDocMergePolicy chose when
+     to merge based on number of documents
+
+     Other implementations of MergePolicy must have a no-argument constructor
+     -->
+    <mergePolicy class="org.apache.lucene.index.LogByteSizeMergePolicy">
+      <double name="maxMergeMB">64.0</double>
+    </mergePolicy>
+
+    <!--
+     Expert:
+     The Merge Scheduler in Lucene controls how merges are performed.  The ConcurrentMergeScheduler (Lucene 2.3 default)
+      can perform merges in the background using separate threads.  The SerialMergeScheduler (Lucene 2.2 default) does not.
+     -->
+    <mergeScheduler class="org.apache.lucene.index.ConcurrentMergeScheduler">
+      <int name="maxThreadCount">2</int>
+    </mergeScheduler>
+    <!-- these are global... can't currently override per index -->
+    <writeLockTimeout>1000</writeLockTimeout>
+    <commitLockTimeout>10000</commitLockTimeout>
+
+    <lockType>single</lockType>
+  </indexDefaults>
+
+  <mainIndex>
+    <!-- lucene options specific to the main on-disk lucene index -->
+    <useCompoundFile>false</useCompoundFile>
+    <mergeFactor>10</mergeFactor>
+    <!-- for better multi-segment testing, we are using slower
+    indexing properties of maxBufferedDocs=10 and LogDocMergePolicy.
+    -->
+    <maxBufferedDocs>10</maxBufferedDocs>
+    <maxMergeDocs>2147483647</maxMergeDocs>
+    <maxFieldLength>10000</maxFieldLength>
+    
+    <mergePolicy class="org.apache.lucene.index.LogByteSizeMergePolicy">
+      <double name="maxMergeMB">64.0</double>
+    </mergePolicy>
+    
+    <mergeScheduler class="org.apache.lucene.index.ConcurrentMergeScheduler">
+      <int name="maxThreadCount">2</int>
+    </mergeScheduler>
+    <unlockOnStartup>true</unlockOnStartup>
+  </mainIndex>
+
+  <updateHandler class="solr.DirectUpdateHandler2">
+
+    <!-- autocommit pending docs if certain criteria are met 
+    <autoCommit> 
+      <maxDocs>10000</maxDocs>
+      <maxTime>3600000</maxTime> 
+    </autoCommit>
+    -->
+    <!-- represents a lower bound on the frequency that commits may
+    occur (in seconds). NOTE: not yet implemented
+    
+    <commitIntervalLowerBound>0</commitIntervalLowerBound>
+    -->
+
+    <!-- The RunExecutableListener executes an external command.
+         exe - the name of the executable to run
+         dir - dir to use as the current working directory. default="."
+         wait - the calling thread waits until the executable returns. default="true"
+         args - the arguments to pass to the program.  default=nothing
+         env - environment variables to set.  default=nothing
+      -->
+    <!-- A postCommit event is fired after every commit
+    <listener event="postCommit" class="solr.RunExecutableListener">
+      <str name="exe">/var/opt/resin3/__PORT__/scripts/solr/snapshooter</str>
+      <str name="dir">/var/opt/resin3/__PORT__</str>
+      <bool name="wait">true</bool>
+      <arr name="args"> <str>arg1</str> <str>arg2</str> </arr>
+      <arr name="env"> <str>MYVAR=val1</str> </arr>
+    </listener>
+    -->
+
+
+  </updateHandler>
+
+
+  <query>
+    <!-- Maximum number of clauses in a boolean query... can affect
+        range or wildcard queries that expand to big boolean
+        queries.  An exception is thrown if exceeded.
+    -->
+    <maxBooleanClauses>1024</maxBooleanClauses>
+
+
+    <!-- Cache specification for Filters or DocSets - unordered set of *all* documents
+         that match a particular query.
+      -->
+    <filterCache
+      class="solr.search.FastLRUCache"
+      size="512"
+      initialSize="512"
+      autowarmCount="256"/>
+
+    <queryResultCache
+      class="solr.search.LRUCache"
+      size="512"
+      initialSize="512"
+      autowarmCount="1024"/>
+
+    <documentCache
+      class="solr.search.LRUCache"
+      size="512"
+      initialSize="512"
+      autowarmCount="0"/>
+
+    <!-- If true, stored fields that are not requested will be loaded lazily.
+    -->
+    <enableLazyFieldLoading>true</enableLazyFieldLoading>
+
+    <!--
+
+    <cache name="myUserCache"
+      class="solr.search.LRUCache"
+      size="4096"
+      initialSize="1024"
+      autowarmCount="1024"
+      regenerator="MyRegenerator"
+      />
+    -->
+
+
+    <!--
+    <useFilterForSortedQuery>true</useFilterForSortedQuery>
+    -->
+
+    <queryResultWindowSize>10</queryResultWindowSize>
+
+    <!-- set maxSize artificially low to exercise both types of sets -->
+    <HashDocSet maxSize="3" loadFactor="0.75"/>
+
+
+    <!-- boolToFilterOptimizer converts boolean clauses with zero boost
+         into cached filters if the number of docs selected by the clause exceeds
+         the threshold (represented as a fraction of the total index)
+    -->
+    <boolTofilterOptimizer enabled="false" cacheSize="32" threshold=".05"/>
+
+
+    <!-- a newSearcher event is fired whenever a new searcher is being prepared
+         and there is a current searcher handling requests (aka registered). -->
+    <!-- QuerySenderListener takes an array of NamedList and executes a
+         local query request for each NamedList in sequence. -->
+    <!--
+    <listener event="newSearcher" class="solr.QuerySenderListener">
+      <arr name="queries">
+        <lst> <str name="q">solr</str> <str name="start">0</str> <str name="rows">10</str> </lst>
+        <lst> <str name="q">rocks</str> <str name="start">0</str> <str name="rows">10</str> </lst>
+      </arr>
+    </listener>
+    -->
+
+    <!-- a firstSearcher event is fired whenever a new searcher is being
+         prepared but there is no current registered searcher to handle
+         requests or to gain prewarming data from. -->
+    <!--
+    <listener event="firstSearcher" class="solr.QuerySenderListener">
+      <arr name="queries">
+        <lst> <str name="q">fast_warm</str> <str name="start">0</str> <str name="rows">10</str> </lst>
+      </arr>
+    </listener>
+    -->
+
+
+  </query>
+
+
+  <!-- An alternate set representation that uses an integer hash to store filters (sets of docids).
+       If the set cardinality <= maxSize elements, then HashDocSet will be used instead of the bitset
+       based HashBitset. -->
+
+  <!-- requestHandler plugins... incoming queries will be dispatched to the
+     correct handler based on the qt (query type) param matching the
+     name of registered handlers.
+      The "standard" request handler is the default and will be used if qt
+     is not specified in the request.
+  -->
+  <requestHandler name="standard" class="solr.StandardRequestHandler">
+  	<bool name="httpCaching">true</bool>
+  </requestHandler>
+  <requestHandler name="dismaxOldStyleDefaults"
+                  class="solr.DisMaxRequestHandler" >
+     <!-- for historic reasons, DisMaxRequestHandler will use all of
+          it's init params as "defaults" if there is no "defaults" list
+          specified
+     -->
+     <str name="q.alt">*:*</str>
+     <float name="tie">0.01</float>
+     <str name="qf">
+        text^0.5 features_t^1.0 subject^1.4 title_stemmed^2.0
+     </str>
+     <str name="pf">
+        text^0.2 features_t^1.1 subject^1.4 title_stemmed^2.0 title^1.5
+     </str>
+     <str name="bf">
+        ord(weight)^0.5 recip(rord(iind),1,1000,1000)^0.3
+     </str>
+     <str name="mm">
+        3&lt;-1 5&lt;-2 6&lt;90%
+     </str>
+     <int name="ps">100</int>
+  </requestHandler>
+  <requestHandler name="dismax" class="solr.DisMaxRequestHandler" >
+    <lst name="defaults">
+     <str name="q.alt">*:*</str>
+     <float name="tie">0.01</float>
+     <str name="qf">
+        text^0.5 features_t^1.0 subject^1.4 title_stemmed^2.0
+     </str>
+     <str name="pf">
+        text^0.2 features_t^1.1 subject^1.4 title_stemmed^2.0 title^1.5
+     </str>
+     <str name="bf">
+        ord(weight)^0.5 recip(rord(iind),1,1000,1000)^0.3
+     </str>
+     <str name="mm">
+        3&lt;-1 5&lt;-2 6&lt;90%
+     </str>
+     <int name="ps">100</int>
+    </lst>
+  </requestHandler>
+  <requestHandler name="old" class="solr.tst.OldRequestHandler" >
+    <int name="myparam">1000</int>
+    <float name="ratio">1.4142135</float>
+    <arr name="myarr"><int>1</int><int>2</int></arr>
+    <str>foo</str>
+  </requestHandler>
+  <requestHandler name="oldagain" class="solr.tst.OldRequestHandler" >
+    <lst name="lst1"> <str name="op">sqrt</str> <int name="val">2</int> </lst>
+    <lst name="lst2"> <str name="op">log</str> <float name="val">10</float> </lst>
+  </requestHandler>
+
+  <requestHandler name="/admin/" class="org.apache.solr.handler.admin.AdminHandlers" />
+
+  <requestHandler name="test" class="solr.tst.TestRequestHandler" />
+
+  <!-- test query parameter defaults -->
+  <requestHandler name="defaults" class="solr.StandardRequestHandler">
+    <lst name="defaults">
+      <int name="rows">4</int>
+      <bool name="hl">true</bool>
+      <str name="hl.fl">text,name,subject,title,whitetok</str>
+    </lst>
+  </requestHandler>
+
+  <!-- test query parameter defaults -->
+  <requestHandler name="lazy" class="solr.StandardRequestHandler" startup="lazy">
+    <lst name="defaults">
+      <int name="rows">4</int>
+      <bool name="hl">true</bool>
+      <str name="hl.fl">text,name,subject,title,whitetok</str>
+    </lst>
+  </requestHandler>
+
+  <requestHandler name="/update"     class="solr.XmlUpdateRequestHandler"          />
+  <requestHandler name="/update/csv" class="solr.CSVRequestHandler" startup="lazy">
+  	<bool name="httpCaching">false</bool>
+  </requestHandler>
+
+  <searchComponent name="spellcheck" class="org.apache.solr.handler.component.SpellCheckComponent">
+    <str name="queryAnalyzerFieldType">lowerfilt</str>
+
+    <lst name="spellchecker">
+      <str name="name">default</str>
+      <str name="field">lowerfilt</str>
+      <str name="spellcheckIndexDir">spellchecker1</str>
+      <str name="buildOnCommit">true</str>
+    </lst>
+    <!-- Example of using different distance measure -->
+    <lst name="spellchecker">
+      <str name="name">jarowinkler</str>
+      <str name="field">lowerfilt</str>
+      <!-- Use a different Distance Measure -->
+      <str name="distanceMeasure">org.apache.lucene.search.spell.JaroWinklerDistance</str>
+      <str name="spellcheckIndexDir">spellchecker2</str>
+
+    </lst>
+    <lst name="spellchecker">
+      <str name="classname">solr.FileBasedSpellChecker</str>
+      <str name="name">external</str>
+      <str name="sourceLocation">spellings.txt</str>
+      <str name="characterEncoding">UTF-8</str>
+      <str name="spellcheckIndexDir">spellchecker3</str>
+    </lst>
+  </searchComponent>
+
+  <searchComponent name="termsComp" class="org.apache.solr.handler.component.TermsComponent"/>
+
+  <requestHandler name="/terms" class="org.apache.solr.handler.component.SearchHandler">
+    <arr name="components">
+      <str>termsComp</str>
+    </arr>
+  </requestHandler>
+  <!--
+  The SpellingQueryConverter to convert raw (CommonParams.Q) queries into tokens.  Uses a simple regular expression
+   to strip off field markup, boosts, ranges, etc. but it is not guaranteed to match an exact parse from the query parser.
+   -->
+  <queryConverter name="queryConverter" class="org.apache.solr.spelling.SpellingQueryConverter"/>
+
+  <requestHandler name="spellCheckCompRH" class="org.apache.solr.handler.component.SearchHandler">
+    <lst name="defaults">
+      <!-- omp = Only More Popular -->
+      <str name="spellcheck.onlyMorePopular">false</str>
+      <!-- exr = Extended Results -->
+      <str name="spellcheck.extendedResults">false</str>
+      <!--  The number of suggestions to return -->
+      <str name="spellcheck.count">1</str>
+    </lst>
+    <arr name="last-components">
+      <str>spellcheck</str>
+    </arr>
+  </requestHandler>
+
+  
+  <searchComponent name="tvComponent" class="org.apache.solr.handler.component.TermVectorComponent"/>
+
+  <requestHandler name="tvrh" class="org.apache.solr.handler.component.SearchHandler">
+    <lst name="defaults">
+
+    </lst>
+    <arr name="last-components">
+      <str>tvComponent</str>
+    </arr>
+  </requestHandler>
+
+  <searchComponent class="solr.HighlightComponent" name="highlight">
+  <highlighting>
+   <!-- Configure the standard fragmenter -->
+   <fragmenter name="gap" class="org.apache.solr.highlight.GapFragmenter" default="true">
+    <lst name="defaults">
+     <int name="hl.fragsize">100</int>
+    </lst>
+   </fragmenter>
+
+   <fragmenter name="regex" class="org.apache.solr.highlight.RegexFragmenter">
+    <lst name="defaults">
+     <int name="hl.fragsize">70</int>
+    </lst>
+   </fragmenter>
+
+   <!-- Configure the standard formatter -->
+   <formatter name="html" class="org.apache.solr.highlight.HtmlFormatter" default="true">
+    <lst name="defaults">
+     <str name="hl.simple.pre"><![CDATA[<em>]]></str>
+     <str name="hl.simple.post"><![CDATA[</em>]]></str>
+    </lst>
+   </formatter>
+  </highlighting>
+  </searchComponent>
+
+
+  <!-- enable streaming for testing... -->
+  <requestDispatcher handleSelect="true" >
+    <requestParsers enableRemoteStreaming="true" multipartUploadLimitInKB="2048" />
+    <httpCaching lastModifiedFrom="openTime" etagSeed="Solr" never304="false">
+      <cacheControl>max-age=30, public</cacheControl>
+    </httpCaching>
+  </requestDispatcher>
+
+  <admin>
+    <defaultQuery>solr</defaultQuery>
+    <gettableFiles>solrconfig.xml scheam.xml admin-extra.html</gettableFiles>
+  </admin>
+
+  <!-- test getting system property -->
+  <propTest attr1="${solr.test.sys.prop1}-$${literal}"
+            attr2="${non.existent.sys.prop:default-from-config}">prefix-${solr.test.sys.prop2}-suffix</propTest>
+
+  <queryParser name="foo" class="FooQParserPlugin"/>
+
+  <updateRequestProcessorChain name="dedupe">
+    <processor class="org.apache.solr.update.processor.SignatureUpdateProcessorFactory">
+      <bool name="enabled">false</bool>
+      <bool name="overwriteDupes">true</bool>
+      <str name="fields">v_t,t_field</str>
+      <str name="signatureClass">org.apache.solr.update.processor.TextProfileSignature</str>
+    </processor>
+    <processor class="solr.RunUpdateProcessorFactory" />
+  </updateRequestProcessorChain>
+
+</config>

