GitDiffStart: e9ea070f5b31e504350729426a0eec1fdb207d07 | Thu Jan 24 16:21:48 2013 +0000
diff --git a/lucene/core/src/java/org/apache/lucene/index/BinaryDocValuesWriter.java b/lucene/core/src/java/org/apache/lucene/index/BinaryDocValuesWriter.java
new file mode 100644
index 0000000..a855b3b
--- /dev/null
+++ b/lucene/core/src/java/org/apache/lucene/index/BinaryDocValuesWriter.java
@@ -0,0 +1,122 @@
+package org.apache.lucene.index;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import static org.apache.lucene.util.ByteBlockPool.BYTE_BLOCK_SIZE;
+
+import java.io.IOException;
+import java.util.Iterator;
+
+import org.apache.lucene.codecs.DocValuesConsumer;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.BytesRefArray;
+import org.apache.lucene.util.Counter;
+
+
+/** Buffers up pending byte[] per doc, then flushes when
+ *  segment flushes. */
+class BinaryDocValuesWriter extends DocValuesWriter {
+
+  private final BytesRefArray bytesRefArray;
+  private final FieldInfo fieldInfo;
+  private int addedValues = 0;
+  private final BytesRef emptyBytesRef = new BytesRef();
+
+  // nocommit this needs to update bytesUsed?
+
+  public BinaryDocValuesWriter(FieldInfo fieldInfo, Counter counter) {
+    this.fieldInfo = fieldInfo;
+    this.bytesRefArray = new BytesRefArray(counter);
+  }
+
+  public void addValue(int docID, BytesRef value) {
+    if (docID < addedValues) {
+      throw new IllegalArgumentException("DocValuesField \"" + fieldInfo.name + "\" appears more than once in this document (only one value is allowed per field)");
+    }
+    if (value == null) {
+      throw new IllegalArgumentException("field=\"" + fieldInfo.name + "\": null value not allowed");
+    }
+    if (value.length > (BYTE_BLOCK_SIZE - 2)) {
+      throw new IllegalArgumentException("DocValuesField \"" + fieldInfo.name + "\" is too large, must be <= " + (BYTE_BLOCK_SIZE - 2));
+    }
+    
+    // Fill in any holes:
+    while(addedValues < docID) {
+      addedValues++;
+      bytesRefArray.append(emptyBytesRef);
+    }
+    addedValues++;
+    bytesRefArray.append(value);
+  }
+
+  @Override
+  public void finish(int maxDoc) {
+  }
+
+  @Override
+  public void flush(SegmentWriteState state, DocValuesConsumer dvConsumer) throws IOException {
+    final int maxDoc = state.segmentInfo.getDocCount();
+
+    dvConsumer.addBinaryField(fieldInfo,
+                              new Iterable<BytesRef>() {
+
+                                @Override
+                                public Iterator<BytesRef> iterator() {
+                                   return new Iterator<BytesRef>() {
+                                     BytesRef value = new BytesRef();
+                                     int upto;
+
+                                     @Override
+                                     public boolean hasNext() {
+                                       return upto < maxDoc;
+                                     }
+
+                                     @Override
+                                     public void remove() {
+                                       throw new UnsupportedOperationException();
+                                     }
+
+                                     @Override
+                                     public BytesRef next() {
+                                       if (upto < bytesRefArray.size()) {
+                                         bytesRefArray.get(value, upto);
+                                       } else {
+                                         value.length = 0;
+                                       }
+                                       upto++;
+                                       return value;
+                                     }
+                                   };
+                                 }
+                               });
+
+    // nocommit
+    //reset();
+  }
+
+  @Override
+  public void abort() {
+    // nocommit
+    //reset();
+  }
+
+  private void reset() {
+    // nocommit
+    //bytesRefArray.clear();
+  }
+}
\ No newline at end of file
diff --git a/lucene/core/src/java/org/apache/lucene/index/BytesDVWriter.java b/lucene/core/src/java/org/apache/lucene/index/BytesDVWriter.java
deleted file mode 100644
index 16c9267..0000000
--- a/lucene/core/src/java/org/apache/lucene/index/BytesDVWriter.java
+++ /dev/null
@@ -1,121 +0,0 @@
-package org.apache.lucene.index;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import static org.apache.lucene.util.ByteBlockPool.BYTE_BLOCK_SIZE;
-
-import java.io.IOException;
-import java.util.Iterator;
-
-import org.apache.lucene.codecs.DocValuesConsumer;
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.BytesRefArray;
-import org.apache.lucene.util.Counter;
-
-
-/** Buffers up pending byte[] per doc, then flushes when
- *  segment flushes. */
-// nocommit name?
-// nocommit make this a consumer in the chain?
-class BytesDVWriter extends DocValuesWriter {
-
-  private final BytesRefArray bytesRefArray;
-  private final FieldInfo fieldInfo;
-  private int addedValues = 0;
-  private final BytesRef emptyBytesRef = new BytesRef();
-
-  public BytesDVWriter(FieldInfo fieldInfo, Counter counter) {
-    this.fieldInfo = fieldInfo;
-    this.bytesRefArray = new BytesRefArray(counter);
-  }
-
-  public void addValue(int docID, BytesRef value) {
-    if (docID < addedValues) {
-      throw new IllegalArgumentException("DocValuesField \"" + fieldInfo.name + "\" appears more than once in this document (only one value is allowed per field)");
-    }
-    if (value == null) {
-      // nocommit improve message
-      throw new IllegalArgumentException("null binaryValue not allowed (field=" + fieldInfo.name + ")");
-    }
-    if (value.length > (BYTE_BLOCK_SIZE - 2)) {
-      throw new IllegalArgumentException("DocValuesField \"" + fieldInfo.name + "\" is too large, must be <= " + (BYTE_BLOCK_SIZE - 2));
-    }
-    
-    // Fill in any holes:
-    while(addedValues < docID) {
-      addedValues++;
-      bytesRefArray.append(emptyBytesRef);
-    }
-    addedValues++;
-    bytesRefArray.append(value);
-  }
-
-  @Override
-  public void finish(int maxDoc) {
-  }
-
-  @Override
-  public void flush(SegmentWriteState state, DocValuesConsumer dvConsumer) throws IOException {
-    final int maxDoc = state.segmentInfo.getDocCount();
-
-    dvConsumer.addBinaryField(fieldInfo,
-                              new Iterable<BytesRef>() {
-
-                                @Override
-                                public Iterator<BytesRef> iterator() {
-                                   return new Iterator<BytesRef>() {
-                                     BytesRef value = new BytesRef();
-                                     int upto;
-
-                                     @Override
-                                     public boolean hasNext() {
-                                       return upto < maxDoc;
-                                     }
-
-                                     @Override
-                                     public void remove() {
-                                       throw new UnsupportedOperationException();
-                                     }
-
-                                     @Override
-                                     public BytesRef next() {
-                                       // nocommit make
-                                       // mutable Number:
-                                       if (upto < bytesRefArray.size()) {
-                                         bytesRefArray.get(value, upto);
-                                       } else {
-                                         value.length = 0;
-                                       }
-                                       upto++;
-                                       return value;
-                                     }
-                                   };
-                                 }
-                               });
-
-    reset();
-  }
-
-  public void abort() {
-    reset();
-  }
-
-  private void reset() {
-    bytesRefArray.clear();
-  }
-}
\ No newline at end of file
diff --git a/lucene/core/src/java/org/apache/lucene/index/DocValuesProcessor.java b/lucene/core/src/java/org/apache/lucene/index/DocValuesProcessor.java
index 0a035e8..a726871 100644
--- a/lucene/core/src/java/org/apache/lucene/index/DocValuesProcessor.java
+++ b/lucene/core/src/java/org/apache/lucene/index/DocValuesProcessor.java
@@ -100,53 +100,53 @@ final class DocValuesProcessor extends StoredFieldsConsumer {
 
   void addBinaryField(FieldInfo fieldInfo, int docID, BytesRef value) {
     DocValuesWriter writer = writers.get(fieldInfo.name);
-    BytesDVWriter binaryWriter;
+    BinaryDocValuesWriter binaryWriter;
     if (writer == null) {
-      binaryWriter = new BytesDVWriter(fieldInfo, bytesUsed);
+      binaryWriter = new BinaryDocValuesWriter(fieldInfo, bytesUsed);
       writers.put(fieldInfo.name, binaryWriter);
-    } else if (!(writer instanceof BytesDVWriter)) {
+    } else if (!(writer instanceof BinaryDocValuesWriter)) {
       throw new IllegalArgumentException("Incompatible DocValues type: field \"" + fieldInfo.name + "\" changed from " + getTypeDesc(writer) + " to binary");
     } else {
-      binaryWriter = (BytesDVWriter) writer;
+      binaryWriter = (BinaryDocValuesWriter) writer;
     }
     binaryWriter.addValue(docID, value);
   }
 
   void addSortedField(FieldInfo fieldInfo, int docID, BytesRef value) {
     DocValuesWriter writer = writers.get(fieldInfo.name);
-    SortedBytesDVWriter sortedWriter;
+    SortedDocValuesWriter sortedWriter;
     if (writer == null) {
-      sortedWriter = new SortedBytesDVWriter(fieldInfo, bytesUsed);
+      sortedWriter = new SortedDocValuesWriter(fieldInfo, bytesUsed);
       writers.put(fieldInfo.name, sortedWriter);
-    } else if (!(writer instanceof SortedBytesDVWriter)) {
+    } else if (!(writer instanceof SortedDocValuesWriter)) {
       throw new IllegalArgumentException("Incompatible DocValues type: field \"" + fieldInfo.name + "\" changed from " + getTypeDesc(writer) + " to sorted");
     } else {
-      sortedWriter = (SortedBytesDVWriter) writer;
+      sortedWriter = (SortedDocValuesWriter) writer;
     }
     sortedWriter.addValue(docID, value);
   }
 
   void addNumericField(FieldInfo fieldInfo, int docID, long value) {
     DocValuesWriter writer = writers.get(fieldInfo.name);
-    NumberDVWriter numericWriter;
+    NumericDocValuesWriter numericWriter;
     if (writer == null) {
-      numericWriter = new NumberDVWriter(fieldInfo, bytesUsed);
+      numericWriter = new NumericDocValuesWriter(fieldInfo, bytesUsed);
       writers.put(fieldInfo.name, numericWriter);
-    } else if (!(writer instanceof NumberDVWriter)) {
+    } else if (!(writer instanceof NumericDocValuesWriter)) {
       throw new IllegalArgumentException("Incompatible DocValues type: field \"" + fieldInfo.name + "\" changed from " + getTypeDesc(writer) + " to numeric");
     } else {
-      numericWriter = (NumberDVWriter) writer;
+      numericWriter = (NumericDocValuesWriter) writer;
     }
     numericWriter.addValue(docID, value);
   }
 
   private String getTypeDesc(DocValuesWriter obj) {
-    if (obj instanceof BytesDVWriter) {
+    if (obj instanceof BinaryDocValuesWriter) {
       return "binary";
-    } else if (obj instanceof NumberDVWriter) {
+    } else if (obj instanceof NumericDocValuesWriter) {
       return "numeric";
     } else {
-      assert obj instanceof SortedBytesDVWriter;
+      assert obj instanceof SortedDocValuesWriter;
       return "sorted";
     }
   }
diff --git a/lucene/core/src/java/org/apache/lucene/index/NormsConsumerPerField.java b/lucene/core/src/java/org/apache/lucene/index/NormsConsumerPerField.java
index 868e84b..178aedb 100644
--- a/lucene/core/src/java/org/apache/lucene/index/NormsConsumerPerField.java
+++ b/lucene/core/src/java/org/apache/lucene/index/NormsConsumerPerField.java
@@ -25,7 +25,7 @@ final class NormsConsumerPerField extends InvertedDocEndConsumerPerField impleme
   private final DocumentsWriterPerThread.DocState docState;
   private final Similarity similarity;
   private final FieldInvertState fieldState;
-  private NumberDVWriter consumer;
+  private NumericDocValuesWriter consumer;
   
   public NormsConsumerPerField(final DocInverterPerField docInverterPerField, final FieldInfo fieldInfo, NormsConsumer parent) {
     this.fieldInfo = fieldInfo;
@@ -46,7 +46,7 @@ final class NormsConsumerPerField extends InvertedDocEndConsumerPerField impleme
         // nocommit wrongish?  what about the
         // only-doc-with-norms-enabled-hits-exc case?
         fieldInfo.setNormValueType(FieldInfo.DocValuesType.NUMERIC);
-        consumer = new NumberDVWriter(fieldInfo, docState.docWriter.bytesUsed);
+        consumer = new NumericDocValuesWriter(fieldInfo, docState.docWriter.bytesUsed);
       }
       consumer.addValue(docState.docID, similarity.computeNorm(fieldState));
     }
diff --git a/lucene/core/src/java/org/apache/lucene/index/NumberDVWriter.java b/lucene/core/src/java/org/apache/lucene/index/NumberDVWriter.java
deleted file mode 100644
index 041780b..0000000
--- a/lucene/core/src/java/org/apache/lucene/index/NumberDVWriter.java
+++ /dev/null
@@ -1,128 +0,0 @@
-package org.apache.lucene.index;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.util.Iterator;
-
-import org.apache.lucene.codecs.DocValuesConsumer;
-import org.apache.lucene.util.Counter;
-import org.apache.lucene.util.packed.AppendingLongBuffer;
-
-// nocommit pick numeric or number ... then fix all places ...
-
-/** Buffers up pending long per doc, then flushes when
- *  segment flushes. */
-// nocommit rename to NumericDVWriter?
-// nocommit make this a consumer in the chain?
-class NumberDVWriter extends DocValuesWriter {
-
-  private final static long MISSING = 0L;
-
-  private AppendingLongBuffer pending;
-  private final Counter iwBytesUsed;
-  private long bytesUsed;
-  private final FieldInfo fieldInfo;
-
-  public NumberDVWriter(FieldInfo fieldInfo, Counter iwBytesUsed) {
-    pending = new AppendingLongBuffer();
-    bytesUsed = pending.ramBytesUsed();
-    this.fieldInfo = fieldInfo;
-    this.iwBytesUsed = iwBytesUsed;
-  }
-
-  public void addValue(int docID, long value) {
-    if (docID < pending.size()) {
-      throw new IllegalArgumentException("DocValuesField \"" + fieldInfo.name + "\" appears more than once in this document (only one value is allowed per field)");
-    }
-
-    // Fill in any holes:
-    for (int i = pending.size(); i < docID; ++i) {
-      pending.add(MISSING);
-    }
-
-    pending.add(value);
-
-    updateBytesUsed();
-  }
-
-  private void updateBytesUsed() {
-    final long newBytesUsed = pending.ramBytesUsed();
-    iwBytesUsed.addAndGet(newBytesUsed - bytesUsed);
-    bytesUsed = newBytesUsed;
-  }
-
-  @Override
-  public void finish(int maxDoc) {
-  }
-
-  @Override
-  public void flush(SegmentWriteState state, DocValuesConsumer dvConsumer) throws IOException {
-
-    final int maxDoc = state.segmentInfo.getDocCount();
-
-    dvConsumer.addNumericField(fieldInfo,
-                               new Iterable<Number>() {
-
-                                 @Override
-                                 public Iterator<Number> iterator() {
-                                   return new Iterator<Number>() {
-                                     int upto;
-                                     AppendingLongBuffer.Iterator iter = pending.iterator();
-
-                                     @Override
-                                     public boolean hasNext() {
-                                       return upto < maxDoc;
-                                     }
-
-                                     @Override
-                                     public void remove() {
-                                       throw new UnsupportedOperationException();
-                                     }
-
-                                     @Override
-                                     public Number next() {
-                                       // nocommit make
-                                       // mutable Number:
-                                       long value;
-                                       if (upto < pending.size()) {
-                                         value =  iter.next();
-                                       } else {
-                                         value = 0;
-                                       }
-                                       upto++;
-                                       return value;
-                                     }
-                                   };
-                                 }
-                               });
-
-    reset();
-  }
-
-  public void abort() {
-    reset();
-  }
-
-  // nocommit do we really need this...?  can't/doesn't parent alloc
-  // a new instance after flush?
-  void reset() {
-    pending = new AppendingLongBuffer();
-    updateBytesUsed();
-  }
-}
\ No newline at end of file
diff --git a/lucene/core/src/java/org/apache/lucene/index/NumericDocValuesWriter.java b/lucene/core/src/java/org/apache/lucene/index/NumericDocValuesWriter.java
new file mode 100644
index 0000000..20742e0
--- /dev/null
+++ b/lucene/core/src/java/org/apache/lucene/index/NumericDocValuesWriter.java
@@ -0,0 +1,129 @@
+package org.apache.lucene.index;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.Iterator;
+
+import org.apache.lucene.codecs.DocValuesConsumer;
+import org.apache.lucene.util.Counter;
+import org.apache.lucene.util.packed.AppendingLongBuffer;
+
+// nocommit pick numeric or number ... then fix all places ...
+
+/** Buffers up pending long per doc, then flushes when
+ *  segment flushes. */
+class NumericDocValuesWriter extends DocValuesWriter {
+
+  private final static long MISSING = 0L;
+
+  private AppendingLongBuffer pending;
+  private final Counter iwBytesUsed;
+  private long bytesUsed;
+  private final FieldInfo fieldInfo;
+
+  public NumericDocValuesWriter(FieldInfo fieldInfo, Counter iwBytesUsed) {
+    pending = new AppendingLongBuffer();
+    bytesUsed = pending.ramBytesUsed();
+    this.fieldInfo = fieldInfo;
+    this.iwBytesUsed = iwBytesUsed;
+  }
+
+  public void addValue(int docID, long value) {
+    if (docID < pending.size()) {
+      throw new IllegalArgumentException("DocValuesField \"" + fieldInfo.name + "\" appears more than once in this document (only one value is allowed per field)");
+    }
+
+    // Fill in any holes:
+    for (int i = pending.size(); i < docID; ++i) {
+      pending.add(MISSING);
+    }
+
+    pending.add(value);
+
+    updateBytesUsed();
+  }
+
+  private void updateBytesUsed() {
+    final long newBytesUsed = pending.ramBytesUsed();
+    iwBytesUsed.addAndGet(newBytesUsed - bytesUsed);
+    bytesUsed = newBytesUsed;
+  }
+
+  @Override
+  public void finish(int maxDoc) {
+  }
+
+  @Override
+  public void flush(SegmentWriteState state, DocValuesConsumer dvConsumer) throws IOException {
+
+    final int maxDoc = state.segmentInfo.getDocCount();
+
+    dvConsumer.addNumericField(fieldInfo,
+                               new Iterable<Number>() {
+
+                                 @Override
+                                 public Iterator<Number> iterator() {
+                                   return new Iterator<Number>() {
+                                     int upto;
+                                     AppendingLongBuffer.Iterator iter = pending.iterator();
+
+                                     @Override
+                                     public boolean hasNext() {
+                                       return upto < maxDoc;
+                                     }
+
+                                     @Override
+                                     public void remove() {
+                                       throw new UnsupportedOperationException();
+                                     }
+
+                                     @Override
+                                     public Number next() {
+                                       long value;
+                                       if (upto < pending.size()) {
+                                         value =  iter.next();
+                                       } else {
+                                         value = 0;
+                                       }
+                                       upto++;
+                                       // TODO: make reusable Number
+                                       return value;
+                                     }
+                                   };
+                                 }
+                               });
+
+    // nocommit
+    //reset();
+  }
+
+  @Override
+  public void abort() {
+    // nocommit
+    //reset();
+  }
+
+  // nocommit do we really need this...?  can't/doesn't parent alloc
+  // a new instance after flush?
+  void reset() {
+    // nocommit
+    //pending = new AppendingLongBuffer();
+    //updateBytesUsed();
+  }
+}
\ No newline at end of file
diff --git a/lucene/core/src/java/org/apache/lucene/index/SortedBytesDVWriter.java b/lucene/core/src/java/org/apache/lucene/index/SortedBytesDVWriter.java
deleted file mode 100644
index 5205fe3..0000000
--- a/lucene/core/src/java/org/apache/lucene/index/SortedBytesDVWriter.java
+++ /dev/null
@@ -1,209 +0,0 @@
-package org.apache.lucene.index;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import static org.apache.lucene.util.ByteBlockPool.BYTE_BLOCK_SIZE;
-
-import java.io.IOException;
-import java.util.Iterator;
-
-import org.apache.lucene.codecs.DocValuesConsumer;
-import org.apache.lucene.util.ArrayUtil;
-import org.apache.lucene.util.ByteBlockPool;
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.BytesRefHash.DirectBytesStartArray;
-import org.apache.lucene.util.BytesRefHash;
-import org.apache.lucene.util.Counter;
-import org.apache.lucene.util.RamUsageEstimator;
-
-
-/** Buffers up pending byte[] per doc, deref and sorting via
- *  int ord, then flushes when segment flushes. */
-// nocommit name?
-// nocommit make this a consumer in the chain?
-class SortedBytesDVWriter extends DocValuesWriter {
-  final BytesRefHash hash;
-  private int[] pending = new int[DEFAULT_PENDING_SIZE];
-  private int pendingIndex = 0;
-  private final Counter iwBytesUsed;
-  private final FieldInfo fieldInfo;
-
-  private static final BytesRef EMPTY = new BytesRef(BytesRef.EMPTY_BYTES);
-  private static final int DEFAULT_PENDING_SIZE = 16;
-
-  public SortedBytesDVWriter(FieldInfo fieldInfo, Counter iwBytesUsed) {
-    this.fieldInfo = fieldInfo;
-    this.iwBytesUsed = iwBytesUsed;
-    hash = new BytesRefHash(
-        new ByteBlockPool(
-            new ByteBlockPool.DirectTrackingAllocator(iwBytesUsed)),
-            BytesRefHash.DEFAULT_CAPACITY,
-            new DirectBytesStartArray(BytesRefHash.DEFAULT_CAPACITY, iwBytesUsed));
-    iwBytesUsed.addAndGet(RamUsageEstimator.NUM_BYTES_ARRAY_HEADER + RamUsageEstimator.NUM_BYTES_INT * DEFAULT_PENDING_SIZE);
-  }
-
-  public void addValue(int docID, BytesRef value) {
-    if (docID < pendingIndex) {
-      throw new IllegalArgumentException("DocValuesField \"" + fieldInfo.name + "\" appears more than once in this document (only one value is allowed per field)");
-    }
-    if (value == null) {
-      // nocommit improve message
-      throw new IllegalArgumentException("null sortedValue not allowed (field=" + fieldInfo.name + ")");
-    }
-    if (value.length > (BYTE_BLOCK_SIZE - 2)) {
-      throw new IllegalArgumentException("DocValuesField \"" + fieldInfo.name + "\" is too large, must be <= " + (BYTE_BLOCK_SIZE - 2));
-    }
-
-    // Fill in any holes:
-    while(pendingIndex < docID) {
-      addOneValue(EMPTY);
-    }
-
-    addOneValue(value);
-  }
-
-  @Override
-  public void finish(int maxDoc) {
-    if (pendingIndex < maxDoc) {
-      addOneValue(EMPTY);
-    }
-  }
-
-  private void addOneValue(BytesRef value) {
-    int ord = hash.add(value);
-    if (ord < 0) {
-      ord = -ord-1;
-    } 
-    
-    if (pendingIndex <= pending.length) {
-      int pendingLen = pending.length;
-      pending = ArrayUtil.grow(pending, pendingIndex+1);
-      iwBytesUsed.addAndGet((pending.length - pendingLen) * RamUsageEstimator.NUM_BYTES_INT);
-    }
-    pending[pendingIndex++] = ord;
-  }
-
-  @Override
-  public void flush(SegmentWriteState state, DocValuesConsumer dvConsumer) throws IOException {
-    final int maxDoc = state.segmentInfo.getDocCount();
-
-    final int emptyOrd;
-    if (pendingIndex < maxDoc) {
-      // Make sure we added EMPTY value before sorting:
-      int ord = hash.add(EMPTY);
-      if (ord < 0) {
-        emptyOrd = -ord-1;
-      } else {
-        emptyOrd = ord;
-      }
-    } else {
-      emptyOrd = -1;
-    }
-
-    final int valueCount = hash.size();
-
-    final int[] sortedValues = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());
-    final int sortedValueRamUsage = RamUsageEstimator.NUM_BYTES_ARRAY_HEADER + RamUsageEstimator.NUM_BYTES_INT*valueCount;
-    iwBytesUsed.addAndGet(sortedValueRamUsage);
-    final int[] ordMap = new int[valueCount];
-
-    for(int ord=0;ord<valueCount;ord++) {
-      ordMap[sortedValues[ord]] = ord;
-    }
-
-    final int bufferedDocCount = pendingIndex;
-
-    dvConsumer.addSortedField(fieldInfo,
-
-                              // ord -> value
-                              new Iterable<BytesRef>() {
-                                @Override
-                                public Iterator<BytesRef> iterator() {
-                                  return new Iterator<BytesRef>() {
-                                    int ordUpto;
-                                    BytesRef scratch = new BytesRef();
-
-                                    @Override
-                                    public boolean hasNext() {
-                                      return ordUpto < valueCount;
-                                    }
-
-                                    @Override
-                                    public void remove() {
-                                      throw new UnsupportedOperationException();
-                                    }
-
-                                    @Override
-                                    public BytesRef next() {
-                                      hash.get(sortedValues[ordUpto], scratch);
-                                      ordUpto++;
-                                      return scratch;
-                                    }
-                                  };
-                                }
-                              },
-
-                              // doc -> ord
-                              new Iterable<Number>() {
-                                @Override
-                                public Iterator<Number> iterator() {
-                                  return new Iterator<Number>() {
-                                    int docUpto;
-
-                                    @Override
-                                    public boolean hasNext() {
-                                      return docUpto < maxDoc;
-                                    }
-
-                                    @Override
-                                    public void remove() {
-                                      throw new UnsupportedOperationException();
-                                    }
-
-                                    @Override
-                                    public Number next() {
-                                      int ord;
-                                      if (docUpto < bufferedDocCount) {
-                                        ord = pending[docUpto];
-                                      } else {
-                                        ord = emptyOrd;
-                                      }
-                                      docUpto++;
-                                      // nocommit make
-                                      // resuable Number?
-                                      return ordMap[ord];
-                                    }
-                                  };
-                                }
-                              });
-    
-    iwBytesUsed.addAndGet(-sortedValueRamUsage);
-    reset();
-  }
-
-  public void abort() {
-    reset();
-  }
-
-  private void reset() {
-    iwBytesUsed.addAndGet((pending.length - DEFAULT_PENDING_SIZE) * RamUsageEstimator.NUM_BYTES_INT);
-    pending = ArrayUtil.shrink(pending, DEFAULT_PENDING_SIZE);
-    pendingIndex = 0;
-    hash.clear();
-  }
-}
diff --git a/lucene/core/src/java/org/apache/lucene/index/SortedDocValuesWriter.java b/lucene/core/src/java/org/apache/lucene/index/SortedDocValuesWriter.java
new file mode 100644
index 0000000..dbe1d9f
--- /dev/null
+++ b/lucene/core/src/java/org/apache/lucene/index/SortedDocValuesWriter.java
@@ -0,0 +1,211 @@
+package org.apache.lucene.index;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import static org.apache.lucene.util.ByteBlockPool.BYTE_BLOCK_SIZE;
+
+import java.io.IOException;
+import java.util.Iterator;
+
+import org.apache.lucene.codecs.DocValuesConsumer;
+import org.apache.lucene.util.ArrayUtil;
+import org.apache.lucene.util.ByteBlockPool;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.BytesRefHash.DirectBytesStartArray;
+import org.apache.lucene.util.BytesRefHash;
+import org.apache.lucene.util.Counter;
+import org.apache.lucene.util.RamUsageEstimator;
+
+
+/** Buffers up pending byte[] per doc, deref and sorting via
+ *  int ord, then flushes when segment flushes. */
+class SortedDocValuesWriter extends DocValuesWriter {
+  final BytesRefHash hash;
+  private int[] pending = new int[DEFAULT_PENDING_SIZE];
+  private int pendingIndex = 0;
+  private final Counter iwBytesUsed;
+  private final FieldInfo fieldInfo;
+
+  private static final BytesRef EMPTY = new BytesRef(BytesRef.EMPTY_BYTES);
+  private static final int DEFAULT_PENDING_SIZE = 16;
+
+  public SortedDocValuesWriter(FieldInfo fieldInfo, Counter iwBytesUsed) {
+    this.fieldInfo = fieldInfo;
+    this.iwBytesUsed = iwBytesUsed;
+    hash = new BytesRefHash(
+        new ByteBlockPool(
+            new ByteBlockPool.DirectTrackingAllocator(iwBytesUsed)),
+            BytesRefHash.DEFAULT_CAPACITY,
+            new DirectBytesStartArray(BytesRefHash.DEFAULT_CAPACITY, iwBytesUsed));
+    iwBytesUsed.addAndGet(RamUsageEstimator.NUM_BYTES_ARRAY_HEADER + RamUsageEstimator.NUM_BYTES_INT * DEFAULT_PENDING_SIZE);
+  }
+
+  public void addValue(int docID, BytesRef value) {
+    if (docID < pendingIndex) {
+      throw new IllegalArgumentException("DocValuesField \"" + fieldInfo.name + "\" appears more than once in this document (only one value is allowed per field)");
+    }
+    if (value == null) {
+      throw new IllegalArgumentException("field \"" + fieldInfo.name + "\": null value not allowed");
+    }
+    if (value.length > (BYTE_BLOCK_SIZE - 2)) {
+      throw new IllegalArgumentException("DocValuesField \"" + fieldInfo.name + "\" is too large, must be <= " + (BYTE_BLOCK_SIZE - 2));
+    }
+
+    // Fill in any holes:
+    while(pendingIndex < docID) {
+      addOneValue(EMPTY);
+    }
+
+    addOneValue(value);
+  }
+
+  @Override
+  public void finish(int maxDoc) {
+    if (pendingIndex < maxDoc) {
+      addOneValue(EMPTY);
+    }
+  }
+
+  private void addOneValue(BytesRef value) {
+    int ord = hash.add(value);
+    if (ord < 0) {
+      ord = -ord-1;
+    } 
+    
+    if (pendingIndex <= pending.length) {
+      int pendingLen = pending.length;
+      pending = ArrayUtil.grow(pending, pendingIndex+1);
+      iwBytesUsed.addAndGet((pending.length - pendingLen) * RamUsageEstimator.NUM_BYTES_INT);
+    }
+    pending[pendingIndex++] = ord;
+  }
+
+  @Override
+  public void flush(SegmentWriteState state, DocValuesConsumer dvConsumer) throws IOException {
+    final int maxDoc = state.segmentInfo.getDocCount();
+
+    final int emptyOrd;
+    if (pendingIndex < maxDoc) {
+      // Make sure we added EMPTY value before sorting:
+      int ord = hash.add(EMPTY);
+      if (ord < 0) {
+        emptyOrd = -ord-1;
+      } else {
+        emptyOrd = ord;
+      }
+    } else {
+      emptyOrd = -1;
+    }
+
+    final int valueCount = hash.size();
+
+    final int[] sortedValues = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());
+    final int sortedValueRamUsage = RamUsageEstimator.NUM_BYTES_ARRAY_HEADER + RamUsageEstimator.NUM_BYTES_INT*valueCount;
+    iwBytesUsed.addAndGet(sortedValueRamUsage);
+    final int[] ordMap = new int[valueCount];
+
+    for(int ord=0;ord<valueCount;ord++) {
+      ordMap[sortedValues[ord]] = ord;
+    }
+
+    final int bufferedDocCount = pendingIndex;
+
+    dvConsumer.addSortedField(fieldInfo,
+
+                              // ord -> value
+                              new Iterable<BytesRef>() {
+                                @Override
+                                public Iterator<BytesRef> iterator() {
+                                  return new Iterator<BytesRef>() {
+                                    int ordUpto;
+                                    BytesRef scratch = new BytesRef();
+
+                                    @Override
+                                    public boolean hasNext() {
+                                      return ordUpto < valueCount;
+                                    }
+
+                                    @Override
+                                    public void remove() {
+                                      throw new UnsupportedOperationException();
+                                    }
+
+                                    @Override
+                                    public BytesRef next() {
+                                      hash.get(sortedValues[ordUpto], scratch);
+                                      ordUpto++;
+                                      return scratch;
+                                    }
+                                  };
+                                }
+                              },
+
+                              // doc -> ord
+                              new Iterable<Number>() {
+                                @Override
+                                public Iterator<Number> iterator() {
+                                  return new Iterator<Number>() {
+                                    int docUpto;
+
+                                    @Override
+                                    public boolean hasNext() {
+                                      return docUpto < maxDoc;
+                                    }
+
+                                    @Override
+                                    public void remove() {
+                                      throw new UnsupportedOperationException();
+                                    }
+
+                                    @Override
+                                    public Number next() {
+                                      int ord;
+                                      if (docUpto < bufferedDocCount) {
+                                        ord = pending[docUpto];
+                                      } else {
+                                        ord = emptyOrd;
+                                      }
+                                      docUpto++;
+                                      // TODO: make reusable Number
+                                      return ordMap[ord];
+                                    }
+                                  };
+                                }
+                              });
+    
+    iwBytesUsed.addAndGet(-sortedValueRamUsage);
+    // nocommit
+    //reset();
+  }
+
+  @Override
+  public void abort() {
+    // nocommit
+    //reset();
+  }
+
+  private void reset() {
+    // nocommit
+    /*
+    iwBytesUsed.addAndGet((pending.length - DEFAULT_PENDING_SIZE) * RamUsageEstimator.NUM_BYTES_INT);
+    pending = ArrayUtil.shrink(pending, DEFAULT_PENDING_SIZE);
+    pendingIndex = 0;
+    hash.clear();
+    */
+  }
+}

