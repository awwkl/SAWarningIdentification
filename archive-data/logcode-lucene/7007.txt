GitDiffStart: 531d3a57448509f2f6e10f64ece1da377e7ca73c | Wed Feb 12 10:42:54 2014 +0000
diff --git a/lucene/CHANGES.txt b/lucene/CHANGES.txt
index 784b724..766cc28 100644
--- a/lucene/CHANGES.txt
+++ b/lucene/CHANGES.txt
@@ -157,6 +157,10 @@ New Features
 * LUCENE-5440: Add LongBitSet for managing more than 2.1B bits (otherwise use
   FixedBitSet). (Shai Erera)
 
+* LUCENE-5437: ASCIIFoldingFilter now has an option to preserve the original token
+  and emit it on the same position as the folded token only if the actual token was
+  folded. (Simon Willnauer, Nik Everett) 
+
 Build
 
 * LUCENE-5217,LUCENE-5420: Maven config: get dependencies from Ant+Ivy config;
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/ASCIIFoldingFilter.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/ASCIIFoldingFilter.java
index 27b396f..4afe735 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/ASCIIFoldingFilter.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/ASCIIFoldingFilter.java
@@ -22,6 +22,7 @@ import java.io.IOException;
 import org.apache.lucene.analysis.TokenFilter;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
 import org.apache.lucene.util.ArrayUtil;
 import org.apache.lucene.util.RamUsageEstimator;
 
@@ -57,17 +58,49 @@ import org.apache.lucene.util.RamUsageEstimator;
  * For example, '&agrave;' will be replaced by 'a'.
  */
 public final class ASCIIFoldingFilter extends TokenFilter {
+  private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
+  private final PositionIncrementAttribute posIncAttr = addAttribute(PositionIncrementAttribute.class);
+  private final boolean preserveOriginal;
+  private char[] output = new char[512];
+  private int outputPos;
+  private State state;
+
   public ASCIIFoldingFilter(TokenStream input)
   {
+    this(input, false);
+  }
+
+  /**
+   * Create a new {@link ASCIIFoldingFilter}.
+   * 
+   * @param input
+   *          TokenStream to filter
+   * @param preserveOriginal
+   *          should the original tokens be kept on the input stream with a 0 position increment
+   *          from the folded tokens?
+   **/
+  public ASCIIFoldingFilter(TokenStream input, boolean preserveOriginal)
+  {
     super(input);
+    this.preserveOriginal = preserveOriginal;
   }
 
-  private char[] output = new char[512];
-  private int outputPos;
-  private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
+  /**
+   * Does the filter preserve the original tokens?
+   */
+  public boolean isPreserveOriginal() {
+    return preserveOriginal;
+  }
 
   @Override
   public boolean incrementToken() throws IOException {
+    if (state != null) {
+      assert preserveOriginal : "state should only be captured if preserveOriginal is true";
+      restoreState(state);
+      posIncAttr.setPositionIncrement(0);
+      state = null;
+      return true;
+    }
     if (input.incrementToken()) {
       final char[] buffer = termAtt.buffer();
       final int length = termAtt.length();
@@ -89,6 +122,12 @@ public final class ASCIIFoldingFilter extends TokenFilter {
     }
   }
 
+  @Override
+  public void reset() throws IOException {
+    super.reset();
+    state = null;
+  }
+
   /**
    * Converts characters above ASCII to their ASCII equivalents.  For example,
    * accents are removed from accented characters.
@@ -97,6 +136,9 @@ public final class ASCIIFoldingFilter extends TokenFilter {
    */
   public void foldToASCII(char[] input, int length)
   {
+    if (preserveOriginal) {
+      state = captureState();
+    }
     // Worst-case length required:
     final int maxSizeNeeded = 4 * length;
     if (output.length < maxSizeNeeded) {
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/ASCIIFoldingFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/ASCIIFoldingFilterFactory.java
index 63f12fc..464fe61 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/ASCIIFoldingFilterFactory.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/ASCIIFoldingFilterFactory.java
@@ -31,15 +31,17 @@ import org.apache.lucene.analysis.TokenStream;
  * &lt;fieldType name="text_ascii" class="solr.TextField" positionIncrementGap="100"&gt;
  *   &lt;analyzer&gt;
  *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
- *     &lt;filter class="solr.ASCIIFoldingFilterFactory"/&gt;
+ *     &lt;filter class="solr.ASCIIFoldingFilterFactory" preserveOriginal="false"/&gt;
  *   &lt;/analyzer&gt;
  * &lt;/fieldType&gt;</pre>
  */
 public class ASCIIFoldingFilterFactory extends TokenFilterFactory implements MultiTermAwareComponent {
+  private final boolean preserveOriginal;
   
   /** Creates a new ASCIIFoldingFilterFactory */
   public ASCIIFoldingFilterFactory(Map<String,String> args) {
     super(args);
+    preserveOriginal = getBoolean(args, "preserveOriginal", false);
     if (!args.isEmpty()) {
       throw new IllegalArgumentException("Unknown parameters: " + args);
     }
@@ -47,7 +49,7 @@ public class ASCIIFoldingFilterFactory extends TokenFilterFactory implements Mul
   
   @Override
   public ASCIIFoldingFilter create(TokenStream input) {
-    return new ASCIIFoldingFilter(input);
+    return new ASCIIFoldingFilter(input, preserveOriginal);
   }
 
   @Override
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestASCIIFoldingFilter.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestASCIIFoldingFilter.java
index fbece77..81495b1 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestASCIIFoldingFilter.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestASCIIFoldingFilter.java
@@ -31,91 +31,103 @@ import java.util.ArrayList;
 import java.util.Iterator;
 
 public class TestASCIIFoldingFilter extends BaseTokenStreamTestCase {
+  /**
+   * Pop one input token's worth of tokens off the filter and verify that they are as expected.
+   */
+  void assertNextTerms(String expectedUnfolded, String expectedFolded, ASCIIFoldingFilter filter,
+      CharTermAttribute termAtt) throws Exception {
+    assertTrue(filter.incrementToken());
+    assertEquals(expectedFolded, termAtt.toString());
+    if (filter.isPreserveOriginal() && !expectedUnfolded.equals(expectedFolded)) {
+      assertTrue(filter.incrementToken());
+      assertEquals(expectedUnfolded, termAtt.toString());
+    }
+  }
 
   // testLain1Accents() is a copy of TestLatin1AccentFilter.testU().
   public void testLatin1Accents() throws Exception {
     TokenStream stream = whitespaceMockTokenizer("Des mot clÃ©s ? LA CHA?NE ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Ä² ? ?"
       +" ? ? ? ? ? ? ? ? ? ? ? ? ? Å¸ ? Ã¡ Ã¢ Ã£ Ã¤ Ã¥ Ã¦ Ã§ Ã¨ Ã© Ãª Ã« Ã¬ Ã­ Ã® Ã¯ Ä³"
       +" Ã° Ã± Ã² Ã³ Ã´ Ãµ Ã¶ Ã¸ ? ? Ã¾ Ã¹ Ãº Ã» Ã¼ Ã½ Ã¿ ï¬? ï¬?");
-    ASCIIFoldingFilter filter = new ASCIIFoldingFilter(stream);
+    ASCIIFoldingFilter filter = new ASCIIFoldingFilter(stream, random().nextBoolean());
 
     CharTermAttribute termAtt = filter.getAttribute(CharTermAttribute.class);
     filter.reset();
-    assertTermEquals("Des", filter, termAtt);
-    assertTermEquals("mot", filter, termAtt);
-    assertTermEquals("cles", filter, termAtt);
-    assertTermEquals("A", filter, termAtt);
-    assertTermEquals("LA", filter, termAtt);
-    assertTermEquals("CHAINE", filter, termAtt);
-    assertTermEquals("A", filter, termAtt);
-    assertTermEquals("A", filter, termAtt);
-    assertTermEquals("A", filter, termAtt);
-    assertTermEquals("A", filter, termAtt);
-    assertTermEquals("A", filter, termAtt);
-    assertTermEquals("A", filter, termAtt);
-    assertTermEquals("AE", filter, termAtt);
-    assertTermEquals("C", filter, termAtt);
-    assertTermEquals("E", filter, termAtt);
-    assertTermEquals("E", filter, termAtt);
-    assertTermEquals("E", filter, termAtt);
-    assertTermEquals("E", filter, termAtt);
-    assertTermEquals("I", filter, termAtt);
-    assertTermEquals("I", filter, termAtt);
-    assertTermEquals("I", filter, termAtt);
-    assertTermEquals("I", filter, termAtt);
-    assertTermEquals("IJ", filter, termAtt);
-    assertTermEquals("D", filter, termAtt);
-    assertTermEquals("N", filter, termAtt);
-    assertTermEquals("O", filter, termAtt);
-    assertTermEquals("O", filter, termAtt);
-    assertTermEquals("O", filter, termAtt);
-    assertTermEquals("O", filter, termAtt);
-    assertTermEquals("O", filter, termAtt);
-    assertTermEquals("O", filter, termAtt);
-    assertTermEquals("OE", filter, termAtt);
-    assertTermEquals("TH", filter, termAtt);
-    assertTermEquals("U", filter, termAtt);
-    assertTermEquals("U", filter, termAtt);
-    assertTermEquals("U", filter, termAtt);
-    assertTermEquals("U", filter, termAtt);
-    assertTermEquals("Y", filter, termAtt);
-    assertTermEquals("Y", filter, termAtt);
-    assertTermEquals("a", filter, termAtt);
-    assertTermEquals("a", filter, termAtt);
-    assertTermEquals("a", filter, termAtt);
-    assertTermEquals("a", filter, termAtt);
-    assertTermEquals("a", filter, termAtt);
-    assertTermEquals("a", filter, termAtt);
-    assertTermEquals("ae", filter, termAtt);
-    assertTermEquals("c", filter, termAtt);
-    assertTermEquals("e", filter, termAtt);
-    assertTermEquals("e", filter, termAtt);
-    assertTermEquals("e", filter, termAtt);
-    assertTermEquals("e", filter, termAtt);
-    assertTermEquals("i", filter, termAtt);
-    assertTermEquals("i", filter, termAtt);
-    assertTermEquals("i", filter, termAtt);
-    assertTermEquals("i", filter, termAtt);
-    assertTermEquals("ij", filter, termAtt);
-    assertTermEquals("d", filter, termAtt);
-    assertTermEquals("n", filter, termAtt);
-    assertTermEquals("o", filter, termAtt);
-    assertTermEquals("o", filter, termAtt);
-    assertTermEquals("o", filter, termAtt);
-    assertTermEquals("o", filter, termAtt);
-    assertTermEquals("o", filter, termAtt);
-    assertTermEquals("o", filter, termAtt);
-    assertTermEquals("oe", filter, termAtt);
-    assertTermEquals("ss", filter, termAtt);
-    assertTermEquals("th", filter, termAtt);
-    assertTermEquals("u", filter, termAtt);
-    assertTermEquals("u", filter, termAtt);
-    assertTermEquals("u", filter, termAtt);
-    assertTermEquals("u", filter, termAtt);
-    assertTermEquals("y", filter, termAtt);
-    assertTermEquals("y", filter, termAtt);
-    assertTermEquals("fi", filter, termAtt);
-    assertTermEquals("fl", filter, termAtt);
+    assertNextTerms("Des", "Des", filter, termAtt);
+    assertNextTerms("mot", "mot", filter, termAtt);
+    assertNextTerms("clÃ©s", "cles", filter, termAtt);
+    assertNextTerms("?", "A", filter, termAtt);
+    assertNextTerms("LA", "LA", filter, termAtt);
+    assertNextTerms("CHA?NE", "CHAINE", filter, termAtt);
+    assertNextTerms("?", "A", filter, termAtt);
+    assertNextTerms("?", "A", filter, termAtt);
+    assertNextTerms("?", "A", filter, termAtt);
+    assertNextTerms("?", "A", filter, termAtt);
+    assertNextTerms("?", "A", filter, termAtt);
+    assertNextTerms("?", "A", filter, termAtt);
+    assertNextTerms("?", "AE", filter, termAtt);
+    assertNextTerms("?", "C", filter, termAtt);
+    assertNextTerms("?", "E", filter, termAtt);
+    assertNextTerms("?", "E", filter, termAtt);
+    assertNextTerms("?", "E", filter, termAtt);
+    assertNextTerms("?", "E", filter, termAtt);
+    assertNextTerms("?", "I", filter, termAtt);
+    assertNextTerms("?", "I", filter, termAtt);
+    assertNextTerms("?", "I", filter, termAtt);
+    assertNextTerms("?", "I", filter, termAtt);
+    assertNextTerms("Ä²", "IJ", filter, termAtt);
+    assertNextTerms("?", "D", filter, termAtt);
+    assertNextTerms("?", "N", filter, termAtt);
+    assertNextTerms("?", "O", filter, termAtt);
+    assertNextTerms("?", "O", filter, termAtt);
+    assertNextTerms("?", "O", filter, termAtt);
+    assertNextTerms("?", "O", filter, termAtt);
+    assertNextTerms("?", "O", filter, termAtt);
+    assertNextTerms("?", "O", filter, termAtt);
+    assertNextTerms("?", "OE", filter, termAtt);
+    assertNextTerms("?", "TH", filter, termAtt);
+    assertNextTerms("?", "U", filter, termAtt);
+    assertNextTerms("?", "U", filter, termAtt);
+    assertNextTerms("?", "U", filter, termAtt);
+    assertNextTerms("?", "U", filter, termAtt);
+    assertNextTerms("?", "Y", filter, termAtt);
+    assertNextTerms("Å¸", "Y", filter, termAtt);
+    assertNextTerms("?", "a", filter, termAtt);
+    assertNextTerms("Ã¡", "a", filter, termAtt);
+    assertNextTerms("Ã¢", "a", filter, termAtt);
+    assertNextTerms("Ã£", "a", filter, termAtt);
+    assertNextTerms("Ã¤", "a", filter, termAtt);
+    assertNextTerms("Ã¥", "a", filter, termAtt);
+    assertNextTerms("Ã¦", "ae", filter, termAtt);
+    assertNextTerms("Ã§", "c", filter, termAtt);
+    assertNextTerms("Ã¨", "e", filter, termAtt);
+    assertNextTerms("Ã©", "e", filter, termAtt);
+    assertNextTerms("Ãª", "e", filter, termAtt);
+    assertNextTerms("Ã«", "e", filter, termAtt);
+    assertNextTerms("Ã¬", "i", filter, termAtt);
+    assertNextTerms("Ã­", "i", filter, termAtt);
+    assertNextTerms("Ã®", "i", filter, termAtt);
+    assertNextTerms("Ã¯", "i", filter, termAtt);
+    assertNextTerms("Ä³", "ij", filter, termAtt);
+    assertNextTerms("Ã°", "d", filter, termAtt);
+    assertNextTerms("Ã±", "n", filter, termAtt);
+    assertNextTerms("Ã²", "o", filter, termAtt);
+    assertNextTerms("Ã³", "o", filter, termAtt);
+    assertNextTerms("Ã´", "o", filter, termAtt);
+    assertNextTerms("Ãµ", "o", filter, termAtt);
+    assertNextTerms("Ã¶", "o", filter, termAtt);
+    assertNextTerms("Ã¸", "o", filter, termAtt);
+    assertNextTerms("?", "oe", filter, termAtt);
+    assertNextTerms("?", "ss", filter, termAtt);
+    assertNextTerms("Ã¾", "th", filter, termAtt);
+    assertNextTerms("Ã¹", "u", filter, termAtt);
+    assertNextTerms("Ãº", "u", filter, termAtt);
+    assertNextTerms("Ã»", "u", filter, termAtt);
+    assertNextTerms("Ã¼", "u", filter, termAtt);
+    assertNextTerms("Ã½", "y", filter, termAtt);
+    assertNextTerms("Ã¿", "y", filter, termAtt);
+    assertNextTerms("ï¬?", "fi", filter, termAtt);
+    assertNextTerms("ï¬?", "fl", filter, termAtt);
     assertFalse(filter.incrementToken());
   }
 
@@ -1876,7 +1888,8 @@ public class TestASCIIFoldingFilter extends BaseTokenStreamTestCase {
     };
 
     // Construct input text and expected output tokens
-    List<String> expectedOutputTokens = new ArrayList<String>();
+    List<String> expectedUnfoldedTokens = new ArrayList<String>();
+    List<String> expectedFoldedTokens = new ArrayList<String>();
     StringBuilder inputText = new StringBuilder();
     for (int n = 0 ; n < foldings.length ; n += 2) {
       if (n > 0) {
@@ -1884,32 +1897,30 @@ public class TestASCIIFoldingFilter extends BaseTokenStreamTestCase {
       }
       inputText.append(foldings[n]);
 
-      // Construct the expected output token: the ASCII string to fold to,
-      // duplicated as many times as the number of characters in the input text.
+      // Construct the expected output tokens: both the unfolded and folded string,
+      // with the folded duplicated as many times as the number of characters in
+      // the input text.
       StringBuilder expected = new StringBuilder();
       int numChars = foldings[n].length();
       for (int m = 0 ; m < numChars; ++m) {
         expected.append(foldings[n + 1]);
       }
-      expectedOutputTokens.add(expected.toString());
+      expectedUnfoldedTokens.add(foldings[n]);
+      expectedFoldedTokens.add(expected.toString());
     }
 
     TokenStream stream = whitespaceMockTokenizer(inputText.toString());
-    ASCIIFoldingFilter filter = new ASCIIFoldingFilter(stream);
+    ASCIIFoldingFilter filter = new ASCIIFoldingFilter(stream, random().nextBoolean());
     CharTermAttribute termAtt = filter.getAttribute(CharTermAttribute.class);
-    Iterator<String> expectedIter = expectedOutputTokens.iterator();
+    Iterator<String> unfoldedIter = expectedUnfoldedTokens.iterator();
+    Iterator<String> foldedIter = expectedFoldedTokens.iterator();
     filter.reset();
-    while (expectedIter.hasNext()) {
-      assertTermEquals(expectedIter.next(), filter, termAtt);
+    while (foldedIter.hasNext()) {
+      assertNextTerms(unfoldedIter.next(), foldedIter.next(), filter, termAtt);
     }
     assertFalse(filter.incrementToken());
   }
   
-  void assertTermEquals(String expected, TokenStream stream, CharTermAttribute termAtt) throws Exception {
-    assertTrue(stream.incrementToken());
-    assertEquals(expected, termAtt.toString());
-  }
-  
   /** blast some random strings through the analyzer */
   public void testRandomStrings() throws Exception {
     Analyzer a = new Analyzer() {
@@ -1917,7 +1928,8 @@ public class TestASCIIFoldingFilter extends BaseTokenStreamTestCase {
       @Override
       protected TokenStreamComponents createComponents(String fieldName) {
         Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);
-        return new TokenStreamComponents(tokenizer, new ASCIIFoldingFilter(tokenizer));
+        return new TokenStreamComponents(tokenizer,
+          new ASCIIFoldingFilter(tokenizer, random().nextBoolean()));
       } 
     };
     checkRandomData(random(), a, 1000*RANDOM_MULTIPLIER);
@@ -1928,7 +1940,8 @@ public class TestASCIIFoldingFilter extends BaseTokenStreamTestCase {
       @Override
       protected TokenStreamComponents createComponents(String fieldName) {
         Tokenizer tokenizer = new KeywordTokenizer();
-        return new TokenStreamComponents(tokenizer, new ASCIIFoldingFilter(tokenizer));
+        return new TokenStreamComponents(tokenizer,
+          new ASCIIFoldingFilter(tokenizer, random().nextBoolean()));
       }
     };
     checkOneTerm(a, "", "");

