GitDiffStart: 825bc9bdac6a5a7d62ba24f591e5eb4de62e243c | Thu Apr 6 01:40:42 2006 +0000
diff --git a/CHANGES.txt b/CHANGES.txt
index 369d772..7e208f0 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -8,8 +8,9 @@ API Changes
 
  1. All deprecated methods and fields have been removed, except
     DateField, which will still be supported for some time
-    so Lucene can read its date fields from old indexes (Yonik Seeley)
- 
+    so Lucene can read its date fields from old indexes
+    (Yonik Seeley & Grant Ingersoll)
+
 Bug fixes
 
  1. LUCENE-330: Fix issue of FilteredQuery not working properly within
@@ -20,7 +21,7 @@ Bug fixes
 
  3. Added methods to get/set writeLockTimeout and commitLockTimeout in
     IndexWriter. These could be set in Lucene 1.4 using a system property.
-    This feature had been removed without adding the corresponding 
+    This feature had been removed without adding the corresponding
     getter/setter methods.  (Daniel Naber)
 
  4. LUCENE-413: Fixed ArrayIndexOutOfBoundsException exceptions
@@ -29,6 +30,10 @@ Bug fixes
  5. Implemented FilterIndexReader.getVersion() and isCurrent()
     (Yonik Seeley)
 
+ 6. LUCENE-540: Fixed a bug with IndexWriter.addIndexes(Directory[])
+    that sometimes caused the index order of documents to change.
+    (Yonik Seeley)
+
 
 1.9.1
 
diff --git a/src/java/org/apache/lucene/index/IndexWriter.java b/src/java/org/apache/lucene/index/IndexWriter.java
index c2df47e..201eca2 100644
--- a/src/java/org/apache/lucene/index/IndexWriter.java
+++ b/src/java/org/apache/lucene/index/IndexWriter.java
@@ -569,7 +569,7 @@ public class IndexWriter {
     
     // merge newly added segments in log(n) passes
     while (segmentInfos.size() > start+mergeFactor) {
-      for (int base = start+1; base < segmentInfos.size(); base++) {
+      for (int base = start; base < segmentInfos.size(); base++) {
         int end = Math.min(segmentInfos.size(), base+mergeFactor);
         if (end-base > 1)
           mergeSegments(base, end);
@@ -710,9 +710,9 @@ public class IndexWriter {
       infoStream.println(" into "+mergedName+" ("+mergedDocCount+" docs)");
     }
 
-    for (int i = end-1; i >= minSegment; i--)     // remove old infos & add new
+    for (int i = end-1; i > minSegment; i--)     // remove old infos & add new
       segmentInfos.remove(i);
-    segmentInfos.addElement(new SegmentInfo(mergedName, mergedDocCount,
+    segmentInfos.set(minSegment, new SegmentInfo(mergedName, mergedDocCount,
                                             directory));
 
     // close readers before we attempt to delete now-obsolete segments
diff --git a/src/test/org/apache/lucene/index/TestIndexWriterMerging.java b/src/test/org/apache/lucene/index/TestIndexWriterMerging.java
new file mode 100644
index 0000000..85f46f5
--- /dev/null
+++ b/src/test/org/apache/lucene/index/TestIndexWriterMerging.java
@@ -0,0 +1,107 @@
+package org.apache.lucene.index;
+/**
+ * Copyright 2006 The Apache Software Foundation
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.store.RAMDirectory;
+import org.apache.lucene.analysis.standard.StandardAnalyzer;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+import junit.framework.TestCase;
+
+import java.io.IOException;
+
+
+public class TestIndexWriterMerging extends TestCase
+{
+
+  /**
+   * Tests that index merging (specifically addIndexes()) doesn't
+   * change the index order of documents.
+   */
+  public void testLucene() throws IOException
+  {
+
+    int num=100;
+
+    Directory indexA = new RAMDirectory();
+    Directory indexB = new RAMDirectory();
+
+    fillIndex(indexA, 0, num);
+    boolean fail = verifyIndex(indexA, 0);
+    if (fail)
+    {
+      fail("Index a is invalid");
+    }
+
+    fillIndex(indexB, num, num);
+    fail = verifyIndex(indexB, num);
+    if (fail)
+    {
+      fail("Index b is invalid");
+    }
+
+    Directory merged = new RAMDirectory();
+
+    IndexWriter writer = new IndexWriter(merged, new StandardAnalyzer(), true);
+    writer.setMergeFactor(2);
+
+    writer.addIndexes(new Directory[]{indexA, indexB});
+    writer.close();
+    merged.close();
+
+    fail = verifyIndex(merged, 0);
+
+    assertFalse("The merged index is invalid", fail);
+  }
+
+  private boolean verifyIndex(Directory directory, int startAt) throws IOException
+  {
+    boolean fail = false;
+    IndexReader reader = IndexReader.open(directory);
+
+    int max = reader.maxDoc();
+    for (int i = 0; i < max; i++)
+    {
+      Document temp = reader.document(i);
+      //System.out.println("doc "+i+"="+temp.getField("count").stringValue());
+      //compare the index doc number to the value that it should be
+      if (!temp.getField("count").stringValue().equals((i + startAt) + ""))
+      {
+        fail = true;
+        System.out.println("Document " + (i + startAt) + " is returning document " + temp.getField("count").stringValue());
+      }
+    }
+    return fail;
+  }
+
+  private void fillIndex(Directory dir, int start, int numDocs) throws IOException
+  {
+
+    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(), true);
+    writer.setMergeFactor(2);
+    writer.setMaxBufferedDocs(2);
+
+    for (int i = start; i < (start + numDocs); i++)
+    {
+      Document temp = new Document();
+      temp.add(new Field("count", (""+i), Field.Store.YES, Field.Index.UN_TOKENIZED));
+
+      writer.addDocument(temp);
+    }
+    writer.close();
+  }
+}

