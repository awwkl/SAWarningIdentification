GitDiffStart: 83fa975ae984511c53b68c153655ad7a6a23e807 | Wed Feb 20 20:53:46 2013 +0000
diff --git a/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseIterationMarkCharFilter.java b/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseIterationMarkCharFilter.java
index 7a14d52..79da29f 100644
--- a/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseIterationMarkCharFilter.java
+++ b/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseIterationMarkCharFilter.java
@@ -39,7 +39,7 @@ import java.io.Reader;
  * <p>
  * The implementation buffers input until a full stop punctuation character (U+3002)
  * or EOF is reached in order to not keep a copy of the character stream in memory.
- * Vertical iteration marks, which are even rarer than horizonal iteration marks in
+ * Vertical iteration marks, which are even rarer than horizontal iteration marks in
  * contemporary Japanese, are unsupported.
  * </p>
  */
diff --git a/lucene/analysis/stempel/src/java/org/egothor/stemmer/MultiTrie.java b/lucene/analysis/stempel/src/java/org/egothor/stemmer/MultiTrie.java
index 35fe110..e2e9173 100644
--- a/lucene/analysis/stempel/src/java/org/egothor/stemmer/MultiTrie.java
+++ b/lucene/analysis/stempel/src/java/org/egothor/stemmer/MultiTrie.java
@@ -63,7 +63,7 @@ import java.util.List;
 
 /**
  * The MultiTrie is a Trie of Tries. It stores words and their associated patch
- * commands. The MultiTrie handles patch commmands individually (each command by
+ * commands. The MultiTrie handles patch commands individually (each command by
  * itself).
  */
 public class MultiTrie extends Trie {
diff --git a/lucene/analysis/stempel/src/java/org/egothor/stemmer/MultiTrie2.java b/lucene/analysis/stempel/src/java/org/egothor/stemmer/MultiTrie2.java
index 15571dc..be9faa2 100644
--- a/lucene/analysis/stempel/src/java/org/egothor/stemmer/MultiTrie2.java
+++ b/lucene/analysis/stempel/src/java/org/egothor/stemmer/MultiTrie2.java
@@ -64,7 +64,7 @@ import java.util.List;
  * The MultiTrie is a Trie of Tries.
  * <p>
  * It stores words and their associated patch commands. The MultiTrie handles
- * patch commmands broken into their constituent parts, as a MultiTrie does, but
+ * patch commands broken into their constituent parts, as a MultiTrie does, but
  * the commands are delimited by the skip command.
  */
 public class MultiTrie2 extends MultiTrie {
diff --git a/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/package.html b/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/package.html
index 783e561..b849cec 100644
--- a/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/package.html
+++ b/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/package.html
@@ -53,7 +53,7 @@ Contained packages:
  </tr>
  <tr>
    <td><a href="programmatic/package-summary.html">programmatic</a></td>
-   <td>Sample performance test written programatically.</td>
+   <td>Sample performance test written programmatically.</td>
  </tr>
 </table>
 
@@ -102,7 +102,7 @@ Easiest way to run a benchmarks is using the predefined ant task:
  </li>
  <li>java org.apache.lucene.benchmark.byTask.programmatic.Sample
      <br>- would run a performance test programmatically - without using an alg
-     file. This is less readable, and less convinient, but possible.
+     file. This is less readable, and less convenient, but possible.
  </li>
 </ul>
 </p>
@@ -118,7 +118,7 @@ Each benchmark run has a DocMaker and a QueryMaker. These two should usually
 match, so that "meaningful" queries are used for a certain collection.
 Properties set at the header of the alg file define which "makers" should be
 used. You can also specify your own makers, extending DocMaker and implementing
-QureyMaker.
+QueryMaker.
 	<blockquote>
 		<b>Note:</b> since 2.9, DocMaker is a concrete class which accepts a 
 		ContentSource. In most cases, you can use the DocMaker class to create 
@@ -228,7 +228,7 @@ The following is an informal description of the supported syntax.
  a number to repeat exhaustively.
  This is sometimes useful, for adding as many files as a doc maker can create,
  without iterating over the same file again, especially when the exact
- number of documents is not known in advance. For insance, TREC files extracted
+ number of documents is not known in advance. For instance, TREC files extracted
  from a zip file. Note: when using this, you must also set
  <font color="#FF0066">doc.maker.forever</font> to false.
  <br>Example -  <font color="#FF0066">{ AddDoc } : *</font>  - would add docs
@@ -271,7 +271,7 @@ The following is an informal description of the supported syntax.
  which is faster, adding
  many smaller documents, or few larger documents.
  Next candidates for supporting a parameter may be the Search tasks,
- for controlling the qurey size.
+ for controlling the query size.
  </li>
  <li>
  <b>Statistic recording elimination</b>: - a sequence can also end with
@@ -294,7 +294,7 @@ The following is an informal description of the supported syntax.
  This would specify repetition of N with rate of R operations/sec.
  Use '<font color="#FF0066">R/sec</font>' or
  '<font color="#FF0066">R/min</font>'
- to explicitely specify that the rate is per second or per minute.
+ to explicitly specify that the rate is per second or per minute.
  The default is per second,
  <br>Example -  <font color="#FF0066">[ AddDoc ] : 400 : 3</font> - would do 400
  addDoc in parallel, starting up to 3 threads per second.
@@ -412,7 +412,7 @@ regular index/search work tasks, report tasks, and control tasks.
      or makeQuery() creates the next document or query
      that it "knows" to create.
      If that pool is "exhausted", the "maker" start over again.
-     The resetInpus command
+     The ResetInputs command
      therefore allows to make the rounds comparable.
      It is therefore useful to invoke ResetInputs together with NewRound.
      </li>
@@ -475,7 +475,7 @@ regular index/search work tasks, report tasks, and control tasks.
 	 <li>
 	 <font color="#FF0066">WriteLineDoc</font> prepares a 'line'
 	 file where each line holds a document with <i>title</i>, 
-	 <i>date</i> and <i>body</i> elements, seperated by [TAB].
+	 <i>date</i> and <i>body</i> elements, separated by [TAB].
 	 A line file is useful if one wants to measure pure indexing
 	 performance, without the overhead of parsing the data.<br>
 	 You can use LineDocSource as a ContentSource over a 'line'
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/bloom/FuzzySet.java b/lucene/codecs/src/java/org/apache/lucene/codecs/bloom/FuzzySet.java
index 4297315..835365b 100644
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/bloom/FuzzySet.java
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/bloom/FuzzySet.java
@@ -243,7 +243,7 @@ public class FuzzySet {
   /**
    * 
    * @param targetMaxSaturation A number between 0 and 1 describing the % of bits that would ideally be set in the 
-   * result. Lower values have better qccuracy but require more space.
+   * result. Lower values have better accuracy but require more space.
    * @return a smaller FuzzySet or null if the current set is already over-saturated
    */
   public FuzzySet downsize(float targetMaxSaturation)
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/package.html b/lucene/core/src/java/org/apache/lucene/analysis/package.html
index 9f835eb..4c68b8d 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/package.html
+++ b/lucene/core/src/java/org/apache/lucene/analysis/package.html
@@ -562,7 +562,7 @@ public final class LengthFilter extends FilteringTokenFilter {
   CharTermAttribute, the length of the term can be determined and tokens that
   are either too short or too long are skipped.  Note how
   <code>accept()</code> can efficiently access the instance variable; no 
-  attribute lookup is neccessary. The same is true for the consumer, which can
+  attribute lookup is necessary. The same is true for the consumer, which can
   simply use local references to the Attributes.
 </p>
 <p>
@@ -791,7 +791,7 @@ API: Noun
 </pre>
 Each word is now followed by its assigned PartOfSpeech tag. Of course this is a naive 
 part-of-speech tagging. The word 'This' should not even be tagged as noun; it is only spelled capitalized because it
-is the first word of a sentence. Actually this is a good opportunity for an excerise. To practice the usage of the new
+is the first word of a sentence. Actually this is a good opportunity for an exercise. To practice the usage of the new
 API the reader could now write an Attribute and TokenFilter that can specify for each word if it was the first token
 of a sentence or not. Then the PartOfSpeechTaggingFilter can make use of this knowledge and only tag capitalized words
 as nouns if not the first word of a sentence (we know, this is still not a correct behavior, but hey, it's a good exercise). 
diff --git a/lucene/core/src/java/org/apache/lucene/index/LogMergePolicy.java b/lucene/core/src/java/org/apache/lucene/index/LogMergePolicy.java
index 5918946..a3c954a 100644
--- a/lucene/core/src/java/org/apache/lucene/index/LogMergePolicy.java
+++ b/lucene/core/src/java/org/apache/lucene/index/LogMergePolicy.java
@@ -96,7 +96,7 @@ public abstract class LogMergePolicy extends MergePolicy {
    *  will never be merged. */
   protected int maxMergeDocs = DEFAULT_MAX_MERGE_DOCS;
 
-  /** If the size of the merge segment exceesd this ratio of
+  /** If the size of the merge segment exceeds this ratio of
    *  the total index size then it will remain in
    *  non-compound format even if {@link
    *  #setUseCompoundFile} is {@code true}. */
@@ -420,7 +420,7 @@ public abstract class LogMergePolicy extends MergePolicy {
     }
 
     // If the segments are already merged (e.g. there's only 1 segment), or
-    // there are <maxNumSegements:.
+    // there are <maxNumSegments:.
     if (isMerged(infos, maxNumSegments, segmentsToMerge)) {
       if (verbose()) {
         message("already merged; skip");
diff --git a/lucene/core/src/java/org/apache/lucene/search/TimeLimitingCollector.java b/lucene/core/src/java/org/apache/lucene/search/TimeLimitingCollector.java
index b671b01..2d2eb0e 100644
--- a/lucene/core/src/java/org/apache/lucene/search/TimeLimitingCollector.java
+++ b/lucene/core/src/java/org/apache/lucene/search/TimeLimitingCollector.java
@@ -104,7 +104,7 @@ public class TimeLimitingCollector extends Collector {
   
   /**
    * Syntactic sugar for {@link #setBaseline(long)} using {@link Counter#get()}
-   * on the clock passed to the construcutor.
+   * on the clock passed to the constructor.
    */
   public void setBaseline() {
     setBaseline(clock.get());
diff --git a/lucene/core/src/java/org/apache/lucene/store/BufferedIndexInput.java b/lucene/core/src/java/org/apache/lucene/store/BufferedIndexInput.java
index ceb9131..56c88ce 100644
--- a/lucene/core/src/java/org/apache/lucene/store/BufferedIndexInput.java
+++ b/lucene/core/src/java/org/apache/lucene/store/BufferedIndexInput.java
@@ -318,7 +318,7 @@ public abstract class BufferedIndexInput extends IndexInput {
   }
 
   /**
-   * Flushes the in-memory bufer to the given output, copying at most
+   * Flushes the in-memory buffer to the given output, copying at most
    * <code>numBytes</code>.
    * <p>
    * <b>NOTE:</b> this method does not refill the buffer, however it does
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/writercache/lru/NameHashIntCacheLRU.java b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/writercache/lru/NameHashIntCacheLRU.java
index 43e0704..8a61b0b 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/writercache/lru/NameHashIntCacheLRU.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/writercache/lru/NameHashIntCacheLRU.java
@@ -23,7 +23,7 @@ import org.apache.lucene.facet.taxonomy.CategoryPath;
  * An an LRU cache of mapping from name to int.
  * Used to cache Ordinals of category paths.
  * It uses as key, hash of the path instead of the path.
- * This way the cahce takes less RAM, but correctness depends on
+ * This way the cache takes less RAM, but correctness depends on
  * assuming no collisions. 
  * 
  * @lucene.experimental
diff --git a/lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java b/lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java
index 1760023..1c7a341 100644
--- a/lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java
+++ b/lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java
@@ -1197,7 +1197,7 @@ public class HighlighterTest extends BaseTokenStreamTestCase implements Formatte
 
         Highlighter highlighter = getHighlighter(query, null, HighlighterTest.this);
 
-        // Get 3 best fragments and seperate with a "..."
+        // Get 3 best fragments and separate with a "..."
         TokenStream tokenStream = analyzer.tokenStream(null, new StringReader(s));
 
         String result = highlighter.getBestFragments(tokenStream, s, 3, "...");
diff --git a/lucene/misc/src/test/org/apache/lucene/misc/SweetSpotSimilarityTest.java b/lucene/misc/src/test/org/apache/lucene/misc/SweetSpotSimilarityTest.java
index 8bf68ff..f238ba7 100644
--- a/lucene/misc/src/test/org/apache/lucene/misc/SweetSpotSimilarityTest.java
+++ b/lucene/misc/src/test/org/apache/lucene/misc/SweetSpotSimilarityTest.java
@@ -83,7 +83,7 @@ public class SweetSpotSimilarityTest extends LuceneTestCase {
     }
 
 
-    // seperate sweet spot for certain fields
+    // separate sweet spot for certain fields
 
     final SweetSpotSimilarity ssBar = new SweetSpotSimilarity();
     ssBar.setLengthNormFactors(8,13, 0.5f, false);
diff --git a/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/processors/BooleanQuery2ModifierNodeProcessor.java b/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/processors/BooleanQuery2ModifierNodeProcessor.java
index ae762cd..7f4d727 100644
--- a/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/processors/BooleanQuery2ModifierNodeProcessor.java
+++ b/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/processors/BooleanQuery2ModifierNodeProcessor.java
@@ -55,7 +55,7 @@ import org.apache.lucene.queryparser.flexible.standard.parser.StandardSyntaxPars
  * {@link Operator#AND}, if it is, the same operation when an
  * {@link AndQueryNode} is found is applied to it. Each {@link BooleanQueryNode}
  * which direct parent is also a {@link BooleanQueryNode} is removed (to ignore
- * the rules of precidence).
+ * the rules of precedence).
  * </p>
  * 
  * @see ConfigurationKeys#DEFAULT_OPERATOR
diff --git a/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest.java b/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest.java
index f39bb5c..ab41b5d 100644
--- a/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest.java
+++ b/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest.java
@@ -430,7 +430,7 @@ public class AnalyzingSuggesterTest extends LuceneTestCase {
     }
   }
   
-  // Holds surface form seperately:
+  // Holds surface form separately:
   private static class TermFreq2 implements Comparable<TermFreq2> {
     public final String surfaceForm;
     public final String analyzedForm;
diff --git a/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest.java b/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest.java
index d7e79e1..7e2ef95 100644
--- a/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest.java
+++ b/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest.java
@@ -466,7 +466,7 @@ public class FuzzySuggesterTest extends LuceneTestCase {
     }
   }
   
-  // Holds surface form seperately:
+  // Holds surface form separately:
   private static class TermFreq2 implements Comparable<TermFreq2> {
     public final String surfaceForm;
     public final String analyzedForm;
diff --git a/lucene/tools/junit4/tests.policy b/lucene/tools/junit4/tests.policy
index 545987d..d17d3c5 100644
--- a/lucene/tools/junit4/tests.policy
+++ b/lucene/tools/junit4/tests.policy
@@ -48,7 +48,7 @@ grant {
   permission java.lang.reflect.ReflectPermission "*";
   permission java.lang.RuntimePermission "*";
 
-  // These two *have* to be spelled out a seperate
+  // These two *have* to be spelled out a separate
   permission java.lang.management.ManagementPermission "control";
   permission java.lang.management.ManagementPermission "monitor";
 
diff --git a/solr/CHANGES.txt b/solr/CHANGES.txt
index af98897..df3f8e2 100644
--- a/solr/CHANGES.txt
+++ b/solr/CHANGES.txt
@@ -990,7 +990,7 @@ Bug Fixes
   or SolrIndexWriter initialization. (hossman)
 
 * SOLR-3518: Include final 'hits' in log information when aggregating a 
-  distibuted request (Markus Jelsma via hossman)
+  distributed request (Markus Jelsma via hossman)
 
 * SOLR-3628: SolrInputField and SolrInputDocument are now consistently backed 
   by Collections passed in to setValue/setField, and defensively copy values 
@@ -1083,7 +1083,7 @@ Bug Fixes
   (James Dyer)
 
 * SOLR-3087: Fixed DOMUtil so that code doing attribute validation will 
-  automaticly ignore nodes in the resserved "xml" prefix - in particular this 
+  automatically ignore nodes in the reserved "xml" prefix - in particular this
   fixes some bugs related to xinclude and fieldTypes.
   (Amit Nithian, hossman)
 
@@ -1114,7 +1114,7 @@ Bug Fixes
 Other Changes
 ----------------------
 
-* SOLR-3690: Fixed binary release packages to include dependencie needed for 
+* SOLR-3690: Fixed binary release packages to include dependencies needed for
   the solr-test-framework (hossman)
 
 * SOLR-2857: The /update/json and /update/csv URLs were restored to aid
@@ -1145,7 +1145,7 @@ Other Changes
   replicas before running the leader process - or if they all do not come up, 
   N amount of time. (Jan Høydahl, Per Steffensen, Mark Miller)
 
-* SOLR-3750: Optionaly, on session expiration, we can explicitly wait some time before 
+* SOLR-3750: Optionally, on session expiration, we can explicitly wait some time before
   running the leader sync process so that we are sure every node participates.
   (Per Steffensen, Mark Miller)
 
@@ -1329,7 +1329,7 @@ Bug Fixes
   For the example configuration, this means /browse now works with SolrCloud.
   (janhoy, ehatcher)
 
-* SOLR-3677: Fixed missleading error message in web ui to distinguish between 
+* SOLR-3677: Fixed misleading error message in web ui to distinguish between
   no SolrCores loaded vs. no /admin/ handler available.
   (hossman, steffkes)
   
@@ -1547,7 +1547,7 @@ New Features
   
 * SOLR-1298: Return FunctionQuery as pseudo field.  The solr 'fl' param
   now supports functions.  For example:  fl=id,sum(x,y) -- NOTE: only
-  functions with fast random access are reccomended. (yonik, ryan)
+  functions with fast random access are recommended. (yonik, ryan)
   
 * SOLR-705: Optionally return shard info with each document in distributed
   search.  Use fl=id,[shard]  to return the shard url.  (ryan)  
@@ -1657,7 +1657,7 @@ New Features
   chain. Serialization format is pluggable, and defaults to JSON. (ab)
 
 * SOLR-3363: Consolidated Exceptions in Analysis Factories so they only throw 
-  InitalizationExceptions (Chris Male)
+  InitializationExceptions (Chris Male)
 
 * SOLR-2690: New support for a "TZ" request param which overrides the TimeZone 
   used when rounding Dates in DateMath expressions for the entire request 
@@ -1851,7 +1851,7 @@ Bug Fixes
   (James Dyer, Tomás Fernández Löbbe)
 
 * SOLR-2605: fixed tracking of the 'defaultCoreName' in CoreContainer so that
-  CoreAdminHandler could return consistent information regardless of wether
+  CoreAdminHandler could return consistent information regardless of whether
   there is a a default core name or not. (steffkes, hossman)
 
 * SOLR-3370: fixed CSVResponseWriter to respect globs in the 'fl' param
@@ -1881,7 +1881,7 @@ Bug Fixes
 
 * SOLR-3522: fixed parsing of the 'literal()' function (hossman)
 
-* SOLR-3548: Fixed a bug in the cachability of queries using the {!join} 
+* SOLR-3548: Fixed a bug in the cachability of queries using the {!join}
   parser or the strdist() function, as well as some minor improvements to 
   the hashCode implementation of {!bbox} and {!geofilt} queries.
   (hossman)
@@ -1917,7 +1917,7 @@ Other Changes
   more spread out (Erick Erickson via hossman)
 
 * SOLR-2288: Small tweaks to eliminate compiler warnings.  primarily
-  using Generics where applicable in method/object declatations, and
+  using Generics where applicable in method/object declarations, and
   adding @SuppressWarnings("unchecked") when appropriate (hossman)
 
 * SOLR-2375: Suggester Lookup implementations now store trie data
@@ -1990,7 +1990,7 @@ Other Changes
   (ehatcher)
   
 * SOLR-3032: logOnce from SolrException logOnce and all the supporting
-  structure is gone. abortOnConfugrationError is also gone as it is no longer referenced.
+  structure is gone. abortOnConfigurationError is also gone as it is no longer referenced.
   Errors should be caught and logged at the top-most level or logged and NOT propagated up the 
   chain. (Erick Erickson)
 
diff --git a/solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/XPathRecordReader.java b/solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/XPathRecordReader.java
index 2df46b4..e5c808d 100644
--- a/solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/XPathRecordReader.java
+++ b/solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/XPathRecordReader.java
@@ -71,9 +71,9 @@ public class XPathRecordReader {
   public static final int FLATTEN = 1;
 
   /**
-   * A constructor called with a '|' seperated list of Xpath expressions
+   * A constructor called with a '|' separated list of Xpath expressions
    * which define sub sections of the XML stream that are to be emitted as
-   * seperate records.
+   * separate records.
    * 
    * @param forEachXpath  The XPATH for which a record is emitted. Once the
    * xpath tag is encountered, the Node.parse method starts collecting wanted 
diff --git a/solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler.java b/solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler.java
index 27f0e1e..fe15354 100644
--- a/solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler.java
+++ b/solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler.java
@@ -302,7 +302,7 @@ public class HttpShardHandler extends ShardHandler {
         String collections = params.get("collection");
         if (collections != null) {
           // If there were one or more collections specified in the query, split
-          // each parameter and store as a seperate member of a List.
+          // each parameter and store as a separate member of a List.
           List<String> collectionList = StrUtils.splitSmart(collections, ",",
               true);
           // In turn, retrieve the slices that cover each collection from the
diff --git a/solr/core/src/java/org/apache/solr/update/DocumentBuilder.java b/solr/core/src/java/org/apache/solr/update/DocumentBuilder.java
index 6ce5c9e..a6fd10c 100644
--- a/solr/core/src/java/org/apache/solr/update/DocumentBuilder.java
+++ b/solr/core/src/java/org/apache/solr/update/DocumentBuilder.java
@@ -275,7 +275,7 @@ public class DocumentBuilder {
 
             // we can't copy any boost unless the dest field is 
             // indexed & !omitNorms, but which boost we copy depends
-            // on wether the dest field already contains values (we 
+            // on whether the dest field already contains values (we
             // don't want to apply the compounded docBoost more then once)
             final float destBoost = 
               (destinationField.indexed() && !destinationField.omitNorms()) ?
diff --git a/solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor.java b/solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor.java
index be8fe32..e96ed77 100644
--- a/solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor.java
+++ b/solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor.java
@@ -1180,7 +1180,7 @@ public class DistributedUpdateProcessor extends UpdateRequestProcessor {
   }
 
   /**
-   * Returns a boolean indicating wether or not the caller should behave as 
+   * Returns a boolean indicating whether or not the caller should behave as
    * if this is the "leader" even when ZooKeeper is not enabled.  
    * (Even in non zk mode, tests may simulate updates to/from a leader)
    */
diff --git a/solr/core/src/java/org/apache/solr/util/DOMUtil.java b/solr/core/src/java/org/apache/solr/util/DOMUtil.java
index e09500a..e304e1b 100644
--- a/solr/core/src/java/org/apache/solr/util/DOMUtil.java
+++ b/solr/core/src/java/org/apache/solr/util/DOMUtil.java
@@ -42,7 +42,7 @@ public class DOMUtil {
     outer: for (int j=0; j<attrs.getLength(); j++) {
       Node attr = attrs.item(j);
 
-      // automaticly exclude things in the xml namespace, ie: xml:base
+      // automatically exclude things in the xml namespace, ie: xml:base
       if (XML_RESERVED_PREFIX.equals(attr.getPrefix())) continue outer;
 
       String attrName = attr.getNodeName();
@@ -234,7 +234,7 @@ public class DOMUtil {
          according to the DOM Level-3 Core documentation - which
          specifies that the Attr's children should have their
          textContent concated (Attr's can have a single child which
-         is either Text node or an EntityRefrence).  In practice,
+         is either Text node or an EntityReference).  In practice,
          DOM implementations do not seem to use child nodes of
          Attributes, storing the "text" directly as the nodeValue.
          Fortunately, the DOM Spec indicates that when Attr.nodeValue
diff --git a/solr/core/src/java/org/apache/solr/util/doc-files/min-should-match.html b/solr/core/src/java/org/apache/solr/util/doc-files/min-should-match.html
index a5287b6..d8039b3 100644
--- a/solr/core/src/java/org/apache/solr/util/doc-files/min-should-match.html
+++ b/solr/core/src/java/org/apache/solr/util/doc-files/min-should-match.html
@@ -30,7 +30,7 @@ DisMaxRequestHandler.
 </blockquote>
 
 
-<h2>Explaination of Concept: "Min Number Should Match"</h2>
+<h2>Explanation of Concept: "Min Number Should Match"</h2>
 <div>
 :TODO:
 </div>
@@ -55,7 +55,7 @@ DisMaxRequestHandler.
 
  <dt><code>75%</code></dt>
  <dd>A percentage, indicating that this percent of the total number of
-     optional clauses are neccessary.  The number computed from the
+     optional clauses are necessary.  The number computed from the
      percentage is rounded down and used as the minimum.
  </dd>
 
@@ -71,17 +71,17 @@ DisMaxRequestHandler.
      by any of the previously mentioned specifiers is a conditional
      specification.  It indicates that if the number of optional clauses is
      equal to (or less than) the integer, they are all required, but
-     if it's greater then the integer, the specification applies.
+     if it's greater than the integer, the specification applies.
      In this example: if there are 1 to 3 clauses they are all required,
      but for 4 or more clauses only 90% are required.
  </dd>
 
  <dt><code>2&lt;-25% 9&lt;-3</code></dt>
- <dd>Multiple conditional specifications can be seperated by spaces,
-     each one only being valid for numbers greater then the one before it.
+ <dd>Multiple conditional specifications can be separated by spaces,
+     each one only being valid for numbers greater than the one before it.
      In this example: if there are 1 or 2 clauses both are required,
-     if there are 3-9 clauses all but 25% are requred, and if there
-     are more then 9 clauses, all but three are required.
+     if there are 3-9 clauses all but 25% are required, and if there
+     are more than 9 clauses, all but three are required.
  </dd>
 </dl>
 
@@ -104,10 +104,10 @@ DisMaxRequestHandler.
  </li>
  <li>
  No matter what number the calculation arrives at,
- a value greater then the number of optional clauses, or a value less then
+ a value greater than the number of optional clauses, or a value less than
  1 will never be used.  (ie: no matter how low or how high the result of the
  calculation result is, the minimum number of required matches will never
- be lower then 1 or greatered then the number of clauses.
+ be lower than 1 or greater than the number of clauses.
  </li>
 </ul>
 
diff --git a/solr/example/etc/create-solrtest.keystore.sh b/solr/example/etc/create-solrtest.keystore.sh
index 902a996..d3decee 100755
--- a/solr/example/etc/create-solrtest.keystore.sh
+++ b/solr/example/etc/create-solrtest.keystore.sh
@@ -20,8 +20,8 @@
 # This script shows how the solrtest.keystore file used for solr tests 
 # and these example configs was generated.
 #
-# Running this script should only be neccessary if the keystore file
-# needs to be replaced, which shouldn't be required until sometime arround
+# Running this script should only be necessary if the keystore file
+# needs to be replaced, which shouldn't be required until sometime around
 # the year 4751.
 #
 # NOTE: the "-ext" option used in the "keytool" command requires that you have
diff --git a/solr/example/solr/collection1/conf/solrconfig.xml b/solr/example/solr/collection1/conf/solrconfig.xml
index 70f08fd..f0bccb2 100755
--- a/solr/example/solr/collection1/conf/solrconfig.xml
+++ b/solr/example/solr/collection1/conf/solrconfig.xml
@@ -323,7 +323,7 @@
                    commit before automatically triggering a new commit.
 
          maxTime - Maximum amount of time in ms that is allowed to pass
-                   since a document was added before automaticly
+                   since a document was added before automatically
                    triggering a new commit. 
          openSearcher - if false, the commit causes recent index changes
            to be flushed to stable storage, but does not cause a new
@@ -1123,7 +1123,7 @@
 
        http://wiki.apache.org/solr/SolrReplication 
 
-       It is also neccessary for SolrCloud to function (in Cloud mode, the 
+       It is also necessary for SolrCloud to function (in Cloud mode, the
        replication handler is used to bulk transfer segments when nodes 
        are added or need to recover).
 
@@ -1132,7 +1132,7 @@
   <requestHandler name="/replication" class="solr.ReplicationHandler" > 
     <!--
        To enable simple master/slave replication, uncomment one of the 
-       sections below, depending on wether this solr instance should be 
+       sections below, depending on whether this solr instance should be
        the "master" or a "slave".  If this instance is a "slave" you will 
        also need to fill in the masterUrl to point to a real machine.
     -->
diff --git a/solr/test-framework/src/java/org/apache/solr/SolrTestCaseJ4.java b/solr/test-framework/src/java/org/apache/solr/SolrTestCaseJ4.java
index d436e6b..050b475 100755
--- a/solr/test-framework/src/java/org/apache/solr/SolrTestCaseJ4.java
+++ b/solr/test-framework/src/java/org/apache/solr/SolrTestCaseJ4.java
@@ -544,7 +544,7 @@ public abstract class SolrTestCaseJ4 extends LuceneTestCase {
   }
 
   /**
-   * Validates a query matches some JSON test expressions using the default double delta tollerance.
+   * Validates a query matches some JSON test expressions using the default double delta tolerance.
    * @see JSONTestUtil#DEFAULT_DELTA
    * @see #assertJQ(SolrQueryRequest,double,String...)
    */
@@ -698,7 +698,7 @@ public abstract class SolrTestCaseJ4 extends LuceneTestCase {
     try {
       StringWriter r = new StringWriter();
 
-      // this is anoying
+      // this is annoying
       if (null == args || 0 == args.length) {
         r.write("<add>");
         r.write(doc.xml);
@@ -795,7 +795,7 @@ public abstract class SolrTestCaseJ4 extends LuceneTestCase {
     return new LocalSolrQueryRequest(h.getCore(), mp);
   }
 
-  /** Neccessary to make method signatures un-ambiguous */
+  /** Necessary to make method signatures un-ambiguous */
   public static class XmlDoc {
     public String xml;
     @Override

