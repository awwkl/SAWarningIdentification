GitDiffStart: 614af8799c143ed2f0ee88a67ddb2f5c57672885 | Wed Nov 27 17:32:42 2013 +0000
diff --git a/lucene/core/src/java/org/apache/lucene/search/IndexSearcher.java b/lucene/core/src/java/org/apache/lucene/search/IndexSearcher.java
index 90310e8..266a26e 100644
--- a/lucene/core/src/java/org/apache/lucene/search/IndexSearcher.java
+++ b/lucene/core/src/java/org/apache/lucene/search/IndexSearcher.java
@@ -431,7 +431,7 @@ public class IndexSearcher {
       limit = 1;
     }
     if (after != null && after.doc >= limit) {
-      throw new IllegalArgumentException("after.doc exceeds the number of documents in that reader: after.doc="
+      throw new IllegalArgumentException("after.doc exceeds the number of documents in the reader: after.doc="
           + after.doc + " limit=" + limit);
     }
     nDocs = Math.min(nDocs, limit);
diff --git a/lucene/demo/src/java/org/apache/lucene/demo/facet/AssociationsFacetsExample.java b/lucene/demo/src/java/org/apache/lucene/demo/facet/AssociationsFacetsExample.java
index adb55d6..27664ea 100644
--- a/lucene/demo/src/java/org/apache/lucene/demo/facet/AssociationsFacetsExample.java
+++ b/lucene/demo/src/java/org/apache/lucene/demo/facet/AssociationsFacetsExample.java
@@ -104,16 +104,15 @@ public class AssociationsFacetsExample {
     TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoDir);
     FacetsConfig config = getConfig(null);
     
-    FacetsCollector sfc = new FacetsCollector();
+    FacetsCollector fc = new FacetsCollector();
     
     // MatchAllDocsQuery is for "browsing" (counts facets
     // for all non-deleted docs in the index); normally
-    // you'd use a "normal" query, and use MultiCollector to
-    // wrap collecting the "normal" hits and also facets:
-    searcher.search(new MatchAllDocsQuery(), sfc);
+    // you'd use a "normal" query:
+    Facets.search(searcher, new MatchAllDocsQuery(), 10, fc);
     
-    Facets tags = new TaxonomyFacetSumIntAssociations("$tags", taxoReader, config, sfc);
-    Facets genre = new TaxonomyFacetSumFloatAssociations("$genre", taxoReader, config, sfc);
+    Facets tags = new TaxonomyFacetSumIntAssociations("$tags", taxoReader, config, fc);
+    Facets genre = new TaxonomyFacetSumFloatAssociations("$genre", taxoReader, config, fc);
 
     // Retrieve results
     List<FacetResult> results = new ArrayList<FacetResult>();
diff --git a/lucene/demo/src/java/org/apache/lucene/demo/facet/ExpressionAggregationFacetsExample.java b/lucene/demo/src/java/org/apache/lucene/demo/facet/ExpressionAggregationFacetsExample.java
index 04f3b8c..6062e4d 100644
--- a/lucene/demo/src/java/org/apache/lucene/demo/facet/ExpressionAggregationFacetsExample.java
+++ b/lucene/demo/src/java/org/apache/lucene/demo/facet/ExpressionAggregationFacetsExample.java
@@ -100,16 +100,15 @@ public class ExpressionAggregationFacetsExample {
     bindings.add(new SortField("popularity", SortField.Type.LONG)); // the value of the 'popularity' field
 
     // Aggregates the facet values
-    FacetsCollector sfc = new FacetsCollector(true);
+    FacetsCollector fc = new FacetsCollector(true);
 
     // MatchAllDocsQuery is for "browsing" (counts facets
     // for all non-deleted docs in the index); normally
-    // you'd use a "normal" query, and use MultiCollector to
-    // wrap collecting the "normal" hits and also facets:
-    searcher.search(new MatchAllDocsQuery(), sfc);
+    // you'd use a "normal" query:
+    Facets.search(searcher, new MatchAllDocsQuery(), 10, fc);
 
     // Retrieve results
-    Facets facets = new TaxonomyFacetSumValueSource(taxoReader, config, sfc, expr.getValueSource(bindings));
+    Facets facets = new TaxonomyFacetSumValueSource(taxoReader, config, fc, expr.getValueSource(bindings));
     FacetResult result = facets.getTopChildren(10, "A");
     
     indexReader.close();
diff --git a/lucene/demo/src/java/org/apache/lucene/demo/facet/MultiCategoryListsFacetsExample.java b/lucene/demo/src/java/org/apache/lucene/demo/facet/MultiCategoryListsFacetsExample.java
index 32e98b8..1ec6ffb 100644
--- a/lucene/demo/src/java/org/apache/lucene/demo/facet/MultiCategoryListsFacetsExample.java
+++ b/lucene/demo/src/java/org/apache/lucene/demo/facet/MultiCategoryListsFacetsExample.java
@@ -109,22 +109,21 @@ public class MultiCategoryListsFacetsExample {
     TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoDir);
     FacetsConfig config = getConfig(null);
 
-    FacetsCollector sfc = new FacetsCollector();
+    FacetsCollector fc = new FacetsCollector();
 
     // MatchAllDocsQuery is for "browsing" (counts facets
     // for all non-deleted docs in the index); normally
-    // you'd use a "normal" query, and use MultiCollector to
-    // wrap collecting the "normal" hits and also facets:
-    searcher.search(new MatchAllDocsQuery(), sfc);
+    // you'd use a "normal" query:
+    Facets.search(searcher, new MatchAllDocsQuery(), 10, fc);
 
     // Retrieve results
     List<FacetResult> results = new ArrayList<FacetResult>();
 
     // Count both "Publish Date" and "Author" dimensions
-    Facets author = new FastTaxonomyFacetCounts("author", taxoReader, config, sfc);
+    Facets author = new FastTaxonomyFacetCounts("author", taxoReader, config, fc);
     results.add(author.getTopChildren(10, "Author"));
 
-    Facets pubDate = new FastTaxonomyFacetCounts("pubdate", taxoReader, config, sfc);
+    Facets pubDate = new FastTaxonomyFacetCounts("pubdate", taxoReader, config, fc);
     results.add(pubDate.getTopChildren(10, "Publish Date"));
     
     indexReader.close();
diff --git a/lucene/demo/src/java/org/apache/lucene/demo/facet/RangeFacetsExample.java b/lucene/demo/src/java/org/apache/lucene/demo/facet/RangeFacetsExample.java
index 7108281..606d9da 100644
--- a/lucene/demo/src/java/org/apache/lucene/demo/facet/RangeFacetsExample.java
+++ b/lucene/demo/src/java/org/apache/lucene/demo/facet/RangeFacetsExample.java
@@ -89,15 +89,14 @@ public class RangeFacetsExample implements Closeable {
   public FacetResult search() throws IOException {
 
     // Aggregates the facet counts
-    FacetsCollector sfc = new FacetsCollector();
+    FacetsCollector fc = new FacetsCollector();
 
     // MatchAllDocsQuery is for "browsing" (counts facets
     // for all non-deleted docs in the index); normally
-    // you'd use a "normal" query, and use MultiCollector to
-    // wrap collecting the "normal" hits and also facets:
-    searcher.search(new MatchAllDocsQuery(), sfc);
+    // you'd use a "normal" query:
+    Facets.search(searcher, new MatchAllDocsQuery(), 10, fc);
 
-    Facets facets = new RangeFacetCounts("timestamp", sfc,
+    Facets facets = new RangeFacetCounts("timestamp", fc,
                                          PAST_HOUR,
                                          PAST_SIX_HOURS,
                                          PAST_DAY);
diff --git a/lucene/demo/src/java/org/apache/lucene/demo/facet/SimpleFacetsExample.java b/lucene/demo/src/java/org/apache/lucene/demo/facet/SimpleFacetsExample.java
index 4cd1a88..b5d5376 100644
--- a/lucene/demo/src/java/org/apache/lucene/demo/facet/SimpleFacetsExample.java
+++ b/lucene/demo/src/java/org/apache/lucene/demo/facet/SimpleFacetsExample.java
@@ -105,19 +105,18 @@ public class SimpleFacetsExample {
     TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoDir);
     FacetsConfig config = getConfig(null);
 
-    FacetsCollector sfc = new FacetsCollector();
+    FacetsCollector fc = new FacetsCollector();
 
     // MatchAllDocsQuery is for "browsing" (counts facets
     // for all non-deleted docs in the index); normally
-    // you'd use a "normal" query, and use MultiCollector to
-    // wrap collecting the "normal" hits and also facets:
-    searcher.search(new MatchAllDocsQuery(), sfc);
+    // you'd use a "normal" query:
+    Facets.search(searcher, new MatchAllDocsQuery(), 10, fc);
 
     // Retrieve results
     List<FacetResult> results = new ArrayList<FacetResult>();
 
     // Count both "Publish Date" and "Author" dimensions
-    Facets facets = new FastTaxonomyFacetCounts(taxoReader, config, sfc);
+    Facets facets = new FastTaxonomyFacetCounts(taxoReader, config, fc);
     results.add(facets.getTopChildren(10, "Author"));
     results.add(facets.getTopChildren(10, "Publish Date"));
     
@@ -140,11 +139,11 @@ public class SimpleFacetsExample {
 
     // Now user drills down on Publish Date/2010:
     q.add("Publish Date", "2010");
-    FacetsCollector sfc = new FacetsCollector();
-    searcher.search(q, sfc);
+    FacetsCollector fc = new FacetsCollector();
+    Facets.search(searcher, q, 10, fc);
 
     // Retrieve results
-    Facets facets = new FastTaxonomyFacetCounts(taxoReader, config, sfc);
+    Facets facets = new FastTaxonomyFacetCounts(taxoReader, config, fc);
     FacetResult result = facets.getTopChildren(10, "Author");
 
     indexReader.close();
diff --git a/lucene/demo/src/java/org/apache/lucene/demo/facet/SimpleSortedSetFacetsExample.java b/lucene/demo/src/java/org/apache/lucene/demo/facet/SimpleSortedSetFacetsExample.java
index 2058ba3..5f6d190 100644
--- a/lucene/demo/src/java/org/apache/lucene/demo/facet/SimpleSortedSetFacetsExample.java
+++ b/lucene/demo/src/java/org/apache/lucene/demo/facet/SimpleSortedSetFacetsExample.java
@@ -96,16 +96,15 @@ public class SimpleSortedSetFacetsExample {
     FacetsConfig config = getConfig();
 
     // Aggregatses the facet counts
-    FacetsCollector sfc = new FacetsCollector();
+    FacetsCollector fc = new FacetsCollector();
 
     // MatchAllDocsQuery is for "browsing" (counts facets
     // for all non-deleted docs in the index); normally
-    // you'd use a "normal" query, and use MultiCollector to
-    // wrap collecting the "normal" hits and also facets:
-    searcher.search(new MatchAllDocsQuery(), sfc);
+    // you'd use a "normal" query:
+    Facets.search(searcher, new MatchAllDocsQuery(), 10, fc);
 
     // Retrieve results
-    Facets facets = new SortedSetDocValuesFacetCounts(state, sfc);
+    Facets facets = new SortedSetDocValuesFacetCounts(state, fc);
 
     List<FacetResult> results = new ArrayList<FacetResult>();
     results.add(facets.getTopChildren(10, "Author"));
@@ -125,11 +124,11 @@ public class SimpleSortedSetFacetsExample {
     // Now user drills down on Publish Year/2010:
     DrillDownQuery q = new DrillDownQuery(config);
     q.add("Publish Year", "2010");
-    FacetsCollector sfc = new FacetsCollector();
-    searcher.search(q, sfc);
+    FacetsCollector fc = new FacetsCollector();
+    Facets.search(searcher, q, 10, fc);
 
     // Retrieve results
-    Facets facets = new SortedSetDocValuesFacetCounts(state, sfc);
+    Facets facets = new SortedSetDocValuesFacetCounts(state, fc);
     FacetResult result = facets.getTopChildren(10, "Author");
     indexReader.close();
     
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/Facets.java b/lucene/facet/src/java/org/apache/lucene/facet/Facets.java
index e6e94ba..330115c 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/Facets.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/Facets.java
@@ -20,13 +20,16 @@ package org.apache.lucene.facet;
 import java.io.IOException;
 import java.util.List;
 
+import org.apache.lucene.search.FieldDoc;
 import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.FilteredQuery;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.MultiCollector;
 import org.apache.lucene.search.Query;
+import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.Sort;
 import org.apache.lucene.search.TopDocs;
+import org.apache.lucene.search.TopDocsCollector;
 import org.apache.lucene.search.TopFieldCollector;
 import org.apache.lucene.search.TopFieldDocs;
 import org.apache.lucene.search.TopScoreDocCollector;
@@ -52,74 +55,108 @@ public abstract class Facets {
    *  depending on the type of document. */
   public abstract List<FacetResult> getAllDims(int topN) throws IOException;
 
-  // nocommit where to move?
-
-  /** Utility method, to search for top hits by score
-   *  ({@link IndexSearcher#search(Query,int)}), but
-   *  also collect results into a {@link
-   *  FacetsCollector} for faceting. */
-  public static TopDocs search(IndexSearcher searcher, Query q, int topN, FacetsCollector sfc) throws IOException {
-    // TODO: can we pass the "right" boolean for
-    // in-order...?  we'd need access to the protected
-    // IS.search methods taking Weight... could use
-    // reflection...
-    TopScoreDocCollector hitsCollector = TopScoreDocCollector.create(topN, false);
-    searcher.search(q, MultiCollector.wrap(hitsCollector, sfc));
-    return hitsCollector.topDocs();
+  // nocommit where to put these utility methods?
+
+  /** Utility method, to search and also collect all hits
+   *  into the provided {@link FacetsCollector}. */
+  public static TopDocs search(IndexSearcher searcher, Query q, int n, FacetsCollector fc) throws IOException {
+    return doSearch(searcher, null, q, null, n, null, false, false, fc);
   }
 
-  // nocommit where to move?
+  /** Utility method, to search and also collect all hits
+   *  into the provided {@link FacetsCollector}. */
+  public static TopDocs search(IndexSearcher searcher, Query q, Filter filter, int n, FacetsCollector fc) throws IOException {
+    return doSearch(searcher, null, q, filter, n, null, false, false, fc);
+  }
 
-  /** Utility method, to search for top hits by score with a filter
-   *  ({@link IndexSearcher#search(Query,Filter,int)}), but
-   *  also collect results into a {@link
-   *  FacetsCollector} for faceting. */
-  public static TopDocs search(IndexSearcher searcher, Query q, Filter filter, int topN, FacetsCollector sfc) throws IOException {
-    if (filter != null) {
-      q = new FilteredQuery(q, filter);
+  /** Utility method, to search and also collect all hits
+   *  into the provided {@link FacetsCollector}. */
+  public static TopFieldDocs search(IndexSearcher searcher, Query q, Filter filter, int n, Sort sort, FacetsCollector fc) throws IOException {
+    if (sort == null) {
+      throw new IllegalArgumentException("sort must not be null");
+    }
+    return (TopFieldDocs) doSearch(searcher, null, q, filter, n, sort, false, false, fc);
+  }
+
+  /** Utility method, to search and also collect all hits
+   *  into the provided {@link FacetsCollector}. */
+  public static TopFieldDocs search(IndexSearcher searcher, Query q, Filter filter, int n, Sort sort, boolean doDocScores, boolean doMaxScore, FacetsCollector fc) throws IOException {
+    if (sort == null) {
+      throw new IllegalArgumentException("sort must not be null");
     }
-    return search(searcher, q, topN, sfc);
+    return (TopFieldDocs) doSearch(searcher, null, q, filter, n, sort, doDocScores, doMaxScore, fc);
   }
 
-  // nocommit where to move?
+  /** Utility method, to search and also collect all hits
+   *  into the provided {@link FacetsCollector}. */
+  public TopDocs searchAfter(IndexSearcher searcher, ScoreDoc after, Query q, int n, FacetsCollector fc) throws IOException {
+    return doSearch(searcher, after, q, null, n, null, false, false, fc);
+  }
 
-  /** Utility method, to search for top hits by a custom
-   *  {@link Sort} with a filter
-   *  ({@link IndexSearcher#search(Query,Filter,int,Sort)}), but
-   *  also collect results into a {@link
-   *  FacetsCollector} for faceting. */
-  public static TopFieldDocs search(IndexSearcher searcher, Query q, Filter filter, int topN, Sort sort, FacetsCollector sfc) throws IOException {
-    return search(searcher, q, filter, topN, sort, false, false, sfc);
+  /** Utility method, to search and also collect all hits
+   *  into the provided {@link FacetsCollector}. */
+  public static TopDocs searchAfter(IndexSearcher searcher, ScoreDoc after, Query q, Filter filter, int n, FacetsCollector fc) throws IOException {
+    return doSearch(searcher, after, q, filter, n, null, false, false, fc);
   }
 
-  // nocommit where to move?
+  /** Utility method, to search and also collect all hits
+   *  into the provided {@link FacetsCollector}. */
+  public static TopDocs searchAfter(IndexSearcher searcher, ScoreDoc after, Query q, Filter filter, int n, Sort sort, FacetsCollector fc) throws IOException {
+    if (sort == null) {
+      throw new IllegalArgumentException("sort must not be null");
+    }
+    return (TopFieldDocs) doSearch(searcher, after, q, filter, n, sort, false, false, fc);
+  }
 
-  /** Utility method, to search for top hits by a custom
-   *  {@link Sort} with a filter
-   *  ({@link IndexSearcher#search(Query,Filter,int,Sort,boolean,boolean)}), but
-   *  also collect results into a {@link
-   *  FacetsCollector} for faceting. */
-  public static TopFieldDocs search(IndexSearcher searcher, Query q, Filter filter, int topN, Sort sort, boolean doDocScores, boolean doMaxScore, FacetsCollector sfc) throws IOException {
-    int limit = searcher.getIndexReader().maxDoc();
-    if (limit == 0) {
-      limit = 1;
+  /** Utility method, to search and also collect all hits
+   *  into the provided {@link FacetsCollector}. */
+  public static TopDocs searchAfter(IndexSearcher searcher, ScoreDoc after, Query q, Filter filter, int n, Sort sort, boolean doDocScores, boolean doMaxScore, FacetsCollector fc) throws IOException {
+    if (sort == null) {
+      throw new IllegalArgumentException("sort must not be null");
     }
-    topN = Math.min(topN, limit);
-
-    boolean fillFields = true;
-    TopFieldCollector hitsCollector = TopFieldCollector.create(sort, topN,
-                                                               null,
-                                                               fillFields,
-                                                               doDocScores,
-                                                               doMaxScore,
-                                                               false);
+    return (TopFieldDocs) doSearch(searcher, after, q, filter, n, sort, doDocScores, doMaxScore, fc);
+  }
+
+  private static TopDocs doSearch(IndexSearcher searcher, ScoreDoc after, Query q, Filter filter, int n, Sort sort,
+                                  boolean doDocScores, boolean doMaxScore, FacetsCollector fc) throws IOException {
+
     if (filter != null) {
       q = new FilteredQuery(q, filter);
     }
-    searcher.search(q, MultiCollector.wrap(hitsCollector, sfc));
-    return (TopFieldDocs) hitsCollector.topDocs();
-  }
 
-  // nocommit need searchAfter variants too
+    int limit = searcher.getIndexReader().maxDoc();
+    if (limit == 0) {
+      limit = 1;
+    }
+    n = Math.min(n, limit);
+
+    if (after != null && after.doc >= limit) {
+      throw new IllegalArgumentException("after.doc exceeds the number of documents in the reader: after.doc="
+                                         + after.doc + " limit=" + limit);
+    }
 
+    TopDocsCollector<?> hitsCollector;
+    if (sort != null) {
+      if (after != null && !(after instanceof FieldDoc)) {
+        // TODO: if we fix type safety of TopFieldDocs we can
+        // remove this
+        throw new IllegalArgumentException("after must be a FieldDoc; got " + after);
+      }
+      boolean fillFields = true;
+      hitsCollector = TopFieldCollector.create(sort, n,
+                                               (FieldDoc) after,
+                                               fillFields,
+                                               doDocScores,
+                                               doMaxScore,
+                                               false);
+    } else {
+      // TODO: can we pass the right boolean for
+      // in-order instead of hardwired to false...?  we'd
+      // need access to the protected IS.search methods
+      // taking Weight... could use reflection...
+      hitsCollector = TopScoreDocCollector.create(n, after, false);
+    }
+    searcher.search(q, MultiCollector.wrap(hitsCollector, fc));
+    return hitsCollector.topDocs();
+  }
 }
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/FloatTaxonomyFacets.java b/lucene/facet/src/java/org/apache/lucene/facet/FloatTaxonomyFacets.java
index b0bf080..9356906 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/FloatTaxonomyFacets.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/FloatTaxonomyFacets.java
@@ -35,7 +35,6 @@ public abstract class FloatTaxonomyFacets extends TaxonomyFacets {
     values = new float[taxoReader.getSize()];
   }
   
-  // nocommit we could do this lazily instead:
   protected void rollup() throws IOException {
     // Rollup any necessary dims:
     for(Map.Entry<String,FacetsConfig.DimConfig> ent : config.getDimConfigs().entrySet()) {
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/IntTaxonomyFacets.java b/lucene/facet/src/java/org/apache/lucene/facet/IntTaxonomyFacets.java
index 92668fe..6ff76cf 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/IntTaxonomyFacets.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/IntTaxonomyFacets.java
@@ -35,7 +35,6 @@ public abstract class IntTaxonomyFacets extends TaxonomyFacets {
     values = new int[taxoReader.getSize()];
   }
   
-  // nocommit we could do this lazily instead:
   protected void rollup() throws IOException {
     // Rollup any necessary dims:
     for(Map.Entry<String,FacetsConfig.DimConfig> ent : config.getDimConfigs().entrySet()) {
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/TestCachedOrdinalsReader.java b/lucene/facet/src/test/org/apache/lucene/facet/TestCachedOrdinalsReader.java
index c16cbcd..5b6fb56 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/TestCachedOrdinalsReader.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/TestCachedOrdinalsReader.java
@@ -18,12 +18,9 @@ package org.apache.lucene.facet;
  */
 
 import java.io.IOException;
-import java.util.Arrays;
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
-import org.apache.lucene.facet.FacetTestCase;
-import org.apache.lucene.facet.taxonomy.FacetLabel;
 import org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyWriter;
 import org.apache.lucene.index.AtomicReaderContext;
 import org.apache.lucene.index.DirectoryReader;
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/TestDrillDownQuery.java b/lucene/facet/src/test/org/apache/lucene/facet/TestDrillDownQuery.java
index fa6c81d..263c114 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/TestDrillDownQuery.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/TestDrillDownQuery.java
@@ -18,9 +18,6 @@ package org.apache.lucene.facet;
  */
 
 import java.io.IOException;
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.Map;
 import java.util.Random;
 
 import org.apache.lucene.analysis.MockAnalyzer;
@@ -28,8 +25,6 @@ import org.apache.lucene.analysis.MockTokenizer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.TextField;
-import org.apache.lucene.facet.FacetTestCase;
-import org.apache.lucene.facet.taxonomy.FacetLabel;
 import org.apache.lucene.facet.taxonomy.TaxonomyWriter;
 import org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyReader;
 import org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyWriter;
@@ -47,7 +42,6 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.IOUtils;
 import org.junit.AfterClass;
 import org.junit.BeforeClass;
-import org.junit.Test;
 
 public class TestDrillDownQuery extends FacetTestCase {
   
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/TestRangeFacetCounts.java b/lucene/facet/src/test/org/apache/lucene/facet/TestRangeFacetCounts.java
new file mode 100644
index 0000000..43b64cc
--- /dev/null
+++ b/lucene/facet/src/test/org/apache/lucene/facet/TestRangeFacetCounts.java
@@ -0,0 +1,533 @@
+package org.apache.lucene.facet;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.DoubleDocValuesField;
+import org.apache.lucene.document.DoubleField;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.document.FloatDocValuesField;
+import org.apache.lucene.document.FloatField;
+import org.apache.lucene.document.LongField;
+import org.apache.lucene.document.NumericDocValuesField;
+import org.apache.lucene.facet.DrillSideways.DrillSidewaysResult;
+import org.apache.lucene.facet.taxonomy.TaxonomyReader;
+import org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyReader;
+import org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyWriter;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.IndexWriterConfig;
+import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.MatchAllDocsQuery;
+import org.apache.lucene.search.NumericRangeQuery;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util._TestUtil;
+
+
+public class TestRangeFacetCounts extends FacetTestCase {
+
+  public void testBasicLong() throws Exception {
+    Directory d = newDirectory();
+    RandomIndexWriter w = new RandomIndexWriter(random(), d);
+    Document doc = new Document();
+    NumericDocValuesField field = new NumericDocValuesField("field", 0L);
+    doc.add(field);
+    for(long l=0;l<100;l++) {
+      field.setLongValue(l);
+      w.addDocument(doc);
+    }
+    field.setLongValue(Long.MAX_VALUE);
+    w.addDocument(doc);
+
+    IndexReader r = w.getReader();
+    w.close();
+
+    FacetsCollector fc = new FacetsCollector();
+    IndexSearcher s = newSearcher(r);
+    s.search(new MatchAllDocsQuery(), fc);
+
+    RangeFacetCounts facets = new RangeFacetCounts("field", fc,
+        new LongRange("less than 10", 0L, true, 10L, false),
+        new LongRange("less than or equal to 10", 0L, true, 10L, true),
+        new LongRange("over 90", 90L, false, 100L, false),
+        new LongRange("90 or above", 90L, true, 100L, false),
+        new LongRange("over 1000", 1000L, false, Long.MAX_VALUE, true));
+    
+    FacetResult result = facets.getTopChildren(10, "field");
+    assertEquals("value=101 childCount=5\n  less than 10 (10)\n  less than or equal to 10 (11)\n  over 90 (9)\n  90 or above (10)\n  over 1000 (1)\n",
+                 result.toString());
+    
+    r.close();
+    d.close();
+  }
+
+  /** Tests single request that mixes Range and non-Range
+   *  faceting, with DrillSideways and taxonomy. */
+  public void testMixedRangeAndNonRangeTaxonomy() throws Exception {
+    Directory d = newDirectory();
+    RandomIndexWriter w = new RandomIndexWriter(random(), d);
+    Directory td = newDirectory();
+    DirectoryTaxonomyWriter tw = new DirectoryTaxonomyWriter(td, IndexWriterConfig.OpenMode.CREATE);
+
+    FacetsConfig config = new FacetsConfig(tw);
+
+    for (long l = 0; l < 100; l++) {
+      Document doc = new Document();
+      // For computing range facet counts:
+      doc.add(new NumericDocValuesField("field", l));
+      // For drill down by numeric range:
+      doc.add(new LongField("field", l, Field.Store.NO));
+
+      if ((l&3) == 0) {
+        doc.add(new FacetField("dim", "a"));
+      } else {
+        doc.add(new FacetField("dim", "b"));
+      }
+      w.addDocument(config.build(doc));
+    }
+
+    final IndexReader r = w.getReader();
+
+    final TaxonomyReader tr = new DirectoryTaxonomyReader(tw);
+
+    IndexSearcher s = newSearcher(r);
+
+    DrillSideways ds = new DrillSideways(s, config, tr) {
+
+        @Override
+        protected Facets buildFacetsResult(FacetsCollector drillDowns, FacetsCollector[] drillSideways, String[] drillSidewaysDims) throws IOException {        
+          // nocommit this is awkward... can we improve?
+          // nocommit is drillDowns allowed to be null?
+          // should it?
+          FacetsCollector dimFC = drillDowns;
+          FacetsCollector fieldFC = drillDowns;
+          if (drillSideways != null) {
+            for(int i=0;i<drillSideways.length;i++) {
+              String dim = drillSidewaysDims[i];
+              if (dim.equals("field")) {
+                fieldFC = drillSideways[i];
+              } else {
+                dimFC = drillSideways[i];
+              }
+            }
+          }
+
+          Map<String,Facets> byDim = new HashMap<String,Facets>();
+          byDim.put("field",
+                    new RangeFacetCounts("field", fieldFC,
+                          new LongRange("less than 10", 0L, true, 10L, false),
+                          new LongRange("less than or equal to 10", 0L, true, 10L, true),
+                          new LongRange("over 90", 90L, false, 100L, false),
+                          new LongRange("90 or above", 90L, true, 100L, false),
+                          new LongRange("over 1000", 1000L, false, Long.MAX_VALUE, false)));
+          byDim.put("dim", getTaxonomyFacetCounts(taxoReader, config, dimFC));
+          return new MultiFacets(byDim, null);
+        }
+
+        @Override
+        protected boolean scoreSubDocsAtOnce() {
+          return random().nextBoolean();
+        }
+      };
+
+    // First search, no drill downs:
+    DrillDownQuery ddq = new DrillDownQuery(config);
+    DrillSidewaysResult dsr = ds.search(null, ddq, 10);
+
+    assertEquals(100, dsr.hits.totalHits);
+    assertEquals("value=100 childCount=2\n  b (75)\n  a (25)\n", dsr.facets.getTopChildren(10, "dim").toString());
+    assertEquals("value=100 childCount=5\n  less than 10 (10)\n  less than or equal to 10 (11)\n  over 90 (9)\n  90 or above (10)\n  over 1000 (0)\n",
+                 dsr.facets.getTopChildren(10, "field").toString());
+
+    // Second search, drill down on dim=b:
+    ddq = new DrillDownQuery(config);
+    ddq.add("dim", "b");
+    dsr = ds.search(null, ddq, 10);
+
+    assertEquals(75, dsr.hits.totalHits);
+    assertEquals("value=100 childCount=2\n  b (75)\n  a (25)\n", dsr.facets.getTopChildren(10, "dim").toString());
+    assertEquals("value=75 childCount=5\n  less than 10 (7)\n  less than or equal to 10 (8)\n  over 90 (7)\n  90 or above (8)\n  over 1000 (0)\n",
+                 dsr.facets.getTopChildren(10, "field").toString());
+
+    // Third search, drill down on "less than or equal to 10":
+    ddq = new DrillDownQuery(config);
+    ddq.add("field", NumericRangeQuery.newLongRange("field", 0L, 10L, true, true));
+    dsr = ds.search(null, ddq, 10);
+
+    assertEquals(11, dsr.hits.totalHits);
+    assertEquals("value=11 childCount=2\n  b (8)\n  a (3)\n", dsr.facets.getTopChildren(10, "dim").toString());
+    assertEquals("value=100 childCount=5\n  less than 10 (10)\n  less than or equal to 10 (11)\n  over 90 (9)\n  90 or above (10)\n  over 1000 (0)\n",
+                 dsr.facets.getTopChildren(10, "field").toString());
+    IOUtils.close(tw, tr, td, w, r, d);
+  }
+
+  public void testBasicDouble() throws Exception {
+    Directory d = newDirectory();
+    RandomIndexWriter w = new RandomIndexWriter(random(), d);
+    Document doc = new Document();
+    DoubleDocValuesField field = new DoubleDocValuesField("field", 0.0);
+    doc.add(field);
+    for(long l=0;l<100;l++) {
+      field.setDoubleValue(l);
+      w.addDocument(doc);
+    }
+
+    IndexReader r = w.getReader();
+
+    FacetsCollector fc = new FacetsCollector();
+
+    IndexSearcher s = newSearcher(r);
+    s.search(new MatchAllDocsQuery(), fc);
+    Facets facets = new RangeFacetCounts("field", fc,
+        new DoubleRange("less than 10", 0.0, true, 10.0, false),
+        new DoubleRange("less than or equal to 10", 0.0, true, 10.0, true),
+        new DoubleRange("over 90", 90.0, false, 100.0, false),
+        new DoubleRange("90 or above", 90.0, true, 100.0, false),
+        new DoubleRange("over 1000", 1000.0, false, Double.POSITIVE_INFINITY, false));
+                                         
+    assertEquals("value=100 childCount=5\n  less than 10 (10)\n  less than or equal to 10 (11)\n  over 90 (9)\n  90 or above (10)\n  over 1000 (0)\n",
+                 facets.getTopChildren(10, "field").toString());
+
+    IOUtils.close(w, r, d);
+  }
+
+  public void testBasicFloat() throws Exception {
+    Directory d = newDirectory();
+    RandomIndexWriter w = new RandomIndexWriter(random(), d);
+    Document doc = new Document();
+    FloatDocValuesField field = new FloatDocValuesField("field", 0.0f);
+    doc.add(field);
+    for(long l=0;l<100;l++) {
+      field.setFloatValue(l);
+      w.addDocument(doc);
+    }
+
+    IndexReader r = w.getReader();
+
+    FacetsCollector fc = new FacetsCollector();
+
+    IndexSearcher s = newSearcher(r);
+    s.search(new MatchAllDocsQuery(), fc);
+
+    Facets facets = new RangeFacetCounts("field", fc,
+        new FloatRange("less than 10", 0.0f, true, 10.0f, false),
+        new FloatRange("less than or equal to 10", 0.0f, true, 10.0f, true),
+        new FloatRange("over 90", 90.0f, false, 100.0f, false),
+        new FloatRange("90 or above", 90.0f, true, 100.0f, false),
+        new FloatRange("over 1000", 1000.0f, false, Float.POSITIVE_INFINITY, false));
+    
+    assertEquals("value=100 childCount=5\n  less than 10 (10)\n  less than or equal to 10 (11)\n  over 90 (9)\n  90 or above (10)\n  over 1000 (0)\n",
+                 facets.getTopChildren(10, "field").toString());
+    
+    IOUtils.close(w, r, d);
+  }
+
+  public void testRandomLongs() throws Exception {
+    Directory dir = newDirectory();
+    RandomIndexWriter w = new RandomIndexWriter(random(), dir);
+
+    int numDocs = atLeast(1000);
+    long[] values = new long[numDocs];
+    for(int i=0;i<numDocs;i++) {
+      Document doc = new Document();
+      long v = random().nextLong();
+      values[i] = v;
+      doc.add(new NumericDocValuesField("field", v));
+      doc.add(new LongField("field", v, Field.Store.NO));
+      w.addDocument(doc);
+    }
+    IndexReader r = w.getReader();
+
+    IndexSearcher s = newSearcher(r);
+    FacetsConfig config = new FacetsConfig();
+    
+    int numIters = atLeast(10);
+    for(int iter=0;iter<numIters;iter++) {
+      if (VERBOSE) {
+        System.out.println("TEST: iter=" + iter);
+      }
+      int numRange = _TestUtil.nextInt(random(), 1, 5);
+      LongRange[] ranges = new LongRange[numRange];
+      int[] expectedCounts = new int[numRange];
+      for(int rangeID=0;rangeID<numRange;rangeID++) {
+        long min = random().nextLong();
+        long max = random().nextLong();
+        if (min > max) {
+          long x = min;
+          min = max;
+          max = x;
+        }
+        boolean minIncl = random().nextBoolean();
+        boolean maxIncl = random().nextBoolean();
+        ranges[rangeID] = new LongRange("r" + rangeID, min, minIncl, max, maxIncl);
+
+        // Do "slow but hopefully correct" computation of
+        // expected count:
+        for(int i=0;i<numDocs;i++) {
+          boolean accept = true;
+          if (minIncl) {
+            accept &= values[i] >= min;
+          } else {
+            accept &= values[i] > min;
+          }
+          if (maxIncl) {
+            accept &= values[i] <= max;
+          } else {
+            accept &= values[i] < max;
+          }
+          if (accept) {
+            expectedCounts[rangeID]++;
+          }
+        }
+      }
+
+      FacetsCollector sfc = new FacetsCollector();
+      s.search(new MatchAllDocsQuery(), sfc);
+      Facets facets = new RangeFacetCounts("field", sfc, ranges);
+      FacetResult result = facets.getTopChildren(10, "field");
+      assertEquals(numRange, result.labelValues.length);
+      for(int rangeID=0;rangeID<numRange;rangeID++) {
+        if (VERBOSE) {
+          System.out.println("  range " + rangeID + " expectedCount=" + expectedCounts[rangeID]);
+        }
+        LabelAndValue subNode = result.labelValues[rangeID];
+        assertEquals("r" + rangeID, subNode.label);
+        assertEquals(expectedCounts[rangeID], subNode.value.intValue());
+
+        LongRange range = ranges[rangeID];
+
+        // Test drill-down:
+        DrillDownQuery ddq = new DrillDownQuery(config);
+        ddq.add("field", NumericRangeQuery.newLongRange("field", range.min, range.max, range.minInclusive, range.maxInclusive));
+        assertEquals(expectedCounts[rangeID], s.search(ddq, 10).totalHits);
+      }
+    }
+
+    IOUtils.close(w, r, dir);
+  }
+
+  public void testRandomFloats() throws Exception {
+    Directory dir = newDirectory();
+    RandomIndexWriter w = new RandomIndexWriter(random(), dir);
+
+    int numDocs = atLeast(1000);
+    float[] values = new float[numDocs];
+    for(int i=0;i<numDocs;i++) {
+      Document doc = new Document();
+      float v = random().nextFloat();
+      values[i] = v;
+      doc.add(new FloatDocValuesField("field", v));
+      doc.add(new FloatField("field", v, Field.Store.NO));
+      w.addDocument(doc);
+    }
+    IndexReader r = w.getReader();
+
+    IndexSearcher s = newSearcher(r);
+    FacetsConfig config = new FacetsConfig();
+    
+    int numIters = atLeast(10);
+    for(int iter=0;iter<numIters;iter++) {
+      if (VERBOSE) {
+        System.out.println("TEST: iter=" + iter);
+      }
+      int numRange = _TestUtil.nextInt(random(), 1, 5);
+      FloatRange[] ranges = new FloatRange[numRange];
+      int[] expectedCounts = new int[numRange];
+      for(int rangeID=0;rangeID<numRange;rangeID++) {
+        float min = random().nextFloat();
+        float max = random().nextFloat();
+        if (min > max) {
+          float x = min;
+          min = max;
+          max = x;
+        }
+        boolean minIncl = random().nextBoolean();
+        boolean maxIncl = random().nextBoolean();
+        ranges[rangeID] = new FloatRange("r" + rangeID, min, minIncl, max, maxIncl);
+
+        // Do "slow but hopefully correct" computation of
+        // expected count:
+        for(int i=0;i<numDocs;i++) {
+          boolean accept = true;
+          if (minIncl) {
+            accept &= values[i] >= min;
+          } else {
+            accept &= values[i] > min;
+          }
+          if (maxIncl) {
+            accept &= values[i] <= max;
+          } else {
+            accept &= values[i] < max;
+          }
+          if (accept) {
+            expectedCounts[rangeID]++;
+          }
+        }
+      }
+
+      FacetsCollector sfc = new FacetsCollector();
+      s.search(new MatchAllDocsQuery(), sfc);
+      Facets facets = new RangeFacetCounts("field", sfc, ranges);
+      FacetResult result = facets.getTopChildren(10, "field");
+      assertEquals(numRange, result.labelValues.length);
+      for(int rangeID=0;rangeID<numRange;rangeID++) {
+        if (VERBOSE) {
+          System.out.println("  range " + rangeID + " expectedCount=" + expectedCounts[rangeID]);
+        }
+        LabelAndValue subNode = result.labelValues[rangeID];
+        assertEquals("r" + rangeID, subNode.label);
+        assertEquals(expectedCounts[rangeID], subNode.value.intValue());
+
+        FloatRange range = ranges[rangeID];
+
+        // Test drill-down:
+        DrillDownQuery ddq = new DrillDownQuery(config);
+        ddq.add("field", NumericRangeQuery.newFloatRange("field", range.min, range.max, range.minInclusive, range.maxInclusive));
+        assertEquals(expectedCounts[rangeID], s.search(ddq, 10).totalHits);
+      }
+    }
+
+    IOUtils.close(w, r, dir);
+  }
+
+  public void testRandomDoubles() throws Exception {
+    Directory dir = newDirectory();
+    RandomIndexWriter w = new RandomIndexWriter(random(), dir);
+
+    int numDocs = atLeast(1000);
+    double[] values = new double[numDocs];
+    for(int i=0;i<numDocs;i++) {
+      Document doc = new Document();
+      double v = random().nextDouble();
+      values[i] = v;
+      doc.add(new DoubleDocValuesField("field", v));
+      doc.add(new DoubleField("field", v, Field.Store.NO));
+      w.addDocument(doc);
+    }
+    IndexReader r = w.getReader();
+
+    IndexSearcher s = newSearcher(r);
+    FacetsConfig config = new FacetsConfig();
+    
+    int numIters = atLeast(10);
+    for(int iter=0;iter<numIters;iter++) {
+      if (VERBOSE) {
+        System.out.println("TEST: iter=" + iter);
+      }
+      int numRange = _TestUtil.nextInt(random(), 1, 5);
+      DoubleRange[] ranges = new DoubleRange[numRange];
+      int[] expectedCounts = new int[numRange];
+      for(int rangeID=0;rangeID<numRange;rangeID++) {
+        double min = random().nextDouble();
+        double max = random().nextDouble();
+        if (min > max) {
+          double x = min;
+          min = max;
+          max = x;
+        }
+        boolean minIncl = random().nextBoolean();
+        boolean maxIncl = random().nextBoolean();
+        ranges[rangeID] = new DoubleRange("r" + rangeID, min, minIncl, max, maxIncl);
+
+        // Do "slow but hopefully correct" computation of
+        // expected count:
+        for(int i=0;i<numDocs;i++) {
+          boolean accept = true;
+          if (minIncl) {
+            accept &= values[i] >= min;
+          } else {
+            accept &= values[i] > min;
+          }
+          if (maxIncl) {
+            accept &= values[i] <= max;
+          } else {
+            accept &= values[i] < max;
+          }
+          if (accept) {
+            expectedCounts[rangeID]++;
+          }
+        }
+      }
+
+      FacetsCollector sfc = new FacetsCollector();
+      s.search(new MatchAllDocsQuery(), sfc);
+      Facets facets = new RangeFacetCounts("field", sfc, ranges);
+      FacetResult result = facets.getTopChildren(10, "field");
+      assertEquals(numRange, result.labelValues.length);
+      for(int rangeID=0;rangeID<numRange;rangeID++) {
+        if (VERBOSE) {
+          System.out.println("  range " + rangeID + " expectedCount=" + expectedCounts[rangeID]);
+        }
+        LabelAndValue subNode = result.labelValues[rangeID];
+        assertEquals("r" + rangeID, subNode.label);
+        assertEquals(expectedCounts[rangeID], subNode.value.intValue());
+
+        DoubleRange range = ranges[rangeID];
+
+        // Test drill-down:
+        DrillDownQuery ddq = new DrillDownQuery(config);
+        ddq.add("field", NumericRangeQuery.newDoubleRange("field", range.min, range.max, range.minInclusive, range.maxInclusive));
+        assertEquals(expectedCounts[rangeID], s.search(ddq, 10).totalHits);
+      }
+    }
+
+    IOUtils.close(w, r, dir);
+  }
+
+  // LUCENE-5178
+  public void testMissingValues() throws Exception {
+    assumeTrue("codec does not support docsWithField", defaultCodecSupportsDocsWithField());
+    Directory d = newDirectory();
+    RandomIndexWriter w = new RandomIndexWriter(random(), d);
+    Document doc = new Document();
+    NumericDocValuesField field = new NumericDocValuesField("field", 0L);
+    doc.add(field);
+    for(long l=0;l<100;l++) {
+      if (l % 5 == 0) {
+        // Every 5th doc is missing the value:
+        w.addDocument(new Document());
+        continue;
+      }
+      field.setLongValue(l);
+      w.addDocument(doc);
+    }
+
+    IndexReader r = w.getReader();
+
+    FacetsCollector sfc = new FacetsCollector();
+
+    IndexSearcher s = newSearcher(r);
+    s.search(new MatchAllDocsQuery(), sfc);
+    Facets facets = new RangeFacetCounts("field", sfc,
+        new LongRange("less than 10", 0L, true, 10L, false),
+        new LongRange("less than or equal to 10", 0L, true, 10L, true),
+        new LongRange("over 90", 90L, false, 100L, false),
+        new LongRange("90 or above", 90L, true, 100L, false),
+        new LongRange("over 1000", 1000L, false, Long.MAX_VALUE, false));
+    
+    assertEquals("value=100 childCount=5\n  less than 10 (8)\n  less than or equal to 10 (8)\n  over 90 (8)\n  90 or above (8)\n  over 1000 (0)\n",
+                 facets.getTopChildren(10, "field").toString());
+
+    IOUtils.close(w, r, d);
+  }
+}
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/TestRangeFacets.java b/lucene/facet/src/test/org/apache/lucene/facet/TestRangeFacets.java
deleted file mode 100644
index a520014..0000000
--- a/lucene/facet/src/test/org/apache/lucene/facet/TestRangeFacets.java
+++ /dev/null
@@ -1,540 +0,0 @@
-package org.apache.lucene.facet;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
-
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.DoubleDocValuesField;
-import org.apache.lucene.document.DoubleField;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.document.FloatDocValuesField;
-import org.apache.lucene.document.FloatField;
-import org.apache.lucene.document.LongField;
-import org.apache.lucene.document.NumericDocValuesField;
-import org.apache.lucene.facet.FacetTestCase;
-import org.apache.lucene.facet.DrillSideways.DrillSidewaysResult;
-import org.apache.lucene.facet.taxonomy.FacetLabel;
-import org.apache.lucene.facet.taxonomy.TaxonomyReader;
-import org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyReader;
-import org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyWriter;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.IndexWriterConfig;
-import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.MatchAllDocsQuery;
-import org.apache.lucene.search.NumericRangeQuery;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.IOUtils;
-import org.apache.lucene.util._TestUtil;
-
-
-// nocommit rename to TestRangeFacetCounts
-public class TestRangeFacets extends FacetTestCase {
-
-  public void testBasicLong() throws Exception {
-    Directory d = newDirectory();
-    RandomIndexWriter w = new RandomIndexWriter(random(), d);
-    Document doc = new Document();
-    NumericDocValuesField field = new NumericDocValuesField("field", 0L);
-    doc.add(field);
-    for(long l=0;l<100;l++) {
-      field.setLongValue(l);
-      w.addDocument(doc);
-    }
-    field.setLongValue(Long.MAX_VALUE);
-    w.addDocument(doc);
-
-    IndexReader r = w.getReader();
-    w.close();
-
-    FacetsCollector fc = new FacetsCollector();
-    IndexSearcher s = newSearcher(r);
-    s.search(new MatchAllDocsQuery(), fc);
-
-    RangeFacetCounts facets = new RangeFacetCounts("field", fc,
-        new LongRange("less than 10", 0L, true, 10L, false),
-        new LongRange("less than or equal to 10", 0L, true, 10L, true),
-        new LongRange("over 90", 90L, false, 100L, false),
-        new LongRange("90 or above", 90L, true, 100L, false),
-        new LongRange("over 1000", 1000L, false, Long.MAX_VALUE, true));
-    
-    FacetResult result = facets.getTopChildren(10, "field");
-    assertEquals("value=101 childCount=5\n  less than 10 (10)\n  less than or equal to 10 (11)\n  over 90 (9)\n  90 or above (10)\n  over 1000 (1)\n",
-                 result.toString());
-    
-    r.close();
-    d.close();
-  }
-
-  /** Tests single request that mixes Range and non-Range
-   *  faceting, with DrillSideways and taxonomy. */
-  public void testMixedRangeAndNonRangeTaxonomy() throws Exception {
-    Directory d = newDirectory();
-    RandomIndexWriter w = new RandomIndexWriter(random(), d);
-    Directory td = newDirectory();
-    DirectoryTaxonomyWriter tw = new DirectoryTaxonomyWriter(td, IndexWriterConfig.OpenMode.CREATE);
-
-    FacetsConfig config = new FacetsConfig(tw);
-
-    for (long l = 0; l < 100; l++) {
-      Document doc = new Document();
-      // For computing range facet counts:
-      doc.add(new NumericDocValuesField("field", l));
-      // For drill down by numeric range:
-      doc.add(new LongField("field", l, Field.Store.NO));
-
-      if ((l&3) == 0) {
-        doc.add(new FacetField("dim", "a"));
-      } else {
-        doc.add(new FacetField("dim", "b"));
-      }
-      w.addDocument(config.build(doc));
-    }
-
-    final IndexReader r = w.getReader();
-
-    final TaxonomyReader tr = new DirectoryTaxonomyReader(tw);
-
-    IndexSearcher s = newSearcher(r);
-
-    DrillSideways ds = new DrillSideways(s, config, tr) {
-
-        @Override
-        protected Facets buildFacetsResult(FacetsCollector drillDowns, FacetsCollector[] drillSideways, String[] drillSidewaysDims) throws IOException {        
-          // nocommit this is awkward... can we improve?
-          // nocommit is drillDowns allowed to be null?
-          // should it?
-          FacetsCollector dimFC = drillDowns;
-          FacetsCollector fieldFC = drillDowns;
-          if (drillSideways != null) {
-            for(int i=0;i<drillSideways.length;i++) {
-              String dim = drillSidewaysDims[i];
-              if (dim.equals("field")) {
-                fieldFC = drillSideways[i];
-              } else {
-                dimFC = drillSideways[i];
-              }
-            }
-          }
-
-          Map<String,Facets> byDim = new HashMap<String,Facets>();
-          byDim.put("field",
-                    new RangeFacetCounts("field", fieldFC,
-                          new LongRange("less than 10", 0L, true, 10L, false),
-                          new LongRange("less than or equal to 10", 0L, true, 10L, true),
-                          new LongRange("over 90", 90L, false, 100L, false),
-                          new LongRange("90 or above", 90L, true, 100L, false),
-                          new LongRange("over 1000", 1000L, false, Long.MAX_VALUE, false)));
-          byDim.put("dim", getTaxonomyFacetCounts(taxoReader, config, dimFC));
-          return new MultiFacets(byDim, null);
-        }
-
-        @Override
-        protected boolean scoreSubDocsAtOnce() {
-          return random().nextBoolean();
-        }
-      };
-
-    // First search, no drill downs:
-    DrillDownQuery ddq = new DrillDownQuery(config);
-    DrillSidewaysResult dsr = ds.search(null, ddq, 10);
-
-    assertEquals(100, dsr.hits.totalHits);
-    assertEquals("value=100 childCount=2\n  b (75)\n  a (25)\n", dsr.facets.getTopChildren(10, "dim").toString());
-    assertEquals("value=100 childCount=5\n  less than 10 (10)\n  less than or equal to 10 (11)\n  over 90 (9)\n  90 or above (10)\n  over 1000 (0)\n",
-                 dsr.facets.getTopChildren(10, "field").toString());
-
-    // Second search, drill down on dim=b:
-    ddq = new DrillDownQuery(config);
-    ddq.add("dim", "b");
-    dsr = ds.search(null, ddq, 10);
-
-    assertEquals(75, dsr.hits.totalHits);
-    assertEquals("value=100 childCount=2\n  b (75)\n  a (25)\n", dsr.facets.getTopChildren(10, "dim").toString());
-    assertEquals("value=75 childCount=5\n  less than 10 (7)\n  less than or equal to 10 (8)\n  over 90 (7)\n  90 or above (8)\n  over 1000 (0)\n",
-                 dsr.facets.getTopChildren(10, "field").toString());
-
-    // Third search, drill down on "less than or equal to 10":
-    ddq = new DrillDownQuery(config);
-    ddq.add("field", NumericRangeQuery.newLongRange("field", 0L, 10L, true, true));
-    dsr = ds.search(null, ddq, 10);
-
-    assertEquals(11, dsr.hits.totalHits);
-    assertEquals("value=11 childCount=2\n  b (8)\n  a (3)\n", dsr.facets.getTopChildren(10, "dim").toString());
-    assertEquals("value=100 childCount=5\n  less than 10 (10)\n  less than or equal to 10 (11)\n  over 90 (9)\n  90 or above (10)\n  over 1000 (0)\n",
-                 dsr.facets.getTopChildren(10, "field").toString());
-    IOUtils.close(tw, tr, td, w, r, d);
-  }
-
-  public void testBasicDouble() throws Exception {
-    Directory d = newDirectory();
-    RandomIndexWriter w = new RandomIndexWriter(random(), d);
-    Document doc = new Document();
-    DoubleDocValuesField field = new DoubleDocValuesField("field", 0.0);
-    doc.add(field);
-    for(long l=0;l<100;l++) {
-      field.setDoubleValue(l);
-      w.addDocument(doc);
-    }
-
-    IndexReader r = w.getReader();
-
-    FacetsCollector fc = new FacetsCollector();
-
-    IndexSearcher s = newSearcher(r);
-    s.search(new MatchAllDocsQuery(), fc);
-    Facets facets = new RangeFacetCounts("field", fc,
-        new DoubleRange("less than 10", 0.0, true, 10.0, false),
-        new DoubleRange("less than or equal to 10", 0.0, true, 10.0, true),
-        new DoubleRange("over 90", 90.0, false, 100.0, false),
-        new DoubleRange("90 or above", 90.0, true, 100.0, false),
-        new DoubleRange("over 1000", 1000.0, false, Double.POSITIVE_INFINITY, false));
-                                         
-    assertEquals("value=100 childCount=5\n  less than 10 (10)\n  less than or equal to 10 (11)\n  over 90 (9)\n  90 or above (10)\n  over 1000 (0)\n",
-                 facets.getTopChildren(10, "field").toString());
-
-    IOUtils.close(w, r, d);
-  }
-
-  public void testBasicFloat() throws Exception {
-    Directory d = newDirectory();
-    RandomIndexWriter w = new RandomIndexWriter(random(), d);
-    Document doc = new Document();
-    FloatDocValuesField field = new FloatDocValuesField("field", 0.0f);
-    doc.add(field);
-    for(long l=0;l<100;l++) {
-      field.setFloatValue(l);
-      w.addDocument(doc);
-    }
-
-    IndexReader r = w.getReader();
-
-    FacetsCollector fc = new FacetsCollector();
-
-    IndexSearcher s = newSearcher(r);
-    s.search(new MatchAllDocsQuery(), fc);
-
-    Facets facets = new RangeFacetCounts("field", fc,
-        new FloatRange("less than 10", 0.0f, true, 10.0f, false),
-        new FloatRange("less than or equal to 10", 0.0f, true, 10.0f, true),
-        new FloatRange("over 90", 90.0f, false, 100.0f, false),
-        new FloatRange("90 or above", 90.0f, true, 100.0f, false),
-        new FloatRange("over 1000", 1000.0f, false, Float.POSITIVE_INFINITY, false));
-    
-    assertEquals("value=100 childCount=5\n  less than 10 (10)\n  less than or equal to 10 (11)\n  over 90 (9)\n  90 or above (10)\n  over 1000 (0)\n",
-                 facets.getTopChildren(10, "field").toString());
-    
-    IOUtils.close(w, r, d);
-  }
-
-  public void testRandomLongs() throws Exception {
-    Directory dir = newDirectory();
-    RandomIndexWriter w = new RandomIndexWriter(random(), dir);
-
-    int numDocs = atLeast(1000);
-    long[] values = new long[numDocs];
-    for(int i=0;i<numDocs;i++) {
-      Document doc = new Document();
-      long v = random().nextLong();
-      values[i] = v;
-      doc.add(new NumericDocValuesField("field", v));
-      doc.add(new LongField("field", v, Field.Store.NO));
-      w.addDocument(doc);
-    }
-    IndexReader r = w.getReader();
-
-    IndexSearcher s = newSearcher(r);
-    FacetsConfig config = new FacetsConfig();
-    
-    int numIters = atLeast(10);
-    for(int iter=0;iter<numIters;iter++) {
-      if (VERBOSE) {
-        System.out.println("TEST: iter=" + iter);
-      }
-      int numRange = _TestUtil.nextInt(random(), 1, 5);
-      LongRange[] ranges = new LongRange[numRange];
-      int[] expectedCounts = new int[numRange];
-      for(int rangeID=0;rangeID<numRange;rangeID++) {
-        long min = random().nextLong();
-        long max = random().nextLong();
-        if (min > max) {
-          long x = min;
-          min = max;
-          max = x;
-        }
-        boolean minIncl = random().nextBoolean();
-        boolean maxIncl = random().nextBoolean();
-        ranges[rangeID] = new LongRange("r" + rangeID, min, minIncl, max, maxIncl);
-
-        // Do "slow but hopefully correct" computation of
-        // expected count:
-        for(int i=0;i<numDocs;i++) {
-          boolean accept = true;
-          if (minIncl) {
-            accept &= values[i] >= min;
-          } else {
-            accept &= values[i] > min;
-          }
-          if (maxIncl) {
-            accept &= values[i] <= max;
-          } else {
-            accept &= values[i] < max;
-          }
-          if (accept) {
-            expectedCounts[rangeID]++;
-          }
-        }
-      }
-
-      FacetsCollector sfc = new FacetsCollector();
-      s.search(new MatchAllDocsQuery(), sfc);
-      Facets facets = new RangeFacetCounts("field", sfc, ranges);
-      FacetResult result = facets.getTopChildren(10, "field");
-      assertEquals(numRange, result.labelValues.length);
-      for(int rangeID=0;rangeID<numRange;rangeID++) {
-        if (VERBOSE) {
-          System.out.println("  range " + rangeID + " expectedCount=" + expectedCounts[rangeID]);
-        }
-        LabelAndValue subNode = result.labelValues[rangeID];
-        assertEquals("r" + rangeID, subNode.label);
-        assertEquals(expectedCounts[rangeID], subNode.value.intValue());
-
-        LongRange range = ranges[rangeID];
-
-        // Test drill-down:
-        DrillDownQuery ddq = new DrillDownQuery(config);
-        ddq.add("field", NumericRangeQuery.newLongRange("field", range.min, range.max, range.minInclusive, range.maxInclusive));
-        assertEquals(expectedCounts[rangeID], s.search(ddq, 10).totalHits);
-      }
-    }
-
-    IOUtils.close(w, r, dir);
-  }
-
-  public void testRandomFloats() throws Exception {
-    Directory dir = newDirectory();
-    RandomIndexWriter w = new RandomIndexWriter(random(), dir);
-
-    int numDocs = atLeast(1000);
-    float[] values = new float[numDocs];
-    for(int i=0;i<numDocs;i++) {
-      Document doc = new Document();
-      float v = random().nextFloat();
-      values[i] = v;
-      doc.add(new FloatDocValuesField("field", v));
-      doc.add(new FloatField("field", v, Field.Store.NO));
-      w.addDocument(doc);
-    }
-    IndexReader r = w.getReader();
-
-    IndexSearcher s = newSearcher(r);
-    FacetsConfig config = new FacetsConfig();
-    
-    int numIters = atLeast(10);
-    for(int iter=0;iter<numIters;iter++) {
-      if (VERBOSE) {
-        System.out.println("TEST: iter=" + iter);
-      }
-      int numRange = _TestUtil.nextInt(random(), 1, 5);
-      FloatRange[] ranges = new FloatRange[numRange];
-      int[] expectedCounts = new int[numRange];
-      for(int rangeID=0;rangeID<numRange;rangeID++) {
-        float min = random().nextFloat();
-        float max = random().nextFloat();
-        if (min > max) {
-          float x = min;
-          min = max;
-          max = x;
-        }
-        boolean minIncl = random().nextBoolean();
-        boolean maxIncl = random().nextBoolean();
-        ranges[rangeID] = new FloatRange("r" + rangeID, min, minIncl, max, maxIncl);
-
-        // Do "slow but hopefully correct" computation of
-        // expected count:
-        for(int i=0;i<numDocs;i++) {
-          boolean accept = true;
-          if (minIncl) {
-            accept &= values[i] >= min;
-          } else {
-            accept &= values[i] > min;
-          }
-          if (maxIncl) {
-            accept &= values[i] <= max;
-          } else {
-            accept &= values[i] < max;
-          }
-          if (accept) {
-            expectedCounts[rangeID]++;
-          }
-        }
-      }
-
-      FacetsCollector sfc = new FacetsCollector();
-      s.search(new MatchAllDocsQuery(), sfc);
-      Facets facets = new RangeFacetCounts("field", sfc, ranges);
-      FacetResult result = facets.getTopChildren(10, "field");
-      assertEquals(numRange, result.labelValues.length);
-      for(int rangeID=0;rangeID<numRange;rangeID++) {
-        if (VERBOSE) {
-          System.out.println("  range " + rangeID + " expectedCount=" + expectedCounts[rangeID]);
-        }
-        LabelAndValue subNode = result.labelValues[rangeID];
-        assertEquals("r" + rangeID, subNode.label);
-        assertEquals(expectedCounts[rangeID], subNode.value.intValue());
-
-        FloatRange range = ranges[rangeID];
-
-        // Test drill-down:
-        DrillDownQuery ddq = new DrillDownQuery(config);
-        ddq.add("field", NumericRangeQuery.newFloatRange("field", range.min, range.max, range.minInclusive, range.maxInclusive));
-        assertEquals(expectedCounts[rangeID], s.search(ddq, 10).totalHits);
-      }
-    }
-
-    IOUtils.close(w, r, dir);
-  }
-
-  public void testRandomDoubles() throws Exception {
-    Directory dir = newDirectory();
-    RandomIndexWriter w = new RandomIndexWriter(random(), dir);
-
-    int numDocs = atLeast(1000);
-    double[] values = new double[numDocs];
-    for(int i=0;i<numDocs;i++) {
-      Document doc = new Document();
-      double v = random().nextDouble();
-      values[i] = v;
-      doc.add(new DoubleDocValuesField("field", v));
-      doc.add(new DoubleField("field", v, Field.Store.NO));
-      w.addDocument(doc);
-    }
-    IndexReader r = w.getReader();
-
-    IndexSearcher s = newSearcher(r);
-    FacetsConfig config = new FacetsConfig();
-    
-    int numIters = atLeast(10);
-    for(int iter=0;iter<numIters;iter++) {
-      if (VERBOSE) {
-        System.out.println("TEST: iter=" + iter);
-      }
-      int numRange = _TestUtil.nextInt(random(), 1, 5);
-      DoubleRange[] ranges = new DoubleRange[numRange];
-      int[] expectedCounts = new int[numRange];
-      for(int rangeID=0;rangeID<numRange;rangeID++) {
-        double min = random().nextDouble();
-        double max = random().nextDouble();
-        if (min > max) {
-          double x = min;
-          min = max;
-          max = x;
-        }
-        boolean minIncl = random().nextBoolean();
-        boolean maxIncl = random().nextBoolean();
-        ranges[rangeID] = new DoubleRange("r" + rangeID, min, minIncl, max, maxIncl);
-
-        // Do "slow but hopefully correct" computation of
-        // expected count:
-        for(int i=0;i<numDocs;i++) {
-          boolean accept = true;
-          if (minIncl) {
-            accept &= values[i] >= min;
-          } else {
-            accept &= values[i] > min;
-          }
-          if (maxIncl) {
-            accept &= values[i] <= max;
-          } else {
-            accept &= values[i] < max;
-          }
-          if (accept) {
-            expectedCounts[rangeID]++;
-          }
-        }
-      }
-
-      FacetsCollector sfc = new FacetsCollector();
-      s.search(new MatchAllDocsQuery(), sfc);
-      Facets facets = new RangeFacetCounts("field", sfc, ranges);
-      FacetResult result = facets.getTopChildren(10, "field");
-      assertEquals(numRange, result.labelValues.length);
-      for(int rangeID=0;rangeID<numRange;rangeID++) {
-        if (VERBOSE) {
-          System.out.println("  range " + rangeID + " expectedCount=" + expectedCounts[rangeID]);
-        }
-        LabelAndValue subNode = result.labelValues[rangeID];
-        assertEquals("r" + rangeID, subNode.label);
-        assertEquals(expectedCounts[rangeID], subNode.value.intValue());
-
-        DoubleRange range = ranges[rangeID];
-
-        // Test drill-down:
-        DrillDownQuery ddq = new DrillDownQuery(config);
-        ddq.add("field", NumericRangeQuery.newDoubleRange("field", range.min, range.max, range.minInclusive, range.maxInclusive));
-        assertEquals(expectedCounts[rangeID], s.search(ddq, 10).totalHits);
-      }
-    }
-
-    IOUtils.close(w, r, dir);
-  }
-
-  // LUCENE-5178
-  public void testMissingValues() throws Exception {
-    assumeTrue("codec does not support docsWithField", defaultCodecSupportsDocsWithField());
-    Directory d = newDirectory();
-    RandomIndexWriter w = new RandomIndexWriter(random(), d);
-    Document doc = new Document();
-    NumericDocValuesField field = new NumericDocValuesField("field", 0L);
-    doc.add(field);
-    for(long l=0;l<100;l++) {
-      if (l % 5 == 0) {
-        // Every 5th doc is missing the value:
-        w.addDocument(new Document());
-        continue;
-      }
-      field.setLongValue(l);
-      w.addDocument(doc);
-    }
-
-    IndexReader r = w.getReader();
-
-    FacetsCollector sfc = new FacetsCollector();
-
-    IndexSearcher s = newSearcher(r);
-    s.search(new MatchAllDocsQuery(), sfc);
-    Facets facets = new RangeFacetCounts("field", sfc,
-        new LongRange("less than 10", 0L, true, 10L, false),
-        new LongRange("less than or equal to 10", 0L, true, 10L, true),
-        new LongRange("over 90", 90L, false, 100L, false),
-        new LongRange("90 or above", 90L, true, 100L, false),
-        new LongRange("over 1000", 1000L, false, Long.MAX_VALUE, false));
-    
-    assertEquals("value=100 childCount=5\n  less than 10 (8)\n  less than or equal to 10 (8)\n  over 90 (8)\n  90 or above (8)\n  over 1000 (0)\n",
-                 facets.getTopChildren(10, "field").toString());
-
-    IOUtils.close(w, r, d);
-  }
-}
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/TestSearcherTaxonomyManager.java b/lucene/facet/src/test/org/apache/lucene/facet/TestSearcherTaxonomyManager.java
index b3fe6cb..ef41b6a 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/TestSearcherTaxonomyManager.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/TestSearcherTaxonomyManager.java
@@ -26,9 +26,7 @@ import java.util.concurrent.atomic.AtomicBoolean;
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
-import org.apache.lucene.facet.FacetTestCase;
 import org.apache.lucene.facet.SearcherTaxonomyManager.SearcherAndTaxonomy;
-import org.apache.lucene.facet.taxonomy.FacetLabel;
 import org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyWriter;
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.search.MatchAllDocsQuery;
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/TestTaxonomyFacetAssociations.java b/lucene/facet/src/test/org/apache/lucene/facet/TestTaxonomyFacetAssociations.java
index 730a483..8fb3384 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/TestTaxonomyFacetAssociations.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/TestTaxonomyFacetAssociations.java
@@ -19,7 +19,6 @@ package org.apache.lucene.facet;
 
 
 import org.apache.lucene.document.Document;
-import org.apache.lucene.facet.taxonomy.FacetLabel;
 import org.apache.lucene.facet.taxonomy.TaxonomyReader;
 import org.apache.lucene.facet.taxonomy.TaxonomyWriter;
 import org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyReader;
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/TestTaxonomyFacetCounts2.java b/lucene/facet/src/test/org/apache/lucene/facet/TestTaxonomyFacetCounts2.java
index 6f775fb..0d0f288 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/TestTaxonomyFacetCounts2.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/TestTaxonomyFacetCounts2.java
@@ -30,14 +30,11 @@ import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field.Store;
 import org.apache.lucene.document.StringField;
-import org.apache.lucene.facet.FacetTestCase;
-import org.apache.lucene.facet.taxonomy.FacetLabel;
 import org.apache.lucene.facet.taxonomy.TaxonomyReader;
 import org.apache.lucene.facet.taxonomy.TaxonomyWriter;
 import org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyReader;
 import org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyWriter;
 import org.apache.lucene.index.DirectoryReader;
-import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.IndexWriterConfig;
 import org.apache.lucene.index.NoMergePolicy;
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/TestTaxonomyFacetSumValueSource.java b/lucene/facet/src/test/org/apache/lucene/facet/TestTaxonomyFacetSumValueSource.java
index cdbd2c4..72cda32 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/TestTaxonomyFacetSumValueSource.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/TestTaxonomyFacetSumValueSource.java
@@ -17,15 +17,9 @@ package org.apache.lucene.facet;
  * limitations under the License.
  */
 
-import java.io.ByteArrayOutputStream;
 import java.io.IOException;
-import java.io.PrintStream;
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
-import java.util.Set;
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
@@ -33,11 +27,7 @@ import org.apache.lucene.document.Field;
 import org.apache.lucene.document.IntField;
 import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.document.StringField;
-import org.apache.lucene.facet.FacetTestCase;
-import org.apache.lucene.facet.taxonomy.FacetLabel;
-import org.apache.lucene.facet.taxonomy.PrintTaxonomyStats;
 import org.apache.lucene.facet.taxonomy.TaxonomyReader;
-import org.apache.lucene.facet.taxonomy.TaxonomyWriter;
 import org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyReader;
 import org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyWriter;
 import org.apache.lucene.index.AtomicReaderContext;
@@ -51,22 +41,15 @@ import org.apache.lucene.queries.function.ValueSource;
 import org.apache.lucene.queries.function.docvalues.DoubleDocValues;
 import org.apache.lucene.queries.function.valuesource.IntFieldSource;
 import org.apache.lucene.queries.function.valuesource.LongFieldSource;
-import org.apache.lucene.queries.function.valuesource.QueryValueSource;
 import org.apache.lucene.search.ConstantScoreQuery;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.MatchAllDocsQuery;
-import org.apache.lucene.search.MultiCollector;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.Scorer;
 import org.apache.lucene.search.TopDocs;
 import org.apache.lucene.search.TopScoreDocCollector;
-import org.apache.lucene.search.similarities.DefaultSimilarity;
-import org.apache.lucene.search.similarities.PerFieldSimilarityWrapper;
-import org.apache.lucene.search.similarities.Similarity;
 import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IOUtils;
-import org.apache.lucene.util._TestUtil;
 
 public class TestTaxonomyFacetSumValueSource extends FacetTestCase {
 
@@ -122,8 +105,8 @@ public class TestTaxonomyFacetSumValueSource extends FacetTestCase {
 
     // MatchAllDocsQuery is for "browsing" (counts facets
     // for all non-deleted docs in the index); normally
-    // you'd use a "normal" query, and use MultiCollector to
-    // wrap collecting the "normal" hits and also facets:
+    // you'd use a "normal" query and one of the
+    // Facets.search utility methods:
     searcher.search(new MatchAllDocsQuery(), c);
 
     TaxonomyFacetSumValueSource facets = new TaxonomyFacetSumValueSource(taxoReader, new FacetsConfig(), c, new IntFieldSource("num"));
@@ -274,15 +257,13 @@ public class TestTaxonomyFacetSumValueSource extends FacetTestCase {
     DirectoryTaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);
     
     FacetsCollector fc = new FacetsCollector(true);
-    TopScoreDocCollector topDocs = TopScoreDocCollector.create(10, false);
     ConstantScoreQuery csq = new ConstantScoreQuery(new MatchAllDocsQuery());
     csq.setBoost(2.0f);
     
-    newSearcher(r).search(csq, MultiCollector.wrap(fc, topDocs));
+    TopDocs td = Facets.search(newSearcher(r), csq, 10, fc);
 
     Facets facets = new TaxonomyFacetSumValueSource(taxoReader, config, fc, new TaxonomyFacetSumValueSource.ScoreValueSource());
     
-    TopDocs td = topDocs.topDocs();
     int expected = (int) (td.getMaxScore() * td.totalHits);
     assertEquals(expected, facets.getSpecificValue("dim", "a").intValue());
     
@@ -354,12 +335,12 @@ public class TestTaxonomyFacetSumValueSource extends FacetTestCase {
       @Override public String description() { return "score()"; }
     };
     
-    FacetsCollector sfc = new FacetsCollector(true);
+    FacetsCollector fc = new FacetsCollector(true);
     TopScoreDocCollector tsdc = TopScoreDocCollector.create(10, true);
     // score documents by their 'price' field - makes asserting the correct counts for the categories easier
     Query q = new FunctionQuery(new LongFieldSource("price"));
-    newSearcher(r).search(q, MultiCollector.wrap(tsdc, sfc));
-    Facets facets = new TaxonomyFacetSumValueSource(taxoReader, config, sfc, valueSource);
+    Facets.search(newSearcher(r), q, 10, fc);
+    Facets facets = new TaxonomyFacetSumValueSource(taxoReader, config, fc, valueSource);
     
     assertEquals("value=10.0 childCount=2\n  1 (6.0)\n  0 (4.0)\n", facets.getTopChildren(10, "a").toString());
     
@@ -416,15 +397,14 @@ public class TestTaxonomyFacetSumValueSource extends FacetTestCase {
     DirectoryReader r = DirectoryReader.open(iw, true);
     DirectoryTaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);
     
-    FacetsCollector sfc = new FacetsCollector(true);
-    TopScoreDocCollector topDocs = TopScoreDocCollector.create(10, false);
-    newSearcher(r).search(new MatchAllDocsQuery(), MultiCollector.wrap(sfc, topDocs));
+    FacetsCollector fc = new FacetsCollector(true);
+    TopDocs hits = Facets.search(newSearcher(r), new MatchAllDocsQuery(), 10, fc);
     
-    Facets facets1 = getTaxonomyFacetCounts(taxoReader, config, sfc);
-    Facets facets2 = new TaxonomyFacetSumValueSource(new DocValuesOrdinalsReader("$b"), taxoReader, config, sfc, new TaxonomyFacetSumValueSource.ScoreValueSource());
+    Facets facets1 = getTaxonomyFacetCounts(taxoReader, config, fc);
+    Facets facets2 = new TaxonomyFacetSumValueSource(new DocValuesOrdinalsReader("$b"), taxoReader, config, fc, new TaxonomyFacetSumValueSource.ScoreValueSource());
 
     assertEquals(r.maxDoc(), facets1.getTopChildren(10, "a").value.intValue());
-    double expected = topDocs.topDocs().getMaxScore() * r.numDocs();
+    double expected = hits.getMaxScore() * r.numDocs();
     assertEquals(r.maxDoc(), facets2.getTopChildren(10, "b").value.doubleValue(), 1E-10);
     IOUtils.close(taxoWriter, iw, taxoReader, taxoDir, r, indexDir);
   }
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestCategoryPath.java b/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestCategoryPath.java
deleted file mode 100644
index 6dca6c3..0000000
--- a/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestCategoryPath.java
+++ /dev/null
@@ -1,306 +0,0 @@
-package org.apache.lucene.facet.taxonomy;
-
-import java.util.Arrays;
-
-import org.apache.lucene.facet.FacetTestCase;
-import org.apache.lucene.util._TestUtil;
-import org.junit.Test;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-public class TestCategoryPath extends FacetTestCase {
-  
-  @Test 
-  public void testBasic() {
-    assertEquals(0, FacetLabel.EMPTY.length);
-    assertEquals(1, new FacetLabel("hello").length);
-    assertEquals(2, new FacetLabel("hello", "world").length);
-  }
-  
-  @Test 
-  public void testToString() {
-    // When the category is empty, we expect an empty string
-    assertEquals("", FacetLabel.EMPTY.toString('/'));
-    // one category (so no delimiter needed)
-    assertEquals("hello", new FacetLabel("hello").toString('/'));
-    // more than one category (so no delimiter needed)
-    assertEquals("hello/world", new FacetLabel("hello", "world").toString('/'));
-  }
-
-  @Test 
-  public void testGetComponent() {
-    String[] components = new String[atLeast(10)];
-    for (int i = 0; i < components.length; i++) {
-      components[i] = Integer.toString(i);
-    }
-    FacetLabel cp = new FacetLabel(components);
-    for (int i = 0; i < components.length; i++) {
-      assertEquals(i, Integer.parseInt(cp.components[i]));
-    }
-  }
-
-  @Test
-  public void testDelimiterConstructor() {
-    FacetLabel p = new FacetLabel("", '/');
-    assertEquals(0, p.length);
-    p = new FacetLabel("hello", '/');
-    assertEquals(p.length, 1);
-    assertEquals(p.toString('@'), "hello");
-    p = new FacetLabel("hi/there", '/');
-    assertEquals(p.length, 2);
-    assertEquals(p.toString('@'), "hi@there");
-    p = new FacetLabel("how/are/you/doing?", '/');
-    assertEquals(p.length, 4);
-    assertEquals(p.toString('@'), "how@are@you@doing?");
-  }
-  
-  @Test
-  public void testDefaultConstructor() {
-    // test that the default constructor (no parameters) currently
-    // defaults to creating an object with a 0 initial capacity.
-    // If we change this default later, we also need to change this
-    // test.
-    FacetLabel p = FacetLabel.EMPTY;
-    assertEquals(0, p.length);
-    assertEquals("", p.toString('/'));
-  }
-  
-  @Test 
-  public void testSubPath() {
-    final FacetLabel p = new FacetLabel("hi", "there", "man");
-    assertEquals(p.length, 3);
-    
-    FacetLabel p1 = p.subpath(2);
-    assertEquals(2, p1.length);
-    assertEquals("hi/there", p1.toString('/'));
-
-    p1 = p.subpath(1);
-    assertEquals(1, p1.length);
-    assertEquals("hi", p1.toString('/'));
-
-    p1 = p.subpath(0);
-    assertEquals(0, p1.length);
-    assertEquals("", p1.toString('/'));
-
-    // with all the following lengths, the prefix should be the whole path 
-    int[] lengths = { 3, -1, 4 };
-    for (int i = 0; i < lengths.length; i++) {
-      p1 = p.subpath(lengths[i]);
-      assertEquals(3, p1.length);
-      assertEquals("hi/there/man", p1.toString('/'));
-      assertEquals(p, p1);
-    }
-  }
-
-  @Test 
-  public void testEquals() {
-    assertEquals(FacetLabel.EMPTY, FacetLabel.EMPTY);
-    assertFalse(FacetLabel.EMPTY.equals(new FacetLabel("hi")));
-    assertFalse(FacetLabel.EMPTY.equals(Integer.valueOf(3)));
-    assertEquals(new FacetLabel("hello", "world"), new FacetLabel("hello", "world"));    
-  }
-  
-  @Test 
-  public void testHashCode() {
-    assertEquals(FacetLabel.EMPTY.hashCode(), FacetLabel.EMPTY.hashCode());
-    assertFalse(FacetLabel.EMPTY.hashCode() == new FacetLabel("hi").hashCode());
-    assertEquals(new FacetLabel("hello", "world").hashCode(), new FacetLabel("hello", "world").hashCode());
-  }
-  
-  @Test 
-  public void testLongHashCode() {
-    assertEquals(FacetLabel.EMPTY.longHashCode(), FacetLabel.EMPTY.longHashCode());
-    assertFalse(FacetLabel.EMPTY.longHashCode() == new FacetLabel("hi").longHashCode());
-    assertEquals(new FacetLabel("hello", "world").longHashCode(), new FacetLabel("hello", "world").longHashCode());
-  }
-  
-  @Test 
-  public void testArrayConstructor() {
-    FacetLabel p = new FacetLabel("hello", "world", "yo");
-    assertEquals(3, p.length);
-    assertEquals("hello/world/yo", p.toString('/'));
-  }
-  
-  @Test 
-  public void testCharsNeededForFullPath() {
-    assertEquals(0, FacetLabel.EMPTY.fullPathLength());
-    String[] components = { "hello", "world", "yo" };
-    FacetLabel cp = new FacetLabel(components);
-    int expectedCharsNeeded = 0;
-    for (String comp : components) {
-      expectedCharsNeeded += comp.length();
-    }
-    expectedCharsNeeded += cp.length - 1; // delimiter chars
-    assertEquals(expectedCharsNeeded, cp.fullPathLength());
-  }
-  
-  @Test 
-  public void testCopyToCharArray() {
-    FacetLabel p = new FacetLabel("hello", "world", "yo");
-    char[] charArray = new char[p.fullPathLength()];
-    int numCharsCopied = p.copyFullPath(charArray, 0, '.');
-    assertEquals(p.fullPathLength(), numCharsCopied);
-    assertEquals("hello.world.yo", new String(charArray, 0, numCharsCopied));
-  }
-  
-  @Test 
-  public void testCompareTo() {
-    FacetLabel p = new FacetLabel("a/b/c/d", '/');
-    FacetLabel pother = new FacetLabel("a/b/c/d", '/');
-    assertEquals(0, pother.compareTo(p));
-    assertEquals(0, p.compareTo(pother));
-    pother = new FacetLabel("", '/');
-    assertTrue(pother.compareTo(p) < 0);
-    assertTrue(p.compareTo(pother) > 0);
-    pother = new FacetLabel("a/b_/c/d", '/');
-    assertTrue(pother.compareTo(p) > 0);
-    assertTrue(p.compareTo(pother) < 0);
-    pother = new FacetLabel("a/b/c", '/');
-    assertTrue(pother.compareTo(p) < 0);
-    assertTrue(p.compareTo(pother) > 0);
-    pother = new FacetLabel("a/b/c/e", '/');
-    assertTrue(pother.compareTo(p) > 0);
-    assertTrue(p.compareTo(pother) < 0);
-  }
-
-  @Test
-  public void testEmptyNullComponents() throws Exception {
-    // LUCENE-4724: CategoryPath should not allow empty or null components
-    String[][] components_tests = new String[][] {
-      new String[] { "", "test" }, // empty in the beginning
-      new String[] { "test", "" }, // empty in the end
-      new String[] { "test", "", "foo" }, // empty in the middle
-      new String[] { null, "test" }, // null at the beginning
-      new String[] { "test", null }, // null in the end
-      new String[] { "test", null, "foo" }, // null in the middle
-    };
-
-    for (String[] components : components_tests) {
-      try {
-        assertNotNull(new FacetLabel(components));
-        fail("empty or null components should not be allowed: " + Arrays.toString(components));
-      } catch (IllegalArgumentException e) {
-        // ok
-      }
-    }
-    
-    String[] path_tests = new String[] {
-        "/test", // empty in the beginning
-        "test//foo", // empty in the middle
-    };
-    
-    for (String path : path_tests) {
-      try {
-        assertNotNull(new FacetLabel(path, '/'));
-        fail("empty or null components should not be allowed: " + path);
-      } catch (IllegalArgumentException e) {
-        // ok
-      }
-    }
-
-    // a trailing path separator is produces only one component
-    assertNotNull(new FacetLabel("test/", '/'));
-    
-  }
-
-  @Test
-  public void testInvalidDelimChar() throws Exception {
-    // Make sure CategoryPath doesn't silently corrupt:
-    char[] buf = new char[100];
-    FacetLabel cp = new FacetLabel("foo/bar");
-    try {
-      cp.toString();
-      fail("expected exception");
-    } catch (IllegalArgumentException iae) {
-      // expected
-    }
-    try {
-      cp.copyFullPath(buf, 0, '/');
-      fail("expected exception");
-    } catch (IllegalArgumentException iae) {
-      // expected
-    }
-    cp = new FacetLabel("abc", "foo/bar");
-    try {
-      cp.toString();
-      fail("expected exception");
-    } catch (IllegalArgumentException iae) {
-      // expected
-    }
-    try {
-      cp.copyFullPath(buf, 0, '/');
-      fail("expected exception");
-    } catch (IllegalArgumentException iae) {
-      // expected
-    }
-    cp = new FacetLabel("foo:bar");
-    try {
-      cp.toString(':');
-      fail("expected exception");
-    } catch (IllegalArgumentException iae) {
-      // expected
-    }
-    try {
-      cp.copyFullPath(buf, 0, ':');
-      fail("expected exception");
-    } catch (IllegalArgumentException iae) {
-      // expected
-    }
-    cp = new FacetLabel("abc", "foo:bar");
-    try {
-      cp.toString(':');
-      fail("expected exception");
-    } catch (IllegalArgumentException iae) {
-      // expected
-    }
-    try {
-      cp.copyFullPath(buf, 0, ':');
-      fail("expected exception");
-    } catch (IllegalArgumentException iae) {
-      // expected
-    }
-  }
-
-  @Test
-  public void testLongPath() throws Exception {
-    String bigComp = null;
-    while (true) {
-      int len = FacetLabel.MAX_CATEGORY_PATH_LENGTH;
-      bigComp = _TestUtil.randomSimpleString(random(), len, len);
-      if (bigComp.indexOf('\u001f') != -1) {
-        continue;
-      }
-      break;
-    }
-
-    try {
-      assertNotNull(new FacetLabel("dim", bigComp));
-      fail("long paths should not be allowed; len=" + bigComp.length());
-    } catch (IllegalArgumentException e) {
-      // expected
-    }
-
-    try {
-      assertNotNull(new FacetLabel("dim\u001f" + bigComp, '\u001f'));
-      fail("long paths should not be allowed; len=" + bigComp.length());
-    } catch (IllegalArgumentException e) {
-      // expected
-    }
-  }
-  
-}
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestFacetLabel.java b/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestFacetLabel.java
new file mode 100644
index 0000000..85abea0
--- /dev/null
+++ b/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestFacetLabel.java
@@ -0,0 +1,306 @@
+package org.apache.lucene.facet.taxonomy;
+
+import java.util.Arrays;
+
+import org.apache.lucene.facet.FacetTestCase;
+import org.apache.lucene.util._TestUtil;
+import org.junit.Test;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+public class TestFacetLabel extends FacetTestCase {
+  
+  @Test 
+  public void testBasic() {
+    assertEquals(0, FacetLabel.EMPTY.length);
+    assertEquals(1, new FacetLabel("hello").length);
+    assertEquals(2, new FacetLabel("hello", "world").length);
+  }
+  
+  @Test 
+  public void testToString() {
+    // When the category is empty, we expect an empty string
+    assertEquals("", FacetLabel.EMPTY.toString('/'));
+    // one category (so no delimiter needed)
+    assertEquals("hello", new FacetLabel("hello").toString('/'));
+    // more than one category (so no delimiter needed)
+    assertEquals("hello/world", new FacetLabel("hello", "world").toString('/'));
+  }
+
+  @Test 
+  public void testGetComponent() {
+    String[] components = new String[atLeast(10)];
+    for (int i = 0; i < components.length; i++) {
+      components[i] = Integer.toString(i);
+    }
+    FacetLabel cp = new FacetLabel(components);
+    for (int i = 0; i < components.length; i++) {
+      assertEquals(i, Integer.parseInt(cp.components[i]));
+    }
+  }
+
+  @Test
+  public void testDelimiterConstructor() {
+    FacetLabel p = new FacetLabel("", '/');
+    assertEquals(0, p.length);
+    p = new FacetLabel("hello", '/');
+    assertEquals(p.length, 1);
+    assertEquals(p.toString('@'), "hello");
+    p = new FacetLabel("hi/there", '/');
+    assertEquals(p.length, 2);
+    assertEquals(p.toString('@'), "hi@there");
+    p = new FacetLabel("how/are/you/doing?", '/');
+    assertEquals(p.length, 4);
+    assertEquals(p.toString('@'), "how@are@you@doing?");
+  }
+  
+  @Test
+  public void testDefaultConstructor() {
+    // test that the default constructor (no parameters) currently
+    // defaults to creating an object with a 0 initial capacity.
+    // If we change this default later, we also need to change this
+    // test.
+    FacetLabel p = FacetLabel.EMPTY;
+    assertEquals(0, p.length);
+    assertEquals("", p.toString('/'));
+  }
+  
+  @Test 
+  public void testSubPath() {
+    final FacetLabel p = new FacetLabel("hi", "there", "man");
+    assertEquals(p.length, 3);
+    
+    FacetLabel p1 = p.subpath(2);
+    assertEquals(2, p1.length);
+    assertEquals("hi/there", p1.toString('/'));
+
+    p1 = p.subpath(1);
+    assertEquals(1, p1.length);
+    assertEquals("hi", p1.toString('/'));
+
+    p1 = p.subpath(0);
+    assertEquals(0, p1.length);
+    assertEquals("", p1.toString('/'));
+
+    // with all the following lengths, the prefix should be the whole path 
+    int[] lengths = { 3, -1, 4 };
+    for (int i = 0; i < lengths.length; i++) {
+      p1 = p.subpath(lengths[i]);
+      assertEquals(3, p1.length);
+      assertEquals("hi/there/man", p1.toString('/'));
+      assertEquals(p, p1);
+    }
+  }
+
+  @Test 
+  public void testEquals() {
+    assertEquals(FacetLabel.EMPTY, FacetLabel.EMPTY);
+    assertFalse(FacetLabel.EMPTY.equals(new FacetLabel("hi")));
+    assertFalse(FacetLabel.EMPTY.equals(Integer.valueOf(3)));
+    assertEquals(new FacetLabel("hello", "world"), new FacetLabel("hello", "world"));    
+  }
+  
+  @Test 
+  public void testHashCode() {
+    assertEquals(FacetLabel.EMPTY.hashCode(), FacetLabel.EMPTY.hashCode());
+    assertFalse(FacetLabel.EMPTY.hashCode() == new FacetLabel("hi").hashCode());
+    assertEquals(new FacetLabel("hello", "world").hashCode(), new FacetLabel("hello", "world").hashCode());
+  }
+  
+  @Test 
+  public void testLongHashCode() {
+    assertEquals(FacetLabel.EMPTY.longHashCode(), FacetLabel.EMPTY.longHashCode());
+    assertFalse(FacetLabel.EMPTY.longHashCode() == new FacetLabel("hi").longHashCode());
+    assertEquals(new FacetLabel("hello", "world").longHashCode(), new FacetLabel("hello", "world").longHashCode());
+  }
+  
+  @Test 
+  public void testArrayConstructor() {
+    FacetLabel p = new FacetLabel("hello", "world", "yo");
+    assertEquals(3, p.length);
+    assertEquals("hello/world/yo", p.toString('/'));
+  }
+  
+  @Test 
+  public void testCharsNeededForFullPath() {
+    assertEquals(0, FacetLabel.EMPTY.fullPathLength());
+    String[] components = { "hello", "world", "yo" };
+    FacetLabel cp = new FacetLabel(components);
+    int expectedCharsNeeded = 0;
+    for (String comp : components) {
+      expectedCharsNeeded += comp.length();
+    }
+    expectedCharsNeeded += cp.length - 1; // delimiter chars
+    assertEquals(expectedCharsNeeded, cp.fullPathLength());
+  }
+  
+  @Test 
+  public void testCopyToCharArray() {
+    FacetLabel p = new FacetLabel("hello", "world", "yo");
+    char[] charArray = new char[p.fullPathLength()];
+    int numCharsCopied = p.copyFullPath(charArray, 0, '.');
+    assertEquals(p.fullPathLength(), numCharsCopied);
+    assertEquals("hello.world.yo", new String(charArray, 0, numCharsCopied));
+  }
+  
+  @Test 
+  public void testCompareTo() {
+    FacetLabel p = new FacetLabel("a/b/c/d", '/');
+    FacetLabel pother = new FacetLabel("a/b/c/d", '/');
+    assertEquals(0, pother.compareTo(p));
+    assertEquals(0, p.compareTo(pother));
+    pother = new FacetLabel("", '/');
+    assertTrue(pother.compareTo(p) < 0);
+    assertTrue(p.compareTo(pother) > 0);
+    pother = new FacetLabel("a/b_/c/d", '/');
+    assertTrue(pother.compareTo(p) > 0);
+    assertTrue(p.compareTo(pother) < 0);
+    pother = new FacetLabel("a/b/c", '/');
+    assertTrue(pother.compareTo(p) < 0);
+    assertTrue(p.compareTo(pother) > 0);
+    pother = new FacetLabel("a/b/c/e", '/');
+    assertTrue(pother.compareTo(p) > 0);
+    assertTrue(p.compareTo(pother) < 0);
+  }
+
+  @Test
+  public void testEmptyNullComponents() throws Exception {
+    // LUCENE-4724: CategoryPath should not allow empty or null components
+    String[][] components_tests = new String[][] {
+      new String[] { "", "test" }, // empty in the beginning
+      new String[] { "test", "" }, // empty in the end
+      new String[] { "test", "", "foo" }, // empty in the middle
+      new String[] { null, "test" }, // null at the beginning
+      new String[] { "test", null }, // null in the end
+      new String[] { "test", null, "foo" }, // null in the middle
+    };
+
+    for (String[] components : components_tests) {
+      try {
+        assertNotNull(new FacetLabel(components));
+        fail("empty or null components should not be allowed: " + Arrays.toString(components));
+      } catch (IllegalArgumentException e) {
+        // ok
+      }
+    }
+    
+    String[] path_tests = new String[] {
+        "/test", // empty in the beginning
+        "test//foo", // empty in the middle
+    };
+    
+    for (String path : path_tests) {
+      try {
+        assertNotNull(new FacetLabel(path, '/'));
+        fail("empty or null components should not be allowed: " + path);
+      } catch (IllegalArgumentException e) {
+        // ok
+      }
+    }
+
+    // a trailing path separator is produces only one component
+    assertNotNull(new FacetLabel("test/", '/'));
+    
+  }
+
+  @Test
+  public void testInvalidDelimChar() throws Exception {
+    // Make sure CategoryPath doesn't silently corrupt:
+    char[] buf = new char[100];
+    FacetLabel cp = new FacetLabel("foo/bar");
+    try {
+      cp.toString();
+      fail("expected exception");
+    } catch (IllegalArgumentException iae) {
+      // expected
+    }
+    try {
+      cp.copyFullPath(buf, 0, '/');
+      fail("expected exception");
+    } catch (IllegalArgumentException iae) {
+      // expected
+    }
+    cp = new FacetLabel("abc", "foo/bar");
+    try {
+      cp.toString();
+      fail("expected exception");
+    } catch (IllegalArgumentException iae) {
+      // expected
+    }
+    try {
+      cp.copyFullPath(buf, 0, '/');
+      fail("expected exception");
+    } catch (IllegalArgumentException iae) {
+      // expected
+    }
+    cp = new FacetLabel("foo:bar");
+    try {
+      cp.toString(':');
+      fail("expected exception");
+    } catch (IllegalArgumentException iae) {
+      // expected
+    }
+    try {
+      cp.copyFullPath(buf, 0, ':');
+      fail("expected exception");
+    } catch (IllegalArgumentException iae) {
+      // expected
+    }
+    cp = new FacetLabel("abc", "foo:bar");
+    try {
+      cp.toString(':');
+      fail("expected exception");
+    } catch (IllegalArgumentException iae) {
+      // expected
+    }
+    try {
+      cp.copyFullPath(buf, 0, ':');
+      fail("expected exception");
+    } catch (IllegalArgumentException iae) {
+      // expected
+    }
+  }
+
+  @Test
+  public void testLongPath() throws Exception {
+    String bigComp = null;
+    while (true) {
+      int len = FacetLabel.MAX_CATEGORY_PATH_LENGTH;
+      bigComp = _TestUtil.randomSimpleString(random(), len, len);
+      if (bigComp.indexOf('\u001f') != -1) {
+        continue;
+      }
+      break;
+    }
+
+    try {
+      assertNotNull(new FacetLabel("dim", bigComp));
+      fail("long paths should not be allowed; len=" + bigComp.length());
+    } catch (IllegalArgumentException e) {
+      // expected
+    }
+
+    try {
+      assertNotNull(new FacetLabel("dim\u001f" + bigComp, '\u001f'));
+      fail("long paths should not be allowed; len=" + bigComp.length());
+    } catch (IllegalArgumentException e) {
+      // expected
+    }
+  }
+  
+}

